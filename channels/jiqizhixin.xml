<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>大模型中标TOP10里的黑马：中关村科金的应用攻坚之道</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:46:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ac803b5a-ebae-4bb1-9db4-8ce61e88d0d6/1768271983190.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;一份大模型中标数据报告，揭示了产业重心转移的清晰轨迹：应用类项目占比近六成，市场用真金白银为 &amp;ldquo;落地&amp;rdquo; 投票。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;2025 年，中国大模型产业在招投标市场上演了一场令人瞠目的 &amp;ldquo;狂飙&amp;rdquo;。智能超参数的监测数据显示，全年大模型相关中标项目数量达到 &lt;strong&gt;7539 个&lt;/strong&gt;，披露金额 &lt;strong&gt;295.2 亿元&lt;/strong&gt;，较 2024 年分别激增 &lt;strong&gt;396%&lt;/strong&gt; 与 &lt;strong&gt;356%&lt;/strong&gt;。市场正以前所未有的速度，将技术潜力兑换为商业订单。&lt;/p&gt;&lt;p&gt;更关键的结构性变化在于项目类型：&lt;strong&gt;应用类项目占比高达 58%&lt;/strong&gt;，在 2025 年 11 月甚至达到 63% 的峰值。这明确宣告，产业的焦点已从实验室的参数竞赛，彻底转向商业场景的价值验证。市场用最直接的预算分配，为大模型的发展路径投下了决定性的一票。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;市场转向：从 &amp;ldquo;技术占位&amp;rdquo; 到 &amp;ldquo;价值锚地&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的大模型中标市场，描绘出一条陡峭的指数增长曲线。这不仅意味着市场规模在膨胀，更揭示了价值重心在迁移。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuYVeYtzyMbImVLgNf2uVeQ1BHP8BC9Sqzw9hn09RBly0qdy9CFJxibA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7046296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527965" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b58f84a2-87a3-47bb-9bbe-c3a83e20add0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;根据智能超参数的分类，大模型项目被划分为算力、数据、大模型（基座 / 平台）和应用（智能体 / 场景解决方案）四大类。2025 年的数据清晰地显示，&lt;strong&gt;应用类项目以 58% 的数量占比一骑绝尘&lt;/strong&gt;，成为绝对主流。从季度趋势看，其占比从第一季度的 44% 一路攀升至第三季度的 61%，并在第四季度稳定在 60.5%。&lt;/p&gt;&lt;p&gt;与此同时，&lt;strong&gt;算力类项目金额占比最高（52.9%）&lt;/strong&gt;，但数量占比（27%）远低于应用类。这背后是一个关键的市场信号：随着 DeepSeek、通义千问 Qwen 等高性能开源模型的成熟，更多企业选择直接采购算力，调用或微调现有成熟模型，以快速构建自己的应用。大模型（基座 / 平台）类项目占比为 10%，其中智能体开发平台的采购成为重要组成部分。&lt;/p&gt;&lt;p&gt;行业分布同样耐人寻味。教科、政务、通信、能源、金融是项目数量排名前五的行业。其中，&lt;strong&gt;政务行业以金额占比约 40% 位居榜首&lt;/strong&gt;，这与各地政府将智算中心升级为与大模型强绑定的产业赋能中心密切相关。金融行业则在下半年展现出从算力投资向应用部署的明显转向。&lt;/p&gt;&lt;p&gt;从厂商格局看，通用大模型厂商（如科大讯飞、百度、火山引擎、阿里云等）和拥有广泛渠道的三大运营商是中标主力。然而，一个值得注意的现象是，像&lt;strong&gt;中关村科金、蚂蚁数科这样的垂类大模型厂商，凭借在金融等细分赛道的深耕，同样在中标市场占据了一席之地&lt;/strong&gt;。这印证了一个产业判断：当通用模型的能力差距趋于收敛，&lt;strong&gt;生态构建能力与场景掌控力&lt;/strong&gt;，正取代单纯的模型性能，成为新的竞争壁垒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;攻坚样本：中关村科金的 &amp;ldquo;行业深潜&amp;rdquo; 与 &amp;ldquo;场景破局&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在通用大模型厂商凭借全栈能力横扫市场的同时，另一条深耕垂直领域的路径同样结出了硕果。中关村科金，这家并非以通用模型见长的企业，正是这条路径上的一个典型攻坚者，其在中标市场的表现，精准映射了 &amp;ldquo;应用为王&amp;rdquo; 时代的核心逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkArLp0HCauialpszTDMEvkN5GU1LqqF7UVA7Gd09GiblBmFyooR7S7t9vw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="1.8583333333333334" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527966" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6bcf4175-1285-4af1-b161-ccc93e228e7f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;智能超参数发布的《中国大模型中标项目监测与洞察报告 (2025)》显示，&lt;strong&gt;中关村科金以 23 个中标项目入围 2025 年应用类大模型项目中标厂商 TOP10 榜单，是榜单中少数聚焦垂类场景的大模型厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其战略自始就锚定 &amp;ldquo;应用&amp;rdquo; 与 &amp;ldquo;落地&amp;rdquo;。中关村科金自 2023 年起便战略布局大模型平台，并沿着&lt;strong&gt; &amp;ldquo;平台 + 应用 + 服务&amp;rdquo; 的三级引擎战略&lt;/strong&gt;，推动垂类大模型在垂直行业和场景的应用落地，为 &amp;ldquo;应用为王&amp;rdquo; 提供了多个维度的注脚，其在金融、政务、工业、汽车、零售等多个赛道的全面落地，展现了垂类大模型厂商的独特竞争力。&lt;/p&gt;&lt;p&gt;在工业制造这一复杂且专业壁垒极高的领域，中关村科金展现出将前沿 AI 技术与传统产业深度融合的深厚功力。其助力中国船舶集团经济研究中心打造的&lt;strong&gt;船舶行业大模型 &amp;ldquo;百舸&amp;rdquo;&lt;/strong&gt;，融合了船舶领域百万级专业知识库与长文本推理能力，构建了智能问答、研报写作、文档解读、情报分析等行业智能体，有效推动了船舶行业 &amp;ldquo;数智大脑&amp;rdquo; 的建设。&lt;/p&gt;&lt;p&gt;针对有色金属冶炼等高能耗场景，中关村科金与南方有色金属公司合作，打造了&lt;strong&gt;广西首个有色金属行业大模型&lt;/strong&gt;，通过落地冶炼工艺优化、能源管理、设备智能运维等核心场景智能体，取得了关键生产环节的量化突破：将主操手操作频率降低 90%，温度控制偏差由 &amp;plusmn;15℃收窄至 &amp;plusmn;5℃，并助力综合能耗下降 8%。这标志着垂类大模型已能深入高能耗流程的核心环节，为工业绿色智能化转型提供了关键技术支撑。&lt;/p&gt;&lt;p&gt;在交通基建这类传统上被认为与 AI 技术距离较远的行业，中关村科金也成功开辟了智能化新路径。其与宁夏交建联合打造的&lt;strong&gt;交通基建垂类大模型 &amp;ldquo;灵筑智工&amp;rdquo;&lt;/strong&gt;，基于上万份行业规范、工程技术文档等高质量数据训练，使模型在专业问题上的回答准确率较通用大模型提升 40%。基于该模型构建的专业智能体，在实际应用中平均提效超 60%，不仅解决了工程师撰写施工方案、核算工程量等耗时费力的痛点，更通过智能成本预警等功能，推动了整个行业从 &amp;ldquo;经验驱动&amp;rdquo; 向 &amp;ldquo;数据 + AI 驱动&amp;rdquo; 的转型。&lt;/p&gt;&lt;p&gt;如果说在工业等传统领域的突破证明了其技术下沉的能力，那么在数字化程度最高、要求最严苛的金融行业，中关村科金的深耕则更凸显了其 &amp;ldquo;行业 Know-how&amp;rdquo; 的价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依据智能超参数报告，中关村科金在金融行业大模型项目中标厂商中位列第四&lt;/strong&gt;，仅次于百度云、科大讯飞、火山引擎等大厂，成为垂类厂商深耕金融赛道的标杆代表。其中标项目广泛覆盖智能客服升级、远程视频银行、智能风控合规、智能运营提效等核心业务场景。&lt;/p&gt;&lt;p&gt;中关村科金深耕金融领域多年，已服务 500 多家头部金融机构，包括 50% 以上百强银行及 70% 的信托机构，沉淀了深厚的行业 Know-how。依托其 &amp;ldquo;得助大模型平台 + 金融行业智能体平台&amp;rdquo; 的核心产品组合，中关村科金打造了覆盖 &amp;ldquo;营销 - 风控 - 运营 - 企业服务&amp;rdquo; 全链路的金融智能体矩阵，这并非简单的工具叠加，而是将大模型能力深度融入金融机构从获客、服务到风险管理的核心业务流程。&lt;/p&gt;&lt;p&gt;例如，中关村科金与&lt;strong&gt;中信券商&lt;/strong&gt;合作打造大模型财富助手，能够实时洞察市场动态与数据，精准匹配理财产品与投资组合，并自动生成专业营销话术，助力展业效率提升 3 倍；为&lt;strong&gt;某国有大型商业银行&lt;/strong&gt;提供全栈音视频服务，实现视频银行、合规双录、视频客服、视频会议等全场景统一接入管理；与&lt;strong&gt;中国电建财务公司&lt;/strong&gt;联合打造 &amp;ldquo;财神大模型&amp;rdquo; 及办公智能体，实现员工业务知识获取效率提升 70%；为&lt;strong&gt;百年人寿&lt;/strong&gt;打造的保险知识库问答智能体，问答准确率稳定在 90% 以上，知识获取效率提升 50%，赋能内部 17 个部门；为&lt;strong&gt;申万宏源证券&lt;/strong&gt;打造合规垂直领域专有大模型，赋能员工高效查询制度文件，筑牢业务合规防线。&lt;/p&gt;&lt;p&gt;在智能客服与数字人这一大模型落地最火热的赛道，中关村科金的表现尤为突出，已成为该领域的核心参与者。IDC《中国智能客服市场份额，2024》报告显示，中关村科金位居中国智能客服市场第四，位列垂类大模型厂商第一。根据智能超参数的中标报告，&lt;strong&gt;在 &amp;ldquo;智能客服 &amp;amp; 数字人&amp;rdquo; 应用场景，科大讯飞、百度、中关村科金是中标项目数量排名前三的厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;中关村科金的核心支撑源于自研的得助智能客户平台 5.0，这一覆盖营销服全场景的新一代人机协作智能平台，以 &amp;ldquo;人类员工 + 数字员工&amp;rdquo; 协同为核心，通过多智能体深度联动，让数字员工成为人类员工的专业伙伴与高效延伸。其解决方案已成功赋能金融、汽车、零售、跨境出海、政务民生等多个行业领域，形成了兼具广度与深度的行业实践图谱。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;汽车行业&lt;/strong&gt;，中关村科金的解决方案已深度融入客户运营全链路。例如，其与&lt;strong&gt;丰田&lt;/strong&gt;合作，通过大模型语音智能体进行老客精准营销外呼，在实现超 60% 高接通率，激活沉睡客户；为&lt;strong&gt;岚图汽车&lt;/strong&gt;构建的销售洞察质检平台，则将销售流程合规性提升 70%。这些实践表明，中关村科金正将智能客服从传统的服务支持角色，升级为驱动销售增长与客户体验升级的核心引擎。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;零售与消费领域&lt;/strong&gt;，面对海量、高频的客户咨询与严苛的服务体验要求，中关村科金为&lt;strong&gt;瑞幸咖啡、添可、老板电器&lt;/strong&gt;等知名品牌提供了从智能应答、全渠道服务到全量质检的一体化方案。这些方案不仅有效应对了大促期间的咨询洪峰，更通过智能化工具将客服中心从成本部门转变为提升客户满意度、挖掘服务价值的关键环节。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;全球化服务&lt;/strong&gt;方面，通过构建支持多语种实时互译、全渠道智能路由的 Instadesk 全球客户联络中心解决方案，中关村科金帮助&lt;strong&gt; Imou 乐橙、阿里巴巴国际站&lt;/strong&gt;等出海企业攻克了跨时区、跨文化的服务难题，实现了服务效率与全球用户满意度的双重提升；也为 &lt;strong&gt;UniUni &lt;/strong&gt;这样的北美本地物流平台，以及&lt;strong&gt;泰国大都会水务局&lt;/strong&gt;这样的海外公共服务机构，提供了稳定、高效的多语言智能客服支持，成功将服务能力从企业出海延伸至本地化公共服务领域。&lt;/p&gt;&lt;p&gt;这些遍布多行业的落地案例共同表明，中关村科金的智能客服解决方案不再是简单的问答工具，而是深度嵌入客户旅程、与业务流程紧密耦合的 &amp;ldquo;价值挖掘引擎&amp;rdquo;。这正契合了当前大模型应用从 &amp;ldquo;功能实现&amp;rdquo; 向 &amp;ldquo;业务赋能&amp;rdquo; 演进的核心趋势。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;未来展望：2026，价值交付的深水区与垂类厂商的护城河&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标数据，已经为 2026 年乃至更远未来的发展轨迹画下了清晰的延长线。市场增长的 &amp;ldquo;陡峭曲线&amp;rdquo; 或许会逐渐平缓，但竞争的 &amp;ldquo;深度曲线&amp;rdquo; 将陡然加剧。行业将全面驶入&lt;strong&gt;价值的 &amp;ldquo;深水区&amp;rdquo;&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一，ROI 成为硬指标：从 &amp;ldquo;成本中心&amp;rdquo; 到 &amp;ldquo;利润引擎&amp;rdquo; 的证明之战。&lt;/strong&gt; 随着大模型技术本身日趋成熟和开源化，获取先进 AI 能力的门槛正在迅速降低。2026 年，企业客户将不再满足于 &amp;ldquo;拥有大模型&amp;rdquo; 的演示效果，而是会苛刻地追问每一个 AI 项目的投资回报率（ROI）。这意味着，大模型必须从 &amp;ldquo;成本中心&amp;rdquo; 证明自己作为 &amp;ldquo;利润中心&amp;rdquo; 或 &amp;ldquo;效率引擎&amp;rdquo; 的价值。峰瑞资本创始合伙人李丰的判断正在成为行业共识：AI 投资将进入 &amp;ldquo;第三阶段&amp;rdquo;，即投资真正落地、能挣到钱的应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二，行业 Know-how 与高质量私有数据，将构筑起最坚固的护城河。 &lt;/strong&gt;当通用模型的底层能力可以通过 API 便捷获取时，决定应用效果的将不再是模型的通用性能，而是对特定行业业务流程、专业术语、合规红线的深度理解，以及基于私有数据训练出的 &amp;ldquo;领域专家&amp;rdquo; 能力。中关村科金为中国电建财务公司打造的 &amp;ldquo;财神大模型&amp;rdquo;，与宁夏交建用上万份规范训练的 &amp;ldquo;灵筑智工&amp;rdquo; 大模型，其价值核心正在于此。这些基于海量、高价值、非公开行业数据构建的垂类模型，不仅效果远超通用模型，更因其数据资产的独特性和专业性，形成了竞争对手难以短时间复制的壁垒。未来，&amp;ldquo;数据资产化&amp;rdquo; 与 &amp;ldquo;知识工程化&amp;rdquo; 的能力，将比单纯的算法创新更为关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三，应用形态将从 &amp;ldquo;单点智能工具&amp;rdquo; 演进为 &amp;ldquo;全链路业务智能体&amp;rdquo;。&lt;/strong&gt; 当前的应用大多集中于客服、问答、内容生成等单点环节。下一步，大模型将更深入地与业务流程融合，进化为能够自主完成复杂任务的 &amp;ldquo;业务智能体&amp;rdquo;（Agent）。未来的智能客服将不再是孤立的问答机器人，而是融入客户旅程，能够主动进行销售外呼、完成复杂业务办理、甚至进行客户情绪安抚与挽留的 &amp;ldquo;全能型数字员工&amp;rdquo;。这要求供应商提供的不是单点产品，而是一整套能够与企业现有 IT 系统深度集成、随业务需求灵活编排的智能体生态系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGib2wScIJJRS3gBdbXdGaNic1ooYib28CmErmYgno8QrjDaoRE2YwKYWw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527998" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cfd2e9ac-9259-41e0-b7e5-1f31db85a9b2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;第四，生态协同将成为主流，垂类厂商与通用平台的关系从 &amp;ldquo;替代&amp;rdquo; 转向 &amp;ldquo;共生&amp;rdquo;。&lt;/strong&gt; 未来的市场格局很可能不是 &amp;ldquo;你死我活&amp;rdquo; 的替代关系，而是分层协作的共生生态。像中关村科金这样的垂类应用厂商，将更专注于在特定行业深挖场景，打造开箱即用的行业智能体解决方案；而通用大模型厂商和云厂商，则提供稳定、高效、低成本的算力与模型基座。&lt;strong&gt;中关村科金携手华为云、阿里云、百度智能云、火山引擎、亚马逊云科技、超聚变等企业共同发布的 &amp;ldquo;超级连接&amp;rdquo; 全球生态伙伴计划，正体现了这种开放协作的趋势。&lt;/strong&gt;2026 年，能否融入主流生态、能否与上下游高效协同，将决定一家厂商的市场边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标狂飙，是中国大模型产业从技术狂热走向商业理性的成人礼。市场用近 300 亿的订单，宣告了 &amp;ldquo;应用落地&amp;rdquo; 时代的正式开启。&lt;/p&gt;&lt;p&gt;2026 年的 &amp;ldquo;价值深水区&amp;rdquo;，将是检验真功夫的战场。大厂之外，像中关村科金这样，凭借对行业的深刻理解与扎实的产品和价值交付能力，已然为企业级大模型和智能体厂商如何穿越周期、赢得市场，提供了一个清晰的范本。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，梁文锋署名开源「记忆」模块，DeepSeek V4更细节了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:18:05 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/30c33348-2e2f-4927-8387-a39e06b425ed/1768270430059.png" style="width: 700%;" class="fr-fic fr-dib"&gt;就在十几个小时前，DeepSeek 发布了一篇新论文，主题为《Conditional Memory via Scalable Lookup:A New Axis of Sparsity for Large Language Models》，与北京大学合作完成，作者中同样有梁文锋署名。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALWDibzfe0HzEE5mIybPwTIAI5uGiaI0QA1ZZqyzr79hq8C0bwgj2SOiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528058" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8300495e-2055-4ff9-abf8-9873f1500199/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;简单总结一波&lt;strong&gt;这项新研究要解决的问题&lt;/strong&gt;：目前大语言模型主要通过混合专家（MoE）来实现稀疏化，这被称为「条件计算」。但是，现有的 Transformer 缺少原生的知识查找机制，只能被迫通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;针对这一现状，&lt;strong&gt;DeepSeek 提出了条件记忆（conditional memory），从而与 MoE 的条件计算互补，并通过引入一个新模块 Engram 来实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，模块「Engram」相关的实现已经上传到了 GitHub。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA86NTkhF1jNYqnOSG9OAujyOVQa3cUGicFmAPEXKXroicohumgL38XGqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528060" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c16a6833-4c22-46d2-a7f8-a93402bade79/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;项目地址：https://github.com/deepseek-ai/Engram&lt;/p&gt;&lt;p&gt;这让网友们感慨：「DeepSeek is back！」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALjBOxiceaogbXLPCibElgW4JDeWTo2491OtK0YJTS7emWDCWWCPJh3WA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9717514124293786" data-s="300,640" data-type="png" data-w="1062" type="block" data-imgfileid="503528062" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0a406ecb-aa43-4a96-923a-1b2ebd0b28f6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，结合元旦期间公布的研究《mHC:Manifold-ConstrainedHyper-Connections》，我们可以明确的是 DeepSeek v4 的模样愈发清晰，就等上新了！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;除了条件计算（MoE），LLM 还需要一个独立的条件记忆 Engram&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MoE 模型通过条件计算实现了模型容量的扩展，但现有的 Transformer 架构缺乏原生的知识查找原语，只能通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;为了解决这一问题，DeepSeek 提出了条件记忆（conditional memory）这一与条件计算互补的稀疏化维度，并通过 Engram 模块加以实现。Engram 在经典 𝑁-gram 嵌入的基础上进行了现代化改造，使其能够以 O (1) 时间复杂度完成知识查找。&lt;/p&gt;&lt;p&gt;通过形式化提出稀疏性分配问题，DeepSeek 还发现了一条&lt;strong&gt;呈 U 型的扩展规律&lt;/strong&gt;，用以刻画神经计算（MoE）与静态记忆（Engram）之间的最优权衡关系。&lt;/p&gt;&lt;p&gt;在这一规律的指导下，&lt;strong&gt;DeepSeek 将 Engram 扩展至 270 亿参数规模，并在严格等参数量、等 FLOPs 的条件下，其整体性能显著优于纯 MoE 基线模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;尤为值得注意的是，尽管记忆模块本身主要被用于提升知识检索能力（如 MMLU 提升 +3.4、CMMLU 提升 +4.0），但 DeepSeek 观察到其在通用推理能力（如 BBH 提升 +5.0、ARC-Challenge 提升 +3.7）以及代码与数学推理任务（HumanEval 提升 +3.0、MATH 提升 +2.4）上带来了更为显著的增益。&lt;/p&gt;&lt;p&gt;进一步的分析表明，&lt;strong&gt;Engram 能够将静态知识的重建负担从模型的浅层中剥离出来，从而有效加深网络用于复杂推理的有效深度&lt;/strong&gt;。此外，通过将局部依赖关系交由查表机制处理，Engram 释放了注意力机制的容量，使其能够更专注于全局上下文建模，从而显著提升了长上下文检索能力（例如 Multi-Query NIAH 的准确率从 84.2 提升至 97.0）。&lt;/p&gt;&lt;p&gt;最后，Engram 在系统层面同样展现出基础设施感知的高效性：其确定性的寻址方式支持在运行时从主机内存进行预取，几乎不会带来额外的性能开销。&lt;/p&gt;&lt;p&gt;DeepSeek 认为，&lt;strong&gt;条件记忆将成为下一代稀疏大模型中不可或缺的核心建模原语&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Engram 架构如下，其设计目标是在结构上将静态模式存储与动态计算过程从 Transformer 主干网络中分离出来，从而对其进行增强。该模块对序列中每一个位置依次执行两个功能阶段：检索与融合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAFKoRVttBOmQoIev9VHCpaVOlLtibYm336AibGdPxlqx2d1wa5kr1OEMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528063" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d9aef974-d08b-4723-be55-ed8ac921b9a5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在运行过程中，DeepSeek 首先对当前位置的后缀 N-gram 进行提取与压缩，并通过哈希机制以确定性的方式检索对应的静态嵌入向量。随后，这些被检索到的嵌入会在当前隐藏状态的调制下进行动态调整，并进一步通过一个轻量级卷积操作加以精炼。最后，Engram 与多分支架构进行集成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于哈希 𝑁-gram 的稀疏检索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一阶段的目标是将局部上下文映射到静态记忆条目，这一过程主要包括分词器压缩以及通过确定性哈希机制来检索对应的嵌入表示。&lt;/p&gt;&lt;p&gt;分词器压缩：为了最大化记忆单元的语义密度，DeepSeek 引入了一层词表投影（vocabulary projection）。为此，他们预先设计了一个映射函数&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAgSxiccS8q33sCb3TGn941oX3R7gPxTBPYUwhOuHPGQkUic5Y3KsYOmkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2389558232931727" data-s="300,640" data-type="png" data-w="996" type="block" data-imgfileid="503528064" data-aistatus="1" data-original-style="width:58px;height:20px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4b3f0322-af0a-4995-a5d2-f385e590fefe/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 12.44%;"&gt;，其将原始 token ID 映射为基于文本规范化等价关系（例如使用 NFKC 规范化、统一大小写等）得到的规范化标识符（canonical identifiers）。在实际应用中，对于一个规模为 128k 的分词器，该过程能够将有效词表规模缩减约 23%（详见附录 C）。&lt;/p&gt;&lt;p&gt;多头哈希：直接对所有可能的 N-gram 组合空间进行参数化在计算和存储上都是不可行的。借鉴 Tito Svenstrup 等（2017）的工作，DeepSeek 采用了一种基于哈希的近似方法。为了降低哈希冲突的影响，对于每一种 N-gram 阶数 n，引入 K 个相互独立的哈希头。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上下文感知门控&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前一阶段通过哈希 𝑁-gram 从条件记忆中检索得到的嵌入向量，本质上提供的是一种与具体语境无关的静态先验信息。然而，正因为其静态属性，这些嵌入缺乏对当前上下文的自适应能力，并且在实际应用中可能受到哈希冲突或词项多义性带来的噪声干扰。&lt;/p&gt;&lt;p&gt;为此，DeepSeek 在检索之后引入了一种上下文感知的门控机制，其设计灵感来源于注意力机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;系统效率：计算与存储的解耦&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在带有记忆机制的模型中，规模扩展往往受到 GPU 高带宽显存（HBM）容量有限的制约。然而，Engram 所采用的确定性检索机制天然支持将参数存储与计算资源进行解耦。不同于 MoE 依赖运行时隐藏状态进行动态路由，Engram 的检索索引完全由输入 token 序列决定。这种可预测性使得针对训练与推理阶段的专门优化策略成为可能，如图 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAD4Hibb8SMweeACleRMlsD8LmqQlMl1llDq9iciaO6Egveyo8RsPSLNpNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.725" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528065" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4fe509c8-9e8d-412b-9529-666695d72011/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在训练阶段，为容纳大规模嵌入表，DeepSeek 采用标准的模型并行方案，将嵌入表分片分布在多张 GPU 上。在前向传播过程中，通过 All-to-All 通信原语收集被激活的嵌入行；在反向传播阶段，则将对应梯度分发回各个分片，从而使总可用记忆容量能够随加速器数量线性扩展。&lt;/p&gt;&lt;p&gt;在推理阶段，这种确定性特性进一步支持一种预取&amp;ndash;重叠（prefetch-and-overlap）策略。由于在前向计算开始之前即可确定所需访问的记忆索引，系统能够通过 PCIe 从容量充足的主机内存中异步地预取嵌入向量。为有效掩蔽通信带来的延迟，Engram 模块被放置在主干网络中的特定层级，利用其前序 Transformer 层的计算作为缓冲，从而避免 GPU 计算停顿。&lt;/p&gt;&lt;p&gt;这也要求一种硬件 &amp;mdash; 算法协同设计（hardware&amp;ndash;algorithm co-design）：一方面，将 Engram 放置得更深可以拉长用于隐藏通信延迟的计算窗口；另一方面，从建模效果来看，较早地介入以卸载局部模式的重建更为有利。因此，Engram 的最优插入位置必须同时满足建模性能与系统时延两方面的约束。&lt;/p&gt;&lt;p&gt;此外，自然语言中的 𝑁-gram 天然遵循 Zipfian 分布，即少量高频模式贡献了绝大多数的记忆访问。这一统计特性启发研究者可以构建一种多级缓存层次结构（Multi-Level Cache Hierarchy）：将高频访问的嵌入缓存于更快的存储介质中（如 GPU HBM 或主机 DRAM），而将大量低频的长尾模式存放在容量更大但速度较慢的存储介质中（如 NVMe SSD）。这种分层设计使 Engram 能够扩展到极大规模的记忆容量，同时对有效访问延迟的影响保持在最低水平。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;U 型扩展规律与稀疏性分配&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为「条件记忆」的一种具体实现，Engram 在结构上与 MoE 专家提供的「条件计算」形成了互补。本节旨在探究这种二元特性（Duality）的扩展属性，以及如何最优地分配稀疏容量。&lt;/p&gt;&lt;p&gt;具体而言，本项研究由两个核心问题驱动：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;有限约束下的分配&lt;/strong&gt;：在总参数量和训练计算量固定（即等参数、等 FLOPs）的情况下，应该如何在 MoE 专家与 Engram 嵌入之间划分稀疏容量？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无限记忆范式&lt;/strong&gt;：考虑到 Engram 具有不随规模增长（Non-scaling）的&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAHcWDB842FnjQ5Q4PhGicvSibickXHW66FibPGUah3vTkP1UyWSE1iblunJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5721925133689839" data-s="300,640" data-type="png" data-w="374" type="block" data-imgfileid="503528067" data-aistatus="1" data-original-style="width:28px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6388a81a-17e5-41f7-ab56-1a51aee7b2c7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 5.39%;"&gt;查找开销，如果放宽记忆预算或进行激进扩展，Engram 自身会表现出怎样的扩展行为？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首先来看 &lt;strong&gt;MoE 与 Engram 之间的最优分配比例&lt;/strong&gt;。在计算匹配公式时，DeepSeek 使用以下三个参数度量来分析这个权衡：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;P_tot：总的可训练参数，不包括词汇嵌入和语言模型头。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;P_act：每个 token 激活的参数。这一量度决定了训练成本（FLOPs）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMRupgtg13d22OV6JrKF6CiaUEO14Bnv7XCTEib2lv2Mc1fnm8WZlfWMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.15789473684210525" data-s="300,640" data-type="png" data-w="836" type="block" data-imgfileid="503528069" data-aistatus="1" data-original-style="width:132px;height:21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/a97cfbce-f1f9-4dc5-87d8-5998968c4163/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 24.99%;"&gt;：不激活的参数，表示可用于扩大模型大小而不增加计算成本的「自由」参数预算（例如未选择的专家或未检索的嵌入）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DeepSeek 在每个 FLOPs 预算内保持 P_tot 和 P_act 固定，这样模型具有相同数量的参数和相同的每 token FLOPs。对于 MoE，P_act 由选定的 top-k 专家决定，而未选择的专家的参数贡献给 P_sparse。对于 Engram，每个 token 只检索固定数量的槽（slots），因此增加嵌入槽的数量会增加 P_tot，但不会增加每 token 的 FLOPs。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAH43shOXT1A8Alp089KGPz1kC74mepCkHpMicXaflpbr2icTfyas8NeXA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.08055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528070" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6544befb-5aa2-44cb-96da-70dd742d8244/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;「在无限内存模式下的 Engram」&lt;/strong&gt;。在固定参数预算下优化分配之外，DeepSeek 探索了互补的设置：激进的内存扩展。这个研究的动机来自于 Engram 独特的能力，能够将存储与计算解耦。&lt;/p&gt;&lt;p&gt;DeepSeek 使用一个固定的 MoE 主干，具有 P_tot &amp;asymp; 3B 和 P_act = 568M，并训练了 100B 个 token 以确保收敛。在此基础上附加了一个 Engram 表，并调整了槽的数量 M 从 2.58 &amp;times; 10⁵ 到 1.0 &amp;times; 10⁷（增加最多约 13 亿参数）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下图 3（左）揭示了验证损失与分配比例 𝜌 之间一致的 U 形关系&lt;/strong&gt;。值得注意的是，即使 MoE 分配减少到仅 𝜌 &amp;asymp; 40%（即 5.7B 模型为 46 个专家，9.9B 模型为 43 个专家），Engram 模型仍然达到了与纯 MoE 基准（𝜌 = 100%）相当的性能。&lt;/p&gt;&lt;p&gt;此外，纯 MoE 基准证明是次优的：将大约 20%-25% 的稀疏参数预算重新分配给 Engram 获得最佳性能。定量分析中，在 10B 范围内（𝐶 = 6 &amp;times; 10&amp;sup2;⁰），验证损失从 1.7248（𝜌 = 100%）改善到 1.7109，接近 𝜌 &amp;asymp; 80% 时的最优值（&amp;Delta; = 0.0139）。值得注意的是，这一最优点的位置在不同的范围内稳定（𝜌 &amp;asymp; 75%-80%），表明在固定稀疏性下，各个规模之间有一个稳健的分配偏好。这一观察到的 U 形确认了两种模块之间的结构互补性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;图 3（右）展示了增加内存槽数量会显著改善验证损失，并且这一改进在整个范围内持续稳定&lt;/strong&gt;。该曲线遵循严格的幂律（在对数空间中线性），这表明 Engram 提供了一个可预测的扩展旋钮：更大的内存在不需要额外计算的情况下继续带来收益。&lt;/p&gt;&lt;p&gt;关键一点是，在扩展效率方面：虽然 OverEncoding 通过更大的内存表受益，但 Engram 在相同的内存预算下释放了更大的扩展潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结合分配规律来看，这些结果验证了条件记忆作为稀疏容量的独立、可扩展轴的作用，它补充了 MoE 的条件计算。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYI9OhrrdFotHP42En2iajz85DmEC2doZWnOoJYLwSXO3e1sdqaCImJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.4925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528081" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/543c6639-1b21-4309-840f-f78637bb6ca7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过提出的 Engram 架构以及经验推导出的分配法则，DeepSeek 将 Engram 扩展至数十亿参数规模，以验证其在真实语言模型预训练中的有效性。&lt;/p&gt;&lt;p&gt;总共训练了以下四种模型：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Dense-4B（总参数量 41 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MoE-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Engram-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以及 Engram-40B（总参数量 395 亿）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所有模型均采用完全相同的数据训练流程（相同的 token 预算及顺序），且在激活参数量上严格匹配。&lt;/p&gt;&lt;p&gt;关于实验设置，所有模型均在包含 2620 亿 token 的语料库上进行预训练，并采用了 DeepSeek-v3 的分词器，其词表大小为 128k。DeepSeek 在涵盖语言建模、知识、推理、阅读理解以及代码 / 数学的多样化基准测试集上对模型进行评估。对于每项基准测试，均遵循标准的提示词协议和评估指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;先来看大规模预训练的实验结果，如下表 1 所示，稀疏架构展示了比密集模型更优的扩展规律。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在相同的训练计算预算下，所有三种稀疏变体（MoE-27B，Engram-27B/40B）在所有基准测试中显著超越了 iso-FLOPs 的 Dense-4B 基准。&lt;/p&gt;&lt;p&gt;更重要的是，&lt;strong&gt;Engram-27B 在 iso - 参数和 iso-FLOPs 的 MoE-27B 基准上持续取得改进&lt;/strong&gt;。有趣的是，这些提升并不限于知识密集型任务（例如，MMLU: +3.0，MMLU-Pro: +1.8，CMMLU: +4.0），在这些任务中，内存容量直观上是有益的。此外还观察到，在一般推理领域（例如，BBH: +5.0，ARC-Challenge: +3.7，DROP: +3.3）以及代码和数学推理任务（例如，HumanEval: +3.0，MBPP: +1.6，GSM8K: +2.2，MATH: +2.4）中，改进更加显著。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;扩展到 Engram-40B 进一步减少了预训练损失，并提高了大多数基准测试的性能&lt;/strong&gt;。尽管它尚未在每个任务上严格超越 Engram-27B，但这可能是由于训练不足的结果。此外，Engram-40B 与基准模型之间的训练损失差距在训练结束时继续扩大，表明扩展的内存容量尚未在当前的 token 预算内完全饱和。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACCBl08YcAEt8TJGEtgr6co2ElHKhympbpN6GoEMgJUSpFhSAichtaQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.1018518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528082" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3989c993-b2fb-4a25-b836-10319eb4d81b/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来是&lt;strong&gt;长上下文训练&lt;/strong&gt;。通过将局部依赖建模卸载至静态查找，Engram 架构为处理全局上下文保留了宝贵的注意力容量。DeepSeek 通过进行长文本扩展训练，对这一结构性优势进行了实验验证。通过采用严密的评估协议，将架构设计带来的贡献与基础模型本身的能力剥离开来，证明了 Engram 在长程检索和推理任务中带来了显著的性能增益。&lt;/p&gt;&lt;p&gt;DeepSeek 首先解耦基础模型能力与架构设计之间的影响，其次进行受控对照分析，结果如下表 2 所示，主要得出了以下两个结论：&lt;/p&gt;&lt;p&gt;一是&lt;strong&gt;超越注意力机制的长文本能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;虽然注意力机制和位置编码为上下文处理提供了结构基础，但实验结果表明，长文本性能并非仅由架构先验决定。通过观察 Engram 的演进轨迹（从 41k 步到 50k 步），即使在控制相同模型架构和固定长文本扩展阶段计算预算的前提下，长文本性能仍随预训练进程单调提升。这表明长文本性能与基础模型的通用建模能力存在内在耦合。因此，严谨的架构对比必须通过对齐「基础模型损失（Loss）」而非仅仅对齐「训练步数」来控制这一混淆变量。&lt;/p&gt;&lt;p&gt;二是&lt;strong&gt;受控设置下的架构优越性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;基于上述原则，DeepSeek 将 Engram 与 MoE 基准模型进行了对比测试。在控制基础能力的前提下，Engram 模块的效率增益变得十分显著：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等损耗设置（Iso-Loss Setting，41k 步 vs. 基准）&lt;/strong&gt;：该设置严格分离了架构效率的影响。当对比 Engram-27B（46k 步）与完整训练的 MoE-27B（50k 步），即预训练损失完全对齐的两个模型时，Engram 表现出显著增益。具体而言，它在复杂检索任务中大幅超越基准模型（例如，多查询「大海捞针」 NIAH：97.0 vs. 84.2；变量跟踪 VT：87.2 vs. 77.0）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等计算量设置（Iso-FLOPs Setting，50k 步 vs. 基准）&lt;/strong&gt;：在标准的等计算预算下，Engram-27B（50k 步）进一步拉大了差距，在所有指标上均实现了顶尖性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极端设置（约 82% 计算量）&lt;/strong&gt;：即使是提前停止训练的 Engram-27B（41k 步），在面对完整训练的 MoE-27B（50k 步）时依然极具竞争力。它在 LongPPL 指标上与基准持平，并在 RULER 测试中实现超越，这充分证明了 Engram 架构的内在优越性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528083" data-ratio="0.45555555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAfwbCxbtEKFLia4VL5J1662B4LxwO0Paq8m6Heic6ia4E5OCA0R09tvB4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/62e24474-5ef0-4253-8ddc-2de57dec69c3/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，下图 4 是&lt;strong&gt;对表示对齐与收敛速度的分析&lt;/strong&gt;。(a) 基于 LogitLens 的逐层 KL 散度分析。在模型浅层，KL 散度持续保持在较低水平，这表明 Engram 加速了预测的收敛。(b-c) 为基于 CKA 计算的相似度热力图。高相似度对角线显著的向上偏移表明，Engram 的浅层在功能上等效于 MoE 模型的深层，从而有效地增加了模型的深度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZIWf0cDNkZhTrlYbpiaicpZlRyIRuflwhEsYTJR8Cziatupd9FzHzJ6kg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528084" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/547b3877-47dc-45a6-9614-011ee6e43a5b/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更多细节请参考原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一个模型统一4D世界生成与重建，港科大One4D框架来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:10:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/9100d25b-1d5e-4994-8380-46ec7215d836/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;本文第一作者密振兴，香港科技大学计算机科学与技术学院人工智能方向博士生，研究方向是多模态理解与生成，视频生成和世界模型，目前正在寻找工业界全职职位。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，视频扩散模型在 &amp;ldquo;真实感、动态性、可控性&amp;rdquo; 上进展飞快，但它们大多仍停留在纯 RGB 空间。模型能生成好看的视频，却缺少对三维几何的显式建模。这让许多世界模型（world model）导向的应用（空间推理、具身智能、机器人、自动驾驶仿真等）难以落地，因为这些任务不仅需要像素，还需要完整地模拟 4D 世界。&lt;/p&gt;&lt;p&gt;来自香港科技大学（HKUST）的研究团队提出 One4D，一个统一的 4D 生成与 4D 重建框架。One4D 构造了一个同步输出多模态的视频扩散模型，能够用一个模型同步输出 RGB 视频与 Pointmap（XYZ）几何视频，并支持从单张图像到 4D 生成、从稀疏帧到 4D 生成 + 重建、以及从完整视频到 4D 重建等多种任务形态。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAy5FibWXueDFAwrB8GuU8D5SeXcCfHSlScdE5NGdFUNwMiawiaZfkFgTVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527905" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/aee20b91-4ff5-448e-bc7f-1b9d0cf75fca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2511.18922&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github：https://github.com/MiZhenxing/One4D&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;二、One4D 算法设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 的核心目标是用强大的视频生成模型（比如Wan Video）统一 4D 生成与 4D 重建，输出对齐的 RGB 和几何多模态结果。论文亮点有：&lt;/p&gt;&lt;p&gt;1. 多模态输出：RGB + Pointmap；&lt;/p&gt;&lt;p&gt;2. DLC：解耦 LoRA 控制，稳住 RGB 同时学几何对齐；&lt;/p&gt;&lt;p&gt;3. UMC：统一掩码条件，一套模型覆盖生成和重建任务。&lt;/p&gt;&lt;p&gt;具体来说，One4D 将动态 4D 场景表示为两种同步的输出模态。(1) RGB frames（外观）；(2) Pointmaps（XYZ），即与 RGB 视频对齐的 3 通道几何视频，每个像素存 XYZ 值，可进一步导出 Depth 并结合后处理估计相机轨迹，最终可视化为 4D 点云和相机。&lt;/p&gt;&lt;p&gt;并且，One4D 在一个框架内支持三种输入：单张图到 4D 生成，稀疏视频帧到 4D 生成 + 重建，完整视频到 4D 重建。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. DLC：解耦 LoRA 控制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在基于视频扩散模型的 &amp;ldquo;RGB + 几何&amp;rdquo; 多模态联合建模里，一个常见做法是把模态在通道维拼接。但在低资源微调时，这会导致严重的跨模态干扰，几何学不好，基础模型的 RGB 质量也容易被拖垮。而将两个模态在长宽维度拼接，共享参数，也会导致跨模态干扰，几何精度不高，而且与 RGB 无法保持对齐。&lt;/p&gt;&lt;p&gt;One4D 提出 Decoupled LoRA Control（DLC） 来专门解决这个问题，设计目标包括：&lt;/p&gt;&lt;p&gt;(1) 低资源微调也尽量保住底座视频模型的强先验；(2) 解耦 RGB 与几何生成，减少互相干扰；(3) 仍要保留必要的跨模态通信，确保像素级对齐一致。&lt;/p&gt;&lt;p&gt;具体做法是：&lt;/p&gt;&lt;p&gt;1. 为 RGB 与 Pointmap 分别挂载模态专属 LoRA，并且形成两条解耦计算分支，共享冻结的 base 参数，但 forward 分开跑。确保两个模态能够相对独立。&lt;/p&gt;&lt;p&gt;2. 再用少量 zero-init 的 control links 连接对应层，让两个模态从 0 开始逐步学会互相控制，从而实现精确的像素级对齐。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQTZaZkW0GIAP9IuIHY8oIRqgkYpEs9mgSJVMfMjkiaqlRdevibVTZbHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3425925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527877" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b7804e0d-830e-4922-a9f5-72aa7875997f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从直观上理解 DLC 的设计， RGB 分支努力保持视频美学与运动先验，几何分支专心拟合几何视频的分布，少量控制连接负责对齐同步。这也正是 One4D 强调的多模态输出同步生成的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. UMC：统一掩码条件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了使用同一个视频模型统一 4D 的生成和重建，One4D 基于Wan Video的多任务框架，提出了 Unified Masked Conditioning（UMC），把不同类型的条件如单帧、稀疏帧、全视频，统一打包成一个条件视频，缺失帧用 0 填充，并使用一个 mask 张量指定哪些帧需要生成。单张图对应纯生成，稀疏帧对应混合生成 + 重建，全视频对应纯重建。在UMC的具体实现上，RGB 分支的条件视频通过 VAE 编码之后，连接到 RGB 的 latent states 上。而 XYZ 分支不直接使用这个条件视频，控制信号是通过 DLC 从 RGB 传递给 XYZ，这保证了 XYZ 分支能够更好地去适应新模态。UMC 的设计让 One4D 具备一个非常实用的能力，同一个扩散骨干，同时做 4D 生成和 4D 重建。One4D 模型不需要为不同任务改结构，只需改变输入帧的稀疏度，就可以在不同生成与重建任务之间平滑切换。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAnGBjSE74EJmJvQPuSGjUhwJE32v1YhP5XGCOibkzACIONCmbiaVSbsHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527906" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2844cf21-3eb5-49ac-91f4-7b3309ea4dbe/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 训练数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练 One4D，需要获得大规模 &amp;ldquo;外观 - 几何&amp;rdquo; 配对数据。One4D 的数据构建遵循两个原则：几何要准、分布要真实。因此我们采用合成数据 + 真实数据混合策略。&lt;/p&gt;&lt;p&gt;合成数据通过游戏引擎渲染动态场景，天然提供每帧的几何真值，用于为 Pointmap（XYZ）提供稳定监督，帮助模型学到可靠的时序几何一致性。&lt;/p&gt;&lt;p&gt;真实数据，收集自公开视频数据的真实场景视频，以覆盖复杂光照、材质、运动模式。由于真实视频通常缺少几何真值，我们使用现有的 4D 重建方法 Geo4D 生成几何标注，从而把真实世界外观分布引入训练。&lt;/p&gt;&lt;p&gt;这套数据策略带来的直接收益是，合成数据提供几何精度与稳定性，真实数据提供视觉多样性与真实分布，从而让 One4D 在保持视频质感的同时，也能输出可用、对齐、时序一致的 4D 几何结果。One4D 使用 34K 条视频在 8 张 NVIDIA H800 GPU 上训练 5500 步，就得到了很好的效果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 单图到 4D 生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文将 One4D 与 4DNeX 做了单图到 4D 的对比，评价指标有：&lt;/p&gt;&lt;p&gt;用户偏好（User study）：在一致性、动态性、美学、深度质量、整体 4D 连贯性等维度上，One4D 全面领先。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAWSiayo3LXZanO22cpWzGmfMu0fC3gibktSb7X851adcRyxS3EiaTxbu2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527879" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c6c11557-ff3c-46c6-9e87-2ce280279238/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;VBench：动态性（Dynamic）显著提升（55.7 vs 25.6），同时 I2V consistency 仍保持可比水平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAOKXBMNEWoX3XJu21mtsJlVXs9mUgWSw8PUyAXhyQl9OnGWzX1xDGDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3296296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527880" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a987755f-c7a5-4872-8efc-7e49f3a9eada/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些结果支持了 One4D 的优势，输出的多模态结果有更真实的 RGB 动态、更干净的深度、更完整连贯的 4D 点云与相机轨迹。在不牺牲 RGB 视频质量的前提下，仍然能学到准确、细粒度的 4D 几何结构。更多对比视频请移步项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAbRXDSNibZtWxzuqTDrHCQStJ0aKz3mTkIRhz45XE1voWQx4orUR7ndw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5592592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527881" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/fd5af25d-4b44-48f2-a7a6-cc569a261c16/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. 完整视频到 4D 重建&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 并不只在 4D 生成任务上优势显著，它还是一个重建模型，在完整视频 4D 重建上也保持了不错的性能。在深度重建评测数据集 Sintel 和 Bonn 上，One4D 的表现明显超过一些只做重建的方法如 MonST3R 和 CUT3R。即使我们的方法使用 Geo4D 构造了训练数据，它也取得了与只做重建的 Geo4D 相近的效果。更多对比视频请移步项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkANTdicLL9p38qtQ0fHwTX40IjPbZicqYHB7Sy8sXOYRYk5UZbMqsxEicbA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527883" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5b2e704c-5ffa-4106-bb34-074d79ac472e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsB03GfkiaTfwRp5l4yymUSDEMia5ZFPIGH79jQMgibXDEINrZ7jH3Yyhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.9259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527884" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/97cf48e9-d4db-4a82-b270-cf479ba392f6/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在相机轨迹评估数据集 Sintel 和 TUM 上，One4D 的相机估计能力也保持了可用精度，充分证明了 One4D 统一重建与生成的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQpRJNibhjhzibxogWwy7nd92WczNVIjMia9lcFusFFYmG5PAIiaBNChwsQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527902" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/7d7d6c39-71c5-402b-8808-2fbb97ccc0ca/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 稀疏视频帧到 4D 生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在稀疏视频帧设置下，One4D 的输入仅是首尾帧以及少量中间帧，此时模型需要生成缺失 RGB 帧并补全完整几何序列。实验证明，即使在极稀疏条件下，One4D 仍能得到合理的 4D 结构。这意味着 One4D 不止能做重建，而是真正具备生成动态 4D 场景的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA9jhZuT98kJib0EibMzADYDm8W0vfZtPCvFcPMvVHdMW05mGboDse9vJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527901" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/94de583a-c911-4c5d-a94b-f7e55b25dcd5/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 让视频扩散模型不再只会生成 RGB，而是能够同步生成外观（RGB）与几何（Pointmap / 深度 / 相机轨迹），在同一套框架中统一了 4D 生成和重建任务。它通过 UMC 与 DLC 解决了多任务切换与多模态联合训练中最关键的稳定性与对齐问题。One4D 推动视频生成走向生成可用于理解与交互的 4D 世界，为下一代世界模型与多模态内容创作提供了更实用的基础能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>端到端智驾的算力困局，九章智算云这样破局</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Mon, 12 Jan 2026 17:08:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;前言：智驾的&amp;ldquo;iPhone时刻&amp;rdquo;，正在被算力重新定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026年1月7日至8日， 中国汽车大数据融合与创新应用大会 在上海隆重举行。作为汽车产业数字化转型的重要风向标，本次大会汇聚了来自整车厂、零部件企业、高校科研机构及AI技术平台的300+行业精英，聚焦&amp;ldquo;数据驱动创新&amp;rdquo;的核心命题。&lt;img src="https://image.jiqizhixin.com/uploads/editor/63f8c2ab-1beb-432d-966b-48b61e9914de/%E5%9B%BE%E7%89%87000.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在这场高规格的技术盛宴中， 九章智算云（Alaya NeW）技术总监胡宗星 受邀发表主题演讲《 跨越&amp;ldquo;算力墙&amp;rdquo;&amp;mdash;&amp;mdash;超大规模集群如何加速端到端智驾 》，深入剖析当前智能驾驶从模块化向端到端演进过程中面临的三大基础设施挑战，并系统性地展示了九章智算云在解决这些问题方面的方案与价值。&lt;img src="https://image.jiqizhixin.com/uploads/editor/18cb4a63-2fb9-48e0-aecc-8eb36afa7a72/%E5%9B%BE%E7%89%8700.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端到端智驾：一场从&amp;ldquo;规则驱动&amp;rdquo;到&amp;ldquo;感知决策一体化&amp;rdquo;的革命&lt;/strong&gt;&lt;br&gt;&lt;br&gt;这是九章智算云技术总监胡宗星指出，过去，大家做模块化智驾，是将感知、预测、规划拆开，告诉车见到红灯停、见到行人让。那时候，几十台服务器就够用了。而如今，行业正迈向端到端（End-to-End）架构 &amp;mdash;&amp;mdash;直接输入原始摄像头视频流，输出车辆控制指令。这不仅意味着模型参数量跃升至百亿级别，更带来了对算力、数据吞吐和系统稳定性的全新要求。&amp;ldquo;这不是简单的硬件升级，而是一场关于 超大规模计算集群 的战役。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三座大山：算力墙、存储墙、通信墙&lt;/strong&gt;&lt;br&gt;&lt;br&gt;智驾每升一级，算力需求增长10倍。这不是买几台服务器就能解决的问题，这是一场关于超大规模集群（Hyperscale Cluster）的战役。面对这场变革，传统IT架构迅速暴露出三大瓶颈：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;计算墙 ：单卡算力有限，无法支撑千亿级参数模型训练；&lt;/li&gt;&lt;li&gt;&amp;middot;存储墙 ：海量视频数据读取速度跟不上GPU计算速度，导致GPU空转；&lt;/li&gt;&lt;li&gt;通信墙 ：多卡间通信延迟高、拥塞严重，使得&amp;ldquo;1+1&amp;lt;2&amp;rdquo;的现象频发。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些痛点共同构成了所谓的&amp;ldquo; 基础设施危机 &amp;rdquo;&amp;mdash;&amp;mdash;即使你拥有最先进的GPU，也无法发挥其全部潜力。&amp;ldquo;如果把GPU比作大脑，那么网络就是血管，存储是食物供给。任何一个环节卡住，整个系统都会瘫痪。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;九章智算云的破局之道：专为AI而生的基础设施&lt;/strong&gt;&lt;br&gt;&lt;br&gt;针对上述挑战，九章智算云提出了一套完整的解决方案&amp;mdash;&amp;mdash; 构建面向AI原生的超大规模集群架构 ，具体体现在三个核心技术方向：&lt;img src="https://image.jiqizhixin.com/uploads/editor/b4a69cf9-d83d-4208-82ec-6c519457150f/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;strong&gt;&amp;nbsp;推倒&amp;ldquo;通信墙&amp;rdquo;：构建微秒级低时延无损网络&lt;/strong&gt;在千卡级集群中，网络是决定效率的关键。九章智算云采用 RoCE v2无损网络 + Fat-Tree结构 ，实现全链路微秒级延迟，确保数据高速流动，避免因网络拥塞造成训练中断。哪怕几千张卡同时吼叫，网络也能从容应对。&amp;ldquo;就像给数据修了一条永不堵车的高速公路。&amp;rdquo;&lt;br&gt;&lt;br&gt;打通&amp;ldquo;存储墙&amp;rdquo;：三级存储加速策略端到端训练最怕什么？怕GPU算得太快，数据读写跟不上。为解决数据供给瓶颈，九章智算云设计了&amp;ldquo; 热-温-冷 &amp;rdquo;三级存储架构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;热数据 ：通过全闪存阵列与分布式缓存，实现毫秒级响应；&lt;/li&gt;&lt;li&gt;温/冷数据 ：按访问频率分层存储，兼顾性能与成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一机制确保GPU始终处于&amp;ldquo;满负荷运行&amp;rdquo;状态，大幅提升资源利用率。搞定&amp;ldquo;稳定性&amp;rdquo;：故障自愈保障持续训练不管你的单卡多强，在千卡集群面前，硬件故障不是&amp;ldquo;会不会发生&amp;rdquo;，而是&amp;ldquo;什么时候发生&amp;rdquo;。 GPU掉卡、ECC报错、网络抖动，这是常态。试想一下，如果你跑了一个月的模型，因为最后一天一张卡坏了而前功尽弃，那是灾难。九章智算云有一个绝活是 &amp;ldquo;故障自愈&amp;rdquo;机制，通过实时监测，一旦发现某张卡有&amp;ldquo;罢工&amp;rdquo;的苗头，系统将自动隔离故障节点，并从最近的断点（Checkpoint）自动拉起训练任务，&lt;strong&gt;全程无需人工干预&lt;/strong&gt;。&amp;ldquo;我们将有效训练时间占比提升至95%以上，让一个月的训练不再因为一张卡掉线而功亏一篑。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语：专注模型，剩下的交给我们&lt;/strong&gt;&lt;br&gt;&lt;br&gt;在演讲最后，九章智算云技术总监胡宗星强调：&amp;ldquo;在端到端智驾的赛道上，算法专家应该专注于让模型更聪明，而不是去修服务器、调网络、处理崩溃。&amp;rdquo;九章智算云的存在意义，正是为了 将底层复杂的算力管理、网络优化、容错机制等&amp;lsquo;脏活累活&amp;rsquo;彻底解放出来 ，让客户能够以更低的成本、更高的效率，专注于模型创新与业务落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;展望未来：助力中国智驾走向世界&lt;/strong&gt;&lt;br&gt;&lt;br&gt;此次在 2026中国汽车大数据融合与创新应用大会 上的精彩分享，不仅是九章智算云技术实力的一次集中展示，也标志着国产AI基础设施正在从&amp;ldquo;跟随者&amp;rdquo;向&amp;ldquo;引领者&amp;rdquo;转变。随着智能驾驶进入规模化落地阶段， 高性能、高稳定、高性价比的算力平台将成为产业竞争的新高地 。九章智算云将继续深耕AI原生基础设施，携手车企、研究院与开发者，共同推动中国智能汽车产业迈向新纪元。九章智算云（Alaya NeW） &amp;mdash;&amp;mdash; 用最强的网络、最快的存储、最稳的集群，加速智驾未来的到来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;后记&lt;/strong&gt;&lt;br&gt;&lt;br&gt;本次活动由ATC汽车技术平台主办，复旦大学大数据研究院协办。九章智算云作为受邀的AI算力基础设施服务商，展现了中国企业在智能驾驶底层技术领域的深厚积累与创新能力。&lt;br&gt;未来，我们将持续参与行业交流，推动技术开放与生态共建，为中国汽车产业的智能化转型注入强劲动力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>真香！刚骂完AI，Linux之父的首个Vibe Coding项目上线</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 15:06:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/14c32ba6-4250-4978-8901-f45ca54c0d89/1768201395481.png" style="width: 700%;" class="fr-fic fr-dib"&gt;时代变了，就连 Linus Torvalds 现在也氛围编程（Vibe Coding）了。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527915" data-ratio="0.7001953125" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZ8fslDia3gtGZxsdFmyB0UQOK8V0hKNAQ6gyRcd07Mjibv09ZPyptSiaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1024" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/62a6f83c-0c3a-49c5-ac24-e4ccfb080e0c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;上周末，最著名程序员、Linux 作者 Linus Torvalds 发布 Vibe Coding 项目的消息让不少人始料未及。&lt;/p&gt;&lt;p&gt;大神在 GitHub 上发布了一个名叫 AudioNoise 的新项目，和 Linux 并列。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAy427dp7ocWbBPNN82LZn2OYG7xRvgibMcWbE3Wc32vesxwic1NyWR4fA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.4203703703703704" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527916" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7a3b288d-86cd-43e2-8d63-0508e9960f59/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在自述文件中，Torvalds 说这是一个和吉他效果器相关的代码库，「这些效果器在利用 AI 技术『模拟箱体』&amp;hellip;&amp;hellip; 另外需要注意的是，这个 Python 可视化工具基本上是用 Vibe Coding 的方式编写的。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMiaAuGU6qeytHyicEiaEKtS3sPV48ZwCxXtQZPwjsnFAficqAumzpt7DoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8274725274725274" data-s="300,640" data-type="png" data-w="910" type="block" data-imgfileid="503527917" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a64dbb4a-3fa8-4ab3-ae2b-10a7d6028837/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Torvalds 表示，他对模拟滤波器的了解要比对 Python 的了解要多得多。一开始写这个项目时，他就像平时那样通过谷歌搜索然后照搬照抄的方式进行编程，但后来他决定省略中间环节 &amp;mdash;&amp;mdash; 也就是他自己 &amp;mdash;&amp;mdash; 直接使用 Google Antigravity 来实现音频样本的可视化。&lt;/p&gt;&lt;p&gt;看起来在新年假期里，Torvalds 也没有闲着，他也在顺应最近科技界最大的 AI 潮流。&lt;/p&gt;&lt;p&gt;对此，人们的反应既有欢迎的，也有谨慎的。首先当然是普大喜奔：「官宣了，Vibe Coding 是合法的。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8x6cUozDujmh2rWeTU3xcRkDxCjOsgncActwr0VSgVPykjFfUXmg2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.30886075949367087" data-s="300,640" data-type="jpeg" data-w="395" type="block" data-imgfileid="503527919" data-aistatus="1" data-original-style="width: 332px;height: 103px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/ee470b50-5d4f-47e0-83ab-d2df3b4876c7/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Torvalds 首个 AI 项目，生成了什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个名为「AudioNoise」的项目在 5 天前上传到了 GitHub，目前已经收获了 1.4k 的 Stars。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAqbDaPZiaWMYwbgDU6eoqpmDXTIEQotctFyIjicoZZVjnG8NicIuXXhRDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.40555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527921" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d6071f6d-92b2-4a74-9967-6629c1135407/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;GitHub 地址：https://github.com/torvalds/AudioNoise&lt;/p&gt;&lt;p&gt;根据主页介绍，&lt;strong&gt;AudioNoise 项目源自 Torvalds 几个月前做的一个「随机吉他效果器板设计」（GuitarPedal），包括电路原理图和代码&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这是他在 Linux 内核之外的一个兴趣尝试，目的不是打造成品设备，而是探索运算放大器（op-amp）等电路设计原理，详情可参考以下项目。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAmaKTsw8FXKyGukLEnfmeQPy1y8SNNicICZNMaICREjx29FlCxEBibgHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.40185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527922" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8022af40-8e5c-490c-a1ce-ce7c4cbcb24f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;GitHub 地址：https://github.com/torvalds/GuitarPedal&lt;/p&gt;&lt;p&gt;从上个项目的结果来看，虽然 Torvalds 制作的基于树莓派 RP2354A 开发板和 TAC5112 音频编解码器的数字吉他单块效果器确实可以正常运行。但是 Torvalds 对一些模拟接口的选择并不太满意，尤其是那些电位器。此外他越来越讨厌那个会发出咔嗒声的脚踏开关，即使它能兼做编程时的引导选择开关。&lt;/p&gt;&lt;p&gt;因此，Torvalds 暂时没有去管硬件设计，而是认真琢磨了物理交互界面以及数字音效。他的想法很简单，「既然全都是数字化的，那就先搞模拟，别太纠结硬件。」&lt;/p&gt;&lt;p&gt;这就像 Torvalds 最开始做模拟电路一样，只是玩玩而已，不必太当真。&lt;strong&gt;本项目主要的设计目标是学习数字音频处理相关的基础知识，这和他此前做吉他单块项目来学习硬件的初衷完全一致。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;项目中并没有什么基于 FFT（快速傅里叶变换）的声码器，有的只是 IIR（无限冲激响应）滤波器和基础的延迟循环。&lt;/p&gt;&lt;p&gt;一切都是「单采样输入，单采样输出，并且零延迟」。采样可能会存储在延迟循环中，以便在后续调用时实现回声效果），但也没有进行任何复杂的实时处理。&lt;/p&gt;&lt;p&gt;Torvalds 对 TAC5112 在 ADC（模数转换器） 到 DAC（数模转换器） 链路中低于毫秒级的延迟表现很满意，因此现在也打算延续这种设计思路。再加上他以前没做过这些，所以单从新手这个角度来看，一切都显得非常基础和简单。&lt;/p&gt;&lt;p&gt;换句话说：这些 IIR 滤波器并不是现代单块或吉他音箱里那种高端的 AI「箱体模拟」。虽然它们确实能模拟移相器等模拟电路，但只是通过数字全通滤波器来模拟 RC（电阻器和电容器）网络的效果，并没有用到什么真正高深的技术。&lt;/p&gt;&lt;p&gt;Torvalds 特别强调了，&lt;strong&gt;项目中的 Python 可视化工具基本上是靠「氛围编程（Vibe-Coding）」写出来的&lt;/strong&gt;。他起初只是采用典型的「搜索并照猫画虎」式编程，但后来省去了中间人（他自己），&lt;strong&gt;直接让 Google Antigravity 来写这个音频采样可视化工具&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;对于 AI 编程工具的加入，Torvalds 自己的心得是：&lt;strong&gt;过程基本顺利&lt;/strong&gt;，虽然他有时需要琢磨一下使用「内置矩形选择」功能时到底出了什么状况。在告诉 Antigravity 直接写一个自定义的 RectangleSelector 之后，情况就好了很多。&lt;/p&gt;&lt;p&gt;如果要问&lt;strong&gt;氛围编程是不是要比他自己动手写出来的效果好呢？他的回答是肯定的&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACA5B0s3ACOgNb4gVEh33pzz8btQaUzZlhVVEPTOVzZfqsF6m5lsRIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.8101851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527923" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/a7797ce0-f68e-4b45-9c27-c93f48c24dc8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Torvalds 使用的 AI 软件开发平台 Antigravity，是去年 11 月谷歌刚刚发布的智能体式开发平台，直接对标 Cursor。&lt;/p&gt;&lt;p&gt;它将传统的 AI 驱动的集成开发环境 (IDE) 发展为「智能体优先」的形态。背靠谷歌自家的最新大模型 Gemini 3，可以驱动编程智能体自主规划和执行复杂的、端到端的软件任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkADgk2tVxxfYxaA9QbDUHHmCgiaWzbic511MGK8iapfu84USNKdTtpWbkDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.48055555555555557" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527924" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/40082d06-25ad-43fc-866b-55748c77779e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然，更重要的是，这个工具目前在招揽用户时期是免费使用的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;圈内热评：AI 大势下的「顺流而下」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Linux 之父开始使用 AI 编程工具这一「罕见的盛况」，在圈内引发了现象级的讨论，简直是「活久见」系列。&lt;/p&gt;&lt;p&gt;有人感叹，「我认识的最厉害程序员，包括那些构建编译器、CUDA 内核和操作系统等最核心功能的程序员，他们以前对「所有 AI 代码都是垃圾」的呼声最高。但如今，他们的想法正在迅速改变，并对 AI 的强大感到震惊。没有时间去否认这一点了。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAkD0vtkPPqN9FunMmSZwo34rxMN0wiaQ2MSvXG31fibOyicpqyLqVYbKhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5657407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527926" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c6722554-db52-4540-999f-4e766b47034a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Antigravity 创建者、谷歌 DeepMind 工程师 Varun Mohan 视 Torvalds 为自己的编程偶像之一，此次对其能够在最新的项目中使用该 AI 编程工具感到莫大的荣幸。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAKViaBtvqvJVt1eq5h7RFglF1icYj5PdqOyBaz8bVRa5VTw5PemKMOMTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527927" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/21148314-de6f-493e-a9fd-dacf7e4b00d1/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;云开发平台 Vercel CEO Guillermo Rauch 列举了 2026 开年发生的几件大事，其中 Torvalds 在其非内核项目中使用氛围编程与陶哲轩宣布 GPT 和 Aristotle 自主解决 Erdős 问题、编程大神 DHH 收回在 Lex 播客中发表的「AI 不会编程」的言论等并列。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAJAIUUn5msB7M0DficqTq61lSlgZ2gjNgSb2bpcdsjOHOuTZy55XXhJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0212962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527928" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d1049b86-28ea-400d-83c7-6de787b63a2a/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;几天前，Linus 还在骂 AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为曾经引领时代的程序员大神，Linus Torvalds 对于 AI 写代码这件事的态度还是相对保守的。至少直到去年底，他在几次采访中还是把编程分为「入门」与「生产」两个维度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv5lu1S4vnMM4s4xdIzso9Mw5l5pCiaxB6VPWMqs77azddWfLsL3AfLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527929" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/88bdfdcb-f8c4-4a05-8610-55c8940f4f52/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他认为对于非专业人士来说 Vibe Coding 是一项降低门槛的伟大技术，但对于生产环境和内核开发，Linus 明确表示 Vibe Coding「是一个非常，非常糟糕的主意 &amp;mdash;&amp;mdash; 如果你自己都不理解代码的逻辑，当它在生产环境中崩溃时，你根本无法修复。」&lt;/p&gt;&lt;p&gt;Torvalds 认为目前的 AI 辅助编程主要是「90% 的营销加 10% 的现实」，极其反感那些利用 AI 生成「垃圾代码」并提交给内核维护者的行为。&lt;/p&gt;&lt;p&gt;1 月 7 日，在 Linux 内核开发人员讨论如何规范 AI 生成的 Linux 内核时，Torvalds 忍不住插话进来：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAEGcdqpgTBeibuWylF7K64Uf71j4f83XBh7WjdAHCkwWDH7A3yQ9pDAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.9453703703703704" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527931" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/b93e1aa8-c963-4704-9893-e5b5f4ad73c2/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;他表示：「讨论 AI 生成的垃圾毫无意义，简直愚蠢至极。那些生成垃圾内容的人根本不会在他们的补丁中注明这一点。所以，停止这种愚蠢的行为。我不希望任何内核开发文档包含任何关于人工智能的声明。」&lt;/p&gt;&lt;p&gt;这样厌恶的态度，让人想起当年他对老黄竖起的中指。&lt;/p&gt;&lt;p&gt;不知为何在骂完之后，Torvalds 就放出了自己用 AI 写好的代码。&lt;/p&gt;&lt;p&gt;AudioNoise 这个小项目，会成为 Linus Torvalds 的「真香时刻」吗？&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/theprimeagen/comments/1q9q2kd/linus_torvalds_is_a_vibecoder_now/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/AiBattle_/status/2010105477166969307?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://github.com/torvalds/AudioNoise&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://news.ycombinator.com/item?id=46569587&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/kimmonismus/status/2010445425694867753?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2010215226978042218?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/_mohansolo/status/2010023056778137699?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>引入几何约束后，VLM跨越了「空间推理」的认知鸿沟</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 15:00:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/6350129a-df86-4485-a3ff-06a05ead53f1/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;现有的视觉大模型普遍存在&lt;strong&gt;「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;语义-几何鸿沟」（Semantic-to-Geometric Gap）&lt;/strong&gt;，不仅分不清东南西北，更难以处理精确的空间量化任务。例如问「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;你坐在沙发上时，餐桌在你的哪一侧？&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」，VLM 常常答错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;这种「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语义‑几何鸿沟」源自于视觉大模型的语义空间无法承载高保真的几何细节，导致其在空间推理时是在「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;凭空瞎猜」，这使得模型读懂了画面的语义，却停留在「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语言的世界」中，不具备现实世界赖以运行的几何直觉，导致空间判断漏洞百出。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgzspD2PWXLxLQym7vvtfC3eTNejia4FcWw4mpZxicibN1HIyC6W79gUvfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.24259259259259258" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527563" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c909d735-54a3-4218-b7b2-b84337bc34eb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="2 2 []"&gt;论文标题：Geometrically-Constrained Agent for Spatial Reasoning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2511.22659&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;作者团队：Zeren Chen, Xiaoya Lu, Zhijie Zheng, Pengrui Li, Lehan He, Yijin Zhou, Jing Shao, Bohan Zhuang, Lu Sheng&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;通讯单位：北京航空航天大学，上海人工智能实验室&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://gca-spatial-reasoning.github.io&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目代码：https://github.com/gca-spatial-reasoning/gca&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对这一痛点，&lt;strong&gt;北京航空航天大学&lt;/strong&gt;与&lt;strong&gt;上海人工智能实验室&lt;/strong&gt;的研究团队创新提出了&lt;strong&gt;几何约束智能体（Geometrically-Constrained Agent, GCA）&lt;/strong&gt;，开创了&lt;strong&gt;「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;先形式化约束，后确定性计算」&lt;/strong&gt;的空间推理新范式。GCA 不依赖海量数据微调，而是通过构建形式化任务约束，强制 VLM 从「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;模糊直觉」转向「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;精确求解」，通过视觉工具调用和编写计算代码进行参数化计算，为空间推理搭建了一座可验证、确定性的几何桥梁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;GCA 直接带领 Qwen、Gemini 等基座模型实现「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;能力跃迁」。在公认高难度的 MMSI-Bench 测试中，GCA 将模型性能提升近 50%，击败现有 Training-based 及 Tool-integrated 方法，并在多个主流空间推理测试中确立了空间推理领域的新 SOTA。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgQr3oibD3FysOQcuBpkd2oM90icGsmPHzPAFSFn2TXafb9tKfZ2Vjh2vA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.5055555555555555" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527564" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/305fea21-3161-4a19-9e7b-2f0d31949ec2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;核心挑战：跨越「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; text-align: center;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;语义 - 几何」的认知鸿沟&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;视觉语言模型（VLM）在图像描述与通用语义理解上表现卓越，然而，当任务转向需要高精度几何计算的空间推理时 &amp;mdash;&amp;mdash; 例如判断物体的精确朝向、测量距离或进行视角变换 &amp;mdash;&amp;mdash; 其表现却显著下滑。&lt;/p&gt;&lt;p&gt;研究团队指出，这种能力断层的根源在于&lt;strong&gt;「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;语义 - 几何鸿沟」&lt;/strong&gt;。具体表现为：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉 &amp;amp; 几何信息的有损压缩&lt;/strong&gt;：VLM 将丰富的像素信息压缩为抽象的语义特征，这一过程如同将一幅详细地图简化为几个地标名称，导致物体精确位置、朝向、尺度等高保真几何细节大量丢失。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;几何想象的缺失&lt;/strong&gt;：以「坐在沙发上」这一场景为例，VLM 仅能调用模糊的空间常识（知道人与沙发通常同向），却无法在脑海中精确构建出「从沙发视角看去」的三维场景。这种几何想象力的匮乏，使其在面对复杂空间推理时力不从心。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;🛠️ 核心方法：基于形式化约束的两阶段推理&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgUXoJUTh5z052kicaIAmSTTRqNZeKVn3m5Yo5MJibHC3P7PiaCD2OXPR8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527565" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/86c1be07-eef2-4f1e-a7d3-00d5e9d0a330/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了在「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语义」与「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;几何」之间搭建可靠桥梁，GCA 创新性地引入了&lt;strong&gt;形式化任务约束&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg649GlJcLYRXb4llT3GdVDoKTgxeaSGNxsAIyQNNLpz9zKqrUmTkY6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6885245901639344" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="503527605" data-aistatus="1" data-original-style="width:32px;height:22px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/96df95bb-0ab9-45f5-b42d-6e22ac071210/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 5.48%;"&gt;），将空间推理精准拆解为两个阶段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 任务形式化 &amp;mdash;&amp;mdash; 从「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;模糊指令」到「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;精确规则&lt;/span&gt;&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;VLM 首先扮演「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语义分析师」的角色，利用其强大的语义理解能力，将模糊的自然语言指令转化为明确的数学约束。这一步骤不涉及具体计算，而是确立规则：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参考系约束（&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgqEYOrHNX9Y2yapcILnQUC9DAVT3QuzGt41qtJrHWWcQGrSAUBJl9pg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.975" data-s="300,640" data-type="png" data-w="80" type="block" data-imgfileid="503527606" data-aistatus="1" data-original-style="width:23px;height:22px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2f8842d6-d0e5-4123-a1db-38cefd4517eb/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 3.88%;"&gt;）：明确空间计算的「锚点」。GCA 归纳了三种人类常用的核心参考系，模型必须从中指定其一：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基于物体的参考系 (Object-based Frame)&lt;/strong&gt;：利用物体自身的坐标系。例如指令「当你在洗手时...」隐含了观察者必须「面对洗手池」，因此参考系由洗手池的朝向决定。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基于相机的参考系 (Camera-based Frame)&lt;/strong&gt;：即标准的视图坐标系。例如「从图 1 的视角来看...」，此时参考系直接绑定为相机的基于方向的参考系 (Direction-based Frame)：由两个物体的位置关系定义。例如「烤箱在水槽的北面」，此时「北」的方向由从水槽指向烤箱的向量严格定义。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgYThRIgSpvOCBp4JjnstV0UWTWxfdbqWwqNGS5zxOHbca9rzSeK1XDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527566" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/10fc5d16-5f48-4b13-af2e-c66920b5ef0a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;目标约束（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgheBcibicBBk6VZtZoySialZCh09r4XLINKIibGC0JibvjVPr3icKv18ciaUdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.048780487804878" data-s="300,640" data-type="png" data-w="82" type="block" data-imgfileid="503527607" data-aistatus="1" data-original-style="width:22px;height:23px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5e959d53-0222-45f4-8ca7-e23bbc665399/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.88%;"&gt;）&lt;/strong&gt;：明确要解答的「几何问题」本身，例如具体的距离值、角度或方位。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 几何计算 &amp;mdash;&amp;mdash; 在规则内进行「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;确定性求解」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在确立约束后，VLM 转变为「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;任务求解器」。它不再进行开放式的语义联想，而是严格遵循 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg649GlJcLYRXb4llT3GdVDoKTgxeaSGNxsAIyQNNLpz9zKqrUmTkY6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6885245901639344" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="503527605" data-aistatus="1" data-original-style="width:32px;height:22px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/684cb7b5-bf5c-49ee-920a-b1063a8a69b7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 5.59%;"&gt; 划定的边界，调用 3D 重建、目标检测、OCR 等感知与计算工具（Toolbox），执行确定性的几何计算，在参考系 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgqEYOrHNX9Y2yapcILnQUC9DAVT3QuzGt41qtJrHWWcQGrSAUBJl9pg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.975" data-s="300,640" data-type="png" data-w="80" type="block" data-imgfileid="503527606" data-aistatus="1" data-original-style="width:23px;height:22px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/738c2b55-be68-49b4-8dcf-5beb27a5a30e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 4.22%;"&gt; 下求解目标 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgheBcibicBBk6VZtZoySialZCh09r4XLINKIibGC0JibvjVPr3icKv18ciaUdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="1.048780487804878" data-s="300,640" data-type="png" data-w="82" type="block" data-imgfileid="503527607" data-aistatus="1" data-original-style="width:22px;height:23px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9c149648-84ce-43cb-ae2c-7be1cbbf6d08/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;。这一阶段的高效实现依赖以下三个核心设计：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;智能工具调度与绑定&lt;/strong&gt;：VLM 像指挥官一样，调度 3D 重建等感知工具获取数据，并能智能地将「最左边的椅子」等模糊描述，精准绑定到具体的几何对象上，消除语义歧义。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;感知与计算的无缝衔接&lt;/strong&gt;：感知工具负责将视觉世界参数化为高保真 3D 表示，计算工具则负责执行代码、完成坐标转换，二者在统一框架下协同，实现从「看到」到「算准」的闭环。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;检索增强的可靠计算&lt;/strong&gt;：采用类似 RAG 的策略，VLM 从一个已验证的几何公式库中检索正确模型来生成代码，从根本上杜绝「幻觉」，确保每项计算都基于可靠的物理原理。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;实验结果：全新的空间推理 SOTA&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 MMSI-Bench、MindCube-tiny、OmniSpatial 等多个主流空间推理基准上，GCA 证明了其有效性，构建了一个全新的空间智能 SOTA。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;综合性能提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GCA 取得了 65.1% 的平均准确率，显著超越了现有基于训练的方法与工具集成的方法。特别是在极具挑战性的多图空间推理基准 MMSI-Bench 中，面对复杂的视角变换与相对方位推断，现有主流模型往往只能徘徊在 25%~30% 左右的「随机猜测」水平线。&lt;/p&gt;&lt;p&gt;而基于 Qwen3-VL-Thinking 构建的 GCA，准确率从 32.6% 跃升至 47.6%。这一数据证明，GCA 成功让 VLM 摆脱了「蒙答案」的困境，向具备可靠的空间推理能力迈出了关键一步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强大的通用性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GCA 并非特定模型的「专属补丁」，而是一种无需训练（Training-free）的通用推理范式，可直接赋能各类基座模型。&lt;/p&gt;&lt;p&gt;实验显示，在搭载 GCA 架构后，受测模型在 MMSI-Bench 上的性能平均实现了约 37% 的相对提升。其中，基于 Gemini-2.5-Pro 构建的 GCA 表现尤为惊艳，其准确率从 36.9% 飞跃至 55.0%，有效地激发了顶级模型的空间推理潜力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgSsAaC9icez3QCfMGQiamW4EVNxIZ4XCYIMEICWibATwLB78EOVSnicLuDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.3907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527567" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/0209a4ef-5201-4fea-9639-eb5904933f6e/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgVy7pVQib0UG9H4ChkJvsXdWmfr6pZxMnYoHV3Ad4avjauleWEk3haFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527568" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/f5af012e-416e-43bc-b9de-cc78427c763d/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;通过系统的消融实验与归因分析，研究进一步证实了 GCA 架构的前瞻性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;形式化约束至关重要&lt;/strong&gt;：对比实验表明，若仅为 VLM 提供工具而不施加形式化约束（Unconstrained Tool Use），其性能提升微乎其微。这证明，缺乏 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg649GlJcLYRXb4llT3GdVDoKTgxeaSGNxsAIyQNNLpz9zKqrUmTkY6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6885245901639344" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="503527605" data-aistatus="1" data-original-style="width:32px;height:22px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/a40be931-1a12-4639-8a86-aab9e22b0aaf/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 5.92%;"&gt;&amp;nbsp;的引导，VLM 无法做出正确的几何规划；正是「先约束」的范式，真正释放了工具的潜力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可解释的错误归因&lt;/strong&gt;：得益于 GCA 架构的模块化设计，研究团队能够对推理链路进行精确的错误归因。分析显示，VLM 在「任务形式化」阶段的准确率已高达～70%，当前主要错误来源于下游感知工具（如 3D 重建失败或遮挡）。这表明，GCA 的推理逻辑是稳健的，其性能将随着感知模型的进步而持续提升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgyKnW4wjg8vdxKZia7sFHXPMAnD5FfZBEgLHbiblLmNBzyoZGIUocibmqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.25555555555555554" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527569" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/fea59f97-ea24-41aa-9def-5d206280c4e5/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结与意义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GCA 提出了一种「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语言定义约束，几何执行计算」的新范式。通过将模糊的空间查询转化为带约束的数学问题，GCA 有效避免了 VLM 在有损语义空间中进行不可靠的空间想象。这不仅大幅提升了推理的准确性，也让机器向拥有「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;几何直觉」迈出了关键一步，回应了攀登「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;空间智能」高峰的核心挑战。&lt;/span&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>清华等团队用AI驱动百万倍速药物筛选，一天内十万亿次扫描的超高速虚拟平台</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 12 Jan 2026 14:11:13 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMsufN3S0jWLyiclA0PAgLaOIMPsJPiamLjZH2hYU4AhyYuiagf0QNL8Iyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5675925925925925" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027124" data-aistatus="1" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/e867f7bd-00ba-4c4e-a259-437989f37078/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;人类基因组编码约有 20000 种蛋白质，其中 90% 与疾病密切相关，却长期处于 &amp;ldquo;无药可靶&amp;rdquo; 状态。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;关键生物机制隐藏在庞杂而碎片化的数据中，但即便拥有高通量实验和海量分子数据，研究者仍然需要依赖经验，在无数可能性中逐一试探。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;清华大学智能产业研究院（AIR）- 北京智源人工智能研究院&amp;ldquo;健康计算联合研究中心&amp;rdquo; 兰艳艳教授课题组带来了新的成果。他们研发的 AI 驱动的超高通量药物虚拟筛选平台&amp;nbsp;DrugCLIP，能以千万倍的对接速度实现精准的虚拟筛查。&lt;/p&gt;&lt;p&gt;相关研究内容以「Deep contrastive learning enables genome-wide virtual screening」为题，于&amp;nbsp;&lt;span data-pm-slice='1 1 ["para",null]'&gt;2026 年 1 月 9 日&lt;/span&gt;发布在《Science》。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMibqDUulV38fvFcQppy2iaoZXFpU89kMvCO67iaGcmYKzicuEibDSaytHRlA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4186046511627907" data-s="300,640" data-type="png" data-w="688" type="block" data-backw="546" data-backh="229" data-imgfileid="100027116" data-aistatus="1" data-original-style="width:100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/984815f9-4981-4ee1-a013-dfb4420aa963/640.png" alt="图片" data-before-load-time="1768198201754" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;论文链接：https://www.science.org/doi/10.1126/science.ads9530&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式重构：从&amp;ldquo;物理模拟&amp;rdquo;到&amp;ldquo;跨模态向量检索&amp;rdquo;的技术跃升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统药物筛选长期受困于&amp;ldquo;不可能三角&amp;rdquo;：精度、通量与化学空间规模。传统的分子对接高度依赖原子级的物理受力模拟，面对万亿级分子库时，庞大的计算代价让全基因组筛选成了不可能完成的任务。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMAQRYzFHEOXFvIeYibnqM4r2uicHtkRQpZn4gJuXTLIUvM0M3hx7qhmibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6926406926406926" data-s="300,640" data-type="png" data-w="693" type="block" data-backw="546" data-backh="378" data-imgfileid="100027117" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b7107aae-d3c8-4f87-bb89-4c4eb8fd0dbf/640.png" alt="图片" data-before-load-time="1768198201975" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：化学空间与化合物库。&lt;/p&gt;&lt;p&gt;DrugCLIP 的核心创新在于创造性地构建了蛋白质口袋与小分子的&amp;ldquo;向量化结合空间&amp;rdquo;。它不再执着于模拟分子如何&amp;ldquo;卡入&amp;rdquo;蛋白的动态过程，而是利用深度对比学习技术，将复杂的生物相互作用重构为计算机领域极度成熟的向量检索问题。&lt;/p&gt;&lt;p&gt;在这种硬核架构下，团队展现了极具前瞻性的 AI 逻辑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;自监督结构预训练： 团队创造性地从海量蛋白数据中切取片段模拟&amp;ldquo;假配体&amp;rdquo;，构造了多达 550 万组 训练样本。这种策略让 AI 在接触真实药物前，就已深刻领悟了蛋白表面的结构特征，赋予了模型极强的 Zero-shot泛化能力。&lt;/li&gt;&lt;li&gt;多尺度表征对齐： 团队通过训练两个深度神经网络编码器，将蛋白口袋的 3D 拓扑结构与小分子的化学表征映射到同一个高维共嵌入空间（Joint Embedding Space）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMibtvBRyNftOGiaVN4a7FwjfSzzQrWQiajrf3tFMVbfneNPbFymvV5bWaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9761006289308176" data-s="300,640" data-type="png" data-w="795" type="block" data-backw="546" data-backh="533" data-imgfileid="100027118" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/13799d7c-e8d3-45c9-a91c-2e131436c7e9/640.png" alt="图片" data-before-load-time="1768198202014" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：DrugCLIP 的框架。&lt;/p&gt;&lt;p&gt;这种算法级的范式转换，直接将单节点（128 核 CPU + 8 张 GPU）的日打分能力推向了 10 万亿次（10 的 13 次方） 的巅峰。相较于传统工具，筛选效率提升了 100 万倍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从预测到验证：攻克&amp;ldquo;暗靶点&amp;rdquo;与 AlphaFold 结构的无缝对接&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DrugCLIP 的价值不仅在于算力的飞跃，更在于其对全新靶点的硬核筛选能力。针对此前既无实验结构、也无已知抑制剂的&amp;ldquo;暗靶点&amp;rdquo;&amp;mdash;&amp;mdash;人源 E3 泛素连接酶 TRIP12（与癌症和帕金森相关），DrugCLIP 直接基于 AlphaFold2 预测的蛋白结构进行盲筛，成功命中多个活性抑制剂。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMSbMvadncckurMjeZvk9G3mtYQzpXHuPJ2VV3eONuPT2RBqldtNEASg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.2314814814814814" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="546" data-backh="673" data-imgfileid="100027119" data-aistatus="1" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c7d2faa2-429f-4052-bb50-962e9a45026c/640.png" alt="图片" data-before-load-time="1768198202064" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：借助 GenPack 将 DrugCLIP 应用于 AlphaFold 预测结构。&lt;/p&gt;&lt;p&gt;在临床靶点 NET（去甲肾上腺素转运体）的实验中，DrugCLIP 筛选出的候选分子中有 15% 证实有效，且部分分子的活性直接超越了现有的一线临床药物。相关复合物结构已通过冷冻电镜解析，进一步验证了其生物学可信度。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMnzxXibpKHdOjHLrkLEgId99ibUpfbEchD3wW1fvR8UCKmibcdTBGAydLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.0537037037037038" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="546" data-backh="575" data-imgfileid="100027121" data-aistatus="1" data-original-style="width:100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4b89e525-8d3d-4c5c-85a4-4f8e009d76e1/640.png" alt="图片" data-before-load-time="1768198202383" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：DrugCLIP 的计算机模拟基准测试结果及针对 NET 的湿实验验证。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;赋能万众创新：开启基因组级药物发现生态&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了践行赋能科研社区、重塑药物研发现状的愿景，研究团队利用 DrugCLIP 完成了人类历史上首次全基因组规模的虚拟筛选：覆盖约 1 万个蛋白靶点、2 万个结合口袋，对超过 5 亿个小分子进行全量对齐，产出 200 万个高潜力靶点分子对，并据此构建了目前全球规模最大的蛋白-配体筛选数据库 GenomeScreenDB。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMtua4TYkZknNyzE7XdPIHIVq0TedPzVITMuBntjgiclFtgmc66nENDVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.4381720430107527" data-s="300,640" data-type="png" data-w="744" type="block" data-backw="546" data-backh="239" data-imgfileid="100027122" data-aistatus="1" data-original-style="width:100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/471dc8b7-73b0-4551-9584-b8c466a0cc38/640.png" alt="图片" data-before-load-time="1768198202398" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：全基因组虚拟筛选结果的 t-SNE 可视化图及实例与靶点数量维恩图。&lt;/p&gt;&lt;p&gt;早在 2025 年 6 月，清华 AIR 已联合智源研究院预先发布了 DrugCLIP 平台，正式向全球科研社区免费开放。截至目前，该平台已吸引了超过千余名科研人员深度使用，累计完成了超过万次大规模筛选任务。 这种极速、低门槛的筛选体验，正在极大地降低新靶点开发的起始门槛。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMZmjEyDlyTdibp8Fra8GeooAMOrbCwLl5coJzKPlksYNqpJE4elgZSCg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4603174603174603" data-s="300,640" data-type="png" data-w="693" type="block" data-backw="546" data-backh="251" data-imgfileid="100027123" data-aistatus="1" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b3e4a12d-a5e0-4640-9622-39952f80039e/640.png" alt="图片" data-before-load-time="1768198202414" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;DrugCLIP 官网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;相关链接：https://www.drugclip.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;作为 AI4S（AI for Science）重塑生命科学底层逻辑的绝佳范例，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;DrugCLIP&amp;nbsp;&lt;/span&gt;正在重新定义药物发现的路径与边界，推动人工智能成为下一代医疗突破的核心驱动力。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",null]'&gt;DrugCLIP 不仅实现了药物筛选速度的百万倍级提升，更首次完成了全基因组规模的药物映射，实现了从&amp;ldquo;大海捞针&amp;rdquo;到&amp;ldquo;精准定位&amp;rdquo;的筛选突破。在此基础之上，进一步提升靶点与药物分子匹配的精度、推动药物从筛选到设计的全链条贯通，成为接下来的关键方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",null]'&gt;DrugCLIP 的发表，不仅是对技术突破的国际认可，更意味着药物研发正式迈入&amp;ldquo;后 AlphaFold 时代&amp;rdquo;的规模化、系统化新阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;相关报道：https://phys.org/news/2026-01-ai-tool-discovery-life-medicines.html&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>2026年，大模型训练的下半场属于「强化学习云」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:24:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3177c979-5de5-4d7c-a344-0b87d712ac1d/1768195078091.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2024 年底，硅谷和北京的茶水间里都在讨论同一个令人不安的话题：&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650942531&amp;idx=1&amp;sn=2fabcd16a94b0966864aaf18c6338faf&amp;scene=21#wechat_redirect" target="_blank"&gt;Scaling Law 似乎正在撞墙&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;那时候，尽管英伟达的股价还在狂飙，但多方信源显示，包括彼时备受期待的 Orion（原计划的 GPT-5）在内，新一代旗舰模型在单纯增加参数规模和训练数据后，并未展现出预期的边际效益提升。另外，也有研究认为预训练所需的数据将会很快耗尽，其甚至还预测了明确的时间节点：2028 年。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALf5AERXPc62A6EIBStJTcQ5GwfUPhS6q03jbbENvaZwc3e4589DtuQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6027777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527888" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/cfad2cd2-a2e7-41a8-9305-9a758923b90f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 来自论文 arXiv:2211.04325v2&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;OpenAI 和 Safe Superintelligence Inc 的联合创始人 Ilya Sutskever 当时还留下了一句意味深长的判词：「2010 年代是规模扩大的时代，现在人们又回到了奇迹和发现的时代。」这句话在当时被许多人解读为悲观的预警，也就是单纯依靠堆砌算力和数据的预训练路线，恐怕已经触到了天花板。&lt;/p&gt;&lt;p&gt;直到 2025 年初，接连的惊喜打破了僵局。&lt;/p&gt;&lt;p&gt;那时候，OpenAI 的 o1 模型已在几个月前率先引入了强化推理，展示了模型在思考时间换取智能深度上的惊人潜力，证明了 test-time scaling（测试时间扩展）是一条通往更高智能的可行路径。然而，o1 的闭源特性让这项技术一度被视为只有巨头才能掌握的「黑科技」。&lt;/p&gt;&lt;p&gt;2025 年 1 月 横空出世的 DeepSeek R1 将 o1 的技术路线成功复现并彻底开源。它的意义不在于从零发明，而是用极低的成本和开放的姿态向全行业证明：&lt;strong&gt;Scaling Law 并没有撞墙，它只是换了引擎&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;DeepSeek R1 等推理模型的成功揭示了一个事实：&lt;strong&gt;深度的推理能力比单纯的参数规模更关键。&lt;/strong&gt;通过强化学习（RL）驱动的思维链（CoT），模型在后训练阶段展现出了类似于人类「慢思考」的推理能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGA9be6iceO5Tmib7aYKia7hW5BiaEvPoK4u9Ox8kZWYhGndfO0v6rvsOFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527887" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9590c21b-25cb-4e7d-95bf-3c11d8659ed9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; DeepSeek-R1 的多阶段训练流程，来自 arXiv:2501.12948v2&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;正如九章云极 DataCanvas AI 首席科学家缪旭在 2025 算力生态大会上回顾的那样：「DeepSeek 的横空出世，让我们第一次感觉到，原来强化学习可以让大模型的进化速度再次提升。」对于更广泛的开发者而言，这种「感觉」正是源于 DeepSeek 拉低了技术门槛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAF8YQML1WXO2RHPPPoKOCq8z5JqlByCdWCGDicibB7anDdqdSeCoJzwfA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.6648148148148149" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527891" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3b1b1126-7de7-4814-8d1f-40276a2d3246/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;看起来，算力的重心正从 &lt;strong&gt;pre-training scaling（预训练扩展）&lt;/strong&gt;走向&lt;strong&gt; post-train scaling（后训练扩展）&lt;/strong&gt;和&lt;strong&gt; test-time scaling（测试时间扩展）&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsXPhyg7G7zEGtK6UCrVon26Rg53DFZz9X0mPhU8UDE5EZ2D5Equusg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527889" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/23487201-98cb-43cf-a471-09928702fb9a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;来自英伟达博客&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 2026 年的今天，我们已经可以确信：&lt;strong&gt;大模型训练的下半场属于强化学习。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这个阶段，模型不再仅仅是基于海量预训练数据的概率涌现，而是能像人类专家一样，通过与环境的交互、试错和自我博弈，进行深度的逻辑推演。&lt;/p&gt;&lt;p&gt;如果说预训练是培养一个通识教育的毕业生，那么基于 RL 的后训练就是将其投入真实世界，进化成一名真正的专家。然而，新的机遇也带来了新的基建危机：当算力的消耗重心从静态的&lt;strong&gt;训练&lt;/strong&gt;转向动态的&lt;strong&gt;探索与推理&lt;/strong&gt;，现有的云计算架构开始显得力不从心。&lt;/p&gt;&lt;p&gt;行业呼唤一种全新的算力形态，去承载这种以「&lt;strong&gt;进化&lt;/strong&gt;」为核心的新智能。而在这一轮基础设施的代际更迭中，谁能率先定义这种形态，谁就能握住下一个时代的入场券。&lt;/p&gt;&lt;p&gt;基于这一观察，缪旭在演讲中抛出了一个定义未来的公式：「&lt;strong&gt;当智能可以并行进化，强化学习云将成为群体智能的放大器。&lt;/strong&gt;」&lt;/p&gt;&lt;p&gt;这里的关键词「&lt;strong&gt;强化学习云&lt;/strong&gt;」，正是九章云极为应对这场范式转移给出的基础设施答案。作为&lt;strong&gt;独立智算云赛道的领军企业&lt;/strong&gt;，九章云极不仅首先提出了这一概念，更通过前瞻性的布局，率先定义了后训练时代的算力标准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首发优势 &amp;nbsp;为什么九章云极能定义「强化学习云」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 OpenAI o1 验证了路径，DeepSeek R1 引爆了热潮，那么九章云极则是在最短时间内率先给出了基础设施答案。&lt;/p&gt;&lt;p&gt;仅仅数月后的 2025 年 6 月，九章云极便正式发布了&lt;strong&gt;业界首个工业级强化学习云平台 Agentic RL&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;而当时，放眼全球，尽管以 Anyscale (Ray) 为代表的硅谷先驱已经在分布式计算框架层面为强化学习提供了底层支持，AWS、谷歌等云巨头也已将 RL 视为通用机器学习平台（如 SageMaker、Vertex AI）下的一个功能组件或工具包，但整体上主流市场的目光仍主要聚焦于如何构建更大的预训练集群或降低传统推理（inference 而非 reasoning）成本，尚未有任何一家企业像九章云极这样，敏锐地洞察到智能体（Agent）时代的算力特征变革，并&lt;strong&gt;将「强化学习」独立定义为一种全新的工业级云服务形态&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种能够迅速捕捉前沿算法趋势，并率先将其转化为标准化、工业级云产品的能力，正是九章云极在独立智算云赛道中确立首发优势与领军地位的基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么我们需要专门的强化学习云？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的云计算架构，本质上是为静态负载设计的。无论是 Web 服务还是传统的深度学习推理（inference），其计算特征相对线性且可预测。但强化学习截然不同，它是一个高频交互、动态探索的过程。智能体需要在模拟环境中进行海量的试错，而这会导致算力需求呈现出剧烈的波峰波谷特征，且对异构资源的调度有着极高的要求。&lt;/p&gt;&lt;p&gt;如果用传统的静态算力去跑 RL 训练，结果要么资源利用率极低，要么在探索高峰期直接卡死。&lt;/p&gt;&lt;p&gt;针对这一痛点，九章云极并没有选择在旧架构上打补丁，而是进行了系统级的重构。其强化学习云 Agentic RL 基于混合专家（MoE）架构与 Serverless 理念，实现了算力的「&lt;strong&gt;按需即取、即用即还&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;数据显示，相比于传统方案，&lt;strong&gt;Agentic RL 可将端到端训练效率提升 500%，综合成本下降 60%&lt;/strong&gt;。更关键的是，它是&lt;strong&gt;全球首个支持万卡级异构算力调度的强化学习基础设施平台&lt;/strong&gt;。这种对大规模异构算力的驾驭能力，标志着九章云极已经率先完成了从「卖资源」到「卖能力」的进化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agentic RL：让通用模型变成专家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;顾名思义，Agentic RL 的核心是 &lt;strong&gt;Agentic（智能体）&lt;/strong&gt;和 &lt;strong&gt;RL（强化学习）&lt;/strong&gt;。但 Agentic RL 并不只是智能体与强化学习的简单叠加，其内涵蕴涵了 AI 能力维度的一次关键跃迁：从单纯的「内容生成」转向复杂的「决策控制」。&lt;/p&gt;&lt;p&gt;在这里，「&lt;strong&gt;控制&lt;/strong&gt;」尤为关键。在九章云极看来，无论是供应链的动态调度，还是工业设计的精密规划，本质上都是一个高难度的&lt;strong&gt;控制问题&lt;/strong&gt;。Agentic RL 的核心目标，正是通过 RL 赋予大模型这种在动态环境中精准感知、规划并执行的能力，使其从单纯的语言专家进化为能解决实际物理世界难题的执行者。&lt;/p&gt;&lt;p&gt;正是为了支撑这种「从生成到控制」的能力跨越，在 2025 算力生态大会上，九章云极 AI 首席科学家缪旭进一步展示了其强化学习云背后的 Agentic RL 技术架构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4JzWZHTaqZEUZf7icMJ3vGj7tJMn2ATibdheat4U5dB6oTxpKwBLlC3Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.40370370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527890" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/61f69a39-03ec-4a65-b8ea-aeab9633e509/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;简单来说，Agentic RL 的使命是将通用模型进化为专家模型，其应具备长时程规划、长/短期记忆、复杂工具调用、检索增强生成优化、角色一致性等多种能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA0OQxPn9zm2AoBOtyq8icict5Iz0HFab93asDT65QCmAzJ0jmZPvmiaBZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527892" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/10c7a0ed-1165-435d-9424-ccbaad3c2e04/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;基于此，缪旭提出了一个更宏大的终局构想：未来的通用人工智能（AGI）可能不会是一个单一的巨型模型，而是由成千上万个垂类专家智能体组成的「&lt;strong&gt;群体智能&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;不同于传统的强化学习，面向群体智能的 Agentic RL 面对的是极度复杂的目标，比如城市规划的长时序约束，或工业设计的精密系统组合。为了支撑这种高难度的进化，九章云极构建了一些核心技术，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致效能的异步系统&lt;/strong&gt;：针对 RL 训练中极不稳定的负载特征，九章云极研发了全异步训练架构，通过 rollout 和 n+1 模型更新机制，成功将 GPU 利用率长期保持在 95% 以上。在算力昂贵的今天，这种工程优化直接等同于巨大的成本优势。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;5 倍速的离线进化&lt;/strong&gt;：针对强化学习样本利用率低的顽疾，九章云极采用了「基于回放的离线强化学习算法」。通过对时间跨度的压缩与样本的高效回放，实现了 5 倍于传统方法的训练速度提升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYBqvX5bPI7Dvfibic45t3XkxHYcMcrUsYmicfYC0mDVsRwAsibQJDBnZWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527893" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/73e8f8c3-bcbf-4603-bbb6-6c655a6982d3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;安全探索的「世界模型」&lt;/strong&gt;：在自动驾驶或医疗等「不能失败」的领域，九章云极与高校合作构建了可控的世界模型。它就像一个高保真的虚拟沙盒，让智能体在其中放手试错，解决现实世界「不敢探索」的难题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAIlXiblmwwjsnib9tbVnOjjEiaQSPqc7P6nkRWSFCgibvYI4yb04LxLzicsg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527894" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/06ccebc1-7e7d-4990-abf5-61cc643e6767/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Alaya NeW Cloud 的全栈重构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;九章云极强化学习云很强，这离不开其精心构建的 Alaya NeW Cloud 智能基础设施。&lt;/p&gt;&lt;p&gt;不同于传统云厂商在通用云上「打补丁」的做法，九章云极从一开始就围绕智能体的运行逻辑，完成了从底层基础设施到上层应用的四层全栈重构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAibwlBHBbVcJXiaAQf3vicicqEl4sxfEVGxQiastD4NtPD9dIjO5a9wSGfSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527895" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/1a4022cb-eb97-48cf-97ea-5a5ac1858993/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了底层技术的突破，九章云极在工程化落地层面也展现出了惊人的敏捷性。为了让最前沿的模型能力即刻触达用户，平台实现了&lt;strong&gt;云容器实例 (CCI)&lt;/strong&gt; 的一键式部署，全流程覆盖，即开即用。以 2025 年终压轴上线的&lt;strong&gt;满血版 DeepSeek-3.2&lt;/strong&gt; 为例，在高端算力卡的加持下，其部署速度更快，运行更高效，完美诠释了平台对最新 SOTA 模型的快速支持能力。&lt;/p&gt;&lt;p&gt;整体看来，在这个智能体时代，九章云极扮演的角色不再仅仅是互联网数据中心（IDC）提供商，更是进化环境提供商。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;开发者&lt;/strong&gt;：只要极少代码即可启动完整的「训练-推理-回传」闭环。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;产业&lt;/strong&gt;：无论是城市规划、工业制造还是自动驾驶，每一个垂直领域的智能体都能在九章智算云上找到专属的进化路径。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;在黄山 &amp;nbsp; 打造城市级智算样板&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;技术领先只是起点，能否在复杂的真实物理世界中落地，才是检验「领军者」成色的试金石。&lt;/p&gt;&lt;p&gt;当大多数智算中心还停留在「建机房、堆显卡」的 1.0 阶段，九章云极已经率先在安徽黄山跑通了「&lt;strong&gt;智算+产业&lt;/strong&gt;」的 2.0 闭环。这里不仅有一座算力中心，更有一个正在运行的、基于强化学习云的城市级实验样本。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;48 天奇迹，这就是九章速度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在黄山，九章云极创造了一个行业纪录：&lt;strong&gt;48 天&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;是的，仅仅 48 天，一座规模达 500 PFLOPS 的&lt;strong&gt;「大位」智算中心&lt;/strong&gt;便拔地而起并投入运营。&lt;/p&gt;&lt;p&gt;这种令人咋舌的交付速度，不仅源于九章云极成熟的工程化能力，更验证了其智算操作系统在异构算力调度上的极致效率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当强化学习走进「全程 AI 伴游」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「大位」智算中心绝非一座冰冷的机房，它是国内首个「&lt;strong&gt;文旅+AI&lt;/strong&gt;」城市级产业应用基础设施。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAtLsGRlTFzvoVqqOAzKjAmlHiaJ1p2sL1yEicGsg6d1tQPsoaZhTeklpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.524074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527896" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/56a97771-17ff-427e-a212-a55be332ea76/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在这里，九章云极的强化学习技术找到了最复杂的演练场：人类社会互动。依托算力底座，黄山实现了国内首个「全程 AI 伴游」景区。成千上万个智能体正在这里学习如何理解游客的意图、规划最优路线、处理突发状况。&lt;/p&gt;&lt;p&gt;这实际上是一场大规模的 Agentic RL 社会实验。每一个游客的反馈，都是一次 Reward（奖励）；每一次路线规划，都是一次 Policy（策略）更新。这种在真实高频场景中打磨出的智能进化能力，远比实验室里的数据更具商业价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智算经济：不仅是投入，更是增长引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于城市管理者而言，智算中心往往面临「建得起、用不起」或「不仅烧电、还烧钱」的质疑。九章云极则用数据打破了这一魔咒。&lt;/p&gt;&lt;p&gt;在本次大会发布的《2026 智算赋能城市产业发展白皮书》中，黄山被定义为「中小城市智算赋能标杆」。易观分析预测，随着「大位」智算中心的全面达产，每年将直接带动黄山市营利性服务业增加值增长不少于 2 亿元。&lt;/p&gt;&lt;p&gt;这一实战成果，正如九章云极董事长方磊在大会现场所下的判断：「&lt;strong&gt;全&lt;/strong&gt;&lt;strong&gt;球 AI 基建正重构生产力底座，算力核心价值在于普惠与落地效能。&lt;/strong&gt;」 黄山模式的成功，正是这一理念的最佳注脚。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAhaS8u56GrNnmozdkpTtGiawEibSUYRelm8ULDUBOnia4uA5ZffMcG2uEg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527897" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/a9fbd7fb-bc5d-427d-898f-ab65fac8cae2/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;通过「智算基建+文旅赋能+场景落地+商业闭环」，九章云极证明了强化学习云不仅能消耗电力，更能生产 GDP。&lt;/p&gt;&lt;p&gt;这种「黄山样板」正在产生强大的磁吸效应。大会现场，中科动力、百鹏互联、歌歌 AI 等 6 家 AI 企业集中签约落地。它们看中的，正是九章云极所构建的这个既有算力底座、又有丰富场景的智算生态。&lt;/p&gt;&lt;p&gt;从技术上的「定义者」到商业上的「破局者」，九章云极用黄山的实践告诉市场：下一代智算云，必须是能直接驱动产业增长的云。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;终局思维 &amp;nbsp;独立智算云赛道的「头号玩家」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 AI 基础设施的牌桌上，玩家虽多，但位置截然不同。有的在做「全能选手」（既做模型又做云），有的在做「卖水人」（只卖裸金属）。而九章云极选择了一条更为艰难、却也更为辽阔的道路：&lt;strong&gt;做独立智算云赛道的领军者。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;独立：真正开放生态的基础&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在「百模大战」向「千行百业」转型的今天，企业的顾虑显而易见：如果我把核心业务数据交给一个同时也做大模型的云厂商，它会不会既是裁判又是运动员？&lt;/p&gt;&lt;p&gt;这就是「独立智算云」存在的根本逻辑：&lt;strong&gt;中立性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;九章云极明确了自己的边界：不与客户争利，不绑定特定模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkATkgSKpvibFCHySBwdXGQm5ypicWMWxVdx7Ge4y5kgKBWeicicpm4ibkmuJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.40370370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527898" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c1cb6a9c-679e-4297-8d75-57fcab310611/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种「独立性」在算力高度集中的当下显得尤为珍贵。针对目前行业内只有不到 10 家巨头公司掌握 10 万卡以上资源的现状，九章云极明确倡导「开源 1000 专家模型」。&lt;/p&gt;&lt;p&gt;他们期望通过动态组合来放大群体智能，为那 10 万家中小企业提供高效的智能化解决方案，让每一个垂直领域的 Agent 都能在九章智算云上找到专属的进化路径 。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkASrmHOTAQrDPNFMQrOIQwmO2dzXjMgBkEEW6EGfwEY39F8MztibBdH8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527899" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/1fa31d6f-cc43-4d53-b362-42a0b7b49970/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种「独立智算云+开源专家模型」的组合拳，彻底区别于那些试图绑定自家闭源大模型的巨头云厂商 ，使其更有可能成功构建起&lt;strong&gt;真正的开放生态&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;正如其发起的 AI-STAR 企业生态联盟，并没有排他性的门户之见，而是连接了上游芯片厂商与下游应用厂商，共同组成了一个自主可控的产业链闭环 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;领军：从卖算力到定标准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;何为领军？不仅是规模最大，更是掌握定义规则的权力。&lt;/p&gt;&lt;p&gt;在算力计费混乱的草莽时代，九章云极率先推出了 「&lt;strong&gt;1 度算力&lt;/strong&gt;」 的普惠化标准，试图让算力像水电一样可度量、可流通。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVqdV8QPlkAtUyL0iaD0C2j3sVq9qpBCicCRyia1ZnyPXIgNJd40Wj5iaJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.18235294117647058" data-s="300,640" data-type="png" data-w="1020" type="block" data-imgfileid="503527900" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/cd0b3d30-03e2-405f-9067-df250bea8dbf/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而在后训练时代，九章云极再次通过强化学习云定义了下一代基础设施的标准架构：&lt;strong&gt;一套包含 Agentic RL 技术架构、Serverless 弹性调度和异构资源管理在内的完整操作系统。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这正是九章云极区别于普通云厂商的核心标志。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;以领军之姿 &amp;nbsp; 为企业打造进化引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年，当我们谈论云计算时，语境已经变了。&lt;/p&gt;&lt;p&gt;如果说过去十年的云计算是「能源时代」，厂商们比拼的是谁的电费更便宜；那么未来的十年，我们将进入「进化时代」，竞争的焦点是谁能让智能体进化得更快、更强。&lt;/p&gt;&lt;p&gt;作为&lt;strong&gt;独立智算云赛道的领军企业&lt;/strong&gt;，九章云极通过首创的强化学习云 Agentic RL，已经率先拿到了通往这个新时代的钥匙。它不仅仅是在提供算力，更是在为在这个星球上即将涌现的无数硅基智能体，提供进化的源动力。&lt;/p&gt;&lt;p&gt;在黄山的数据中心里，成千上万个智能体正在 7x24 小时地自我博弈。对于九章云极而言，这个关于「进化」的故事才刚刚开始。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>顶尖AI竟输给三岁宝宝，BabyVision测试暴露多模态模型硬伤</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:15:13 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/87e98ff5-ace4-4784-93b8-bf34724c7b6a/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;01｜&amp;ldquo;看懂世界&amp;rdquo; 这关，大模型还没上幼儿园&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去一年，大模型在语言与文本推理上突飞猛进：论文能写、难题能解、甚至在顶级学术 / 竞赛类题目上屡屡刷新上限。但一个更关键的问题是：&lt;strong&gt;当问题不再能 &amp;ldquo;用语言说清楚&amp;rdquo; 时，模型还能不能 &amp;ldquo;看懂&amp;rdquo;？&lt;/strong&gt;UniPat AI 携手红杉中国 xbench 团队，并联合多家大模型公司与高校的研究员，发布新的&lt;strong&gt;多模态理解评测集 BabyVision&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;UniPat AI 致力于构建真实场景下 AI 训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。&lt;/p&gt;&lt;p&gt;如果一个视觉问题可以完全用文字描述且不丢信息，它本质上就会 &amp;ldquo;退化成文本题&amp;rdquo;。模型可以靠强大的语言推理能力一路通关，看起来很会看，其实是在走语言捷径。而真正的视觉能力，需要在没有语言扶梯的情况下完成：比较、追踪、空间想象、模式归纳。&lt;strong&gt;而 BabyVision 证明了多模态大模型的这些纯视觉能力还停留在 &amp;ldquo;三岁幼儿&amp;rdquo; 的阶段 ！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Google DeepMind 创始人 Demis Hassabis，在 25 年终播客中也提到类似观点：&amp;ldquo;大模型可以在国际数学奥林匹克拿金牌，却会在小学几何题上出错；它能生成惊艳图像，却不理解杯子为什么不会飘在空中。&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv34HjyBhr0WO3FGBdqmvRrbnDBZzUGDlZVC913FMyxacweOZYiaCc1g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.7685185185185185" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527858" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1bf74415-7494-4213-a76b-5e8975819e9b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAvm6LSBq5NQbzIVJZxPaEc85TcHZeUBCKvhy6h9icha0VRsTs3ziaprUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.39351851851851855" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527936" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/36a2451a-ea9a-486c-8894-635875ec5f22/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;blog：https://unipat.ai/blog/BabyVision&lt;/p&gt;&lt;p&gt;github：https://github.com/UniPat-AI/BabyVision&lt;/p&gt;&lt;p&gt;huggingface：https://huggingface.co/collections/UnipatAI/babyvision&lt;/p&gt;&lt;p&gt;&lt;strong&gt;02｜把顶尖模型和孩子放到同一张 &amp;ldquo;纯视觉试卷&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;BabyVision 先做了一项非常直接的对比实验：把 20 道视觉中心任务（vision-centric）作为 BabyVision-Mini 交给不同年龄段孩子（3/6/10/12 岁）和当下顶尖多模态模型来做。&lt;/p&gt;&lt;p&gt;这份 &amp;ldquo;小试卷&amp;rdquo; 要求严格控制语言依赖：&lt;strong&gt;题目要求很简单，答案必须靠视觉信息本身得出。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;结果非常 &amp;ldquo;扎心&amp;rdquo;（如图 1 所示）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;大多数模型的分数，&lt;strong&gt;聚集在明显低于平均 3 岁儿童的区间；&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini3‑Pro‑Preview 是唯一稳定超过 3 岁基线的模型，但&lt;strong&gt;距离 6 岁儿童仍差约 20 个百分点&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是其中一道题，直观且反直觉，连线垃圾分类，小孩可以轻松做对，但顶尖模型追踪一条线都能追丢。&lt;/p&gt;&lt;p&gt;任务：三件物品沿着线分别连到哪个颜色垃圾桶？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVG7PticNxtFicKCaSwqYHFMQwzpf5ly3xFtmsnO0jDkXO87RumNq8xEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527859" data-aistatus="1" data-original-style="width:411px;height:325px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/892326aa-9ed8-412f-83e1-d377498231b9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkApiaZelZxwcLf36b74z4IyYeywSnTAe5PrZhawtKibnsV9icVHC7vibZUbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8843537414965986" data-s="300,640" data-type="png" data-w="882" type="block" data-imgfileid="503527860" data-aistatus="1" data-original-style="width:439px;height:388px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5f732fb9-9bdc-448d-89b8-9fda9e176a17/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;正确答案：A - 蓝，B - 黄，C - 绿&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型答案（Gemini3-Pro-Preview）：A - 绿，B - 黄，C - 蓝&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;人类的解法几乎是本能，从点出发沿线走到终点（&lt;strong&gt;下面照片是三岁幼儿真实做题痕迹&lt;/strong&gt;）。但模型会写出一大段 &amp;ldquo;逐段追踪&amp;rdquo; 的推理，最后仍把两条路径接反：看起来 &amp;ldquo;很会分析&amp;rdquo;，其实在最基础的视觉追踪上掉线。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;03｜BabyVision‑Full 用 388 题，把视觉能力拆成 4 大类能力 22 个子任务&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队将视觉能力提炼为四大核心类别，每类下细分若干子任务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;精细辨别（Fine-grained Discrimination）&lt;/strong&gt;：分辨细微的视觉差异（8 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉追踪（Visual Tracking）&lt;/strong&gt;：跟随路径、线条与运动轨迹（5 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;空间感知（Spatial Perception）&lt;/strong&gt;：理解三维结构及其关系（5 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉模式识别（Visual Pattern Recognition）&lt;/strong&gt;：识别逻辑与几何规律（4 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这套设计的核心理念很明确：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不是为了 &amp;ldquo;刁难&amp;rdquo; 模型，而是量化那些 &amp;ldquo;人类直觉就会、但构成智能地基&amp;rdquo; 的视觉原子能力。这同样是具身智能（embodied AI）走向现实世界的必修课。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了最大程度确保 &amp;ldquo;纯视觉&amp;rdquo; 考核的有效性，BabyVision 在数据构建上也下足了工夫。&lt;/p&gt;&lt;p&gt;项目团队首先参考了儿童认知教材和视觉发育测验，梳理出了上述 4 大类共 22 种基础视觉子任务。&lt;/p&gt;&lt;p&gt;接着，每个子技能挑选出 2-3 个种子示例（种子图片），作为该类型任务的典型代表。基于这些种子示例，研究者利用逆向图像搜索和关键词搜索，从互联网上爬取了约 4000 张相似的候选图片。&lt;/p&gt;&lt;p&gt;在数据收集过程中，团队严格遵守版权规范，只挑选可用于非商业或学术用途的素材，并过滤掉可能包含大量文字说明或需要文化常识才能理解的图片。由此获得的海量图片进入人工标注环节：多名专业人员逐一检查图片，筛除不适合出题的样本，对保留下来的图片精心设计问题和标准答案。为了确保答案的客观正确，每个问题还附有详细的 &amp;ldquo;解题过程&amp;rdquo; 说明，以证明答案确实可由视觉推理得出。&lt;/p&gt;&lt;p&gt;最终，所有标注完成的问题都经过 &amp;ldquo;双盲质检&amp;rdquo;&amp;mdash;&amp;mdash; 两位独立专家交叉审核，每道题只有在双方都认可其答案无误、推理严谨的情况下才被收录 ；若出现异议则退回修改，反复仍无法达成一致的题目则果断弃用。经过这一系列严苛的筛选，BabyVision 最终产出了 388 道高质量视觉题目，涵盖 22 种子任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAU8NkG6THshd0AU6313qseMxg0Mnr1x6SSGpjpXwFlq4GtaFxLpmQcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.175" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527861" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5a98a82d-5bc1-4e47-98fd-9eb1a6f84113/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;最终评测结果：人类 94.1%，最强闭源 49.7%，最强开源 22.2%&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 BabyVision‑Full 上，研究团队引入了人类基线，16 位至少本科背景的测试者完成全量 388 题，人类准确率达&lt;strong&gt;&amp;nbsp;94.1%&lt;/strong&gt;。&amp;nbsp;&lt;/p&gt;&lt;p&gt;再看模型：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;闭源最强：&lt;strong&gt;Gemini3‑Pro‑Preview 49.7%&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其后：&lt;strong&gt;GPT‑5.2 34.8%、Doubao‑1.8 30.2%&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;开源侧：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;最强模型（&lt;strong&gt;Qwen3VL‑235B‑Thinking&lt;/strong&gt;）整体 &lt;strong&gt;22.2%&lt;/strong&gt;，多数模型在 12&amp;ndash;19% 区间。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;更关键的是：&lt;strong&gt;差距不是集中在某一个类别&lt;/strong&gt;。四大类能力都在下滑，说明这是 &amp;ldquo;系统性缺基础视觉能力&amp;rdquo;，而非某个单点缺陷。 一些子任务甚至几乎 &amp;ldquo;全员翻车&amp;rdquo;，例如 &lt;strong&gt;Count 3D Blocks&lt;/strong&gt; 在多模型中普遍偏低，暴露的是模型结构化场景能力不足。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA6K7ZSNW1fC1k1hB7QuIujMbJhebibHxJr20HWutweCmibbfdk9JFSNzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.9537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527862" data-aistatus="1" data-original-style="width:492px;height:469px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/f6d71de4-dd2d-4a73-9958-a533dc035d5d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;04｜为什么会这样？因为这些视觉推理题目是没法用语言描述的（Unspeakable）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最反直觉的地方在于：&lt;/p&gt;&lt;p&gt;BabyVision 里的很多题，对人类来说不难，甚至孩子会用指一指、圈一圈、沿着线走一遍就搞定。&lt;/p&gt;&lt;p&gt;但模型一旦用文字去 &amp;ldquo;复述&amp;rdquo; 视觉，再用语言推理去算，信息就丢了。&lt;/p&gt;&lt;p&gt;研究团队把这种现象概括为：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;这些视觉题是 &amp;ldquo;unspeakable&amp;rdquo; 的，无法在不损失信息的情况下被完整语言化；模型试图把视觉压缩成 token，细节在压缩中消失。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;并进一步总结了 4 类典型挑战：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战 1：看不见 &amp;ldquo;非语言细节&amp;rdquo;（Observing Non-Verbal Details）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAoHiczERwTu9nBSIV96lxpXLTGNBAUjNVmnuRTL5dK5oEwcYuGAmqMAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9316666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527863" data-aistatus="1" data-original-style="width:442px;height:412px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/71e1c1a5-ea0c-4969-9d75-df10a2bd59fb/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;比如拼图 / 补全题里，选项差别可能只是&lt;strong&gt;一个微小边界、一个局部凸起、一个像素级错位&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;人类凭几何直觉 &amp;ldquo;对齐边界&amp;rdquo; 就能秒选；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型一旦把形状用语言概括成 &amp;ldquo;像钩子、两个腿、差不多七八个六边形&amp;rdquo;，细节就被抹平，选项在 token 空间里变得 &amp;ldquo;几乎一样&amp;rdquo;。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;挑战 2：追线追丢了（Manifold Understanding）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVG7PticNxtFicKCaSwqYHFMQwzpf5ly3xFtmsnO0jDkXO87RumNq8xEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527864" data-aistatus="1" data-original-style="width:399px;height:316px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7c82cac3-ee8c-49fd-9532-63643cf6e84a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;连线 / 绕线 / 轨迹题，答案编码在 &amp;ldquo;连通性&amp;rdquo; 里：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;人类是&lt;strong&gt;锁定一条线&amp;rarr;穿过交叉&amp;rarr;一路追到终点&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型往往把线翻译成 &amp;ldquo;左 / 右 / 上 / 下&amp;rdquo; 的离散步骤，一遇到交叉点就出现分叉爆炸，&lt;strong&gt;容易 &amp;ldquo;换轨&amp;rdquo; 追错线&lt;/strong&gt;。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;挑战 3：缺少真正的空间想象（Spatial Imagination）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4rsCA4xeU6OBqfcgbBE8QJd4x4gOFmyBiciaFnjIKKCJ2L9FsgXT145w/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.97" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527865" data-aistatus="1" data-original-style="width:415px;height:403px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/38f54f76-6739-4440-ae53-5012c6ca8c92/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;三维方块计数、视角投影、遮挡下的结构判断，人类通常不是 &amp;ldquo;用语言一步步描述&amp;rdquo;，而是把结构在脑中 &amp;ldquo;立起来&amp;rdquo;，换个角度看，再数。&lt;/p&gt;&lt;p&gt;模型则容易犯两类错误：&lt;strong&gt;漏掉隐藏块、投影关系搞错&lt;/strong&gt;。这不是逻辑差，而是缺少稳定的 3D 内部表征与变换能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战 4：图形规律归纳难（Visual Pattern Induction）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZdItK1Dbetp1raMxwcRUaicTBNOdBvxgKwE63PwhRbRmGxFjTcV5Wog/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.7536764705882353" data-s="300,640" data-type="png" data-w="816" type="block" data-imgfileid="503527866" data-aistatus="1" data-original-style="width:443px;height:334px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/08ee768c-cff8-470b-b552-6a22e631e03a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这类题要求从少量视觉示例里抽象出规则，再迁移到新图。&lt;/p&gt;&lt;p&gt;人类做的是关系映射，真正决定正确性的是 &amp;ldquo;&lt;strong&gt;发生了什么变化&lt;/strong&gt;&amp;rdquo; 而不是 &amp;ldquo;&lt;strong&gt;那里有什么&lt;/strong&gt;&amp;rdquo;，具体的形状、颜色、绝对位置都可以变，只有它们在变换中的 &amp;ldquo;身份&amp;rdquo; 不变。&lt;/p&gt;&lt;p&gt;模型常常盯着表面属性（颜色、形状），把 &amp;ldquo;结构规则&amp;rdquo; 误读成 &amp;ldquo;外观统计&amp;rdquo;，导致迁移时幻觉规则。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;05｜如果不让它用文字回答，让它 &amp;ldquo;画&amp;rdquo; 呢？BabyVision‑Gen 给出一个新方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当文本推理不够用，一个自然的问题出现了：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;能不能让模型像孩子一样，用画、圈、连线、描轨迹来作答？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;于是有了 BabyVision‑Gen：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从原基准中重新标注出&amp;nbsp;&lt;strong&gt;280 道&lt;/strong&gt;适合 &amp;ldquo;生成式作答&amp;rdquo; 的题&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求模型输出图像 / 视频来表达解题过程或答案&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;并开发了自动评测工具，与人工评测一致性达 &lt;strong&gt;95%&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队在 BabyVision‑Gen 上评测了多种生成模型（包括 Nano‑Banana‑Pro、Qwen‑Image、Veo‑3、Sora‑2）。现阶段得到的结论很克制但重要：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;生成式推理在视觉追踪、精细辨别等 VLM 易翻车任务上出现 &amp;ldquo;更像人类&amp;rdquo; 的行为（会真的去画轨迹、做标注）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但整体仍然缺乏稳定到达完全正确解的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这至少说明：把视觉推理 &amp;ldquo;落地到视觉操作&amp;rdquo; 上，可能是补齐短板的一条路。&lt;/p&gt;&lt;p&gt;下面看一个具体的例子：&lt;/p&gt;&lt;p&gt;任务：用红线沿着从左上角图形延伸出的那条线，完整地描出其全程路径。&lt;/p&gt;&lt;p&gt;Sora2&lt;a href="https://mp.weixin.qq.com/s/-uCVMlIJKaQ80YSBzhRFOw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6f413c5f-44af-4675-8ba7-48e14bf120e2/1768194840251.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAc7uK2NthD9btBqJhXQbybcGxauqWkX6QRniawY9gP9gbXmOBN0mYJicw%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4338405709814808591" data-ratio="1.7777777777777777" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4338405709814808591" data-vh="380.8125" data-vidtype="2" data-vw="677" data-w="1280" height="393" scrolling="no" width="677"&gt;&lt;div data-key="wxv_4338405709814808591"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;NanoBanana-pro&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA3Eg5KqoBEbHcWj6NQnZ9ddl9pa33KXGHBG3SdFCNgxUB8ibhrq3IOKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.9253731343283582" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503527871" data-aistatus="1" data-original-style="width:491px;height:454px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/fa2e6b89-b019-4719-95be-2130bcd1d160/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;06｜为什么 BabyVision 重要？因为现实世界不靠语言提示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;正如研究团队在 Blog（https://unipat.ai/blog/BabyVision）中所写：&lt;/p&gt;&lt;p&gt;很难想象一个视觉能力低于 3 岁孩子的机器人，能够可靠地在真实物理世界里帮助人类。&amp;nbsp;&lt;/p&gt;&lt;p&gt;今天，多模态模型 &amp;ldquo;会说会写&amp;rdquo; 已经很强。&lt;/p&gt;&lt;p&gt;但要走向真正的通用智能与具身智能，视觉地基必须补上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;看得准（细粒度辨别）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;追得住（轨迹 / 连通性）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;想得出（3D 结构想象）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归纳得了（图形规则迁移）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;BabyVision 的价值正在于：把 &amp;ldquo;看懂世界&amp;rdquo; 拆成可测量、可诊断、可迭代的 22 个原子能力，告诉我们差距到底在哪里、下一步该补什么，从而引导多模态大模型发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;UniPat&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;UniPat AI 致力于构建真实场景下 AI 训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。&lt;/p&gt;&lt;p&gt;官网链接：https://unipat.ai&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026 Oral｜快手提出全新「检索数据引擎」CroPS，打破搜索信息茧房</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:07:40 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8810ff32-b049-412f-8061-caa79c22c3ed/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;短视频搜索业务是向量检索在工业界最核心的应用场景之一。然而，当前业界普遍采用的「自强化」训练范式过度依赖历史点击数据，导致系统陷入信息茧房，难以召回潜在相关的新鲜内容。&lt;/p&gt;&lt;p&gt;针对这一问题，&lt;strong&gt;快手搜索团队提出了一套全新的检索数据引擎 CroPS（Cross-Perspective Positive Samples）&lt;/strong&gt;。该方法通过引入用户换 Query 数据、推荐流数据以及大模型生成的世界知识，多视角丰富了正样本信号，并结合层次化标签分配（HLA）策略和 H-InfoNCE 损失函数，实现了对相关性的精细化建模。&lt;/p&gt;&lt;p&gt;目前，CroPS 已在快手搜索业务中实现全量部署，服务亿级用户。实测表明，&lt;strong&gt;该方案在具备极强的架构普适性的同时，显著提升了 CTR 与长播率，并有效降低用户换 Query 率，优化用户搜索体验。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本工作相关成果《CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search》已被人工智能顶级会议 AAAI 2026 Oral 接收。&amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gTjyyR9ATcQ5PfPHZHibaoq1jyTgib0P5vrO3wTXFxCMU4zEI0FjYfAJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.22592592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527340" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8f756158-097c-4449-95cc-40c2baf8aefd/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2511.15443v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前工业界主流的向量检索模型通常采用对比学习范式进行训练，拉近 Query 与正样本在向量空间中的距离，同时推远与负样本的距离，从而学习内容相关性。&lt;/p&gt;&lt;p&gt;然而，在绝大多数工业系统中，&lt;strong&gt;训练数据的正样本高度依赖历史曝光日志中的用户交互行为（如点击），导致「自强化」循环发生&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;具体而言，模型倾向于检索与历史高频点击内容相似的视频，用户受限于展示结果，只能在有限内容中选择和反馈，而这些反馈又再次作为正样本进入下一轮训练，进一步强化了模型原有的偏好。&lt;/p&gt;&lt;p&gt;这种机制不可避免地引发了严重的样本偏差。一方面，大量潜在相关但从未获得曝光机会的优质长尾内容，被系统性地排除在正样本之外，甚至在随机负采样过程中被错误标记为负样本。这种偏差使模型的检索视野逐渐狭窄，搜索结果变得保守且单一。&lt;/p&gt;&lt;p&gt;另一方面，由于缺乏对新颖内容的探索能力，用户的搜索体验逐渐固化，难以在结果中获得惊喜或满足探索性需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gq62JOOOPgCqKE8xKCibiakejibHWoI8VZG4oG5tAicCia83Wd157SwjoUIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527341" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5bfb1380-8ec2-4407-8846-2ec8b7f9420d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;以往的学术研究多致力于改进模型结构（如引入交互更复杂的 Poly-Encoder）或优化负采样策略（如挖掘困难负样本），从而提升检索性能。虽然这些方法在一定程度上增强了对已知内容的判别能力，但始终在历史曝光数据的界限内打转，无法从根本上缓解正样本来源单一所带来的 &amp;ldquo;信息茧房&amp;rdquo; 效应。&lt;/p&gt;&lt;p&gt;针对这一挑战，&lt;strong&gt;快手搜索团队提出了 CroPS 框架，从根源上打破数据闭环。CroPS 首次在业界引入「跨视角」的正样本信号，重塑了检索模型的训练图景。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g7ufbJ6VkJAs6Zib8HB5kgug107N1QastqsJb7ibiahX05YVSE1u1ZUXXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.40925925925925927" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527342" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/531a315e-d13f-42c5-9f7e-27242cd6b4ee/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;多视角正样本增强引擎 CroPS&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了打破数据边界，CroPS 框架构建了一个包含三个维度的正样本增强引擎，分别利用用户换 &amp;nbsp;Query 行为、推荐系统反馈以及大语言模型（LLM）的世界知识，来全方位地丰富语义空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 基于用户换 Query 行为的查询级增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在真实的搜索场景中，用户往往难以一次性精准表达意图。当用户输入查询词 A 却未能找到满意结果时，通常会进行查询重构，输入语义相关但表述不同的查询词 B。如果用户在查询词 B 的结果下产生了深度交互，那么该交互视频在语义上极有可能是查询词 A 的理想正样本，尽管它从未在 A 的结果中获得足够的曝光。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CroPS 敏锐地捕捉到了这种「意图连续性」&lt;/strong&gt;。通过分析用户在短时间窗口内的改写序列，并利用轻量级语义判别器进行过滤，系统能够将改写后获得的成功点击 &amp;ldquo;回流&amp;rdquo; 给原始查询，利用用户的修正行为来纠正模型的语义偏差。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 打破搜推壁垒的系统级增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;推荐系统拥有海量用户消费数据，并且其算法机制天然倾向于发散和探索，因此推荐流中的视频往往具有更丰富的多样性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CroPS 建立了一套跨系统的信号桥接机制&lt;/strong&gt;：对于同一个用户，如果他在推荐信息流中深度消费了某个视频，且该视频在语义上与用户近期的搜索词高度相关，该视频就会被引入作为搜索模型的正样本。&lt;/p&gt;&lt;p&gt;通过这种跨系统的信号融合，搜索模型能够利用推荐系统的探索能力，将用户感兴趣但未主动搜索到的内容纳入召回视野，从而有效缓解单一系统带来的位置偏差和曝光偏差。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 引入大模型的知识级增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当平台现有的内容库或日志无法覆盖某些长尾、复杂查询时，单纯依赖内部数据是无解的。为此，&lt;strong&gt;CroPS 引入了大语言模型（LLM）作为「虚拟检索器」和「内容生成器」，利用 LLM 蕴含的丰富世界知识生成高质量合成样本&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;具体而言，系统采用单样本提示（One-shot Prompting）策略，让 LLM 扮演视频内容专家，针对特定查询生成包含标题、描述和标签的虚拟视频元数据。将这些合成数据作为正样本，训练双塔模型，相当于将外部世界的常识与逻辑 &amp;ldquo;蒸馏&amp;rdquo; 进检索模型中。&lt;/p&gt;&lt;p&gt;这一方法使得模型在面对「冷门」或「从未见过」的搜索 query 时，仍能够凭借语义理解能力找到相关内容，从而彻底突破平台存量数据的限制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g0j3xoTSpJgYTKfp4hvg2TxfNmudjI4sNRMM1eqiaMcV0NNqU3G8l98Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.6684931506849314" data-s="300,640" data-type="png" data-w="730" type="block" data-imgfileid="503527348" data-aistatus="1" data-original-style="width:480px;height:801px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/51ecd71d-5f01-4855-8f45-9baca2bf9d5c/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;层次化标签分配 (HLA)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;HLA 的核心是解决 CroPS 多源正样本的「可靠性差异」问题&lt;/strong&gt;。不同来源的正样本（比如：用户换 Query 后产生互动的视频、推荐流中的视频）与用户真实需求的契合度各不相同。如果一视同仁进行训练，模型可能难以抓住重点。&lt;/p&gt;&lt;p&gt;因此，HLA 为样本分配「分层标签」，让模型能够识别样本的重要程度，从而学习更细粒度的相关性，更好地契合系统优化目标。&lt;/p&gt;&lt;p&gt;具体来说，HLA 将样本划分为「正样本相关层级」和「负样本层级」，为后续训练提供「细粒度监督信号」，不同类型样本对应固定标签，具体如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gm1meuoWKUGo49zsenuKHfdG6NviasicVxDZ3M9cDOib4HDshaz2oicATOA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6240601503759399" data-s="300,640" data-type="png" data-w="1064" type="block" data-imgfileid="503527350" data-aistatus="1" data-original-style="width:496px;height:310px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f4ea35eb-c1a3-4fd8-8315-af8c6100fa0b/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;H-InfoNCE 损失函数&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的语义召回采用的是 InfoNCE 进行优化，默认「样本只有正 / 负两种标签」，会逐个对比「单个正样本」和「对应的负样本」，无法区分 HLA 里「高标签正样本（如上图 Table 1 的标签 5）」和「低标签正样本（如上图 Table 1 的标签 3）」的层次化差异。&lt;/p&gt;&lt;p&gt;而 H-InfoNCE 在训练时，将「当前样本」与「标签严格低于它的所有样本」进行对比。这不仅突显了高优先级样本的重要性，也使学习目标与 HLA 的层级逻辑完全对齐，实现细粒度的语义区分。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;若当前样本是「用户换 Query（标签 5）」&lt;/strong&gt;，H-InfoNCE 会将其与「标签 &amp;le;4 的所有样本（包括推荐正例、曝光未点击样本、负样本等）」 一起对比，强制模型学习「标签 5 样本与查询的相似度，必须高于所有低标签样本」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;若当前样本是「曝光未点击样本（标签 3）」&lt;/strong&gt;，则只需对比「标签 &amp;le;2 的样本」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过这种方式，模型能够逐步掌握「高标签样本更重要」的排序逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gWPibibEia5QV4y3GR6QNeVWo8LyZLy7oUbC3LWmf1Lic1XZLZn41DvtLoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.20925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527351" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/405e3542-6919-40e3-ade4-cbfe18b816a0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; H-InfoNCE 在这里通过样例标签矩阵、样本 mask 矩阵等得到了高效实现。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g2n9X9Ycq80t52lWD9MZVcvHictwXxr1YtXYuZNS6JUnBiarziadwgYibZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.1935185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527352" data-aistatus="1" data-original-style="width:332px;height:64px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fc505d33-3936-451c-a88d-9f2fa6eee5c6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gL5X7e0ElhEI7XD2D1ZFCOPMFfms5D3d0DG8xCSJoRHZLZibKS1S8bmA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527353" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f5fd0547-fb20-4c08-8932-d9468d2482e4/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证这一框架的有效性，团队构建了两类测试集，来衡量模型的召回率 Recall@100：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CT&lt;/strong&gt;：用户点击测试数据集，即用户点击的视频作为正例；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;QR&lt;/strong&gt;：用户换 Query 测试数据集，即用户换 Query 后消费的视频作为正例。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;同时也引入了相关性标注测试数据集，以 NDCG@4 为监测指标，作为模型的相关性表征能力度量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;离线实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文中主要比较了三类主流方法：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;经典方法&lt;/strong&gt;：BM25（概率排序基线）、NCE（传统对比学习）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;神经网络方法&lt;/strong&gt;：DPR（双编码器稠密检索）、ANCE（动态难负样本采样）、ADORE+STAR（NN 模型引入筛选负例）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;负采样策略&lt;/strong&gt;：TriSampler（基于样本的空间位置进行的负例采样）、FS-LR（多级别负标签策略）。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在离线实验测试中，CroPS 相较于最强基线 FS-LR 在 CT 数据集上提升 9.5%，在换 Query 测试集 QR 上提升 7.1%。同时 NDCG@4 和 最强基线相当（67.4%-&amp;gt;67.0%）&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gTudqCG3dEQKmibxxibcApAAFpQMrBot8XBwarvz9d5bFN6tbZ7esIGnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6996047430830039" data-s="300,640" data-type="png" data-w="1012" type="block" data-imgfileid="503527354" data-aistatus="1" data-original-style="width:459px;height:321px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/95c99719-02eb-48bc-9c89-3c1b1a6380ef/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;在线实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在快手搜索的大规模 A/B 测试中，CroPS 带来了全方位的业务增长：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;点击率（CTR）显著提升了 0.869%，长播放率（LPR）提升了 0.483%&lt;/strong&gt;，表明召回的内容不仅相关度高，而且内容质量足以吸引用户长时间驻留。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;用户换 Query 率（RQR）下降了 0.646%&lt;/strong&gt;，意味着用户「一次搜对」的概率大幅增加，不再需要频繁更换搜索词来找到想要的内容，直接反映了用户搜索体验的质变。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g8Qjp9pXtMkkRwbsRWc0htJycocicsCCpAE1SD7icHPJm2ISZvWxNhibAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.4324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527355" data-aistatus="1" data-original-style="width:485px;height:210px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/d003abe1-b43f-407b-a6e2-2155485d6fd8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gkia4x7WvhHricPjwqt1V0eYJUhv7ziaK6ytPEBer85NENZ6PbflHUtheA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.31844660194174756" data-s="300,640" data-type="png" data-w="1030" type="block" data-imgfileid="503527356" data-aistatus="1" data-original-style="width:487px;height:155px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/cd309848-c6d9-422a-a549-1e00a008de69/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CroPS 证明了在工业检索系统中，正样本增强是缓解「信息茧房」问题的有效钥匙，能够提升系统上限。通过跨视角引入多样化信号，并结合精细化优化策略，&lt;strong&gt;CroPS 成功打破了自强化训练的边界&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;未来，快手搜索团队将进一步探索 CroPS 与生成式检索（Generative Retrieval）方法的融合，持续挖掘大规模语言模型在搜索全链路中的潜力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>被Jim Fan点赞！全球第一的千寻智能Spirit v1.5正式开源！</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 10:25:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/63add113-7164-4987-a0a2-3c9161545a00/1768184391206.png" style="width: 700%;" class="fr-fic fr-dib"&gt;提到具身智能，你首先会想到什么？&lt;/p&gt;&lt;p data-path-to-node="6"&gt;是宇树在春晚惊艳亮相的「转手绢」、特斯拉 Optimus 的「金色传说」、真到被怀疑真假的小鹏，还是 2025 年各家竞相上演的「炫技大赏」，空翻、家务、热舞、打拳，无所不能？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagaq2pZsdiaGuwia1qA24doNdnLia2tjW8icRummRjjLhYoFckLLla3QGOiag/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.0574074074074074" data-type="png" data-w="1080" data-width="2731" data-height="2887" data-imgfileid="503527693" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/23a674e8-7332-44f0-9895-229d6cd79063/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="7"&gt;已经过去的 2025 年，无疑是具身智能大爆发的一年。&lt;/p&gt;&lt;p data-path-to-node="8"&gt;热闹属于硬件，但具身智能还有另一个关键赛道：&lt;strong&gt;具身智能与机器人基础模型&lt;/strong&gt;，即具身智能的「大脑」。它们定义了具身智能的智力天花板，也长期主导了行业对「通用性」的解释权。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;在这个赛道，过去两年的叙事主线几乎被 Pi、Google、Figure 等海外团队主导。但在 2026 年伊始，格局发生了变化。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;1 月 12 号，千寻智能（Spirit AI）开源了自研 VLA 基础模型&amp;nbsp;&lt;strong&gt;Spirit v1.5&lt;/strong&gt;，该模型在第三方机器人模型评测组织&amp;nbsp;&lt;strong&gt;RoboChallenge 的 Table30 榜单上位列第一，超过了之前最强模型 Pi0.5&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz2lTewrr9WmOZnw1s0gjGVYzcPc56VXjKcO9TygF7ycWL6feaEzXTlQ/640?wx_fmt=jpeg#imgIndex=2" data-ratio="0.4777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz3seibTdcUYARKbzhptcuhEjBUGUg65ickic0EAib6lucEKWzMQqKCia0x1g/0?wx_fmt=png&amp;from=appmsg" data-cropx2="2940" data-cropy1="172.9411764705882" data-cropy2="1576.8166089965396" data-imgfileid="503527823" data-aistatus="1" data-original-style="width: 578px;height: 276px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/842144eb-116f-4460-acb5-88c4daae8cb6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;千寻开源了Spirit v1.5的基模权重、推理代码以及使用样例，接受公众检验，也方便社区在 Spirit v1.5 的基础上创新。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Code: https://github.com/Spirit-AI-Team/spirit-v1.5&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Model: https://huggingface.co/Spirit-AI-robotics/Spirit-v1.5&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Blog：https://www.spirit-ai.com/en/blog/spirit-v1-5&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="13"&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7a81cc85-59b3-4311-935f-fab796c3c5b6/1768184432544.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/734660a4-01f6-4883-8ed9-7154720bb4c9/1768184448166.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Spirit v1.5 vs Pi0.5 视频对比。上：Spirit v1.5，下：Pi0.5。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="15"&gt;这一手「硬核登顶+开源共享」的组合拳，引发了海外 AI 社区的即时关注，甚至引来了&lt;span data-pm-slice="0 0 []"&gt;英伟达具身智能负责人 Jim Fan（&lt;/span&gt;&lt;span data-type="text"&gt;范麟熙&lt;/span&gt;&lt;span data-type="text"&gt;）的点赞、&lt;/span&gt;Hugging Face 的官方祝贺，以及多位海外大 V 的转发。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzOXDEj1pphPXGQjqW1p18nCwHXCicZRCLBicib6C5czrogxRn0hyiahCgxg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5314814814814814" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527853" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0f9123a8-ae9a-4623-b24d-472df9339db8/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzSqa4ic1CcX6BdjN9vSH0b1a3zB0MguOZmYJF4MCZ2U3jQZrp89ouwnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.298148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527855" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/743a3b40-a0d8-4fbf-bcdb-1459baecb5ce/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzC4neKSzdZV6pqibyoGiadqAu6lmq0XuGYQuAEiatIImIZicDHKibj1Iz0Qg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0083333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527854" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/8a80b8b0-3366-4177-b800-dbeff0824146/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="17"&gt;这不再是一次简单的榜单轮换。它意味着，在具身智能这个未来的核心战场上，中国团队终于结束了「跟随模式」，正式拿到了「全球第一梯队」的入场券。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;Spirit v1.5 为什么能赢 Pi0.5？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;要回答这个问题，我们必须先看一眼「竞技场」。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;RoboChallenge 是由 Dexmal、Hugging Face 和智源研究院等机构发起的全球首个大规模真机评测平台。与常见的仿真环境跑分不同，RoboChallenge 的核心在于&lt;strong&gt;物理世界的真机实测&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="21"&gt;平台建立了一套名为「Table30」的任务集，包含设定在桌面环境中的 30 个多样化操作任务。这些任务不仅涵盖插花、制作三明治、插入网线等日常技能，还被特意设计用来挑战模型能力的各个维度：包括精确的 3D 定位、遮挡处理、时间依赖性以及多阶段长序列任务。&lt;/p&gt;&lt;p data-path-to-node="22"&gt;在该体系下，Spirit v1.5 在多构型机器人（包括 Franka、Arx5、UR5 及双臂 ALOHA 系统）上均进行了评测。截至 2026 年 1 月 12 日的评估显示，Spirit v1.5 在该基准测试上超越了 Pi0.5 等之前的全球领先开源模型，取得了当前最优的性能。&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a72a15c0-542e-4f4c-9e73-bd3adced34cc/1768184491629.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8b77dd1-20f7-4546-9980-a12aa28237b2/1768184508699.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Spirit v1.5 vs Pi0.5 视频对比。上：Spirit v1.5，下：Pi0.5。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="24"&gt;Spirit v1.5 的胜出并非偶然，其核心原因在于对机器人预训练数据范式的根本性重构。&lt;/p&gt;&lt;p data-path-to-node="25"&gt;&lt;strong&gt;摆脱「干净数据」的诅咒，转向「物理常识」的习得&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="26"&gt;传统的具身模型，大多基于如 Open X-Embodiment (OXE)、Agibot 和 RoboCOIN 等数据集进行训练。这些数据集虽然规模庞大，但主要由高度精选的、即所谓的「干净」数据组成。&lt;/p&gt;&lt;p data-path-to-node="27"&gt;在这种模式下，为了最大化采集成功率，研究人员往往像电影导演一样精心设计场景：物体被放置在可预测、易于触及的位置，动作被简化或脚本化。这种「完美」的数据虽然为模型提供了一个稳定的起点，但却产生了一个致命的副作用：经验的零散孤岛。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;如果在训练中，「擦桌子」的数据集永远只包含桌子和标准的擦拭动作，模型就永远学不会如何在抹布打滑后恢复，或者如何处理桌面上意料之外的杂物。这种过度「净化」的数据限制了机器人的泛化能力，一旦面对开放世界的不可预测性，模型极易失效。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;相比之下，Spirit v1.5 采用了「&lt;strong&gt;开放式、目标驱动&lt;/strong&gt;」的数据采集策略。其核心理念是摒弃书面脚本，只给操作员一个模糊的高层目标（如「清理厨房」），允许其即兴发挥。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;在 RoboChallenge 的 Table30 测试中，Spirit v1.5 展现出的跨场景泛化能力主要得益于以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="31,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="31,0,0"&gt;构建连续的技能流形&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="31,0,0"&gt;传统数据制造了任务间的割裂，而 Spirit v1.5 的数据采集员可能会先拿起食物容器，发现碎屑后开始擦拭，接着整理餐具。这种连续的会话将多个微技能自然串联，涵盖了抓取、扭转、插入和复杂的双手协调。&lt;/p&gt;&lt;p data-path-to-node="31,0,0"&gt;这意味着模型不再是机械地重复单一动作，而是学习到了动作与动作之间的过渡与衔接。如同案例所示：无论是给假人模型化妆，还是组装复杂的乐高结构，模型掌握的是一个原子技能谱系，而非孤立的动作片段。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="31,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="31,1,0"&gt;内化的纠错与恢复能力&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="31,1,0"&gt;这是 Spirit v1.5 区别于传统模型的关键。由于训练数据通过「将采集员派往现实环境中的随机地点」获得，包含了海量的物体交互和环境转换，模型见识过各种失败与混乱。因此，Spirit v1.5 习得了类似人类的「物理常识」。&lt;/p&gt;&lt;p data-path-to-node="31,1,0"&gt;当面对复杂操作中的干扰、物体打滑或光线突变时，模型展现出了惊人的韧性，它学会了在动作执行受阻时如何进行动态调整和恢复，而不是像脚本机器那样直接死机。&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d7d0b905-3291-460b-8346-3c3a90ed71e9/1768184549448.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d0550c10-f5ea-4767-96b8-5904c18d9a76/1768184566003.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="31,1,0"&gt;&lt;sup&gt;多样化采集数据示例。上：采集员通过末端执行器操作给假人模型化妆。下：采集员组装复杂的乐高结构。两个案例都展示了多样化原子技能的连续流，包括抓取、扭转、插入和复杂的双手协调。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;模型不是「更大」，而是「更对」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;技术报告中的消融实验进一步证实，Spirit v1.5 的优势源于更高效的数据利用策略，而非盲目的算力扩张。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;实验建立了两组模型进行对比：A 组使用精选演示数据，B 组使用开放式多样化数据，且保持两组的总数据量完全相同。结果揭示了显著的「多样性增益」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="36,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="36,0,0"&gt;收敛速度与迁移效率&lt;/b&gt;：在针对全新任务微调时，使用多样化采集训练的模型（Spirit 策略）达到相同性能基线所需的迭代次数比基线模型少了 40%。这表明，任务的多样性比单任务的演示数量更为关键。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagwSj7Xdgjjt9UCQkWiaEjKtjmd6dcKgUeKGVlVkUsGkreSJdojfb1UWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6" data-type="png" data-w="1080" data-width="1280" data-height="768" data-imgfileid="503527719" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5bd3aa2d-4091-4b4f-804b-60b70f9cc752/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="36,0,1"&gt;&lt;sup&gt;多样化采集预训练的模型比干净数据采集训练的模型具有更快的收敛速度和更好的验证误差。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="36,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="36,1,0"&gt;验证误差的持续下降&lt;/b&gt;：研究还发现，随着多样化数据规模的扩大，模型在新任务上的验证误差呈持续下降趋势。这证明模型正在有效地从现实世界日益增加的内在多样性中汲取养分，形成了一种通用的策略基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagQtQia5TLzd43UnA7OWLH20IeCJ6oPsEnRmEX9bqWKibvB7cSlTfkobvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6" data-type="png" data-w="1080" data-width="1500" data-height="900" data-imgfileid="503527720" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9d7a395b-55c9-4d80-927a-a6b71cf344e7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="36,1,1"&gt;&lt;sup&gt;不同数据规模下的模型效果。扩大多样化采集的数据规模可以持续降低模型的验证误差。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="37"&gt;&lt;strong&gt;既是「榜单杀手」，也是「工程利器」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="38"&gt;除了在学术榜单上领先，Spirit v1.5 在工程落地层面也解决了困扰行业已久的可扩展性的难题。&lt;/p&gt;&lt;p data-path-to-node="39"&gt;传统的「干净数据」采集需要工程师团队设计任务、编写详细指南并严格筛选数据，这种工作流程极大地限制了数据采集的体量和扩展性。&lt;/p&gt;&lt;p data-path-to-node="40"&gt;Spirit v1.5 采用的非结构化采集方式，允许操作员在只设定高层目标（如「清理厨房」）的前提下即兴发挥。这种范式转变带来了巨大的工程效益：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="41,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="41,0,0"&gt;采集效率提升&lt;/b&gt;：数据显示，人均有效采集时长增加了 &lt;strong&gt;200%&lt;/strong&gt;。因为操作员不再是重复数百次枯燥的机械动作，而是像玩游戏一样在物理世界中互动，保持了极高的投入度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="41,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="41,1,0"&gt;专家依赖降低&lt;/b&gt;：这种流程将对算法专家干预的需求削减了 &lt;strong&gt;60%&lt;/strong&gt;。这意味着，大规模扩展数据采集规模不再受限于稀缺的专家资源，管理成本不再线性增加。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="42"&gt;目前，Spirit v1.5 的基模权重、推理代码以及使用样例已全部开源，供研究人员复现和探索。这不仅证明了其作为「实战派」模型的底气，也为通用机器人从实验室走向真实的家庭和产线环境铺平了道路。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;&lt;strong&gt;中国开源力量的突破性进展&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="44"&gt;如果说技术上的超越是 Spirit v1.5 的「硬实力」，那么选择全量开源则是其更具产业价值的决定。&lt;/p&gt;&lt;p data-path-to-node="45"&gt;回顾过去两年，从 Qwen、DeepSeek 到 Kimi、GLM 等，中国的大模型团队已经证明了这一点：&lt;strong&gt;开源模型不仅能追平闭源模型的性能，更能成为推动全球技术平权的重要基础设施。&lt;/strong&gt;这些来自中国的开源力量，实际上已经成为了许多海外开发者构建应用的首选基座。&lt;/p&gt;&lt;p data-path-to-node="46"&gt;不可否认，「开源共建」也已逐渐成为具身智能领域的行业共识，但拼图尚未完整。&lt;/p&gt;&lt;p data-path-to-node="47"&gt;高性能的机器人基础模型（如 Google RT 系列或 Pi）大多处于闭源或半闭源状态。开发者往往面临「两难」：要么使用性能较弱的旧模型，要么依赖大厂的 API，不仅成本高昂，且难以针对特定硬件进行适配。这种「基座缺失」直接制约了具身智能从实验室走向产业落地的速度。&lt;/p&gt;&lt;p data-path-to-node="48"&gt;Spirit v1.5 的开源，标志着&lt;strong&gt;中国团队正在将 LLM 领域的开源繁荣，延续到具身智能领域&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="49,0,0"&gt;&lt;strong&gt;对于科研界&lt;/strong&gt;，它打破了「无 SOTA 可用」的局面，提供了一个与 Pi0.5 同等甚至更强的可复现基线；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="49,1,0"&gt;&lt;strong&gt;对于产业界&lt;/strong&gt;，它为大量试图进入具身智能赛道的中小型厂商，提供了一套经过验证的、可商用的技术底座，避免了行业性的重复造轮子。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="50"&gt;从 Qwen、DeepSeek 到 Spirit，中国团队正在通过高质量的开源贡献，逐渐从全球 AI 生态的「参与者」转变为关键基础设施的「建设者」。&lt;/p&gt;&lt;p data-path-to-node="51"&gt;&lt;strong&gt;结语：从「追随」到「定义」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="52"&gt;RoboChallenge 的榜首位置或许会轮换，数据的记录终将被刷新，但 Spirit v1.5 的出现具有明确的界碑意义：&lt;/p&gt;&lt;p data-path-to-node="53"&gt;它通过实验证明了「&lt;strong&gt;非结构化的多样性是比精选数据更好的老师&lt;/strong&gt;」。在通往通用具身智能的道路上，中国团队已经结束了单纯的「跟随模式」，具备了在核心技术路径（数据范式）与生态建设上与全球顶尖团队「对等对话」甚至「定义规则」的能力。&lt;/p&gt;&lt;p data-path-to-node="54"&gt;随着代码仓库的公开，全球的目光和测试数据将涌向 Spirit v1.5。对于千寻智能而言，登顶榜单只是一个开始，真正的考验才刚刚拉开序幕：如何在真实世界的千万种场景中，经受住全球开发者的验证与打磨。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Sakana让AI互相「猎杀」，而它们开始了趋同进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:59:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3068ed3b-cfe2-4d99-89f8-d577333542b7/1768139698064.png" style="width: 700%;" class="fr-fic fr-dib"&gt;想象一下，一群 AI 程序在一台虚拟计算机里相互猎杀，目标只有一个：&lt;strong&gt;生存&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是 Sakana AI 与 MIT 合作的最新研究：&lt;strong&gt;Digital Red Queen（DRQ）&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagibdw6SsGTU6xk0b1YGDb2wEeZ1J1dzUQBib0icyibw4tkRVPzTrPwQrp4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.25" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527661" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/adfc502c-97d9-40e5-ab6e-194779bd3adf/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他们重拾了 1984 年的经典编程游戏《Core War》，利用大模型驱动了一场跨越维度的「军备竞赛」。&lt;/p&gt;&lt;p&gt;在这里，没有预设的标准答案，只有不断进化的对手。简单来说，他们提出了一种自演化汇编代码的方法。该方法通过在《Core War》中不断战斗来迭代代码演化。与静态优化目标不同，通过训练新「战士」对抗不断变化的对手，可以生成既健壮又通用的「战士」。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7f4932a6-6d4a-4df7-bf4b-b321845c4d76/1768139718803.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种「自博弈」模式产生出的汇编代码，不仅展现出了惊人的复杂性，更揭示了人工生命中一种有趣的现象：&lt;strong&gt;趋同进化&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVaggSsQIxt8ZYZrsggf3MmE4HibalBH8DhgPIGPMhicHk3GCuybXj9QybHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.24351851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527663" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8d7cb0f6-e4ca-496a-b3a4-1eb06759f949/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.03335&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/SakanaAI/drq/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;博客地址：https://sakana.ai/drq/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;《Core War》 是一款诞生于 1984 年的竞技编程游戏，在这款游戏中，被称为「战士」（warriors）的程序在一个虚拟计算机中争夺控制权。参赛者需要使用一种名为 Redcode 的专用汇编语言来编写程序。&lt;/p&gt;&lt;p&gt;在这项研究中，Sakana 探索了一个全新设定：&lt;strong&gt;当 LLM 驱动这个游戏时，会发生什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于静态评测基准，他们构建了一个动态的对抗演化环境，在其中程序不断适应、进化，以击败逐渐累积的对手历史，而非一组固定敌人。然后发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;这一动态对抗过程促使模型产生了越来越通用的策略；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不同的程序实现最终会趋向于相似的高性能行为模式，展现出类似趋同进化（convergent evolution）的现象；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;整体演化过程符合红皇后动态（Red Queen dynamics），即各个智能体不断适应彼此，持续进化但始终处于竞争状态。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终，本研究将《Core War》定位为一个用于研究人工系统中红皇后（Red Queen）动力学的实验沙盒，为分析 AI 智能体在现实世界对抗性环境（例如网络安全）中的演化方式，提供了一个安全且可控的研究环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag3BiazjJ4Z09GrNBUXKwxvJuPhicOOImubykFrMrgxcvvBgf7PyWNQMhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527664" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/36693e3e-a3c6-4a92-90a9-3ebc4d97b6b3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVaglsxiazYcEdB9U8DEcaWf0FArENhaRnqs7ZORWicmYLm4QuUhfJTTT1lA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4981481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527665" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1e534a9f-00f0-4ae8-9d43-fa1a2054bf6d/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;由 DRQ 生成的两个「战士」程序：Ring Warrior Enhanced v9 和 Spiral Bomber Optimized v22。选取这两个示例是为了展示 DRQ 的两个互补特性：其在单个程序中合成质量上截然不同的策略的能力，以及其生成整体表现良好的「战士」程序的能力。请注意，注释部分由大语言模型生成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/db02af18-13a9-4d9b-abcc-946712c2a368/1768139751093.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;在一个隔离的《Core War》沙盒环境中模拟，演化得到的「战士」程序。用户可以交互式地查看鼠标光标所在位置附近的「战士」汇编语言代码（Redcode）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「战士」程序相互竞争 &amp;nbsp;争夺一台虚拟机的控制权&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人类是一场非凡的进化军备竞赛的产物，在与其他生物体持续不断的竞争中被塑造而成。然而，进化并没有停止：竞争仍然在各个层面持续存在，从病毒与细菌，到人类个体、公司之间多方面展开博弈。&lt;/p&gt;&lt;p&gt;随着越来越多的人工智能系统被部署到现实世界中，它们也将不可避免地进入这一竞争格局。这些 AI 系统将以直接或间接的方式相互竞争，从而引发一种全新的演化动态。&lt;/p&gt;&lt;p&gt;为了为这样的未来做好准备，并研究其中演化过程，Sakana 使用 LLM 来演化一组程序，让它们在《Core War》的游戏中相互竞争，这些竞争者的任务是在尽可能长的时间里保持自身进程活跃的同时，尝试使对手程序崩溃，从而取得对一台虚拟计算机的控制权。&lt;/p&gt;&lt;p&gt;整个模拟过程通过交替执行各个程序中的一条指令来运行。一个「战士」可以通过向对手占据的内存位置写入非法指令（如 DAT 命令）来发起攻击，一旦对手程序执行到该位置就会崩溃。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/14b2adbf-7651-4530-a5d9-7aae7db9ff90/1768139769993.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;在《Core War》中相互对战的已发现「战士」示例。在本研究中，Sakana 使用 LLM，通过 Digital Red Queen 的自博弈算法来演化「战士」。这一过程促使出现了多种多样且复杂的策略，包括定向轰炸、自我复制以及大规模多线程。在这里，本文展示了一些被发现的「战士」在《Core War》对战中的表现。图中符号表示指令操作码，颜色表示最后一次修改每个内存地址的「战士」。代码和数据之间没有区分，使得该环境高度动态且不稳定。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，在《Core War》中，代码和数据之间没有界限，因此「战士」程序会在运行过程中频繁地修改自己和对手的代码。&lt;/p&gt;&lt;p&gt;这使得自我修改甚至自我复制成为可能，但也造就了一个极度不稳定的环境，程序必须在这种条件下设法生存下来。&lt;/p&gt;&lt;p&gt;此外，《Core War》是图灵完备的，也就是说，从理论上它可以支持任意复杂的策略。&lt;/p&gt;&lt;p&gt;多年来，人类玩家在《Core War》中设计出了许多巧妙的策略，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;向随机内存位置投放炸弹；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;编写可自我复制的程序；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不断扫描内存，侦测对手位置并发起攻击。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些策略的诞生，实际上是一场由人类主导的元军备竞赛，玩家不断尝试新策略，测试哪些能奏效、哪些不行。&lt;/p&gt;&lt;p&gt;那么，如果我们让 LLM 也参与这样一场军备竞赛，会发生什么？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新提出的方法：数字红皇后（DRQ）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在进化生物学领域，&lt;strong&gt;「红皇后假说（Red Queen Hypothesis）」认为物种必须不断进化，仅仅是为了在千变万化的竞争对手面前生存。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该假说指出，仅仅适应当前环境是不够的。相反，生物必须持续进化 &amp;mdash;&amp;mdash; 不是为了获得优势，而仅仅是为了在这个变幻莫测的世界中维持相对的适应度。&lt;/p&gt;&lt;p&gt;这个概念完美捕捉了对抗性军备竞赛的本质：&lt;strong&gt;即「适应」永远不是一种永久状态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个名字源于《爱丽丝镜中奇遇记》，红皇后对爱丽丝说：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;「在这个国度，你必须拼命奔跑，才能留在原地。」&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4a06ca7a-2459-4b73-8743-41f5e5889139/1768139804308.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;受生物学启发，Sakana 构建了一种名为数字红皇后（DRQ）的简单算法，它在计算环境中体现了这一思想。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DRQ 利用 LLM 来在持续的环境变化中让「战士」进化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体来说：它从一个初始战士开始，然后进化出第二个战士来击败第一个。接着，再进化出第三个战士，使其在对抗前两个战士时表现出色，以此类推。这一过程产生了一个战士世系，其中每个后代都适应于由其所有前代定义的不断变化的环境。&lt;/p&gt;&lt;p&gt;Sakana 表示：「DRQ 本身并非旨在成为一种全新的算法。相反，它是先前多智能体和自博弈方法的最小化实现。它被适配到《Core War》领域，旨在隔离并研究持续协同进化（coevolution）的动态。」&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a72f29f3-6f01-40ce-82c1-715e75ceba91/1768139818850.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究发现，&lt;strong&gt;随着 DRQ 运行轮次的增加，战士们逐渐变得更具通用稳健性&lt;/strong&gt;（这一指标通过与未见过的、由人类设计的战士对抗来衡量）。&lt;/p&gt;&lt;p&gt;这提供了一种稳定且持续生产稳健程序的途径，而无需进行「在测试集上训练」（即直接针对大量人类设计的程序进行优化）。&lt;/p&gt;&lt;p&gt;更令人惊讶的是，实验中还观察到独立运行的多个 DRQ 实验（每个实验都从不同的战士开始初始化）会随时间推移，慢慢趋向于演化出具有相似行为的战士。值得注意的是，这种趋同并没有发生在源代码层面，这表明趋同的是「功能」而非「实现」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagJz8eOMUkAibXvfvYPic4SW09ozOhvUPd9H4APEXAu4EicIPcQlnqZgayw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.32314814814814813" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527667" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e789c70d-7800-47b7-8429-f20edef43d25/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;DRQ 的趋同进化：随着轮次增加，DRQ 产生的战士具有更强的通用稳健性。同时，不同独立运行的 DRQ 实验之间，战士行为的差异在减小，表明出现了趋同。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag7NSRuerZmQWszkoNYq7GqnLE1BFA0frTqG9DF2MWIrFPsf3dK3xsBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.45185185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527668" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/35a870f6-c879-448e-9ff4-adb1fc45d915/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表型趋同（Phenotypic Convergence）：轮次增加带来的趋同仅体现在战士的「表型」（行为）上，而非「基因型」（源代码）。这类似于生物学中功能上的趋同，而非 DNA 的趋同。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一结果让人联想到生物学中的趋同进化 &amp;mdash;&amp;mdash; &lt;strong&gt;即相似的功能特征通过不同的机制独立进化了多次。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;例如，鸟类和蝙蝠各自独立进化出了翅膀；蜘蛛和蛇独立进化出了毒液。&lt;/p&gt;&lt;p&gt;在这些案例中，由于环境变化施加的功能需求倾向于这些解决方案，进化最终达成了相似的通用目的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;讨论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「红皇后（Red Queen）」动态及其引发的趋同进化现象在自然界中普遍存在，这表明 DRQ 算法和 Core War 领域的结合，可能为研究对抗性军备竞赛其他特性提供了一个极具潜力的实验环境。通过模拟得到的宏观洞察，可以帮助我们预测 LLM 在现实世界中的军备竞赛将如何展开与演变。像 DRQ 这样的算法，甚至有助于在系统部署到现实世界之前，实现自动化的红队测试（red-teaming）。&lt;/p&gt;&lt;p&gt;在《Core War》这样的沙盒中进行此类研究的好处是，它完全自成体系：所有程序都在一台使用人造语言的虚拟机器上运行，因此生成的任何内容都无法在沙盒外执行。这提供了一个安全的环境，可以探索那些在现实世界中进行可能具有风险的对抗性动态。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4ebd7700-3793-4f63-a48f-c1e0d0470d35/1768139852297.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;在沙盒化的《Core War》环境中，可以模拟进化出来的「战士」程序，并将它们的行为可视化。用户可以交互式地可视化这些「战士」的汇编语言（Redcode），并通过鼠标光标所在的位置进行查看。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;尽管基础版 DRQ 算法本身较为简单，但它在《Core War》中表现出乎意料得好，这表明：&lt;strong&gt;即便是最简单的自对弈循环，也能揭示出复杂且鲁棒的策略。&lt;/strong&gt;这使得 DRQ 成为探索其他竞争性多智能体仿真（如人工生命、生物学、药物设计、现实世界网络安全或市场生态系统）的有力候选方案。&lt;/p&gt;&lt;p&gt;未来的工作还可以探索更丰富的设置，让多个智能体能够同时共进化，从而更好地模拟现实世界 &amp;mdash;&amp;mdash; 在那里，大规模种群是并行适应的，而不是沿着单一的演化线发展。最终，所获得的洞察将有助于更好地掌握未来，并帮助我们理解这些进化性军备竞赛背后的科学原理。&lt;/p&gt;&lt;p&gt;更多信息，可查看原论文获悉！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
