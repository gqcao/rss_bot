<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>超DeepEP两倍！无问芯穹FUSCO以「空中变阵」突破MoE通信瓶颈，专为Agent爆发设计</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 17:56:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-10</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fc5e277e-d4f4-4723-9276-10496196c2ad/1767174672284.png" style="width: 700%;" class="fr-fic fr-dib"&gt;随着 ChatGPT、Gemini、DeepSeek-V3、Kimi-K2 等主流大模型纷纷采用混合专家架构（Mixture-of-Experts, MoE）及专家并行策略（Expert Parallelism, EP），MoE 技术已在产业应用中逐渐成为主流。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;与此同时，以代码智能体、Cursor 类对话式 IDE 为代表的新型应用，&lt;strong&gt;一方面显著推高了用户请求规模，另一方面大幅拉长了单次推理的上下文长度，两者均呈现出一个数量级以上的增长。&lt;/strong&gt;在 MoE 架构下，这种变化不仅线性放大了计算开销，还显著增加了跨专家的通信与调度成本，使得整体系统压力接近一个数量级提升，并在规模化服务场景中进一步被放大。&lt;/section&gt;&lt;p&gt;MoE 模型因其结构上的稀疏性与专家并行特性，天然引入了频繁且规模庞大的全局分布式数据交换。而&lt;strong&gt;当前主流通信库及解决方案（如 DeepEP）&lt;/strong&gt;仍基于 “通信与数据布局解耦” 的传统设计假设，难以高效应对实际生产中的跨设备、非连续、动态重排的数据访问模式，在高并发、长上下文与大规模专家配置的场景下，DeepEP 性能已逐渐趋近瓶颈，直接制约了 MoE 大模型的持续落地、系统稳定扩展与经济性运行。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LictTuJfnD7iaNSwyf2MwHicM6FaMqO8b72ZIJEqMvzpavNAbERkuuoIxg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=1" data-ratio="0.24814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526329" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c5165c2a-7868-4a12-9ce9-13163196b61b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://www.arxiv.org/abs/2512.22036&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源地址：https://github.com/infinigence/FUSCO&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;基于此，无问芯穹联合清华大学、中关村学院、上海交大及南加州大学，面向 MoE 模型结构和 EP 并行策略场景，推出高效通信库 “FUSCO”。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这是一种全新的融合式通信优化路径：将通信过程与数据底层布局主动协同，在数据搬运的同时完成布局转换，从而彻底消除冗余的数据重排操作。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一设计将融合优化的边界从传统的计算算子之间融合，拓展至通信与数据操作之间的跨层融合，揭示了大模型训练与推理中一个此前未被充分挖掘的优化新空间。在此基础上，FUSCO 可自动实现负载均衡与冗余通信消除，并在不同 GPU 架构与网络拓扑下保持良好的可移植性，为大规模模型的端到端执行提供了一种更具系统性的融合优化路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验表明，相较于 NCCL 和 DeepSeek 的 DeepEP 通信库，FUSCO 的通信性能可最高分别提升 3.84 倍和 2.01 倍。且在实际部署场景中，随着并发请求数和文本长度（例如达到 2048K tokens）的增加，其性能优势将进一步扩大。&lt;/strong&gt;这为基于 MoE 模型的推理、训练的各类 Agent 场景提供了有力支持。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L9Y6wmxvmAoZqGOPq9shTS36rH4ualNiaI2Qe03ibrf2mc77iawAthlo1w/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="1.3359375" data-s="300,640" data-type="png" data-w="1024" type="block" data-imgfileid="503526331" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f964268d-d216-4535-9aee-35e2ed641ff6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;背景 &amp;nbsp;MoE 专家并行架构下的通信与数据重排瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大规模 MoE 模型的训练和推理中，单个 GPU 往往无法承载完整模型权重或处理全部 token。因而系统通常引入&lt;strong&gt;专家并行（Expert Parallelism）&lt;/strong&gt;，将不同专家分布在多个 GPU 上，以提升计算吞吐并扩展模型容量。尽管该策略有效提升了可扩展性，但也引入了新的性能瓶颈：&lt;strong&gt;token 需要在不同专家所在的 GPU 之间进行跨设备的数据重排与通信，形成分布式数据重排（Distributed Data Shuffling）过程&lt;/strong&gt;，其典型执行流程包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通信前的 token 重排&lt;/strong&gt;：根据 token–expert 的映射关系确定目标 GPU，并将 token 按目标 GPU 的通信布局重新排列，以满足 All-to-All 的数据组织要求；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨 GPU 的 All-to-All 通信&lt;/strong&gt;：重排后的 token 通过 All-to-All 通信发送至对应专家所在的 GPU；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通信后的 token 重排&lt;/strong&gt;：每个 GPU 根据其本地承载的专家集合，对接收到的 token 进一步按专家进行排列，并完成对应专家的计算；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;镜像式的合并 (Combine) 过程&lt;/strong&gt;：在专家计算完成后，系统按与上述过程相反的顺序，依次执行本地逆向重排、All-to-All 通信以及最终的 token 顺序恢复，以保证输出与原始 token 顺序一致。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;传统集合通信库遵循 “通信与数据布局解耦” 的设计范式：通信被视为对连续数据块的被动搬运，而数据在模型执行过程中所固有的布局语义（如视图变换、维度重排与切片关系）通常被忽略。这一抽象虽然简化了接口，却在大模型训练与推理中引入了大量隐式的中间张量重排与内存拷贝，成为制约端到端效率的重要瓶颈。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LJpNk1T25uRiaPMfrXxnJOXIkwTG0HN9OAmERqJss0ppmO5kxfBLkDqQ/640?wx_fmt=jpeg&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.7824074074074074" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526336" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4b8d54f8-14cc-4b87-b2dd-738da91e2b8c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;随着专家并行规模的扩大，上述过程的开销呈上升趋势&lt;/strong&gt;。训练和推理的吞吐虽然随更多设备的参与而提升，但分布式数据重排在端到端总延迟中所占比例总体上不断增加。&lt;/p&gt;&lt;p&gt;这一现象主要源于随着专家分布在更多设备上，token 在设备间的传输量增加，同时全局同步成本也随之上升。每个 token 都必须在参与 GPU 间交换和重排，这相对于计算增加了额外的延迟。尽管专家内部的前馈计算仍然高效，但在更高的专家并行度和更大集群规模下，分布式数据重排已成为端到端性能的重要瓶颈。&lt;/p&gt;&lt;p&gt;为量化这一过程的开销，我们进一步对&lt;strong&gt;一次通信前后的数据重排与通信本身&lt;/strong&gt;进行了细致分析。以 32 MB 数据为例，使用 PyTorch 的 index_select 算子模拟本地重排操作，并分别在机内（NVLink）和跨机（RoCE）环境下，结合 NCCL 的 send/recv 原语测量通信延迟。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;机内 (NVLink)&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;跨机 (RoCE)&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;总时延&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;0.349&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;0.96&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;通信时延&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;0.109&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;0.72&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;重排时延&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;0.24&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;0.24&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;重排占比&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;68.8%&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="191"&gt;&lt;section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;25%&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;结果显示，重排操作在总 shuffle 时间中的占比分别高达 68.8%（机内）和 25%（跨机）。&lt;/strong&gt;这说明 MoE 中的数据移动瓶颈不仅来自网络带宽限制，还受限于内存绑定的数据重排操作。并且，随着互联效率不断提升，通信本身变得更快，若数据重排开销保持不变，其在总执行时间中的占比将更突出。&lt;/p&gt;&lt;p&gt;此外，&lt;strong&gt;传统的 All-to-All 通信对 token 冗余和网络层次缺乏感知。&lt;/strong&gt;在实际 MoE 工作负载中，同一 token 可能被路由到同一节点上不同 GPU 的多个专家，但在当前通信实现中，这些重复 token 会被序列化发送多次，造成带宽浪费和通信效率下降。现有优化方案如 DeepEP 虽然引入了跨机去重，但高度依赖特定网络硬件，部署范围有限，且未消除通信前后的数据重排，在通用 MoE 场景中的优化效果仍有限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;FUSCO 设计解析 &amp;nbsp;如何让大规模的分布式数据交换既高效又轻量？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FUSCO 的核心思路在于认识到：&lt;strong&gt;数据重排本质上就是一次数据布局的变换，而通信本身已经定义了数据该如何被拆分、发送和放置。因此，与其在通信前后引入额外的布局调整，不如顺着通信过程本身来完成布局变换。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于这一观察，我们提出了一种数据与通信协同设计的方法，在数据传输的过程中同步完成布局变换，从而避免将数据通信与数据重排变换分离执行的传统做法。每个数据段（LLM 中的 token）在传输的过程中即完成排列和发送，从而既减少了额外拷贝，也最大化利用了 GPU 和网络带宽。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5M6yYfrpPmg3ibCkOichfqvGBxLCTLsaBrAaNlgFXvIJVQkG3SskRwDA/640?wx_fmt=jpeg&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.45" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526338" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/15aab0d3-a81d-4afd-a9ce-32656130f317/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;融合重排的通信：让数据在传输中一步到位完成布局变换&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为实现数据在传输过程中即完成重排，&lt;strong&gt;FUSCO 打破了将重排视为独立步骤的传统思路，从上到下协同设计通信接口和底层算子&lt;/strong&gt;：接口层负责精确表达数据 “从哪里来、到哪里去” 的布局语义，而算子层则负责在一次通信执行路径中高效地落实这些语义。&lt;/p&gt;&lt;p&gt;通过将布局描述与通信执行紧密绑定，&lt;strong&gt;FUSCO 构建了一条从接口到算子的贯通路径，使数据重排不再是独立的前后处理，而是被自然地融合进通信过程本身&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（1）通信接口设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在专家并行中，各个设备上的原始数据通常是一个大的连续张量，由多个 token 组成。经过 MoE 路由后，不同 token 可能被分配到不同的设备，而路由到同一设备的 token 往往在张量中呈离散分布，而非连续的一块。每个 token 的大小通常在 4KB 到 14KB 之间，需要发送到该设备上的不同专家。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;所谓 “数据重排”，本质上是在通信前，将这些离散 token 按目标设备和对应专家进行组织，并在通信完成后将它们正确地放置到各自的目标位置。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了简化讨论，先考虑两个设备之间的一次单向传输。为精确描述这些离散数据的布局，我们将通信数据抽象为一组逻辑段。每个段对应内存中一小段连续数据，FUSCO 用一个称为段描述符的数据结构记录其起始地址。在通信过程中，一端并不直接操作原始张量，而是根据连续的段描述符序列，从张量的对应位置读取或写入数据，从而实现对离散 token 的精确访问和操作。&lt;/p&gt;&lt;p&gt;在发送端，这个描述符序列规定了通信负载如何从源张量中被逐段读取；在接收端，对应的描述符序列则明确了每一段数据在目标内存中的落点。&lt;/p&gt;&lt;p&gt;基于上述段描述符序列的创新设计，FUSCO 以两个互补的通语实现其通信接口：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;gather-send&lt;/strong&gt;：发送端依据本地的段描述符序列，按顺序从多个不连续位置读取段数据并发起发送；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;scatter-recv&lt;/strong&gt;：接收端依据自身的段描述符序列，将接收到的段数据直接写入目标布局中的对应位置。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这两个原语在语义上是一一对应的：每一个逻辑段在发送端和接收端都有明确匹配的描述符，从而保证数据在端到端传输过程中被精确放置，无需任何额外的中间缓冲或后处理重排。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（2） 高效通信算子&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管前面通过描述信息已经可以精确表达 “哪些 token 从哪里来、到哪里去”，但一个更现实的问题随之而来：&lt;strong&gt;在引入细粒度重排语义之后，通信还能否保持原有的吞吐效率？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FUSCO 的答案是：&lt;strong&gt;通过一套流水线化的执行方式，将布局整理与数据传输紧密地绑定在一起。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在机内通信场景下，发送端和接收端位于同一台机器，FUSCO 直接使用 GPU 到 GPU 的点对点拷贝。关键在于，描述信息的解析被嵌入到拷贝路径之中：GPU 在执行数据拷贝的同时，按照描述信息从分散的位置读取数据，并直接写入目标布局对应的位置。整个过程中不会引入额外的中间缓冲或额外的内存遍历。&lt;/p&gt;&lt;p&gt;跨机通信则需要经过网卡，而要充分利用网络带宽，必须持续提供足够大的发送数据。为此，FUSCO 并不会把每个数据段单独进行一次发送，而是将多段数据组织成较大的发送单元，每个发送单元包含多个逻辑段。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LRjWWibhVh2mGC5azyH1E0y6yOLibLiaKJup6PxCKIZFfqlJzUZNwzldxw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=5" data-ratio="0.6611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526330" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f2f48952-ce2a-4f71-b658-2bc566a7790d/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;FUSCO 跨机通信流水线执行路径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在此基础上，FUSCO 将跨机通信组织为一条清晰的流水线执行路径：GPU 作为生产者，按照描述信息依次收集数据、完成布局整理，并将结果写入发送缓冲区；网卡作为消费者，一旦发现缓冲区中有就绪的数据单元，便立即发起 RDMA 传输。&lt;/p&gt;&lt;p&gt;由于单个发送单元的网络传输时间通常长于 GPU 准备该单元所需的时间，GPU 侧的内存操作可以稳定地与网络传输重叠，使通信链路始终保持高利用率。&lt;/p&gt;&lt;p&gt;通过这种设计，&lt;strong&gt;数据重排不再是通信前后的附加步骤，而是被直接嵌入到一次点对点通信的执行过程中完成。在引入灵活重排能力的同时，FUSCO 依然能够维持与高性能通信库相当的带宽效率。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通信调度和策略：跨机优化与负载均衡的 token 传输&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FUSCO 的通信调度优化围绕两种数据重排操作展开：gather-send 和 scatter-recv。&lt;strong&gt;其核心目标是在消除重排的基础上，减少跨机传输量并平衡各设备通信负载。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为此，系统会先生成一份详细的执行计划，将 MoE 的 token 路由信息转化为可直接执行的低层指令。计划中明确了每个 token 的来源、目标 GPU 以及目标节点的位置，使 gather-send 和 scatter-recv 能直接利用这些元数据，无需在通信前、通信中、通信后进行额外的数据重排操作。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LX2yAkQA0I4NTibhcx9BHbQk8MY3HnOT1KGVbjkiaCwhjccjsveaJcGMA/640?wx_fmt=jpeg&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.6787037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526337" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8f38c713-d466-47cc-a5ca-ba0963034e78/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; FUSCO 通信调度策略&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在生成执行计划时，FUSCO 首先考虑了&lt;strong&gt;跨节点通信的效率问题&lt;/strong&gt;。直接将每个 token 发送到目标节点的所有 GPU 会导致重复传输。为解决这一问题，FUSCO 为每个发送 GPU 在每个目标节点指定一个 “转发 GPU”：当某个 GPU 需要向同一节点的多个 GPU 发送相同 token 时，转发 GPU 会先接收发送端的数据，然后通过节点内部高速链路（如 NVLink）将数据分发给该节点的其他 GPU。这样不仅减少了跨节点传输，也充分利用了节点内的高速网络，让数据流动更顺畅。&lt;/p&gt;&lt;p&gt;同时，FUSCO 还考虑了&lt;strong&gt;转发 GPU 的选择&lt;/strong&gt;。如果总是集中在少数 GPU 上，容易形成网络热点。FUSCO 通过将转发 GPU 组织成通信组来解决这一问题，确保高负载 GPU 分散在不同组中，实现跨节点负载均衡。这样每块 GPU 都不会因数据过多而成为瓶颈，整个网络的利用率也更高。&lt;/p&gt;&lt;p&gt;总结来看，FUSCO 的通信调度策略主要通过三方面提升效率：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;精确执行计划&lt;/strong&gt;：每个 token 直接到达目标 GPU 的对应内存位置，无需额外重排。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分层转发&lt;/strong&gt;：跨节点只传输一份，节点内快速分发，减少重复传输。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;在线负载均衡&lt;/strong&gt;：在运行时根据实际 MoE 路由流量动态构建通信组，高负载 GPU 均匀分布。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们基于 NCCL 实现了 FUSCO，在保持与 NCCL 相同网络兼容性的同时，复用了其高效通信能力，让 FUSCO 可以专注于算法优化。FUSCO 为 MoE 层提供了简单直观的 dispatch/combine 接口，可无缝接入现有 LLM 训练和推理框架。&lt;/p&gt;&lt;p&gt;不同于 DeepEP 仅能在特定网络环境（ibgda, NVLink, RDMA）下工作，FUSCO 能在多种网络环境下高效运行，无需针对网络做额外调优。&lt;/p&gt;&lt;p&gt;简而言之，FUSCO 可以作为 MoE 框架中 AlltoAll 通信的高效解决方案，同时兼顾性能与易用性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果与分析 &amp;nbsp; FUSCO 的性能与优势&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通信性能：完全消除 MoE 模型通信数据重排开销，效率 2 倍优于 DeepEP&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在应用上，与现有的通信库相比，FUSCO 的最大特点在于&lt;strong&gt;完全消除了 MoE 模型通信中的数据重排开销，并在此基础上实现跨节点 token 去重和节点内高速分发，从而显著提升通信效率。系统适配主流 MoE 训练和推理框架和 GPU 架构，在各种典型的 MoE 路由流量场景都能够稳定降低延迟和提升吞吐。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在量化评测中，我们构造了三种具有代表性的 MoE 通信流量配置进行测试：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;第一种是真实推理流量，直接采用大模型推理过程中实际产生的 MoE 路由结果，能够反映真实场景下的通信特征；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第二种是单节点路由流量，即一个 token 被路由到的 topk 个 expert 都在同一节点上，此时跨节点只需要传输一份数据，主要考察系统对冗余跨节点通信的消除能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第三种是负载不均衡流量，不同 GPU 间通信量差异显著，用于模拟热点 GPU 和通信倾斜严重的极端情况，重点评估系统的负载均衡能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这三种配置均使用 64 张 GPU 进行性能测试，分别测试每卡文本长度 4K/8K/16K/32K 的情况，总文本长度最大可达 2048K。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LHDL9h4HEkOibRz0Zznfuib1LXh7ZEUyxugbmNWIu7OYB72YVNUNy5R3Q/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=7" data-ratio="0.5502846299810247" data-s="300,640" data-type="png" data-w="1054" type="block" data-imgfileid="503526333" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/a4a9b036-830c-4b59-9927-2a4d41ed0ba4/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 真实通信数据重排负载下的性能对比（64 GPUs，文本长度可达 32K*64，下同）&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L45gw4uDEaEKGDCFy34wia2tXk6VUTJficejAZOxTvFpDyO5RZjuJlMOA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=8" data-ratio="0.5137614678899083" data-s="300,640" data-type="png" data-w="872" type="block" data-imgfileid="503526332" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/4f783d42-6592-49de-a5c1-2b83083652fa/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 每个 token 仅会被路由到一个设备上的多个 expert 下的性能对比&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LrTLvqY7NHyNpEr1sRDicCsVJqVEGvr1xIyORb0Fnjp1he05sEyiaeMRA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=9" data-ratio="0.5" data-s="300,640" data-type="png" data-w="872" type="block" data-imgfileid="503526334" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c7eb2799-ff58-47c5-9696-93fd84f8d891/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 设备之间负载不均衡情况下的性能对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实验结果表明，在上述三种典型流量配置下，&lt;strong&gt;FUSCO 相比 NCCL 和 DeepEP 均能取得更高的通信效率。相较于 NCCL 和 DeepSeek 的 DeepEP 通信库，FUSCO 的通信性能最高可分别提升 3.84 倍和 2.01 倍，而且文本长度越长加速越明显。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;无论是在真实推理环境、跨节点通信最小化的场景，还是存在严重负载不均衡的情况下，&lt;strong&gt;FUSCO 都能稳定降低通信开销，为 MoE 模型的训练与推理提供更加高效、可靠的通信支持。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端到端性能：训练与推理效率全面提升，最高 1.39 倍优化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在全模型训练和推理中，FUSCO 同样展现出明显优势。我们在 64 张 GPU 上对 Qwen3-235B-A22B 和 DeepSeek-V3 两种代表性 MoE 模型进行了评测，涵盖模型单轮训练时间和推理首 token 响应时间。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LicxVC041yGS9PKTF6YPFcLfZRGvrKxFcoCxdQ3cOnlItLOO0gtYwibxw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=10" data-ratio="0.5518518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526335" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9d44b97b-7dca-4b74-9ecb-1dcfdf11da31/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; FUSCO 带来的端到端训练与推理的性能提升&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;结果显示，在训练任务中，FUSCO 相较于 NCCL 性能最高提升 1.39 倍，相较于 DeepEP 性能最高提升 1.19 倍 ；在推理任务中，FUSCO 相较于 NCCL 性能最高提升 1.25 倍，相较于 DeepEP 性能最高提升 1.16 倍。且在实际部署中，模型规模越大，性能提升越显著。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FUSCO 通过将 MoE 模型的 token 路由信息直接转化为可执行的 gather-send 与 scatter-recv 通信原语策略&lt;strong&gt;，彻底消除了传统通信前后的数据重排开销&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在多节点 64 GPU 测试中，相较于 NCCL 和 DeepEP，FUSCO 的通信性能分别提升了 3.84 倍和 2.01 倍，同时端到端性能增幅最高达 40%。&lt;/p&gt;&lt;p&gt;无问芯穹这一创新方案不仅&lt;strong&gt;为大规模 MoE 模型提供了可扩展、低成本的通信支持，为大规模 MoE 模型的通信优化提供了可验证的创新示范&lt;/strong&gt;。更有力推动了面向 Agent 的硬件效率潜能的释放，加速智能体的规模化高效落地。&lt;/p&gt;&lt;p&gt;相关代码和使用示例现已开源，欢迎在实际项目中下载测试与应用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;开源地址：https://github.com/infinigence/FUSCO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://www.arxiv.org/abs/2512.22036&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>「视频世界模型」新突破：AI连续生成5分钟，画面也不崩</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 17:48:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-9</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/b2395540-7872-4a01-8c0f-9c42e8cddeae/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当 Sora 让世界看到了 AI 生成视频的惊艳效果，一个更深层的问题浮出水面：如何让生成的视频不只是「看起来像」，而是真正理解并遵循物理世界的规律？这正是「视频世界模型」（Video World Model）要解决的核心挑战。当生成时长从几秒扩展到几分钟，模型不仅要画面逼真，更要在长时间尺度上保持结构、行为与物理规律的一致性。然而，误差累积与语义漂移往往导致长视频出现画面退化与逻辑崩坏 &amp;mdash;&amp;mdash; 这已成为衡量世界模型能力的关键瓶颈。&lt;/p&gt;&lt;p&gt;围绕这一挑战，上海人工智能实验室联合复旦大学、南京大学、南洋理工大学 S-Lab 等单位提出了&lt;strong&gt;&amp;nbsp;LongVie 2&lt;/strong&gt;&amp;mdash;&amp;mdash; 一个能够生成长达 &lt;strong&gt;5 分钟高保真、可控视频的世界模型框架&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrlRbtCU8udhlgPCzzUqpPj0KYbicFRZGIgVyDdvOLEy5ia4fu5ISFvXJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525990" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ec107e81-cdd0-472a-8bf2-f74ea3442fa9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; LongVie 2 可自回归生成 3-5 分钟的超长可控视频&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="2 2 []"&gt;论文：https://arxiv.org/pdf/2512.13604&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://vchitect.github.io/LongVie2-project/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub：https://github.com/Vchitect/LongVie&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;视频演示：https://www.youtube.com/watch?v=ln1kMNYj50Y&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/oMWv6P6mm21XMk9bpZtKXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26bb2f16-70f3-492a-9a5e-e504780e4f52/1767174301445.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;strong&gt;什么是理想的视频世界模型？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个理想的视频世界模型，不应只是「生成得更久」，而应同时具备以下三项核心能力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;全面可控性（Comprehensive Controllability）：能够在长时间生成过程中稳定响应多种控制信号，保持场景结构与运动意图不漂移；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;长期视觉保真（Long-term Fidelity）：随着时间推进，画面质量不发生明显退化，不出现纹理崩塌或细节丢失；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;长程上下文一致性（Long-context Consistency）：跨片段、跨时间保持语义、身份与物理规律的一致，避免「换世界式」断裂。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;现有世界模型的瓶颈在哪里？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文系统调研了当前主流的视频世界模型，发现一个共同问题：随着生成时长的增加，模型的可控性、视觉保真度与时间一致性会同步下降。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrKYa72CzzbvIcoXw4ImLlft3opNGgDXhNaxwP0IqBOIVgt7n8F6ibE2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.2824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525992" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/43cfe190-bf6c-4ff9-b0dd-90390be02ef3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 现有模型在长时间生成时的退化问题&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LongVie 2：三阶段递进式训练&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为系统性解决上述挑战，LongVie 2 设计了一套逐层递进的三阶段训练策略，从控制、稳定性到时间一致性层层强化：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrEibYQ0VibHwSj2s8E9kFT3tyaQjxmic0WvGEq7kRicAgmfOQYw8jnVAflA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.20462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525996" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ae91c531-35eb-47e4-a417-982737e18278/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; LongVie 2 三阶段训练流程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段一：Dense &amp;amp; Sparse 多模态控制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过引入稠密信号（如深度图）与稀疏信号（如关键点轨迹），为模型提供稳定且可解释的世界约束。这使生成过程不再完全依赖隐式记忆，从源头提升长程可控性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段二：退化感知训练（Degradation-aware Training）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;长视频生成中，质量衰减几乎不可避免。LongVie 2 的核心创新在于：在训练阶段主动「制造困难」&amp;mdash;&amp;mdash;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr87gjI76SaVtjosaZjpUMhXibDiaDvYICvoQEa4toUazY4VWrOIaqys0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.42314814814814816" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525999" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/ef79ec55-997c-4a4d-9360-e6e1423ad636/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 退化感知训练示意图&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;利用 VAE 的多次 encode-decode 模拟重建误差；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;通过 加噪 + Diffusion 去噪 构造退化图像。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以此作为训练信号，使模型学会在不完美输入下保持稳定生成，显著增强长期视觉保真度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段三：历史上下文建模&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在生成过程中显式引入历史片段信息，并通过针对性 loss 约束相邻片段的衔接，使跨片段过渡更加自然顺畅，有效缓解长视频中的语义断裂与逻辑跳变问题。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrys4yLGuRsWIYPUdEEr1MOKGIibE0Yf4RHf4WHBFaltlFsH50muNq0VQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.31851851851851853" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526003" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/464d0593-861b-4e94-bdff-49221d7d8864/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 三阶段训练效果对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一图看懂 LongVie 2 框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过多模态控制、退化感知训练与历史上下文建模的协同设计，LongVie 2 将长视频生成从「片段拼接」提升为持续演化的世界建模过程：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrdgKTDN4syCdCTZbbKnplv6U1thn84yseZyRoXfvuD8zK2BeOuAMAEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526006" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/20186ee2-83b0-4589-a136-479d08970f16/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; LongVie 2 整体框架&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从左至右，LongVie 2 首先将跨片段的稠密（深度）与稀疏（关键点）控制视频做全局归一化，并为所有片段采用统一的噪声初始化。随后在每一片段生成时，将全局归一化后的控制信号、上一片段的末帧与文本提示送入模型，逐步生成完整的长视频。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LongVie 2 能力展示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该研究将&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;LongVie 2&lt;/span&gt;与 Go-With-The-Flow 和 Diffusion As Shader 进行了对比。结果显示，LongVie 2 在可控性方面表现显著优于现有方法：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvryd0bCnLSkzkaaCgyzxzKonb9a2B3oJdLG0cf85ooIGRyzSazCQVgow/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.33055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526007" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/77e6838e-3663-4f0f-805a-35ec84d0a1a5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 与现有方法的可控性对比&lt;/sup&gt;&lt;a href="https://mp.weixin.qq.com/s/oMWv6P6mm21XMk9bpZtKXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/98e05880-2b4b-461b-86e9-f6cb067b414f/1767174384227.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/oMWv6P6mm21XMk9bpZtKXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dd08b91d-ff10-405a-add9-a7648175e6ce/1767174400600.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;消融实验也充分验证了三阶段训练的有效性：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrJF6gYQswzziagrXlQcXCJwZLt249VrGJANnic2by0t2o71y4Le4uWQZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.22777777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526020" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d4853a60-ae19-49f6-b35e-4d8bf45162ce/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 消融实验结果&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;LongVGenBench&amp;nbsp; 首个可控超长视频评测基准&lt;/p&gt;&lt;p&gt;当前缺乏面向可控长视频生成的标准化评测。为此，本文提出 &lt;strong&gt;LongVGenBench&lt;/strong&gt;&amp;mdash;&amp;mdash; 首个专为超长视频生成设计的基准数据集，包含 &lt;strong&gt;100 个时长超过 1 分钟&lt;/strong&gt;的高分辨率视频，覆盖真实世界与合成环境的多样场景，旨在推动该方向的系统研究与公平评测。&lt;/p&gt;&lt;p&gt;定量评估与用户主观测评结果显示，LongVie 2 在多项指标上达到 &lt;strong&gt;SOTA 水平&lt;/strong&gt;，并获得最高用户偏好度：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrvRjk8Uoldia3iaZWewjNnWcTm3ZnQ5LyQiaah4k6q2bnEFOzcpRO4YkMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.35648148148148145" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526018" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ca54fca3-c428-4543-a40d-c2c4b3e618e2/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrHm8SCCEWolUQJ4Er2ZEbuaWssq0cHIyRFZEDceicjqc5dItNVTlSfVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.46835443037974683" data-s="300,640" data-type="png" data-w="948" type="block" data-imgfileid="503526019" data-aistatus="1" data-original-style="width:472px;height:221px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/3cf8e219-f29f-425e-921f-5d708e10c2c4/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 定量评测结果与用户研究&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，稚晖君发布的人形机器人Q1，小到能塞进书包</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 16:39:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-8</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/792d8dab-7b17-4a86-a434-9bfe2eb54f7a/1767170079344.png" style="width: 700%;" class="fr-fic fr-dib"&gt;这就是 2025 科技界最后一个重磅产品？&lt;/p&gt;&lt;p&gt;12 月 31 日下午，稚晖君（彭志辉）的机器人公司智元机器人正式发布了&lt;strong&gt;全球首款、全身力控的小尺寸人形机器人 Q1&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L4qSPzEqy30NTU4ziaK95hnNJr19EyL9rFEYDhJkicQUeJca6ibn8BcS0A/640?wx_fmt=gif&amp;amp;from=appmsg#imgIndex=1" data-ratio="0.752" data-type="gif" data-w="500" data-width="500" data-height="376" data-backw="500" data-backh="376" data-imgfileid="503526413" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f18616c1-0ffd-4cbe-b935-47c372236dbf/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;17 年前，乔布斯把笔记本电脑塞进了信封；17 年后，稚晖君把完整的人形机器人塞进了书包。&lt;/p&gt;&lt;p&gt;Q1 的出现，似乎预示着稚晖君「极客精神」的回归：它试图将全尺寸机器人的动力性能与智能化压缩至背包大小，从而定义未来个人机器人的基本范式。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lv1R5pheOvTejszCk5FiaOwzB5ePLBMcPQgbkjGR72ibHSjibZC47icmlEg/640?wx_fmt=gif&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.5634847080630213" data-type="gif" data-w="1079" type="block" data-backw="562" data-backh="317" data-imgfileid="503526396" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/39f5c449-7946-4694-bd47-c051a4ab95b2/640.gif" data-order="1" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;它并不是为了小体积而缩小 ——Q1 的设计初衷，是为了在保持全尺寸人形机器人能力的条件下，极大降低科研成本与物理交互的门槛。用稚晖君的话说：「当机器人变小，世界的物理法则也变得温柔。」&lt;/p&gt;&lt;p&gt;换句话说，正常尺寸机器人能做的它都能做，还能做得更好。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lc8E9Z3vXHicFWbhOTsYpyVkhj81sb7p6S7icBJNItzNLjF0dsENv51Pg/640?wx_fmt=gif&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.58" data-type="gif" data-w="500" data-width="500" data-height="290" data-backw="500" data-backh="290" data-imgfileid="503526415" data-aistatus="1" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/57239511-f39a-4ab3-9875-6e3d21b027a9/640.gif" data-order="2" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Q1 面向高校、创业公司的科研团队，开发工具包和接口完全开放；同时又面向硬核潮玩市场，极客们可以利用 3D 打印技术为其打造专属的皮肤和装甲，不论是猫娘还是蒸汽朋克，颜值完全由用户决定。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Ly5WSQPX4jFChFUKibdTCuCwZt3AaZA6oehmX6icdcN7BtzXsbqQhtUvg/640?wx_fmt=gif&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.8733333333333333" data-type="gif" data-w="450" type="block" data-backw="450" data-backh="393" data-imgfileid="503526414" data-aistatus="1" data-original-style="width:100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/07eb4821-e69e-415a-bbc4-564bb209ad73/640.gif" data-order="3" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;稚晖君也表示，机器人也可以与机器人合作，就像 AI 大模型的智能体一样。（机器狗：你礼貌吗）&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LYejSeRcCxf3vGAyXtTeS3AicMCTmKZaUgzT6ocLaMBjjKn11dLw3Y3A/640?wx_fmt=gif&amp;amp;from=appmsg#imgIndex=5" data-ratio="0.77" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="385" data-imgfileid="503526424" data-aistatus="1" data-original-style="width:100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/0bc2dce0-b0b0-4ef5-a02c-d09f434d86a7/640.gif" data-order="4" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;Q1采用了模块化的硬件设计，支持头部等位置的整体更换，配合零门槛的动作编排。它就像一个等待提示词的AI，你可以让它在物理世界完成很多任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;极致微型化与动力学的革命&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人形机器人在今年属实是大放异彩。&lt;/p&gt;&lt;p&gt;从春晚舞台上机器人扭秧歌的趣味亮相，到王力宏演唱会上它们与人类伴舞并完成高难度动作、甚至引来马斯克点赞，再到社交平台上各种关于机器人乌龙笑话的刷屏……&lt;/p&gt;&lt;p&gt;但这些机器人都是全尺寸的「等身」大小。&lt;/p&gt;&lt;p&gt;为什么做小这么难？&lt;/p&gt;&lt;p&gt;小尺寸人形机器人Q1有个关键词&lt;strong&gt;：&lt;/strong&gt;全身力控。&lt;/p&gt;&lt;p&gt;机器人领域中的&lt;strong&gt;全身力控（Whole-Body Control, WBC）&lt;/strong&gt;是一种高级控制技术，用于协调机器人全身多个自由度（如关节、腿、臂等）在与环境接触时的力与运动，同时综合考虑平衡、姿态、任务优先级等因素。相比传统只控制末端执行器运动或位置，全身力控让机器人不仅实现「去哪儿」，还要精确「怎么用力」去完成任务。&lt;/p&gt;&lt;p&gt;为了实现精准的全身力控，在主流的人形机器人设计中，普遍采用QDD关节来打造机器人本体，是高性能机器人的核心组件。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LLAx7uSQC8qGs2RqZfEdrIPVxiao0DOcotMYMggGwC8ZjEicOib2X5OqNg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.4842592592592593" data-type="png" data-w="1080" data-width="3506" data-height="1698" data-backw="562" data-backh="272" data-imgfileid="503526412" data-aistatus="1" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e79439b0-8437-4867-b04d-8f6c01454437/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;QDD（准直驱）&lt;/strong&gt;是一种介于传统高减速比伺服驱动与「真正直驱」之间的执行器设计：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用低减速比的减速结构连接电机和输出轴；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;结合高扭矩密度电机和低传动比，保留电机侧低惯性、良好背驱性，有利于高带宽力控和动力反馈；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;相比传统方案（如高比减速+伺服电机），QDD 在力量感知、外力互动、动态响应方面有明显优势。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;1、高扭矩密度电机难以缩小体积&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;QDD 的核心是强力矩但低传动比的电机，这要求在有限的体积下产生高扭矩，同时保持低反射惯量。&lt;/p&gt;&lt;p&gt;但电机本身的扭矩密度受电磁材料、磁路尺寸、绕组填充率等物理极限制约。在缩小尺寸时，线圈填铜率下降、散热变困难、磁通密度不足都会导致输出扭矩显著下降。&lt;/p&gt;&lt;p&gt;2、&lt;strong&gt;热管理难题更突出&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;高扭矩密度意味着大电流密度，而小体积里散热条件非常受限。在 QDD 里没有传统高减速比「缓冲&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;，电机必须自己承担大部分工作，这对热管理提出了非常高的要求。&lt;/p&gt;&lt;p&gt;3、&lt;strong&gt;制造和材料工艺挑战更高&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;小尺寸制造对工艺要求极高：磁体、绕组、轴承都要极高精度；编码器、高性能驱动电子器件要集成在狭小空间。&lt;/p&gt;&lt;p&gt;这种高集成度本身就是技术门槛极高的交叉学科工程。&lt;/p&gt;&lt;p&gt;正如电子产品的发展规律所揭示的那样——&lt;strong&gt;尺寸越小，水平越高&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;智元机器人 Q1 在全身力控人形机器人领域创造了新的&lt;strong&gt;「迷你皇冠」&lt;/strong&gt;，将原本结构复杂、制造门槛极高的 QDD 关节压缩至鸡蛋大小的体量，不仅刷新了工程极限，也集中展现了其卓越的技术创新能力与扎实的工业实力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;属于你的个人机器人来了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在国内具身智能领域，智元机器人作为明星公司一直处于聚光灯下。该公司成立于 2023 年 2 月，在不到三年的时间里估值已飙升至 150 亿元人民币。&lt;/p&gt;&lt;p&gt;今年 7 月，智元机器人相关主体宣布完成了对 A 股科创板上市公司上纬新材的控股，原主营新材料业务的上市公司开始转向具身智能机器人布局。今年11月，智元团队成员（包括稚晖君）已进入董事会，并推动业务转型与机器人板块落地。&lt;/p&gt;&lt;p&gt;与资本运作同样快速的是智元机器人的技术发展与落地。目前智元已完成机器人本体、三大智能技术的快速迭代，灵创、灵心、精灵平台及灵渠OS等技术生态也逐渐完善。智元机器人已经构建了核心零部件、传感器等供应链。&lt;/p&gt;&lt;p&gt;智元机器人的产品远征、灵犀、精灵三大系列，分别面向工业、服务与消费端，构建了全场景覆盖的格局。在今年 12 月初，该公司已经达到了5000 台机器人量产下线的里程碑。&lt;/p&gt;&lt;p&gt;如今 Q1 的问世，势必会让人形机器人成为更多普通用户的伙伴。&lt;/p&gt;&lt;p&gt;未来的 AI 交互终端真的是个大屏设备吗？或许，正确的答案是一个「跟你长得很像」的机器人。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>7B扩散语言模型单样例1000+ tokens/s！上交大联合华为推出LoPA</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 16:31:48 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-7</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ec55e9db-9e8b-41d7-b248-bcbf30d2d013/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;a href="https://mp.weixin.qq.com/s/9PrF80XDWTxF8aj7jcWQjQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8d643edd-4608-4d4f-a66d-5e23163a9783/1767169769443.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;视频 1：单样例推理速度对比：SGLang 部署的 Qwen3-8B (NVIDIA) vs. LoPA-Dist 部署 (NVIDIA &amp;amp; Ascend)（注：NVIDIA 平台相同，配置对齐）&lt;/sup&gt;&lt;/section&gt;&lt;p&gt;在大语言模型（LLMs）领域，扩散大语言模型（dLLMs）因其并行预测特性，理论上具备超越传统自回归（AR）模型的推理速度潜力。然而在实践中，受限于现有的解码策略，dLLMs 的单步生成往往局限于 1-3 个 Token，难以真正释放其并行潜力。&lt;/p&gt;&lt;p&gt;近期，&lt;strong&gt;上海交通大学 DENG Lab 联合华为的一项新研究&lt;/strong&gt;打破了这一瓶颈。该工作提出了一种名为 &lt;strong&gt;LoPA （Lookahead Parallel Decoding） 的无需训练的解码算法&lt;/strong&gt;，通过主动探索最优填词顺序，显著提升了 dLLMs 的推理并行度和吞吐量。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;本文作者团队来自上海交通大学 DENG Lab 与华为。该研究由徐晨开、金义杰同学等人共同完成，指导教师为邓志杰老师。DENG Lab 隶属上海交通大学，致力于高效、跨模态生成模型的研究。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503525993" data-ratio="0.23796296296296296" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrmCIDZcbftwiaiasvc5pOHa2rlg8dqYWIWSfEasH95NHUfAq9pia9YLPfQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/581a3570-86a2-49b9-a273-8b58f716889a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="2 2 []"&gt;论文地址：https://arxiv.org/abs/2512.16229&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/zhijie-group/LoPA&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;博客地址：https://zhijie-group.github.io/blogs/lopa&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验显示，LoPA 将 D2F-Dream 在 GSM8K 基准上的单步生成 Token 数（TPF）从 3.1 提升至 10.1，并行度提升超 3 倍。配合团队自研的 LoPA-Dist 分布式推理系统，在华为 Ascend 910C 平台上实现了 1073.9 tokens/s 的单样本吞吐量，不仅大幅超越基线模型，更将 dLLMs 的推理效率推向了新高度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr40mkVZlMSHBImjrqBgb0HsABY9dJhrb5kUFRjDkg4bBkFwgevAibGwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3787037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525995" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d44d52ee-12e3-4ae3-8e2e-f994d1582aaa/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1：LoPA 的吞吐量结果展示。LoPA 将 D2F-Dream 的单样本吞吐量在 MBPP 和 GSM8K 上分别提升至高达 1073.9 和 856.5 个 token/s，显著优于基线方法。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;简单来说，LoPA 为 dLLMs 赋予了以下核心特性：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 极高的并行度&lt;/strong&gt;：首次将 dLLMs 的每步生成数量（TPF）提升至 10 Token 量级，突破了传统方法的效率瓶颈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 无需训练&lt;/strong&gt;：作为一种即插即用的解码算法，无需对模型进行重训或微调。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 前瞻并行解码&lt;/strong&gt;：通过引入分支并行机制，主动探索不同的填词顺序（TFO），避免模型陷入低置信度的局部最优。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. 系统级加速&lt;/strong&gt;：配套设计的 LoPA-Dist 系统，支持 CUDA 和 Ascend 双平台，通过分支并行最大化硬件利用率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrAVTa0Av4JokQ6bkQWjtDOW3Y2WuG2Qw6HPh0Vg0NNXLCXOyrGefTvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3101851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525997" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/e5dc36aa-3c77-4e93-95a4-0f6d1ec6aff5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;sup&gt;图 2：对不同分支数的 D2F-Dream 进行 LoPA 扩展性分析。结果表明，LoPA 能有效扩展 D2F 的 TPF，使其峰值超过 10，从而显著减少解码总步骤数。&amp;nbsp;&lt;/sup&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;问题的根源：填词顺序限制并行潜力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;dLLMs 理论上支持全序列并行生成，但在实际应用中，现有的主流模型（如 Fast-dLLM, D2F, SDAR）普遍采用置信度驱动采样（Confidence-Driven Sampling）。这种策略倾向于贪婪地优先填充当前置信度最高的位置。&lt;/p&gt;&lt;p&gt;研究团队发现，并行度的高低与填词顺序（Token Filling Order, TFO）高度相关。贪婪策略虽然在当前步骤保证了准确性，但并不考虑后续步骤的预测置信度，导致模型在后续迭代中并没有充分释放并行度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrOlCXrE4oWvNSUMa2ohllta6fjOEQVOTbWz07nLSfjRHIul59rJ1faQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525998" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b2afb370-6502-43ec-a3fe-74c55c4c976c/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：LoPA 算法流程概览。在每次迭代中，LoPA 通过独立采样高置信度位置，生成一个锚定分支以及多个前瞻分支。然后，分支置信度验证机制并行评估所有分支，以选择最优路径。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LoPA 的核心设计：前瞻并行与分支验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决上述问题，LoPA 引入了前瞻并行解码机制。其核心思想是：利用少量的额外计算开销，同时探索多种填词顺序，从而找到一条能让未来预测 &amp;ldquo;更自信&amp;rdquo; 的路径。&lt;/p&gt;&lt;p&gt;LoPA 的工作流程包含三个关键阶段：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 多分支并行探索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LoPA 在保留标准锚点分支（Anchor Branch，即常规贪婪策略）的同时，额外对当前的最高置信度的 k 个位置分别采样得到 k 个前瞻分支（Lookahead Branches）。每个分支代表一种不同的填词顺序尝试。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 分支置信度验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;团队设计了分支置信度（Branch Confidence）指标，用于量化分支中剩余未填位置的平均预测置信度。较高的分支置信度意味着该路径在下一轮迭代中能填充更多的 Token，具备更高的并行潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 并行验证与复用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过隔离不同分支的注意力设计，所有候选分支（锚点 + 前瞻）可以在一次前向传递中并行完成验证。系统最终选择未来潜力最大的分支作为本次迭代结果。验证过程中计算的 Logits 被直接复用于下一步生成，无需额外前向传播。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526000" data-ratio="0.6018518518518519" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrsicUUFoiaNv6tjWJbTL9MJOqREBLXq64ownxGVSoBAoRRuX5n9zJRicZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/fbf85e22-09d3-4b27-b0f2-7a5073221868/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4：LoPA 分支并行分布式推理系统设计展示。关键区别在于针对不同后端定制的键值缓存管理协议：LoPA-Dist-NV 采用稳健的两阶段更新机制以确保一致性，而 LoPA-Dist-Ascend 则采用精简的单阶段更新策略以优化服务效率。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;系统级创新：LoPA-Dist 分布式推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了承载 LoPA 的多分支计算，团队设计了 LoPA-Dist 分布式推理系统，引入了全新的分支并行（Branch Parallelism, BP）策略，可与张量并行（Tensor Parallelism，TP）等现有并行机制混合使用。&lt;/p&gt;&lt;p&gt;该系统针对不同硬件平台进行了定制优化：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. LoPA-Dist-NV（CUDA）&lt;/strong&gt;：面向低延迟场景。采用静态 KV Cache 和独创两阶段更新协议（Pre-Write &amp;amp; Commit-Winner-Cache），确保分支切换时的缓存一致性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. LoPA-Dist-Ascend（Ascend 910C）&lt;/strong&gt;：面向高吞吐服务场景。采用混合并行策略（TP+BP），结合图编译技术融合算子，异步调度，以及量化机制，大幅降低 Kernel 启动开销。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrBOnCKoqzdiaOWLcMWku94icCuQgQOiamYek68GM0CVKFsQkqfY7LUCwYg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526001" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/2c172334-72b4-484c-a917-17c4aa2e7765/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5：LoPA 的并行度扩展曲线。在 GSM8K 和 HumanEval+ 上，LoPA 分别将 D2F-Dream 和 D2F-DiffuCoder 的 TPF 分别扩展至高达 10.1 和 8.3，并保持和基线相当的性能。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：速度与质量的双重提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;并行度：单步突破 10 Token&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LoPA 在 SOTA 扩散语言模型 D2F 上进行了实验。实验结果表明，随着前瞻分支数量的增加，模型的 TPF 呈现显著上升趋势。在 GSM8K 任务上，LoPA 将 D2F-Dream 的 TPF 推高至 10.1，大幅缩短了总推理步数。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrpsaicH7e317ShaFC3ZgNnXwu3rgntSJBdV5VGlOEs5fXjvSTGiaA9aPw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.25277777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526002" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b7843eb4-40f4-48bf-abf2-4e908fc194b1/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 1：LoPA 集成 D2F-Dream 的性能。LoPA 集成的 D2F-Dream 在多个基准测试中实现了保持精度的 TPF 提升。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrlz2ognLMLN0TK7BEV9n7JgrlibN6557NKx1eC93q0l0ekhVkH5lzibrw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2919847328244275" data-s="300,640" data-type="png" data-w="1048" type="block" data-imgfileid="503526004" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/0d187380-47ee-461d-90c7-3ce04790c11e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 2：LoPA 集成 D2F-Diffucoder 的性能。LoPA 集成的 D2F-DiffuCoder 在代码任务中实现了保持精度的 TPF 提升。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;系统吞吐量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在系统层面，LoPA-Dist 展现了优异的扩展能力。在华为 Ascend 910C 平台上，系统实现了 1073.86 tokens/s 的峰值吞吐量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrw8CG2V57w9a1PriaEHoGssiadefeg6vWkgtLffsCtWLxlSRKWRFbXByw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.18703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526005" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/803b5af7-b684-4225-a4a4-20a47669414c/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 3：LoPA 系统性能。结果表明，我们的系统能够有效地将算法并行性（高 TPF）转化为显著的实际运行时间加速，在专用的 LoPA-Dist-Ascend 引擎上实现了超过 1000 token/s 的平均吞吐量。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LoPA 通过算法与系统的协同设计，成功突破了 dLLM 推理的并行度瓶颈，证明了非自回归模型在保持高性能的同时，能够实现远超传统模型的推理速度。团队表示，未来将进一步探索 LoPA 在 SDAR 等更多 dLLM 架构上的应用，推动高效生成模型的落地。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>卓驭打造科技平权，端到端辅助驾驶延伸至重卡高速、无人物流</title>
      <description>&lt;![CDATA[卓驭科技在步入第十年之际，由公司CEO沈劭劼进行了一场题为《行者》的演讲。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Wed, 31 Dec 2025 16:18:42 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-6</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;12 月 30 日，卓驭品牌盛典 2025 在深圳举行。&lt;/p&gt;&lt;p&gt;不同于常规的技术参数发布会，本次卓驭科技的发布更侧重技术路线阐释、工程哲学与未来布局。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/451dfb1d-22e4-4bcf-8346-e497dd023433/QQ20251231-161006.jpg" style="width: 67.52%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;作为从大疆独立仅一年多的智能驾驶公司，卓驭首次系统对外解读了其从规则驱动到数据驱动的技术转型、软硬一体的工程能力，以及从乘用车向商用车等多场景延伸的战略路径。&lt;/p&gt;&lt;p&gt;卓驭科技 CEO 沈劭劼在演讲中系统回顾了卓驭团队自 2016 年创立至今、从大疆车载迈向独立主体的发展历程，介绍了多模态端到端世界模型体系，并宣告了其 &amp;ldquo;数据驱动的空间智能移动基座&amp;rdquo; 正式成型。&lt;/p&gt;&lt;p&gt;卓驭的技术根基源自大疆的机器人工程基因，早期沿用规则驱动方案。但随着智能驾驶场景复杂度提升，基于规则的辅助驾驶系统陷入了 &amp;ldquo;解决一个问题，冒出十个新问题&amp;rdquo; 的工程困境。&lt;/p&gt;&lt;p&gt;2024 年 10 月 14 日，卓驭做出关键决策：全删原有代码库，全面转向端到端架构。在转型初期，团队面临模型不成熟、交付压力大、输出不稳定等多重挑战，但最终探索出一条差异化的技术路径。&lt;/p&gt;&lt;p&gt;借鉴 &amp;ldquo;巧力出奇迹&amp;rdquo; 的总体思路，卓驭不盲目堆算力与参数量，而是将视觉 - 语言 - 动作（VLA）模型拆解为多个可解释、可分工的模块。他们以较低成本攻克了行业公认的 &amp;ldquo;因果推理&amp;rdquo; 与 &amp;ldquo;低频数据生成&amp;rdquo; 两大难题，实现了端到端系统在中等算力平台上的可用性与可部署性。&lt;/p&gt;&lt;p&gt;卓驭提供高质量、低价格的辅助驾驶解决方案，通过极致优化，能够让 10 万元级车型也能具备城市领航辅助驾驶能力：其在地平线征程 8650 芯片上实现性能媲美 Orin X，通过网络压缩与优化，将端到端网络成功部署在 TI TDA4 等中算力平台，实现了 &amp;ldquo;中算力城市 NOA&amp;rdquo;。&lt;/p&gt;&lt;p&gt;与此同时，卓驭推出高通 8775 舱驾一体方案，以单芯片同时驱动智能座舱与智能驾驶系统，推动了整车架构向中央计算的方向演进。&lt;/p&gt;&lt;p&gt;历时九年，卓驭的辅助驾驶系统已历经千万公里真实道路的考验，卓驭也已经从行业新生力量成长为业界领军企业，乘用车领域覆盖 9 大客户 15 大品牌，量产覆盖 50 多个车型和所有动力构型，此外还有 30 + 款即将量产车型。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/73703826-6a81-4e1d-ac18-a52da2ee00ac/QQ20251231-160528.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;卓驭着重建设 &amp;ldquo;全场景兜底能力&amp;rdquo;，希望通过持续建设全流程产业链能力、完善的软硬件能力，以及对客户 &amp;ldquo;产品交付&amp;rdquo;、对用户 &amp;ldquo;不放弃每一位&amp;rdquo; 的兜底能力。&lt;/p&gt;&lt;p&gt;基于这一判断，卓驭选择在统一架构上向上延展，而非重新搭建高算力方案。从 TDA4（中算力）到 8650 及更高算力平台，再到 8775（舱驾一体），其核心架构保持一致且可规模化复用。&lt;/p&gt;&lt;p&gt;目前，卓驭已推出两大高算力方案：一是 L3/L4 方案，搭载两块 Thor 芯片，配合自研激目前向感知系统和知周补盲雷达；二是舱驾一体方案，采用高通 SA8797，将 VLA 融入统一架构。基于对算力的极致运用，卓驭的工程实力获得英伟达、德州仪器等芯片厂商认可 &amp;mdash;&amp;mdash;&amp;ldquo;同样的芯片，在我们手里能跑出更高的效率&amp;rdquo;。&amp;quot;&lt;/p&gt;&lt;p&gt;面向未来，卓驭希望构建空间智能的移动基座，引领自主移动机器人时代，其技术能力将不再局限于乘用车辅助驾驶，而是依托数据驱动的开发范式、成熟的基座模型及软硬一体的工程能力，将移动智能的边界拓展至商用车等更广泛的业务场景。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2e0a68be-8bec-42f3-8929-5ed313113a8d/QQ20251231-160615.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;卓驭宣布，在 2026 年上半年会上线重卡 NOA 辅助驾驶。&lt;/p&gt;&lt;p&gt;目前，卓驭已启动重卡高速 NOA 项目，旨在解决重卡司机长时间驾驶疲劳的痛点，提升干线物流的安全与效率水平，且已与徐工、陕汽、重汽三大业界头部客户确立合作，首批重卡车型将于 2026 年上半年正式量产。&lt;/p&gt;&lt;p&gt;基于端到端的辅助驾驶方式，正在为智能的泛化提供便利。卓驭透露，从乘用车到重卡的能力迁移，所需的时间不超过 1 个月。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4cacd87b-d570-4a4f-9085-b1675e333c75/QQ20251231-160722.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;同时，卓驭正联合商用车头部企业，共同设计和定义无人物流车，应用于矿山、港口等场景，这意味着在该项目中卓驭将不只是 tier1 供应商，而会参与到产品设计等更多环节。&lt;/p&gt;&lt;p&gt;昨天，卓驭发布了全新的使命、价值观与愿景：使命从原本的 &amp;ldquo;让给所有人带来安全轻松的出行体验&amp;rdquo;，升级为 &amp;ldquo;为世界提供安全、轻松的移动智能&amp;rdquo;，价值观升级为 &amp;ldquo;激极尽志、求真品诚、用户为本、成就客户&amp;rdquo;，并希望以此实现 &amp;ldquo;引领自主移动机器人时代&amp;rdquo; 的愿景。&lt;/p&gt;&lt;p&gt;未来，卓驭将会把移动智能推向更多场景。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>视远 · 正心明智——「AI 中国」机器之心2025年度评选正式揭晓</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 13:19:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-5</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe5QJ8IBG8nibRpDVIUB4tAsZ02f1uXn6OseqhOA9HB2UicJdIT3bNwI6A/640?wx_fmt=webp&amp;from=appmsg#imgIndex=0" data-ratio="0.5712962962962963" data-s="300,640" data-type="webp" data-w="1080" type="block" data-imgfileid="503526129" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/372907fd-2b19-4d58-842e-65673e69045d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2025 年的日历已经翻到最后一页。&lt;/p&gt;&lt;p&gt;这一年里，大模型的演进速度被不断推高：新的模型架构、训练范式与推理策略轮番登场，技术边界一次次被向前推移。&lt;/p&gt;&lt;p&gt;放眼海外，GPT-5、Gemini 3 等新一代模型相继亮相，在理解、生成与推理等核心能力上持续抬升上限，通用智能的轮廓愈发清晰。&lt;/p&gt;&lt;p&gt;回到国内，2025 年的 AI 场面同样热闹。国产大模型一边在核心能力上不断拉近与国际头部模型的差距，甚至在个别方向上实现反超，另一边也在开源、工程化和应用适配上明显提速。&lt;/p&gt;&lt;p&gt;然而，在技术浪潮起伏中，我们更需要清醒识别真正具备长远价值的 AI 力量。因为决定行业走向的，从来不是某一次参数翻倍、某一项榜单刷新，而是哪些能力能够在真实世界中持续发挥作用 &amp;mdash;&amp;mdash; 它们是否真正重塑了生产方式，并在时间的检验中沉淀为基础能力。&lt;/p&gt;&lt;p&gt;正是基于这样的判断与追问，我们尝试把目光从短期热度中抽离，去辨认那些真正值得被记录的技术进展与创新路径。&lt;/p&gt;&lt;p&gt;带着这些思考与期待，机器之心精心策划了 2025 年度榜单，记录中国人工智能奋进的这一年，勾勒技术创新的璀璨未来。&lt;/p&gt;&lt;p&gt;今日，「AI 中国」机器之心 2025 年度评选正式揭晓：&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;最强技术实力企业/机构 TOP 10&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeawtmGqASNYD9ApHpmsb1ab5GBuOc9YFODDpxGUkSWZJvxAKVcBy4lA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.3601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526132" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f0f76124-6dca-4227-80bc-9c5c7fb636b9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;人工智能领军企业 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibend6ZuXedZQGToQroeiafFc5jLuDC2O5MHCvGzib4EfLhXeY3iaFgumU7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.8953703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526133" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/99207199-8921-491d-857e-a4b4aab8e143/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;最佳大模型 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe8udYv7NMF1V9Q8uicLITatvWwTs703BicQ9ACaicOVOeOSN2VDZu73IoQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="2.448148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526134" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/dae6faf7-5bae-469a-bfd9-26abf9c23c02/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;最佳大模型产品 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibes10ZjuzKmBHS1N4C5UcG6via2U83Wia4cxhvuVmcoPrZEmUMczj1icBOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="2.448148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526135" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/9a0df25c-1f70-4cf7-b82d-a128721702dd/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;具身智能领军企业 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeUQVbvUWibhPu4bFP8WzDMCvJ4GAMY9UYOvGq8SibGp5QwKa8RHib3zFAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.8953703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526136" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2e90595e-dd2d-4428-b14e-73ae6504dba3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;ScienceAI 领军企业/机构 TOP 10&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeD0UiceN1D29jo7o5u1cHYFXxYespdHmaexN0YXSZkkXQeIlkibZicqicfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.3601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526137" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9c019211-7f58-4fdd-8abe-be7a41bba7ac/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>NUS尤洋教授深度探讨智能增长的瓶颈：或许我们将这样实现AGI？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 13:16:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-4</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;2026 年即将到来，AI 的发展也已经进入了一个新的阶段：我们已经取得了惊人成就，却同时面临进一步增长的瓶颈。&lt;/section&gt;&lt;p&gt;新加坡国立大学（NUS）的尤洋教授近期发表了一篇深度分析：《&lt;strong&gt;智能增长的瓶颈&lt;/strong&gt;》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LOniaWe4cQKOzUoUhicTOxStOI0kc6svMJxboh81K966XlZJvuuYmbkmw/640?wx_fmt=jpeg&amp;amp;from=appmsg#imgIndex=1" data-ratio="0.40063091482649843" data-s="300,640" data-type="jpeg" data-w="634" type="block" data-imgfileid="503526311" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f6bd305d-ff9e-4e9a-81e0-3e72b54679ca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;原文链接：https://zhuanlan.zhihu.com/p/1989100535295538013&lt;/p&gt;&lt;p&gt;在这篇分析文章中，尤洋教授从技术本质出发，直指智能增长的核心矛盾，为我们揭示了 AGI（通用人工智能）的可能路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;观点速览&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;✅&lt;strong&gt;&amp;nbsp;智能增长的本质不是架构变革，而是算力如何转化为智能&lt;/strong&gt;：AI 的核心智能来自于预训练及其 Loss 结构（例如 GPT 的 Next-Token Prediction）。这些机制更像是把算力转化为智能的方法，而非智能本身。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ 现有智能增长遇到瓶颈的根源&lt;/strong&gt;：当前范式（Transformer + 超大算力）在面对进一步增长时， 难以充分消化不断增长的算力资源，这导致了所谓 “预训练红利递减”。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ 算力并不是无限扩展就能解决问题&lt;/strong&gt;：即使算力指数级增长，如果现有算法无法有效利用这些计算资源，智能提升仍将受限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ 未来方向不在于工程优化，而是底层范式突破&lt;/strong&gt;：文章探讨了更高精度计算、更高阶优化器、更灵活的 Loss 设计、超大规模训练策略等潜在突破点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ AI 未来仍然乐观&lt;/strong&gt;：智能增长瓶颈虽强，但仍有可能通过更好的算力利用方式被克服。预训练可能才刚刚开始，大模型智能仍有巨大的发展空间。&lt;/p&gt;&lt;p&gt;AGI 的未来将如何发展？让我们拭目以待。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibeTWEreV5NLd1rQ2ASjPBb10pQCTARuib8FAZ7YSNA11TaiaXUtXLShAwQ/640?wx_fmt=jpeg&amp;amp;from=appmsg#imgIndex=2" data-ratio="1.5" data-s="300,640" data-type="jpeg" data-w="1000" type="block" data-imgfileid="503526216" data-aistatus="1" data-original-style="width: 296px;height: 444px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c8963d7f-778f-42e2-90d6-ef48a9999f72/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 尤洋教授，《智能增长的瓶颈》作者&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;以下为其分享原文：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能增长的瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年已至。在 ChatGPT 诞生三年多后的今天，关于我们的智能水平是否令人满意，以及未来是否还能强劲增长，笔者想分享一些个人的看法。如有谬误，恳请大家指正。&lt;/p&gt;&lt;p&gt;为了能深入探讨智能的本质，本文将不涉及产品易用性、成本等商业化或落地问题，因为这些本质上与智能突破本身无关。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 智能的现状&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;什么是智能？其实目前并没有一个明确的定义。&lt;/p&gt;&lt;p&gt;从最近图灵奖得主 Yann LeCun 和诺贝尔奖得主 Demis Hassabis 关于 AGI 的争论中，我感受到即便是世界上最顶尖的&lt;strong&gt;专家&lt;/strong&gt;也无法准确定义智能。&lt;/p&gt;&lt;p&gt;个人感觉，AGI 很难定义，其标准也会随着时代的变化而变化。我依然记得十几年前，普通人对人脸识别技术感到不可思议。如果把今天的 ChatGPT 拿到 2006 年，相信那时候的很多人会毫不怀疑地认为我们已经实现了 AGI。&lt;/p&gt;&lt;p&gt;我觉得智能的核心是&lt;strong&gt;预测&lt;/strong&gt;和&lt;strong&gt;创作&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;我认为如果达到以下这种状态，那么就离 AGI 不远了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如果你选择接受哪个工作 Offer，完全听从 AI 的意见。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果你买足球彩票预测世界杯冠军，完全听从 AI 的意见。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果你有健康问题，会完全采用 AI 制定的方案去治疗。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;你分辨不清楚一部奥斯卡最佳电影是否是由 AI 生成的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;石油公司的勘探团队用 AI 替代了所有数值算法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 能指导初级高铁工程师在 5 分钟内排除高铁的疑难故障。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 能研制出一款专杀癌细胞且不破坏好细胞的药物。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 能通过某区域的地下结构数据，精准预测地震的时间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;等等……&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;今天，我们显然还没实现这些。未来能否实现，取决于我们能否克服智能发展的瓶颈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 智能发展的瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，我们经常听到一些关于智能发展遇到瓶颈，或者预训练红利已尽的观点。何为瓶颈？我们先探讨一下智能从何而来。&lt;/p&gt;&lt;p&gt;过去 10 年，AI 大模型的技术本质，是把电力能源通过计算过程转化为可复用的智能。技术的好坏取决于这个转化效率的高低。类似的表述，我也听月之暗面的朋友提及过。&lt;/p&gt;&lt;p&gt;今天模型的智能本身，最主要还是来自预训练（往往是自监督方法），仅有少量来自微调或强化学习。&lt;/p&gt;&lt;p&gt;为什么？先算一笔浅显的经济账：因为预训练消耗的算力最多，消耗的能源也最多。&lt;/p&gt;&lt;p&gt;当然，预训练、微调、强化学习本质上都是在计算梯度以更新参数。如果有合适的海量数据和 Loss 函数，未来在预训练阶段采用 SFT（监督微调）或特殊的强化学习方法也有可能。&lt;/p&gt;&lt;p&gt;从智能增长的角度，我们甚至不用刻意区分预训练、SFT 和强化学习。它们的区别主要在于更新参数的次数与规模。&lt;strong&gt;从计算本质上看：预训练、微调、强化学习（比如 GRPO）都是在计算梯度的类似物，并用它来更新参数。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么，能源从何而来呢？这就是 GPU 或算力。英伟达在这点上做了最大的贡献。虽然英伟达有很多先进的技术，比如更强的 Tensor Cores、Transformer Engine、互联技术（NVLink / 网络化 NVLink）、软件栈等，但我先试图用一句话说清楚英伟达过去几年在技术上做的最重要的事情，即其 GPU 设计的核心思路。&lt;/p&gt;&lt;p&gt;简而言之，英伟达过去几年最重要的路线是：&lt;strong&gt;在同样的物理空间里堆更多 HBM（高带宽内存）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;HBM 虽然带宽很高，但依然是计算核心之外的内存（Off-chip from logic die），与计算核心存在不可忽略的物理距离。为了掩盖内存访问延迟，GPU 只能依赖超大的 Batch Size（批处理量）和大规模并行来处理数据。英伟达 GPU 本质上就是一台并行计算机。&lt;/p&gt;&lt;p&gt;因此，英伟达对算法层和软件层的要求非常明确：必须提供足够大的 Batch Size 或并行度。&lt;/p&gt;&lt;p&gt;面对英伟达的要求，很多研究团队都提出了自己的方案。比如 RNN、Transformer、卷积序列模型（CNN for Sequence）等等。甚至有人尝试用 SVM 来处理大规模序列数据。&lt;/p&gt;&lt;p&gt;那为什么 Transformer 率先脱颖而出？因为 Transformer 也是一台并行计算机。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe1zVVszeSf8HcLzhoFWnss4rObllWFmwFKjERQuPxb46iarzCZzVZsrw/640?wx_fmt=jpeg&amp;amp;from=appmsg#imgIndex=3" data-ratio="1.4559322033898305" data-s="300,640" data-type="jpeg" data-w="590" type="block" data-imgfileid="503526226" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/24e3ce8a-5297-4d2a-83ba-a7d43f9cb147/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 原初的 Transformer 架构&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这里我引用一下 Ilya Sutskever 的一句话：“Transformers: parallel computers in disguise”，直白的意思是：Transformer 本质上是一个被神经网络外壳包裹起来的并行计算机。这也是 Transformer 最先能够显现智能的核心原因，因为&lt;strong&gt;它的并行计算特性完美匹配了 GPU 的并行计算单元&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe74VN9hKHibtLDjZfxHoumJs5QKT9N1MbjgFETcbO9ZgUTzWWggHmuPA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.43333333333333335" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526092" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/54926c94-fc79-4fc8-bb77-1679e570b877/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;同时，OpenAI 完美地实现了 &lt;strong&gt;Next-Token Prediction&lt;/strong&gt; 这个 Loss 函数，它给了 AI 大模型近乎无限的训练数据。理论上 BERT 的 Loss 函数（完形填空和 Next Sentence Prediction）也可以提供近乎无限的数据，但在实践中，Next-Token Prediction 的效果明显更好。&lt;/p&gt;&lt;p&gt;我推测，这个 Loss 函数最小化了人类的干预 —— 它不是人为设计的，而是大自然在进化过程中赋予人脑的逻辑。并且，Next-Token Prediction 其实是&lt;strong&gt;预测未来&lt;/strong&gt;，而 BERT 的完形填空其实是把过去的信息和现在的信息串联起来。这就好比让一个足球专家根据历史数据和当天的比赛结果去解释合理性，几乎所有专家都能做到；但是，如果让专家去预测每一场比赛的精准比分，他们会经常出错。这再次说明了，&lt;strong&gt;预测 (Prediction) 是智能的核心能力体现，难度远高于解释 (Explanation)&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其实我挺佩服 OpenAI 团队能够坚持下来的勇气。2018 年时，BERT 在媒体上的影响力几乎完全碾压了 GPT，且当时 OpenAI 的 AI 研发团队体量跟 Google 比起来微不足道。很佩服他们没有放弃 Next-Token Prediction，也没有转向类 BERT 的训练方式。真理往往需要时间去检验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe1ZT4VndxCK3n8phMO6pZVQX90icquXrCovlG5rxYI32Wmias4OY0WU1A/640?wx_fmt=webp&amp;amp;from=appmsg#imgIndex=5" data-ratio="0.5" data-s="300,640" data-type="webp" data-w="800" type="block" data-imgfileid="503526223" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1350a0e1-c403-4655-9406-c6e2c6926123/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; BERT 对比 GPT&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;同时，以 Transformer 为核心的方案收获了 “一箭双雕” 的双重优势：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型的每层参数量越多，并行度就越高 (Tensor Parallelism)&lt;/strong&gt;。 所以，只要通信代价不显著增加，能同时利用的算力就越多。这点需要点赞行业领导者的先见之明。几年前，我看到 CNN 时代有研究人员试图把模型往深度发展，比如设想 1000 层的神经网络。其实非常深（层数非常多）的神经网络是不利于有效利用算力的，因为流水线并行提供的并行度上限不高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Transformer 的不同 Token 可以同时计算&lt;/strong&gt;。 序列长度越长，并行度就越高，只要通讯代价不显著增加，能同时利用的算力就越多。Sequence Parallelism 与 Data Parallelism 互补，进一步提供了更多的并行度。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;就这样，我们见证了 GPT-1、BERT、GPT-2、GPT-3、ChatGPT、Gemini 一步一步把智能提升到了今天的高度。&lt;/p&gt;&lt;p&gt;到这里，大家大概也清楚为什么 AI 模型的智能增长会遇到瓶颈了 —— 因为&lt;strong&gt;我们现在的范式无法充分消化持续增长的算力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;假定一次模型训练和微调消耗的浮点数计算次数（即程序员面试中的计算复杂度的具体值）从 10&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;ⁿ&lt;/span&gt; 变成 10ⁿ⁺³ 时，我们是否获得了一个显著更好的模型？&lt;/p&gt;&lt;p&gt;其实，很多时候我们把 “效率优化技术” 和 “智能提升技术” 混淆了。比如，明天我提出一个新的架构，实验发现达到跟 GPT-5 类似的效果，只需要 20% 的参数量或计算量。这其实更多是落地或商业化问题；智能的终极问题是：使用同样的浮点数计算次数（而非 Token 量），能否获得一个更好的模型。&lt;strong&gt;浮点数计算次数，才是算力最基本、最本质的计量单位。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 未来的方法探讨&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先从硬件层来看，我们&lt;strong&gt;需要持续产生更大的绝对算力&lt;/strong&gt;，这不一定局限于单位芯片上的算力提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibehp5PDHhwdbWXPpaSqxLx8D5ZrD5awkiaMCeWGqzSfyiagXjyj6e4fTBg/640?wx_fmt=jpeg&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.4861111111111111" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526228" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8026f37c-8700-4096-8342-5e6dc2027b49/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 前沿规模机器学习模型训练所用计算量的趋势，图源：Epoch AI&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;即便单位芯片上的算力没有大幅度提升，我们通过集群的方式也能构建更大的绝对算力。这里需要平衡的是：聚集芯片带来的性能增长，要高于 “芯片或服务器之间通信增长带来的负担”。&lt;/p&gt;&lt;p&gt;所以，具体的硬指标就是：增长或至少维持住 “计算开销/通信开销” 这个比值。这是整个 AI 基础设施层最核心的技术目标。要想实现这个目标，我们需要扩展性更好的并行计算技术，无论是软件还是硬件。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;更上层&lt;/strong&gt;的探索中，我们需要让 AI 模型在单位时间内 “吃下” 更多能源，并真正将其转化为智能。个人感觉大概有以下几点方向：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;更高精度的计算能力。&lt;/strong&gt; 今天，从 FP16 到 FP32，甚至 FP64，模型智能并未出现明显跃升。这本身就是一个瓶颈。理论上，更高精度应当带来更可靠的计算结果，这一点在传统科学计算中早已得到验证。这个观点可能与主流机器学习共识并不一致，而且真正发生可能需要很长时间，但从本质上看，智能仍然需要更精准的计算。这与过拟合并无直接关系，过拟合的根源在于数据规模不足或参数与数据不匹配。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;更高阶的优化器。&lt;/strong&gt; Google 的朋友告诉我，他们有时候已经不用类 Adam 优化器，而是用更高阶的优化器在训练模型。高阶优化器理论上能在学习过程中给模型更好的指导，算出更好的梯度，这是模型智能提升的本质。当然，高阶优化器的全面替代可能需要很长的时间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;扩展性更好的模型架构或 Loss 函数。&amp;nbsp;&lt;/strong&gt;我们仍然需要一种扩展性更好的整合和利用算力的方式。这点我们需要注意：优化效率不一定能提升智能。比如 Mamba 出来的时候，宣传重点是吞吐量的提升，用更小的模型获得同水平的智能。但是，本文关注的是：在最健全的 AI 基础设施上，用最大的可接受成本，能否训出更好的模型，获得更高的智能。比如，今天 Google 告诉你：预算 300 亿美元，半年内给我训出一个更好的模型，不考虑省钱问题，花 10 亿和花 100 亿没区别。在这个场景下，你最终是否会用 Mamba 这样的架构？你是否需要设计更好的 Loss 函数？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;更多的 Epoch 和更好的超参数。&amp;nbsp;&lt;/strong&gt;迫于成本压力，我们今天其实并没有对 AI 模型进行深度优化，甚至没有深度搜索超参数。这其实也是我之所以对 AI 模型的智能继续增长有信心的原因。我这里的意思不是直接训练更多的 Epoch。明知无效却生硬地跑更多 Epoch 其实是方法不对（比如参数量和数据量不匹配）。但是，根本上，更多的 Epoch 代表更多的浮点数、更多的能源。我们需要找到方法去 “吃下” 更多能源，并转化出更高智能。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;有些技术对大规模落地 AI 非常重要，比如低精度训练、剪枝、量化、蒸馏、PD 分离等推理优化技术。但是，在一个 “算力转智能” 极端有效的情况下，这些技术跟&lt;strong&gt;提升智能上限&lt;/strong&gt;无关。笔者对这些技术的贡献者非常尊重，它们在实际落地中至关重要，只是与本文探讨的主题无关。&lt;/p&gt;&lt;p&gt;智能增长归根到底还是算力利用问题。假定算力无限大，比如一个集群的算力达到今天的万亿倍，可能我们会发现更简单的模型结构比 Transformer 和 Next-Token Prediction 的扩展性更好。从 SVM 到 CNN、LSTM、BERT、GPT、MoE：我们始终在寻找能更高效利用算力且具备更好扩展性的方法。这个过程中，&lt;strong&gt;核心原因是问题的规模在不断扩大&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;我们在 AI 时代到来之前便已实现天气预报，然而至今仍未能攻克地震预报，尽管两者本质上都是针对地球数据的研究。究其原因，地下结构涉及比大气更加错综复杂、且变量规模呈指数级庞大的动态多模态数据。这种传统计算模式难以驾驭的高维复杂性，恰恰是未来 AI 技术大有可为的机遇所在。&lt;/p&gt;&lt;p&gt;所以，我有信心我们未来会不断找到更高效的算力使用方式。虽然过程中可能会有很多困难和低潮，但大趋势不可阻挡。&lt;/p&gt;&lt;p&gt;最后，借用 Richard Sutton 教授的一句话收尾：&lt;strong&gt;人工智能 70 年的研究留给我们最大的经验教训是，依托计算能力的通用方法才是最终的赢家，且具备压倒性的优势。&lt;/strong&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>重塑语音安全！上海交大联合宇生月伴，研发高性能高泛化语音鉴伪大模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 13:10:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-3</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/f1107484-50ba-4c95-b5f6-1cfb11925ecd/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="3" data-pm-slice="0 0 []"&gt;在生成式 AI 技术日新月异的背景下，合成语音的逼真度已达到真假难辨的水平，随之而来的语音欺诈与信息伪造风险也愈演愈烈。作为应对手段，语音鉴伪技术已成为信息安全领域的研究重心。&lt;/p&gt;&lt;p data-path-to-node="4"&gt;然而，当前的语音鉴伪模型正面临严峻的「泛化性挑战」：许多在特定实验室数据集上表现优秀的模型，在面对现实世界中从未见过的生成算法时，检测性能往往会出现剧烈下滑。这种「泛化瓶颈」严重限制了鉴伪技术在复杂多变的真实场景中的应用价值。&lt;/p&gt;&lt;p data-path-to-node="5"&gt;针对这一难题，上海交通大学听觉认知与计算声学实验室和宇生月伴公司（VUI Labs）联合发表了最新研究成果，提出了一种以数据为中心的研究范式。该研究深入探究了训练数据分布与模型泛化能力之间的底层逻辑，通过系统性的实证研究与策略优化，构建了兼具高性能与高泛化性的语音鉴伪大模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe4cgqCfpbjHzmVcokJtibDVnZEQ5QkqednsQWXbFibVj2WJzI7ePomc3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2898148148148148" data-type="png" data-w="1080" data-width="2128" data-height="616" data-imgfileid="503526202" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/83ba4400-78c8-4189-9ec9-0a54dad89cff/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;论文标题：A Data-Centric Approach to Generalizable Speech Deepfake Detection&lt;/li&gt;&lt;li&gt;论文链接：https://arxiv.org/pdf/2512.18210&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="7,1,0"&gt;&lt;strong&gt;核心视角： 从单一构建到多源聚合&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;不同于以往关注架构创新的路径，论文从数据中心视角切入，将数据版图重构为两个核心视角：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="9,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,0,0"&gt;构建单一数据集：&lt;/b&gt; 基于不同信源（source）和生成器（generator）生成伪造样本，构建数据集。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="9,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,1,0"&gt;聚合多源数据集：&lt;/b&gt; 汇聚具有不同信源、生成算法及其他声学条件的异构数据池，构建多样化训练数据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiaJOBrrUfUHIaFKarm44d8cDY5g40HEzT5PibSDD3KmSWN4WteNQk56w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.2077625570776256" data-type="png" data-w="876" data-width="876" data-height="1058" data-imgfileid="503526180" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6bf0a741-e040-4313-8eb7-69bf77872ce8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="10"&gt;基于上述视角，论文旨在通过系统性的实证分析探索两个核心问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="11,0,0"&gt;&lt;strong&gt;在单一数据集构建中&lt;/strong&gt;，如何在数据规模和多样性（信源 / 生成器）之间进行资源的科学分配？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="11,1,0"&gt;&lt;strong&gt;在聚合多源数据集时&lt;/strong&gt;，如何设计高效的混合与采样策略以实现最优泛化性能？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="12"&gt;&lt;b data-index-in-node="0" data-path-to-node="12"&gt;规模定律：&lt;/b&gt;&lt;b data-index-in-node="0" data-path-to-node="12"&gt;多样性远胜数据总量&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="13"&gt;为了揭示资源分配的最优原则，论文针对训练数据的组成规律开展了大规模实证分析。通过量化信源多样性、生成器多样性与样本容量之间的复杂关系，揭示了语音鉴伪领域内在的「规模定律」。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;核心发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="15,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="15,0,0"&gt;多样性是泛化的首要动力：&lt;/b&gt; 在资源有限的情况下，提升信源与生成器的多样性所带来的性能增益，远比单纯增加数据总量更具效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="15,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="15,1,0"&gt;信源与生成器属性互补：&lt;/b&gt; 信源多样性有助于模型构建稳健的真实语音分布，而生成器多样性则显著强化了模型对各类伪造特征的识别。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="15,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="15,2,0"&gt;泛化表现具备可预测性：&lt;/b&gt; 泛化误差随数据多样性的增加呈现出稳定的幂律缩放特性，使泛化能力的提升从随机探索走向科学建模。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeY0aJsEibdwG4Rhib25mH3EGMFiaQWZ3ibnWRV5hiazic7sm9icH86IMSsOZNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5666666666666667" data-type="png" data-w="1080" data-width="1804" data-height="1022" data-imgfileid="503526224" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a93362fa-aa8e-4116-aaf2-14abff2bfc5a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="16"&gt;&lt;b data-index-in-node="0" data-path-to-node="16"&gt;采样策略：&lt;/b&gt;&lt;b data-index-in-node="0" data-path-to-node="16"&gt;科学混合异构数据池&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;既然多样性的价值远胜于纯粹的数据堆叠，那么如何科学地混合来自不同源头的异构数据，就成为了解决泛化难题的第二个关键问题。基于规模定律的分析，论文提出了多样性优化采样策略（Diversity-Optimized Sampling Strategy，DOSS）。该策略的核心在于将复杂的异构数据按照信源或生成器划分为细粒度的域，并相对公平地对待每一种已知的生成模式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="18,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,0,0"&gt;细粒度域定义：&lt;/b&gt; 将真实语音按「信源」划分，将伪造语音按「信源 + 生成器」的组合进行索引，从而在更微观的层面实施分布控制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="18,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,1,0"&gt;多样性筛选（DOSS-Select）：&lt;/b&gt; 一种基于数据剪枝策略，旨在构建更平衡且高效的训练子集，剔除边际收益递减的冗余样本以提升训练效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="18,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,2,0"&gt;分布加权（DOSS-Weight）：&lt;/b&gt; 一种数据重加权策略，在保留全量数据的同时，调整各数据域在训练时的采样概率，让模型更均衡地学习不同规模域的特征，避免被海量但单一的数据分布所主导。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19"&gt;实验结果验证了该策略在处理大规模异构数据时的优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="20,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="20,0,0"&gt;极高的数据效率：&lt;/b&gt; 采用 DOSS-Select 策略，仅需使用约 3% 的总数据量，其泛化性能即可超越朴素聚合全部数据的基线水平。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="20,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="20,1,0"&gt;显著的性能提升：&lt;/b&gt; 采用 DOSS-Weight 策略，实现了相对朴素聚合基线约 30% 的大幅度误差削减。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibekCIVCt6zrran5LsKoiagxRqbESSbnp0FnoicIyguAye8AtpTIibibiclVWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6601851851851852" data-type="png" data-w="1080" data-width="1802" data-height="1190" data-imgfileid="503526193" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8458b586-e59c-40f6-b294-797dfc0d42cc/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="21"&gt;&lt;b data-index-in-node="0" data-path-to-node="21"&gt;实战评估：&lt;/b&gt;&lt;b data-index-in-node="0" data-path-to-node="21"&gt;学术基准和商业接口实测&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;为了验证上述策略的稳健性与可扩展性，论文构建了一个包含 1.2 万小时音频、涵盖 300+ 个伪造领域的大规模异构数据池。通过应用 DOSS 策略进行训练，最终得到了高性能高泛化的大模型，并在多个学术基准和商业接口上进行了实测，均取得了突破性表现：&lt;/p&gt;&lt;p data-path-to-node="23,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="23,0,0"&gt;学术基准：刷新跨域性能记录&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="23,0,0"&gt;在多个公开测试集的评估中，模型平均等错误率（EER）降至 1.65%，在多个主流基准测试中均刷新了记录，确立了新的技术基准和 SOTA。此外，数据与模型效率的表现尤为出色：相较于之前最好的来自日本 NII 的系统&amp;mdash;&amp;mdash;在 7.4 万小时数据上训练的 2B 规模模型（平均 EER 3.94%），提出的新方案仅凭约 1/6 的训练数据与更精简的参数规模，便实现了检测误差的倍数级削减。即便是在更轻量的 300M 版本下，其性能表现依然稳健，证明了科学的数据策略比单纯的规模堆叠更能有效释放模型的泛化潜力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeBB202hTMOaPdvXkGbicOl9eLicFptw3icTC6kcf9W5iapOpIvZGic7ujKGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.37037037037037035" data-type="png" data-w="1080" data-width="1894" data-height="702" data-imgfileid="503526200" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ded4c52a-dbed-426e-b4b4-670ea10b2d85/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="23,1,0"&gt;商业接口：直面现实安全威胁&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="23,1,0"&gt;针对从 Google、Microsoft 等主流云服务到 ElevenLabs、MiniMax 等前沿高拟真引擎的 9 类最新商业接口进行评估，模型平均检测准确率达到了 96.01%。即便在面对目前极具挑战性的高保真合成引擎 Qwen3 时，模型仍能保持 87.32% 的高准度识别。这进一步印证了从多样化训练数据中学习到的表征，能够有效迁移并泛化至现实中不断进化的商业生成方式。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe3iaptPib8goy1P2k0J5Q7rkJ7WJuzLaFOcqeknlCwZ6TJUxDE7U9HCng/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.24814814814814815" data-type="png" data-w="1080" data-width="2036" data-height="506" data-imgfileid="503526201" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4505ecc6-7b61-4fd9-a779-48888f59d65e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="24"&gt;&lt;b data-index-in-node="0" data-path-to-node="24"&gt;总结&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="25"&gt;不同于以往在模型架构与算法优化上的迭代，深挖训练数据组成的底层逻辑正在成为重塑语音安全防线的关键。本论文通过量化多样性的规模效应并引入优化采样机制，成功实现了对异构数据资源的高效调度与深度挖掘。这种向「数据中心」范式的深刻转变，为构建高性能、高泛化的语音安全大模型提供了全新的探索思路。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;&lt;b data-index-in-node="0" data-path-to-node="26"&gt;团队介绍&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;研究团队来自于上海交通大学计算机学院听觉认知与计算声学实验室（SJTU Auditory Cognition and Computational Acoustics Lab，AudioCC Lab）和宇生月伴公司（VUI Labs），该团队由语音对话和听觉处理领域知名学者，教育部长江学者钱彦旻教授领导，专注于完整的听觉人工智能与计算声学领域的前沿研究。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;实验室集结了一支由青年教师、博士生、硕士生、本科生及专职科研人员等组成的近 40 人科研团队，在语音、音频、音乐及自然声信号处理等领域积累了丰富的技术经验。实验室依托国家重点项目及企业合作支持，拥有数百块先进 GPU 计算资源，致力于解决产业级技术难题。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;近年来，团队在国际顶级期刊和会议上发表了数百项学术成果，并在多项国际评测中斩获冠军。团队成员全面发展，毕业生均进入国内外顶级企业和研究机构，持续推动人工智能技术的创新与应用。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华北电力大学等开发基于AI的催化设计蓝图，跨材料的电化学通用设计框架</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Wed, 31 Dec 2025 12:00:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-2</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwhz8RBNFIvNz4IKHZp78sRkGEH5dQujls2nwRM2OrIT5H7icBUWk8ULg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="314" data-imgfileid="100027018" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/a2230bb1-b2ff-4f6f-8e20-2cea1b80241a/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨%&lt;/p&gt;&lt;p&gt;在日常生产中，时常能看到过氧化氢的影子，从消毒剂、医疗灭菌到环境清理和制造。都有它发挥价值的地方。但大多数双氧水仍通过需要大量能源的大规模工业工艺生产，仍需寻找相关的替代品。&lt;/p&gt;&lt;p&gt;来自华北电力大学等的研究团队在寻找相关反应的催化剂方面有了突破。他们开发了一个通用且可转移的催化剂设计框架，整合了加权原子中心对称函数（wACSF）描述符与机器学习和微动力学建模。&lt;/p&gt;&lt;p&gt;相关研究内容以「Universal Catalyst Design Framework for Electrochemical Hydrogen Peroxide Synthesis Facilitated by Local Atomic Environment Descriptors」为题，发表在《&lt;em&gt;Angewandte Chemie International Edition&lt;/em&gt;》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwTdfVbVrutSickbuvFGGcssAZiaAVOHlzgsNjQp25v6a8wImzIyAiaOicmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3580683156654888" data-type="png" data-w="849" data-width="849" data-height="304" data-imgfileid="100027016" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/c0e6e366-c327-4481-afc1-b2d9ba6ced7f/640.png" alt="图片" data-before-load-time="1767153643151" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://onlinelibrary.wiley.com/doi/10.1002/anie.202518027&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计反应催化剂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过氧化氢合成被认为是一种经济高效的生产方式，并且相当环保节能。该方法还通过将电能转换为氢形式的化学能，提供了一种稳健的能量储存解决方案，从而将能源生产与环境可持续性相结合。&lt;/p&gt;&lt;p&gt;受到当前催化剂设计局限的启发，相关团队开发了一个通用且可转移的催化剂设计框架，将新构建的加权原子中心对称函数（wACSF）描述符与机器学习和微动力学建模整合。&lt;/p&gt;&lt;p&gt;与主要描述原子几何环境的传统 ACSF 方法不同，wACSF 描述符包含几何和化学特征，包括活性中心原子的内在活性活性特性。这种双重表示使得对多样化催化系统的统一描述成为可能，克服了传统机器学习辅助方法的可迁移性不足。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwh2RhuyAzjicysfIPbibUntbFoB0AcSmLImhVMSZriacFNNKxgY4c2xm8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.676" data-type="png" data-w="500" data-width="500" data-height="338" data-imgfileid="100027015" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/db435881-6673-4de2-ae63-bc2b8c610a10/640.png" alt="图片" data-before-load-time="1767153643177" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：催化剂设计框架概述。&lt;/p&gt;&lt;p&gt;该框架的运行逻辑大致如下：&lt;/p&gt;&lt;ol start="1"&gt;&lt;li&gt;&lt;p&gt;首先选出主要材料，并根据催化剂的活性点位等构建原子的化学环境特征。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;利用 XGBoost 回归，随后进行特征分析和递归消去以丢弃冗余特征。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;采用先进的机器学习算法来开发有效模型，随后将得到的无吸附能量纳入微动力学火山模型中进行测试。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后，通过机器学习预测的无吸附能量筛选过程，将通过微动力学模型快速识别潜在高性能催化剂。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;性能与验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;利用该框架，团队成功预测了多种催化剂类型中的关键反应特性。这些预测与详细的量子力学计算结果及先前报告的实验数据高度吻合，表明该方法适用于多种材料。&lt;/p&gt;&lt;p&gt;接下来，团队通过 &amp;ldquo;通用设计框架&amp;rdquo; 筛选出最优候选催化剂 &amp;mdash;&amp;mdash;&lt;strong&gt;LiScO₂&lt;/strong&gt;，从电化学性能、稳定性、理论 - 实验匹配度三方面完成系统验证。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwmgRLj9ksx5UOZ3CP54GAhNAtdoLBttLs3WVIskm8LdO5eUr849DPAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6625" data-type="png" data-w="800" data-width="800" data-height="530" data-imgfileid="100027014" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a6887d69-aeb9-47f6-a18e-71077f8f4154/640.png" alt="图片" data-before-load-time="1767153643373" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：理论预测的实验验证。&lt;/p&gt;&lt;p&gt;该框架所验证的结果显示， LiScO₂催化剂在 2.2 V vs. RHE 下 H₂O₂法拉第效率达 90%，2.4 V 时仍保持 &amp;gt; 80% 选择性。稳定性表现也相当优异，能在流动池测试中连续运行 168 小时，法拉第效率维持 82%&amp;ndash;86%，并且无结构降解。&lt;/p&gt;&lt;p&gt;验证结果与预测结果偏差值在 5% 之内，是目前 2e⁻ WOR 催化剂中最优匹配的例子。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该研究提出了一个&lt;strong&gt;通用的催化剂设计框架&lt;/strong&gt;。通过开发加权原子中心对称函数（wACSF）描述符，整合数据库自动化、机器学习（ML）和微动建模，其中 wACSF 结合了几何与化学特征，实现了跨不同催化剂家族的局部环境统一且可迁移的表示。&lt;/p&gt;&lt;p&gt;该框架可以实现夸材料催化剂筛选与机制洞察，体现了设计中的统一范式。它已被应用于数字催化平台（迄今为止最大的数字平台实验和计算催化数据库，由 Hao Li 实验室开发），可用于高效预测反应性质。&lt;/p&gt;&lt;p&gt;相关链接：https://phys.org/news/2025-12-ai-based-blueprint-catalysts-materials.html&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为云CEO周跃峰：要避免AI成为泡沫，必须要提升行业生产力</title>
      <description>&lt;![CDATA[用一行行代码解决真实问题。]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 31 Dec 2025 10:19:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;“不能让今天的 AI 仅仅用于满足人的情绪价值，必须要提升我们的生产力。”&lt;/p&gt;&lt;p&gt;在近期召开的 2025 华为开发者大赛暨开发者年度会议上，华为高级副总裁、华为云 CEO 周跃峰面对数百名开发者，直指当前人工智能热潮中的 “泡沫” 隐忧。这位新任华为云掌舵人，首次系统阐释了华为云在 AI 时代的新蓝图 —— 联合开发者，在华为云 “黑土地” 上，共同打造行业 AI 的 “梦工厂”。&lt;/p&gt;&lt;p&gt;&lt;span class="fr-img-caption fr-fic fr-dib" style="width: 812.616px;"&gt;&lt;span class="fr-img-wrap"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/73101878-0016-4234-a8b1-26f7165822e0/%E5%9B%BE%E7%89%871.png"&gt;&lt;span class="fr-inner"&gt;华为高级副总裁、华为云 CEO 周跃峰&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行业 AI “梦工厂” 计划&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首次剧透的 “行业 AI 梦工厂” 计划，勾勒出华为云的 AI 宏图。&lt;/p&gt;&lt;p&gt;“华为云应该成为行业 AI 的‘梦工厂’。” 周跃峰解释说，“这个梦工厂里会有各种‘作坊’，每个作坊专注一个垂直领域。”&lt;/p&gt;&lt;p&gt;这些 “作坊” 实际指的是一个个面向垂直领域的社区。华为云将开放华为在医疗、自动驾驶、具身智能等领域长期积累的技术能力、工具链与行业实践经验，为开发者提供坚实而丰沃的创新土壤。首批透露的 “作坊” 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;具身智能开发者社区：开放具身智能相关的工具链、软件和仿真环境&lt;/li&gt;&lt;li&gt;“魔擎” 医疗社区：基于瑞金医院实践，让更多医院和医生能开发专属 AI 医疗方案&lt;/li&gt;&lt;li&gt;商专车自动驾驶社区：服务特定场景的自动驾驶开发需求&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“从明年开始，业界会看到我们的一系列动作。我们也希望用我们的能力来打开中国各个行业 AI 的一扇扇大门，包括农业、育种、科研等等”，周跃峰表示，“我们会真正把华为云建设成为行业 AI 的‘梦工厂’，使能千行万业实现他们的 AI 梦想。”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;每个 Token 都要体现价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“我希望今天我们 AI 做的很多东西能够真正改变提升我们的生产力，而不仅仅是情绪价值，不仅仅是 Token 数量。” 周跃峰的发言有着工程师式的务实，“我希望每一个 Token 背后都有非常高的社会价值和我们劳动价值的体现。”&lt;/p&gt;&lt;p&gt;这种务实态度源于他亲历的实践。在过去的 18 个月里，周跃峰深度参与了上海瑞金医院病理 AI 项目。这不是一个停留在论文或演示中的项目，而是一个已经深度融入医院日常诊疗流程的系统。&lt;/p&gt;&lt;p&gt;“今天在瑞金医院看病，病理切片基本都是机器先看，医生复核签字就行了。” 周跃峰透露，“这在全国是首家真正把 AI 用到临床流程中的医院。”&lt;/p&gt;&lt;p&gt;更关键的是系统的闭环设计 —— 医生每诊断一个病例，数据都会反馈到模型中进行再训练。在瑞金医院的屏幕上，实时显示着每位医生当天通过 AI 系统诊断的病例数，以及有多少数据进入了 “数据飞轮”。&lt;/p&gt;&lt;p&gt;“医疗领域的每个 Token 都关联着鲜活的生命。” 周跃峰说，“金融风控的每个 Token 都守护着财产安全。这些价值，远比单纯追求 Token 数量有意义得多。”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 一定要沿着生产力提升的方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与一些云厂商侧重算力租赁的模式不同，华为云走的是一条更重、更难的路径。周跃峰坦言，华为云每年在基础设施上有着巨大投入，需要大量自研，成本很高。&lt;/p&gt;&lt;p&gt;但他坚信打造 “黑土地” 以及走行业 AI 路径的价值：“华为云在 AI 这条路上面走的跟别的云公司不太一样，但是我从内心认为，我们这条路是最踏实的、最坚实的，如果 AI 要成功的话，一定是沿着提升生产力的方向成功。”&lt;/p&gt;&lt;p&gt;未来，华为云将聚焦几个关键技术方向：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全栈自主的基础设施：基于昇腾、鲲鹏架构构建国产化算力底座&lt;/li&gt;&lt;li&gt;更开放的 ModelArts 平台：支持多模型调度和第三方模型&lt;/li&gt;&lt;li&gt;更智能的 CodeArts：集成更强大的智能编程能力&lt;/li&gt;&lt;li&gt;行业智能体平台：将推出面向行业场景的 Agent 编排平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“华为公司有 20 多万员工，其中大量是研发人员。” 周跃峰自信地说，“在中国找不到第二家公司有如此丰富的编程环境 —— 从汇编到 Python，各种语言团队我们都有。做不好智能编程，我觉得是不可能的。”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;给开发者的建议：深耕行业价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对开发者的提问，周跃峰给出了明确的建议方向。&lt;/p&gt;&lt;p&gt;“建议大家关注那些真正能提升生产力的 AI 应用。” 他说，“比如如何用 AI 优化复杂决策系统 —— 就像电动车行业的供应链优化，订单下来后如何快速协调数百家供应商，这需要处理海量实时数据，传统方法很难解决。”&lt;/p&gt;&lt;p&gt;另一个方向是行业智能体开发平台。“今天很多 Agent 平台源自 C 端，但行业端的需求完全不同。” 周跃峰指出，“行业 Agent 的发育速度较慢，这正是需要开发者共同努力的地方。”&lt;/p&gt;&lt;p&gt;对于近期火热的具身智能，周跃峰既看好也保持理性：“当前算法还不足以支撑各行业对机器人的泛化要求，算法与身体的物理适配也还不够。” 为此，华为云将通过开放算力、工具链和仿真环境，降低开发门槛，让创业者能将更多资源投入到核心算法研发中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;华为的 “踏实” 文化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“华为公司很务实。” 周跃峰也谈到了华为的内部文化，“我们不是上市公司，没法通过股市融资。每一分钱都是自己赚出来的。”&lt;/p&gt;&lt;p&gt;这塑造了华为的务实风格。周跃峰说，“正是这种‘踏实’，让我们必须把每一分钱都投在能真正提升生产力的方向上。”&lt;/p&gt;&lt;p&gt;周跃峰最后留下自己的微信，邀请开发者直接交流。“这条路不容易，但我和团队相信，只有让 AI 真正提升生产力，技术才有长远价值。”&lt;/p&gt;&lt;p&gt;在 AI 热潮汹涌的今天，华为云选择了一条少有人走的路，沉入行业深处，用一行行代码解决真实问题。这条路径或许不会立即带来亮眼的 Token 数据，但正如周跃峰所说：“如果 AI 要成功，一定是沿着提升生产力的方向成功。”&lt;/p&gt;&lt;p&gt;科技发展的历史上，最终改变世界的，从来不是最热闹的技术，而是那些真正解决问题、创造价值的技术。华为云的 AI 路径，正在验证这个朴素的真理。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>摩尔线程天使投资人：对近期AI的四十个观察</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 30 Dec 2025 20:43:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-11</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;blockquote&gt;&lt;p&gt;本文作者为摩尔线程天使投资人、中国初代 AI 投资人王捷。他于今年 8 月发表了《浮现中的 AI 经济》一文，对即将到来的 AI 经济进行了展望和解读。本篇文章是他近期对当前 AI 的思考的小结。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;关于 AI 经济的四十个问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;《浮现中的 AI 经济》（以下简称 &amp;ldquo;文章&amp;rdquo;）发表以来，AI 行业继续发生了众多大事，OpenAI 牵头的千亿美金 &amp;ldquo;循环交易&amp;rdquo; 引发 &amp;ldquo;AI 泡沫论&amp;rdquo; 大讨论，模型公司估值来到数千亿美金级别，而 Gemini 3 和 GPT5.2 等新发布模型版本又持续体现了能力进步，中国模型也持续在开源领域保持全球领先。&lt;/p&gt;&lt;p&gt;我们看到，与 AI 相关的历史事实，正继续以 &amp;ldquo;&lt;strong&gt;非线性、非均匀&lt;/strong&gt;&amp;rdquo; 的特征往前发展：Scaling Law 并未收敛，AI 行业继续呈现加速发展的特点，与 AI 相关的经济活动规模来到了前所未有的量级；同时，历史进程呈现出 &amp;ldquo;非均匀&amp;rdquo; 的面貌，虽然人们是在同一个时空下，但是与 AI 有关的经济社会活动，和与 AI 无关的经济社会活动，看起来不在同一个历史进程中，前者正以强大的动能迅猛往前发展，而后者维持着我们所熟悉和习惯的、传统工业经济的节奏和特点。&lt;/p&gt;&lt;p&gt;另外，文章发表以来，一些行业领袖表达了与文章类似的观点，如马斯克认为社会将进入 &amp;ldquo;全民高收入&amp;rdquo; 时代，黄仁勋推测 AI 将把全球 GDP 推高 5 倍至 500 万亿美元，黄仁勋对于 &amp;ldquo;AI 工厂&amp;rdquo;、&amp;ldquo;数字员工&amp;rdquo; 的讨论。如何在有效框架下具体地讨论这些问题，越发成为大家共同的关注。&lt;/p&gt;&lt;p&gt;基于以上，为了集中回应读者朋友对于文章的兴趣，也为了对文章所表达的内容做更进一步的阐述，我们整理了关于 AI 经济的四十个重要问题，供关心 AI 大模型接下来对于经济、社会影响的朋友们参考。&lt;/p&gt;&lt;p&gt;我们希望这些观察，之于即将展开的 AI 经济，能对其为什么会发生、将有哪些结构性特征，给出一些可参考的观察；对于 AI 经济将要如何展开，给出一些理解、预判的视角、基准和指标；对于 AI 大模型即将带来的对于社会、经济的全面影响，给出一些观察和分析的基础框架。在一个即将展开的未知大时代，我们相信&lt;strong&gt;要揭开其全貌，提出问题，是开始的方式之一&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问题一：Transformer 架构的 Scaling Law 在何处收敛？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Scaling Law 启动了我们当前所在的 AI 大模型发展的大浪潮；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Scaling Law 作为 AI 大模型行业发展的基石，将会在何种条件下、什么时候收敛？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二：Transformer 之后，下一个将 AI 智能往前大幅推进的架构是什么？会诞生在哪里？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;这会决定我们到达 transformer 架构下的 AI 能力上限后，继续往哪里走；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;目前全球众多 AI 研究机构在做这方面的探索；正如 2015 年成立的 OpenAI 带来了这一轮的大语言模型浪潮，目前的边缘地带在十年后又可能成为最重要的技术推动力量。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三：我们需要知道更多关于 AI 大语言模型基础规律&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;目前，我们已经知道大语言模型的推理成本每 12 个月下降 90%、能力密度约每 100 天翻一番、完成复杂任务的能力每七个月翻倍等一些关于大语言模型的规律；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们能否发现 AI 大语言模型的 &amp;ldquo;摩尔定律&amp;rdquo;？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题四：AI 将以什么样的顺序、在什么时间扩散到各个行业、整个社会？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;回看蒸汽机和电力的扩散过程，基本分为&lt;strong&gt;核心原理成熟、工程化成熟、跨行业和规模化部署、成为基础设施&lt;/strong&gt;四个阶段；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;当前的 AI，处在核心原理成熟当中&lt;/strong&gt;（Scaling Law 尚未收敛）、&lt;strong&gt;工程化尚有巨大发展空间&lt;/strong&gt;（如 Deepseek、Kimi 通过工程优化都实现了明显提升模型效能）、&lt;strong&gt;跨行业和规模化部署处在早期&lt;/strong&gt;（各行业的专用 agent 均刚刚出现，都还在探索各自行业适用 AI 的最优解），这样一个阶段；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;蒸汽机完成上述过程用了 120&amp;ndash;150 年，电力完成上述过程用了 80&amp;ndash;100 年；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们初步预计，AI 完成上述整个过程可能会用 40&amp;ndash;60 年；AI 的研究始于 1956 年的达特茅斯会议；如果把 2012 年的神经网络 AlexNet 作为核心原理成熟的起点的话，那 &lt;strong&gt;AI 可能在 2035 到 2050 年完成上述过程&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题五：Transformer 架构的 Scaling Law 收敛时，对应的 AI 工作能力是怎么样的？需要一套对于 AI Agent 工作能力的评测体系&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;也就是，届时全球最领先的 AI 大模型所具备的 &amp;ldquo;工作能力&amp;rdquo;，将会达到什么水平？对于这里的 AI 工作能力，我们需要量化的评估指标，即一套对于 AI Agent 工作能力的评测体系；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当前流行的各项 AI 能力评测基准，评测任务基本不来自于真实经济活动；我们需要构建评测任务来自于真实经济活动的评测基准；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以上评测体系，可以让我们知道不同推理能力的 AI 大语言模型的 ROI / 创造价值能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题六：关于 &amp;ldquo;经济图灵测试&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在文章中我们提到，对于从事经济活动的 AI 而言，更好的评估基准是专门来评估其从事经济活动的能力，我们将其命名为 &amp;ldquo;经济图灵测试&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基于问题五提到的评测体系，我们应该有能力构建可用的 &amp;ldquo;经济图灵测试&amp;rdquo; 标准，来评价什么情况下我们认为 AI 独立完成了经济任务，什么情况下我们的经济和社会可以完全接受 AI 完成的工作结果，以及我们是否同意 AI 持续为我们完成这样的工作。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题七：关于产出增强倍数（Output Augmentation Multiple）&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;用一个经济体中一个劳动力一年的总成本，投入到 AI 和机器人系统执行该劳动力同样的任务，所得到产出与该劳动力一年产出的比值，我们称之为 &amp;ldquo;产出增强倍数&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;产出增强倍数，是这次由 AI 驱动的工业革命带给人类的结果的最显式和简洁的表达：同样的投入，人干和 AI 干，后者的产出是前者的多少倍？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在数字世界和物理世界，产出增强倍数各是多少？哪些行业的产出增强倍数高，哪些行业的产出增强倍数低？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题八：不同行业、不同经济体、AI 经济不同发展阶段的产出增强倍数各是多少？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不同行业、不同经济体的产出增强倍数各不相同；当我们有足够多的样本，我们将可以统计出这些产出增强倍数各是多少；这些产出增强倍数将为我们提供不同行业、不同经济体的 &amp;ldquo;AI 浓度&amp;rdquo; 和 &amp;ldquo;AI 有效度&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 AI 经济的不同发展阶段，会有不同的产出增强倍数；随着 AI 对于全球经济产出的贡献越来越大，对于产出增强倍数的跟踪，将有助于我们理解整个这次 AI 工业革命。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题九：在问题一的收敛状态到来时，AI 带来的工作能力会把一个经济体的全要素生产率提高百分之多少？会把稳态下的全球 GDP 增长率提高百分之多少？以及，AI 生产力会把全球的 GDP 提高到目前全球 GDP 的多少倍？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们知道，全要素生产率决定一个经济体的长期经济增长率。如果 AI 的工作能力提高了全要素生产率，那也会提高全球的长期经济增长率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第三问是问题七的加总：也就是我们在文章中提到的，&lt;strong&gt;&amp;ldquo;N 倍于当前人类经济总产出的产出能力&amp;rdquo;&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;现在大家对此有很多积极的猜测，比如黄仁勋认为是 5 倍；但是，我们需要更多扎实的基础性统计和计算工作。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十：我们会怎样进入 &amp;ldquo;非稀缺经济&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对于一个经济体，我们将有机会定义其单位时间的&lt;strong&gt; &amp;ldquo;产出/需求比&amp;rdquo;（Output&amp;ndash;Demand Ratio）&lt;/strong&gt;，即该经济体的单位时间总产出，比上该单位时间该经济体总需求的倍数；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当单位时间的 &amp;ldquo;产出 / 需求比&amp;rdquo; 大于多少时，人们会感觉处在一个 &amp;ldquo;非稀缺经济&amp;rdquo; 中。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;&amp;ldquo;数字层使得每个个人的脑力的差异，在经济活动中被很大程度上抹除了 &amp;mdash;&amp;mdash; 新的情况是，只要有足够的电力和算力，你可以让无数个拥有科学家般智商的数字员工替你无休止地工作。&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题十一：文章提到 AI 经济阶段将可能出现的一个重要基础设施是 &amp;ldquo;数字层&amp;rdquo;。&amp;ldquo;数字层&amp;rdquo; 由用户的个人 AI 助理和各个垂类的 AI Agent 组成，全面了解消费者和生产者等经济主体，也全面了解物理世界。&amp;ldquo;数字层&amp;rdquo; 的工作机制是怎么样的？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于对个人 AI 助理和各个垂类的 AI Agent 的观察，我们可以初步说，当前正在出现的 &amp;ldquo;数字层&amp;rdquo; 是以&lt;strong&gt; LLM 为决策核心、以 Agent 为执行单元、在状态 &amp;mdash; 目标 &amp;mdash; 行动闭环中持续运行的代理化操作层&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以 chatbot 为例，它可以接收用户的问题和关于用户的环境信息，通过模型计算生成回答（可能结合实时信息获取模块），发送给用户；可以全天候工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以 agent 为例，它可以接收用户任务和环境信息，以任务为目标自主规划执行策略，收集所需信息，调用工具并执行，给用户交付该任务要求的结果；可以全天候工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以 AI 硬件 / 机器人为例，它可以感知和接收用户的环境信息，接收用户提出的任务，理解需求后自主规划执行策略，收集需要的信息，调用工具并执行，给用户交付该任务要求的结果；可以全天候工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 具有&lt;strong&gt;目标导向、自主搜索 / 获取信息、自主决策、自主行动、全天候&lt;/strong&gt;的特点。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十二：为什么数字层可能构建 &amp;ldquo;全知全能&amp;rdquo; 的能力？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数字层&lt;/strong&gt;承接了互联网和移动互联网的连接基础，&lt;strong&gt;最终将连接&lt;/strong&gt;全球所有的互联网和移动互联网用户，也就是&lt;strong&gt;全球经济活动中几乎所有的消费者和生产者&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;由于数字层可以完整执行 &amp;ldquo;收集信息 - 决策 - 行动&amp;rdquo; 链条，数字层将成为每位消费者和生产者在经济活动中的 &amp;ldquo;代理者&amp;rdquo;，在数字层能够赋能到消费者和生产者的任务中，帮助消费者和生产者完成该任务。一段时间之后，数字层&lt;strong&gt;会对使用它的消费者和生产者形成深度、完整的了解&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;所有数字层主体是通过数据协议相通的，它们都处在同一个互联网网络体系上。他们对作为各自用户的消费者和生产者的了解加总后，会形成对全球所有消费者和生产者近似于 &amp;ldquo;全知&amp;rdquo; 的了解。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;拥有了对全球所有消费者和生产者近似于 &amp;ldquo;全知&amp;rdquo; 的了解，数字层本身又可&lt;strong&gt;完整执行 &amp;ldquo;收集信息-决策-行动&amp;rdquo; 链条&lt;/strong&gt;，也就会形成近似 &amp;ldquo;全能&amp;rdquo; 的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十三：&amp;ldquo;数字层&amp;rdquo; 如何降低交易成本？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;文章中提到，交易成本包括组织成本（组织内）和狭义的交易成本（组织间）。文章的角度是 AI 作为工具来辅助人，讨论了 AI 辅助人的情况下，两种交易成本是如何降低的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;另一种情形是，&lt;strong&gt;AI Agent 成为行动主体 &amp;mdash;&amp;mdash; 数字员工&lt;/strong&gt;。这也会产生&lt;strong&gt;拥有数字员工的公司&lt;/strong&gt;。这种情形下，&amp;ldquo;数字层&amp;rdquo; 也将有效地&lt;strong&gt;降低组织内&lt;/strong&gt;和&lt;strong&gt;组织间&lt;/strong&gt;两种&lt;strong&gt;交易成本&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;交易成本的下降，也会对 AI 生产力的提高起贡献作用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十四：&amp;ldquo;分散知识&amp;rdquo;，都会上传到数字层吗？&amp;ldquo;分散知识&amp;rdquo; 未来将如何发现、积累和传承？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;哈耶克认为，&amp;ldquo;&lt;strong&gt;社会经济问题&lt;/strong&gt;即：人们如何才能够确使那些为每个社会成员所知道的资源得到最佳使用的问题，也就是&lt;strong&gt;如何才能够以最优的方式把那些资源用以实现各种唯有这些个人才知道其相对重要性的目的的问题&lt;/strong&gt;。&amp;rdquo; 而 &amp;ldquo;&lt;strong&gt;有关各种情势的知识&lt;/strong&gt;（the knowledge of the circumstances），从来就不是以一种集中的且整合的形式存在的，而&lt;strong&gt;仅仅是作为所有彼此独立的个人所掌握的不完全的而且还常常是相互矛盾的分散知识而存在的。&lt;/strong&gt;&amp;rdquo;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;即，因为真实世界的多样和复杂性，从事经济活动的人们在不同领域形成了专长和比较优势，有了社会分工和交换，这是我们经济活动的基本结构；同时，从事不同领域经济活动的人们也形成了对该领域专门的认知、经验和知识，即上一段所说的 &amp;ldquo;&lt;strong&gt;分散知识&lt;/strong&gt;&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这些 &amp;ldquo;分散知识&amp;rdquo;，是在每一个有传承的行业群体中，由该行业的第一代人开始发现，经由后面的每一代人继续发现、积累和传承，到目前我们所处的这一代人脑中。这些 &amp;ldquo;分散知识&amp;rdquo; 通常以行业最佳实践、行业标准操作流程（SOP）、行业操作守则、该行业核心群体视之为财富的经验和认知等形式存在，是该行业的核心知识，为该行业的核心群体所护卫，会被严格控制传播范围，不会轻易传播为大众所知。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这些 &amp;ldquo;分散知识&amp;rdquo;，正是各个行业的从业人群，在此行业的经济活动中谋得成果和经济利润的信息和知识基础。目前我们可以看到，各个行业的 &amp;ldquo;分散知识&amp;rdquo;，都正在被上传到由 agent 构成的数字层中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数字层中的 agent 可以执行经济任务，&amp;ldquo;分散知识&amp;rdquo; 被上传至数字层后，将通过数字层中亿万个 agent 持续发挥作用。未来，当数字层执行的经济任务在人类所有经济任务中占比达到大部分或者绝大部分时，&lt;strong&gt;是否意味着，&amp;ldquo;分散知识&amp;rdquo; 的发现、积累和传承，将主要在数字层中进行？&lt;/strong&gt;这些过程与之前人类的这类过程有什么区别？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十五：&amp;ldquo;数字层&amp;rdquo; 将如何帮助、提升、增强用户？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从有计算机开始，人们就希望计算机能够辅助和增强人类，如 &amp;ldquo;互联网之父&amp;rdquo; J.C.R. Licklider 在 1960 年的经典论文《Man-Computer Symbiosis》指出，计算机的价值在于&lt;strong&gt;放大&lt;/strong&gt;（amplify）&lt;strong&gt;人类思考与推理的能力&lt;/strong&gt;，计算机应该作为人类的 &amp;ldquo;认知放大器（cognitive amplifier）&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;有限理性&amp;rdquo; 的提出者赫伯特・西蒙认为，&lt;strong&gt;人类认知能力受限于注意力、记忆、计算能力&lt;/strong&gt;，因此是 &amp;ldquo;有限理性&amp;rdquo;；&lt;strong&gt;计算机&lt;/strong&gt;可以&lt;strong&gt;提供搜索、计算、模拟与信息组织能力&lt;/strong&gt;，因此能够扩展（amplify）人类的有限理性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 全面辅助人与物理世界的互动，进一步&lt;strong&gt;提高人类 &amp;ldquo;收集信息 - 决策 - 行动&amp;rdquo; 全链条的理性化程度&lt;/strong&gt;，是人类理性化的再一次重大进展；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;具体而言，人们作为 AI 产品的用户，已经可以感受到 Chatbot 和 Agent 在信息搜集、信息整理、逻辑化分析、形式化推理、无偏差实时执行、自我反思、反馈闭环方面的优秀功能，这些功能可以在各个实际场景帮助、提升、增强用户；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;同时，&amp;ldquo;数字层&amp;rdquo; 拥有上限非常高的智商和情商，可以&lt;strong&gt;作为普惠的、贴身的导师，帮助每个人成为更优秀的自己&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十六：具体而言，什么样的公司，会是构成 &amp;ldquo;数字层&amp;rdquo; 的有力竞争者？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;这会很大程度上很具体的决定，未来二十年我们生活在一个什么样的数字世界当中，由谁向我们提供数字世界的基础设施；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;互联网平台公司、基座模型公司、手机公司、AI 硬件公司、垂类 AI Agent、机器人公司&lt;/strong&gt;都是构成 &amp;ldquo;数字层&amp;rdquo; 的有力竞争者；谁会胜出？在什么时候？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十七：看起来，构成 &amp;ldquo;数字层&amp;rdquo; 的公司们，大部分以前也存在，为什么现在要单独以 &amp;ldquo;数字层&amp;rdquo; 来理解他们呢？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们在文章中提到，在人类活动数字化进程的第一阶段，互联网时代和移动互联网时代，数字世界起到的最大的作用是匹配，思考和决策还是需要人脑来做，数字世界不能单独闭环地完成工作；在人类活动数字化进程的第二阶段，数字世界可以闭环完成 &amp;ldquo;收集信息 - 决策 - 行动&amp;rdquo; 链条，便可以作为人和物理世界互动当中的 &amp;ldquo;代理层&amp;rdquo;，也就是文中提出的 &amp;ldquo;数字层&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;为什么&lt;strong&gt;人一定会把大部分与物理世界的互动交由经过这个 &amp;ldquo;代理层&amp;rdquo; 来处理呢&lt;/strong&gt;？因为这个 &amp;ldquo;代理层&amp;rdquo; 可以增强人的理性和行动能力从而提高效率，以及降低交易成本；在这几件事情上，有 &amp;ldquo;数字层&amp;rdquo; 和没有 &amp;ldquo;数字层&amp;rdquo; 的差异巨大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十八：&amp;ldquo;数字层&amp;rdquo; 会成为经济和社会的一个基础设施吗？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在个体意义上，&amp;ldquo;数字层&amp;rdquo; 是个人和物理世界之间新出现的 &amp;ldquo;一层&amp;rdquo;，可以极大增强个人行动的理性和行动能力，增强到 &amp;ldquo;数字层&amp;rdquo; 出现之前个人很难达到的程度；同时降低经济活动的交易成本；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;因此在总体意义上，&amp;ldquo;数字层&amp;rdquo; 是个人和物理世界之间新出现的 &amp;ldquo;一层&amp;rdquo;，在本文问题四的 AI 扩散完成后，&lt;strong&gt;一种可能性是，大部分的经济活动都会通过 &amp;ldquo;数字层&amp;rdquo; 来完成&lt;/strong&gt;，&amp;ldquo;数字层&amp;rdquo; 会成为整个经济和社会中重要的基础设施。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十九：我们当前处在 &amp;ldquo;数字层&amp;rdquo; 发展的什么时间点上？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;就 &amp;ldquo;数字层&amp;rdquo; 的出现，保证让 &amp;ldquo;数字层&amp;rdquo; 造福于人类而言，我们目前处在一个非常重要、同时也非常短暂的窗口期；&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果我们齐心协力往正确的方向推动，&amp;ldquo;数字层&amp;rdquo; 可以成为人类能力的 &amp;ldquo;放大器&amp;rdquo;、&amp;ldquo;增强器&amp;rdquo;，让机器智能补足人类的短板，同时核心的、终局的决策和权限保留在人类手中；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但另一方面，也存在 &amp;ldquo;数字层&amp;rdquo; 脱离我们控制，以及 &amp;ldquo;数字层&amp;rdquo; 的红利仅为少数人享有的风险，这是人类在这个阶段需要协力解决的重大问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;范式变化：整个经济活动范式从 &amp;ldquo;人的认知和经验&amp;mdash;行动&amp;mdash;经济产出&amp;rdquo; 变为 &amp;ldquo;使用电力和调用算力的 AI 大模型计算&amp;mdash;行动&amp;mdash;经济产出&amp;rdquo;。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题二十：AI 大模型商业形态的终局：在能源、算力、基座模型、应用之间的价值分配是怎么样的；通俗的话来说，用户所付的一块钱，是如何在以上四层之间分配的？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;目前我们处在 AI 经济刚刚启动的阶段，&lt;/strong&gt;我们能看到的是，&lt;strong&gt;行业在基座模型研发和算力消耗上投入了大量的花销，应用层的价值占比还很小，AI 计算尚未引起（局部或全局）的能源价格上涨&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们&lt;strong&gt;希望知道在 AI 大模型商业形态来到稳态&lt;/strong&gt;的时候，&lt;strong&gt;以上四层的价值分布&lt;/strong&gt;，以便于我们推断 AI 经济将给整个经济系统如何带来影响。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;目前可以预见的是，算力、模型层有显著的价值分配占比，且全球算力、模型层只有数量不多的一些公司，那意味着全球 GDP 的一定比例会流入这些公司，这些公司会有巨额收入和利润。我们应该如何理解和应对这样巨额的收入和利润？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十一：AI 将按照怎样的顺序，具备从事不同职业的工作能力？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;自 AI 具备泛化地交付工作能力以来，AI 在交付的工作，目前主要是代码、计算机、数学、文生图 / 视频、设计、教育、线上销售等纯线上工作，以及机械化、重复性的脑力工作如笔记整理、发票整理、账目整理等工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果我们将所有职业列表出来，&lt;strong&gt;AI 将按照什么样的顺序，具备每一项职业所需要的工作能力&lt;/strong&gt;？总的来看，AI 能够完成的工作，具有任务清晰可形式化、输入输出标准化、评价函数明确、能力可通过数据规模提升等特点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于该时间表和发展顺序的合理估计，将有助于我们应对接下来要发生的系列变化。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十二：AI 对就业的冲击将如何发生？一个预估全景图&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如问题二十七所述，AI 具备泛化地交付工作能力之后，会具备越来越多的职业所需要的工作能力，也就会在客观上形成对原有就业的替代；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;有了以上 &amp;ldquo;AI 如何具备不同行业工作能力&amp;rdquo; 的路线图，我们将&lt;strong&gt;有能力绘制 &amp;ldquo;AI 对就业的冲击将如何发生&amp;rdquo; 的预估全景图&lt;/strong&gt;，以了解和清楚 AI 造成的就业替代将会如何发生；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这个预估全景图首先是&lt;strong&gt;告诉我们未来的全景是怎么样的&lt;/strong&gt;，影响的量级有多大，为此我们需要做什么样的心理准备；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其次，预估全景图&lt;strong&gt;是一个评价和纠正体系&lt;/strong&gt;，让我们知道相较于全局，我们此刻在哪，我们是否偏离了已预见的航道，如何调整，是否有调整的工具；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当然，我们会根据实际的进展情况，定期来评估和更新这个预估全景图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十三：会否形成初级工作的 &amp;ldquo;真空地带&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;目前 AI 对初级工作的替代已经开始了，在这些工作领域，会否形成初级工作的 &amp;ldquo;真空地带&amp;rdquo;？即对于人类有需求的职位直接从中级开始，年轻人没有了上手的工作，年轻人失去了职业发展的初始路径，这是需要仔细解决的问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十四：工作逻辑的变化：&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系正在形成当中&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在&lt;strong&gt;由人执行的经济活动中，单个劳动力是最小的行动单元&lt;/strong&gt;，且单个劳动力需要长期稳定从事某个工作，因此工作可被拆分的最小单元是职业 / 职位 / 工种，&lt;strong&gt;人类的工作是以职业为基本单元&lt;/strong&gt;；在由 &lt;strong&gt;AI Agent 执行的经济活动中&lt;/strong&gt;，最小的执行单元是 &amp;ldquo;一个任务&amp;rdquo;，因此&lt;strong&gt;工作可被拆分的最小单元是任务&lt;/strong&gt;。&amp;ldquo;任务&amp;rdquo; 是远比 &amp;ldquo;职位 / 工种&amp;rdquo; 更小的执行单元。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当 AI 在整个经济活动中承担的工作占比越来越大之后，工作的基本单元，会日渐从职业变化为任务。&lt;strong&gt;整个工作体系可能从 &amp;ldquo;以职业 / 职位为中心&amp;rdquo; 向 &amp;ldquo;以任务为中心&amp;rdquo; 转变&lt;/strong&gt;，&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系正在形成当中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系将使得工作的颗粒度更细，经济活动将被划分为可被更加细密排列的基本单元，从而提高经济活动的效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;职业可以被拆解为任务，也意味着人仍然作为职业主体的情况下，原来由其负责的任务，可以被 AI 来完成。这也是一种形式的人机协同。一方面，这是工作场景中 &amp;ldquo;AI 协助人&amp;rdquo; 的很好的形式，AI 完成一部分任务，人完成另一些 AI 尚不能完成的任务，并且管理 AI；另一方面，我们也需要防范一种可能性，即职业主体仍然是人，但是其负责的任务都已经是 AI 来完成，&amp;ldquo;每天坐在工位前的还是我，但是有价值的活都是 AI 在干了，我只是在看着它干活&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系，将带来众多深远的影响，需要我们进一步探讨。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;一个人机共生、AI 作为工作同事的阶段正在到来。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题二十五：正在出现当中的 AI 员工&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 具备（泛化）交付工作的能力之后，这些具备工作能力的 AI，可以成为实际意义上的 &amp;ldquo;AI 员工&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 员工都具备哪些特点？AI 员工与人类员工的区别有哪些？哪些行业将率先拥有 AI 员工？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十六：组织中的 AI 员工&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;可以预见，在我们的各类组织（如公司、非营利组织、政府等）中，都会出现 AI 员工；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 员工将给组织的管理带来哪些变化？如 AI 员工的招聘、培训、考核，都会是什么样的？AI 员工将如何与人类员工分工协作？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 员工将如何改变组织，带来组织形态的哪些变化？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十七：广大的中小企业可以因为 AI 员工获得较之前更强的竞争能力吗？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;当前使用了 AI Agent 参与工作流程的中小企业，反馈他们认为自己获得了远超过当前人类员工人数的工作能力；广大的&lt;strong&gt;中小企业可以因为 AI 员工，获得较之前更强的竞争能力&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中小企业竞争能力的增强，有可能提高初创企业创业成功的概率，可能使得更多大公司的核心员工成立自己的公司，可能使得某些经济领域的重要资源更广泛地分布。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 可能成为一个细颗粒度、高频、跨主体的经济感知-决策-执行层。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题二十八：AI 经济阶段的经济统计是怎么样的？数字层将如何影响经济统计？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;随着越来越多的经济活动以数字化的形式进行，越来越多的经济活动经由 &amp;ldquo;数字层&amp;rdquo; 执行，经济活动中那些物理世界的属性，将越来越多地体现为数字世界的属性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;数字层&amp;rdquo; 的细颗粒度、高频、跨主体特点&lt;/strong&gt;，可能会为我们提供更丰富的经济统计工具，相应地提高经济统计的颗粒度、频次，并让我们可能更容易拥有全局的统计结果。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十九：AI 经济是否可以一部分地平抑经济周期？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;经济周期&lt;/strong&gt;的形成，与&lt;strong&gt;信息不完全、价格和数量调整摩擦、预期与金融放大&lt;/strong&gt;都有关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 &amp;ldquo;数字层&amp;rdquo; 成为经济活动的基础设施之后，&amp;ldquo;数字层&amp;rdquo; 对以上三个环节都能起到缓解和改善的作用：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 全面了解消费者和生产者等经济主体，也全面了解物理世界，可能降低经济状态空间的不可观测性，从而可能降低当前经济活动中信息不完全的程度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 可能实现微观层面的连续调节，把当前由人脑判断做出的调节档位提升数个数量级的精度，从而降低价格和数量调整的摩擦；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 连接经济活动的全局，可能实现全局协调和跨期协调，可能降低当前经济活动中个体对于信号的主观放大带来的波动性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十：我们应该如何发挥好 &amp;ldquo;数字层&amp;rdquo; 的优势，尽量避免其潜在的弊端？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&amp;ldquo;数字层&amp;rdquo; 细颗粒度、高频、跨主体的特点，将为我们带来一个较现在颗粒度更细、频次更高、更容易得到全局信息的经济基础设施；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但同时，这些特点也带来一些潜在的风险，如高频执行的频次远超人脑可以反应的范畴，过去在金融量化系统中也曾造成过人脑来不及反应的 &amp;ldquo;闪崩&amp;rdquo;；如何增强 &amp;ldquo;数字层&amp;rdquo; 的稳定性，是需要多方共同努力的课题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十一：是否以及如何设计经济系统中新的政策工具？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;就已经开始显现的 AI 对就业的冲击，我们应该如何设计劳动力的 AI 培训、促进新岗位产生等缓冲机制？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更一般地，当前经济系统中的调节工具，即诞生于工业革命以来的财政工具和税收工具，能否适配 AI 经济的特点？如果不能完全适配的话，我们应该如何设计新的政策工具？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十二：如何设计社会财富再分配体系？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 AI 经济阶段，大量经济活动的成果积累在模型层和头部的应用层公司，社会财富的分配存在失衡的风险；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;同时，大部分劳动的价值被压缩；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何设计有效的社会财富再分配体系？这是我们需要面对的重大课题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;人类发展的一个历史规律是，那些能显著提高人类生产力和生活水平的技术进步，最终会扩散到全世界，遍布这个星球。AI 也是如此。世界各国会或先或后地进入 AI 在其整个经济活动中起重要作用的阶段。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题三十三：世界各国将以什么样的顺序进入 AI 经济阶段？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 大模型服务、AI 应用服务、AI 算力基础设施，将以什么样的顺序，先后抵达全球所有国家？世界各国将以什么样的顺序进入 AI 经济阶段？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十四：如何评价一个经济体的 &amp;ldquo;经济社会被 AI 赋能&amp;rdquo; 的程度？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们需要一套体系，&lt;strong&gt;来评价一个经济体的 &amp;ldquo;经济社会被 AI 赋能&amp;rdquo; 的程度；&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该体系初步的指标包括企业的 AI 使用率（特别是中小企业）、AI 在企业业务流程中的覆盖比例、Agent 部署密度、企业员工人均 AI 交互频次、居民人均 AI 交互频次等；仍需要进一步构建；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该评价体系可以让各经济体对于自己处在 AI 经济发展的哪一个相对位置，有更清晰的判断，便利于这些经济体制订自己的 AI 经济发展计划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该评价体系也可用于国际组织评价全球不同国家地区的 AI 发展情况。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十五：什么是 &amp;ldquo;AI 充裕经济体&amp;rdquo;/&amp;ldquo;AI 充裕社会&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于以上评价体系，我们可以建立 &amp;ldquo;&lt;strong&gt;AI 充裕经济体&lt;/strong&gt;&amp;rdquo; 和&lt;strong&gt; &amp;ldquo;AI 充裕社会&amp;rdquo;&lt;/strong&gt; 的概念。这样的经济体，是&lt;strong&gt;一个 AI 被充分、适当地使用，AI 充分赋能经济和社会发展的经济体，AI 可以为该经济体带来人类可欲的结果&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;是否 &amp;ldquo;AI 充裕&amp;rdquo;，可能成为下一个阶段评价一个国家竞争力的重要指标，也是评价 &amp;ldquo;发达国家 / 发展中国家&amp;rdquo; 的一个重要角度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;电力、算力、模型将成为各国家的战略资源。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十六：&amp;ldquo;AI 欠充裕经济体&amp;rdquo; 和 &amp;ldquo;AI 匮乏经济体&amp;rdquo;，应该采用什么样的发展和追赶策略？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 的发展需要&lt;strong&gt;能源、算力、数据、算法&lt;/strong&gt;四个层面的配合建设。一个经济体需要以稳定、充足、低成本的电力供应作为基础，在本地建设足够规模的算力中心，结合本经济体已经积累的互联网数据、各行业业务数据、政府数据，通过调用闭源或者开源基座模型服务，建设该经济体的 AI 能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;具体到某一个国家和地区，需要在能源、算力、数据、算法四个层面评估本国 / 本地区的基础和现状，制订合理、有效、前期成本可控的发展和追赶策略；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型研发、AI 应用研发、标准制定、平台治理可能都发生在 &amp;ldquo;AI 充裕国家&amp;rdquo;；&amp;ldquo;AI 欠充裕经济体&amp;rdquo; 和 &amp;ldquo;AI 匮乏经济体&amp;rdquo; 可通过模型本地化、建设区域算力节点来补齐 AI 能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十七：AI 经济会带来国际分工、国际供应链的哪些变化？不同国家占全球 GDP 的比例，将如何变化？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;传统国际分工是基于各国不同的技术差异、劳动力等要素禀赋差异，这些差异是国际分工的前提，也塑造了国际分工的形态；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 AI 经济阶段，全球 Agent 和机器人建立在同一个 &amp;ldquo;数字层&amp;rdquo; 之上，&lt;strong&gt;全球 Agent 和机器人的工作能力将趋同，传统国际分工的要素禀赋差异前提可能被改变&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 AI 经济阶段，&amp;ldquo;&lt;strong&gt;按任务划分的经济活动的全球最优分配&lt;/strong&gt;&amp;rdquo;，是国际分工逻辑的可能性之一；&lt;strong&gt;不同国家在 &amp;ldquo;关键任务节点的不可替代性&lt;/strong&gt;&amp;rdquo;&amp;nbsp;可能成为国家之间分工的重要因素。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;国际分工变化之后，各国在全球 GDP 中占比的逻辑也会发生变化；以及，我们应该如何应对这种变化带来的影响？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十八：对于 AI 经济阶段，全球算力和能源需求的预估&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在以上背景下，全球算力需求将以什么样的速度增长？我们是否会遇到算力供给的瓶颈？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;激增的算力需求将给能源供应带来哪些变化？我们是否会遇到能源 / 电力供给的瓶颈？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十九：我们是否可能，以及如何设定 AI 与人的能力分工？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;目前我们看到的情况是，AI 可以把数据类、分析类的工作做得比人好，而人类在情感、感受、共情、审美、创造力等领域仍然保持绝对优势。这个局面能长期保持吗？或者说，&lt;strong&gt;基于神经网络的大语言模型，其思维能力的边界在哪里&lt;/strong&gt;？是否存在一些领域，AI 永远也追不上人脑的能力？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果有的话，这些领域是什么？如何定义这些领域？&lt;strong&gt;计算机的精确性和人脑的模糊性，是天然的划分标准之一吗？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果没有的话，&lt;strong&gt;我们是否应该、是否可能设定一条界限，让 AI 的能力停留在这条界限的一侧？如何设定这条界限？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;让人类保有&lt;strong&gt;价值设定、目标设定、判断力、创造力、情感交流、审美、对 AI 的监督 / 管理 / 最终控制权&lt;/strong&gt;，是否这条界限的一个答案？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何确保所有的 AI 大模型开发商和开发者，都遵循这条界限？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题四十：&amp;ldquo;非稀缺经济&amp;rdquo; 实现后的闲暇消费和生活意义问题&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 具备泛化地交付工作能力之后，人类会有可能拥有一个 &amp;ldquo;非稀缺经济&amp;rdquo;。在约一百年前，&lt;strong&gt;凯恩斯&lt;/strong&gt;敏锐地看到了这一点，在《我们后代在经济上的可能前景》中，他写道：&lt;strong&gt;&amp;ldquo;我们的天性 &amp;mdash;&amp;mdash; 包括我们所有的冲动和最深层的本能 &amp;mdash;&amp;mdash; 为了解决经济问题而进化发展起来的。如果经济问题得以解决，那么人们就将失去他们传统的生存目的&lt;/strong&gt;&amp;rdquo;。&amp;ldquo;经济问题、生存竞争，一直是人类首要的、最紧迫的问题 &amp;mdash;&amp;mdash; 不仅是人类，而且在整个生物界，从生命的最原始形式开始莫不如此&amp;rdquo;。&amp;ldquo;长久以来，我们都是被训练着去奋斗而不是去享受 &amp;hellip;&amp;hellip; 当他再也不能在传统社会的温床和他所珍视的那些风俗习惯中找到自己的根基时，这个问题就显得尤为严重。&amp;rdquo;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;人类自从出现以来，第一次遇到了他真正的、永恒的问题 &amp;mdash;&amp;mdash; 当从紧迫的经济束缚中解放出来以后，应该怎样来利用他的自由？科学和复利的力量将为他赢得闲暇，而他又该如何来消磨这段光阴，生活得更明智而惬意呢？&amp;rdquo;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;凯恩斯也提出了具体的建议，他认为 &amp;ldquo;任何人如果想要生活得舒心畅意，那么他就必须得干一点工作。&amp;rdquo; 他甚至提出了 3 小时工作制：&amp;ldquo;3 小时一轮班或每周 15 小时的工作，也许会使上述问题在相当长一段时间内得以缓解&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;诚如凯恩斯所写，&lt;strong&gt;人基于千万年的遗传形成的生物性，在短期内是难以改变的，但是 AI 改变经济的节奏可能是快速的&lt;/strong&gt;。如果 &amp;ldquo;非稀缺经济&amp;rdquo; 到来，&lt;strong&gt;在工作之外，新的、能使人们在闲暇中获得满足感的活动是什么，对于人类群体的人生意义该如何定义&lt;/strong&gt;，以及如凯恩斯所考虑，是否应该设计新的工作时长机制以&lt;strong&gt;使人对于工作的生物性本能得到部分承接&lt;/strong&gt;，都是需要认真思考的经济、社会和哲学问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者王捷，中国初代 AI 投资人，完整经历了移动互联网各个发展和投资阶段， 2017 年以来主要从事 AI 行业投资，投资了摩尔线程、比亚迪半导体、万国数据、京东科技、开思时代、奇安信、明略科技等公司。作者邮箱 jie_wang7@sina.com，微信如下，欢迎交流，添加请说明工作/学习机构、职务信息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibezJs5hKgvAnq6m4dDBleLtQVHNEooe08JQ2oZ6XLNw8KiciaribUMTUVyw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="1.0204081632653061" data-s="300,640" data-type="jpeg" data-w="1029" type="block" data-imgfileid="503526268" data-aistatus="1" data-original-style="width: 118px;height: 120px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/503f554b-adf8-44aa-bbbe-1d0b3edb8a9a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>三维空间太难懂？RoboTracer让机器人理解复杂空间指令，推理3D空间轨迹，开放世界也能精确行动</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 30 Dec 2025 20:24:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-10</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;tp=webp#imgIndex=0" alt="图片" data-ratio="0.5703703703703704" data-w="1080" data-backw="562" data-backh="321" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3e7840c4-3ad6-4a50-a5b6-c98012fb7379/640.png" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;本文的主要作者来自北京航空航天大学、北京大学、北京智源人工智能研究院和中科院自动化研究所。本文的第一作者为北京航空航天大学博士生周恩申，主要研究方向为具身智能和多模态大模型。本文的共一作者兼项目负责人为北京智源研究院研究员迟程。本文的通讯作者为北京航空航天大学教授盛律和北京大学计算机学院研究员、助理教授仉尚航。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们希望具身机器人真正走进真实世界，尤其走进每个人的家里，帮我们完成浇花、收纳、清洁等日常任务。但家庭环境不像实验室那样干净、单一、可控：物体种类多、摆放杂、随时会变化，这让机器人在三维物理世界中「看懂并做好」变得更难。&lt;/p&gt;&lt;p&gt;想象一下你下班回到家，对家用服务机器人说： 「按从左到右的顺序给每盆花浇水；喷壶要在每朵花上方 1&amp;ndash;5 厘米处停住再浇，这样更均匀。」（如下图）&lt;/p&gt;&lt;section&gt;&lt;a href="https://mp.weixin.qq.com/s/GoOby4U9nUOEgIxw2NgPLQ"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZVbLkz0bMsfO3ibNSrkKAwFQiaL0qkbKQhMPFDibx53tBnFxbFd8zcI7tA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3469879518072289" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="201" data-imgfileid="503525422" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/45111ab2-f826-4e89-96b0-0b990794db58/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;对人来说这很自然，但对机器人来说，难点不在「浇水」本身，而在指令里隐含了大量空间约束：既有&lt;strong&gt;定性&lt;/strong&gt;的（从左到右、在上方），也有&lt;strong&gt;定量&lt;/strong&gt;的（1&amp;ndash;5 厘米）。在杂乱的开放世界场景中，让机器人稳定遵循这些约束，哪怕对目前最先进的视觉 - 语言 - 动作模型（VLA）也依然是挑战。&lt;/p&gt;&lt;p&gt;一个直接的突破口是：让视觉 - 语言模型（VLM）生成一条满足这些空间约束的 3D 位置序列 &amp;mdash;&amp;mdash; &lt;strong&gt;空间轨迹（Spatial Trace）&lt;/strong&gt;。它相当于一座桥梁：既能把「指令在 3D 空间中如何被理解与执行」的过程表达清楚，也能进一步用来指导机器人生成可执行的动作轨迹。但空间轨迹生成本质上非常困难，因为它需要在 3D 场景里进行&lt;strong&gt;多步、带真实尺度约束的推理&lt;/strong&gt;，并且每一步都要同时具备两种关键能力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3D 空间指代&lt;/strong&gt;：理解指令中的&lt;strong&gt;各种空间关系&lt;/strong&gt;，并在 3D 场景中&lt;strong&gt;准确指代定位相关物体&lt;/strong&gt;（例如按「从左到右」依次找到每盆花）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3D 空间度量&lt;/strong&gt;：理解现实世界的&lt;strong&gt;绝对尺度并做计算&lt;/strong&gt;（例如估计花的物理高度，确定其上方 1&amp;ndash;5 厘米对应的具体 3D 位置）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;遗憾的是，现有很多 VLM 工作主要集中在 2D 空间推理或 2D 视觉轨迹生成：一方面往往&lt;strong&gt;弱化了轨迹生成最关键的「多步推理」过程，尤其缺少对中间关键对象的显式建模&lt;/strong&gt;，容易导致结果次优；另一方面输出多停留在 2D 像素坐标，&lt;strong&gt;缺乏 3D 指代定位与绝对尺度理解&lt;/strong&gt;。这也造成了 2D 视觉轨迹与 3D 空间轨迹之间的根本鸿沟。&lt;/p&gt;&lt;p&gt;为了解决这一问题，北京航空航天大学、北京智源人工智能研究院、北京大学等机构联合推出了具备 3D 空间理解与推理能力的多模态大模型 &amp;mdash;&amp;mdash;RoboTracer。RoboTracer 通过&lt;strong&gt;全参数微调（SFT）&lt;/strong&gt;强化空间信息的精准理解（空间感知 / 度量 / 指代），并进一步用&lt;strong&gt;强化学习微调（RFT）&lt;/strong&gt;提升推理与泛化能力，最终在&lt;strong&gt;开放世界场景中实现可用的 3D 空间轨迹生成&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZdjYfy48CH1aF2RdzibyTDY3foGVSdzprCrsb1edCeX4XsDqe1n5swgg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.35180722891566263" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="203" data-imgfileid="503525423" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/876890c5-35bc-4ad2-a9d6-386fa45f3dca/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.13660&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文标题：RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://zhoues.github.io/RoboTracer/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库：https://github.com/Zhoues/RoboTracer&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;评测链接：https://huggingface.co/datasets/JingkunAn/TraceSpatial-Bench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是真机实拍的机器人浇花过程，包含&lt;strong&gt;多步、带真实尺度约束的推理&lt;/strong&gt;：&lt;a href="https://mp.weixin.qq.com/s/GoOby4U9nUOEgIxw2NgPLQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f9cbd93b-6aa4-4276-94b1-d67410df387e/1767097050323.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;SFT 训练下的 RoboTracer 在空间理解 / 空间度量 / 空间指代任务中达到了 &lt;strong&gt;79.1% 的平均成功率&lt;/strong&gt;，刷新了当前最先进水平。而在研究者提出的高难度空间轨迹生成任务评测基准&lt;strong&gt;&amp;nbsp;TraceSpatial-Bench&lt;/strong&gt; 上，RFT 训练后的 RoboTracer 更是&lt;strong&gt;领先所有其他模型，比 Gemini-2.5-Pro 高出 36% 的平均准确率&lt;/strong&gt;，优势显著。&lt;/p&gt;&lt;p&gt;更关键的是，RoboTracer 直接做到「开箱即用」：可以&lt;strong&gt;灵活集成到不同类型的机器人上&lt;/strong&gt;，比如 UR5 机械臂、G1 仿人机器人等，在真实环境中完成&lt;strong&gt;复杂、动态、多步骤任务&lt;/strong&gt;，让机器人真正做到「听得懂、看得清、动得准」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RoboTracer 是什么？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZNZFIvljLeqnQOO8icKu0DiaZuwJArJB6xRPoIzfPfibFRldSTxOQicXJWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.47494033412887826" data-s="300,640" data-type="png" data-w="838" type="block" data-backw="578" data-backh="275" data-imgfileid="503525432" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6e23a344-3077-497d-a6f7-3a8a8b0e757d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;RoboTracer 是一个&lt;strong&gt;三维空间理解与推理能力&lt;/strong&gt;的多模态大模型，其拥有单独的图片编码器和&lt;strong&gt;支持任意多几何输入（绝对深度图，相机内参）的空间编码器&lt;/strong&gt;。该模型具备较完备的空间感知推理能力，不仅仅可以回答各种&lt;strong&gt;空间感知类问答&lt;/strong&gt;，无论是「哪个物体在左边？」这样的定性问题，还是「这个物体高度是多少？」这样的定量问题，并且还预测当前场景的尺度缩放因子；更厉害的是，它还可以基于 3D 空间指代和 3D 空间度量进行，&lt;strong&gt;复杂的组合式推理&lt;/strong&gt;，最终&lt;strong&gt;准确生成精确的空间轨迹&lt;/strong&gt;（如上图，逐一从左到右确定每一盆花的 3D 位置及其高度）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RoboTracer 的核心是什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么相较于以往的方法，RoboTracer 不仅可以精确的感知空间，而且又可以根据多个空间关系组合泛化进行带真实尺度约束的推理呢？其关键因素在于以下几点：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解耦 (u, v, d) 表达增强多任务学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统方法直接回归 (x, y, z) 坐标，往往要求模型强行根据单目图片预测复杂的相机几何信息（比如相机内参），导致训练难、精度低。RoboTracer 提出了一种符合具身场景的解法：&lt;strong&gt;利用 (u, v, d) 进行解耦表达&lt;/strong&gt;。这种表示法利用图像像素 (u, v) 和深度 d，结合已知的相机内参，轻松换算真实 3D 坐标。其核心优势在于：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 降低学习门槛&lt;/strong&gt;：不用让 VLM「硬学」复杂的相机几何信息，训练更简单，精度也更高。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 数据复用能力更强&lt;/strong&gt;：(u, v, d) 很容易投影到更低维的任务上 &amp;mdash;&amp;mdash; 去掉 d 就变成 2D 轨迹；只保留起点 / 终点，又能构造成 2D/3D 的空间指代数据。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通用空间编码器与尺度解码器提升绝对尺度感知&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;想要精准定位物体、测量距离，模型必须理解「真实世界的尺寸」。但很多只用 RGB 训练的 &lt;strong&gt;VLM 缺少绝对尺度概念&lt;/strong&gt;，因此距离 / 尺寸容易估不准。为了解决这一点，研究者加入两个关键模块：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 尺度解码器&lt;/strong&gt;：将 &amp;lt;SCALE&amp;gt; token&amp;nbsp;&lt;strong&gt;直接回归&lt;/strong&gt;成一个数值尺度因子，把「尺度不变的特征」与「真实世界的绝对长度」对应起来。相比分类损失，&lt;strong&gt;用回归损失监督&lt;/strong&gt;更能提升对三维真实尺度的感知。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 通用空间编码器&lt;/strong&gt;：借助前馈式三维度量几何模型提供的&lt;strong&gt;强几何先验&lt;/strong&gt;，显著增强模型的空间与尺度理解。它还能&lt;strong&gt;按需融合&lt;/strong&gt;不同几何信息（如相机内参、位姿、深度）：几何信息越多，空间表示越精细。该设计带来两点好处：（1）&lt;strong&gt;训练更灵活&lt;/strong&gt;：通过灵活输入增强，把不同数据集中带尺度标注的信息用起来，提升空间学习效果（2）&lt;strong&gt;推理更自适应&lt;/strong&gt;：无需重新训练或改结构，就能融合当前可用的几何信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SFT 增强感知，RFT 搭配过程奖励提升推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RoboTracer 采用两阶段训练策略，其中 SFT 阶段针对性地提升模型的单步 3D 空间理解 / 空间度量 / 空间指代能力；RFT 阶段不仅关注最终轨迹结果的奖励，还创新性地设计度量敏感过程奖励，这些奖励函数能够显式监督轨迹生成中涉及的关键中间感知步骤（如 3D 指代、3D 度量和尺度预测）的质量。最终，模型增强了&lt;strong&gt;多步、带真实尺度约束的推理&lt;/strong&gt;，实现了对复杂空间约束任务的空间轨迹规划。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;提出 TraceSpatial 数据集 &amp;nbsp;教一个多模态大模型从0到1学会生成空间轨迹&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZiaMhwvsbkrNlPUxn1aJSjRZeaiaFE0h2B8QrSyO7X3nWerWWcaIdaQyw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4795180722891566" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="277" data-imgfileid="503525434" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/bfa9c211-6250-40c1-9864-6cc642aab910/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了支持前述的 SFT 和 RFT 训练，研究团队构建了一个大规模、高质量、带真实尺度的数据集 &amp;mdash;&amp;mdash;TraceSpatial，具有以下几个核心特点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;场景多样&lt;/strong&gt;：覆盖室内外和桌面环境，包含物体和末端执行器两种分别为中心的空间轨迹，后者包含 3 种不同的单臂 / 双臂机器人构型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;维度丰富&lt;/strong&gt;：包含大量尺度相关数据（占 48.2%），还附带详细的多步推理过程（最高有 9 步），为复杂空间轨迹生成提供支持。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;规模庞大&lt;/strong&gt;：共包含 450 万个样本、3000 万个问答对，目前最大 3D 空间数据集。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;精细标注&lt;/strong&gt;：每个物体都配有层级式描述，从「花」这类种类类别，到像「左数第一个盆花」这样的精确空间指代，确保在复杂场景中也能清晰用文字表述。同时包含大量绝对尺度的几何信息标注（比如相机内参、深度图）以支持灵活的输入增强。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;高质量筛选&lt;/strong&gt;：数据经过严格筛选，确保标注准确、语义清晰。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;易于扩展&lt;/strong&gt;：支持从多种来源生成空间轨迹数据，包括 2D 图像、3D 扫描数据和机器人操纵视频，具备高度扩展性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;RoboTracer 到底有多厉害&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;空间理解 / 空间度量 / 空间指代&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SFT 训练下的 RoboTracer 在空间理解 / 空间度量 / 空间指代任务中达到了 &lt;strong&gt;79.1% 的平均成功率&lt;/strong&gt;，取得了当前最先进水平，&lt;strong&gt;比 Gemini-2.5-Pro 高出 11% 的平均准确率&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZlV0IsBZia7hNLsBr48HBFkXqzK1jP7ib3o9qib5RSGPnlDzRudPcN9DbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3472222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="201" data-imgfileid="503525437" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/31ce6804-9a7b-45b8-b806-a7242204da01/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZLlf1wUqCH9yKbGccHPPQo5Je0yw9icgKxqgPtPHO3JublY1orlDcLmw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.29259259259259257" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="169" data-imgfileid="503525439" data-aistatus="1" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3219a333-b102-452f-bddf-bd7ef9e88ea1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;空间轨迹评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RFT 训练后的 RoboTracer 在研究者们提出的高难度空间轨迹生成任务评测基准 &lt;strong&gt;TraceSpatial-Bench&lt;/strong&gt; 上更是领先所有其他模型，&lt;strong&gt;比 Gemini-2.5-Pro 高出 36% 的平均准确率&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZw5UcWKAKzggcSYXOxfhRdux0SkI5zXnG8jvbCCOYg0ia1nXoWiaPF2rw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.67601246105919" data-s="300,640" data-type="png" data-w="642" type="block" data-imgfileid="503525440" data-aistatus="1" data-original-style="width:287px;height:194px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2138504c-ffad-40fc-a0f2-e20e0f13afa9/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;下面展示一些 RoboTracer 与其它模型输出结果的可视化样例，不难发现目前的 VLM 都理解空间关系并且生成 2D 轨迹，但是由于绝对深度预测不精确导致生成的空间轨迹往往浮空或者碰撞，而 RoboTracer 可以较为精确地预测，而且更多的几何输入预测结果更精确。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ2CuT3OOnDd7K4aMSBV5mDOTK8ck6pfaibXsLO9ds8gu7RicHESqQDBibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.35336538461538464" data-s="300,640" data-type="png" data-w="832" type="block" data-backw="578" data-backh="204" data-imgfileid="503525441" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/36b9660d-8cd2-4bfe-86a1-6aa9d276d490/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;仿真与真机实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在空间操控的机械臂仿真评测中，RoboTracer 的表现远超现有的视觉 - 语言 - 动作（VLA）系统。不仅在模拟环境中成功率遥遥领先，面对开放世界中需要&lt;strong&gt;多步、带真实尺度约束的推理的复杂任务，唯有 RoboTracer 能够完成&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZLuZiaApwc1EIu8WUU7LZPDn8umxxPzINtOUgNJDLmHPEib4Jf6k4aKXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5828220858895705" data-s="300,640" data-type="png" data-w="652" type="block" data-imgfileid="503525442" data-aistatus="1" data-original-style="width:384px;height:224px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/300c0f66-b090-4129-9819-5895df75fbf4/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZnR65ib8icbLIlokZruSHzBkYC6AU5uBXib7LgVPic2sTLNjpH1GkshGJBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3259493670886076" data-s="300,640" data-type="png" data-w="632" type="block" data-imgfileid="503525443" data-aistatus="1" data-original-style="width:380px;height:124px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/74754fc8-9ee2-4f5d-8d59-b04faa753f59/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7ebdb0bd-8135-4a26-91d3-cf00cb1afd01/1767097339125.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/section&gt;&lt;p&gt;更多的实验结果，可视化展示（包括更多的杂乱场景下的真机 Demo 视频的空间轨迹生成结果）详见论文和主页。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
