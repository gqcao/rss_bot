<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>告别「手动画框」！Medical SAM3：首个真正「纯文本提示」驱动的医学全能分割模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Wed, 21 Jan 2026 14:19:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;现有的通用医学分割模型往往只是「伪全能」，因为它们在没有人工提示框辅助时几乎寸步难行。&lt;/p&gt;&lt;p&gt;来自中佛罗里达大学（UCF), 宾夕法尼亚大学(UPenn), &amp;nbsp;伦敦大学学院（UCL）等机构的研究团队&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-top: 16px;margin-bottom: 0px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;近日&lt;/span&gt;发布了Medical SAM3，通过全参数微调与创新的分层训练策略，在 33 个医学数据集上实现了革命性突破：它不再需要医生手动画框，仅凭一句分割「肿瘤」的文本指令，即可在 CT、MRI、内镜等 10 种模态中实现专家级分割，将零样本场景下的平均准确率从 11.9% 暴涨至 73.9%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjfjh2wWpQWTMtuctniaqyY76UdojbTkI5YhAG9fUSyia9nyPvia5QkQxAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027204" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8e96ae43-e201-4041-a963-159cc1dfb73b/640.png" alt="图片" data-before-load-time="1768976276624" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接:&amp;nbsp;https://arxiv.org/abs/2601.10880&lt;/p&gt;&lt;p&gt;代码仓库:&amp;nbsp;https://github.com/AIM-Research-Lab/Medical-SAM3&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjN8jt9ic66V7fefK8NSUyAYWDJKdJc202dhN14W6iaewibDh4tjSiaM7qaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027210" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b727a955-0c72-484c-91b4-8cb6552fb4ac/640.png" alt="图片" data-before-load-time="1768976276657" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;核心痛点：以前的「通用模型」真的通用吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Medical SAM3 之前，许多「医学通用分割模型」在实际使用上存在一个关键前提：它们往往高度依赖空间提示（Spatial Prompts）&amp;mdash;&amp;mdash; 需要人工先提供 Bounding Box（边界框）或点击关键点，模型再在提示区域内完成分割。表面上看这只是交互方式的选择，但它也反映出能力边界：当模型必须先由人把目标「圈出来」，其主要贡献更接近于区域内的像素细化与边界优化，而非从整幅图像中完成稳定的语义定位与目标发现。&lt;/p&gt;&lt;p&gt;这种设定在演示场景中可以获得不错的效果，但在真实工作流里会带来明显的推广门槛：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;医生并不总能提前精确圈定病灶，尤其是边界模糊、形态复杂或早期难判的病例；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在筛查、急诊分诊或跨模态阅片等高通量场景下，逐张图像画框 / 点选会显著增加交互成本，难以规模化；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更重要的是，模型性能会对提示质量产生强依赖，系统的核心难题 &amp;mdash;&amp;mdash;「自动语义定位」&amp;mdash;&amp;mdash; 并未被真正解决。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;论文中的诊断性实验进一步量化了这一现象：当移除人工空间提示、仅通过文本询问（更接近「通用」的使用方式）时，原生 SAM3 在医学图像上的表现出现断崖式下降，平均 Dice 降至 11.9%，并在内镜息肉分割等任务中出现 0.0% 的失效案例。这说明模型在很大程度上把空间提示当作了近似「目标索引」；一旦失去该索引，它在复杂背景、低对比度、强噪声或形态多变的医学影像中就难以稳定定位目标。&lt;/p&gt;&lt;p&gt;因此，Medical SAM3 的核心贡献并非把分数再提高一点，而是试图跨过这条关键门槛：将医学分割从「提示驱动的区域细化」，推进到「仅凭文本即可触发的语义驱动分割」，让模型不再依赖人工先验的空间圈定。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjmCqgRUGxLicUcSSEtWCA7rnTyTTbsneQq7yKOKiaARWrompdMHnnUfpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027206" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/828fcd29-a534-4d5c-8627-50e5307eef2c/640.png" alt="图片" data-before-load-time="1768976276882" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;真正的「语义驱动」：不仅是微调，更是重塑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决医学影像「语义难对齐、结构极复杂、模态差异巨大」这一核心难题，Medical SAM3 没有走业界常见的轻量级适配器（Adapter/LoRA）捷径，而是选择了一条更艰难但也更彻底的路线 &amp;mdash;&amp;mdash; 全参数微调（Full Fine-Tuning）。团队的判断很明确：医学影像与自然图像之间不仅是外观风格的变化，更是成像物理、噪声统计、目标形态与语义体系的整体迁移；仅微调少量参数往往只能「学到一点风格」，却难以让模型真正理解医学场景中那些决定分割成败的细粒度概念（例如模糊边界、低对比病灶、细长结构的连通性、器官之间的解剖约束）。因此，Medical SAM3 通过全参数更新，让模型从底层特征到高层语义都能发生充分适配，从而实现更可靠的「语义驱动分割」。&lt;/p&gt;&lt;p&gt;但全参数微调带来的挑战同样显著：一旦训练策略不当，模型可能会遗忘原有的通用视觉能力，或在训练早期出现不稳定震荡。为此，Medical SAM3 引入了分层学习率衰减（Layer-wise Learning Rate Decay, LLRD）策略，以一种「既保守又激进」的方式精细控制迁移过程：浅层网络使用更小的学习率，尽可能保留通用的边缘、纹理与局部对比特征（这些对所有影像都有效）；而深层网络则使用更大的学习率，获得更强的可塑性，专门去学习医学影像中特有的语义与结构规律，例如「毛玻璃影」的弥散分布、内镜息肉与背景黏膜的微妙边界、视网膜血管的树状拓扑与连续走向。最终，这种「浅层稳住通用视觉、深层重塑医学语义」的迁移范式，推动模型完成了根本性跃迁：从过去高度依赖点 / 框等几何提示的交互式分割，转变为仅凭文本语义即可稳定分割的通用能力。&lt;/p&gt;&lt;p&gt;Medical SAM3 的强大并非只来自训练策略，更来自其构建的大规模、多模态训练底座。研究团队整合了覆盖 10 种成像模态的 33 个数据集，并通过统一的数据标准化与接口设计，使模型能够在 76,956 张高分辨率医学图像与 263,705 个精细掩膜上进行系统学习。尤其关键的是，Medical SAM3 采用了统一的 2D 高分辨率视角（Unified 2D Formulation）：无论输入来自 3D CT/MRI 的切片，还是 2D 的眼底、内镜或显微图像，均被统一处理为 1008&amp;times;1008 的高分辨率表示。这一设计带来两点直接收益：其一，它在工程上打通不同设备与模态的输入壁垒，降低跨域部署的不确定性；其二，它让模型获得更强的尺度一致性与细节表达能力 &amp;mdash;&amp;mdash; 从胸片中占据大面积的肺部轮廓，到电子显微镜下仅数十像素的细胞核边界，模型都能在同一框架下捕捉关键结构，形成真正「跨模态、跨尺度、跨任务」的统一分割能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjRhyic7Du3qb3xPSpzDib1IfmzhBTvRrIUPcCF506ibIic4c1waXHdA5naw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3888888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027208" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/db27f8aa-c2b7-434e-bb33-2c9cafb087f0/640.png" alt="图片" data-before-load-time="1768976276972" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;从内部精通到外部泛化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了系统验证模型的可靠性与可迁移性，团队构建了覆盖内部验证（in-domain）与外部测试（out-of-domain）的全面评估体系：前者检验模型在已覆盖医学分布上的稳定性与细节还原能力，后者则以「从未见过的数据集与模态」为压力测试，衡量其真实世界部署最关键的零样本泛化表现。&lt;/p&gt;&lt;p&gt;在内部验证环节，Medical SAM3 展现出对医学结构与边界细节的扎实掌握，平均 Dice 从 54.0% 提升至 77.0%。这一提升不仅意味着「更像」，更代表模型在像素级边界对齐、细小目标召回、低对比度组织分离等方面达到了更可靠的水平。尤其在视网膜血管分割这类典型「高难任务」中，原生模型常见问题是对细长结构缺乏连续性建模，容易出现断裂、漏检与噪点粘连；Medical SAM3 则显著改善了这一失败模式，将 Dice 从 24.8% 提升至 55.8%。更重要的是，提升并非只体现在分数上：模型不仅能「找到血管」，还能够更好地复原血管的连续走向、分叉拓扑与树状结构，这类结构完整性对后续临床分析（如血管密度、分支形态、病变区域关系）尤为关键。&lt;/p&gt;&lt;p&gt;在更为严苛的外部验证环节（测试从未见过的数据集），模型进一步体现出强大的零样本泛化能力。面对 7 个全新的外部数据集，Medical SAM3 将平均 Dice 从 11.9% 提升至 73.9%，IoU 从 8.0% 提升至 64.4%。这组结果的意义在于：外部测试通常伴随显著的分布偏移 &amp;mdash;&amp;mdash; 例如不同医院设备、采集协议、分辨率、噪声形态、病灶外观与标注风格差异 &amp;mdash;&amp;mdash; 许多模型在此类场景下会出现「性能断崖」。而 Medical SAM3 的提升幅度显示，它并非依赖某一类固定模态或固定提示形式，而是学习到了更通用的医学语义与结构先验。&lt;/p&gt;&lt;p&gt;更具说服力的是，在部分极端案例中表现出现了从「无法工作」到「可用级别」的质变：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;内镜息肉分割（CVC-Clinic）：原生模型由于难以从复杂背景中理解「息肉」这一语义目标，Dice 仅 0.0%；Medical SAM3 则达到 87.9%，说明模型能够在反光、粘液、纹理干扰等情况下仍保持对目标语义的稳定聚焦。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;超声胎头测量（HC18）：超声天然存在斑点噪声、边界模糊与组织对比度弱的问题，原生模型 Dice 为 23.9%；Medical SAM3 提升至 92.6%，体现其对低信噪比模态下轮廓结构的鲁棒提取能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ETIS-Larib：同样从 0.0% 跃升至 86.1%，进一步表明模型在外部域中不只是「略有改善」，而是显著降低了原生模型的完全失效概率。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综合内部与外部结果可以得出一个关键结论：Medical SAM3 能够在不依赖人工提示框辅助的情况下，仅通过文本提示驱动分割，在多模态、多数据分布下保持稳定表现。这意味着模型不仅「能分割」，更具备面向真实临床场景的核心能力：当标注成本高、交互提示受限或需要快速批量处理时，它仍能依靠医学语义理解与结构先验，提供一致、可复用、可迁移的分割输出。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjuq6IVw2KaoMICRkuu6OHG2Xo1iacP2n01IFnToSDJvib9baotwC21CLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.0307328605200945" data-s="300,640" data-type="png" data-w="846" type="block" data-imgfileid="100027209" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/89f216e5-8d16-410b-9e4f-d36d611fba27/640.png" alt="图片" data-before-load-time="1768976277190" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;未来展望：规模化与智能化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管目前的性能已经取得了显著进展，Medical SAM3 团队并未止步。为了进一步提升模型的实用性与智能水平，后续工作将主要集中在以下两个方向：&lt;/p&gt;&lt;p&gt;1. 数据规模与覆盖扩展： 团队计划持续扩充训练语料库，引入更丰富的分割数据，以增强跨域鲁棒性。同时重点补齐临床中的「长尾空白」，例如罕见病灶、小样本亚型、低资源模态以及更复杂的标注形态（多器官、多病灶、细长结构等）。通过更大规模、更多样化的数据「喂养」，进一步降低模型在真实世界场景中遇到分布偏移时的失效概率，让「给一个术语就能稳定分割」更接近可部署的可靠标准。&lt;/p&gt;&lt;p&gt;2. 迈向 Medical SAM3 Agent： 团队的目标不止于做一个分割模型，而是构建面向临床工作流的 Medical SAM3 Agent。通过集成大语言模型（LLMs），系统将具备更强的任务理解、步骤化推理与交互协作能力：例如把医生的自然语言需求拆解为可执行的分割子任务（目标、范围、优先级），在结果不确定时主动发起澄清提问，并把分割结果进一步组织为可读的结构化输出（位置、大小、数量、随访对比等），从而成为医生在阅片、测量与报告生成中的真正智能伙伴。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Medical SAM3 的出现标志着医学 AI 助手从「交互式工具」向「语义智能体」的进化。它不再要求医生充当「画框工」，而是模拟了临床专家的认知过程 &amp;mdash;&amp;mdash; 先理解诊断术语，再主动在图像中搜索病灶。通过建立临床概念与像素级特征之间的直接映射，Medical SAM3 为未来「即插即用」的自动化医疗辅助系统奠定了坚实的基础。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>推翻150年数学直觉：数学家烧坏几台笔记本，解决几何拓扑难题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 13:21:31 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;这是一次数学理论与计算机算力结合的胜利。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKiaWzye7Ly1qrQI4OQWNE85rF3e708FMMWEt9sPuV5hcLZE4IEZgvobQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503529370" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2e7c9054-d778-4b37-bb26-6ab865a9f110/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;设想一下，如果我们的天空总是被一层厚厚的不透明云层所遮蔽，既看不见星星，也无法从上方俯瞰我们的星球，我们还能发现地球是圆的吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答案是肯定的。&lt;/strong&gt;通过测量地面上特定的距离和角度，我们就能确定地球是一个球体，而不是平面或者甜甜圈状。即使没有卫星照片也能做到。&lt;/p&gt;&lt;p&gt;数学家们发现，这种情况在更普遍的二维曲面中也经常成立：&lt;strong&gt;只需要曲面上相对少量的局部信息，就足以推断出其整体形态，也就是由局部唯一确定整体。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;然而在某些例外情况下，这些有限的局部信息可能对应着不止一种曲面。在过去的 150 年里，数学家们一直在致力于整理这些特例：&lt;strong&gt;即那些通常只能定义一种曲面，实际上却描述了多种曲面的局部测量数据。&lt;/strong&gt;但他们能找到的唯一例外并不是像球体或甜甜圈那样规整、封闭的曲面。相反，这些曲面要么向某个方向无限延伸，要么拥有某种「边缘」。&lt;/p&gt;&lt;p&gt;没有人能找到一个打破这一规律的封闭曲面，似乎根本就不存在这样的特例。也许，这类曲面总是可以通过常规的局部信息被唯一确定。&lt;/p&gt;&lt;p&gt;如今，数学家们终于发现了一个寻觅已久的特例。在去年 10 月发表的一篇论文中，三位研究人员，包括柏林工业大学的 Alexander Bobenko、慕尼黑工业大学的 Tim Hoffmann 以及北卡罗来纳州立大学的 Andrew Sageman-Furnas，&lt;strong&gt;描述了一对非常扭曲的封闭曲面，它们虽然拥有相同的局部信息，却具有完全不同的全局结构。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKHkex309GvmZIavCnQiaSv3a2Eh9kV3G4lTxStfRc627qIfj9Je2ia0Zw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5148148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529372" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dc34ab4c-e982-4fd8-a611-6ddebfd202e3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Compact Bonnet pairs: isometric tori with the same curvatures&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://link.springer.com/article/10.1007/s10240-025-00159-z&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一发现耗费了该团队数年的辛劳、几台因运算过热的笔记本电脑，以及一个来自几何学看似无关领域的意外线索。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;几何学中的异类&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数学家们有各种各样的方法来局部地描述一个曲面，但其中两种尤为有用。&lt;/p&gt;&lt;p&gt;其中&lt;strong&gt;一种方法捕捉的是关于曲面「外在」曲率的信息&lt;/strong&gt;，即在曲面上任选一点，你可以沿着无限多的方向计算曲面在空间中的弯曲程度，也就是所谓的曲率。只关注那些能得到最大和最小曲率值的方向，然后取这两个值的平均数，得到的数值被称为「平均曲率」。你可以计算曲面上任意给定点的平均曲率，从而更好地理解它是如何置于周围空间之中的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;另一种测量方法捕捉的是关于曲面「内蕴」曲率的信息&lt;/strong&gt;，这是一种不依赖于曲面所在外部空间的几何属性。试想一张平整的纸，你可以把它卷成圆柱管而不必拉伸或撕裂它。如果纸上两点之间由一条曲线连接，那么这条曲线在圆柱上的长度将保持不变。这意味着这张纸和圆柱体拥有相同的「度量」，即距离的概念。&lt;/p&gt;&lt;p&gt;但如果你试着把这张纸包在球体上，情况就不再是这样了。你不得不拉伸、剪开或弄皱这张纸，点与点之间的曲线长度也会随之改变。因此，这两个曲面拥有不同的度量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKaj8ib2eGZEEI4eGLKasKbmWxXGDBTkdYlXTV4CXAVcyEt95iaHGKu9Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.1462962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529374" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/04e4a12e-d4fc-4442-afb8-d88afd0c74de/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;1867 年，法国数学家 Pierre Ossian Bonnet 证明，如果你知道一个曲面上每一点的度量和平均曲率，通常就足以确定该曲面的形态。当然，只是「通常」。但「通常」并不代表「总是」，正是这种不确定性让数学家们心痒难耐。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKAUR6RDVicReticUM5qO4PnX5sKsV3KftzmZagztMRWxhlMbKqyHGuXwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.260185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529375" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/11d0e6c9-064f-4575-b356-67c63df2279b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Pierre Ossian Bonnet&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 Bonnet 提出证明后的 150 年间，数学家们发现了各种违背这一规律的曲面。这些曲面拥有相同的度量和平均曲率，却不具备相同的全局结构。&lt;/p&gt;&lt;p&gt;但所有这些曲面都属于数学家口中的「非紧致」曲面。它们不像球体、甜甜圈以及其他「紧致」曲面那样能够完美地闭合。相反，非紧致曲面可能向某个方向无限延伸（如平面或圆柱面），或者拥有突然中断的边缘（如同从一个更大的形状上裁下来的一块）。&lt;/p&gt;&lt;p&gt;紧致曲面受到的限制则更多，它们必须满足各种约束条件，才能自身回转并完美闭合。因此，认为它们或许能被其度量和平均曲率唯一确定，似乎是合乎情理的推测。&lt;/p&gt;&lt;p&gt;1981 年，数学家 Blaine Lawson 和 Renato de Azevedo Tribuzy 证明，对于球体及任何与其拓扑等价的曲面，即任何没有孔洞的紧致曲面。这一推测确实成立。&lt;/p&gt;&lt;p&gt;而当涉及到带有一个孔洞的紧致曲面（即拓扑学上的「环面」，类似于甜甜圈）时，情况多了一点回旋余地。数学家们证明，&lt;strong&gt;给定的度量和平均曲率最多只能对应两个不同的环面&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;然而，从来没有人找到过这种「紧致 Bonnet 对」的实例。因此在几十年间，&lt;strong&gt;学界普遍认为环面与球体一样，给定的度量和平均曲率只能定义唯一的环面&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;「很长一段时间里人们都对此深信不疑，」杜克大学的 Robert Bryant 说道，「因为他们造不出任何反例。」&lt;/p&gt;&lt;p&gt;但是，他们错了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;像素化的世界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去 20 年里，Alexander Bobenko 一直在啃那些「数学甜甜圈」。21 世纪初，他曾试图证明紧致 Bonnet 对确实存在。但当他意识到这个问题绝非几个月就能解决时，便将其暂时搁置，转而专注于他认为能更快取得进展的问题。&lt;/p&gt;&lt;p&gt;他转向了一个看似与 Bonnet 问题毫不相干的数学领域，但这恰恰成了最终解开谜题的关键。&lt;/p&gt;&lt;p&gt;Bobenko 开始思考「离散」曲面，这有点像是光滑曲面经过像素化处理后的低分辨率版本。数学家之所以研究离散曲面，是因为它们不仅本身具有重要的几何性质，而且在计算机科学、物理学、工程学等领域也有着广泛的实际应用。&lt;/p&gt;&lt;p&gt;要构建一个离散曲面，需要选取有限数量的点，并用线段将它们连接起来，形成一个由平面构成的形状。通过选择不同的点，可以用不同的方式来表示同一个光滑曲面。例如，下面就是几种表示球体的方式：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK19xHpLApa7KqPVJUNcJ3FoyrxXNN5FyfiarEI0cNs3Aic6PmRnQOWCbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3527777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529376" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a0185904-1b50-4473-abb4-bcac0f24a07b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;有些离散曲面能比其他的更好地进行表征。近二十年来，Bobenko 和他的长期合作伙伴 Tim Hoffmann 一直致力于建立一套理论，旨在利用离散曲面尽可能保留光滑曲面最显著的几何特征。&lt;/p&gt;&lt;p&gt;2010 年代，当时还是哥廷根大学博士生的 Andrew Sageman-Furnas 加入了这项工作，并将 Bonnet 问题重新带回了讨论之中。&lt;/p&gt;&lt;p&gt;Sageman-Furnas 对渔网等编织材料的力学机制很感兴趣，这些材料本质上就是离散曲面，这也吸引他进入了离散数学领域。在此过程中，他提出了 Bonnet 问题的一个离散版本：&lt;strong&gt;局部信息在什么情况下能唯一确定一个离散曲面，又在什么情况下不能？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过调整一种已知的生成 Bonnet 定理反例的方法，Sageman-Furnas 与他的导师 Max Wardetzky 以及 Hoffmann 一起，&lt;strong&gt;找到了一套在离散情形下构造反例的「配方」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;与光滑情形一样，这些反例也总是非紧致的。但由于离散曲面并不包含无限多个点，因此利用计算机对其进行研究是可行的。Sageman-Furnas 不禁设想，&lt;strong&gt;是否可能利用计算机的「暴力求解」法，在离散几何的世界里找到一对紧致 Bonnet 对？&lt;/strong&gt;如果确实如此，那么离散情形或许也能为解决光滑情形下的问题指明方向。&lt;/p&gt;&lt;p&gt;于是，他作为 Bobenko 研究组的博士后研究员来到柏林，加入了 Bobenko 和 Hoffmann 的行列，并着手开展工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;曲面探寻之旅&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2018 年春，&lt;strong&gt;Sageman-Furnas 开始通过计算机搜寻一种特殊的曲面，这种曲面可以被转化为一个 Bonnet 对&lt;/strong&gt;，就像是用「老面」作为基底能烘焙出各种不同的面包一样。这个作为「引子」的曲面，类似于他读研期间用来构建离散 Bonnet 对的那些曲面。但这一次，他要求它必须是一个环面。也就是说，它必须是紧致的，且带有一个或多个孔洞。&lt;/p&gt;&lt;p&gt;Hoffmann 回忆称，Sageman-Furnas 消失了数周，甚至可能数月。当这位年轻的数学家终于再次现身时，他找到了他一直在寻觅的东西：一个长满尖刺的形状，与其说像环面，倒不如说更像是一只折纸犀牛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKGk2ZuGziagQZzHsR7UJIUvs6rQhcsmCeKRVrCqgFthcUpgVCBauub1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.8099352051835853" data-s="300,640" data-type="png" data-w="926" type="block" data-imgfileid="503529378" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/73f4427d-219c-4a96-a717-ab6a6f06f4a7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 「犀牛」。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但它确实是一个环面。根据 Sageman-Furnas 的计算机程序，它具备生成 Bonnet 对所需的所有其他属性。更重要的是，当 Sageman-Furnas 在计算机上生成这些 Bonnet 对时，它们也都是环面。从犀牛形状到 Bonnet 对的变换似乎并没有将犀牛形状扭曲成非紧致曲面。这些曲面始终保持紧致。&lt;/p&gt;&lt;p&gt;「当你开始进行计算探索和设计时，」Sageman-Furnas 说道，「你可以得到一些远超出你想象的新例子。」&lt;/p&gt;&lt;p&gt;但这会不会好得令人难以置信？计算机程序会产生舍入误差：Sageman-Furnas 的犀牛形状可能看起来符合所需的标准，它生成的 Bonnet 对也可能看起来是环面，但这都可能只是假象，是微小计算误差造成的假象。如果没有严格的证明，数学家们无法确定。&lt;/p&gt;&lt;p&gt;「他来了，给我们展示了一些看起来很奇怪的几何物体，看起来很像是数值计算产生的垃圾，」Bonnet 说。「开玩笑地说，我对整个项目最宝贵的贡献可能就是当时我说了一句：『我见过更糟糕的。』」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKm9ZibXJAJkQMEMwMlulbibT6QywvG7Uj0S0lZNRZq0XC9ABOt0jaqztQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529380" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6a8696bd-fae3-4ce1-867a-0ed58b6b35c0/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;Andrew Sageman-Furnas（左）、Tim Hoffmann（中）和 Alexander Bobenko（右）构建了一对新的形状，从而解决了一个长期存在的猜想。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;虽然花了一些时间，但 Hoffmann 和 Sageman-Furnas 最终确信这个「犀牛」形状值得认真研究。如果能够找到这样一个离散的 Bonnet 对的例子，那么光滑曲面的情况或许也并非毫无希望。Hoffmann 和 Sageman-Furnas 在那个夏天里仔细研究这个犀牛形状，寻找线索，有时一次视频通话就长达八到十二个小时，寻找可能有助于他们缩小光滑 Bonnet 环面搜索范围的特殊性质和几何约束。&lt;/p&gt;&lt;p&gt;到了九月，他们终于找到了一个非常有希望的新线索，这让 Bobenko 重新投入到他几十年前放弃的这个问题中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;闭合环路&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;线索与沿着犀牛边缘环绕的特定线条有关。&lt;/p&gt;&lt;p&gt;这些线条已知可以提供关于犀牛曲率的重要信息 &amp;mdash;&amp;mdash; 描绘出它弯曲和折叠程度最大和最小的方向。由于犀牛是一个存在于三维空间中的二维表面，数学家们原本预计这些线条也会在三维空间中勾勒出路径。但实际上，它们总是位于平面或球面上。这些排列如此巧合的可能性微乎其微。&lt;/p&gt;&lt;p&gt;「这让我们觉得一定有什么特别的事情正在发生，」Sageman-Furnas 说道。这太不可思议了。&lt;/p&gt;&lt;p&gt;与离散表面不同，光滑表面没有边缘。但你仍然可以绘制「曲率线」，描绘出最大和最小弯曲的路径。Sageman-Furnas、Bobenko 和 Hoffmann 决定寻找一个光滑的犀牛类比物，其曲率线同样被限制在平面或球面上。也许一个具有这些特性的初始表面可以产生光滑的 Bonnet 环面。&lt;/p&gt;&lt;p&gt;但这样的表面是否存在尚不清楚。&lt;/p&gt;&lt;p&gt;然后博本科意识到，一个多世纪前，法国数学家让・加斯顿・达布就几乎已经提出了数学家们现在需要的东西。&lt;/p&gt;&lt;p&gt;达布提出了生成具有正确曲率线的表面的公式。问题是，他的公式无法生成闭合的曲率线。相反，它们「看起来像螺旋线，并延伸到无穷远，」Bobenko 说。「不可能让它们闭合。」这意味着虽然曲率线可能位于平面和球面上，但整个表面不会是环面。&lt;/p&gt;&lt;p&gt;经过多年的努力，数学家们 &amp;mdash;&amp;mdash; 结合使用纸笔和计算实验 &amp;mdash;&amp;mdash; 终于找到了如何调整达布的公式，使曲率线闭合。他们终于找到了光滑的犀牛类比物，尽管两者看起来并不太相似。&lt;/p&gt;&lt;p&gt;此外，正如他们所希望的那样，这个光滑的犀牛可以生成一对新的环面，它们具有相同的平均曲率和度量数据，但整体结构不同。该团队最终找到了 Bonnet 问题的答案：某些环面最终无法通过其局部特征唯一确定。但是，当他们弄清楚这对 Bonnet 曲面究竟长什么样时，他们发现这两个环面互为镜像。「从技术上讲，这不成问题，」Sageman-Furnas 说道。「从形式上讲，它解决了问题。」但他补充说，这仍然令人不满意。&lt;/p&gt;&lt;p&gt;因此，在接下来的一年里，他们尝试以各种方式调整他们的光滑犀牛曲面。最终，他们意识到，如果放弃其中一组曲率线必须位于球面上的要求，他们就可以构建一个新的光滑犀牛曲面，从而达到他们的目的。然后，他们利用这个曲面生成了一对新的 Bonnet 曲面 &amp;mdash;&amp;mdash; 这一次，是两个非常扭曲的环面，它们显然是不同的曲面，但仍然具有相同的度量和平均曲率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK2Pj78qBQHgWsMWebrW85GEbG2zPHrgeicaw8VxXgLjLHMW8kFfeMzGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529381" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/2c4764d6-c5e7-4295-b63b-9a1066d34678/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该团队最终找到了紧凑型 Bonnet 曲面的一对实例。&lt;/p&gt;&lt;p&gt;这一结果令 UMass Amherst（马萨诸塞大学阿默斯特分校）的数学家 Rob Kusner 感到惊讶。他表示，这表明即使是环面 &amp;mdash;&amp;mdash; 一些最美观、研究最透彻的曲面 &amp;mdash;&amp;mdash; 也并非总能用其局部特征完美描述。&lt;/p&gt;&lt;p&gt;「这是一个我们的直觉不够用的例子，」杜克大学的数学家 Bryant 说道。&lt;/p&gt;&lt;p&gt;不过，数学家们发现的这两个环面有点奇怪：它们像数字「8」一样自身相交。Bobenko 现在希望证明存在不与自身相交的 Bonnet 环面。&lt;/p&gt;&lt;p&gt;Bonnet 环面的发现是对 Bobenko 和 Hoffmann 数十年来在离散曲面研究方面工作的有力验证。传统上，光滑形状的几何学发展速度更快，而离散几何学的理论发展相对滞后。但在这项工作中，离散理论取得了突破性进展，并最终促成了光滑曲面方面的进展。&lt;/p&gt;&lt;p&gt;Hoffmann 认为，这突出表明：虽然离散曲面看起来像是其光滑对应物的简化模型，但它们拥有自身的数学生命。离散世界可以像光滑世界一样丰富，甚至更加丰富，揭示出一些可能被忽略的额外对称性和联系。&lt;/p&gt;&lt;p&gt;「人们似乎忘记了离散方面的研究，」Hoffmann 说道。「但我们仍然可以从中有所收获。」&lt;/p&gt;&lt;p&gt;&lt;sup&gt;原文链接：https://www.quantamagazine.org/two-twisty-shapes-resolve-a-centuries-old-topology-puzzle-20260120/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AI5芯片搞定，马斯克的纯自研超算Dojo 3又回来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 13:15:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜晓楠、冷猫&lt;/section&gt;&lt;p&gt;刚刚，马斯克丢了个重磅炸弹：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「AI5 芯片设计进展顺利，特斯拉将重启 Dojo3 的工作。」&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="782" data-imgfileid="503528989" data-ratio="0.6648148148148149" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ09CeKw4GwgmJ2kllhKkhibHV4f2AmVKKnp1CIx6SIjGUG3ocKtmCTKeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1176" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7ad01776-b1ef-458e-b8f9-0706d42613e8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;简单两句话，包含了特别大的信息量。&lt;/p&gt;&lt;p&gt;Dojo 项目是在 2021 年特斯拉 AI Day 首次提出，定位是「面向机器学习训练的超级计算机」，目的是处理来自特斯拉汽车的视频录制和其他数据，并利用这些数据来训练公司全自动驾驶软件背后的「神经网络」。&lt;/p&gt;&lt;p&gt;在 2021 年的 CVPR 大会上，时任特斯拉人工智能高级总监的 Andrej Karpathy 曾表示，仅凭视觉技术，计算机必须以与人类相同的速度和敏锐度对新环境做出反应。然而，这需要利用强大的超级计算机，基于海量数据集对人工智能进行训练。而特斯拉就拥有这样一台超级计算机，即 Dojo。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0tFIuH9CiamoB7tYfRtVicPP694WibDyBgNmicY6usM4y4kF47kctQubNcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5148148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528990" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d6b11f2a-aa09-4fdc-b12a-e0de12a4ae08/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2023 年 7 月，Dojo 正式投产。彼时，马斯克对 Dojo 项目充满了期待。&lt;/p&gt;&lt;p&gt;但不知大家还记不记得，去年 8 月，马斯克突然&lt;strong&gt;「全面叫停」Dojo 项目，暂时解散专门的 Dojo 团队&lt;/strong&gt;，项目负责人 Peter Bannon 离职，约 20 名核心成员也跳槽成立新公司 DensityAI。&lt;/p&gt;&lt;p&gt;当时，特斯拉实际上在同时推进两套完全不同的芯片体系：用于车载系统和机器人的芯片，以及用于大规模 AI 训练的芯片。&lt;/p&gt;&lt;p&gt;事实证明，这样的双线推进效率并不高。马斯克必须做些取舍，于是决定暂停 Dojo 项目工作，来将全部资源投入到最具战略意义的 AI5 芯片上。&amp;nbsp;&lt;/p&gt;&lt;p&gt;彼时，外界听到这一消息，很多人都认为 Dojo 项目是一次失败，甚至认为马斯克已经放弃了该项目。但现在看来事实并非如此。&lt;/p&gt;&lt;p&gt;当时马斯克在 X 上发文解释：「对于特斯拉来说，分散资源并扩展两种截然不同的 AI 芯片设计是没有意义的。特斯拉的 AI5、AI6 及后续芯片在推理方面将非常出色，至少在训练方面也会相当不错。所有努力都集中在这一点上。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0wK2N9lXAlUJibWh43d3AyQCr5GEQD6tfGhCYU7qkJdibmocD6Lq6UJ0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6046296296296296" data-type="png" data-w="1080" data-width="1188" data-height="718" data-imgfileid="503528991" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3c8da690-44bf-4799-8750-484fff7ea095/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;AI5 是一颗高度关键的芯片，FSD、Cybercab、Optimus 等核心项目都要依赖它。在 2025 年下半年，马斯克非常明确地表示：&lt;strong&gt;AI5 还远未达到预期&lt;/strong&gt;。如果 AI5 失败，特斯拉未来的自动驾驶和自主系统，很可能都会受到「致命影响」。&lt;/p&gt;&lt;p&gt;马斯克很坦诚地说过：&lt;strong&gt;「解决 AI5 对特斯拉来说是生死攸关的&lt;/strong&gt;，这就是为什么我必须将两个团队都集中在这个芯片上，并且我个人在几个月的时间里每个周六都投入工作。」&lt;/p&gt;&lt;p&gt;特斯拉去年在 X 上表示，AI5 芯片可能比 AI4 芯片有高出 50 倍的提升，目标在 2027 年投入生产。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0ARI6CGmiaTBzgwzkgYkyxJficMWJRwgSj5hXHiazExvtbBVn4lBK05lng/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6611111111111111" data-type="png" data-w="1080" data-width="1170" data-height="774" data-imgfileid="503528993" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a89a1c65-aa4c-4a47-82f6-1410a05ce34b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0F25qpoYd3KVaW4vLrYt3NdicwicekmNiaQc8lBjSMAncibtMxuz7yVYK4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528994" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/af51a90d-d4ae-4749-bec5-60efd93f0839/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其实如果仔细回想，去年马斯克在公开解释 Dojo 项目被「叫停」的原因后，还谈到：「在一套超级计算机集群中，无论是用于推理还是训练，把大量 AI5 / AI6 芯片集成到同一块板卡上都是很合理的做法 &amp;mdash;&amp;mdash; 这样可以将网络布线的复杂度和成本直接降低好几个数量级。某种意义上，这大概就可以被称作 Dojo 3 了。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0VUoqyIQe1vAevftU4EKx19q2XPRm0oiaG5P5zyY0mIwyQ7a2YUQdC4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.49166666666666664" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528995" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5092501f-76ee-48f1-b202-49561e2ad873/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而如今，「Dojo3」项目意在将 512 颗 AI5 或 AI6 芯片密集集成于单块主板，形成超级计算机集群。原来，当时马斯克早已暗示了这一点，由此看来，Dojo 项目从来就没有真正停止，只不过是公司整体在路线优先权上的让步行为。现在，一切进展都在计划中，所以，「Dojo3」又回来了。&lt;/p&gt;&lt;p&gt;马斯克表示，「进展顺利」的 AI5 芯片的单颗 SoC 大致相当于 Hopper 级别，双颗则相当于 Blackwell 级别，但成本极低，功耗更低。&lt;/p&gt;&lt;p&gt;而 Dojo3 摒弃了前两代 Dojo 依赖自研 D1 芯片及晶圆级封装的复杂路径，核心在于架构重构与成本优化，从特斯拉战略规划来看，Dojo 3 采用了基于 AI5 和 AI6 芯片的统一架构，使单颗芯片能够同时处理训练和推理任务。&lt;/p&gt;&lt;p&gt;而这种设计能将网络布线复杂性与硬件成本降低数个数量级，同时保留大规模并行计算能力，这或许是特斯拉想要摆脱对英伟达 GPU 依赖，追求自研芯片垂直整合的战略。&lt;/p&gt;&lt;p&gt;与此同时，Dojo 3 提供的强大也将加速特斯拉 FSD 端到端神经网络模型迭代，同时为 Optimus 人形机器人的运动控制、环境感知模型训练提供算力支撑。&lt;/p&gt;&lt;p&gt;这对特斯拉而言绝对是一大利好，并且特斯拉将利用 AI5 芯片的潜能，不再将车载芯片与大规模 AI 算力芯片分开研究设计，而能够使用同一套芯片解决全部问题，&lt;strong&gt;从训练、推理到车辆和机器人，端到端自建完整算力体系&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这也说明了马斯克称这些芯片将成为「全球出货量最高的芯片」，AI5 或将被装进数百万辆汽车、机器人，并同时成为支撑背后训练系统的芯片。&lt;/p&gt;&lt;p&gt;据了解，目前特斯拉已经与三星电子签署了一项价值 165 亿美元的 AI6 芯片生产协议，这将为 Dojo 3 的规模化提供有力支撑。&lt;/p&gt;&lt;p&gt;当然了，马斯克毕竟是一个经常满嘴跑火车的人。&lt;/p&gt;&lt;p&gt;曾经马斯克表示 Dojo3 将是「基于太空的人工智能计算」，因为他和其他人认为相比地面上越建越大的数据中心，把算力搬到轨道上，反而可能是更优解。其想法是太空更容易获取太阳能，那里的低温可能会大大减少所需的电力等等。但他的说法完全属于推测，甚至有一些幻想色彩，专家们对此表示怀疑。&lt;/p&gt;&lt;p&gt;至于这条路究竟会把特斯拉带向哪里，能否达到马斯克的预期，Dojo 3 才刚刚走到起点，答案还得留给时间。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/news/864164/back-to-the-dojo&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.engadget.com/ai/musk-claims-tesla-will-restart-work-on-its-dojo-supercomputer-173127863.html&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/mubeitech/status/2013304716931768596&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/elonmusk/status/2013034224828215706?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>R1一周年，DeepSeek Model 1悄然现身</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 10:22:55 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜Panda&amp;nbsp;&lt;/p&gt;&lt;p&gt;2025 年 1 月 20 日，DeepSeek（深度求索）正式发布了 DeepSeek-R1 模型，并由此开启了新的开源 LLM 时代。在 Hugging Face 刚刚发布的《「DeepSeek 时刻」一周年记》博客中，DeepSeek-R1 也是该平台上获赞最多的模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKWE4M4nP9fpb6GdMDEh7NacCvvickycjL2S3DcwfOeXu7Toz6ArPibofA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.75" data-s="300,640" data-type="png" data-w="1024" type="block" data-imgfileid="503529284" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/0abd4c2c-0ca8-431e-8ab0-d1fc518c706f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如今，刚过一年时间，DeepSeek 的新模型又在 GitHub 悄然现身。&lt;/p&gt;&lt;p&gt;这些天，DeepSeek 给其 FlashMLA 代码库推送了不少更新，而在这些更新中，一个名为 &lt;strong&gt;Model1&lt;/strong&gt; 的模型引起了广大网友的注意。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKIjPCtboAudnkSK2R9jArS4DsDzNeGtYpOkWykGkDIuhnKNDnle3GZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.47962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529285" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d85a8470-e993-440c-9843-4b03712b99c5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如下截图所示，这个目前还很神秘的 Model1 不仅出现在了代码与注释中，甚至还有与 DeepSeek-V3.2 并驾齐驱的文件。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKjLH3mz4ibNL4kz40LIJK2h6uuMNeDPicF5wib9lNjAib6AicXV7t2j51pHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3490136570561457" data-s="300,640" data-type="png" data-w="659" type="block" data-imgfileid="503529283" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a18b1baa-9d3e-4e82-bece-2aa9eb2bee23/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKbicmibeqltdz3ib8u7iaNZAmyjibC2U5JUqibnPcD6enwwKL80cvfSpzyCng/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.2537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529286" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/42d30602-c7a7-4fcb-80af-e02b0faa45b5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLB9QiarHIJ3dGwV2ribGHrT43LITrfwJIFEe6QJzyugzliayaPibYzDDGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529287" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/12fa4325-a864-4310-baeb-7fac95f29c6e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKo2mNVVmITicCqsOQt0pekVteCfzuTHoGpI6esHf71O87m1auJQvSVOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21574074074074073" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529288" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/7830e8e4-fdd1-4608-a2dd-8f20e284c98f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这也不禁让网友们开始猜测，这个 Model1 很可能就是传闻中 DeepSeek 即将在春节前后发布的新模型的代号。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKbttKGKiaicon7ffMDrjeAALz4MPqISfcP4l6ia3ycvdXbtfbgjjTYkicFg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3496932515337423" data-s="300,640" data-type="png" data-w="489" type="block" data-imgfileid="503529289" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/bdc96e74-da55-4f61-a19e-a6d21f1b1899/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKbyCXxe7rOrlWH6SWLvIPtmKTno9tVf2oKicpd5K30yet7oUP4I89O3g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6599496221662469" data-s="300,640" data-type="png" data-w="794" type="block" data-imgfileid="503529290" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/262c0edb-3aa0-443d-8721-719ee2124360/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKDbnUfdIY866JKibfD3Al4CKYvTfXtrkg1zeHvVaLbkaNBPNY5C3CDYg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.3670076726342711" data-s="300,640" data-type="png" data-w="782" type="block" data-imgfileid="503529291" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/e1b2b95c-8feb-4cea-8294-06dc0e0b79af/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们也让 Gemini 帮忙分析了 DeepSeek 的这些 Commit，让其提取了其中的技术细节，结果如下：&lt;/p&gt;&lt;p&gt;根据 DeepSeek 在 2026 年 1 月提交的 flashmla 库代码变更，可以推断出&lt;strong&gt; Model1 是 DeepSeek 下一代旗舰模型 DeepSeek-V4 的内部开发代号或首个工程版本&lt;/strong&gt;。以下是根据代码 diff 提取的技术细节分析：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 核心架构：回归 512 维标准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 csrc/api/common.h 的 DISPATCH_HEAD_DIM 宏中，可以看到 head_dim 的分支处理：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;V32 (DeepSeek-V3.2)：继续沿用 d_qk = 576 的配置。这是 DeepSeek-V3 引入的非对称 MLA 设计（128 维 RoPE + 448 维 Latent）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Model1：切换到了 512 维。这表明 DeepSeek-V4 在 MLA 架构上进行了「标准化」回归，可能是为了更好地匹配 Blackwell (SM100) 架构的算力对齐，或者优化了 Latent 压缩比例。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 全面支持 Blackwell (SM100) 架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;代码库中出现了大量针对 NVIDIA 下一代 Blackwell GPU 的专门优化：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;SM100 接口：api.cpp 中新增了 FMHACutlassSM100FwdRun。这直接指向了 Blackwell 架构的核心指令集优化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;CUDA 版本要求：README 提到在 B200 上运行需要 CUDA 12.9。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;性能表现：在 B200 上，目前尚未完全优化的 Sparse MLA 算子已能达到 350 TFlops。而在 H800 (SM90a) 上，Dense MLA 的计算吞吐量高达 660 TFlops。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 引入「Token-level Sparse MLA」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是 Model1 相比 V3 系列最显著的算子演进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Sparse &amp;amp; Dense 并行：测试脚本中出现了 test_flash_mla_sparse_decoding.py 和 test_flash_mla_dense_decoding.py。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;FP8 KV Cache 混合精度：Sparse 算子使用 FP8 存储 KV Cache，但在计算矩阵乘法时使用 bfloat16 以保证精度。这说明 &lt;strong&gt;Model1 在极长上下文场景下，会通过「稀疏化推理」来降低显存压力和提升速度。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;4. 新机制：Value Vector Position Awareness (VVPA) 与 Engram&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然 diff 主要是算子层面的，但结合 DISPATCH_MODEL_TYPE 的逻辑和社区披露，Model1 引入了以下新特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;VVPA（数值向量位置感知）：这可能解决了传统 MLA 在长文本下位置信息衰减的问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651011743&amp;idx=1&amp;sn=34e666de69c7ad8166d2d46a4f8938fc&amp;scene=21#wechat_redirect" target="_blank"&gt;Engram 机制&lt;/a&gt;：&lt;strong&gt;这被认为是 DeepSeek 在分布式存储或 KV 压缩上的新突破，用于配合 Model1 的高吞吐需求。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而 Gemini 之所以判断 Model1 是 DeepSeek 下一代旗舰模型 DeepSeek-V4 的内部开发代号或首个工程版本，是因为它认为在下面所示的代码中，MODEL1 的定位是一个与 V32 并列且独立的分支，「&lt;strong&gt;说明它不是 V3 系列的补丁，而是一个采用了不同架构参数的全新模型&lt;/strong&gt;。按照 DeepSeek 的命名惯例，在 V3.2 之后的旗舰级架构跨越，逻辑上即为 V4。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKZc02bvvdfrcLtLLhwy0wHQpsMtruks6Zj1xyA3bUzxFpkyX1nZfvzg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5478036175710594" data-s="300,640" data-type="png" data-w="774" type="block" data-imgfileid="503529292" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c8997455-fae4-4d92-8e2c-26fa1f7d34c7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;对此，你怎么看，你觉得 Model1 就是传说中的 DeepSeek V4 吗？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026 Oral | 告别注意力与热传导！北大清华提出WaveFormer，首创波动方程建模视觉</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 10:17:29 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/f1fa8222-99fa-426e-a9e0-904e033fa1bb/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&amp;ldquo;全局交互&amp;rdquo; 几乎等同于 self-attention：每个 token 都能和所有 token 对话，效果强，但代价也直观 &amp;mdash;&amp;mdash; 复杂度随 token 数平方增长，分辨率一高就吃不消。现有方法大多从 &amp;ldquo;相似度匹配&amp;rdquo; 出发（attention），或从 &amp;ldquo;扩散 / 传导&amp;rdquo; 出发（热方程类方法）。但热方程本质上是一个强低通滤波器：随着传播时间增加，高频细节（边缘、纹理）会迅速消失，导致特征过平滑。&lt;/p&gt;&lt;p&gt;我们是否能找到一种既能实现全局交互，又能精准保留高频细节的物理建模方式？&lt;/p&gt;&lt;p&gt;来自&lt;strong&gt;北京大学和清华大学的研究团队&lt;/strong&gt;给出了答案：&lt;strong&gt;波动方程（Wave Equation）&lt;/strong&gt;：把特征图当作空间信号，让语义在网络深度对应的 &amp;ldquo;传播时间&amp;rdquo; 里，遵循欠阻尼波动方程演化。这样一来，低频的全局结构与高频的边缘纹理不再是 &amp;ldquo;此消彼长&amp;rdquo; 的牺牲关系，而可以在可控的波动传播中共同存在。在 AAAI 2026 Oral 论文《WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation》中，研究者首次将视觉特征图视为在波动传播时间下演化的空间信号，受欠阻尼波动方程支配。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0qfOZyoZKdoRXq76iaiaKQPjIbicia89vsIsrbv3ibFVHKBF8F3D5SIDkTqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529110" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/539b681c-de76-4d14-b42d-c1128afb8da1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.08602&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库：https://github.com/ZishanShu/WaveFormer&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;WaveFormer 首次将波动方程作为视觉主干网络的核心全局建模机制。&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0NiaIoNSHtHfCHiboiav5LwaVIaPPppupuibtuLaW81lZ913OxUE0LzZx0Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5842592592592593" data-type="png" data-w="1080" data-width="1246" data-height="728" data-imgfileid="503529112" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/516ba565-ed23-40c2-a436-b8201e215df5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;方法拆解：把图片当作 &amp;ldquo;波场&amp;rdquo;，特征当作 &amp;ldquo;波&amp;rdquo;，让语义振荡传播&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer 的关键思想可以用一句话概括：&lt;/p&gt;&lt;p&gt;全局交互不一定要靠 &amp;ldquo;相似度匹配&amp;rdquo;（attention），也可以靠 &amp;ldquo;波传播动力学&amp;rdquo;。&lt;/p&gt;&lt;p&gt;WaveFormer 将特征传播写成一个欠阻尼波动方程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;u (x, y, t)：&lt;/strong&gt;语义场（可以理解为特征图随 &amp;ldquo;传播时间&amp;rdquo; 演化）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;v：&lt;/strong&gt;传播速度（控制传播范围）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&amp;alpha;：&lt;/strong&gt;阻尼系数（控制衰减强弱）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它还引入了一个很有意思的设定：除了初始语义场 &lt;strong&gt;u0&lt;/strong&gt;，还允许一个 &amp;ldquo;初始速度场&amp;rdquo;&lt;strong&gt; v0&lt;/strong&gt;，表示不同区域语义被激活 / 抑制的变化趋势。&lt;/p&gt;&lt;p&gt;这个设定带来的最大变化是：&lt;strong&gt;空间频率被显式建模了&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;论文里明确把 &amp;ldquo;频率&amp;rdquo; 对应到 2D 特征图的空间频率：低频是全局布局，高频是边缘与纹理。&lt;/p&gt;&lt;p&gt;WaveFormer 不再把不同频率的信息一股脑丢给网络自己 &amp;ldquo;学着处理&amp;rdquo;，而是把它们写进了传播方程的解里：不同频率以不同方式振荡、衰减，但都参与全局语义的长程运输。&lt;/p&gt;&lt;p&gt;关键在于，团队推导了波动方程在频域下的闭式解：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;热方程常见形式会出现类似&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0e8h4pnBc5JzTBmRtu8iawHhKR6QCXticJYrxCDIIlv2cB5V27QGsPibeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5242718446601942" data-s="300,640" data-type="png" data-w="206" type="block" data-imgfileid="503529114" data-aistatus="1" data-original-style="width: 48px;height: 25px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/889df9b7-4457-4a16-b2a4-5a2062cf068d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 10.56%;"&gt;的项，高频随时间急速衰减&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;WaveFormer 的衰减项更像 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0LV3NtpyaeOicGRSyHgDs7zeDiauoLibmkjABiaNNa5ibyLUicSTiaqHe0iczDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5504587155963303" data-s="300,640" data-type="png" data-w="218" type="block" data-imgfileid="503529116" data-aistatus="1" data-original-style="width: 46px;height: 25px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5f21dc21-abef-42f0-88ca-6107dfe4c704/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 9.8%;"&gt;，对不同频率更 &amp;ldquo;公平&amp;rdquo;，而频率差异主要体现在 cos/sin 的振荡项上，从而实现&lt;strong&gt;频率&amp;ndash;时间解耦&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;热传导方程和扩散方程的闭式解的对比：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0fzVGd8icxCZibwJP68vwmBMzZZdjlVFSibnhBZwibQEhDUrPibgf82JJg7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.33055555555555555" data-type="png" data-w="1080" data-width="1708" data-height="564" data-imgfileid="503529117" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6a968639-67cd-4fe5-bdda-f7211be50015/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;WPO：把闭式解变成一个 O (N log N) 的全局模块&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;更 &amp;ldquo;工程友好&amp;rdquo; 的部分在这里：作者把欠阻尼波动方程的频域解，做成了一个可以直接替换 attention 的算子 WPO。&lt;/p&gt;&lt;p&gt;WPO 的实现流程非常清晰：&lt;/p&gt;&lt;p&gt;1. 把输入特征图变换到频域；&lt;/p&gt;&lt;p&gt;2. 用欠阻尼波动方程的&lt;strong&gt;频率&amp;ndash;时间解耦的闭式解&lt;/strong&gt;，对每个频率分量做 &amp;ldquo;振荡式调制&amp;rdquo;；&lt;/p&gt;&lt;p&gt;3. 再逆变换回空间域，从而完成一次 &amp;ldquo;全局语义传播&amp;rdquo;。&lt;/p&gt;&lt;p&gt;因为核心计算发生在频域（FFT /iFFT），WPO 的全局建模复杂度是 &lt;strong&gt;O (N log N)&lt;/strong&gt;，论文在摘要里明确对比 &amp;ldquo;远低于 attention&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在网络结构上，WaveFormer 走的是层级式骨干：stem + 四个阶段，每个阶段由 WPO Block 组成（WPO + FFN + 下采样），整体可以作为 ViT 或 CNN 的 drop-in backbone。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ04xGqYpUbHDGyP1DdA0L98k3265PhibDXWDzib5C3w8L9SujZeOfXBFJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3824074074074074" data-type="png" data-w="1080" data-width="2456" data-height="940" data-imgfileid="503529119" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/49cd5027-5e1f-4dc3-91f2-68ab13419b62/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为什么 &amp;ldquo;波传播&amp;rdquo; 适合视觉？一个更直观的理解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果把一张图像看成 &amp;ldquo;由低频骨架 + 高频细节叠加&amp;rdquo; 的信号，那么视觉建模很多时候在做两件事：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低频：抓住整体结构、主体布局、长程一致性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高频：保住边缘、纹理、细粒度辨别线索。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;WaveFormer 的 &amp;ldquo;波动方程建模&amp;rdquo; 给了一个很直接的机制：&lt;/p&gt;&lt;p&gt;在频域里，每个频率分量按 &amp;ldquo;阻尼振荡&amp;rdquo; 传播：低频衰减慢、负责全局结构；高频振荡快、在阻尼控制下仍能保留边缘纹理。&lt;/p&gt;&lt;p&gt;论文把这种机制称为一种新的、物理一致的建模偏置（physics-inspired inductive bias），用于同时捕捉全局一致性与高频细节。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：速度、效率与精度的全面超越&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ004eYArZ3RQBBhDl7PUXrCeTmDEQuia20sPgWL2wmsGXCpRLqOn7vXag/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.2916666666666667" data-type="png" data-w="1080" data-width="2958" data-height="862" data-imgfileid="503529130" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/952e0d86-7df8-449a-a447-9af789f66485/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;WaveFormer 在三类核心任务上验证：ImageNet 分类、COCO 检测 / 实例分割、ADE20K 语义分割。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ImageNet-1K 分类：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer-B 在&amp;nbsp;&lt;strong&gt;10.8G FLOPs / 68M 参数&lt;/strong&gt;下达到&amp;nbsp;&lt;strong&gt;84.2% Top-1&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;论文同时给出整体结论：在保持竞争精度的同时，最高可带来 &lt;strong&gt;1.6&amp;times; 吞吐提升、30% FLOPs 降低&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;COCO 检测与实例分割（Mask R-CNN）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer 在 box AP 与 mask AP 上整体优于 Swin/ConvNeXt，并且推理 FPS 更高。例如 &lt;strong&gt;WaveFormer-B 达到 47.9% APb、43.2% APm&lt;/strong&gt;，推理速度 &lt;strong&gt;20.4 img/s&lt;/strong&gt;，比 Swin-B/ConvNeXt-B 分别快 &lt;strong&gt;48%/45%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ADE20K 语义分割（UperNet）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;WaveFormer-B 达到 &lt;strong&gt;50.5% mIoU&lt;/strong&gt;，同时 FLOPs 与 FPS 也具备优势；论文把这种提升与 &amp;ldquo;频率意识的波传播能同时保全局结构与细节边界&amp;rdquo; 直接关联起来。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0TFZ2qVVia8Wlib7ls0Scm18VfL5uVdYvpd4pmzkcxhDmcZoELh91t13Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.708433734939759" data-type="png" data-w="830" data-width="830" data-height="588" data-imgfileid="503529132" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7cb3ee54-b1fd-4d3f-b2ad-9f66f6b55484/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ094e9TJ1stayaaCia3chiaDA5KKJcdf2XMT95KiaclZCdKVsQIBCXLrnTw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529138" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/186cfcf6-612e-476b-82f2-e1cfe54dd051/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer 证明了经典的物理波动规律能够为现代人工智能提供强大的归纳偏置 。这种基于波动方程建模的新范式，不仅为视觉基础模型开辟了频域处理的新路径，也为未来多模态语义传播的研究提供了深刻的启示。&lt;/p&gt;&lt;p&gt;WaveFormer 最值得被记住的，可能不是某个单点指标，而是它把 &amp;ldquo;视觉全局建模&amp;rdquo; 换了一种语言来描述：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从 &amp;ldquo;token 相似度交互&amp;rdquo; 转向 &amp;ldquo;语义场的动力学传播&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;从 &amp;ldquo;隐式处理频率&amp;rdquo; 转向 &amp;ldquo;显式建模低频 / 高频及其随深度演化&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;从 &amp;ldquo;黑盒的全局模块&amp;rdquo; 转向 &amp;ldquo;可解释、可控（v 与 &amp;alpha; 可调）的传播过程&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，MiniMax来承包你的桌面了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 20:53:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-14</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-14</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;如果说 2025 年是 Agent 落地元年，那么刚刚开始的 2026 年势必迎来新一轮爆发。&lt;/p&gt;&lt;p&gt;一开年，Agent 赛道便进入到了白热化的竞争，国外如 Anthropic 发布 Cowork，国内如千问 APP 上线「任务助理」。在这一背景下，市场出现了分化，或专注于工作提效，或聚焦于日常生活体验重塑。&lt;/p&gt;&lt;p&gt;在这个红海市场，10 多天前登陆港股的国产 AI 大模型独角兽 MiniMax 选择的路线是「将释放生产力进行到底」。&lt;/p&gt;&lt;p&gt;1 月 20 日，MiniMax 揭开了其第二代智能体产品 &amp;mdash;&amp;mdash;MiniMax Agent 2.0 的面纱，为这个火热的 AI 赛道添加了又一个生力军。此次的更新被定义为了一个&lt;strong&gt;「AI 原生工作台」（AI-native Workspace）&lt;/strong&gt;，从产品形态和能力分布上进行了深度重构。&lt;/p&gt;&lt;p&gt;这个全新的工作台不再像过去那样依赖简单的 Chat 式对话框，而变身为&lt;strong&gt;能感知本地环境、自主拆解复杂任务且提供专家级专业技能的进阶型智能协作伙伴&lt;/strong&gt;。这些能力实现的背后立着以下三大核心支柱：&lt;/p&gt;&lt;p&gt;首先是&lt;strong&gt;桌面端应用「MiniMax Agent Desktop」&lt;/strong&gt;，它让 Agent 跳出了浏览器网页，而能在操作本地文件和本地环境的同时启动网页自动化任务。这意味着，该 APP 实现了本地与云端之间的无缝连接，通过一个全局视角渗透到各个职能角色的核心工作流中，将人类从「在不同窗口间切换、复制粘贴、点击按钮」的重复劳动中解放出来。&lt;/p&gt;&lt;p&gt;MiniMax 桌面端已经上线了 Windows 和 Mac 双版本。&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;「Expert Agents」 ，打造垂直领域的顶级专家分身&lt;/strong&gt;。Expert Agents 超越了现有预设的 Multi-agent 的 Pro 模式，通过封装私有知识和行业独家 SOP（标准操作流程），用专家级的知识、能力和经验储备来武装用户。&lt;/p&gt;&lt;p&gt;MiniMax 表示，1.0 时代依赖的 Multi-agent 多专家系统只能提供 70 分的通用专家组合，&lt;strong&gt;现在借助 Expert Agents 可以将这一分数拉升到 95 分甚至 100 分&lt;/strong&gt;，可靠性有了质的提升。并且官方还会提供大量开箱即用的 Expert Agents，降低了操作门槛，上手更轻松。&lt;/p&gt;&lt;p&gt;用户现在可以在桌面和网页双端限时免费体验 Expert Agents 功能。&lt;/p&gt;&lt;p&gt;最后&lt;strong&gt;定义自己的 Expert Agents&lt;/strong&gt;，通过更多的上下文信息和更自由的自定义设置，让 Agent 在更懂你的基础上提供个性化的专家服务。&lt;/p&gt;&lt;p&gt;如果说去年发布的 MiniMax Agent 1.0 定义了「靠谱的 AI 伙伴」，如今的 2.0 在同样确保结果的准确性之外，在 AI 原生自动化执行的广度、深度、专业度上来了波全方位加强。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测：这个 Agent 真是能文能武&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;表现如何还得看实战。打开 MiniMax Agent 官网 ，下载最新上线的 MiniMax 桌面端，即可开启 AI 原生工作台体验，重塑工作流。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0E86XbDsWUcibNXx9uyNRrS7XdY1tdfAMw2icdGe8HMbWgUThUVOMDwjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529209" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a6b446cb-f365-407d-a390-74e4c223a102/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;官网地址：https://agent.minimaxi.com/&lt;/p&gt;&lt;p&gt;安装完成后，&lt;strong&gt;在引导界面可以看到 MiniMax 桌面端已经深度打通本地文件&lt;/strong&gt;，我们只需选定一个工作目录，即可让 AI 读取、分析、批量处理该目录下的所有文件。这一设计体现了其打造「AI 原生工作台」的核心思路。&lt;/p&gt;&lt;p&gt;下面就开始测试吧。&lt;/p&gt;&lt;p&gt;作为一家媒体，我们的日常工作中一大很重要的任务是&lt;strong&gt;刷选题&lt;/strong&gt;，直接输入下面的提示词，看看我们能否在 MiniMax 桌面端中让 Agent 自主实现这个定时任务，提升我们刷选题的效率。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;每天 9:00 为我提供过去 24 小时内 AI 领域的重点新闻摘要。每条新闻提炼一个核心要点，并附带网络检索来源，确保清晰易读&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/def72d9d-5c10-401b-9a19-cb8bac986d3b/1768913407226.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 4 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;仅仅 2 分多钟，MiniMax 的 Agent 就成功完成了任务，正确编写了脚本并进行了可行性测试。不仅如此，该 Agent 还给出了后续实现定时任务的教程，让我们只需一些复制粘贴，即可在我们的设备上将这个 AI 任务变成每天上午的日常。下图总结了此次任务的执行结果：&lt;/p&gt;&lt;section data-pm-slice="1 2 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0Dh8MYlxFzb3NuntQ2bmuAFVrB8up6CIFibJrcsePMt56TiaYM7Wd14ZQ/640?wx_fmt=png#imgIndex=2" alt="长图滚动查看" data-ratio="2.986111111111111" data-w="1080" data-aistatus="1" data-original-style="width: 1831.41px;height: auto;display: block;border-radius: 4px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b1f45b69-d733-4b42-95fd-cdb1dea98913/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而作为一家专业的人工智能媒体，&lt;strong&gt;读论文&lt;/strong&gt;也是我们的一个日常，接下来我们试了试让 MiniMax 桌面端分析解读 MiniMax-M1 背后的技术脉络。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;这是 MiniMax-M1 的技术报告 https://arxiv.org/pdf/2506.13585，研究其参考文献，了解其背后的技术，然后制作一个网页，展示 MiniMax-M1 背后的技术进化图谱，务必尽量往前追溯。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;很显然，这个任务会更加复杂一些，耗时大概 6 分钟。&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e0c284f5-4135-4cb6-b2b0-7ca96ead9505/1768913437418.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;4 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在执行过程中，Agent 首先分析了任务需求，然后调用工具下载了指定文档，之后对文档进行了分析解读以及技术追溯。之后，它又按照要求编写了一个网页来进行了展示。&lt;/p&gt;&lt;p&gt;最后，MiniMax 的 Agent 为我们创建了这样一个网页，：&lt;/p&gt;&lt;section data-pm-slice="1 2 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0KiaW4QhV9gYunjA9fpxZlicFDGVd5bMtg4PnFx3aBBckTMlf6xcokG8A/640?wx_fmt=png#imgIndex=3" alt="长图滚动查看" data-ratio="4.937037037037037" data-w="1080" data-aistatus="1" data-original-style="width: 1831.41px;height: auto;display: block;border-radius: 4px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/aaed1756-1a49-4f06-8463-3f0b2a70678d/640.png" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不仅如此，该 Agent 还自动在 MiniMax Space 上部署了这个网页， 让我们可以直接使用和分享这个网页：https://sqwu1jsy96cd.space.minimaxi.com/&lt;/p&gt;&lt;p&gt;这种从研读到交付的闭环能力，展现了其在任务执行上的工程深度。&lt;/p&gt;&lt;p&gt;当然，得益于工作目录的设计，MiniMax 桌面端不仅能处理单篇论文，更能&lt;strong&gt;直接处理一个装满文件的文件夹&lt;/strong&gt;。举个例子，我们的日常工作将会积累很多选题，其中包括一些高质量的技术博客，使用以下提示词，我们可以让 MiniMax 将这些博客从文档中提取出去，并制作成精美的 PPT 进行展示。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;这是我们近几个月的日常选题整理文档，请梳理出其中所有的技术博客，并访问每篇技术博客的内容，给出简短的内容整理。将结果整理成一个 PPT，每一页展示一篇技术博客，其中应包括一些引用自博客的图片或截图、博客标题和链接以及内容简介。使用莫兰迪色系。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这个任务就更加复杂了，而且非常繁琐，也因此我们此前都没去处理。而在 MiniMax 桌面端的帮助下，我们仅用 23 分钟时间就完成了整个任务。&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8096a079-7e72-4303-8f8b-162ae27a5884/1768913466957.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 16 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;可以看到，我们的初始文件是一大堆的 docx 文档，MiniMax 桌面端首先调用工具将所有这些文档转换成了 LLM 最喜欢的 markdown 格式，然后读取详细内容，并提取出了分散在各个文档中的技术博客。之后它继续调用工具，读取了文档中这些技术博客链接的具体内容。之后它继续推进，将这些内容总结成了适合制作 PPT 的文案，接下来，还是调用工具，它使用这些文案生成了图像和演示 PPT。&lt;/p&gt;&lt;p&gt;至于效果，可以说是超乎想象地好。&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5307f3ac-af37-4744-9098-aebc41e75e51/1768913484215.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;通过以上测试示例，我们看到了 MiniMax 桌面端在日常工作中对我们的强大助益，同时，我们也看到了将 Agent 接入本地计算机的无限可能性。&lt;/p&gt;&lt;p&gt;举个例子，&lt;strong&gt;对以上视频的加速处理，我们也完全是通过 MiniMax 桌面端完成的&lt;/strong&gt;。而我们所做的，不过是输入了这样一段提示词：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;处理一下文件夹中的视频：将 MiniMax-1 和 2 加速 4 倍，将 3 加速 8 倍，将 4 加速 16 倍。我本地已经安装 ffmpeg。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Agent 精准识别了本地环境中的工具路径，并生成了对应的处理指令。无需用户手动输入复杂的命令行参数，视频加速任务便在后台安静、高效地完成了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0tPnhUxo73ViaOqT9OnFVib8ozqZF8cl1FeMdQwgZGvJw1lv8n9CeroBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.37806451612903225" data-s="300,640" data-type="png" data-w="775" type="block" data-imgfileid="503529252" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4d18d72d-1f93-4bc5-84a6-ecea6b9e7ced/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，我们还简单尝试了 &lt;strong&gt;MiniMax 提供的专家 Agent 创建能力&lt;/strong&gt;。据介绍，该功能「允许用户构建在特定领域达到 95 分甚至 100 分的领域的专家 Agent。不仅仅是简单的 Prompt 调整，而是深度的知识与能力注入。」&lt;/p&gt;&lt;p&gt;创建过程非常简单直观。在对话框左下方选择「子代理」&amp;rarr;「管理子代理」，即可创建出可以多次复用的 Agent，比如这里我们简单创建了一些「专家」。而在每个 Agent 的配置中，我们也可以选择启动不同的工具。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0n8sXu3zSIfZZOib7MGnZiaOc520JXCQjI1v9d9v9H83wPQiaZmTeFD87A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="1.002016129032258" data-s="300,640" data-type="gif" data-w="992" type="block" data-imgfileid="503529253" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/7ff4f585-d0ef-4979-a471-019e93a65c5c/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;之后，我们只需在开启任务之前选择我们想要使用的子代理，即可将相应的 Agent 纳入到我们的工作流程中。比如在下面的例子中，我们启用了上面配置的一系列专家，然后让它们围绕「AI 究竟是什么」进行了一系列深度探讨。这时候，MiniMax 本身会化身这场多智能体讨论的主持人，通过在探讨中调用不同配置的子代理，实现对这一话题多视角反复深度讨论。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0f1KbibJqVED0JAeoT76RoLRicv0PATevB1qUBv5e8rKPZnKzSLbLIObw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.6234375" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503529264" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/07754cd7-44f0-40ca-96e7-4ca5b130fa49/640.gif" data-order="1" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这项能力具有巨大的想象空间。它意味着用户可以将行业经验、部门 SOP 甚至复杂的业务逻辑转化为可调用的模块。当用户面对一项复合任务时，不再是与一个通用模型交谈，而是指挥一支由特定领域专家组成的数字团队。这种从「单点能力」向「专家协作」的转变，为大模型在专业垂直场景的落地提供了更具实操性的路径。&lt;/p&gt;&lt;p&gt;整体体验下来，我们看到 MiniMax Agent 能够理解复杂的 SOP 流程，自主调用本地与云端工具，将原本需要多款软件协作的任务浓缩在单一的提示词输入框中。&lt;strong&gt;这种以任务完成率为核心的设计，正是 MiniMax 试图定义的 AI 原生工作范式。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从刷分到会干活：MiniMax 正在重新定义 AI 能力边界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;总结来看，&lt;strong&gt;MiniMax Agent 2.0 并不是在展示它想得有多聪明，而是在证明它能把事做到哪一步&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在 Agent 2.0 的工作方式里，AI 不再等待人类一次次补充上下文，而是主动进入工作环境，理解你的文件、网页、工作流程，持续推进任务本身。你只要给出一个指令，剩下的拆解、执行与跟进，交由 Agent 在 Workspace 中完成。&lt;/p&gt;&lt;p&gt;这也解释了为什么 MiniMax 要把 Agent 2.0 定义为 AI-native Workspace。&lt;/p&gt;&lt;p&gt;这背后，是 &lt;strong&gt;MiniMax 在模型层面的持续升级，以及一套在内部真实运转的工作方式&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;去年 6 月提出的 Lightning Attention 将长序列计算成本从二次方降为线性，让 Agent 不再失忆；10 月发布的 M2 定位为 Agent &amp;amp; Code Native，采用交错思维机制和 MoE 架构（230B 总参数、10B 激活），API 价格仅为 Claude Sonnet 4.5 的 8%；12 月的 M2.1 则向 Rust、Java、C++ 等后端语言深入，使得模型具备全栈工程能力。&lt;/p&gt;&lt;p&gt;而这些能力，首先被 MiniMax 自己用在了内部。模型被直接嵌入研发与办公的核心流程，从写代码、拆需求到跑 Agent 任务。据了解，在过去数周内，MiniMax 内部接近 100% 的同学开始使用 Agent 实习生。&lt;/p&gt;&lt;p&gt;这样一来，模型能力的每一次升级，都会在真实业务中被高频使用和反复打磨，而内部产生的反馈，又返回到下一轮模型和系统设计上来，形成了一条快速自我强化的迭代闭环。&lt;/p&gt;&lt;p&gt;此次 &lt;strong&gt;MiniMax 定义的「AI 原生工作台」将掀起一场对 AI 参与高复杂度工作的价值重构&lt;/strong&gt;。其中一点是交互逻辑发生了变化，从「人要被动适应 Agent」变为「Agent 主动适应人」。另外通过定制化的 Expert Agents，专业壁垒被打破，普通人无需经历漫长的学习就能获得行业顶级的知识与经验。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>马斯克刚刚真把 𝕏 平台推荐算法给开源了，核心也是Transformer</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 20:44:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜冷猫&lt;/section&gt;&lt;p&gt;刚刚，𝕏 平台（原 Twitter 平台）公布了全新的开源消息：&lt;strong&gt;已将全新的推荐算法开源，该算法由与 xAI 的 Grok 模型相同的 Transformer 架构驱动。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该模型预测用户行为（点赞、回复、转发等）来对帖子进行排序，出现在 For You 一栏中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ06fPgwA5OU8Np61Uia0ojwP74icVvpnTcpiavFNT1ZHa3weFVveO6HAsBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.8703703703703703" data-type="png" data-w="1080" data-width="1170" data-height="1018" data-imgfileid="503529153" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a98a260d-f100-43de-a447-bb6827842658/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;众所周知，推荐算法是社交媒体平台的生命线，几乎已经成为了媒体平台获取用户留存，扩大营销收益的核心。在一周多前，马斯克在 𝕏 平台发推声明「将在 7 天后开源𝕏平台推荐算法」的时候几乎令人难以置信。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0cOvia7PJXmBtUqJ9PQicibc8tLjI0PsYkgAbC0HjyXDDaU7ucSo1SPvJQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6620370370370371" data-type="png" data-w="1080" data-width="1178" data-height="780" data-imgfileid="503529154" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f69fb619-6512-4c56-8048-1eaf7dcc732e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而马斯克确实说到做到，虽然比声称的 7 天内略晚，但推荐算法的确已经完全开源。希望之后能够长期遵循每 4 周重复更新的承诺。&lt;/p&gt;&lt;p&gt;在开源信息发布后，马斯克表示：「我们知道这个算法很笨拙，需要大量的改进，但至少你可以看到我们在实时和透明的情况下努力让它变得更好。&lt;strong&gt;没有其他社交媒体公司这样做&lt;/strong&gt;。」&lt;/p&gt;&lt;p&gt;不过，马斯克选择开源 𝕏 平台推荐算法可能另有原因。&lt;/p&gt;&lt;p&gt;据路透社报道，2025 年 7 月，巴黎检察官调查了该社交媒体平台，怀疑其存在算法偏见和欺诈性数据提取，马斯克将其称为「政治动机的刑事调查」，威胁到其用户的言论自由。&lt;/p&gt;&lt;p&gt;12 月，欧盟对 𝕏 处以 1.2 亿欧元罚款，监管机构表示该公司违反了该地区数字服务法案下的透明度义务。罚款与𝕏的「蓝 V」订阅、广告库缺乏透明度以及未能向研究人员提供平台公共数据有关。&lt;/p&gt;&lt;p&gt;既然已经开源，那我们来看一下 𝕏 平台到底公开了些啥？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0g3eaXJ5M85icKvazszEibxz8tvmiaDoZBuG1xOSS5meAliaeGjUAuPlic2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.25833333333333336" data-type="png" data-w="1080" data-width="1688" data-height="436" data-imgfileid="503529155" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/133b2051-3dd0-44c5-affd-3d894ccd5309/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Github 开源链接：https://github.com/xai-org/x-algorithm&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这份代码仓库包含了 &lt;strong&gt;𝕏 平台「For You」信息流背后的核心推荐系统&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;它将站内关系内容（来自你已关注账号的内容）与站外发现内容（通过基于机器学习的召回机制发现的内容）进行融合，并使用基于 Grok 的 Transformer 模型对所有内容进行统一排序。&lt;/p&gt;&lt;p&gt;随后就是一长串的系统架构：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0ho1jbmH2YJ5UwTibwKT0y62XW3nDeRkpjmgkbwo6U1nSxQmlB6JPHng/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="2.053435114503817" data-type="png" data-w="786" data-width="786" data-height="1614" data-imgfileid="503529156" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/85cb1519-3b24-425c-a918-8993fb16a6ee/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;𝕏 推荐算法系统架构&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;新系统彻底抛弃了传统的手工规则，并大幅减少启发式方法，采用完全的神经网络方式。&lt;/p&gt;&lt;p&gt;整个推荐过程的核心几乎全部交给了这个基于 Grok 的 Transformer 模型：它通过理解你的历史互动行为（比如点赞、回复、转发等），来判断哪些内容与你最相关。&lt;/p&gt;&lt;p&gt;整个系统的核心是称为 Thunder 和 Phoenix 的组件。「For You」信息流算法会从两个来源中&lt;strong&gt;召回、排序并过滤&lt;/strong&gt;内容：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;站内关系内容&lt;/strong&gt;（In-Network，Thunder）：来自你已关注账号的帖子&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;站外发现内容&lt;/strong&gt;（Out-of-Network，Phoenix Retrieval）：从全局内容池中通过模型发现的帖子&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;来自这两个来源的内容会被合并在一起，并统一交由 &lt;strong&gt;Phoenix&amp;nbsp;&lt;/strong&gt;进行排序。&lt;strong&gt;Phoenix 是一个基于 Grok 的 Transformer 模型&lt;/strong&gt;，它会为每一条帖子预测不同形式的互动概率。最终排序分数，是这些预测互动概率的加权组合。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Thunder 组件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是一个&lt;strong&gt;基于内存的帖子存储与实时数据摄取系统&lt;/strong&gt;，用于跟踪全体用户的最新发帖情况，主要功能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从 Kafka 中消费帖子创建 / 删除事件&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;为每个用户分别维护原帖、回复 / 转发、以及视频帖的存储&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;向请求用户提供其关注账号的「站内关系内容（in-network）」候选帖&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;自动清理超过保留期限的旧帖子&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持亚毫秒级查询，无需访问外部数据库即可获取站内关系内容&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Thunder 的作用，是让系统能够极高速地获取「你关注的人最近发了什么」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Phoenix 组件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是推荐系统中的 &lt;strong&gt;机器学习核心组件&lt;/strong&gt;，主要包含两个功能模块：&lt;/p&gt;&lt;p&gt;召回（Two-Tower 双塔模型），用于发现相关的站外内容（out-of-network）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;用户塔（User Tower）：将用户特征和历史互动行为编码为向量表示&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;候选内容塔（Candidate Tower）：将所有帖子编码为向量表示&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;相似度检索：通过向量点积相似度，召回最相关的 Top-K 帖子&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;排序（带候选隔离的 Transformer），用于预测每条候选内容的互动概率：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;以用户上下文（历史互动）和候选帖子作为输入&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用特殊的注意力掩码机制，确保候选帖子之间不能相互看到彼此&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出不同互动行为的概率预测（点赞、回复、转发、点击等）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于 Phoenix 的 transformer 模型预测多种参与类型的概率：&lt;/p&gt;&lt;pre data-lang="css"&gt;&lt;code&gt;Predictions:&lt;/code&gt;
&lt;code&gt;├── P(favorite)&lt;/code&gt;
&lt;code&gt;├── P(reply)&lt;/code&gt;
&lt;code&gt;├── P(repost)&lt;/code&gt;
&lt;code&gt;├── P(quote)&lt;/code&gt;
&lt;code&gt;├── P(click)&lt;/code&gt;
&lt;code&gt;├── P(profile_click)&lt;/code&gt;
&lt;code&gt;├── P(video_view)&lt;/code&gt;
&lt;code&gt;├── P(photo_expand)&lt;/code&gt;
&lt;code&gt;├── P(share)&lt;/code&gt;
&lt;code&gt;├── P(dwell)&lt;/code&gt;
&lt;code&gt;├── P(follow_author)&lt;/code&gt;
&lt;code&gt;├── P(not_interested)&lt;/code&gt;
&lt;code&gt;├── P(block_author)&lt;/code&gt;
&lt;code&gt;├── P(mute_author)&lt;/code&gt;
&lt;code&gt;└── P(report)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;加权评分器将这些因素综合成一个最终得分：&lt;/p&gt;&lt;pre&gt;FinalScore= &amp;Sigma; (weight_i &amp;times; P(action_i)) &lt;/pre&gt;&lt;p&gt;&lt;strong&gt;流量密码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个得分就是影响推文推荐水平的量化数据。简单分析，𝕏 平台的推荐逻辑更加关注评估内容与用户的关系质量。&lt;/p&gt;&lt;p&gt;在新的「For You」机制下，每一条帖子都会被独立评估，排序不再主要依赖点赞数量，而是基于系统对深度互动行为的预测与反馈，包括引用评论、私信分享、复制链接、个人主页点击与关注，以及停留时长。相反，「不感兴趣」、静音、拉黑、举报等负面行为会直接被赋予负权重，显著压低内容分发。&lt;/p&gt;&lt;p&gt;此外，情绪化标题、短期刺激型内容的收益正在下降。算法不仅关注互动峰值，也会捕捉后续的负反馈，从而惩罚低质量、不可持续的互动模式。&lt;/p&gt;&lt;p&gt;同时，发布频率越高并不等于覆盖面越广。系统会对同一作者在同一信息流中的多条内容进行递减加权，刷屏式发布反而更容易被压制。更有效的策略，是降低频率、提高单条内容的独立价值。&lt;/p&gt;&lt;p&gt;在分发机制上，关注关系的重要性进一步上升。来自关注者网络的内容保持满权重，而推送给非关注用户的内容则会被系统性折扣，降低「纯病毒式传播」的成功概率。&lt;/p&gt;&lt;p&gt;总体来看，𝕏 的推荐系统正在明确优化长期关系和内容质量，而不是短期热度。谁能建立稳定、正向的互动关系，谁才能获得更可持续的曝光。&lt;/p&gt;&lt;p&gt;规则已经明确地展现在所有人面前，从中每个人都可以发掘自己的流量密码。&lt;/p&gt;&lt;p&gt;或许大家可以去关注一下我们机器之心的 𝕏 ？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>击败GPT、Gemini，复旦×创智孵化创业团队「模思智能」，语音模型上新了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:40:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南、杜伟&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;在语音大模型赛道上，GPT-4o、Gemini 的能力遥遥领先。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;近日，&lt;strong&gt;由复旦邱锡鹏担任首席科学家的模思智能发布了多说话人自动语音识别（ASR）模型 MOSS-Transcribe-Diarize&lt;/strong&gt;，不但可以语音转文字，还可以将音频片段与对话中不同的说话者关联起来，性能超过了 GPT-4o、Gemini、豆包等一众模型。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;多人说话场景的语音转录是语音识别领域的落地痛点问题。以往模型一旦遇到多人抢着说话就可能听不清、记不准。现在 MOSS-Transcribe-Diarize 摸透了多人说话逻辑，能够轻松应对混乱插话、频繁切话或者重叠说话等复杂场景，真正掌握了「说哪记哪、听声辩人」的技能。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;MOSS-Transcribe-Diarize 在语音识别与分析领域具有突破性意义，解决了语音领域最后的落地痛点。MOSS-Transcribe-Diarize 支持 128K 的长上下文窗口，&lt;strong&gt;可以一次性输入并处理长达 90 分钟的音频&lt;/strong&gt;，突出了复杂场景下的抗干扰能力。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;MOSS-Transcribe-Diarize 的跑分成绩同样亮眼。&lt;/strong&gt;在 AISHELL-4、Podcast、Movies 等多个语音基准测试中，模型均取得了业界最优（SOTA）的整体表现。尤其是在影视剧场景下，背景音更杂、多人同时说话、频繁插话、声音重叠，是语音转录里&lt;strong&gt;最乱、也最接近真实应用的情况。&lt;/strong&gt;即便面对这样的复杂语音条件，MOSS-Transcribe-Diarize 依然稳定跑出了当前业界最优的整体成绩：&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0nvS6kWd3rgdOY3rUwjd4x0kjHrsqvy8kyev40ziaK1MuibZT7TM7PAlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529151" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4a6a54d9-4043-4060-bb74-9834e3a8bd1a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="2 2 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 此处 GPT-4o 特指 gpt-4o-transcribe-diarize&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;再更具体一点，该模型实现了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最低的 CER（字错误率）与 cpCER（最优排列字错误率）&lt;/strong&gt;：在多说话人混合与重叠场景下取得业内领先的转录准确率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最佳的 &amp;Delta;cp 指标（说话人分离性能 ）&lt;/strong&gt;：相比于其它因为长音频切片而导致的说话人识别不一致的模型，MOSS-Transcribe-Diarize 保持了最好的说话人标签准确性和一致性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;超长音频处理&lt;/strong&gt;：在面对超长音频时，当前顶尖商业模型（如 GPT-4o Transcribe Diarize、Gemini 3 Pro）受限于输入长度或输出格式的稳定性，而 MOSS-Transcribe-Diarize 能够稳定输出完整的带有说话人以及时间戳的语音转录结果。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实战效果惊艳，经典名场面「华强买瓜」：&lt;a href="https://mp.weixin.qq.com/s/LoP4twE1X5UFSY3G7g42mQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8388af55-0fd3-4eed-a00a-ef4013e49a89/1768905487029.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Mygo 的飞鸟山公园：&lt;a href="https://mp.weixin.qq.com/s/LoP4twE1X5UFSY3G7g42mQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e991c545-34f5-43b7-bdc5-869cb019cc5f/1768905501344.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;看起来 AI 模型可以把说话人和每个人所讲的内容识别地清清楚楚，不论是嘈杂的环境音，人物的方言、俚语，还是因为情感波动表现出的喊叫、哭泣等都不会影响 AI 的判断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首个统一多模态模型，挑战 AI 语音最难题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS-Transcribe-Diarize 的特点不仅在于语音能力，它作为统一的端到端多模态语音转录模型，能够像人类一样，在「听」的过程中同时完成「听懂内容」、「识别是谁说的」以及「记录说话时间」这三件事。&lt;/p&gt;&lt;p&gt;它主要解决的是语音处理中一个经典且极具挑战的问题：SATS，即「带说话人归属和时间戳的转录」。 想象一下，在参加环境嘈杂、一堆人在场的会议时，大家你一言我一语，乱哄哄一片。这种面向多说话人的转录既要求内容准确，也要标明「何人何时发言」。&lt;/p&gt;&lt;p&gt;但是&lt;strong&gt;，传统的模块化组件拼接方案（如自动语音识别 + 说话人日志）、引入 LLM 的半级联方案（使用自动语音识别和说话人日志生成候选内容，然后利用 LLM 修正错误）&lt;/strong&gt;以及&lt;strong&gt;近期将识别与归属统一在多模态框架下的尝试（如 Sortformer、SpeakerLM、JEDIS-LLM 等）&lt;/strong&gt;都不同程度地存在着缺陷，比如级联方案对于说话人重叠的音频表现不鲁棒，其他方案对长时间多说话人对话的转录效果不佳，亟需更优的解决方案。&lt;/p&gt;&lt;p&gt;邱锡鹏团队发布的 MOSS-Transcribe-Diarize 一扫现有 SATS 方案的不足，一举解决了三大核心瓶颈，即长上下文窗口受限、长时记忆脆弱和缺乏原生时间戳。相关技术报告已在几天前发布，同时官方也开放了 &lt;strong&gt;API 接口&lt;/strong&gt;，目前为限时免费期，感兴趣的同学可自行体验：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;技术报告：https://arxiv.org/pdf/2601.01554&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型主页：https://mosi.cn/models/moss-transcribe-diarize&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;API 接入：https://studio.mosi.cn/docs/moss-transcribe-diarize&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中展示了新模型的大量技术特点：其作为一个统一的多模态大语言模型，可以通过端到端的方式同时执行语音识别（ASR）、说话人归属和时间戳预测，消除可能产生的误差传播。&lt;/p&gt;&lt;p&gt;为了达成这些效果，MOSS-Transcribe-Diarize 在模型架构、训练数据组成上形成了一套自己的解法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在架构设计上，它采用了统一的音频 - 文本多模态架构。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;设计者将多说话人的声学表示投影到预训练文本 LLM 的特征空间中，使得该模型在单一的端到端框架内能够联合建模词汇内容、说话人归属和时间戳预测。&lt;/p&gt;&lt;p&gt;模型在一个推理过程中直接输出带有 [S01]、[S02] 标签和精确时间戳的文本。这种机制利用了语义信息来辅助说话人识别（例如，通过说话内容的连贯性来判断是否换人了），极大地提高了识别准确率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在训练数据的组成上，采用「虚实结合」的策略。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS-Transcribe-Diarize 使用大量真实世界的对话音频以及通过概率模拟器生成的合成数据进行训练，增强了对重叠语音、轮替和声学变化等性能指标的鲁棒性。该模型训练使用的真实数据包含了从公共语料库中采样的大量说话人片段，并覆盖了现实中不同类型的多说话人场景。&lt;/p&gt;&lt;p&gt;得益于架构与数据层面的一系列巧思，MOSS-Transcribe-Diarize 才能够一举攻克行业长期以来面临的长对话和多说话人转录难题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长短音频、切话叠音，多场景表现最优&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在与国内外顶级模型的较量中，MOSS-Transcribe-Diarize 在多个基准测试中拿下 SOTA 成绩。它究竟强在哪些方面呢？我们接下来进行了一番深入探究。&lt;/p&gt;&lt;p&gt;1）在&lt;strong&gt;包含近 40 分钟真实世界会议录音的 AISHELL-4 数据集&lt;/strong&gt;上，MOSS-Transcribe-Diarize 在 CER 和 cpCER 两项指标上大幅优于所有基线模型，并表现出了更低的 &amp;Delta;cp 值。这验证了相较于纯粹的 ASR 错误，由说话人归属错误引入的额外性能衰退要少得多，并由此证明了长上下文、端到端建模在长对话中维持说话人一致性方面的有效性。&lt;/p&gt;&lt;p&gt;相比之下，GPT-4o 和 Gemini 3 Pro 均无法可靠地处理 AISHELL-4 等长音频输入，前者受限于音频输入长度，无法完成完整录音转录；后者无法生成符合既定说话人归属格式的有效输出。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ03pW558PqlTxpTYhLdNUEQxMjMLziaLu7hmr4rrFsUGVhY51gayE2MUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529160" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/baa61a3f-8a29-42b6-ad4c-4038ff805a60/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2）在&lt;strong&gt;&amp;nbsp;Podcast 数据集&lt;/strong&gt;（多说话人播客访谈场景）上，MOSS-Transcribe-Diarize 再次取得所有参评模型中最低的 CER 和 cpCER。尽管其他基线模型也达到很高的 ASR 准确率，但在 &amp;Delta;cp 值这点上落败了。这表明，在频繁的话轮转换和长跨度的说话人重现场景下，MOSS-Transcribe-Diarize 能够让说话人归属更加准确。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0wAH5Eq9cd2M4EJwINa9yx0qaO59PZ9CUGqrq87PYzFjMeXZC28xjjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529078" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cc4b02b9-d2c3-4c11-830c-4e72499cac58/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;3）在&lt;strong&gt;&amp;nbsp;Movies 数据集&lt;/strong&gt;（复杂影视剧场景）上，强调短促话语、快速说话人交替以及频繁的语音重叠场景，MOSS-Transcribe-Diarize 面对这种短语音转录任务依然优于所有基线模型。它还在 CER 和 cpCER 两项指标之间保持了相对较小的差距，这意味着不仅能听清说了什么，还能非常精准地判断出是谁说的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0nvS6kWd3rgdOY3rUwjd4x0kjHrsqvy8kyev40ziaK1MuibZT7TM7PAlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529159" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/57239345-b869-41ad-8fb6-f6ed17baeb53/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;目标：情境智能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS 系列大模型的背后，是国内 AI 领域领军人物，复旦大学教授邱锡鹏带领的团队。在中国 AI 版图中，他们显得极具特色。该团队的 MOSS 模型是国内第一个对标 ChatGPT 并开源的对话式大语言模型，并提出了最早的具有内生语音能力的大模型 SpeechGPT 和原生端到端全模态大模型 AnyGPT。团队组建的模思智能（MOSI AI）则由上海创智学院与复旦大学自主孵化，是一家专注面向情境智能的多模态大模型公司。&lt;/p&gt;&lt;p&gt;他们保持了一条清晰且具有战略眼光的技术路径：&lt;strong&gt;让大模型理解复杂的真实世界情境，并以情境多模态实现通用人工智能。&lt;/strong&gt;在这条路线上，他们一直在不断探索，发布了一系列多模态领域的前沿技术成果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;去年 7 月，模思开源了革命性的对话语音合成模型&amp;nbsp;&lt;strong&gt;MOSS-TTSD&lt;/strong&gt;，能够根据完整的多人对话文本，直接生成高质量对话语音。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;去年 11 月，&lt;strong&gt;MOSS-Speech&lt;/strong&gt; 的发布展现了语音 AI 技术的突破，实现了 SOTA 性能。这是一个无文本引导的真端到端语音大模型，可以在保持模型高智商程度的前提下，解决人机低时延交互的挑战。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最近发布的&lt;strong&gt;&amp;nbsp;MOSS-Transcribe-Diarize&lt;/strong&gt;，则攻克了复杂日常多人对话场景的语音识别，对于多模态 AI 的实际落地具有重要意义。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一系列技术成果可覆盖实时对话交互、复杂场景音频生成、高鲁棒性语音理解、多模态交互等核心能力场景，在流畅度、响应速度、理解能力和可控性方面实现了行业领先表现。&lt;/p&gt;&lt;p&gt;面向未来，模思将持续深耕让 AI「理解用户所处的全局情境」的多模态智能，通过规模化物理世界的复杂真实情境，实现真正自然、连贯、可成长、可信赖的智能交互，推动多模态交互与具身智能的产业化落地。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>当黄仁勋将存储定义为「AI运行内存」，基础设施该如何实现物种进化？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:35:39 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜Panda&amp;nbsp;&lt;/p&gt;&lt;p&gt;一根 256 GB 内存条标价 5000 美元？这个价格已经轻松超过了英伟达顶配显卡 RTX 5090 的市场溢价。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JW5fhqyibMtv1Mc4icLwgUldO4SPLvp10W5aeCGEUaN0yg6SSvGwkTPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7512755102040817" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503528866" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8ec2cd31-a8e0-4db6-b13c-ca421e7f76fc/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 此推文引发了广泛讨论，已收获超 200 万浏览，图源：X@Yuchenj_UW&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;由于 AI 算力需求引发了极端的结构性紧缺，全球内存市场正陷入一场前所未有的疯狂。报道称 OpenAI 与三星电子、SK 海力士签署了大规模 DRAM 晶圆供应协议，其预估的 DRAM 晶圆需求可能达到全球 DRAM 晶圆产能的约 40%，这一需求规模在行业内引发了对存储供应紧张的关注。与此同时，微软、谷歌等大型科技公司也派出采购团队在韩国与这些主要存储芯片供应商展开密集谈判，以争取更多 DRAM 和高带宽存储（HBM）供应资源。&lt;/p&gt;&lt;p&gt;而就在 2026 年 1 月的 CES 演讲中，英伟达 CEO 黄仁勋又更进一步为这股趋势给出了极具分量的判断。&lt;/p&gt;&lt;p&gt;他指出，围绕 AI 推理与上下文的数据存储正在形成一个「此前从未真正存在过的市场」，并预测其规模很可能成长为全球最大的存储市场之一，因为它在本质上承载着全球 AI 系统的工作内存（working memory）。黄仁勋强调，AI 的工作负载在访问模式、时延要求和数据生命周期上都与传统数据库和存储系统截然不同，因此现有存储架构难以满足需求，存储技术本身必须经历一次根本性的重构。&lt;a href="https://mp.weixin.qq.com/s/w3GRxO8EsPpZJMlhyTQFKA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3956f995-b6b7-4cd7-a15c-8899686328aa/1768905020049.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种底层架构的变革需求，正是当下 AI 基础设施面临的一大核心挑战。&lt;/p&gt;&lt;p&gt;现在，一家成立已过十周年的公司对这一挑战发起了冲锋。&lt;/p&gt;&lt;p&gt;1 月 15 日， XSKY 星辰天合在北京举办了主题为「&lt;strong&gt;数据常青 智算无界&lt;/strong&gt;」的 AIMesh 产品战略发布会，并宣布战略重心从「&lt;strong&gt;信息技术（IT）&lt;/strong&gt;」全面跨越至「&lt;strong&gt;数据智能（Data Intelligence）&lt;/strong&gt;」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qnx0oTH8RxRKYXCcZwibLWkLEzK3RJbKibDpVDvaMeZj5WZwU0q3NiaPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528868" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/07f63fe5-ffa4-4782-bf66-bdee7a9e2852/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这家成立于 2015 年 5 月的企业，已经在十年多的时间里从初创团队成长为一头独角兽，&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzAwNTc0OTM1NA==&amp;mid=2652426304&amp;idx=1&amp;sn=17daab312c04acd94feb1a5607f6d7f5&amp;scene=21#wechat_redirect" target="_blank"&gt;更是已然成为中国对象存储市场的领跑者&lt;/a&gt;，并肩负起了中国核心产业超过 &lt;strong&gt;5500 PB&lt;/strong&gt; 关键数据的安全重任。不仅如此，该公司的增长势头依然强劲：在近三年实现了超过 &lt;strong&gt;50% &lt;/strong&gt;的逆势高增长；随着业务对性能渴望的加剧，其全闪存占比已翻了三倍，达到了 &lt;strong&gt;35%&lt;/strong&gt;。大规模存储方面，XSKY 已经拥有了 &lt;strong&gt;280&lt;/strong&gt; 个 &lt;strong&gt;10 PB&lt;/strong&gt; 级以上的超级集群，甚至跨越了&lt;strong&gt;单机群百 PB&lt;/strong&gt; 的技术门槛。这每一个数字的增长，都是客户投下的一张张信任票，也构成了 XSKY 应对 AI 大爆发的底层底气。&lt;/p&gt;&lt;p&gt;从这些数字也看得出来，AI 大爆发正在催动数据中心的进化。&lt;/p&gt;&lt;p&gt;过去十年的 IT 时代，数据中心的功能类似于一座严谨的「图书馆」，价值核心在于数据的「存得进、找得到」。但在进入数据智能时代后，数据的价值正在从「被检索」进化为「被计算」，每一份文档和图片都正成为生成未来的燃料。&lt;/p&gt;&lt;p&gt;为了适应这种转变，企业的数据中心必须完成一次物种进化，从安静的图书馆演变为一座日夜轰鸣的「AI 工厂」。&lt;/p&gt;&lt;p&gt;面对大模型时代的算力博弈，XSKY 确立了清晰的战略定位：&lt;strong&gt;通过发布 AIMesh 全栈 AI 数据方案，XSKY 致力于打造开放解耦且绝对中立的数据底座，旨在破解企业私有高价值数据向智慧转化的效率瓶颈。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14EXuibnnVku5egumUibbibX6Z1T1fgCAuU7icnYWyZPCUGrkp0x7icDB4rJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528867" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f48cafe3-edd3-4fd5-8cf8-5ab3cd1d48bb/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为什么「专有数据」是 AI 时代唯一的护城河？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大模型技术快速迭代的当下，业界逐渐达成了一个共识：算法正在走向同质化。&lt;/p&gt;&lt;p&gt;正如 AI 大牛 Andrej Karpathy 指出的那样，大模型（如 Transformer）的算法实现非常简洁，通常只有几百行代码。他提出，在大模型时代，数据不再仅仅是燃料，数据就是「源代码」。因为人类不再通过编写逻辑代码来解决问题，而是通过策划、清洗和标注特定的数据集，让模型通过学习这些数据来获得专家能力。&lt;/p&gt;&lt;p&gt;而对于企业而言，当领先的模型架构和训练方法变得透明且易于获取时，企业真正的差异化竞争优势和护城河，就在于其自身拥有的独特「&lt;strong&gt;专有数据&lt;/strong&gt;」。这些数据是企业长年累月积淀下的独有配方，也是将通用大模型转化为具备垂直领域专家能力的燃料。&lt;/p&gt;&lt;p&gt;出于安全和合规的考虑，这些高价值的核心数据不能外溢到公有云，它们必须牢牢掌握在企业自己手中。因此，构建一个私有化、安全且可控的 AI 数据底座成为了企业的刚需。&lt;/p&gt;&lt;p&gt;XSKY 的角色正是守住数据安全的底线，让企业能将私有数据在内部安全地转化为智慧。&lt;/p&gt;&lt;p&gt;这种对数据价值的深度理解，已经在行业头部的实践中得到了验证。刚刚在 1 月 9 日成功登陆港交所的 MiniMax 便是典型的例子。作为全球 AI 领域从创立到上市最快纪录的最新创造者，MiniMax 的成功证明了在算法日益透明的今天，私有数据资产才是支撑企业估值与竞争力的核心。&lt;/p&gt;&lt;p&gt;目前，MiniMax 有 PB 级的数据存放在 XSKY 的存储平台上，其中包括最核心的训练数据与推理模型数据。对于这类处于商业化爆发期的头部 AI 企业而言，存储底座的稳定性直接决定了研发的连续性。&lt;/p&gt;&lt;p&gt;这种需求的变化也预示着基础设施职能的彻底改变。正如前文所说，过去的数据中心更像是一座安静的「图书馆」，核心任务是确保数据「存得进、找得到」。但在 AI 时代，数据中心必须进化为一座日夜轰鸣的「AI 工厂」，数据不再是静止的档案，而是被不断计算、不断产生价值的动态资产。XSKY 的战略目标，就是帮助企业的专有数据完成这一物种进化，让基础设施能够支撑起从数据准备到模型训练再到推理部署的全生命周期。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AIMesh 如何推倒阻碍 AI 效率的「三堵墙」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大模型训练与推理的实战场景中，传统的存储架构正面临严峻的挑战。这些挑战可以被总结成三堵墙：IO 墙、重力墙和内存墙。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;IO 墙&lt;/strong&gt;：当算力的吞吐速度远远超过存储的读写速度时，计算单元被迫进入空转等待状态，导致 GPU 利用率往往低至 30% 到 50%。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;重力墙&lt;/strong&gt;：随着数据体量的指数级增长，跨地域流动的高昂成本让数据逐渐沦为孤岛，形成了难以逾越的「重力墙」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;内存墙&lt;/strong&gt;：随着 AI 应用向长上下文和复杂智能体（Agent）演进，KVCache 的爆炸式增长让显存（HBM）撞上了物理极限的「内存墙」，导致硬件投入成本急剧攀升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wajnnAKlMk5IpymHrPRIGghcZx3jma1sibB5BtTOgUvS8NfNRJgrZjw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.9825517993456925" data-s="300,640" data-type="jpeg" data-w="917" type="block" data-imgfileid="503528901" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b60556c9-0193-4379-8df8-edddce1aafb1/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;典型的「内存墙」：2018 年至 2025 年期间，Transformer 模型尺寸每 2 年增长约 19 倍，而每个加速器的内存每 2 年仅增长约 1.9 倍。不仅如此，过去 20 年间，峰值计算能力增长了约 6 万倍，但 DRAM 带宽仅增长了约 100 倍，互连带宽也仅增长了约 30 倍。结果就是：处理器闲置等待数据。来源：ayarlabs.com&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;要推倒这些深层物理层面的效率障碍，不仅需要软件架构的创新，更需要与底层芯片性能的深度适配。举个例子，作为这一进程的见证者，芯片巨头英特尔与 XSKY 的合作已经跨越了第一个十年。从早期作为 Intel SPDK 技术最早的一批贡献者共同探索用户态轮询技术，到如今实现对最新硬件的 Day-0 级技术响应，这种长期的技术共创为 AIMesh 全栈 AI 数据方案的发布奠定了基础。&lt;/p&gt;&lt;p&gt;基于这种长期的软硬协同积淀，XSKY 通过 AIMesh 构建了一张面向 AI 工厂的数据与内存网，旨在打破这三堵墙，进而利用架构创新将技术参数转化为真实的业务价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshFS：打破 IO 墙，加速模型训练&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对 AI 训练中严峻的「IO 墙」挑战，XSKY 发布了专为 AI 训练而生的并行文件系统 &lt;strong&gt;MeshFS&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14jHrBMUZadPicpmkFvzL0PnlY95icA61y1zW3OwnDNAv0amkGichz4p4Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528869" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/266606c9-c20a-4462-8091-b8dec6a74916/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该系统将 XGFS 成熟的企业级协议栈与 XSEA 星飞全闪架构的 Shared-Everything 极速底座深度融合，为软件栈注入了强劲的性能心脏。&lt;/p&gt;&lt;p&gt;为了彻底破解算力在等待数据时的损耗，MeshFS 在以下三个维度实现了技术突破：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全协议兼容&lt;/strong&gt;：MeshFS 提供标准的 POSIX 语义，这意味着现有的 Python 或 TensorFlow 训练代码无需修改即可运行。更重要的是其实现了「一份数据，多协议互通」，数据清洗可以通过 HDFS 接口使用 Spark，训练过程通过 POSIX 接口使用 PyTorch，归档则使用 S3。数据在全流程中不需要搬家，原地即可被不同的业务流处理。MeshFS 也完美支持 Kubernetes CSI。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;线性的极致性能&lt;/strong&gt;：通过全分布式架构和元数据分片技术，MeshFS 的性能可以随节点数线性增长。系统引入了 Run To Completion 技术，将元数据处理延迟压低至微秒级。即使面对亿级规模的小文件数据集，依然能保持顺滑的访问体验。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;企业级管理与智能分层&lt;/strong&gt;：在提供目录 QoS、配额以及审计等完善特性的同时，MeshFS 支持智能分层能力。数据可以在全闪存层和低成本层之间透明流动，让用户能够以 Tier-2 的成本存储数据，同时享受 Tier-0 的训练速度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在性能实测中，MeshFS 凭借「一跳读」设计&lt;strong&gt;实现了顺序读带宽 30% 的提升&lt;/strong&gt;，同时&lt;strong&gt;依靠端到端 EC 写技术让顺序写带宽超出同类产品 50%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;此外，MeshFS 还针对英特尔新一代至强处理器的 AVX-512 与 AMX 指令集进行了深度优化。&lt;/p&gt;&lt;p&gt;在刚刚完成 IPO 的大模型企业 MiniMax 的生产环境中，MeshFS 提供了高吞吐、低延迟的 I/O 支持。无论是在大规模数据的 DataLoad 阶段，还是在关键的 Checkpoint 保存环节，MeshFS 都能有效保证训练效率。而在推理端，MeshFS 的高吞吐特性支撑了近万个推理服务在极短时间内上线，确保了海螺 AI 等核心产品在全球市场的竞争力。&lt;/p&gt;&lt;p&gt;在这种顶级 AI 企业的高强度实战中，XSKY 的技术架构经受住了考验，成为了支撑其走向资本市场的坚实底座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshSpace：推倒重力墙，实现全局流动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对「重力墙」，XSKY 给出的解决方案是 &lt;strong&gt;MeshSpace&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ialN0CV0cPjNBBJjwuIkSWFJcOybsiaF2kPUFv3RUyibgtgKcJRxHgWaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528870" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e33e3f1c-292a-497f-bed7-972c2994564b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为面向 EB 级数据的全局非结构化数据平台，MeshSpace 实现了从「单桶千亿」到「单桶 EB」的架构演进。&lt;/p&gt;&lt;p&gt;MeshSpace 通过三大核心能力，重新定义了大规模存储的治理模式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;平滑演进能力&lt;/strong&gt;：MeshSpace 能够直接纳管企业现有的 XEOS 集群。这意味着过去十年积累的数据资产无需经历痛苦的迁移过程，即可原地升级并融入新的 AI 训练流。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全局控制面统一&lt;/strong&gt;：这是架构设计中最具突破性的地方。通过统一的 DNS 接入，MeshSpace 将分散在不同物理机房、甚至是云端的物理集群抽象为一个逻辑整体。对于业务端而言，无论底层物理资源如何离散，都只有一个统一的入口。物理上是离散的，但在逻辑上，它们就是「一套存储」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据治理全局化&lt;/strong&gt;：MeshSpace 支持异构存储平台的统一调度。数据可以在全闪存、HDD 甚至磁带之间，根据数据温度和业务需求自由流动，确保热数据能够快速参与计算，冷数据能够自动沉降以降低成本。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在性能表现上，MeshSpace 带领对象存储正式迈入了「&lt;strong&gt;百万 OPS 单桶时代&lt;/strong&gt;」。单个对象存储桶可以每秒支持高达一百万次对象写入，以及数百万次对象读取，这一规格远超主流公有云产品的单桶性能上限。不仅如此，XSKY 还对 XScale 最底层的分布式 KV 引擎进行了彻底的优化，让 AI 训练中关键的&lt;strong&gt;大块写性能提升了近 50%&lt;/strong&gt;，同时将&lt;strong&gt;延迟降低了 30%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种架构精准击中了 MiniMax 等混合云用户的痛点。由于采用了混合云架构，数据孤岛带来的跨域调度成本曾是其核心挑战。MeshSpace 几乎是为其量身定制的解决方案，通过统一的全局命名空间收敛数据入口，业务端不再需要感知数据的真实物理位置，从而彻底解决了数据迁移带来的低效问题，极大降低了管理成本。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshFusion：击穿内存墙，降低推理成本&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;至于最后的内存墙，XSKY 推出了一种面向 KVCache 的「持久化内存」方案 &lt;strong&gt;MeshFusion&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;MeshFusion 运行在 GPU 服务器内部，通过创新的软件栈将本地 NVMe SSD 资源池化，转化为可供 GPU 直接调用的 L3 级外部内存。&lt;/p&gt;&lt;p&gt;不仅如此，MeshFusion 还拥有三大必杀技：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;零拷贝&lt;/strong&gt;：数据从 SSD 直通 GPU 显存，极大降低延迟。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致并发&lt;/strong&gt;：专为 KVCache 的小 IO、高并发写入优化，支持原子提交。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;协议自适应&lt;/strong&gt;：兼容 vLLM、SGLang 等主流推理框架，代码零修改。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实测数据显示，&lt;strong&gt;该方案能以 1% 的硬件成本实现近乎无限的上下文窗口，且性能与 DRAM 的差距保持在 10% 以内。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;云计算服务商 ZStack 表示，MeshFusion 的 SSD 扩展内存能力将显著降低 AI 服务规模化部署的门槛，并计划将其与自身的 AIOS 智塔平台展开深度集成。同时，XSKY 正在与英特尔联合预研基于 CXL 技术的内存池化方案，旨在彻底打破物理内存边界，为万亿参数模型提供充裕的资源池支持。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据常青与绝对中立的战略定力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在当前「百模大战」的背景下，技术架构与算法模型正处于剧烈的变动期。对于企业决策者而言，在极高的不确定性中做出确定的选择至关重要。XSKY 给出的答案是&lt;strong&gt;坚持开放解耦，做绝对中立的数据底座&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一战略背后蕴含着深刻的时间逻辑。在 XSKY 看来，算力硬件（GPU）的生命周期通常只有&lt;strong&gt; 3 到 5 年&lt;/strong&gt;，属于快速迭代的变量。相比之下，承载着企业智慧的代码、文档与影像等数据资产，其存续周期通常长达 &lt;strong&gt;10 到 20 年&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，XSKY 提出了「&lt;strong&gt;数据常青&lt;/strong&gt;」的理念，主张用一个稳固、长周期的底座去支撑上层快速演进的算力竞争，以不变的底座应对万变的未来。&lt;/p&gt;&lt;p&gt;为了实现这种确定的支撑，&lt;strong&gt;XSKY 始终坚持不绑定任何一种特定的算力平台&lt;/strong&gt;。无论企业选择英伟达，还是昇腾、寒武纪、摩尔线程、沐曦等国产芯片，AIMesh 都能提供统一且标准的数据服务。这种中立立场赋予了客户在算力博弈中的主动权，使其能够根据业务需求自由选择最合适的硬件资源，而不必担心被特定生态锁死。&lt;/p&gt;&lt;p&gt;这种对中立与解耦的坚守，也让 XSKY 在生态构建中获得了深厚的信赖。以 ZStack 为例，双方在云计算时代便是「存算分离」建设的优选组合，彼此被称为「背靠背的战友」。进入 AI 时代，这种默契得到了延续。ZStack 认为 AIMesh 的架构设计与其 AIOS 智塔战略高度契合，双方计划在智算中心建设中继续复制云时代的成功经验，共同成为智能算力基础设施中可靠、高效的算存基石。&lt;/p&gt;&lt;p&gt;从云计算到大模型，技术浪潮几经更迭，但 XSKY 始终致力于解决大规模数据存储与利用的核心需求。正如发布会所强调的，XSKY 的使命是做企业数据资产的守门人，同时也是 AI 之路的加速器。&lt;strong&gt;通过构建高效、可控的 AI 工厂，XSKY 将持续助力企业打破算力与数据的边界，实现智算无界。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;做数据资产的守门人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年 1 月 15 日举行的这场战略发布会，标志着 XSKY 将其十年的技术积累全面导向 AI 场景。AIMesh 全栈方案的发布，是 XSKY 面对智算时代给出的一份阶段性答卷。&lt;/p&gt;&lt;p&gt;回顾这十年的进阶历程，XSKY 对 AI 浪潮的布局早在数年前就已经开始。在 2022 年，公司便预判到了 AI 对于极致性能与数据治理的迫切需求，并投入研发了 &lt;strong&gt;XSEA 全闪底座&lt;/strong&gt;与&lt;strong&gt; EasyData 数据管理平台&lt;/strong&gt;。作为 Shared-Everything 架构的极速底座，XSEA 已经通过了金融核心交易与自动驾驶算力中心等严苛场景的验证，为今天的 MeshFS 提供了澎湃的性能心脏。而 EasyData 则作为数据编排与治理的中枢，面向从采集、清洗到归档的完整链路提供全局管理，确保了 AI 数据全生命周期的有序流动。&lt;/p&gt;&lt;p&gt;正是基于这些关键技术点的长期深耕，XSKY 才能在今天完成从「单点极致」到「全局统领」的架构升维。这一战略升级的核心目标在于破解企业私有高价值数据向智慧转化的效率瓶颈。&lt;/p&gt;&lt;p&gt;在未来的竞争中，算力硬件的生命周期可能只有 3 到 5 年，但承载企业智慧的数据资产却要存续 10 到 20 年。XSKY 将继续坚守「数据常青」的理念，通过提供开放且解耦的基础设施，支撑上层快速迭代的算力竞争。作为数据资产的守门人，XSKY 同时也是企业 AI 之路的加速器。在智算中心需求爆发的未来，XSKY 将持续助力企业打破存储与计算的边界，确保私有数据资产高效转化为智能优势。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>从平面几何出发：形式化验证如何驱动MLLM的推理能力跃迁</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:27:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/cf61d82f-f59f-4cc9-8777-eac1eee8c7ec/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在迈向通用人工智能（AGI）的征途中，多模态大语言模型（MLLMs）虽然在视觉理解与文本生成上展现了惊人的能力，却始终面临一道难以逾越的鸿沟：如何在复杂的数学与几何推理中，克服固有的幻觉与逻辑断层？ 现有的 &amp;ldquo;结果导向&amp;rdquo; 训练往往掩盖了推理过程的脆弱性，导致模型常常 &amp;ldquo;蒙对答案&amp;rdquo; 却 &amp;ldquo;想错过程&amp;rdquo;。这种 &amp;ldquo;黑盒&amp;rdquo; 式的学习方式，使得模型难以习得真正鲁棒的推理能力。&lt;/p&gt;&lt;p&gt;面对这一挑战，来自&lt;strong&gt;上海交通大学、复旦大学、香港中文大学（深圳）、上海人工智能实验室等研究机构的团队&lt;/strong&gt;提出了一套全新的系统化解决方案：&lt;strong&gt;&amp;ldquo;Formal Enhance Informal Reasoning&amp;rdquo;（以形式化增强非形式化推理）&lt;/strong&gt;。该方案的核心洞察在于：利用领域内（In-Domain）极度严谨、可验证的形式化逻辑，可以作为一种强有力的监督信号，去规范和引导模型在非形式化场景下的推理行为。 更进一步，研究发现这种在严谨数学环境中习得的逻辑素养，不仅仅局限于几何题，更能作为一把通用的钥匙，解锁模型在通用数学乃至更广泛推理任务上的分布外（OOD）泛化能力。&lt;/p&gt;&lt;p&gt;基于这一理念，团队历经三个阶段的探索，构建了从数据底层到模型顶层的完整闭环：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;TrustGeoGen（数据基石）&lt;/strong&gt;：针对现有数据噪声大、逻辑自洽性差的问题，构建了首个形式化验证的几何数据合成引擎。通过集成多模态对齐、全路径形式化验证及 GeoExplore 探索算法，生成了 GeoTrust 数据集，确保每一条数据的逻辑链条都经过数学层面的严格验算，为后续工作提供数据和验证环境保障。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;GeoBench（深度诊断）&lt;/strong&gt;：为了精准定位模型推理短板，提出了基于分层能力评估的基准测试。它将几何推理拆解为视觉感知、目标规划、定理应用、自我反思四个层级，并引入了 &amp;ldquo;无关条件过滤&amp;rdquo; 与 &amp;ldquo;逻辑纠错&amp;rdquo; 等高阶任务，揭示了推理模型在复杂任务中的逻辑局限性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;SGVR（能力跃迁）&lt;/strong&gt;：针对 &amp;ldquo;结果监督&amp;rdquo; 的不足，提出了 Sub-Goal Verifiable Reward 训练框架。该框架将抽象证明转化为可执行的数值子目标（Milestones），利用 Skeleton Rate 提供密集奖励信号。实验证明，这种训练不仅在几何领域提升显著，更实现了向通用数学及逻辑推理任务的强力迁移。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;相关论文：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14vHoRL33VTM2TpWWNlCiaWHuaaTnzsOsZ36y0dXbHvS0PZssUfMh1ofg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.27314814814814814" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528861" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4e404214-1d5f-4bc8-b95d-1516e462b962/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2504.15780&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14yMna6c3RN9VvCZPEcau8JKlQtgTUdBc8yuD4AcGkbE4I2da1zBIPgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.35" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528862" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d105c6a5-2d18-4450-b301-13aef30181b4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：GeoBench: Rethinking Multimodal Geometric Problem-Solving via Hierarchical Evaluation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2512.24119&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14oev1MH8XvtV4WoIicI5cqogcHKdpUUONfxXia4zCld0sU8kVWfBMwdyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.412962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528864" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3fe1faf9-ef9d-4bdc-9121-e3c40b8b8e6a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.05073&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;如何构筑可信推理的基石？TrustGeoGen：形式化验证的几何数据合成引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;如何使训练数据没有逻辑漏洞？&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;连贯且准确的推理过程是可信推理的基础，每一步推理都应该由明确的前置结论和定理推导出。如图 1 所示，TrustGeoGen 用 constructor, reasoner, sampler 和 translator 四个模块来构造问题、扩充推理图谱、回溯推理路劲和转译自然表达。其中，形式化推理引擎 DDAR 被用来保证每一个结论都由预定义的定理规则得到，从而保证了推理链路的连贯性和可解释性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Xiaia5F0YicpknvhlRYias087rOuys2q4PGWMR8pTyiazYN59CjZYs9t7eQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5907407407407408" data-type="png" data-w="1080" data-width="1819" data-height="1075" data-imgfileid="503528865" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4b4d8099-7bc4-4127-a903-f19b02c1f030/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1 TrustGeoGen 可信数据构造流程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;然而，形式化引擎以遍历的方式获得每一个推理步骤，它可以保证推理步骤是正确的，但是无法解释为什么应该这样做。这样的数据仿佛解题过程被省略的参考答案，只能让大模型记住结果而无法真正掌握推理能力。如图 2 所示，connection thinking 被用来帮助构造思考过程性数据。每个推理步骤前，connection thinking 都会显式地、根据最终目标来分析当前已经拥有的结论和下一步应该得到什么结论。将推理步骤以深度思考的方式连接到一起，让模型真正掌握推理能力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD149BUibsXqUvNo1Qt0rGic43FATZupUHa5XT6P9RjPP5iaIr9dVPoEiazT2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.2638398115429919" data-type="png" data-w="849" data-width="849" data-height="1073" data-imgfileid="503528871" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d342e0ce-aa8a-41cb-9bf1-c31c738807cb/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 2 过程性思考数据构造流程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;最后，推理的魅力在于结合已有的信息向未知发起冲锋。这个过程中可能存在错误，也需要进行多次的验证。掌握更多的思维模板（而不是只会链式思考）可以帮助模型应对不同的情况。如图 3 所示，在 sampler 阶段采用不同的采样方式，可以获得具有不同思维模板的推理数据，丰富大模型的推理 &amp;ldquo;技能库&amp;rdquo;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qvX4FjyaZ8bMybIwQoT7iaSOt8KeXnm39ZEhydEUDBkHZZ9AEGSq4ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6697848456501403" data-type="png" data-w="1069" data-width="1069" data-height="716" data-imgfileid="503528876" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/84cb3565-e6ef-4d6a-bda9-d608c359af51/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 3 多解和回溯思维模板数据构造示意图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;TrustGeoGen 不仅以可验证的方式生成大量的几何推理数据，更关注到了自然语言推理与形式化推理的差异，从模型训练的角度来生成连贯可信的推理数据，为提高多模态大语言模型的推理能力奠定了基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理短板究竟在哪里？GeoBench：从感知到反思的分层诊断基准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;做对了几何题，真的意味着模型&amp;lsquo;懂&amp;rsquo;了几何吗？&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当我们为多模态大模型在 GeoQA 等基准上超越人类的表现欢呼时，一个严峻的问题被掩盖了：现有的评估往往只看最终答案，却忽视了推理过程的严谨性。模型是真正掌握了空间逻辑，还是仅仅记住了教科书里的解题套路，甚至只是为了正确答案而在作 reasoning hacking？为了刺破这层迷雾，精准定位模型能力的边界，我们提出了 GeoBench &amp;mdash;&amp;mdash; 一个基于 TrustGeoGen 数据引擎而构建的分层诊断基准。&lt;/p&gt;&lt;p&gt;GeoBench 不再满足于单一的分数，而是将复杂的几何推理能力拆解为四个层层递进的维度：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. &lt;/strong&gt;&lt;strong&gt;视觉感知（Visual Perception）&lt;/strong&gt;：模型能否从图中精准提取数值与结构信息？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 目标导向规划（Goal-Oriented Planning）&lt;/strong&gt;：模型能否将大问题拆解为可操作的子目标？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 严谨定理应用（Rigorous Theorem Application）&lt;/strong&gt;：模型能否在众多定理中精准筛选出适用的那一条？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. 自我反思回溯（Self-Reflective Backtracking）&lt;/strong&gt;：当推理误入歧途时，模型能否及时发现并修正？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14L1eYsvibkksPekicibibctblXbUEBHKKQBPOgcKiazLk7YExGBHbhlmNg8g/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5916666666666667" data-type="png" data-w="1080" data-width="1881" data-height="1113" data-imgfileid="503528877" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b6d7af22-1f7e-4c44-b141-fc01cd6a11b8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4 GeoBench 概览：利用 TrustGeoGen 引擎生成包含图像、问题及推理图的形式化验证几何题，并基于四个推理能力层级，系统化构建分层评测任务&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;基于 TrustGeoGen 引擎生成的 1021 个形式化验证样本，我们设计了六大核心任务对模型进行全方位评估。实验结果不仅揭示了推理模型的短板，更带来了一些全新的发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;能力断层&lt;/strong&gt;：即使是 OpenAI-o3 这样的顶尖推理模型，随着任务复杂度的提升，性能也呈现显著下降趋势。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键瓶颈&lt;/strong&gt;：子目标分解（Sub-Goal Decomposition）无关条件过滤（Irrelevant Premise Filtering）是决定解题成败的最关键因素。这意味着，比起单纯的计算能力，模型更缺乏 &amp;ldquo;排除干扰、规划路径&amp;rdquo; 的大局观。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CoT 的反作用&lt;/strong&gt;：思维链（Chain-of-Thought）并非万能药。在涉及 &amp;ldquo;错误定位&amp;rdquo; 的高阶反思任务中，CoT 提示甚至会产生负面干扰，导致模型在错误的路径上越走越远。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14pQIpsAz47u8yDOvBs0AqkFv7IcaeQqWnbyKDHgtqzWK17ZDcsLhaPw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.1709090909090909" data-type="png" data-w="825" data-width="825" data-height="141" data-imgfileid="503528878" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3cad1706-13ef-4bea-9d33-21a4fbfe389f/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 1 模型在 GeoBench 的 6 个任务上的表现与求解出最终正确答案的相关性（spearman 系数）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;GeoBench 的出现，不仅是一次评测标准的升级，更为未来的几何推理系统指明了进化方向：从盲目追求答案正确率，转向对推理全过程的精细化掌控。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果监督是否足够？SGVR：用可验证的 &amp;ldquo;里程碑&amp;rdquo; 引导通用推理泛化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;平面几何训练场可以实现域外泛化吗？&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GeoBench 的诊断揭示了传统训练的致命弱点：模型常因 &amp;ldquo;虚假相关性&amp;rdquo; 而 &amp;ldquo;蒙对结果&amp;rdquo;，中间过程却充满幻觉。为了打破这种 &amp;ldquo;黑盒&amp;rdquo;，我们提出 SGVR (Sub-Goal Verifiable Reward) 框架，主张 &amp;ldquo;里程碑重于结果&amp;rdquo;（Milestones over Outcome）。我们利用 TrustGeoGen 将抽象证明拆解为一连串可自动验证的数值子目标，并引入 &lt;strong&gt;Skeleton Rate (SR) &lt;/strong&gt;作为核心指标 &amp;mdash;&amp;mdash; 它不再只看最终答案，而是计算推理链条中正确 &amp;ldquo;路标&amp;rdquo; 的比例。配合 GRPO 算法，这种密集的中间奖励强迫模型 &amp;ldquo;步步为营&amp;rdquo;，只有每一步逻辑都经得起验证，才能获得高分。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HYSXicO05icKg5XwS2Vf37k6F7DiaMDGW7HzsRo47qWheATbkRNaq4fPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.637962962962963" data-type="png" data-w="1080" data-width="1265" data-height="807" data-imgfileid="503528879" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/4e3b0123-921c-4986-8c39-006616a635fc/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5 SGVR 的核心机制：利用形式化引擎将复杂的几何证明题分解为多个可验证的数值子目标（Milestones）。通过引入 Skeleton Rate (SR)，模型在每完成一个中间路标时都能获得即时的密集奖励反馈，从而纠正逻辑幻觉，确保推理路径的每一步都精准可信。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这种训练带来了意想不到的惊喜：几何逻辑的 &amp;ldquo;溢出效应&amp;rdquo;。 SGVR 不仅让模型在几何推理任务上实现了&lt;strong&gt; 9.7%&lt;/strong&gt; 的显著提升，更展现出了强大的跨域泛化能力。在完全未见过的 通用数学（AMC, MATH-500） 和 通用逻辑推理 任务中，模型在零样本（Zero-shot）条件下分别获得了 &lt;strong&gt;8.0%&lt;/strong&gt; 和&lt;strong&gt; 2.8% &lt;/strong&gt;的性能跃升。这有力地证明：在高度严谨的几何环境中习得的 &amp;ldquo;验证思维&amp;rdquo;，能够转化为通用的逻辑素养，成为解锁复杂推理难题的关键钥匙。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14KeNTF43l9MicMMEHpbQJERkR2sXicUXHLj8j6fic1uxbeBgsJYLlNz1Mg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3638888888888889" data-type="png" data-w="1080" data-width="3398" data-height="1236" data-imgfileid="503528880" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/b3bc633b-f4c7-4a30-828c-57b9548c460e/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 6 SGVR 在显著提升几何推理能力的同时，展现了卓越的 &amp;ldquo;溢出效应&amp;rdquo;：在完全未接触过的通用数学（AMC, MATH-500）和逻辑推理任务中，模型性能均实现了显著跃升&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在确定了 &amp;ldquo;过程监督&amp;rdquo; 的有效性后，一个核心问题随之而来：我们需要对推理链条进行多大程度的干预？在 SGVR 的消融实验中，我们通过调节 &lt;strong&gt;Mask Ratio&lt;/strong&gt;（即隐藏子目标的比例）探索了验证密度对模型能力的影响。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14vN0GqOqMj9LhtP75CBysjwO97vMibHwv1Rup7C0qYT3UrRO7FVZUwCw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.7675925925925926" data-type="png" data-w="1080" data-width="1237" data-height="950" data-imgfileid="503528881" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/020ecff6-dd76-4f9e-8da4-28cdabcfb9a1/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 6 验证密度对推理性能的影响 &amp;mdash;&amp;mdash; 寻找监督的 &amp;ldquo;黄金分割点&amp;rdquo;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;图 6 的实验结果揭示了一个有趣的现象：&lt;strong&gt;验证并非越密越好，而是存在一个 &amp;ldquo;黄金比例&amp;rdquo;&lt;/strong&gt;。当我们将验证颗粒度保持在适中水平时，模型不仅能获得足够的纠错信号，还能保留一定的自主推理空间。一旦验证过于稀疏，模型会退回到 &amp;ldquo;结果赌博&amp;rdquo; 的老路；而过度的干预则可能导致模型过拟合于特定的验证路径，丧失了处理复杂变体的灵活性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;形式化增强的未来：通往鲁棒性推理的新范式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对当前推理模型普遍存在的逻辑断层与过程不可控问题，团队通过构建从可信数据合成、分级能力诊断到过程监督训练的一整套系统化方案，构建了一个完整的逻辑闭环。该闭环的核心在于：利用形式化验证的严谨性来约束与增强非形式化的推理过程，并通过在特定领域内的深度训练，赋予模型跨越领域边界的广义泛化能力。&lt;/p&gt;&lt;p&gt;这一研究范式表明，平面几何不仅仅是评估模型能力的试金石，更是训练 AI 具备高阶逻辑思维的最佳演练场。未来，团队将致力于将这种 &amp;ldquo;形式化增强&amp;rdquo; 的范式拓展至通用数学、代码生成、物理模拟等更广泛的领域，旨在构建更可信、更鲁棒且具备强大泛化能力的通用推理大模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于 FrontierX Lab：&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14mpEpgx67UKuZn9yicibtZrP9LQRjTdItIbcx7icuBtPTfhIj8eChN7uVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.20833333333333334" data-type="png" data-w="1080" data-width="1330" data-height="277" data-imgfileid="503528882" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c2f31278-0444-49e6-856d-5594b1369bda/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;FrontierX Lab 由上海交通大学人工智能学院助理教授夏纫秋创立，致力于探索人工智能的前沿边界，实验室核心方向涵盖形式化增强的推理大模型、多模态文档理解以及 AI 驱动的自动化科学发现等。实验室长期招募对符号 AI、多模态推理及前沿科学探索充满热情的博士 / 硕士研究生、科研助理及实习生，欢迎发送简历至 xiarenqiu@sjtu.edu.cn，共同拓展 AI 推理的认知边界！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>具身基座模型的曙光初现？35000小时训练数据，打造全球最强跨本体VLA</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 16:06:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;ul&gt;&lt;li&gt;项目官网：https://research.beingbeyond.com/being-h05&lt;/li&gt;&lt;li&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"box-sizing: border-box;font-style: normal;font-weight: 400;text-align: justify;font-size: 16px;color: rgb(62, 62, 62);","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"letter-spacing: 1px;padding: 0px 3px;line-height: 2;box-sizing: border-box;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;论文链接：https://research.beingbeyond.com/projects/being-h05/being-h05.pdf&lt;/span&gt;&lt;/li&gt;&lt;li data-pm-slice="0 0 []"&gt;&lt;span data-eleid="6"&gt;GitHub代码开源：https://github.com/BeingBeyond/Being-H&lt;/span&gt;&lt;/li&gt;&lt;li data-pm-slice="0 0 []"&gt;HuggingFace模型开源：https://huggingface.co/BeingBeyond/Being-H05-2B&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在竞争日趋白热化的具身智能领域，行业主要聚焦于有限的本体市场。本体出货量的高低，不仅决定了自身数据的积累规模，更从根本上框定了基于该本体开发的算法性能上限&amp;mdash;&amp;mdash;用户基数越大，本体在真实场景中的综合表现往往就越强，形成一种近乎&amp;ldquo;马太效应&amp;rdquo;的商业闭环。&lt;/p&gt;&lt;p&gt;如今，这一固有的行业逻辑正在被打破：&amp;nbsp;BeingBeyond团队推出的全球最强跨本体VLA模型Being-H0.5，通过整合数万小时人类视频以及当前全球几乎所有主流机器人构型的操作数据，在视觉‑语言‑动作（VLA）任务中展现出惊人的跨本体泛化能力&amp;mdash;&amp;mdash;无论硬件形态如何差异，模型皆能快速适应、稳定执行。&lt;/p&gt;&lt;p&gt;在长达40多页的技术报告中，BeingBeyond 研究团队回答了这样一个问题：&lt;/p&gt;&lt;p&gt;&amp;ldquo;诚如不同语言虽具有各自的字母、单词，但总会或多或少共享部分底层的语法和逻辑结构，我们是否能让模型像掌握一门小语种一样，在一个数据有限的机器人本体上高效地部署任务技能？&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEGfHjnNtfSbe6XWSMDHE6pSNiaO0yFYd8Fbz208AuXmxn5sZq5Soapuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7898148148148149" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEGfHjnNtfSbe6XWSMDHE6pSNiaO0yFYd8Fbz208AuXmxn5sZq5Soapuw/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="572" data-cropsely2="460" data-imgfileid="100000522" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b4b23049-51a6-4dc8-8ef8-e8ea1946340c/640.png" alt="图片" data-before-load-time="1768896114273" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;图示中在多种形态机器人上部署的任务均由同一个模型checkpoint实现&lt;/p&gt;&lt;p&gt;研究团队认为，目前的 Vision-Language-Action (VLA) 模型大多是&amp;ldquo;单语者&amp;rdquo;：在一个平台上表现优异的模型，换到另一个本体上往往难以成功部署。这种形态异构性和数据稀缺性，成为了通向通用机器人智能的最大障碍。&lt;/p&gt;&lt;p&gt;为了打破这一僵局及回答上面的问题，研究团队推出了 Being-H0.5。其核心理念在于：将人类的交互行为视为物理世界的&amp;ldquo;母语&amp;rdquo;，通过在不同机器人本体之间共享&amp;ldquo;通用语法&amp;rdquo;，来实现VLA在跨本体部署上的超强泛化能力；通过体量近乎没有上限且能够赋予模型广泛轨迹意图、物理与空间先验信息的人类视频，有效避免模型在预训练过程中坍缩到单一本体的低维流形，从而真正实现低成本、跨本体泛化，以及纯依靠实验室数据所不具备的场景泛化能力。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;UniHand-2.0:打造全球最大规模的具身预训练数据集&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;泛化能力的根源首先来自于庞大的高质量数据。为此，研究团队在前作数据集UniHand-1.0的基础上，提出了其2.0版本。该数据集总时长超过3.5万小时，囊括14,000 小时的机器人操作数据， 16,000 小时的人类视频数据，以及5000小时通用多模态数据，总训练 token 数突破 1200 亿。这是全世界首次在机器人领域进行如此大规模、跨本体的数据整合和预训练尝试。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEmV3bHdwcceEjS7QP7cVD4icJxN8PiaSkJN3p9kRbVQd6BhFo2KIWjVxg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000505" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5c070193-61ca-4b62-8ec2-7d80b0193967/640.png" alt="图片" data-before-load-time="1768896114706" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;规模相仿的人类视频、机器人操作、通用多模态数据混合构成&amp;ldquo;铁三角&amp;rdquo;&lt;/p&gt;&lt;p&gt;与以往仅基于&amp;ldquo;轮式底盘 + 双臂夹爪&amp;rdquo;范式的研究（如 &amp;pi; 系列工作）不同，UniHand2.0 第一次实现了跨本体的大规模数据融合，汇集了超过 30 种 不同硬件构型的多样化数据，涵盖了从桌面机械臂到双足机器人在内几乎所有已知的机器人形态。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEbOicdh5D0vbSe2GSp6x9nL9n4A4XiaZYexbJ5eLd5AmJhviaj4EsGQgfQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000506" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/37b780be-4ecb-4d15-923b-a7510018286c/640.png" alt="图片" data-before-load-time="1768896115123" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;UniHand与现有VLA数据集规模对比：超3.5万小时和30余本体，在规模和多样性上提升了3倍以上&lt;/p&gt;&lt;p&gt;针对人类视频普遍缺乏高质量标注的痛点，团队还设计了一套名为 UniCraftor 的便携、可扩展、低成本的人类视频采集系统：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyERlKvib2pLIFZhicAThBhiaJtaP3DgnXicDpsaZWP9KNLuboMib4kL6AXCag/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.45740740740740743" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000507" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/426da185-36b3-4539-9b56-182ca6f72d25/640.png" alt="图片" data-before-load-time="1768896115156" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;统一动作空间&lt;/strong&gt;&lt;strong&gt;（Unified Action Space）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;在 Being‑H0.5 之前，尚未有研究尝试将如此多异构本体数据统一用于训练&amp;mdash;&amp;mdash;其核心挑战在于，不同机器人的状态空间与动作空间差异巨大，直接混合训练极易引发&amp;ldquo;数据冲突&amp;rdquo;，导致模型难以收敛或泛化。&lt;/p&gt;&lt;p&gt;为解决上述难题，BeingBeyond 团队创新性地提出了统一动作空间框架，将双足人形、轮式底盘、桌面机械臂、夹爪、灵巧手等形态各异的机器人，映射到同一特征表示空间中，从而有效支撑跨本体联合训练与知识迁移。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;以人为中心的训练范式：（&lt;/strong&gt;&lt;strong&gt;Human‑Centric Learning）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;在统一动作空间的基础上，以UniHand-2.0作为数据源，Being‑H0.5 提出了一套完整的以人为中心的预训练范式，具体包括：&lt;/p&gt;&lt;p&gt;统一序列化建模：不再为人类演示、机器人轨迹和视觉文本数据设立独立的训练流水线，而是将它们转化成统一的多模态token序列。在这个序列中，视觉和文本负责提供背景信息，而统一的&amp;ldquo;状态/动作&amp;rdquo;Token 则承载物理交互信号。&lt;/p&gt;&lt;p&gt;混合监督（多目标优化）：在同一个序列上根据数据特点应用不同的损失函数。如针对文本数据（如 VQA、运动描述）的Next-token Prediction；针对离散人类动作的Masked Token Prediction，针对连续人类和机器人数据，则在统一空间内进行动作预测（Action Prediction）等。&lt;/p&gt;&lt;p&gt;这种融合的预训练方式能让模型能在从人类行为中提取高层级的、可迁移的交互逻辑（先验）的同时，从机器人数据中提炼高精度的运动控制知识。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEjdYYbhwW5086vhZyc2svkP4cAMLpHBMchWRjiaeW2ogDlfOaWY09aog/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000508" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/47691311-4023-4a37-bb36-c508c44de5d4/640.png" alt="图片" data-before-load-time="1768896115539" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;Being-H0.5模型架构和预训练示意图，MoE+MoF结合的构型&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;面向跨本体的模型架构升级&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;传统的VLA，尤其是近期流行的基于flow-matching架构的模型，其模型容量由于参数大小存在限制，这导致VLA在混合异构数据进行预训练时的性能下降，同时也阻碍了模型泛化到各种复杂下游任务的能力。为了克服这个问题， 团队针对性地进行了一系列架构创新。&lt;/p&gt;&lt;p&gt;首先，受大模型 MoE 架构启发，团队设计了 Mixture-of-Flow（MoF） 架构，将动作专家（action expert）解耦为负责学习通用的运动原语（如：物体如何运动）的共享专家，以及通过机器人感知路由，负责特定形态精准执行的特化专家。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyELq3tsgX2DycddT2npwKPq9V3HG24dbqARHabdiapQtesWuWibmXUOa0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.23425925925925925" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000509" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5f45eea2-fa10-4128-87e6-4b119a30e57a/640.png" alt="图片" data-before-load-time="1768896117222" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;MPG和UAC模块示意图&lt;/p&gt;&lt;p&gt;此外，针对现实部署中的抖动和延迟问题，团队引入了 流形保持门控（Manifold-Preserving Gating, MPG）以确保在感知模糊时模型能退回到鲁棒的先验分布；以及通用异步分块（Universal Async Chunking, UAC）技术，使同一个模型能完美适配不同控制频率和延迟的机器人硬件。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;海量实验验证&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEfiaRlk5bG8s1fYXwJGRibWVayq60SgYl8nuOeXnSEic7m78ySc1LTznfg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000510" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/db4e0eea-7dcf-4341-9369-bd65f13d9109/640.png" alt="图片" data-before-load-time="1768896117223" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;Being-H0.5在不同构型本体上均进行了广泛验证实验&lt;/p&gt;&lt;p&gt;跨本体部署与基准测试：为验证 Being‑H0.5 的跨本体能力，研究团队在&amp;nbsp;PND、Unitree-G1、Franka 等不同构型的人形、机械臂本体上进行了大量真机实验。得益于海量多源数据的训练，该统一模型在复杂任务上展现出卓越的跨本体执行能力。在算法基准测试中，实现了 &amp;ldquo;一个Checkpoint，多本体运行&amp;rdquo; 的工程目标，并成功完成了如 &amp;ldquo;使用按压式喷壶浇花&amp;rdquo; 等对传统夹爪极具挑战性的精细操作。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEWy2Pe05QzW6M9cMU8B7T7ZdncMhv7IklvHHNGvtpZB9icCXgKuWkJzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000511" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d37aedcc-014a-4379-a26f-bb00f866bddd/640.png" alt="图片" data-before-load-time="1768896117256" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;跨本体真机任务&lt;/p&gt;&lt;p&gt;在四组任务上展开的定量评测实验中，Being-H0.5无论是generalist（多本体数据混合训练，难度更大）还是specialist（单一本体数据分开训练，较简单），性能表现都远优于仅能依托单一本体训练的 &amp;pi;-0.5模型。同时，Being-H0.5-generalist模型在平均性能表现上和specialist持平，展现出其跨本体维度上的强大泛化能力。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEzDXl36YU3IIZLTQ43o7jfHFKYOr71MQCrc51egUJJSXriateJOUQesg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.36944444444444446" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000512" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0e4b2871-d7d2-4c91-bf24-8b9a67bb3779/640.png" alt="图片" data-before-load-time="1768896117473" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;真机实验性能对比&lt;/p&gt;&lt;p&gt;仿真评测结果对比：&lt;/p&gt;&lt;p&gt;单纯依赖真机评测，难以广泛地和现有众多VLA模型进行更标准、公平的对比，为了提升模型性能的置信度，团队在两个最常见的仿真benchmark（LIBERO，RoboCasa）上进行评测，对比结果如下：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEUHXwkdJ5XkSPD9s7z4lGmJaKm9fWm2E2Cc8viaPeumibuVoLpxHiaBXNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.537962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000513" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/8a3440b1-8941-4b24-95fc-8583c7e3328f/640.png" alt="图片" data-before-load-time="1768896117489" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;Being-H0.5首次实现VLA基座模型98.9的平均成功率&lt;/p&gt;&lt;p&gt;在仅使用224x224像素图像（所有模型中分辨率最低），不使用任何辅助模态（比如3D）的情况下，Being-H0.5在 LIBERO和RoboCasa&amp;nbsp;上分别取得98.9% 与 54% 的成功率，不仅超越了 &amp;pi;‑0.5、GR00T 等所有已知 VLA 模型，甚至优于部分借助强化学习与 3D 模态的方案，展现出强大的SOTA性能和竞争力。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyE2Q60Ov58Qf0GQicKmwVfBicBY4Gxia2DmsASgz5vCQfObibXJ89jV2uHgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.33796296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000514" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5508a50b-e86c-4ea2-ad7c-095ce0ecb908/640.png" alt="图片" data-before-load-time="1768896117523" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;RoboCasa对比结果，Being-H显著超过pi0.5、GR00T等先进VLA&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;深度开源造福社区&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;当前VLA领域的开源实践多局限于发布预训练参数，而关键的预训练代码与部署方案往往缺失，这极大阻碍了社区的使用、复现与创新。为推动领域的开放发展与协作，团队决定进行完整开源：不仅公开预训练与后训练的全部模型参数，更将提供完整的训练与评估代码，以及一套可复现1000+ GPU小时训练的详细配方。未来，我们还将逐步开源真机部署代码与接口，诚邀社区同仁共同参与，构建更开放的具身智能生态。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;打破数据壁垒，开启跨本体泛化新时代&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;Being-H0.5 的发布，为全球具身智能领域带来了一个范式级的启发：高质量训练数据并非必须源于自建的高成本机器人集群。它巧妙地回应了&amp;ldquo;如何适配不同本体并获取优质数据&amp;rdquo;这一行业核心挑战&amp;mdash;&amp;mdash;将视角转向人类本身这一最丰富、最自然的数据源泉。这从根本上降低了行业门槛：公司无需投入上亿资金构建数据&amp;ldquo;护城河&amp;rdquo;，即可借助以人为中心的学习范式（human-centric learning），高效开发跨本体通用算法。这也是BeingBeyond团队一直以来坚持的核心技术路线，毕竟&amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;人类本身，才是这个世界最大、最自然的数据来源，这正是 human‑centric learning 最根本的魅力所在。&lt;/p&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>EmbodiChain开源，用100%生成式数据自动训练具身智能模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 15:27:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["list",{"type":"ul","style":"list-style-type: disc","class":"list-paddingleft-1","start":null},"listitem",{"style":"color:#7b0c00"},"para",{"tagName":"p","attributes":{"style":"text-align: left; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;论文地址:&amp;nbsp;&lt;/span&gt;https://www.techrxiv.org/doi/full/10.36227/techrxiv.176153394.41323502&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源主页:https://dexforce.com/embodichain/index.html#/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库: https://github.com/DexForce/EmbodiChain&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;技术文档: https://dexforce.github.io/EmbodiChain/introduction.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大语言模型的爆发，让大家见证了 Scaling Law 的威力：只要数据够多、算力够猛，智能似乎就会自动涌现。但在机器人领域，这个公式似乎失效了。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 LLM 时代，数据是「存量」，我们只需要负责「清洗」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在具身智能时代，数据必须是「增量」，我们必须具备「创造」数据的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不同于互联网上唾手可得的万亿级文本，机器人所需的、经过 3D 标定且符合物理规律的高质量交互数据，极度稀缺且昂贵。正因如此，数据采集范式成为了近年来行业研究的绝对焦点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可以看到，整个行业正在向着更低成本、更便捷的方向全速推进：&amp;nbsp;&lt;/strong&gt;从昂贵的遥操设备，到基于动捕手套的灵巧手捕捉和更加便携式的夹爪方案，再到如今甚至不再需要佩戴手套、仅凭双手演示即可采集数据的创新方案。&lt;strong&gt;这些轻量化的数采范式正在将人类的经验数字化，这一路径不仅充满价值，更值得持续深耕，它是连接人类技能与机器人动作的桥梁。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;整个行业在将具身智能推向大模型时代的这个目标上狂奔。&lt;/p&gt;&lt;p&gt;但是，即使是最极致的采集效率，客观上仍受限于物理时间的流逝和人力成本的边界。当下没有任何现有的物理采集范式，能匹配 LLM 训练所需的「互联网级」规模。这成为了具身智能迈向更高阶智能的最大桎梏。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率定律&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了突破这一天花板，需要引入一个新的视角。在传统的 Scaling Law 中，主要关注数据集、算力和参数量。但在具身智能中，有一个被忽视的隐形变量：&lt;strong&gt;数据生成的速率（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:34px;height:23px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ce295742-ac2d-4024-a857-0c2f6da74a5f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dii" style="width: 4.32%;"&gt;）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是&lt;strong&gt;跨维智能团队在论文《GS-World》中提出的核心洞察：智能的进化存在一个「逃逸速度」。&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;瓶颈期&lt;/strong&gt;：&amp;nbsp;当数据生成太慢（依赖人工采集或低速仿真），模型参数再大也无济于事，因为模型「吃不饱」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;爆发期&lt;/strong&gt;：&amp;nbsp;只有当&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:36px;height:24px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2f4ea652-7313-489e-96b8-1950b398f2f3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 4.2%;"&gt;超过临界值&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0TwiaiaZsSVyibmRPSELzibOwhibJzhB33JjX2L46Esibt6oassQsiaYjicFd6w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6216216216216216" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503529097" data-aistatus="1" data-original-style="width:45px;height:28px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/92e1d024-db2f-4dbe-8ac8-8bfebbd17a7e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 5.6%;"&gt;，数据不再是稀缺资源，而是像自来水一样源源不断时，模型性能才会随着参数量的增加而线性释放。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0dqnsfnUGYb2GCibhqYf5ZR85vPGnHZhUichVMvbKB31ibdicjfwJFGNOrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6376811594202898" data-s="300,640" data-type="png" data-w="828" type="block" data-imgfileid="503528999" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/dcf105fb-5df5-43d6-b393-633bba1c17b0/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 效率定律 (Efficiency Law) 下模型性能与数据生成速率的关系&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;要跨越这个鸿沟，除了物理采集的持续精进，另一种极具潜力的解决方式，就是&lt;strong&gt;构建一个能够超高速、自动化生成物理现实的数字世界&lt;/strong&gt;（跨维智能团队在《GS-World》中详述了这一路径）。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0c9DibAnhSlwxiavZtwwg5iczdngQJnppRcsx0KUn7OcGl4T9EpkopD5Gw/640?wx_fmt=jpeg#imgIndex=5" data-ratio="0.3925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0icQFeqRic5svorYD3gwqf7SGD3mQAQBRqEG3ibNtfvRROqKNURS22aDSA/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy1="26.903914590747327" data-cropy2="449.67971530249105" data-imgfileid="503529002" data-aistatus="1" data-original-style="width:562px;height:220px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3e2fc684-8258-467b-984c-8e75b7144d7b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在这个基于物理引擎的生成式世界中，数据的生成速率超越了时间的限制（Efficiency Law）；机器人可以在零成本的试错中习得对物理因果的深刻理解；所有的边缘情况（Corner Cases）都可以在这里被模拟、被攻克。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GS-World 与 EmbodiChain&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，跨维智能正式开源 EmbodiChain。作为通往&lt;strong&gt;&amp;nbsp;GS-World（基于生成式仿真的世界模型）&amp;nbsp;&lt;/strong&gt;的基石，EmbodiChain 不仅仅是一个数据和模型平台，更是一次对具身智能学习范式的重构。&lt;/p&gt;&lt;p&gt;跨维团队提出并验证一个大胆的假设：&lt;strong&gt;仅凭 100% 的生成式仿真数据，只要生成速率（Rate of Generation）突破临界点，机器人就能在真实世界中涌现出超越 SOTA 的泛化能力。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这不是科幻，这就是跨维正在验证的&lt;strong&gt;效率定律（Efficiency Law）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;EmbodiChain 的本质，就是一台&lt;strong&gt;将&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:34px;height:23px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1850e3b5-3909-44ed-b0c1-8d67429646bc/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 4.11%;"&gt;拉满的数据和模型制造引擎&lt;/strong&gt;。它不再依赖对真实世界的有限采样，而是开启了具有物理真实性的数据的批量制造。&lt;/p&gt;&lt;p&gt;然而，要将 GS-World 从蓝图变为现实，绝非易事。跨维研究团队必须面对并攻克&lt;strong&gt;三个核心科学难题&lt;/strong&gt;，这也是 EmbodiChain 致力于解决的关键：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何实现数据生产自动化？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实世界极其复杂，如何仅凭少量先验（如一段视频、一句描述），就在数字世界中自动重建、生成海量且物理一致的场景与任务，而无需人工手动搭建？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何打破「虚实鸿沟」（Sim2Real Gap）？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;仿真数据再多，如果不能迁移到真机也是徒劳。如何在不依赖或尽量少依赖真实数据微调的情况下，让模型习得适应真实世界噪声与动态变化的鲁棒策略？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何突破数据生成的「IO 墙」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Scaling 需要亿级甚至十亿级的交互步数。传统的「生成 - 存储 - 读取 - 训练」模式效率极低。如何构建极致高效的数据流转机制，实现「在线数据流」？&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;EmbodiChain：一条永不停歇的「在线数据流和模型生产线」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了实现这一愿景，跨维智能构建了&lt;strong&gt;&amp;nbsp;GS-World（Generative Simulation World Model，生成式仿真世界模型）&lt;/strong&gt; 的核心基石 &amp;mdash;&amp;mdash;EmbodiChain。&lt;/p&gt;&lt;p&gt;EmbodiChain 作为一个底层的基建技术，可以把它看作&lt;strong&gt;去存储化的数字化流水线&lt;/strong&gt;。Scaling 需要亿级甚至十亿级的交互步数，传统的「生成 - 存储 - 读取 - 训练」模式在面对海量 3D 数据时，存储与传输将成为不可承受之重。&lt;/p&gt;&lt;p&gt;在 EmbodiChain 的架构中，可以彻底抛弃「先存硬盘、再读硬盘」的陈旧范式，取而代之的是在线数据流（Online Data Streaming）和模型自动生产线。&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/105066a2-86d0-4c78-bebe-8903fa14489a/1768893817074.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;EmbodiChain 的核心工作流。数据在生成的同时即被消费，橘色的数据流贯穿全场，无需落地存储。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这条流水线是如何工作的？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;世界生成（Generative Simulation）&lt;/strong&gt;：&amp;nbsp;引擎不仅是环境，更是造物主。Real2Sim 模块从极少的真实样本中提取物理先验，Gen2Sim 模块则响应语言指令，自动构建出符合牛顿力学等物理规律的 3D 场景与资产。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据扩增（Data Scaling）&lt;/strong&gt;：&amp;nbsp;数据不仅要多，还要「难」。系统自动进行视觉增强、物理参数随机化，并剔除那些机器人「够不着」的无效采样。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自我修复（Closed-loop Recovery）&lt;/strong&gt;： 真正的智能来自于从错误中学习。当仿真中的机器人抓取失败，系统会自动生成修正轨迹。这种「失败 - 修正」的闭环，比单纯的成功演示更有价值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一切都在 GPU 内部并行高速运转，数据如洪流般产生，训练完即销毁，不留下一丝冗余，只留下模型能力的增长。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;路线之争：机器人需要的是物理精确的生成式模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在通往具身智能世界模型的路上，目前存在两条截然不同的路线。&lt;/p&gt;&lt;p&gt;一条是近期火热的&lt;strong&gt;视频生成路线（Video World Model）&lt;/strong&gt;，如 Sora 或 LTX-Video，它们试图通过「画出」下一帧来模拟世界。虽然视觉效果惊艳，但一些对比实验揭示了其致命弱点：&lt;strong&gt;幻觉&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;视频模型生成的画面往往缺乏长程的时空一致性，且很难精确遵循动力学方程。用这种「做梦」产生的数据训练机器人，就像让一个飞行员在爱丽丝的仙境中学习开飞机 &amp;mdash;&amp;mdash; 看着很美，一上真机就坠毁。&lt;/p&gt;&lt;p&gt;相反，EmbodiChain 选择的是 &lt;strong&gt;GS-World 路线（基于生成式仿真的世界模型）&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物理先验（Physical Priors）：&lt;/strong&gt; 跨维智能坚持世界模型必须是 3D 的、交互式的、物理严谨的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特权信息（Privileged Information）：&lt;/strong&gt; 在 EmbodiChain 中，使用者拥有上帝视角。比如使用者能够获取物体的精确掩码、空间关系和可供性（Affordance）。通过训练模型预测这些真实世界中不可见的「特权信息」，迫使模型理解了场景背后的&lt;strong&gt;几何本质&lt;/strong&gt;，而不仅仅是表面的像素。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这正是 Yann LeCun 所倡导的理念：&lt;strong&gt;世界模型应该是对世界状态的预测与规划&lt;/strong&gt;。&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dd396cbb-f4b4-48f4-8828-758f30f822ca/1768893887934.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; EmbodiChain中可以获取的特权信息示例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;零真实数据，VLA 真的可行吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证这套「效率定律」，跨维智能做了一件极端的测试：&lt;strong&gt;不使用任何真实数据训练模型。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;跨维智能训练出的 Sim2Real-VLA 模型，在真实世界中执行任务。结果令人惊讶：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;远超基线&lt;/strong&gt;：&amp;nbsp;在没有任何真实数据微调的情况下，它在操作成功率上大幅领先 ACT、Diffusion Policy 等主流方法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无惧干扰&lt;/strong&gt;： 即使跨维智能像「捣乱者」一样更换桌布、移动物体、改变光照，模型依然稳如泰山。甚至在某些任务中，由于去除了真实数据中容易过拟合的背景噪声，模型的表现反而比用真实数据训练还要好。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b68ec599-9159-4c23-bad5-e4d31f5949b0/1768893920724.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c77d8ed0-5332-42f9-a212-65d5192f37e6/1768893933659.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0d8E8iamrJjup4bGsiaYKEj9bln7RDgf6pqtyYOlDso3Wmh6MbsiaALtKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5652173913043478" data-s="300,640" data-type="png" data-w="828" type="block" data-imgfileid="503529026" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3a27c0cd-e3dd-46f2-8832-0755bc459581/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;Sim2Real-VLA 在全生成数据训练下，不仅击败了 SOTA，更展现了惊人的鲁棒性。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;愿景：通往 GS-World 的「效率奇点」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;EmbodiChain 的开源，只是一个开始。&lt;/p&gt;&lt;p&gt;GS-World 蓝图远不止于此。在跨维智能的规划中，&lt;strong&gt;这是一个引擎驱动的闭环路径（Engine-driven Loop）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不仅环境是生成的，任务也是生成的；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不仅策略是进化的，机器人的身体结构（Morphology）也会随着任务需求协同进化。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;跨维智能希望 EmbodiChain 能成为每一位具身智能研究者的基础设施。不需要再为了几千条数据而在实验室里没日没夜地遥操作，不需要再为几十 TB 的硬盘存储发愁。&lt;/p&gt;&lt;p&gt;因为智能的未来，不应该被困在数据的匮乏中。&lt;/p&gt;&lt;p&gt;EmbodiChain 现已开源，邀请你一起见证具身智能的「效率奇点」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
