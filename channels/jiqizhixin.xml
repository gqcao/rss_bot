<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>ControlNet作者张吕敏最新论文：长视频也能实现超短上下文</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:39:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3a90df6c-40f3-401f-a574-a08345c9959e/1767461789356.png" style="width: 700%;" class="fr-fic fr-dib"&gt;大部分的高质量视频生成模型，都只能生成上限约15秒的视频。清晰度提高之后，生成的视频时长还会再一次缩短。&lt;/p&gt;&lt;p&gt;这就让尝试AI视频创意的创作者们非常苦恼了。要想实现创意，必须使用分段生成，结合首尾帧，不仅操作起来很麻烦，而且需要来回抽卡来保证画面的一致性。&lt;/p&gt;&lt;p&gt;那么，限制视频生成时长的瓶颈在哪里？&lt;/p&gt;&lt;p&gt;大家可能不知道的是，一段 60 秒、480p、24 帧/秒的视频，在模型内部会被拆解成 &lt;strong&gt;超过 50 万个「潜在 token」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这些 token 就像一条极长的记忆胶带，模型想要保持剧情连贯、画面一致，就必须从头到尾保存上下文记忆。但代价是：算力直接爆炸，普通显卡根本扛不住。&lt;/p&gt;&lt;p&gt;这正是当前自回归视频生成模型的核心矛盾。一边是越长的上下文，画面越连贯；另一边是越长的上下文，计算成本越高。&lt;/p&gt;&lt;p&gt;于是，研究者们不得不做出妥协：要么用滑动窗口切掉大部分历史，换取可运行的算力；要么对视频进行激进压缩，牺牲清晰度和细节。&lt;/p&gt;&lt;p&gt;问题在于，这些压缩方法往往最先丢掉的，正是决定画面真实感与一致性的高频细节。&lt;/p&gt;&lt;p&gt;也正是在这一困境下，&lt;strong&gt;苏州大学校友，斯坦福大学博士，ControlNet 创作者张吕敏团队&lt;/strong&gt;为此投入了研究&lt;strong&gt;，&lt;/strong&gt;提出了一种新的解决思路，给出了&lt;strong&gt;专为长视频设计的记忆压缩系统，在压缩的同时尽可能保留精细视觉信息。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6ntzwTaPZrJSGJWibn6Sh0xFuawwkzzOvn1B0pVevz8OSrHLPPIMKbmQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.21296296296296297" data-type="png" data-w="1080" data-width="1694" data-height="360" data-imgfileid="503526567" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/de2b4df6-f147-4d93-8755-19dd14bdb9eb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Pretraining Frame Preservation in Autoregressive Video Memory Compression&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2512.23851v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队提出了一种神经网络结构，用于将长视频压缩为短上下文，并设计了一种显式的预训练目标，使模型能够在任意时间位置保留单帧中的高频细节信息。&lt;/p&gt;&lt;p&gt;基线模型可以将一段&lt;strong&gt;&amp;nbsp;20 秒的视频压缩为约 5k 长度的上下文表示&lt;/strong&gt;，同时支持从中随机检索单帧，并在&lt;strong&gt;感知质量上保持良好的外观保真度&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种预训练模型可以直接微调为自回归视频模型的记忆编码器（memory encoder），从而以较低的上下文成本实现长历史记忆建模，并且仅带来相对较小的保真度损失。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6nEyUzOSCvIiaIiaXO1A1wuch9icnJt4CXNj3oA0KJeiclIdDoibQb5q764Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.49166666666666664" data-type="png" data-w="1080" data-width="1142" data-height="562" data-imgfileid="503526570" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/617126f8-783a-41c4-8658-37a0a5138fd1/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;该视频是使用完整历史上下文（不切割任何历史帧）逐秒自回归生成的。20 多秒的历史被压缩为 &amp;sim; 5k 上下文长度，并由 RTX 4070 12GB 处理。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全新的记忆压缩架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体而言，研究团队采用&lt;strong&gt;两阶段策略&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;首先，预训练一个&lt;strong&gt;专用的记忆压缩模型&lt;/strong&gt;，其目标是在任意时间位置上尽可能保留高保真帧级细节信息。&lt;/p&gt;&lt;p&gt;该预训练目标通过对从压缩历史中随机采样的帧最小化其特征距离来实现，从而确保模型在整个序列范围内都能稳健地编码细节信息。&lt;/p&gt;&lt;p&gt;在网络结构设计上，提出了一种&lt;strong&gt;轻量级双路径架构&lt;/strong&gt;：模型同时处理低分辨率视频流和高分辨率残差信息流，并通过将高分辨率特征直接注入 Diffusion Transformer 的内部通道，绕过传统 VAE 所带来的信息瓶颈，从而进一步提升细节保真度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;预训练记忆压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6VYclIm3XC3ojia6Y7ohfHTfRzmffPiaom5XDGoNqVicbCZXOpvOtsqcUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9779116465863453" data-type="png" data-w="996" data-width="996" data-height="974" data-imgfileid="503526569" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/55a28b11-a6bf-41e6-852e-e62f2369ca20/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;记忆压缩模型的预训练。记忆压缩模型需要将长视频（例如 20 秒）压缩成短上下文（例如长度为 5k）。预训练的目标是在任意历史时间位置检索具有高频细节的帧。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;该方法的&lt;strong&gt;核心创新在于其预训练目标设计&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;研究团队观察到，衡量视频压缩机制保留上下文细节能力的一个合适的指标是其任意时间位置高质量帧检索的能力。对于高压缩率，完美检索变得不切实际，因此目标变为最大化任意帧的检索质量。&lt;/p&gt;&lt;p&gt;给定一段长视频历史 H，记忆压缩模型 &lt;span data-meta-block-props='{"blockId":"973803be-232b-42a2-92a2-2756fcc10998","blockType":"EQUATION_BLOCK","initData":{},"props":{"data":{"equation":" \\phi(\\cdot)\n"},"displayMode":"inline","viewType":"inline"}}'&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6qEr9AMGBrcRsPehaEvu0E6KQlSpPn1HicTMgSiabGmMxatg9NK6ibHiaOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9444444444444444" data-s="300,640" data-type="png" data-w="108" type="block" data-imgfileid="503526582" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f00003e1-8c99-4012-8698-552ed010ab03/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;&lt;/span&gt;学习将其压缩为一个紧凑的上下文表示 &lt;span data-meta-block-props='{"blockId":"172ef25e-499d-4cbe-b735-6f3987ebd742","blockType":"EQUATION_BLOCK","initData":{},"props":{"data":{"equation":" \\phi(H)\n"},"displayMode":"inline","viewType":"inline"}}'&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX60y81u8hqicy3e5QHpAzUMyzrs6JG0vkIVia09OzXvsKUpkibicf2qMrL4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7692307692307693" data-s="300,640" data-type="png" data-w="156" type="block" data-imgfileid="503526583" data-aistatus="1" data-original-style="width:38px;height:29px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d25f0cba-e318-4cee-8651-794a54f60db6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 4.95%;"&gt;&lt;/span&gt;，同时仍然保持对&lt;strong&gt;任意时间位置帧&lt;/strong&gt;进行重建的能力。&lt;/p&gt;&lt;p&gt;在训练过程中，模型从历史序列中随机选择一组帧索引 &amp;Omega;，并对其余所有帧进行噪声掩蔽处理；模型必须仅依赖压缩后的表示来重建这些被选中的帧。&lt;/p&gt;&lt;p&gt;如上图所示，帧选择 &amp;Omega; &lt;span data-meta-block-props='{"blockId":"ef138d7a-f199-4790-8aa4-a155e3c33c09","blockType":"EQUATION_BLOCK","initData":{},"props":{"data":{"equation":"\\Omega\n\n"},"displayMode":"inline","viewType":"inline"}}'&gt;与检索过程 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX63Td8IxhnG3eibQNMOqH4KuZHYR9f3X7tehZT7qZ7wicHeL8WFm3081HQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4152542372881356" data-s="300,640" data-type="png" data-w="236" type="block" data-imgfileid="503526584" data-aistatus="1" data-original-style="width:64px;height:27px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e9124a17-0edd-4689-a739-31f69946103f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 7.7%;"&gt;&lt;/span&gt; 可以被构建为一个&lt;strong&gt;自回归视频扩散框架&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;本文采用以噪声作为掩蔽的方法：为被掩蔽帧加入服从&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6jengnEYaUyPacWRm8EPP4s8EDRAGAPztexgw99icfdvmNeheCqffvkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.43902439024390244" data-s="300,640" data-type="png" data-w="246" type="block" data-imgfileid="503526585" data-aistatus="1" data-original-style="width:65px;height:29px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/74cd78bf-119a-4e09-a27e-f0f10fe536e1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 7.06%;"&gt;的潜在噪声水平。&lt;/p&gt;&lt;p&gt;随后，研究团队将所选的干净帧复制作为扩散模型的目标，使扩散系统能够在任意时间位置重建目标帧。该过程可表示为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX69NAwLh9R5DuVcF2DdvNxwqwDsE9V8TosxJbOCGl8DZufesWQYACibeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.15399239543726237" data-type="png" data-w="1052" data-width="1052" data-height="162" data-imgfileid="503526566" data-aistatus="1" data-original-style="width: 397px;height: 61px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3647232f-0613-4358-bdb4-32bb3993bd38/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这种随机化选择机制有效防止模型通过仅编码易于访问的帧（例如首帧或末帧）来「投机取巧」，从而迫使模型学习一种能够在整个时间序列范围内持续保留细节信息的表示方式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6mBSA9c9Lz9EZjbtXGhicx4ick1miccIfoMMIyKxA7mozlvmnJpDNoqXWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.4718875502008032" data-type="png" data-w="996" data-width="996" data-height="470" data-imgfileid="503526568" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/acd7f2ec-afc7-4244-8735-a5349aab1f63/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;内存压缩模型的架构。使用 3D 卷积、SiLU 和注意力机制来构建一个轻量级的神经网络结构，作为基准压缩模型。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;视频扩散模型的微调&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6owEAkic3p28rgL6ZicKpgKunRXKF14yrnbbKdaicBYXGDDiarjJY2Fibiauw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3965863453815261" data-type="png" data-w="996" data-width="996" data-height="395" data-imgfileid="503526572" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/714d42ff-c701-4d71-ab06-55af827343b5/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;微调自回归视频模型。展示了最终自回归视频模型的微调和推理过程。记忆压缩模型的预训练在微调之前完成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;借助预训练完成的记忆压缩模型&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6qEr9AMGBrcRsPehaEvu0E6KQlSpPn1HicTMgSiabGmMxatg9NK6ibHiaOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.9444444444444444" data-s="300,640" data-type="png" data-w="108" type="block" data-imgfileid="503526582" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/cf660150-e057-4dcb-82dc-0ebb3bd2933e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.85%;"&gt;&amp;nbsp;，可以通过对视频扩散模型（例如 WAN，并结合 LoRA 微调）以及该压缩模型作为历史记忆编码器进行联合微调，从而构建一个自回归视频生成系统。&lt;/p&gt;&lt;p&gt;由此得到的视频生成模型具备超长历史窗口（例如超过 20 秒）、极短的历史上下文长度（例如约 5k），并且对帧检索质量进行了显式优化。&lt;/p&gt;&lt;p&gt;该扩散过程亦可按照公式表示为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6tATcP3WDMxpibVjOZzszibWpCf17SAE1xZP3Tm606OeDUSpVNnpqYrMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.1364522417153996" data-type="png" data-w="1026" data-width="1026" data-height="140" data-imgfileid="503526571" data-aistatus="1" data-original-style="width:393px;height:54px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/60846920-f904-47e0-b40c-e001106fcf54/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验中，研究团队使用 8 &amp;times; H100 GPU 集群进行预训练，并使用 1 &amp;times; H100s 或 A100s 进行 LoRAs 微调。所有实验均在 HunyuanVideo和 Wan 系列的基础模型上进行。&lt;/p&gt;&lt;p&gt;数据集由来自多个网站的约 500 万互联网视频组成。其中约一半是竖屏短视频，其余为普通横屏视频。数据经过质量清洗，然后使用 Gemini-2.5-flash VLM 对高质量部分进行字幕标注，剩余部分使用本地 VLM（如 QwenVL）进行处理。测试集包括由 Gemini-2.5-pro 编写的 1000 个故事板提示和 4096 个未在训练数据集中出现过的视频。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定性与定量评估&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6lX4ug0torwlpIJR98PiaWNSG2PDnJAWhB7uIg8oMrfBYRmPLvEJlvvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.42592592592592593" data-type="png" data-w="1080" data-width="1142" data-height="486" data-imgfileid="503526575" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/09264eff-cf7e-43ad-8ba7-7aa032b6f1d2/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;故事板上的定性结果。通过从故事板中流式传输提示来展示结果。故事板是一组提示，其中每个提示涵盖一定数量的帧。故事板可以由外部语言模型编写。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在定性评估方面，如图所示，研究者证明了模型能够处理多种多样的提示和故事板，同时在角色、场景、物体和情节线方面保持一致性。&lt;/p&gt;&lt;p&gt;在定量评估方面，研究者们从 VBench、VBench2等平台引入了多个视频评估指标，并进行了一些修改。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6DgLECiaGe7sl6qJDW6GNaaaToHm73ibeAr9Na8s6Bs16CqLcFviaAl2Dw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.4351851851851852" data-type="png" data-w="1080" data-width="1506" data-height="656" data-imgfileid="503526574" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/db1ef678-34e7-4e7a-b3d1-c3689e1f3767/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;视频内容一致性的定量评测结果。其中，Qwen 中的 「1p」 表示仅使用 1 张图像 作为图像模型输入。由于部分方法存在严重伪影，因此未将其纳入人工 ELO 评分统计。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如表所示，本文提出的方法在多个一致性指标上表现出合理的分数。Wan+Qwen 组合在实例分数上似乎具有领先分数，这可能是由于图像模型不会显著改变或移动对象，从而避免了 VLM 问答检测到的伪影。本文的方法在对象一致性方面表现出有竞争力的分数。此外，用户研究和 ELO 分数验证了本文提出的架构，证实它在压缩和质量之间实现了有效的权衡。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;消融实验&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6MleyBBiajl9POicKZD2k8Lsb9ySJFKjTOeGNXl5tqvkesvBTsOHXrvQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.4824074074074074" data-type="png" data-w="1080" data-width="1232" data-height="594" data-imgfileid="503526573" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/63980fb6-5535-484a-867a-1c1f3682cbaa/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 压缩结构的定量结果。展示了使用不同消融压缩架构的数值测试。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;评测结果如表所示。结果表明，本文方法在 PSNR、SSIM 等指标上取得了相对更优的性能。此外，即便在 4&amp;times;4&amp;times;2 的较高压缩率条件下，该方法仍然能够有效保持原始图像结构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6mnbEia2xBbwLjA8Gd3qrnJEgdRkD1dSZiaOia1Fv8YfqC7lofODFu2VWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.5046296296296297" data-type="png" data-w="1080" data-width="1142" data-height="576" data-imgfileid="503526578" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/6612af3d-77e7-4185-9224-739802d64b5b/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;压缩重建的视觉比较。展示了使用不同可能的神经网络结构和各种压缩设置进行预训练后的重建结果。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6Jb4ocwSOpPOE0abwBuYw2f9JseuBu78WxhJz3b5TpteibHXegoD7uRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.3787037037037037" data-type="png" data-w="1080" data-width="1142" data-height="433" data-imgfileid="503526577" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/7e02e277-3ecb-4536-9eca-a8b612251f23/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;记忆压缩模型预训练的影响。展示了使用或未使用记忆压缩模型预训练的结果。输入是相同的 20 秒历史视频，在输出帧中可视化中间帧。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;除此以外，研究团队还在论文中讨论了不同神经网络架构设计之间的权衡取舍。&lt;/p&gt;&lt;p&gt;更多信息，请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>4个月烧掉30亿Token，这位「菜鸟」程序员做出50多个产品，360万人围观</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:33:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e6620652-ba3e-4b71-842d-7b7d65629045/1767461471804.png" style="width: 700%;" class="fr-fic fr-dib"&gt;长久以来，代码世界的大门似乎只对少数掌握秘术的人敞开。我们被告知：你必须先理解内存、掌握语法、忍受枯燥的文档，才配谈论创造。&lt;/p&gt;&lt;p&gt;现在，随着大模型的发展，编程不再是一场苦修，而是一场大型即时策略游戏。在这个游戏里，很多人学会了与 AI 并肩作战，学会了用一种更纯粹、更直抵本质的方式去构建自己想要的世界。&lt;/p&gt;&lt;p&gt;Ben Tossell（Factory 开发者关系主管）就是其中一员。他是一位不怎么会写代码的人，在过去四个月里，却消耗了 30 亿个 Token。&lt;/p&gt;&lt;p&gt;这意味着每一分、每一秒，他都在通过终端窗口，观察 AI Agent 写下那些他凭一己之力永远无法写出的复杂代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="765" data-imgfileid="503526606" data-ratio="0.770392749244713" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6cCmAhoj1l7IB4QYrY5AJ8hCWSHoJY0R3Z2TSa6pZeRFn4iamUQkgQ5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="993" data-width="993" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6a89c0f5-f5a9-43dc-bd1c-4f74601d3093/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;或许有人会将这种方式贬低为所谓的氛围编程（Vibe-coding），但在 Tossell 看来，这个词带有某种傲慢的偏见。它像极了 2019 年人们对无代码（No-code）的刻板印象 &amp;mdash;&amp;mdash; 而正是那一年，他创办了自己的无代码教育公司并最终被 Zapier 收购。这种偏见选择性地忽视了隐藏在交互与调度背后的核心技能。&lt;/p&gt;&lt;p&gt;在 Tossell 看来，编程新范式下，衡量一个人的技术能力不再是看他能否默写语法，而是看他能否驾驭系统。&lt;/p&gt;&lt;p&gt;从无代码时代的先行者，到如今 30 亿 Token 的调度者，Ben Tossell 证明了一件事：在 AI 时代，通向代码世界的最高通行证不是专业背景，而是那种为了探索而探索的欲望。&lt;/p&gt;&lt;p&gt;为了记录这些体验，Tossell 还专门写了一篇文章，其在 X 上的浏览量已经超过了 360 万。接下来我们看看文章内容。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实际交付的产品&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然烧掉了 30 亿 Token，但 Tossell 表示自己也是收获满满，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;个人网站：Tossell 重新设计了个人网站，使其看起来像一个终端 CLI 工具。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Feed：Tossell 构建了一个简单的社交媒体追踪器，跟踪 subreddit 帖子和 GitHub 问题。它是开源的，得到了 100 多个 stars，很多人也克隆了这个项目。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Factory Wrapped：Tossell 构建了 Factory 产品的第一个版本，展示给团队后他们非常喜欢，并决定将其融入到实际产品中，现在已经上线。Tossell 还添加了新的指南，重新整理了一些内容。虽然这看起来不像传统的编码，但对 Tossell 来说，它依旧是编码，整个过程没有变。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;定制 CLI 工具：创建了一些 CLI 工具，例如 Pylon CLI，团队用它来帮助处理客户支持请求。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;加密追踪器：Tossell 投资了一家能够准确预测金融、天气、健身和蛋白质折叠等动态数据中正面、负面或中性信号的公司。Tossell 基于这些预测构建了一个加密追踪器，能够自动根据预测开设和关闭多空仓位，类似一个迷你对冲基金。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Droidmas：这是一个 12 天的实验或游戏，围绕 X 上人们讨论的不同主题展开，记忆、上下文管理、vibe coding 等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 指导的视频演示系统：简单来说，给它一个提示，它会创建一个视频。该系统作为自己的导演、制片人和编辑，能实时观看录制过程，并根据情况做出反应。如果遇到问题、bug，或者需要等待响应，它会处理。Tossell 用这个系统制作了一段视频，并由 OpenAI 发布。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，Tossell 还做了大约 50 个其他项目，其中有些已经被遗弃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;完全使用 CLI 来工作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tossell 的战场不在花哨的网页界面，而是在纯粹的 CLI（命令行界面）。他认为终端胜过网页界面，并且还能看到它的工作过程。&lt;/p&gt;&lt;p&gt;每当 Tossell 有一个新的想法，或者遇到一个问题，Tossell 就会在 Droid（Factory 的 CLI）中启动一个新项目。他会与模型交流几次，提供上下文，然后切换到规范（spec）模式，制定构建计划。&lt;/p&gt;&lt;p&gt;在规范模式下，Tossell 会提出很多问题，比如他不理解这个是什么，为什么需要这个而不是那个，难道不能这样做吗？等等。&lt;/p&gt;&lt;p&gt;接着，在运行时，Tossell 让 Opus 4.5 在高自主性模式下运行，查看发生了什么，并在遇到错误时介入，最后进行测试，提供反馈并迭代。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;agents.md 设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tossell 花了很多时间来思考如何设置最佳的 agents.md，因为这基本上就是操作手册。&lt;/p&gt;&lt;p&gt;Tossell 本地有一个 repos 文件夹，所有的编码项目都放在那里。在这个文件夹中，有一个 agents.md 文件，里面明确规定了每个新仓库的设置流程，做什么、不做什么，如何使用 GitHub、如何提交代码之类的内容，还会标明是否使用工作 GitHub 账户或个人 GitHub 账户。&lt;/p&gt;&lt;p&gt;端到端测试是 Tossell 以前没有特别关注的事情，但现在他非常希望在每个项目中都进行端到端测试。&lt;/p&gt;&lt;p&gt;基于他目前的知识和能力，很多时候在构建和测试过程中，总会有一些本应该早早发现的低级 bug，如果一开始就做了测试，可能就能避免这些问题。&lt;/p&gt;&lt;p&gt;Tossell 表示，他也经常查看他人的 agents.md 文件，看看有哪些可以借鉴的地方。Tossell 一直在努力改进自己的文档，从而让每次新的工作会话更加顺畅。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Tossell 学到了什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tossell 主要通过 CLI 而非 MCP 进行工作，不过他曾经使用过 MCP，但现在更倾向于使用 CLI 版本，因为它简单且更高效。比如在 Supabase、Vercel 和 GitHub 上，Tossell 总是使用 CLI 而非 MCP。&lt;/p&gt;&lt;p&gt;他还经常为自己的需求创建 CLI 工具。比如，他构建了自己的 Linear CLI，这样就能通过终端查询问题并执行任务，而不需要进入桌面或网页界面。&lt;/p&gt;&lt;p&gt;Bash 命令：Tossell 在处理变更日志的过程中真正理解了 Bash 命令的工作原理。这是一个重复的过程，最终理解了工作流程。Tossell 让 Droid 创建了一个斜杠命令流程，这是 Tossell 第一次正确使用的命令，它运行多个 Bash 命令，并提示模型做一些特定的任务，比如查看 GitHub 差异、检查功能标志的状态，或者将新功能和 bug 修复放到正确的部分。&lt;/p&gt;&lt;p&gt;VPS：Tossell 之前对 VPS 有一个抽象的理解，知道它是一个 24 小时运行的远程计算机。直到 Tossell 真正需要使用 VPS 时，Tossell 才深入了解它的用途。现在，Tossell 使用 VPS 来运行加密追踪器，获取每分钟的数据，同时保持它始终在线。使用 Droid Telegram 机器人时，Tossell 也依赖 VPS，通过 SyncThing 同步本地的仓库到 VPS，这样 Tossell 的仓库总是保持最新状态，能够随时接着上次的状态继续工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新的可编程抽象层&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在看到 Andrej Karpathy 的推文时，Tossell 深有感触 &amp;mdash;&amp;mdash; 现在有了一个新的可编程抽象层需要掌握。&lt;/p&gt;&lt;p&gt;在无代码时代，抽象层是像 Webflow、Zapier 和 Airtable 这样的拖拽工具，将它们拼接在一起，让它看起来像真实的软件（直到你遇到限制）。&lt;/p&gt;&lt;p&gt;但现在，我们不再认为自己必须从零开始学习编写代码才能做这些事情，实际上，需要学习的是如何与 AI 合作。如何给它提供合适的提示？如何确保它拥有正确的上下文？如何把各个部分结合起来以及如何随着时间推移不断优化系统等等。&lt;/p&gt;&lt;p&gt;为了更好的掌握 AI 编程技能，Tossell 还会阅读像 Peter Steinberger 这样的程序员的帖子。从他的帖子中，Tossell 看到了他系统的简洁性：他只是和模型互动，让模型做事。这一发现让 Tossell 感到非常有信心，也让 Tossell 明白自己不需要一个复杂的系统。&lt;/p&gt;&lt;p&gt;Tossell 表示，在 X 上，你会看到很多人不断优化，甚至可能是过度优化自己的系统。对于像 Tossell 这样的人来说，这有时会感到很有压力，但他也认为这正是这个系统的魅力所在：它是一个完全可定制的系统，你可以根据自己的需要，让它按照你希望的方式工作。你可以像 Kieran 一样创建一个计划模式，或者像 Peter 一样直接与模型对话。&lt;/p&gt;&lt;p&gt;不过，他有时也会遇到 bug 和问题，但他明白这些问题其实是用户知识的空白，而不是自己当前能力的局限。&lt;/p&gt;&lt;p&gt;Tossell 的任务是识别这些空白，找到它们，并思考：如何确保这种问题永远不会再发生？或者如何确保自己足够理解这部分系统，以便下次发生时能及时发现。&lt;/p&gt;&lt;p&gt;所以，我们需要做什么呢？其实你只需要问模型。模型知道你不知道的所有东西。你可以不断向它提问。它是你永远耐心的、在你肩膀上的专家程序员。 你可以在 agents.md 中写道：Tossell 不是程序员，你需要非常简单地解释给 Tossell 听。你可以根据自己的需求完全定制它&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们学习的方式改变了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;以往，Tossell 尝试过很多次学习编程，每次都是输入这些字符，按下回车，看看是不是显示 hello world。但 Tossell 觉得这和今天的学习方式差别很大。&lt;/p&gt;&lt;p&gt;如果按照传统的方式来学习编程，想要达到现在能构建的程度，可能需要花费数月甚至数年的时间才能有信心自己写代码。&lt;/p&gt;&lt;p&gt;而现在，Tossell 是从理解代码构建项目的系统思维角度来学习的。Tossell 在经营无代码教育公司时，无意中学到了这一点。你依然要理解：Webflow 是前端，Zapier 是 API 路由和连接层，数据流动，而 Airtable 是数据库。所以 Tossell 之前学会了这些系统化的思维，今天可以帮助他理解这些组件。&lt;/p&gt;&lt;p&gt;有太多东西可以学习了，但也是没有任何软件是不可达成的。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;学会提出那些「愚蠢」的问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人们常会冒出一些看似笨拙的问题，那些资深程序员或许早已习以为常，不再追问。&lt;/p&gt;&lt;p&gt;比如：既然框架是为了简化人类的工作，而现在的 LLM 已经如此强大且智能，为什么我们不干脆抛弃沉重的框架，让它直接写出最纯粹、零依赖的代码？这样不是能大大减少 Bug 和维护成本吗？&lt;/p&gt;&lt;p&gt;后来 Tossell 逐渐意识到，这并非一个傻问题。框架的存在，不仅是工具，更是共识与生态。LLM 的智慧源于海量的训练数据，而这些数据大多根植于现有的成熟框架之中。&lt;/p&gt;&lt;p&gt;这就是 Tossell 构建认知的过程。以前，Tossell 总觉得自己是代码世界的门外汉，甚至觉得这个领域高不可攀；而现在，通过这些直抵本质的提问，Tossell 正一步步拆掉思维的围墙。他不再只是一个使用者，而是正真实地成为这个工程世界的一部分。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于氛围编程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然现在氛围编程这个词很火，但 Tossell 总觉得它没能触及灵魂。我们所做的，远不止于凭感觉，而是在深度理解系统 &amp;mdash;&amp;mdash; 去拆解它的逻辑，去改进它的构造。作为新时代的技术阶层，我们究竟该如何定义自己？&lt;/p&gt;&lt;p&gt;Tossell 不想称自己为非技术人员，但 Tossell 也不想被框在程序员这个传统标签里。他更像是一个处在某种无名阶层中的探索者。如果说无代码曾是一种误读，那么 Vibe Coding 现在也正带着某种傲慢的偏见。&lt;/p&gt;&lt;p&gt;对 Tossell 来说，编程更像是一场真实存在的宏大游戏。&lt;/p&gt;&lt;p&gt;这种新范式迷人之处在于：每一个创意都能被即刻实践，每一个念头都能深入探索。它不需要从一开始就追求完美，因为在这个过程中，掌握系统真谛才是重要的。就像代码未必都要上传 GitHub，有时候，它们只是通往某个系统深处的路标。&lt;/p&gt;&lt;p&gt;我们不要再为了工具而去生产工具。就像看到别人的 React 抓取工具，Tossell 不再只是感叹，而是会问自己： 我能做一个属于自己的吗？它的原理是什么？这种为了探索而探索的自由，正是新技术赋予我们的最高权限。&lt;/p&gt;&lt;p&gt;以前，学会编程更像是一种重资产投入。Tossell 曾以为，如果我们费尽心力做出了一个想法的简陋原型，结果却无人问津，那我们一定会因为投入了太多情感和成本而无法放手。&lt;/p&gt;&lt;p&gt;但在无代码时代，Tossell 第一次尝到了快节奏的甜头：一两个小时，一个周末，快速成型。如果市场不买单，那就随它去吧。因为投入极低，所以放手极快。&lt;/p&gt;&lt;p&gt;而现在，AI 让这种反馈循环达到了光速。&lt;/p&gt;&lt;p&gt;我们正处于软件大爆炸的前夜。你会看到平庸的作品泛滥，但更会看到无数惊艳的项目井喷。那些资深的程序员正以前所未有的速度发布着令人赞叹的开源工具。这意味着，我们拥有了一个取之不尽的灵感库和零件厂，可以随时克隆、调整、重混。&lt;/p&gt;&lt;p&gt;比起从读写文件这种最底层的语法练起，这种以结果为导向的重组效率高得惊人。反馈是即时的，输出是持续的。你不需要在起跑线上纠结太久，你只需要不断地去尝试，去碰撞。&lt;/p&gt;&lt;p&gt;在这个范式下，每一个创意都不再是沉重的负担，而是可以随时抛出的探针。如果你想，你可以随时随地、随心所欲地去构建一切。&lt;/p&gt;&lt;p&gt;Tossell 坚信，每个渴望进入技术世界的人都能做到这一点。你不需要计算机学位，你只需要一份允许自己去玩的许可。把编程看作一场游戏：去注册一个 CLI 智能体，告诉它你想做一个 RSS 追踪器、健身应用或个人网站。然后，按下启动键。&lt;/p&gt;&lt;p&gt;在这个过程中，你会撞上无数 Bug，但这正是最精彩的部分。你不再被错误困扰，而是开始好奇：为什么会这样？你要知道，即便顶尖专家也难逃 Bug 的围攻，而你拥有 ChatGPT 或 Claude 这样的多维智囊团。你可以从不同模型中获取视角，在无数种方案中做出选择。&lt;/p&gt;&lt;p&gt;在工具的丛林里，准则只有一条：最快、最简、最远。&lt;/p&gt;&lt;p&gt;面对琳琅满目的工具，没必要陷入选择瘫痪。选定一个，深挖下去。如果觉得缺了什么，尝试自己去造。&lt;/p&gt;&lt;p&gt;Tossell 最后总结说：「这整件事对我而言，是一场巨大的、令人享受的学习实验。不断构建，不断向前失败，然后不断把新作品推向世界。」&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://x.com/bentossell/status/2006352820140749073&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>LeCun在Meta还有论文：JEPA物理规划的「终极指南」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:29:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5606dbf9-4c0f-472c-89ad-f665d94b1d77/1767461152128.png" style="width: 700%;" class="fr-fic fr-dib"&gt;长期以来，AI 领域一直怀揣着一个宏大的梦想：创造出能够像人类一样直观理解物理世界，并在从未见过的任务和环境中游刃有余的智能体。&lt;/p&gt;&lt;p&gt;传统的强化学习方法往往比较笨拙，需要通过无数次的试错和海量的样本才能学到一点皮毛，这在奖励信号稀疏的现实环境中简直是灾难。&lt;/p&gt;&lt;p&gt;为了打破这一僵局，研究者们提出了「&lt;strong&gt;世界模型&lt;/strong&gt;」这一概念，即让智能体在脑海中构建一个物理模拟器，通过预测未来状态来进行演练。&lt;/p&gt;&lt;p&gt;近年来，虽然能够生成精美像素画面的生成式模型层出不穷，但对于物理规划而言，沉溺于无关紧要的细节（如背景烟雾的流动）往往是低效的。真正的挑战在于，如何在错综复杂的原始视觉输入中提取抽象精髓。&lt;/p&gt;&lt;p&gt;这便引出了本研究的主角：&lt;strong&gt;JEPA-WM（联合嵌入预测世界模型）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;从名字也能看出来，这个模型与 Yann LeCun 的 &lt;strong&gt;JEPA（联合嵌入预测架构）&lt;/strong&gt;紧密相关。事实上也确实如此，并且 Yann LeCun 本人也是该论文的作者之一。更有意思的是，在这篇论文中，Yann LeCun 的所属机构为 Meta FAIR。不知道这是不是他在 Meta 的最后一篇论文？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX68YxNjugbtXkMjk0dMp0GGdRictyDWnRclVzOc4KPPywtgGo16ed5rEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.38055555555555554" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526588" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2403494c-94f8-4be4-aac9-cf23f974f9cb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.24497&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;JEPA-WM 继承了 JEPA 的衣钵，不再纠结于像素级的重建，而是&lt;strong&gt;在高度抽象的表征空间内进行预判&lt;/strong&gt;。在这项研究中，团队试图通过对架构、目标函数和规划算法的全方位扫描，揭示究竟是什么驱动了物理规划的成功，并试图为机器人装上一个更理性的「大脑」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;JEPA-WM 核心方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该团队将 JEPA-WM 的训练与规划流程形式化为一套统一的「终极指南」，重点在于如何在学习到的特征空间中模拟动力学。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 层次化的编码与预测架构&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6m0DCDB1rO2PjSb4bpE7KbhpKTD5Wf39c6LOM3CVCJ6xqibxNP4jcd7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5027777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526589" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1cb180f9-e7e4-4829-9fa8-269446845f43/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在训练阶段，模型主要由四部分交织而成：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉编码器&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6Sh1picVvKKxS6DeJmf4eib3TY4KGHWzNgk3gzJ20jibGnRtX212Y3baWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6962962962962963" data-s="300,640" data-type="png" data-w="135" type="block" data-imgfileid="503526587" data-aistatus="1" data-original-style="width: 35px;height: 24px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/26c8bc0a-1fc5-4001-8991-b4fa80bf993c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 5.23%;"&gt;：使用预训练且冻结的 ViT 权重（如 DINOv2 或 DINOv3）来提取空间特征，确保模型具备敏锐的视觉感知力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;本体感受编码器&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6XdHVYRHd6ORX4icLNX7Zl23KJA9ibwrNKnIiafmtmsAm4pJ0XrYq1bickg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5272727272727272" data-s="300,640" data-type="png" data-w="165" type="block" data-imgfileid="503526590" data-aistatus="1" data-original-style="width: 43px;height: 23px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7adfe226-d658-4b59-ac10-3b86361b8ca2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 6.63%;"&gt;：一个浅层网络，用于捕捉机器人自身的关节角度和位姿，这与视觉信息共同构成了全局状态嵌入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;动作编码器 &lt;/strong&gt;A_&amp;theta;：将机器人的控制指令转化为同维度的特征向量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;预测器 &lt;/strong&gt;P_&amp;theta;：这是模型的心脏。它接收过去窗口内的观测序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6lsaA7j2br8pUhZTqqxkIJg3QF94pAaTMfMc8ibDUleyibicagNqY0RERA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3090909090909091" data-s="300,640" data-type="png" data-w="110" type="block" data-imgfileid="503526591" data-aistatus="1" data-original-style="width: 76px;height: 23px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/54435c81-cb97-4179-8f1f-e95927d2e1aa/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 10.46%;"&gt; 和动作序列&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6pV75vaHjK0sv1aKOIVc2cRA3Gfy5CicW1JE8oA0DCtGj5AzwROaR2aA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.32075471698113206" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503526592" data-aistatus="1" data-original-style="width: 65px;height: 21px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/2fc6422e-f46b-41b9-b7a6-fcf91c012816/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 10.55%;"&gt;&amp;nbsp;，在因果掩码的保护下，并行预测下一时刻的状态嵌入。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 多步展开与动作调节细节&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了让模型不至于「走一步看一步」，研究者引入了多步展开损失&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX662uNuU6G1v2DWy1n0ia00QWxtu4MlibD2RfbKLVMMbpemAodSF6voVIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9565217391304348" data-s="300,640" data-type="png" data-w="46" type="block" data-imgfileid="503526593" data-aistatus="1" data-original-style="width: 26px;height: 25px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/d3e2acf4-d952-4da3-9154-896c1cda9c4f/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.21%;"&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6HAgWXTllUgVgpKHWRQCBe72oXs0fCiaO5ic6J1KRKqaP7ZxibwXgzibwbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.13165829145728644" data-s="300,640" data-type="png" data-w="995" type="block" data-imgfileid="503526594" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ad619104-4b01-4067-8d3c-492a307a0dbb/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在训练时，模型不仅要预测下一帧，还要学会在没有真实观测反馈的情况下，基于自己的预测结果递归生成后续状态。为了提高效率，采用了截断反向传播（TBPTT），即只针对最后一步的预测误差计算梯度，而切断之前的累积梯度。&lt;/p&gt;&lt;p&gt;在动作信息如何干预预测过程上，该团队对比了三种关键方案：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征调节（Feature Conditioning）&lt;/strong&gt;：将动作向量直接拼接到每一个视觉特征向量上，增加了预测器的隐藏层维度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;序列调节（Sequence Conditioning）&lt;/strong&gt;：将动作作为一个独立的 Token 插入到 ViT 的输入序列中，通过注意力机制进行信息分发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自适应层归一化（AdaLN）&lt;/strong&gt;：动作嵌入被投影为缩放和偏移参数，在每一个 Transformer 块中动态调制归一化统计量，这能有效防止动作信号在深层网络中「淡出」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 规划逻辑：在嵌入空间中寻找最优解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;规划被建模为一个在动作空间 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6BEtwOLy7qiauayBTIWiafBr4APxqYEibicQhAAIjgxjwu6tPobsP2gBFxA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.3761467889908257" data-s="300,640" data-type="png" data-w="109" type="block" data-imgfileid="503526595" data-aistatus="1" data-original-style="width: 62px;height: 23px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c50ce09b-7f81-4606-9059-2be7da1962bc/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 6.6%;"&gt; 上的优化问题。给定初始观测 o_t 和目标图像 o_g，智能体会在其内部模型中「试运行」N 条候选路径。评价标准是预测终点的嵌入向量与目标嵌入向量之间的距离&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX60b7YzibOjlKSlWvV5aaLMKE82FXSl859DZU8u7WnyGoWbCU3xnmhE4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.21794871794871795" data-s="300,640" data-type="png" data-w="234" type="block" data-imgfileid="503526596" data-aistatus="1" data-original-style="width: 123px;height: 27px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/14104433-63b2-4b8c-9592-f8ec17190b1a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 12.47%;"&gt;。通过多轮迭代，优化器会不断收敛动作分布，最终输出最优的第一步或前 m 步动作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验与结果：从模拟器到真实机械臂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 Metaworld（42 个操纵任务）、Push-T（物体推送）、PointMaze（导航）以及 DROID（真实机械臂数据集）上进行了评估。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 规划器之争：梯度 vs 采样&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验结果揭示了一个有趣的现象：在像 Metaworld 这种成本曲线相对平滑的任务中，基于梯度的 Adam 或 GD 优化器表现惊人，因为它们能顺着梯度迅速找到目标。但在 2D 导航（Wall, Maze）任务中，梯度法极易卡在局部极小值（例如对着墙猛撞而不懂得绕过门口），此时&lt;strong&gt;基于采样的交叉熵方法（CEM）&lt;/strong&gt;凭借其探索能力完胜。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWictGgomjsDDxhRKpchgqbX66nLeiahjria1mGzUqhrAhuFILarTlRmZ1niaOoAzqfnFDiaDT5qpfXiaxaA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.44537037037037036" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526601" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/98c77a15-ec3e-4b20-ad48-b5ed6b21d6c5/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，新引入的&lt;strong&gt; Nevergrad（NG）&lt;/strong&gt;规划器在无需调参的情况下展现了与 CEM 相当的实力，尤其适合跨任务迁移。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 关键因素的「贡献度」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了量化不同设计决策对智能体最终表现的影响，研究团队采用了一种严谨的控制变量法。&lt;/p&gt;&lt;p&gt;他们以一个基础配置（DINO-WM 结合 ViT-S 编码器及 6 层预测器）为基准，独立改变每一个核心组件，从而在复杂的系统工程中剥离出真正驱动性能增长的关键因子。通过在 Metaworld、Push-T 等多种异构环境下进行数以万计的幕（Episode）测试，实验揭示了世界模型在处理物理逻辑时的内在偏好。以下是影响物理规划成败的核心贡献因素：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;本体感受的显著增益&lt;/strong&gt;：引入机器人内部状态信息（如关节角度、末端位姿）能够一致性地提高规划成功率。在 Metaworld 任务中，这能有效减少机械臂在目标点附近震荡的情况，提供更精准的距离感知。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6I4CRzCs7NnLArxjqW5X4OalfGvdz15rx36qRnKCLWTA59AYBpYJE8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.4222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526597" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/431501cc-df38-40c7-8822-32fd030cbc94/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;编码器架构&lt;/strong&gt;：DINO 系列编码器（DINOv2/v3）在所有任务中均表现出对 V-JEPA 等视频编码器的明显优势。这归功于 DINO 强大的细粒度目标分割能力，这对于需要精确感知物体位置的操纵和导航任务至关重要。在视觉复杂度更高的真实数据（DROID）中，DINOv3 的优势进一步扩大。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;动作调节技术的微妙差异&lt;/strong&gt;：实验发现 AdaLN（自适应层归一化）调节技术在平均性能上表现最强，且计算效率更高。它通过在 Transformer 的每一层注入动作信息，有效防止了控制信号在深层网络传递过程中的消失，相比传统的特征拼接（ftcond）或序列拼接（seqcond）更具稳健性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6BJsmkchtauialiaQwDYY0duEUqZ0MPIbtynEfw1SCXXVdLxfbPPxuCVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4546296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526598" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/9b7f24c9-4896-4ce1-b9a1-1160ef9ded68/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;训练上下文长度的权衡&lt;/strong&gt;：预测器需要至少 2 帧上下文来推断速度信息，这在 W=1 与 W=2 之间的巨大性能鸿沟中得到了印证。然而，&lt;strong&gt;盲目增加上下文长度（如 W &amp;gt; 5）反而有害&lt;/strong&gt;，因为这会减少训练中看到的独特轨迹数量，并可能引入无用的梯度噪声。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6ASiaZ9gCydTDkc0787DSCbN0NiakkALDMsq2ib6G0SVicfVrmF2cn9Hiahw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.4564814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526599" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/6ad53ecd-62c4-4f20-afd8-0ca360e0b253/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;模型规模&lt;/strong&gt;：这是一个令人意外的发现：&lt;strong&gt;在简单的模拟环境（如 Maze, Wall）中，增大模型规模（从 ViT-S 到 ViT-L）非但没有帮助，反而可能由于嵌入空间过于复杂而导致规划效率下降&lt;/strong&gt;。但对于复杂的现实数据（DROID），大容量的编码器和更深的预测器则展现出了明确的正相关收益，说明任务的物理复杂度决定了智能体所需的智力上限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多步损失的对齐作用&lt;/strong&gt;：在训练中加入 2 步展开损失能显著改善预测器的长时稳定性，使其训练任务与测试时的递归规划任务更加对齐。对于最复杂的 DROID 任务，最佳的展开步数甚至需要达到 6 步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 提出的最优解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究最终汇总所有洞察，提出了针对不同任务的最优配置：&lt;strong&gt;在模拟器中使用 ViT-S 配以 AdaLN，而在真实复杂场景中使用 DINOv3 ViT-L 配以 12 层深度的预测器。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6PgkuHVyd2aD1v9wHU2vtYGa1DOhHk2JmicLhunA96KcctDOtTYoic4Ug/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.22962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526600" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/06fdad66-87ca-47e8-9099-86c87ea0e617/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在与 DINO-WM 和 V-JEPA-2-AC 的直接较量中，该模型在几乎所有维度上均取得了领先。&lt;/p&gt;&lt;p&gt;更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>微信炼出扩散语言模型，实现vLLM部署AR模型3倍加速，低熵场景超10倍</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:23:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/a37674ca-a177-4add-b12f-94e3516a5105/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;腾讯微信 AI 团队提出 WeDLM（WeChat Diffusion Language Model），通过在标准因果注意力下实现扩散式解码，在数学推理等任务上实现相比 vLLM 部署的 AR 模型 3 倍以上加速，低熵场景更可达 10 倍以上，同时保持甚至提升生成质量。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;自回归（AR）生成是当前大语言模型的主流解码范式，但其逐 token 生成的特性限制了推理效率。扩散语言模型（Diffusion LLMs）通过并行恢复多个 mask token 提供了一种替代方案，然而在实践中，现有扩散模型往往难以在推理速度上超越经过高度优化的 AR 推理引擎（如 vLLM）。&lt;/p&gt;&lt;p&gt;问题的关键在于：大多数扩散语言模型采用双向注意力机制，这与标准的 KV 缓存机制不兼容，导致并行预测的优势无法转化为实际的速度提升。&lt;/p&gt;&lt;p&gt;近日，腾讯微信 AI 团队提出了 &lt;strong&gt;WeDLM&lt;/strong&gt;（WeChat Diffusion Language Model），这是&lt;strong&gt;首个在工业级推理引擎（vLLM）优化条件下，推理速度超越同等 AR 模型的扩散语言模型&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe0anhK0cBcVt1P9PTmdMiaCCNDTjrU97HrXYiciajZeSxy1PFzOgsKxODg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5176991150442478" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526249" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/24aaf4a5-5411-4106-a5b0-b5f3982a6a51/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文作者：刘瑷玮、何明桦、曾少勋、张思钧、张林昊、武楚涵、贾巍、刘源、周霄、周杰（腾讯微信 AI）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://wedlm.github.io&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub：https://github.com/tencent/WeDLM&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型权重：https://huggingface.co/collections/tencent/wedlm&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以下是模型效果：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9EricQXXByphb4tN0ha6mibe79dCBcQmEC2tPPkyY3g1kJLtJR0eUsZMowFYdARekNDeIynVWf06sA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.6265060240963856" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503526250" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c42cb496-b8e8-4bf1-8e24-809266f55ba3/640.gif" data-order="0" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;上图展示了vLLM 部署的 Qwen3-8B-Instruct（左） 与 &amp;nbsp;WeDLM-8B-Instruct（右） 在相同 prompt 下的实时生成对比。可以直观看到，WeDLM 的生成速度明显更快。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心思路：让扩散解码兼容 KV 缓存&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 的核心洞察是：&lt;strong&gt;mask 恢复并不需要双向注意力&lt;/strong&gt;。扩散式解码只需要让每个 mask 位置能够访问所有已观测的 token，这完全可以在标准因果注意力下实现。&lt;/p&gt;&lt;p&gt;研究团队提出了一个关键指标 &amp;mdash;&amp;mdash; &lt;strong&gt;前缀可缓存性（Prefix Cacheability）&lt;/strong&gt;：在 KV 缓存解码中，只有形成连续左到右前缀的 token 才能被缓存复用。因此，真正影响推理效率的不是「每步预测多少 token」，而是「有多少预测能够转化为可缓存的前缀」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeetiaeODtfAUpE9O0ZXqTeclE7DszONyNSEMp6xKZvcsj0YL3BLuDvQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.45185185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526257" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f528027b-5ecb-4b85-a491-8cf70b4fbedb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图：WeDLM-8B 在数学推理任务上实现约 3 倍加速，同时在准确率和推理速度上显著超越 LLaDA、Dream 等扩散模型。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术方案&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;拓扑重排序（Topological Reordering）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 通过拓扑重排序在保持因果注意力的同时，让 mask 位置能够访问完整的观测上下文。具体而言，将所有已观测 token 移动到物理序列的前端，同时通过 RoPE 位置编码保留其逻辑位置。这样，在标准因果 mask 下，每个待预测位置都能看到所有已知信息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeicv2fialD73zw2k3HdgTDTYKYr8vkYDMUItqsxCdNaVvIScLBWOZiazhg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.497787610619469" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526258" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e8acc538-8319-499c-a0f3-80f111161419/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;双流掩码（Dual-Stream Masking）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为缩小训练与推理的分布差异，WeDLM 设计了双流训练策略：构建一个干净的「记忆流」和一个带 mask 的「预测流」，两者共享位置编码。预测流中的每个 block 从记忆流获取干净的历史上下文，而非可能带噪的中间预测结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;流式并行解码（Streaming Parallel Decoding）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;推理阶段，WeDLM 采用流式并行解码策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;距离惩罚机制&lt;/strong&gt;：优先解码靠左的位置，促进左到右的前缀增长&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;即时缓存&lt;/strong&gt;：在因果注意力下，已解码 token 立即成为有效缓存&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;动态滑动窗口&lt;/strong&gt;：持续填充新的 mask 位置，避免 block 边界的等待开销&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeh9LBDDv1J9FucEr9AGOKFnRzCf77L8S3VMib70tTF8pkmfB1RJKh4sA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3827433628318584" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526259" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/05e437b2-7d5a-4a94-bd3d-8b768c4f9228/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图：传统 block 解码需要等待整个 block 完成才能提交，而 WeDLM 的流式解码可以即时提交已解析的前缀。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生成质量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 基于 Qwen2.5-7B 和 Qwen3-8B 进行训练，使用 100B token 进行继续预训练，10B token 进行 SFT。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeNQSWsYTQ3LsdIiaWJSQEPByUXibsXjwDqTBZA005L4TSrclS9K3icNzbA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5796460176991151" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526260" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/2acecb41-5efb-4d21-b342-a3017bdf0ce0/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 base 模型评测中，&lt;strong&gt;WeDLM-8B 平均得分 74.72，超越 Qwen3-8B（72.61）2.1 个点&lt;/strong&gt;。在数学推理任务上提升尤为显著：GSM8K 提升 4.2 个点，MATH 提升 2.8 个点。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibemqRY2ibBVEJUf1ePdSZAuibc3mZ7t66J5XunVvyztIZYiaTIT0tA66hGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5176991150442478" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526261" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/e7516cce-d36b-4ec0-ba61-c7305e6e808d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 instruct 模型评测中，&lt;strong&gt;WeDLM-8B-Instruct 平均得分 77.53，超越 Qwen3-8B-Instruct（75.12）2.4 个点&lt;/strong&gt;，也领先于 SDAR-8B-Instruct（74.22）等扩散模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理速度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;关键亮点：所有速度对比均基于 vLLM 部署的 AR 模型基线，而非未优化的实现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeaS02hxlXDSZBSL8fFHiaQ8MJ3Btjy8F5yMVxVnYcF8eoByJCgiaAxRKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.27564102564102566" data-s="300,640" data-type="png" data-w="936" type="block" data-imgfileid="503526262" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7a316bf7-058a-4c8c-a9d0-5aa1c741036d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队在论文中展示了不同熵值场景下的速度差异：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低熵场景（如计数任务）：由于输出高度可预测，模型可以大胆并行预测并接受多个 token，实测达到 1673.3 tokens/s&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中熵场景（如数学推导）：结构化的推理步骤仍然具有较好的可预测性，实测 745.2 tokens/s&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高熵场景（如开放问答）：语义多样性高，并行接受率下降，实测 197.8 tokens/s&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;快速上手&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;安装方式非常简单，只需通过 pip 从 GitHub 安装即可。安装完成后，可使用 Python API 快速调用模型进行推理。详细的使用文档和示例代码请参见项目 GitHub 主页。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 的贡献可以归纳为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;因果扩散框架：在标准因果注意力下实现 mask 恢复，天然兼容 KV 缓存和现有推理基础设施（FlashAttention、PagedAttention、CUDA Graphs 等）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;流式并行解码：通过距离惩罚和动态滑动窗口，最大化前缀提交率&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;首次在速度上超越工业级推理引擎部署的 AR 模型：在 vLLM 优化条件下的公平对比中，数学推理实现 3 倍以上加速，低熵场景超过 10 倍&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队指出，这项工作表明「前缀可缓存性」应当作为并行文本生成的一等设计目标。未来的扩散语言模型应更多地被视为高效的多 token 预测机制 &amp;mdash;&amp;mdash; 并行生成 token 的价值，取决于这些 token 能多快地转化为可缓存的前缀。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>陶哲轩：AI让数学进入「工业化」时代，数学家也可以是「包工头」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:19:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/941dfc0f-d694-481c-a585-dedc852f0e3f/1767460311831.png" style="width: 700%;" class="fr-fic fr-dib"&gt;很多人提到数学研究，脑子里浮现的还是那个画面：一个人，一块白板，来回踱步，等灵感突然降临。&lt;/p&gt;&lt;p&gt;但当今世界最伟大的数学家之一、菲尔兹奖得主陶哲轩却告诉我们：这种「手工业时代」的数学研究模式正处于崩溃边缘，一场由 AI 和形式化证明语言（如 Lean）引领的「工业革命」已经悄然开启。&lt;/p&gt;&lt;p&gt;这一洞察来自陶哲轩最近的一次访谈：&lt;a href="https://mp.weixin.qq.com/s/wVTRbVtMZX3-WISdtrjbNg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0d5c4674-19d4-402a-a7fd-70fbb68fe850/1767460324061.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;视频标题：Terry Tao on the future of mathematics&lt;/p&gt;&lt;p&gt;视频链接：https://www.youtube.com/watch?v=4ykbHwZQ8iU&lt;/p&gt;&lt;p&gt;在访谈中，陶哲轩指出，数学研究中存在大量的重复性劳动，如查阅文献、调整他人论文中的参数以及繁琐的计算。通过 LLM 辅助的自动形式化（Auto-formalization），这些琐碎的工作正逐渐变得轻松。&lt;/p&gt;&lt;p&gt;与此同时，Lean 等形式化证明语言与 AI 的深度融合正在改变数学协作的本质。形式化并不只是「把证明写得更严格」，而是&lt;strong&gt;把数学拆成了可以独立验证的原子步骤&lt;/strong&gt;。这种原子化让分布式科研第一次变得可行。&lt;/p&gt;&lt;p&gt;陶哲轩预见到，数学界将出现类似软件工程的分工模式。未来的数学家可能扮演「架构师」或项目经理的角色，领导大型协作项目。这种模块化的研究方式可能允许「公民数学家」（非专业领域专家但具备某些技能的人）参与到前沿研究中，降低进入门槛。如此一来，数学研究的进展或显著加速。&lt;/p&gt;&lt;p&gt;参与访谈的另外两位数学家分别是前 OpenAI 研究科学家、Morph Labs 创始人 Jesse Han，以及斯坦福大学助理教授 Jared Duker Lichtman。&lt;/p&gt;&lt;p&gt;以下是机器之心整理的访谈记录。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从几十年到 18 个月 &amp;nbsp;数学研究正被加速&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;： 说实话，在我整个学术生涯中，我一直觉得我们做数学的方式少了点什么。我们在研究一个数学问题时，总想找到那个能打开问题大门的精妙想法。但在那之前，有大量枯燥的苦力活。比如文献综述，比如你在别人论文里看到一个技巧想用到自己的问题上，但所有的输入条件都有点不一样，你就得手动调整所有的论证。还有那些计算 &amp;mdash;&amp;mdash; 它们确实有用，能帮你建立直觉，但很多时候就是硬磨，不停地算啊算。我以前也试过写一些小程序来加速某些计算，但那时候技术还不成熟。&lt;/p&gt;&lt;p&gt;大概两年前，就在 IPAM（纯粹与应用数学研究所）这里，我们办了一个机器辅助证明的会议，我是组织者之一。在那次会议上，我们接触到了各种各样的尝试 &amp;mdash;&amp;mdash;SAT 求解器、计算机辅助软件包、大语言模型。ChatGPT 刚问世，还有 Lean。那是一个令人兴奋的世界，你突然发现很多事情变得可能了，而且正在发生。比如 Peter Scholze 刚完成了一个长达 18 个月的项目，把他的一个重要定理形式化了 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：液态张量实验。&lt;/p&gt;&lt;p&gt;陶哲轩： 对，液态张量实验。这是个大工程，一个定理花了 18 个月。但这已经被认为是巨大的突破了，因为 &lt;strong&gt;20 世纪的那些形式化项目，动辄要花几十年才能完成。所以这本身就是一个巨大的提速&lt;/strong&gt;，部分原因是我们已经学会了如何使用软件工程的那些工具，比如 GitHub，以及更智能地组织这些项目。从那以后，我对 AI 和形式化都产生了浓厚的兴趣 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;： 就是因为那次会议。&lt;/p&gt;&lt;p&gt;陶哲轩： 对，没错。我开始相信这就是数学的未来，也开始接受一些采访谈这个话题。但到了某个时候，你不能光说不练，得真正动手。所以我就去学了 Lean，花了大概一个月，但其实挺好玩的。这让我想起了写本科分析教材的经历 &amp;mdash;&amp;mdash; 真的是从基础开始，把每一步都做到完全严格。感觉就像在玩电子游戏。我记得 Kevin Buzzard 说过，Lean 是世界上最好玩的电子游戏，大概是这个意思。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;： 让人完全上瘾。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;： 对某类人来说确实非常上瘾。而在过去一年里，&lt;strong&gt;大语言模型追上来了，它们现在可以自动形式化单个证明步骤，真正开始减轻形式化过程中的苦力活，甚至到了可以实时完成的程度。这打开了无数的可能性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;形式化正在改变数学思维 &amp;nbsp;把含混经验转化为可检验的结构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;： 我第一次接触 Kevin Buzzard，是 2017 年他在 MSRI（美国数学科学研究所）教自守形式那门课的时候。几年后我跟他聊天，他说他当时根本没在关注那门课的内容，因为那个夏天他正在自学 Lean&amp;mdash;&amp;mdash; 在 Tom Hales 在第一届大型证明会议上告诉大家 Lean 将是未来之后。&lt;/p&gt;&lt;p&gt;我自己在第一次学习形式化证明的时候，有一个体会是：我慢慢意识到，其实我从来没有真正学会清晰地思考数学论证。高等数学的证明里有一种普遍的，或者说文化性的混乱感。我很好奇，当你越来越深入地去预判如何形式化证明时，你对自己数学思维的认知有什么变化？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;： 确实有一些变化，改变了我写论文的方式。我现在能看到那些「隐形假设」&amp;mdash;&amp;mdash; 那些我们习惯性地默认成立的东西。你会更认真地思考：怎样才是最干净的定义方式？因为在 Lean 里，当你定义一个概念并想使用它时，你必须先建立一堆琐碎的引理，就是所谓的 API，围绕着每个概念。这些东西在论文里往往是「显然这个概念是单调的」「显然它在某种运算下封闭」，但你其实应该证明它们。而且你会发现，如果定义得不够好，形式化这些「琐碎」命题要花两倍甚至五倍的时间。所以这让我学会了如何精简自己的写作。有时候我会对合作者有点不耐烦，因为有些人没有这个视角，还在用老式的非形式化风格写东西。&lt;/p&gt;&lt;p&gt;Heather Macbeth 写过一篇文章，讲形式化和自动化如何催生了一种新的证明写作风格。传统的证明通常是线性的，从 A 到 B，一步一步推，比如一串等式。但有了自动化工具，你可以说：这里有 10 个相关的事实，用一个标准工具来找出这 10 个事实的正确组合就能完成证明。而这个组合往往很无聊，没什么意思 &amp;mdash;&amp;mdash; 你知道某种线性代数之类的东西能从这些事实得出结论。这是一种不同的证明写作风格，某种意义上反而更容易读懂。对人类来说更难验证，但你能更清楚地看到一个证明的输入和输出，而传统写法往往把这些藏起来了。&lt;/p&gt;&lt;p&gt;Jared Duker Lichtman：Peter Scholze 的情况也是这样，他说过，在形式化过程中获得反馈，实际上让他对某个关键引理的细节思考得更清楚了，他觉得这是一个非常有价值的过程。你有一个很棒的框架 &amp;mdash;&amp;mdash; 前严谨阶段、严谨阶段、后严谨阶段。这个框架怎么融入我们现在讨论的话题？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：对，我写过一篇传播很广的文章，讲学习数学的三个阶段。第一个是前严谨阶段，你并不真正知道什么是证明，但对什么行得通、什么行不通有一些模糊的直觉。这通常是小学阶段对数学的理解方式。有时候你的直觉是对的，有时候是错的，但你没有办法分辨哪个是哪个。&lt;/p&gt;&lt;p&gt;然后是严谨阶段，你被迫完全按照规矩来，每一步都要做得准确无误。但在这个阶段，你往往会失去直觉，因为你全部的注意力都在确保每一步都正确。不过这有助于清除你所有错误的直觉，因为你能看到精确的反例，知道论证在哪里失败了。而所有好的直觉 &amp;mdash;&amp;mdash; 那些与严谨推理一致的 &amp;mdash;&amp;mdash; 都会保留下来。&lt;/p&gt;&lt;p&gt;然后是后严谨阶段，你可以在两种模式之间自由切换。你可以非形式化地论证，但现在是安全的，因为你已经清除了所有错误的直觉。你知道如果需要的话，可以把它转换回严谨的形式。反过来，你也可以读一个严谨的论证，然后把它转换成直觉性的语言。&lt;/p&gt;&lt;p&gt;Lean 确实帮我清理了一些思维中低效或错误的习惯。一个很常见的低效问题是：当你在教科书里陈述一个定理时，往往会加入太多假设。你有点过于保守，想确保证明是对的，就加了一堆额外条件 &amp;mdash;&amp;mdash; 这个非空、那个连续、这个为正之类的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：你会想去对这些假设进行压力测试。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：对。但其实还有自动化的 linter 工具，当你在 Lean 里形式化某个东西，证明结束后它会说：「顺便提一下，你从来没用过这个假设。」然后你就会想：「哦，确实，我其实根本不需要正性条件。」文献里确实有过这样的真正突破：人们心里有个思维定式，觉得某个工具只能用在比如正数的情况下，但其实证明在没有正性条件的情况下照样成立，只是没人注意到。形式化能让你自动发现每个工具的自然适用范围。这已经非常有用了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：这个说法很精辟。我们花了很多时间思考一个问题：来自软件工程和计算机科学的深度洞见，如何影响人们对数学认知和数学研究的思考方式。你刚才说的形式化如何让我们更清楚地理解每个定理的假设和输出，这其实就是良好的软件工程实践。Dijkstra 就专门讲过，人们应该更多地去推理前置条件和后置条件。同样的道理，数学家习惯在定理里堆一堆可能用不上的假设，这在软件工程里是典型的反模式 &amp;mdash;&amp;mdash; 一种公认的坏习惯。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;两个顿悟时刻 &amp;nbsp;形式化正在改变数学领域协作方式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：我特别想问你的是：你在形式化过程中的「顿悟时刻」是什么？显然一开始有很高的启动门槛，你得学习所有这些关于这门小众学术编程语言的晦涩知识。但是，在哪个时刻你意识到，把数学变成软件这个过程，不仅仅是翻译，还能加速你的理解，加速数学发现的过程？&lt;/p&gt;&lt;p&gt;对我来说，是在形式化连续统假设的独立性时。有一个时刻我完全迷失了，所有的参考资料都是错的，但我发现可以打开或关闭某些关键假设，然后很快就获得了比任何教科书都深得多的理解。我很好奇你有没有类似的经历。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：有，我有两个印象特别深刻的时刻。&lt;/p&gt;&lt;p&gt;第一个是我在形式化一个和合作者一起证明的定理，叫 PFR 猜想 &amp;mdash;&amp;mdash; 多项式 Freiman-Ruzsa 猜想。结论里有一个指数常数，我们当时证明的是：存在一个常数，使得某个性质成立，而这个常数最后算出来是 12。原因并不神秘，只是把证明中所有零零碎碎的小常数一路累积下来，最后自然就变成了 12。&lt;/p&gt;&lt;p&gt;我们花了大概三周时间，把这个「C 等于 12」的结论完整形式化成 Lean 代码。那是一个完全没有 AI 的年代，整整 20 个人，全靠手工，是一次非常浩大的工程。&lt;/p&gt;&lt;p&gt;后来，有人往 arXiv 上放了一个很短的预印本，说如果你回到原始论文，只要做五个小改动，就可以把这个 12 降到 11。于是大家就开始讨论：那我们要不要把 C 等于 11 也形式化一遍？问题在于，C 等于 12 已经花了我们三周时间，那再来一遍岂不是又是三周？&lt;/p&gt;&lt;p&gt;实际情况并不完全是这样，但直觉上你几乎只是把最终定理里的 12 改成 11。然后你会发现，大概有五行代码变红了，也就是证明不再成立了。但你去看那篇新的预印本，就会发现，哦，这五行我知道该怎么改。结果一改，这五行是好了，又有另外十行变红了。于是你再回去改那十行。就这样来回几次，我们在一天之内就把整个证明更新成了 C 等于 11。&lt;/p&gt;&lt;p&gt;所以，&lt;strong&gt;形式化确实很繁琐，尤其是第一次把一个结果完整写出来的时候。但一旦你想修改一个已有的证明，它就比传统数学方式好得多。这是我第一个非常深刻的体会&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;第二个经历来自一个名为 Equation of Theories 的项目，然后对一项研究进行形式化时，有一次很深的体会。当时有人在把另一位作者写的证明形式化，结果卡在了某一步。我当时也并不了解整个证明的全貌，甚至可以说完全不理解整体结构，但我盯着那一行代码看了一会儿，发现我其实能理解这一行在做什么。&lt;/p&gt;&lt;p&gt;我能够理解足够多的上下文，从而指出：你这里其实只需要复制并稍微修改这一行，让它在类型上匹配，这样就能调用这个工具了。&lt;/p&gt;&lt;p&gt;也就是说，&lt;strong&gt;我只通过检查一千多行代码中的三行，就给出了一个非常原子级（atomic）的诊断，精确地指出了这个证明该如何修复&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;我认为这正是 Lean，乃至形式化验证软件的一大特点：它具有一种&lt;strong&gt;高度模块化的结构&lt;/strong&gt;，这是很多其他软件甚至传统数学中并不具备的。你可以围绕某一行、某一个非常具体的局部问题展开极其精细的讨论，而完全不需要理解系统的其余部分。&lt;/p&gt;&lt;p&gt;而在传统数学中，只有在与你长期合作、彼此已经在思维方式上高度对齐的情况下，才能做到这一点。那种状态下，你们几乎可以在极其细微的层面上互相理解，甚至补全对方的句子。&lt;/p&gt;&lt;p&gt;通常情况下，当你和一个尚未在思维方式上充分同步的人讨论数学问题时，是很难进行这种粒度如此之细的交流的。&lt;/p&gt;&lt;p&gt;所以你确实可以进入那种高度专注、默契协作的状态，那种感觉非常好。但现实是，能让我进入这种状态的合作者其实只有少数。更多时候，合作中充满了翻译成本：你需要反复澄清定义、解释背景，也不可避免地会出现各种误解。&lt;/p&gt;&lt;p&gt;而在 Lean 中，这些问题在很大程度上都会消失。因为你面对的是一个对问题和修复方式都有着精确定义的类型描述。问题是什么、哪里不匹配、该如何修复，都被明确地写进了系统里。Lean 以一种此前从未有过的方式，把数学原子化了 &amp;mdash;&amp;mdash; 这是其他做数学的方法所不具备的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数学进入「工业化」时代 &amp;nbsp;数学家也可以是架构师&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jared Duker Lichtman：顺着这个话题再往前想，其实也很有意思：我们正在用一种全新的方式来使用数学。你经历过互联网的兴起，也算是较早参与并推动了类似 Polymath （博学者项目）这种协作式研究项目的人之一。也许你可以谈谈，你对协作的直觉是如何形成的？在过去大约二十年的时间里，这种协作方式是如何演化的？&lt;/p&gt;&lt;p&gt;以及展望未来，在一种高度模块化的交互模式下，有时甚至是匿名的协作中，数学研究可能会呈现出怎样的新形态？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：我想再补充一点。你在几年前发表于《Notices of the American Mathematical Society》的一篇文章里，提到过一个非常有意思的观点：你如何看待数学家角色的演变。&lt;/p&gt;&lt;p&gt;我也很想听你进一步展开这一点，因为这和我们刚才讨论的内容高度相关，比如，当你开始主导、协调这些形式化项目时，你是否也感受到自己角色的变化？以及你在组织 Polymath 项目过程中积累的经验，又是如何与这种变化发生交汇、相互影响的？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我一直都有一种很强烈的感觉：&lt;strong&gt;我想做的数学，远远超过了一个人所能完成的量。因此，我始终觉得合作极其高效、也极其重要。&lt;/strong&gt;我从合著者身上学到了很多，同样也从互联网上一些看似偶然的交流中学到了很多。&lt;/p&gt;&lt;p&gt;举个例子，我最早开始写博客，其实源于一次非常偶然的经历。有一次，我在自己的网页上随手贴了一个数学问题，并没有期待会有人回应。但当时已经有不少人会浏览我的页面，结果在短短三天之内，就有人给了我一个非常完整的参考说明，直接指出这个问题最早的来源。放在今天，这可能只需要一次简单的 ChatGPT 查询就能得到答案，但在当时，这对我来说是一种颠覆性的体验。&lt;/p&gt;&lt;p&gt;后来，英国数学家 Timothy Gowers 提出了 Polymath 项目，希望通过众包的方式来做数学研究，而我也非常享受参与其中。这种想法和我的直觉高度契合：数学中存在着大量潜在的联系，&lt;strong&gt;参与的人越多，就越有可能产生那些偶然的连接，这些连接往往是任何单一专家、无论多么资深，都很难凭一己之力发现的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;但与此同时，这种协作方式始终存在一个明显的瓶颈。&lt;/p&gt;&lt;p&gt;在 Polymath 项目中，当同时有十几、二十个人参与贡献时，总需要有人来逐条检查这些想法，确保逻辑上一致，并把零散的讨论整理成一个连贯、可读的整体。这个工作通常由我、Timothy Gowers，或者其他少数人来承担，而这件事实际上是非常耗费精力的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman：原本看似去中心化的群体协作，最终还是回到了一个核心人物 + 众多贡献者的老模式。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：对，这种模式虽然很有潜力，但并没有真正实现规模化。不过，它确实促成了一些非常宏大的研究项目：来自数学中完全不同方向的人，会因为偶然的灵感，贡献出大量有价值的线索。很多时候，项目的组织者事先根本不知道这些人彼此之间存在任何关联，但他们提供的想法却是相关且有用的。&lt;/p&gt;&lt;p&gt;问题在于，当时我们并没有完善的组织与验证基础设施。而且那时我们主要是通过博客和 Wiki 来运作项目，而不是像今天这样使用 GitHub 这类更成熟的协作平台。&lt;/p&gt;&lt;p&gt;也正是在这里，形式化工具和 AI 展现出了另一项关键能力：&lt;strong&gt;它们真正实现了不同技能背景人群之间的无缝协作&lt;/strong&gt;。在一个形式化项目中，并不是每个人都需要懂 Lean，也不是每个人都需要精通数学，更不是每个人都要熟悉 GitHub。你只需要一个技能集合彼此有重叠的群体：每个关键环节都有一部分人能够胜任，整体就能顺利推进。&lt;/p&gt;&lt;p&gt;这也使得数学研究第一次真正具备了分工协作的可能性。&lt;/p&gt;&lt;p&gt;在传统数学研究中，无论是单人还是合作，参与者几乎都需要什么都懂：既要理解全部数学内容，又要会写 LaTeX、检查推导、整理论文，每个人都要覆盖所有环节。而在真正意义上的分工体系中，就像工业化生产一样，会有人负责项目管理，有人负责质量验证，有人专注于具体技术细节。&lt;/p&gt;&lt;p&gt;软件工程其实早就完成了这种转变。早期的软件开发也是一个人包办一切，但这种方式无法扩展；一旦进入企业级开发，就必须依赖高度专业化的角色分工。&lt;/p&gt;&lt;p&gt;因此，&lt;strong&gt;我确实预见到一种趋势：在规模化、工业化的条件下生产数学成果，并且伴随着清晰的专业分工&lt;/strong&gt;。当然，传统的、手工式的数学研究依然会存在，也依然会被高度珍视；只是未来会出现一种与之互补的、全新的数学生产方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：那么，这是否意味着你预见到，大多数职业数学家的角色将会演变为这些工业化数学体系的架构师？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我认为，数学家的定义本身会被拓宽。未来会出现一类人，他们擅长运作和管理大型项目，就像大型工程中的项目负责人一样。这些大型项目的管理者会掌握足够多的数学和 Lean 知识，能够在宏观层面理解项目在做什么，但他们未必擅长定位和修复某一条具体的形式化问题。尽管如此，他们能够协调复杂项目的推进，而这本身就是一种非常重要的能力。&lt;/p&gt;&lt;p&gt;同时，也会有一些人，他们可能并不是某个数学领域的专家，但非常擅长形式化工作，或者非常善于使用新的 AI 工具。这些能力本身同样有价值。&lt;/p&gt;&lt;p&gt;在这样的体系中，人们可以更自由地加入或离开项目，协作将变得更加流动。当然，也仍然会存在更传统的研究方式：由一个规模较小的团队组成，所有人都深度参与项目的每一个环节。这种方式依然非常重要，也不会消失。关键在于，我们终于拥有了多种选择。&lt;/p&gt;&lt;p&gt;在当前体系下，许多真正热爱数学的人被挡在数学研究之外，只是因为门槛太高了。如果你想参与前沿研究，就必须掌握博士阶段水平的数学；你还得会用 LaTeX；得知道如何写作、如何避免任何细节错误&amp;hellip;&amp;hellip; 这些要求叠加在一起，对很多人来说极具威慑性，进入门槛过高。&lt;/p&gt;&lt;p&gt;即便成功进入这一体系的人，也常常因为自身技能结构不完整而被忽视或边缘化。但未来并不必然如此，随着工具、形式化和协作方式的变化，这种状况有可能被根本性地改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：在门槛被工具和协作机制降低之后，数学研究不再只属于少数职业数学家，而可以像公民科学一样，吸纳大量具有兴趣和部分技能的普通参与者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：是的，我们其实已经在看到这种趋势了。比如我自己就深度参与过一个数学问题网站。它逐渐发展成了一个社区，聚集了几十位数学背景和受教育程度各不相同的参与者，大家各自贡献一些小而具体的内容。&lt;/p&gt;&lt;p&gt;我们学会了把一个问题模块化拆解：也许你没法完整地解决这个问题，但你可以帮忙查找相关参考文献；或者把问题和某个整数序列联系起来；或者评论、改进他人的证明；又或者做一些数值实验和计算。&lt;/p&gt;&lt;p&gt;正是通过这种方式，很多人都能在自己能力范围内参与进来。&lt;/p&gt;&lt;p&gt;而现实中，确实存在着一个非常庞大的群体，他们渴望参与研究级别的数学工作，只是过去缺乏合适的入口和工具。我希望，也相信，&lt;strong&gt;这些新的工具和协作方式，能够真正释放出这股力量。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 应该先帮数学家「干脏活」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：到目前为止，我们已经谈了很多内容：一方面是你在形式化数学前沿工作的经验，另一方面是你在协调大规模协作项目、加速数学研究方面的实践。而我觉得，正好在这两者的交汇点上，是一个非常合适的时机，来谈谈你目前特别投入、也非常兴奋推动的一个项目，解析数论中数学界限（Bounds）的形式化证明。&lt;/p&gt;&lt;p&gt;或许我们可以从一个简要的介绍开始：面向非专业读者，能否先解释一下 &amp;mdash;&amp;mdash; 为什么这个问题本身如此重要？以及它在某种程度上，如何成为我们刚才讨论过的那些问题（协作、形式化、规模化研究）的一个缩影或体现？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我想先从一个更宏观的角度来讲。我一直认为，自动化本质上是对人类思维的补充工具。&lt;/p&gt;&lt;p&gt;最直观的一种思路是：把人类最想解决、也最困难的数学问题 &amp;mdash;&amp;mdash; 比如像黎曼猜想这样的重大猜想，直接交给计算机，让它们来尝试解决。计算机在这些问题上确实可能取得一定进展，但我认为，在可预见的未来，它们更有可能在另一类完全不同的任务上发挥巨大优势。&lt;/p&gt;&lt;p&gt;这些任务往往与人类真正擅长、或乐于从事的工作是正交的，尤其是那些需要进行大量枯燥的数值计算、枚举海量可能性、反复筛选组合情况的工作。这类任务人类通常并不享受，甚至极易出错，但对 AI 和计算机来说却并不构成障碍。&lt;/p&gt;&lt;p&gt;以我所从事的领域之一解析数论为例，这里就存在一个非常典型的困难：其中有大量极其繁琐、细碎的组合性计算工作，长期以来几乎只能由人类亲自完成，而这正是自动化和 AI 最有潜力介入、并发挥巨大价值的地方。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：对我个人来说，在思考一个解析数论问题时，至少有 70% 的时间，都花在这种繁琐、机械性的工作上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：是的，我认为我们其实已经掌握了很多非常精巧的思想和工具，可以把关于数字的一类陈述，或者关于和的展开、各种算术函数等内容，转化为我们真正关心的另一类陈述。解析数论中正是依靠这些工具在不同表述之间来回转换。&lt;/p&gt;&lt;p&gt;但问题在于，这些工具都有各自的输入和输出条件，而真正做研究时，你需要把它们一环一环地串联起来。相关的工具和结果分散在不同的论文中，每篇论文使用的记号体系都不一样，假设条件也往往和你手头的问题并不完全匹配。于是你不得不重新拆解原有证明，根据自己的需求重写一套版本。&lt;/p&gt;&lt;p&gt;在这个过程中，就会产生大量的重复劳动：反复调整参数、对齐条件、重建推导链条，而且非常容易出错。&lt;/p&gt;&lt;p&gt;为了让事情稍微不那么痛苦，我们发展出了一些权宜之计。其中一个最常见的做法是：不去关心具体常数。比如这里原本是 27，那里是 38，我们干脆都记成一个统一的常数 C，只说明存在某个常数，而不去计算它的具体数值。这样可以显著减少计算量，也能在一定程度上避免错误，即便你在常数上算错了，只要结论仍然成立，通常也不会造成严重后果。&lt;/p&gt;&lt;p&gt;但这种做法是有代价的。它导致解析数论中的很多结果都是非显式的。比如你可能证明了：所有足够大的奇数都可以表示为三个素数之和，但足够大究竟是多大？这个常数 C 到底是多少？我们并没有算出来，说白了，是懒得算。&lt;/p&gt;&lt;p&gt;因此，真正去显式计算所有常数的解析数论研究，只占整个领域中非常小的一部分。这类工作极其繁琐、计算量巨大，做的人很少，论文也往往不太好理解。这并不是作者水平的问题，而是因为研究内容本身就充斥着大量细碎、明确的计算过程，几乎没有那种直观的结构美感可言。&lt;/p&gt;&lt;p&gt;说实话，这种研究并不好理解。但我认为，这恰恰是自动化最理想的应用场景之一。如果我们能够搭建一条流水线，把这些显式型的论文纳入进来，其中的思想和工具本身其实已经相当成熟，真正困难的只是把大量彼此略微不兼容的工具拼接在一起，并把所有参数对齐，那么，用现有的方法就完全有可能在规模化条件下完成这些形式化工作。&lt;/p&gt;&lt;p&gt;在此基础上，我们甚至可以引入 AI 或机器学习，去探索这些工具链的最优组合方式。这将为整个领域打开许多全新的观察视角。&lt;/p&gt;&lt;p&gt;举个具体的例子：如果有人在某个算术函数上证明了一个新的界，我们希望能把这个结果直接丢进一个已经形式化好的、包含上百条定理的系统中，然后像操作 Excel 表格一样自动更新，改动一格，所有依赖它的结果都会自动刷新。&lt;/p&gt;&lt;p&gt;这样一来，我们就可以拥有一个持续演化、动态更新的领域最前沿状态，而不再是那些写死了指数和常数的论文。现在的做法是：每当某个关键结果被改进，研究者往往需要重写整篇论文，重新推导所有相关界限，才能弄清楚最新的最好结果是什么。而这类更新，通常十年才发生一次；但如果工具链足够成熟，这些工作完全可以在几分钟内完成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：所以你的意思是，这本质上是一个软件问题，对吗？就像早期编程时代，人们看待汇编语言时那样，它非常繁琐，到处都是子程序，逻辑隐藏在代码细节里，既不直观，也谈不上可读性。但一旦能够在更高层次上对这些内容进行抽象和推理，情况就会完全不同。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：可以这么理解。而且在现代软件工程中，原则上一切都是可以互操作的。你可以调用别人的子程序，不同工具之间有标准化的接口和格式，它们能够彼此通信，从而构建起极其复杂、庞大的软件生态系统。&lt;/p&gt;&lt;p&gt;当然，这样的系统也会带来一个问题：正是因为系统复杂、组件众多，软件中不可避免会出现各种错误。&lt;/p&gt;&lt;p&gt;但在数学形式化这件事上，像 Lean 这样的工具，至少在理论上，让我们有机会构建一种尽可能无 bug 的协作体系。通过形式化验证，你可以希望、甚至确信这些由大量研究者共同构建的成果是相互兼容、逻辑一致的。而这正是我们目前在数学研究中所缺失的东西：一种真正可靠、可互操作、可规模化扩展的基础设施。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当新工具出现 &amp;nbsp;数学的研究路径会整体改写吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：那么你是否愿意做一个大致的判断或推测：在数论，乃至其他数学领域中，有多大比例的工作其实是由这些相对枯燥、机械性的劳动构成的？如果这种工作负担的比例发生改变，是否可能由此催生一种截然不同的研究工作流程？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：我想在这个问题上再补充一句。事实上，在数学史上，应该已经出现过不少并非基于形式化验证、也不依赖计算机的例子：某些更好的数学技术或方法被发明出来之后，使数学家得以摆脱以往的一些繁琐劳动，从而能够把精力投入到全新的问题和思考方式中。&lt;/p&gt;&lt;p&gt;我也很好奇，在解析数论的发展过程中，是否存在过这样的重要例子？比如，是否有某些关键方法的出现，真正改变了人们理解和研究这一领域的方式？&lt;/p&gt;&lt;p&gt;如果是这样的话，那么我们是否也可以把如今的形式化工具（如 Lean）以及自动形式化技术，视为历史上这一类技术演进的又一个实例，一次新的数学技术革命？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我认为数论其实是最早采用实验性方法的数学分支之一。例如，数论中的一个核心问题，关于素数分布的规律，最早就是由高斯提出的猜想。&lt;/p&gt;&lt;p&gt;高斯当年通过一种极其艰苦的方式来获得直觉：他手工计算了前几十万、甚至上百万个素数，并从这些数据中观察到了某些模式，由此提出了后来影响深远的素数分布猜想。&lt;/p&gt;&lt;p&gt;从今天的角度看，这几乎就是一种早期的计算实验数学：通过大量具体数据的积累，来引导理论判断和猜想的形成。这在当时是非常开创性的做法，也深刻影响了数论此后的发展方向。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：而且当时所依赖的，其实只是规模很小的数据。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：是的。高斯展现出了一种非凡的能力：他能够从规模非常小的数据集中，概括出极其深刻、普遍的规律，这正是高斯天才的体现，也正因为如此，后来很多工具都会以他的名字命名。&lt;/p&gt;&lt;p&gt;而随着计算技术的发展，我们才真正能够系统性地展开这种探索。后来也陆续出现了不少类似的例子：一些重要的猜想最初正是通过数值实验和计算探索被发现的；而在更近的时代，还有一些结果是借助大规模枚举，甚至结合机器学习方法，才逐渐显现出其结构和规律的。&lt;/p&gt;&lt;p&gt;这些进展都说明了一点：新的技术手段不断扩展着数学家可探索的空间，也在持续改变人们理解和研究数论的方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：我想，甚至连图灵当年也在做类似的事情，亲自去计算函数的零点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：像某些算术函数的研究，其实早期就大量依赖数值计算。比如黎曼猜想，在很长一段时间里，正是通过大量数值实验获得了强有力的支持。&lt;/p&gt;&lt;p&gt;因此，历史上早就存在这样的先例：&lt;strong&gt;计算机的引入，催生了一种新的数学研究方式，不再只是依赖纯粹的抽象思考，而是结合数据和实验来推动理论的发展&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;当然，我们现在讨论的这种形式化工作，并不完全等同于数据驱动的数学，但它无疑是一种计算机辅助的研究模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：那么，撇开机器学习领域里那一小部分人，或者少数主动尝试新工具的研究者不谈，对于一位普通的数学家来说，无论是在数论还是其他领域，在日常研究工作中，有多大比例其实是被这种繁琐、机械性的苦工所拖慢、所构成瓶颈的？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：这个问题其实很难给出一个精确的百分比，但我觉得关键并不在于直接统计时间比例，而在于一种间接影响。&lt;/p&gt;&lt;p&gt;正是因为这些繁琐劳动的存在，我们往往会有意识地改变做数学的方式，尽量减少自己要面对的苦工。比如，当我们意识到某一步组合推导开始变得非常凌乱、计算量巨大时，往往会选择刻意绕开，改用另一条思路继续推进。&lt;/p&gt;&lt;p&gt;因此，如果你只看最终论文里呈现出来的内容，会觉得我们似乎做的都是高判断力的工作，真正的苦工并不多。但那是因为我们在研究过程中，已经下意识地避开了道路上的一个个坑，用一个比喻来说，我们是在不断绕开崎岖路段，而不是去填平它们。&lt;/p&gt;&lt;p&gt;而一旦这些工具真正到位，情况可能会发生根本变化。那时，我们会改变做事方式：如果前方出现一个巨大而繁重的计算任务，我们不再选择绕路，而是直接碾过去，动用所有可用的技术手段，借助计算、形式化工具，甚至直接交给计算机，说清楚从这里到那里该怎么走，然后继续前进。&lt;/p&gt;&lt;p&gt;这样一来，我们就可以穿越那些现在几乎是下意识回避的障碍。所以，&lt;strong&gt;从表面上看，当前数学研究中苦工的比例似乎并不高；但如果把那些被我们主动规避掉的工作也算进去，那这个比例其实远比看上去要大得多&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：之前你提到过，一个非常重要的瓶颈在于：寻找合适的合作者本身就很困难，更不用说还要在工作方式、思路层面与他们建立足够的默契。&lt;/p&gt;&lt;p&gt;我想具体问的是：在这种情况下，你觉得在研究过程中，有多大比例的时间，其实是被人与人之间沟通、对齐思路、传递和同步这些界限结果所消耗的？也就是说，为了在人类专家之间完成某种分布式计算，我们究竟付出了多大的沟通成本？&lt;/p&gt;&lt;p&gt;以及，如果你所设想的这一愿景真的实现了形式化、自动化工具能够承担起这些传递与整合工作，你认为这一领域的数学研究整体上有可能被加速多少倍？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我觉得确实如此。首先，这是一个信任问题。在这类计算密集的研究中，只要某一步出了错，整个推导就可能全部失效。因此，你&lt;strong&gt;必须清楚哪些作者是可靠的、哪些结果是可以放心使用的，而这些信息往往是隐性的，并不会明确写在论文里&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;现实中，我们不会公开列出哪些工作存在严重问题，于是你只能依赖对学术共同体的熟悉程度：你得知道这个圈子，知道该去问谁。很多时候，如果某个结果还没有正式发表，但你认识相关领域的专家，就可以直接去问他：这个地方是不是只需要稍微改一下就行？对方可能就会给你一个可靠的判断。&lt;/p&gt;&lt;p&gt;这就形成了一个明显的瓶颈：你必须身处这个关系网络之中，认识足够多对的人，才能高效地在这个领域工作。&lt;/p&gt;&lt;p&gt;而一旦我们能够通过形式化工具（比如 Lean）提供这种可验证的信任保证，情况就会发生根本改变。那时，&lt;strong&gt;你可以放心使用来自陌生研究者的结果，即便你从未见过他们，因为所有证明都已经由系统严格验证过&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;正是在这一点上，我认为&lt;strong&gt;形式化将会极大地解锁生产力，消除大量由于信任与沟通成本造成的阻塞，从而释放出此前被压抑的大量研究潜力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：是的，我明白你的意思。你刚才提到信任这个概念，其实在数学研究中，信任往往是通过长期积累的学术记录建立起来的。一个研究者在某个领域持续工作、不断产出成果，随着时间推移，其他人自然会越来越信任他的结论。&lt;/p&gt;&lt;p&gt;而真正让我开始对形式化和数学基础问题产生强烈兴趣的一个重要故事，正是关于一位数学家的经历。他曾经建立起极高的学术声誉，证明过许多非常了不起的结果，因此在学界拥有极强的可信度。&lt;/p&gt;&lt;p&gt;但在 20 世纪 90 年代末，他写过一篇论文，后来大约在十年之后，他才意识到其中存在一个关键性的错误。回过头来看，他自己也反思到：当时很多人之所以接受那篇结论，很大程度上是因为大家在相信他这个人，而不是因为证明本身被彻底、逐行地验证过。&lt;/p&gt;&lt;p&gt;而这正揭示了一个核心问题：个人声誉和过往记录，并不等同于真理的保证。这类经历也正是形式化证明与基础工具如此重要的原因之一，它们提供的不是基于人的信任，而是基于可验证结构的信任。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：当然，这种做法在深度上是有极限的。我们能够推动数学前进的程度，终究会受到限制。当前在分析学中，这个问题相对没那么严重，是因为这里逐渐形成了一张不断加密的信任之网，而且我们的工作方式往往更接近从第一性原理出发，比其他一些领域更少依赖远距离的结果。&lt;/p&gt;&lt;p&gt;但即便如此，这种基于信任的结构依然是数学发展的一个限制因素。从长远来看，这是一个无法回避的问题，也是形式化和基础工具之所以重要的又一个原因。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：我想再追问一个相关的问题。随着我们开始系统性地回溯并形式化一些经典论文，以及从 20 世纪 60 年代以来的大量文献，你会如何看待这样一个问题：&lt;/p&gt;&lt;p&gt;第一，在现有的数学文献中，可能还存在多少尚未被发现的错误？&lt;/p&gt;&lt;p&gt;第二，这些错误中，有多少只是可以通过小修小补解决的技术性问题？换句话说，整个数学体系作为一个整体，对这类错误究竟有多强的鲁棒性？&lt;/p&gt;&lt;p&gt;也就是说，即便我们真的通过形式化手段暴露出大量隐藏的问题，它们是否大多不会动摇理论的核心结构，而只是需要局部修正？还是说，其中也可能存在少量但影响深远的根本性漏洞？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：说实话，我也很想知道实际的错误率到底是多少。也许结果会让我们惊喜，也可能会让我们不太愉快。等六个月之后再来问我吧。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：今天这次交流真的非常愉快，真希望能再多聊一会儿。那就希望六个月之后，我们还能再进行一次这样的对话。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Sebastian Raschka万字年终复盘：2025，属于「推理模型」的一年</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:58:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fb81ab4c-43c5-47ad-a6bc-1be0d559462c/1767372891034.png" style="width: 700%;" class="fr-fic fr-dib"&gt;随着2025年的日历翻过最后一页，AI 领域再次证明了预测未来的难度。&lt;/p&gt;&lt;p&gt;在这一年，Scaling Law 并没有失效，但它的战场已经转移：从单纯的参数堆叠转向了推理侧的强化。DeepSeek R1 的横空出世，不仅打破了专有模型的神话，更让 RLVR 和 GRPO 算法成为了年度技术风向标。与此同时，我们在架构上看到了 MoE 与高效注意力机制的收敛，也在行业中目睹了「极限刷榜」带来的评估困境。&lt;/p&gt;&lt;p&gt;著名 AI 教育家与研究员 Sebastian Raschka 在他今年的年度总结中，以其一贯的「硬核工程视角」对 2025 年进行了全面复盘。从 DeepSeek 的成本经济学到推理模型的算法细节，从工具使用的演进到 AI 辅助编程的真实体验，Raschka 不仅梳理了技术脉络，还反思了人与 AI 的协作边界。&lt;/p&gt;&lt;p&gt;以下是 Sebastian Raschka 的博客原文：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LGfm3xFmTvoajA6OCRy19ia47jib2vmJGLicqiaRRGr1IRgqaBkOwWpMeIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4064814814814815" data-type="png" data-w="1080" data-width="1371" data-height="557" data-imgfileid="503526344" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e0dbd922-153f-4099-b22b-f3d7425d3c25/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="0 0 []"&gt;https://magazine.sebastianraschka.com/p/state-of-llms-2025&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;随着 2025 年接近尾声，我想回顾一下大语言模型（LLM）在本年度的一些最重要进展，反思现存的局限性和未解难题，并分享一些关于未来的想法。&lt;/p&gt;&lt;p&gt;正如我每年常说的那样，2025 年对于 LLM 和 AI 来说又是充满变数的一年，而且今年没有迹象表明这种进步正在饱和或放缓。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、推理之年：RLVR 与 GRPO&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想探讨的有趣话题很多，让我们按时间顺序从 2025 年 1 月开始说起。&lt;/p&gt;&lt;p&gt;Scaling 仍然有效，但它并没有真正改变 LLM 在实际应用中的表现或感觉（唯一的例外是 OpenAI 刚发布的 o1，它增加了推理轨迹）。因此，当 DeepSeek 在 2025 年 1 月发布 R1 论文，展示了类似推理的行为可以通过强化学习开发出来时，这意义非凡。（在 LLM 的语境下，推理意味着模型会解释其答案，而这种解释本身通常会带来答案准确性的提升。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lp4e3meiaLExm6gBeViavozaCaMdyRtxbvhKlAnvPY8aWia1lVwoe0gDZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9787037037037037" data-type="png" data-w="1080" data-width="1496" data-height="1464" data-imgfileid="503526345" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c7a7b942-af3e-440c-8ff2-db7d116b57ff/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：一个简短的回答和一个包含中间步骤的更长的回答，后者通常是推理模型生成的。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.1 DeepSeek 时刻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 因各种原因备受关注：&lt;/p&gt;&lt;p&gt;首先，DeepSeek R1 是作为开放权重模型发布的，其表现非常出色，足以媲美当时最好的专有模型（如 ChatGPT, Gemini 等）。&lt;/p&gt;&lt;p&gt;其次，DeepSeek R1 的论文促使许多人（尤其是投资者和记者）重新审视 2024 年 12 月发布的 DeepSeek V3 论文。这导致了一个修正后的结论：虽然训练最先进的模型仍然昂贵，但其成本可能比之前假设的低一个数量级，估计更接近 500 万美元，而不是 5000 万或 5 亿美元。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LhwBls2CmcZBdRcl9SRGiarXvicNvHicuEwnxyzJHwrXZniafNqsS4s6ibLA/640?wx_fmt=jpeg#imgIndex=3" data-ratio="0.18888888888888888" data-type="png" data-w="1080" data-width="1456" data-height="351" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5I76ibsxkINcEUXNtPYWYcXkfVsWMAHu2xS3NHiaqianfPFpUDIHjBCuA/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1456" data-cropy1="42.82352941176471" data-cropy2="317.3979238754326" data-imgfileid="503526346" data-aistatus="1" data-original-style="width: 578px;height: 109px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/35c9c5f4-a0ee-4ae7-971a-925272beec72/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：来自 DeepSeek V3 论文 的表格，估计训练 6710 亿参数 DeepSeek V3 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 的补充材料估计，在 DeepSeek V3 基础上训练 R1 模型的成本仅需额外的 29.4 万美元，这再次远低于所有人的预期。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LypJzibIqWMIibn7jhS6gXUEqMC3mHKJCPlBoN9AK9zJCQBhfGaDdCCFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.21203703703703702" data-type="png" data-w="1080" data-width="1358" data-height="288" data-imgfileid="503526348" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d993acdd-ee64-4cce-ad31-a8b16fac9840/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：来自 DeepSeek R1 论文补充材料的表格，估计在 DeepSeek V3 基础上训练 R1 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;当然，关于 500 万美元的估算有许多注意事项。例如，它仅涵盖了最终模型运行的算力信用成本，并未计入研究人员的薪水以及与超参数调整和实验相关的其他开发成本。&lt;/p&gt;&lt;p&gt;第三，也是最有趣的一点，该论文提出了带有可验证奖励的强化学习 (RLVR) 配合 GRPO 算法，作为一种新的（或至少是改进的）算法方法，用于开发所谓的推理模型并在后训练阶段改进 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LRTPlWqqflKSwPibDODO19NNYk5dmDOxSicQRzVnofHvZhc3C42lQbmcw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.875" data-type="png" data-w="1080" data-width="1456" data-height="1274" data-imgfileid="503526349" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f4f8531a-ed73-4938-8c52-a7ea832864cf/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4：强化学习应用的广泛概述及其时机。在这一概述中，我跳过了许多细节，但有兴趣的读者可以在我的《LLMs 推理的强化学习现状》一文中阅读更多内容。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在此之前，像监督指令微调 (SFT) 和基于人类反馈的强化学习 (RLHF) 这样的后训练方法（它们仍然是训练流程的重要组成部分）一直受限于昂贵的书面回复或偏好标签。（当然，人们也可以用其他 LLM 合成生成这些数据，但这有点像「先有鸡还是先有蛋」的问题。）&lt;/p&gt;&lt;p&gt;DeepSeek R1 和 RLVR 的重要性在于，它们允许我们在大量数据上对 LLM 进行后训练，这使它们成为通过在后训练期间扩展算力来改进和解锁能力的绝佳候选者（假设有可用的算力预算）。&lt;/p&gt;&lt;p&gt;RLVR 中的 V 代表「可验证」，意味着我们可以使用确定性方法来分配正确性标签，而这些标签足以让 LLM 学习复杂的问题解决能力。（典型的类别是数学和代码，但也有可能将此想法扩展到其他领域。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L8qmOyFvp2nZibke3IPXUx629WVtUMFHEbTtFzJNDlcYImjx79XVWA2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5361111111111111" data-type="png" data-w="1080" data-width="1082" data-height="580" data-imgfileid="503526350" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e6db5b0d-853f-4f20-96a2-30fc906a7fa1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图5：可验证奖励的一个简单示例。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我不想在这里过于纠结技术细节，因为我想在这篇年度回顾文章中涵盖其他方面。关于推理 LLM 和 RLVR，完全可以写整篇文章或整本书。例如，如果您有兴趣了解更多，可以查看我之前的文章。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上所述，结论是：今年的 LLM 发展本质上是由使用 RLVR 和 GRPO 的推理模型主导的。 基本上，继 DeepSeek R1 之后，每一个主要的开放权重或专有 LLM 开发商都发布了其模型的推理（通常称为「思考/Thinking」）变体。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.2 LLM 关注重点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我要简洁地总结每一年 LLM 开发的关注重点（除了单纯扩展架构和预训练算力之外），我的列表会是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2022: RLHF + PPO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2023: LoRA SFT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2024: 中期训练 (Mid-Training)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2025: RLVR + GRPO&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;预训练仍然是一切的必要基础。除此之外，RLHF（通过 PPO 算法）当然是早在 2022 年带来最初 ChatGPT 模型的功臣。&lt;/p&gt;&lt;p&gt;在 2023 年，重点大量集中在 LoRA 和类 LoRA 的参数高效微调技术上，用于训练小型自定义 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lb3le591ibg3TBNr3SsxooOTJu42nl8Lc9nulFDXquv80XvRzVskk4rA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.36018518518518516" data-type="png" data-w="1080" data-width="1456" data-height="524" data-imgfileid="503526351" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9488821f-174a-4165-a48f-4b6b461d8c6e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 6：近年来专有和开源权重 LLM 开发的一些关注领域。请注意，这是累积性的，意味着例如 RLHF + PPO 仍然相关且被使用。然而，它已不再是讨论的热点话题。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;接着，在 2024 年，所有主要实验室开始通过关注合成数据、优化数据混合、使用特定领域数据以及增加专门的长上下文训练阶段，使其（预）训练流程更加复杂。我在当时的 2024 年文章中总结了这些不同的方法（当时我将这些技术归类为预训练，因为「中期训练」这个术语当时还没被创造出来）：&lt;/p&gt;&lt;p&gt;当时，我认为这些是预训练技术，因为它们使用相同的预训练算法和目标。今天，这些紧随常规通用数据预训练之后的、稍微更专业化的预训练阶段，通常被称为「中期训练」（作为常规预训练和包括 SFT、RLHF 以及现在的 RLVR 在内的后训练之间的桥梁）。&lt;/p&gt;&lt;p&gt;那么，你可能会问，接下来是什么？&lt;/p&gt;&lt;p&gt;我认为明年我们会看到对 RLVR 的（更多）关注。目前，RLVR 主要应用于数学和代码领域。 下一个合乎逻辑的步骤是，不仅使用最终答案的正确性作为奖励信号，还要在 RLVR 训练期间评判 LLM 的解释。这在过去多年里一直以「过程奖励模型」的研究标签存在。然而，它尚未取得超级成功。例如，引用 DeepSeek R1 论文：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;4.2. 不成功的尝试 [...] 总之，虽然 PRM 展示了良好的能力来对模型生成的前 N 个响应进行重新排序或辅助引导搜索 (Snell et al., 2024)，但在我们的实验中，与其在大规模强化学习过程中引入的额外计算开销相比，其优势是有限的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;然而，看看上个月发布的最新 DeepSeekMath-V2 论文（我在之前的文章《从 DeepSeek V3 到 V3.2：架构、稀疏注意力和 RL 更新》中讨论过），我认为未来我们会看到更多将「解释评分」作为训练信号的做法。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://sebastianraschka.com/blog/2025/technical-deepseek.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前对解释进行评分的方法涉及第二个 LLM。这引出了我看到的 RLVR 的另一个方向：扩展到数学和代码以外的其他领域。&lt;/p&gt;&lt;p&gt;所以，如果你今天问我如果不展望 2026 年和 2027 年会看到什么，我会说：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2026: RLVR 的扩展和更多的推理时扩展&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2027: 持续学习&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了上述的 RLVR 扩展，我认为 2026 年将会有更多关注点放在推理时扩展上。推理时扩展意味着我们在训练后，让 LLM 生成答案时花费更多的时间和金钱，但其效果非常显著。&lt;/p&gt;&lt;p&gt;推理扩展并不是一个新的范式，LLM 平台已经在底层使用了某些技术。这是延迟、成本和响应准确性之间的权衡。然而，在某些应用中，准确性比延迟和成本更重要，极端的推理扩展完全是值得的。例如，正如最近的 DeepSeekV2-Math 论文所示，它将模型在具有挑战性的数学竞赛基准测试中的表现推向了金牌水平。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lgo4kxXoySblp3wm7ZrE6jXu78K1U8iaX6JllOCQctk68Lcw1qNrD0Mw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526352" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/079ab775-78ff-4af5-9402-9ec440e6d46b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 7：两种推理时扩展方法的结合：自一致性与自精炼。额外的自精炼迭代可以提高准确性。该图来自 DeepSeekMath-V2 论文。自一致性与自精炼在《从零构建推理模型》一书的第 4 章和第 5 章中有详细说明。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;今年同事之间也有很多关于持续学习的讨论。简而言之，持续学习是指在不从头开始重新训练的情况下，在数据或知识上训练模型。 这并非新想法，我也好奇为什么今年它被提及这么多次，因为目前在持续学习方面并没有任何新的或实质性的突破。&lt;/p&gt;&lt;p&gt;持续学习的挑战在于灾难性遗忘（正如持续预训练的实验所示，学习新知识意味着 LLM 在某种程度上正在遗忘旧知识）。 不过，既然这看起来是一个如此热门的话题，我确实期望在未来几年在最小化灾难性遗忘和使持续学习方法开发成为重要进展方面取得更多进步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、GRPO：年度研究宠儿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在昂贵的 LLM 时代，学术研究近年来一直颇具挑战性。当然，尽管（或者正因为）预算较少，学术界仍然可以做出重要的发现，并成为主流和 LLM 进步及突破的关键支柱。近年来的流行例子包括 LoRA（2021 年的大型语言模型低秩适应）及其相关的参数高效微调方法。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LA631P3NNEmRQdJYWhaANufgibNMduQNOORWIHjiamrUu4GYZmVMpUBrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8175925925925925" data-type="png" data-w="1080" data-width="1456" data-height="1190" data-imgfileid="503526353" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ae1ea1db-0f96-4f41-a2b2-0df356415252/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8：基于代码的 LoRA 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;另一个是 DPO（直接偏好优化：你的语言模型秘密地是一个奖励模型）及其相关的无奖励模型对齐方法，作为基于人类反馈的强化学习的替代方案。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L49PyWufJKTYcKleM4a242icoKynL9iangpUp1xpeLcthhibChbelZlycQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8518518518518519" data-type="png" data-w="1080" data-width="1456" data-height="1240" data-imgfileid="503526354" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c287f634-ddac-4a31-8834-33b92a91e666/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9：基于代码的 DPO 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在我的圈子里，今年的研究亮点是 GRPO。虽然它是在 DeepSeek R1 论文中介绍的，而非源自学术界，但它仍然让研究人员度过了令人兴奋的一年：RLVR 和 GRPO 在概念上都很有趣，而且根据规模不同，进行实验的成本并不令人望而却步。&lt;/p&gt;&lt;p&gt;因此，今年我在 LLM 研究文献中看到了许多对 GRPO 的数学改进（来自公司和学术研究人员），这些后来被采纳进了最先进 LLM 的训练流程中。例如，其中包括以下改进：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Olmo 3：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;零梯度信号过滤 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;主动采样 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Token 级损失 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无 KL 损失 (DAPO by Yu et al., 2025 和 Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Clip higher (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;截断重要性采样 (Yao et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无标准差归一化 (Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;DeepSeek V3.2：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;带有特定领域 KL 强度的 KL 调优（数学领域为零）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重新加权的 KL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Off-policy 序列掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留 top-p / top-k 的采样掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留原始 GRPO 优势归一化&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我可以确认，这些 GRPO 的技巧或修改在实践中具有巨大的影响。例如，采用了其中一些或多项修改后，糟糕的更新不再破坏我的训练运行，我也不再需要定期重新加载检查点。&lt;/p&gt;&lt;p&gt;即便是非常短的运行，我在采用这些技巧时也观察到了巨大的收益：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LG0z49N20icw8aZmCPlrg38v6b50RXiaia5icw5tZB2aISzTVlLYpY78o3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.28888888888888886" data-type="png" data-w="1080" data-width="1456" data-height="421" data-imgfileid="503526356" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/51928105-7550-4bb2-9271-f9f161b99223/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10：我从零开始的 GRPO 训练代码部分结果，该代码可在 GitHub 上获取&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;无论如何，如果你想尝试一下，我在「从头构建推理模型」的代码库中有一个原生 GRPO 脚本。（我很快会添加更多包含相应修改的消融研究。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、LLM 架构：岔路口？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说到 LLM 架构，最先进的模型仍然使用老式的解码器风格 Transformer。然而，今年，开放权重 LLM 或多或少都收敛于使用混合专家 (MoE) 层，以及至少一种「效率调整」的注意力机制：分组查询注意力 、滑动窗口注意力或多头潜在注意力。&lt;/p&gt;&lt;p&gt;除了这些相当标准的 LLM 架构外，我们还看到了针对注意力机制的更激进的效率调整，旨在随序列长度线性扩展。这方面的例子包括 Qwen3-Next 和 Kimi Linear 中的 Gated DeltaNets，以及 NVIDIA Nemotron 3 中的 Mamba-2 层。&lt;/p&gt;&lt;p&gt;无论如何，我不想在这里深入太多细节，因为如果您想了解更多，我有一篇完整的 1.3 万字且最近更新的文章专门讨论这些架构：大型 LLM 架构比较&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LDjr3AVbCichiclibbibn5UjjYP6EAtjtPmkjo1IF8JyuLxgwS32BhhWolw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="1.3712962962962962" data-type="png" data-w="1080" data-width="1167" data-height="1600" data-imgfileid="503526357" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/a31ab06a-5774-46c5-af13-be1d9b417128/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 11：大型 LLM 架构对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我的预测是，我们将继续基于 Transformer 架构构建至少几年，至少在最先进的建模性能方面是这样。 同时，我确实认为我们会看到越来越多像 Gated DeltaNet 和 Mamba 层这样的效率和工程调整，因为在 LLM 训练、部署和使用的规模下，从财务角度来看，这对那些仍在为服务 LLM 烧钱的公司来说是有意义的。&lt;/p&gt;&lt;p&gt;这并不意味着没有其他替代方案。正如我在《超越标准 LLM》中所写，文本扩散模型是一种有趣的方法。目前，它们属于实验性研究模型类别，但 Google 分享说他们将发布 Gemini Diffusion 模型。它在建模质量上不会与其最先进的产品相抗衡，但对于低延迟要求的任务（如代码补全），它将非常快且具吸引力。&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，两周前，开放权重的 LLaDA 2.0 模型发布了。其中最大的一个拥有 1000 亿参数，是迄今为止最大的文本扩散模型，与 Qwen3 30B 相当。（是的，它并没有推动整体的最先进水平，但在扩散模型领域仍是一个值得注意的版本。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、这也是推理扩展和工具使用的一年&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过扩展训练数据和架构来改进 LLM 是一个既定公式，且（仍然）持续奏效。然而，特别是在今年，这已不再是「唯一」足够的秘诀。 我们在 GPT 4.5（2025 年 2 月）上看到了这一点，据传它比 GPT 4（以及后来发布的 GPT 5）大得多，但单纯的Scaling 通常不是最明智的前进方式。GPT 4.5 的能力可能比 GPT 4 更好，但增加的训练预算被认为是「性价比低」。&lt;/p&gt;&lt;p&gt;相反，更好的训练流程（更加关注中期和后训练）和推理扩展推动了今年的大部分进步。 例如，如前所述，在谈论达到金牌级数学表现的 DeepSeekMath-V2 时，推理扩展是我们可以利用的杠杆之一，让 LLM 按需解决极其复杂的任务（GPT Heavy Thinking or Pro 是其他例子；由于高延迟和成本，将这些用于所有事情是没有意义的，但在某些例子中，如具有挑战性的数学或编码问题，高强度的推理扩展是有意义的。）&lt;/p&gt;&lt;p&gt;另一个重大改进来自以工具使用为核心的 LLM 训练。如您所知，幻觉是 LLM 最大的问题之一。可以说，幻觉率一直在改善，我认为这很大程度上归功于上述的工具使用。例如，当被问及谁赢得了 1998 年 FIFA 世界杯时，LLM 不再尝试死记硬背，而是可以通过工具使用传统的搜索引擎，并从该主题的可信网站（例如本例中的 FIFA 官方网站）选择和抓取此信息。数学问题也是如此，使用计算器 API 等等。&lt;/p&gt;&lt;p&gt;例如，OpenAI 的 gpt-oss 模型是今年发布的早期开放权重模型之一，其开发时就特别考虑了工具使用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LElNRkjgywwZAA1LZxvDhyIvBQw9zicricPN0VYq3nDwEa9ukJe8r91Dg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.7416666666666667" data-type="png" data-w="1080" data-width="1456" data-height="1080" data-imgfileid="503526358" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/35d51828-d87b-490a-8483-b0d8b0178702/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 12：来自 gpt-oss 模型卡片论文的注释表格.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;遗憾的是，开源生态系统尚未完全赶上，许多（如果不是大多数）工具仍然默认在非工具使用模式下运行这些 LLM。一个原因是这是一个较新的、不断发展的范式，工具需要适应。另一个原因也是这是一个更难解决的问题，出于安全考虑（给予 LLM 无限制的工具使用访问权限可能会带来潜在的安全风险或对系统造成其他形式的破坏。我认为应该始终问的一个明智问题是：你会信任一个新实习生拥有这种级别的系统访问权限来做这件事吗？）&lt;/p&gt;&lt;p&gt;我确实认为，在未来几年，当在本地使用 LLM 时，启用和允许工具使用将变得越来越普遍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、年度词汇：Benchmaxxing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我必须选一个词或趋势来描述今年的 LLM 发展，那将是「极限刷榜 (Benchmaxxing)」。 在这里，Benchmaxxing 意味着过度关注推高排行榜的分数，有时甚至到了基准测试表现本身成为目标，而不是作为通用能力的代理指标的地步。&lt;/p&gt;&lt;p&gt;一个突出的例子是 Llama 4，它在许多既定基准测试中得分极高。然而，一旦用户和开发者上手使用，他们就意识到这些分数并不能反映真实世界的能力和实用性。 正如那句流行语所说，如果测试集是公开的，它就不是真正的测试集。而如今的问题是，测试集数据不仅（有意或无意地）是训练语料库的一部分，而且在 LLM 开发过程中经常被直接优化。&lt;/p&gt;&lt;p&gt;过去，即使公共测试集的基准分数虚高，至少模型排名仍然保持不变。例如，参见下方 2019 年论文《ImageNet 分类器能泛化到 ImageNet 吗？》中的注释图。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LQiaIscKgRkvX6XoNzlyy7Buqfp4Im1F3G3Jsibm0y8df3xZD2SxCWsRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6351851851851852" data-type="png" data-w="1080" data-width="1388" data-height="882" data-imgfileid="503526359" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/9fbf55b9-b295-43d6-acc8-069df620e25a/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 13：来自 2019 年论文《Do ImageNet Classifiers Generalize to ImageNet?》的标注图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 LLM 开发中，这已经到了基准数字不再是值得信赖的 LLM 性能指标的地步。 然而，我确实认为基准测试仍然是 LLM 必须跨越的必要门槛。即，如果我看到一个 LLM 在基准 Y 上的得分低于 X，我就已经知道它不是一个好的 LLM。然而，如果它在基准 Y 上的得分高于 X，这并不意味着它比另一个在同一基准上得分高于 X 的 LLM 好多少。&lt;/p&gt;&lt;p&gt;另一个需要考虑的方面是，图像分类器只有一个工作，即分类图像。然而，LLM 用于许多不同的任务：翻译文本、总结文本、编写代码、头脑风暴、解决数学问题等等。评估图像分类器（有明确的指标如分类准确率）比评估 LLM 在确定性和自由形式任务上的表现要简单得多。&lt;/p&gt;&lt;p&gt;除了在实践中尝试 LLM 并不断生成新的基准测试外，遗憾的是，这个问题没有解决方案。 顺便说一句，如果你好奇了解 LLM 评估的主要类别，你可能会喜欢我的文章《从头理解 LLM 评估的 4 种主要方法》。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、AI 用于编码、写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然这个问题经常出现，我想分享一下我对 LLM 取代人类进行某些类型任务（甚至工作）的看法。 从高层次来看，我将 LLM 视为赋予某些职业的人们「超能力」的工具。我的意思是，当 LLM 被用好时，它们可以使个人效率大幅提高，并消除日常工作中的许多摩擦。这范围从相对平凡的任务（如确保章节标题的大小写一致）到在大型代码库中查找复杂的错误。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.1 编码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，我仍然自己编写大部分我关心的代码。「我关心的」是指在那些我理解代码且代码正确性至关重要的上下文中。例如，如果我设置一个 LLM 训练脚本，我会实现并仔细检查训练逻辑。这是为了 a) 确保它在做我认为它应该做的事情，以及 b) 保留我在该任务中的知识和专业技能。然而，我现在使用 LLM 来添加周围更平凡的代码，例如添加命令行 argparse 样板代码，以便我可以更方便地从命令行使用我自己的代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LMWf8Vp5AoXZKpSbGtVlHVVHJNFOg0qFNZDJJSx8PTz0zGAaox7KTHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.6666666666666667" data-type="png" data-w="960" data-width="960" data-height="1600" data-imgfileid="503526360" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/950d2605-f1a7-4ce2-bdcc-feb90ce3cf4b/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 14：使用提示「为 training-script.py 添加 argparse 以支持所有超参数选项」向训练脚本添加命令行参数的例子。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但我也越来越多地依靠 LLM 来发现问题、建议改进或对想法进行健全性检查。同时，我想了解我正在构建什么，作为个人目标，我旨在加深我的知识和技能，并继续增长我的专业知识。&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，LLM 对于我核心专业知识之外的任务非常有价值。它们让我自动化了一些我本来没有时间或精力去处理的事情。一个例子是我最近写的一个工具，用于将我的 Substack 文章提取并备份为 Markdown。（我在 Markdown 中起草所有内容，但我经常直接在 Substack 编辑器中编辑和扩充文章，所以我的本地草稿并不总是最新的）。LLM 还帮助我清理了网站上的 CSS，这些 CSS 积累了多年的重复和不一致。今年有很多类似的案例我使用了 LLM。&amp;nbsp;&lt;/p&gt;&lt;p&gt;简而言之，我认为这里的诀窍是识别何时使用以及何时不使用 LLM。以及如何以一种有助于你增长专业知识同时也令人感到满足的方式使用 LLM。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.2 代码库和代码库&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 在编写代码方面变得更好了，但尽管我听到其他人这么说，我不认为代码是或将变得短暂或过时。LLM 赋予人们超能力来生成某些编码项目，这些项目如果由他们自己创建，将需要大量精力。 然而，纯粹由 LLM 生成的代码库并不能取代专家精心制作的代码库。这些专家代码库甚至可能是由人类编码员自己使用 LLM 创建的。但关键点在于，该领域的专家投入了大量时间和精力来创建、测试和完善它。其他人要复制它需要大量工作，所以如果它存在，为什么不采用它呢？&lt;/p&gt;&lt;p&gt;简而言之，我认为一个学习了良好设计模式和权衡取舍、并在职业生涯中研究、见过并构建了许多平台的专家全栈 Web 开发人员，将能够构建比一个随机提示 LLM 构建平台的人更好的平台。 很棒的是，一个随机的人现在可以构建一个平台，即使它不是最好的。然而，使用和提示 LLM 只能让那个人走这么远，平台的质量可能会停滞不前。因此，如果这个人真的关心改进平台，深入研究这里，学习其他人如何构建平台，并带着更多的知识回来更有效地使用 LLM 来指导和改进平台设计，将是一个好主意。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.3 技术写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与编码类似，我不认为 LLM 会使技术写作过时。写一本好的技术书籍需要数千小时和对主题的深刻熟悉。这个过程可能涉及 LLM 来提高清晰度、检查技术正确性、探索替代方案或运行小型实验，但核心工作仍然取决于人类的判断和专业知识。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lv2KFlI8vykxJPX6QTmGefhUaV8rvib3T4k5Q4vvAoWfjS320znibjf7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="1.499531396438613" data-type="png" data-w="1067" data-width="1067" data-height="1600" data-imgfileid="503526362" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/7b4a580c-7dbf-43cb-aacf-4fd2da543603/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp;图 15：一个非分阶段的例子，其中 LLM 只是帮助我找到并修复了前一篇文章中的错误。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;是的，LLM 可以让技术书籍变得更好。它们可以帮助作者发现错误、扩充参考文献，并通常减少花在平凡任务上的时间。这释放了更多时间用于真正需要创造力和经验的深度工作。&amp;nbsp;&lt;/p&gt;&lt;p&gt;从读者的角度来看，我也不认为 LLM 取代了技术写作。使用 LLM 了解一个主题对于快速提问和初学者级别的解释非常有效。然而，当你想要建立更深层次的理解时，这种方法很快就会变得混乱。&lt;/p&gt;&lt;p&gt;在那一点上，与其可能浪费数小时自己试图过滤 LLM 关于你试图学习但（尚）不是专家的主题的回复，通常遵循专家设计的结构化学习路径更有意义。（专家可能使用了也可能没有使用 LLM。）&lt;/p&gt;&lt;p&gt;当然，在参加课程或从书中学习时，使用 LLM 来澄清问题或探索旁支路径仍然非常有意义。让它设计测验或练习来实践知识也很棒。&lt;/p&gt;&lt;p&gt;总的来说，我认为 LLM 对作者和读者来说都是净收益。 但我也认为这里的诀窍是学会识别何时使用以及何时不使用 LLM。例如，主要的缺点是，当一个话题变得困难时，人们很容易立即使用 LLM，因为先自己努力解决问题通常会带来更强的学习效果。&lt;/p&gt;&lt;p&gt;我看待研究的方式也差不多。LLM 对于查找相关文献、发现数学符号中的问题和建议后续实验非常有用。但让一位人类研究员坐在驾驶座上仍然是有意义的。 也许这里的经验法则是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书完全由人类生成，它可能还有进一步改进的空间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书可以通过仅仅提示 LLM 生成，那么它可能不够新颖和/或不够深刻。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;6.4 LLM 与职业倦怠&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 仍然相当新且在不断发展，我认为过度使用 LLM 也有一个较少讨论的缺点。例如，我认为如果模型做了所有的操作，而人类主要是在监督，工作可能会开始让人感到空虚。&lt;/p&gt;&lt;p&gt;当然，有些人真的喜欢专注于管理系统和编排工作流程，这是一个完全有效的偏好。但对于那些喜欢亲手做事的人来说，我认为这种工作模式可能会加速职业倦怠。（这对于那些期望因为有了 LLM 而能更快获得更多结果的公司来说尤其如此。）&lt;/p&gt;&lt;p&gt;与难题搏斗并最终看到它成功，有一种特别的满足感。当 LLM 一次性搞定解决方案时，我没有同样的感觉。我想这类似于烹饪（这只是我想到的，我不是一个好厨师）。如果你喜欢做披萨，使用预制的面团只加配料可能会消除很多乐趣，烹饪变成了达到目的的手段。这不一定是坏事，但我认为如果你在较长一段时间内（几个月或几年）每天做很多小时这样的工作，我能看到它会让人感到空虚并最终导致倦怠。 所以，一个自私的观点是写代码也比读代码更有趣。你可能会同意，创建 Pull Request 通常比审查它们更有趣（当然，这对每个人来说并不都是真的）。&lt;/p&gt;&lt;p&gt;也许一个很好的、理想化的（但并非完美的）类比，说明我们应该如何以可持续的方式使用 AI，就是国际象棋。&amp;nbsp;&lt;/p&gt;&lt;p&gt;国际象棋引擎在几十年前就超越了人类棋手，但人类进行的职业国际象棋仍然活跃且繁荣。我不是国际象棋专家，但我觉得这项游戏可能甚至变得更加丰富和有趣了。&lt;/p&gt;&lt;p&gt;根据我听到的（例如，基于 Kasparov 的《Deep Thinking》一书和以 Magnus Carlsen 为特色的播客），现代棋手一直在使用 AI 来探索不同的想法，挑战他们的直觉，并以前所未有的深度分析错误。&lt;/p&gt;&lt;p&gt;我认为这是一个有用的模型，可以用来思考智力工作其他形式中的 AI。如果用得好，AI 可以加速学习并扩展一个人可以合理承担的工作。我认为我们应该更多地把它视为合作伙伴而不是替代品。 但我也认为，如果 AI 被用来完全外包思考和编码，它就有可能破坏动力和长期技能发展。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LJmeDUugQnicvCtHxDPr3g1edcTd9R4AXG7qUsaziariaFjqD8mNrUC7Ew/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526363" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/033a26a8-67d5-4a5b-bf2d-7d9b1ba1e8a0/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 16：LLMs 降低了入门门槛，使程序员（无论是初学者还是专家）更加高效。然而，在我们即将结束 2025 年之际，我认为仍然值得投资成为专家，因为这样你将能从 LLMs 中获得更多的价值，并能够交付更出色的结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7、优势：私有数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 的通用编码、知识问答和写作能力在不断提高。这很大程度上是因为由于训练流程和范式（例如 RLVR）以及推理扩展和工具使用的改进，Scaling 仍然提供了正向的投资回报。&lt;/p&gt;&lt;p&gt;然而，这将在某个时刻开始趋于平稳（类似于我们在 GPT 4 到 GPT 4.5 开发中看到的），除非我们继续发明新的训练方法和/或架构（目前，还没有人知道这些可能是什么样子的）。&lt;/p&gt;&lt;p&gt;LLM 目前能够解决许多通用任务和低垂的果实。但要将它们确立在某些行业中，就需要更多的领域专业化。我认为 LLM 提供商会很乐意获得高质量的、特定领域的数据。目前看来，这将是一个挑战。&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，似乎大多数接触过的公司都拒绝了此类交易，恰恰是因为数据是专有的并且是其业务差异化的核心。（我从多个来源听到了这一点，还有一篇关于此主题的 The Information 文章。）&amp;nbsp;&lt;/p&gt;&lt;p&gt;在我看来，这完全说得通。我认为将有价值的专有数据（有一天可能会给公司带来优势）卖给 OpenAI 或 Anthropic 可能有点短视。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LPxp0fnU6IHnWXZEvkMUb3JNsLOvUebib7DibTchs39GH8ylYymtpyLPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.45092592592592595" data-type="png" data-w="1080" data-width="1456" data-height="657" data-imgfileid="503526364" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/31132ae5-d478-424b-9a69-6caa2846fcd2/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 17：可用于训练领域专用 LLMs 的数据领域和类型示例，但在这些情况下将数据出售给外部方可能会引起担忧。(我不是法律专家，这也不构成法律建议，但我可以想象，如果是一个纯本地的 LLM，不会离开公司的安全服务器，那么在患者健康数据上训练模型与开发其他使用该患者健康数据的内部软件并无不同。)&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;目前，LLM 开发在大规模上极其昂贵且具有挑战性，这就是为什么只有少数大公司开发最先进的 LLM。然而，我认为 LLM 开发正变得越来越商品化，因为 LLM 开发者频繁在雇主之间轮换，最终将被更大的金融机构、生物技术公司和其他有预算开发利用其私有数据的具有竞争力的内部 LLM 的公司聘用。&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些 LLM 甚至不必完全从头开始训练；许多最先进的 LLM 如 DeepSeek V3.2、Kimi K2 和 GLM 4.7 正在发布，可以进行调整和进一步的后训练。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8、从头构建 LLM 和推理模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你可能想知道我今年都在忙些什么。我的重心几乎完全放在了 LLM 相关的工作上。去年，我决定成为一名独立人士并创办了自己的公司，主要是为了有更多时间从事我自己的研究、书籍撰写、Substack 写作以及行业合作。&lt;/p&gt;&lt;p&gt;作为一名独立研究员，咨询项目是维持这种工作模式可持续的一部分。这不仅涵盖了日常开销（从食品杂货到健康保险），还包括一些不太显眼的成本，比如用于上述实验的云端算力费用。&lt;/p&gt;&lt;p&gt;随着时间的推移，我的目标是进一步减少咨询工作，将更多时间花在长篇研究和写作上，特别是我在这里分享的技术深度文章。&lt;/p&gt;&lt;p&gt;我很幸运，许多公司都联系我提供全职职位。如果独立这条路走不通，那将是一个可行的选择，但目前，我计划保持独立。&lt;/p&gt;&lt;p&gt;如果你觉得我的工作有用，并且在能力范围内，订阅我的 Substack 或购买我的一本书，确实有助于使这类工作变得可持续，我真心感谢大家的支持。&lt;/p&gt;&lt;p&gt;今年我的个人高光时刻之一是收到了关于我的书《从头构建大语言模型》 (Build A Large Language Model (From Scratch))的积极反馈。我收到了来自世界各地公司和大学读者的许多深思熟虑的留言。&lt;/p&gt;&lt;p&gt;这些反馈涵盖了广泛的用例：从大学教授将其作为主要教科书来教授 LLM 原理，到前学生用它准备面试并获得新职位，再到工程师依靠它作为在生产环境中实施自定义 LLM 的踏板。&lt;/p&gt;&lt;p&gt;得知这本书现在已经被翻译成至少九种语言，我也感到非常兴奋。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LXnVK0ap4icfhKtB43uZFxpWSicSRr3NUjdjAibrrRnu61WdnOFWoXU8LQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.7694444444444445" data-type="png" data-w="1080" data-width="1456" data-height="1120" data-imgfileid="503526365" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/b42684b8-231a-4273-b0d9-702e56a9d75c/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 18：构建一个大型语言模型（从头开始）翻译成不同语言。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;许多读者还问是否会有第二版，涵盖更新、更高级的主题。虽然我也考虑过这一点，但我对降低这本书的易读性持谨慎态度。例如，用更复杂的变体（如一些较新的 DeepSeek 模型中使用的多头潜在注意力）来替换标准的多头注意力，会大大提高准入门槛。&lt;/p&gt;&lt;p&gt;相反，目前我倾向于保持这本书的原样，因为它非常适合那些想入门 LLM 的人。对于对更高级材料感兴趣的读者，作为后续，我在这一年中向该书的 GitHub 代码库添加了大量的补充材料。我计划随着时间的推移继续扩展这些材料。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LHWmph5p8XvASuoIFxeQ3ZGjACkW5KnHMlGX1y4yq4gu2CwC0FiaxSZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="1.3546296296296296" data-type="png" data-w="1080" data-width="1178" data-height="1596" data-imgfileid="503526366" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/c0f2302c-4fda-4dc6-876c-1b2b25f6a5b4/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 19：我今年为《从零构建大型语言模型》（From Scratch）仓库添加的一些附加内容摘录。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，正如你可能知道的，我目前正在撰写续作《从头构建推理模型》。&lt;/p&gt;&lt;p&gt;第一本书《从头构建大语言模型》侧重于核心的大语言模型架构和预训练的基础知识。&lt;/p&gt;&lt;p&gt;[图片]&lt;/p&gt;&lt;p&gt;&lt;sup&gt;图 20：展示这两本从零开始的书籍如何相互关联的示意图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这本关于推理模型的书则紧接第一本书的内容。它从一个预训练好的基础模型开始，探索专门旨在提高推理能力的推理时扩展方法和强化学习技术。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LaNVxIytDmkdu3lwIcibBj66lUeicfHV7x21PyHayGMRhibBUowe1zbbqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.8203703703703704" data-type="png" data-w="1080" data-width="1456" data-height="1194" data-imgfileid="503526369" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/e3300f54-90ce-498d-b483-94878212d1c3/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 21：《从零构建推理模型》（早期访问版）的摘录.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;除了这个 Substack 博客，我正在努力撰写这本关于推理的书。在许多方面，我认为这是我迄今为止构思最周密、打磨最精细的一本书。&lt;/p&gt;&lt;p&gt;目前，我估计每一章大约花费 75-120 小时。如果你好奇的话，我估计具体的时间分配通常如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;3-5 小时： 头脑风暴和修改选题&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 构建内容结构&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;20 小时： 编写初始代码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 运行额外实验并阅读最新文献以获取更多见解&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 制作图表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10 小时： 撰写初稿文本&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 重写和润色章节&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 制作练习题加上运行实验&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2-5 小时： 整合编辑和读者的建议&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前，我已经完成了第 6 章的一半，该章实现了用于训练推理模型的带有可验证奖励的强化学习代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LeiasrFI3kzZxIA9LPtzq8hzI7I8iaInogJ2qEX3icsPDaGFveKgQLjfBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.7101851851851851" data-type="png" data-w="1080" data-width="1456" data-height="1034" data-imgfileid="503526370" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/297e6a06-c7f1-4a4a-b835-2b5e67110876/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 22：第 6 章和第 7 章中关于可验证奖励的强化学习实验的初步结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;《从头构建推理模型》是一项非常艰巨的工作，但我完全乐在其中！我希望你和其他读者会发现它像《从头构建大语言模型》一样有用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9、2025 年的惊喜与 2026 年的预测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想用一些主要的收获来结束这篇文章，重点关注我认为对我来说有点令人惊讶的事情，以及我对 2026 年的预测。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9.1 2025 年值得注意和令人惊讶的事情&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;让我们从 2025 年的惊喜开始。如果你在 2024 年早些时候问我，这些可能是我没想到的发展：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;几个推理模型已经在主要数学竞赛中达到金牌级表现（OpenAI 的一个未命名模型、Gemini Deep Think 和开放权重的 DeepSeekMath-V2）。我对这种事情的发生并不感到惊讶，但我很惊讶这在 2025 年就已经发生了，而不是 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Llama 4（或一般的 Llama）在开放权重社区中几乎完全失宠，Qwen 在受欢迎程度上已经超过了 Llama（根据 Nathan Lambert 的 ATOM 项目报告的下载量和衍生品数量衡量）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Mistral AI 在 2025 年 12 月宣布的最新旗舰 Mistral 3 模型使用了 DeepSeek V3 架构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;除了 Qwen3 和 DeepSeek R1/V3.2 之外，许多额外的竞争者出现在最先进开放权重模型的竞赛中，包括 Kimi、GLM、MiniMax 和 Yi。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更便宜、高效的混合架构已经成为领先实验室的更大优先事项（Qwen3-Next、Kimi Linear、Nemotron 3），而不是由单独的实验室开发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;OpenAI 发布了一个开放权重模型（gpt-oss，我今年早些时候写了一篇关于它的独立文章）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MCP（加入 Linux 基金会）已经成为代理式 LLM 系统中工具和数据访问的标准（目前）；我原本预计生态系统在 2025 年会保持更加碎片化，直到至少 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;9.2 2026 年预测&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们可能会看到一个工业规模、面向消费者的扩散模型，用于廉价、可靠、低延迟的推理，Gemini Diffusion 可能会率先推出。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开放权重社区将缓慢但稳定地采用具有本地工具使用和日益增强的代理能力的 LLM。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;RLVR 将更广泛地扩展到数学和编码以外的其他领域（例如化学、生物学等）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;经典的 RAG 将慢慢淡出作为文档查询的默认解决方案。与其在每个文档相关的查询上使用检索，开发人员将更多地依赖更好的长上下文处理，特别是随着将会有更好的「小型」开放权重模型出现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大量的 LLM 基准测试和性能进步将来自于改进的工具和推理时扩展，而不是来自于训练或核心模型本身。看起来 LLM 正在变得更好，但这主要是因为周围的应用正在改进。同时，开发人员将更多地专注于降低延迟，并使推理模型在不必要时减少推理 Token 的消耗。别误会，2026 年将进一步推动最先进水平，但今年的进步比例将更多地来自推理端，而不仅仅是训练端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后总结，我认为如果说 2025 年有一个元教训，那就是 LLM 的进步不再是关于单一的突破，而是通过多个独立的杠杆在多条战线上进行改进。这包括架构调整、数据质量改进、推理训练、推理扩展、工具调用等等。 同时，评估仍然很困难，基准测试是不完美的，关于何时以及如何使用这些系统的良好判断仍然至关重要。&lt;/p&gt;&lt;p&gt;我希望 2026 年我们继续看到有趣的改进，但也希望我们了解改进来自何处。这既需要更好和更一致的基准测试，当然也需要透明度。&lt;/p&gt;&lt;p&gt;谢谢阅读！&lt;/p&gt;&lt;p&gt;Cheers, Sebastian&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5beSNXduviaPh5O08SOVvMAEOVUiaZqfrDN74M5rqYia6YE0L3ibDeiaSXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1456" data-height="970" data-imgfileid="503526372" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/cfed2d35-1bfa-4b46-add0-e3c5b0e2cefc/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;附赠：LLM 研究论文精选列表（2025 年 7 月至 12 月）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今年 6 月，我曾分享了一篇附赠文章，其中包含了我为付费订阅者（是你们让这个 Substack 博客得以维持）精心挑选并收藏的研究论文列表。&lt;/p&gt;&lt;p&gt;以同样的方式，作为对所有好心支持者的感谢，我在下面准备了一份列表，列出了我在 2025 年 7 月至 12 月期间收藏并归类的所有有趣的研究文章。我略读了这些论文的摘要，但只详细阅读了其中很小的一部分。不过，我仍然喜欢不断收集这些有条理的列表，因为在进行特定项目时，我经常会回过头来查阅其中的某一组论文。&lt;/p&gt;&lt;p&gt;然而，鉴于目前这篇文章的篇幅已经非常巨大，我将这份列表分享在一篇单独的文章中，链接如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>KAN作者刘子鸣：AI还没等到它的「牛顿」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:45:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1c023bee-dd43-4080-8124-a33dfa63ca35/1767372187912.png" style="width: 700%;" class="fr-fic fr-dib"&gt;大家新年快乐！今天和大家分享 KAN 作者刘子鸣最新发布的一篇博客。&lt;/p&gt;&lt;p&gt;过去的一年，我们见证了 Scaling Laws 持续发力，模型能力不断刷新天花板。虽然 AI 社区从未停止对可解释性的探索，但在工程进展如此迅猛的当下，我们对模型内部机制的理解，似乎总是慢了半拍。&lt;/p&gt;&lt;p&gt;刘子鸣在博客中，借用科学史提出了一个发人深省的观点：如果参照物理学的发展史，&lt;strong&gt;今天的 AI 可能还远未在这个时代的「牛顿力学」时刻，而是仍处于「第谷（Tycho）时代」&lt;/strong&gt;，一个拥有大量观测和实验，却尚未来得及系统性总结规律的早期阶段。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526556" data-ratio="1.0787037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVydCiaASeS1zapMI5GD3fd59tlyBCbNQfbbrCiaaw9888j9thmPRNibJJPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3ece9a6d-fcae-45cb-b21a-ced28a27fb4c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们拥有海量的实验数据和强大的模型，却缺乏对底层现象的系统性梳理。他指出，为了追求短期性能指标，AI 领域跳过了「理解」这一关键步骤，这实际上是在背负高昂的「认知债务」。&lt;/p&gt;&lt;p&gt;更为矛盾的是，当前的学术发表机制往往偏爱「完美的故事」或「巨大的性能提升」，导致大量像「第谷的观测记录」那样碎片化但极具价值的「AI 现象学」工作被忽视。&lt;/p&gt;&lt;p&gt;为此，刘子鸣呼吁建立一种「平易近人的现象学」：&lt;strong&gt;不以即时应用为导向，回归到用 Toy Model（玩具模型）进行可控的、多视角的假设驱动探索&lt;/strong&gt;。他宣布将身体力行，通过博客分享「半成品」的实验笔记，并计划在清华大学开设相关课程，邀请社区共同偿还这笔认知债务，推动 AI 从「炼丹」走向真正的物理学。&lt;/p&gt;&lt;p&gt;明星数据科学家 Jeremy Howard 也在评论区表示赞同，长期以来「实验性观察」几乎无法在 AI/ML 期刊和会议上发表，这种现象无疑阻碍了该领域的发展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyfwV2mmL3HK0JibYYJZPjnSVFomHx9k2gDIk8Tasyk1nwxYMDaGR8bng/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526557" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e2b0f798-3a38-431c-aa7a-15f6138ecbef/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 物理学需要思维模式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大家都知道，物理学领域主要沿着「第谷 &amp;mdash; 开普勒 &amp;mdash; 牛顿」这一科研范式发展，而如果借用这一类比来理解 AI 的发展阶段，那么&lt;strong&gt;今天的 AI 研究很大程度上仍然停留在「第谷阶段」，即以「实验与观察」为主的阶段&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;但即便是在「观察」这一层面，业界目前所做的事情也极其原始：大多数人关注的仍然只是少数几个基于性能的指标调优。这背后，源于物理学与 AI 在目标上的根本差异。&lt;/p&gt;&lt;p&gt;物理学的目标是通过「理解世界来改变世界」，其中「理解」本身占据着核心地位。因此，这个领域对那些能够提供洞见即便（暂时）没有实际用途的工作，也具有极高的容忍度。&lt;/p&gt;&lt;p&gt;相比之下，AI 的目标则是「直接改变世界」，近些年 Scaling Laws 的盛行使得整个领域得以跳过「理解」这一阶段，直接进入对 AI 本身进行改造和强化。但这似乎构成了一种&lt;strong&gt;认知债务（cognitive debt）&amp;mdash;&amp;mdash; 这种债务迟早是要偿还的，如果不是现在，那也会是在未来&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，现在就谈论 AI 的「牛顿力学」阶段还为时过早，即使是在基础现象学层面，仍处于非常早期的阶段。AI 的现象学可以是相对宏观的 &amp;mdash;&amp;mdash; 连接不同的模型，例如涌现与 Scaling laws，也可以更微观 &amp;mdash;&amp;mdash; 聚焦于训练动态，例如 Grokking、双下降（double descent）或稳定性边缘（edge of stability）&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;我们首先需要发现更多现象，只有这样，我们才会有动力去建立模型，并发展理论来研究它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么 AI 现象学如此难以发展？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么 AI 现象学的发展如此困难？一个原因是&lt;strong&gt;论文发表文化在其中扮演了重要角色&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;总结来看，当前可发表的工作往往只有两类：在性能上有显著提升的工作（在这种情况下，现象学似乎「没有必要」），或者拥有一个足够吸引人的「故事」。&lt;/p&gt;&lt;p&gt;而所谓「好故事」，通常有两种形式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;普适性（Universality）&lt;/strong&gt;：该现象必须在大量不同设定中都能被验证，稳定性边缘（edge of stability）就是一个例子。但这类工作对投稿的要求极高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;惊奇性（Surprise）&lt;/strong&gt;：现象必须足够反直觉、足够出人意料。这种情况非常罕见，也高度不可预测，grokking 就是代表性案例。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这也解释了为什么 AI 领域中被反复引用的现象学例子如此之少。在「AI 物理学」仍处于如此早期阶段的情况下，却对现象学提出了过高的期望，反而抑制了它的发展。&lt;/p&gt;&lt;p&gt;朱泽园所写的《大语言模型的物理学》是一项非常出色的工作，但从我与朋友们的交流来看，大家普遍的感受是：这很有意思，但不知道如果自己想进入这个领域，该从哪里开始。&lt;/p&gt;&lt;p&gt;同样的情况也出现在我们自己的工作《叠加导致稳健的神经缩放》《 Superposition Leads to Robust Neural Scaling》中。很多人好奇这样的「故事」是如何被构思出来的。&lt;/p&gt;&lt;p&gt;我无法代表整个 AI 物理学领域的整个研究群体，但从个人经验来看，我花费了大量时间去「包装」一个故事 &amp;mdash;&amp;mdash; 这既「浪费」自己的时间，也在无形中拉大了与读者之间的距离。&lt;/p&gt;&lt;p&gt;更重要的是，能够被包装成故事的现象极其稀少。许多我个人觉得非常有趣的现象，因为无法整理成一篇论文，最终只能被随意丢弃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;迈向更易理解的现象学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因此，我倡导一种更易于接近、更具包容性的现象学研究方式。这种方法将比当前的 AI 现象学更宽容，也更接近物理学中现象学的精神。它应当：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不以即时可用性为导向；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不被要求包装成一个完整的「故事」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不限制分析工具，只要它们在描述、预测上是有效的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;同时，它将强调：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可控性&lt;/strong&gt;：使用玩具模型来简化和抽象现实场景，使得结果能够用最少的资源复现（理想情况下，一台笔记本加一个 CPU 就足够了）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多视角刻画&lt;/strong&gt;：从尽可能多的角度和指标来描述研究对象 &amp;mdash;&amp;mdash; 就像「盲人摸象」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;好奇心或假设驱动的探索&lt;/strong&gt;：现象应当能够带来新的洞见，定性结果已经足够，定量结果当然更好。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;这种「可接近的现象学」也许不容易发表在主流 AI 会议上，但它对于社区建设具有极高价值。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;比如，研究者 A 发现了一个现象（关键在于把它公开出来），B 将其与自己此前观察到的现象联系起来，C 将二者统一，D 进行理论分析，E 再将这些洞见转化为算法改进。最终，这五个人可以一起写一篇论文。&lt;/p&gt;&lt;p&gt;但在传统模式下，A 可能只会在一个很小的圈子里合作。就我对 AI 物理学社区的理解，目前这个领域仍然高度碎片化，往往按应用领域分割。例如，做视觉的研究者通常只与其他视觉研究者合作，他们的直觉也主要由视觉任务塑造。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那我们能够做什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就我个人的经验来看，我是先从写博客开始的，开始以博客文章的形式，分享我们自己的「AI 现象学」研究。读者应当抱有这样的预期：这是同事在分享阶段性结果 &amp;mdash;&amp;mdash; 工作可能并不完整，但原始数据和思考过程会被透明地呈现出来。&lt;/p&gt;&lt;p&gt;目标有三点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是迫使自己记录观察结果&lt;/strong&gt;：正如前面所说，无法写成论文的现象往往会被丢弃。这个尝试部分受到苏剑林博客的启发 &amp;mdash;&amp;mdash; 他的博客更偏向数学原理，而我的将更强调实验观察（现象学）、「物理直觉」，以及在必要时提供一些（半）定量分析，为未来的数学研究提供问题和直觉。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;二是吸引志同道合的研究者与学生&lt;/strong&gt;：如果你对这些问题感兴趣，欢迎联系我，一起探索。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;课程准备&lt;/strong&gt;：我计划在清华大学开设一门《Physics of AI》课程。这些博客文章（及配套代码）未来可能会成为课程材料。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么对于你来说，该如何开始：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是找到你真正关心的问题&lt;/strong&gt;：例如，研究扩散模型损失函数的参数化方式，或复现已有现象（如 Grokking）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义一个简单的玩具模型&lt;/strong&gt;：例如，李天宏与何恺明的 JIT 论文使用一个二维螺旋数据集来研究损失参数化。而理解 grokking 的最好方式就是自己亲手训练一个模加任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;致力于彻底理解这个玩具模型&lt;/strong&gt;：这是最困难的一步。由于发表文化的影响，我们往往急于从玩具模型跳到更真实的模型。一旦玩具模型给出了「正向结果」，我们就会立刻离开。这是一种监督式使用玩具模型。而我认为，玩具模型在无监督使用时，才能真正展现其力量。既然是玩具，就应当以孩童般的好奇心去对待它，反复把玩，从所有可能的角度理解它（就像盲人摸象）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，我无法保证这些洞见会立刻转化为性能提升，但我相信：如果整个领域持续积累这样的理解，最终一定会发生一次类似渗流（percolation）的相变。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/ZimingLiu11/status/2006810684546494522&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://kindxiaoming.github.io/blog/2025/physics-of-ai/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>自回归也能做强视觉模型？NEPA开启「下一嵌入预测」时代，谢赛宁参与</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:41:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/80ddf4c3-cd2b-4aaa-9742-a7a969aaff98/1767371980146.png" style="width: 700%;" class="fr-fic fr-dib"&gt;众所周知，LeCun 不喜自回归，并且还提出了一种名为联合嵌入预测架构（JEPA）的新方向，并且该方向也一直在有&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651008220&amp;idx=1&amp;sn=5619349cb36b173f01dd8503866bfea9&amp;scene=21#wechat_redirect" target="_blank"&gt;新成果&lt;/a&gt;涌现。&lt;/section&gt;&lt;p&gt;然而，自回归模型的成功也是有目共睹的，尤其是在语言领域。那么，生成式预训练在自然语言上的成功能否在视觉领域重现呢？&lt;/p&gt;&lt;p&gt;近日，密歇根大学、纽约大学、普林斯顿大学和弗吉尼亚大学的一个联合研究团队对此给出了肯定答案。&lt;/p&gt;&lt;p&gt;只不过，他们不是训练模型输出用于下游任务的特征，而是让它们生成嵌入（embeddings）以直接执行预测任务。可以说，这是从学习表征（learning representations）到学习模型（learning models）的一种范式转变。&lt;/p&gt;&lt;p&gt;具体而言，模型会通过因果掩码（causal masking）和停止梯度（stop gradient），以过去图块嵌入为条件，学习预测未来的图块嵌入。类似于下一 token 预测，该团队将这种方法称为&lt;strong&gt;下一嵌入预测自回归（Next-Embedding Predictive Autoregression）&lt;/strong&gt;，简称&amp;nbsp;&lt;strong&gt;NEPA&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21Tl60htjCibLb86l6ztHwZ5ibu1HPtRBWPOHE1oC0KCzzVxkbV70pJhiaeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2363238512035011" data-s="300,640" data-type="png" data-w="914" type="block" data-imgfileid="503524697" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/28d28fa9-f4b4-4ece-b30b-b39829acf0af/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Next-Embedding Prediction Makes Strong Vision Learners&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.16922v1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址：https://sihanxu.me/nepa/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/SihanXU/nepa&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址：https://huggingface.co/collections/SixAILab/nepa&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该论文目前正是 alphaXiv 上热度第一的论文。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TRNiccU8mL773Yia5o5LyEPiciaTSoQURXJsiaGJZslKh4RYUiczEeJSJ1ZOQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.42592592592592593" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503524703" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/af5e5d14-37e9-4b30-a8a5-3ca1a997ba8d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;本文第一作者为 Sihan Xu，密歇根大学博士生，导师是密歇根大学电气工程与计算机科学系正教授 Stella X. Yu；这项研究的部分工作是其在纽约大学访问期间完成。纽约大学著名研究科学家谢赛宁也在作者名单中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视觉预训练是计算机视觉的核心议题之一。自监督学习也已成为现代视觉预训练方法的基石，使得无需人工标签即可训练可扩展的视觉学习器。&lt;/p&gt;&lt;p&gt;其核心目标是学习表征（learn representations）：优化模型，从而将原始像素映射到固定维度的表征，这些表征随后可被使用或针对下游任务进行微调。&lt;/p&gt;&lt;p&gt;这一哲学统一了基于实例判别（instance discrimination）、自蒸馏（self-distillation）和掩码重建（masked reconstruction）的方法。&lt;/p&gt;&lt;p&gt;其目标是学习能够被各种规模的下游模块（从轻量级的特定于任务的头到诸如视觉 - 语言模型等大型级联系统）所使用的视觉表征。&lt;/p&gt;&lt;p&gt;现代自然语言处理的成功则建立在一个根本不同的范式之上。&lt;/p&gt;&lt;p&gt;语言模型的预训练目标并不是作为特征提取器；而是作为生成式和预测式系统。其目标不是生成句子的静态嵌入，而是通过一个简单的因果目标（causal objective）对数据分布本身进行建模。&lt;/p&gt;&lt;p&gt;这种训练会迫使模型内化语言中的语义和条件依赖关系。推理不再是一个「编码&amp;rarr;解决任务」的两阶段过程，而是由模型本身执行的单一预测计算。&lt;/p&gt;&lt;p&gt;这一区别至关重要，涉及根本。它表明：&lt;strong&gt;生成式预测&lt;/strong&gt;（而非表征学习）可能提供了一条扩展预训练的直接途径。&lt;/p&gt;&lt;p&gt;最近的一系列研究已经转向了这一哲学。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;早期的像素级生成式预训练（iGPT）展示了可迁移的特征，但在处理超长序列和弱语义对齐方面表现一般。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;JEPA 超越了像素层面，通过预测潜在目标（latent targets）来更紧密地与语义结构对齐。然而，JEPA 依然是通过从动量编码器（momentum encoder）回归到潜在目标来进行训练，而不是将生成式预测作为自监督目标。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于这些观察，Sihan Xu 等人想知道：&lt;strong&gt;极简的因果预训练是否也能产生强大的视觉学习器。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体来说，图像被分解为图块（patches），这些图块再被映射为图块级嵌入的序列。然后训练一个因果 Transformer，在给定所有先前嵌入的情况下预测下一个嵌入，这与语言模型中的「下一 Token 预测」范式非常近似。&lt;/p&gt;&lt;p&gt;基于这些观察，Sihan Xu 等人想知道：极简的因果预训练是否也能产生强大的视觉学习器？&lt;/p&gt;&lt;p&gt;具体来说，图像被分解为图块（patches），这些图块再被映射为图块级嵌入的序列。然后训练一个因果 Transformer，在给定所有先前嵌入的情况下预测下一个嵌入，这与语言模型中的「下一 Token 预测」范式非常近似。&lt;/p&gt;&lt;p&gt;该团队对目标嵌入使用停止梯度（stop-gradient）以创建一个稳定的预测任务。这种形式是刻意保持极简的。它不需要像素级解码器、不需要离散的视觉 Tokenizer（分词器），也不需要对比学习中常见的工程化数据增强、负样本对或动量编码器。整个学习信号源于模型在嵌入空间中预测未来的能力。&lt;/p&gt;&lt;p&gt;于是乎，一个新的模型家族诞生了：&lt;strong&gt;下一嵌入预测自回归（NEPA）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一嵌入预测自回归（NEPA）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;整体来看，NEPA 方法是极简主义的。如果说现在的视觉模型都在比拼谁的装备更复杂（动量编码器、解码器、离散 Tokenizer&amp;hellip;&amp;hellip;），那么 NEPA 就是那个穿着白 T 恤走进战场的选手。它的核心哲学非常简单：像 GPT 预测下一个词那样，去预测图像的下一个「特征块」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TnFonJO3BcWgtt1mEpJI5DBeeqUUkTyo2BuOib64hOK3m7uPECYrXDJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8323494687131051" data-s="300,640" data-type="png" data-w="847" type="block" data-imgfileid="503524698" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/41714c99-1adc-47cd-98b3-3808c4d9b098/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其核心思路可以总结如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;切块与编码：首先，把一张图切成若干小块（Patch），每一块通过编码器变成一个向量（Embedding）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;预测未来：观看前面的块，猜下一块长什么样。这和语言模型（LLM）的「下一词预测」相似，只不过这里处理的是连续的数学向量，而不是离散的词。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;防止「作弊」：为了防止模型偷懒（比如输出一样的结果），作者借用了 SimSiam 的经典招数：&lt;strong&gt;停止梯度（Stop-Gradient）&lt;/strong&gt;。简单说，就是让作为「标准答案」的那个目标向量保持静止，不参与反向传播。这就像是射箭时，靶子必须固定，不能让你把靶子移到箭射中的地方。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;具体到架构设计上，他们采用了一个带有因果注意力掩码的标准视觉 Transformer（ViT）主干网络。&lt;/p&gt;&lt;p&gt;与像素级重建方法不同，该方法不需要单独的解码器。该 Transformer 直接根据过去的图像块嵌入来预测未来的图像块嵌入，使用单个主干网络同时进行上下文编码和预测，这与自回归语言模型类似。图像通过一个二维卷积（Conv2d）图像块嵌入层被分割成不重叠的图像块，并在输入到 Transformer 之前添加可学习的位置嵌入。&lt;/p&gt;&lt;p&gt;他们采用了带有层归一化（LayerNorm） 的预归一化设计，并对输出特征应用最终的层归一化。&lt;/p&gt;&lt;p&gt;为了提高稳定性和可扩展性，该团队该结合了受 DINOv3 和视觉大语言模型 VisionLLaMA 启发的现代训练和归一化方法，如图 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TvtynlmVyjdNbnUQJ8cBTcj2znKrDxX3DxonMB9WG0443Tv13ibs5p9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0035545023696681" data-s="300,640" data-type="png" data-w="844" type="block" data-imgfileid="503524699" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/72fe0ab4-3387-49b0-8b9f-11d165f64048/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些模型设计有助于训练，但与核心框架无关，感兴趣的读者可参阅原论文以及相关论文。&lt;/p&gt;&lt;p&gt;训练好之后怎么用呢？换个「头」就行。下面是两个例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分类&lt;/strong&gt;：取出最后一个预测出来的嵌入向量，接个简单的分类头，就能识别这是猫还是狗。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分割&lt;/strong&gt;：接一个 UPerNet 头。有趣的是，虽然训练时是「只看过去」的单向预测，但在做分割这种需要全局信息的任务时，可以解除封印，开启双向注意力（Bidirectional Attention），让模型看清全图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总之，NEPA 证明了，只要你有一个好的预测目标，就不需要那些花里胡哨的架构，一个标准的 Transformer 加上「防坍塌」技巧，就能成为顶级的视觉学习者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在量化性能方面，NEPA 展现出了与 SOTA 方法相媲美甚至更优的实力。&lt;/p&gt;&lt;p&gt;仅在 ImageNet-1K 上进行预训练，NEPA 的 ViT-B 和 ViT-L 模型分别达到了 83.8% 和 85.3% 的 Top-1 准确率，这一成绩优于 MoCo v3、BEiT，并与 MAE 和 JEPA 处于同一水平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TRVLkoJYcxnpXAFBjofpDlROJ65l161AHn76pdtdbHibcuReFAY2g9qw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.44351851851851853" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524701" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d52d992f-c7c5-4b3b-bfe6-12fbfc5ecb2f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更重要的是，尽管预训练过程中从未涉及像素重建，NEPA 依然表现出了强大的迁移能力，在 ADE20K 语义分割任务上分别取得了 48.3% 和 54.0% 的 mIoU，证明了纯粹的嵌入预测足以学习到处理密集预测任务所需的丰富语义特征。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TqmjpE8gia2aXTDSOP3ozkNXXNEzeVyfeaT1AFZWjGDics64ibs0rT8Ribw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524700" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d7f40ce3-acf1-4cbd-a058-94a2c8b4e43c/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;最后，通过对模型内部注意力和嵌入的可视化分析，研究揭示了 NEPA 的有效性来源。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TUjhgpVP5uuXGIF9ib4S3NaJQibG5p9gjibibE68m8LetLCC7ArVc0lP2yQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524702" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/4a62b361-b7fd-4da0-b006-45d9c7eb1bd5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可视化结果显示，模型自动学会了长距离且以对象为中心的注意力模式，能够忽略背景干扰，将注意力集中在语义相关的区域。同时，预测出的嵌入向量在语义上与属于同一物体的其他图块高度相似，表明模型并非死记硬背局部纹理，而是真正理解了物体层面的结构。&lt;/p&gt;&lt;p&gt;这种通过简单的「下一嵌入预测」所习得的全局语义依赖，不仅验证了该方法的有效性，也为跨模态的统一预训练范式提供了一种无需复杂手工设计的通用视角。&lt;/p&gt;&lt;p&gt;消融实验和更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>「辍学创业」的风再次席卷硅谷，但真正的变量从来不是学位</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:37:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/94b1d6ec-0ad2-491f-94f9-bba80473d27e/1767371655483.png" style="width: 700%;" class="fr-fic fr-dib"&gt;在 80、90 后的成长记忆里，「辍学创业，成为亿万富翁」这类故事流传甚广。&lt;/p&gt;&lt;p&gt;理性分析后都知道，这里面有幸存者偏差，也有个体差异 &amp;mdash;&amp;mdash; 盖茨、扎克伯格都是哈佛级别，随时能回去拿学位；乔布斯也没有完全离开校园，而是以旁听生的身份自由选课。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyyJ0DGHyShpDgwP0zscmCDdlEkOeibPNtbOiamcIbpVeAa8bPibHFqhm9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526545" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/96c6c54c-7ad5-4924-ae5d-b4c362922ede/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但没想到，最近，这股风又刮回来了。在硅谷，「辍学创业」正成为一个值得强调的正向标签。&lt;/p&gt;&lt;p&gt;这一趋势在 Y Combinator 的 Demo Day 上体现得尤为明显：越来越多的创始人在一分钟路演中主动强调自己的辍学身份。&lt;/p&gt;&lt;p&gt;Moxxie Ventures 创始人兼普通合伙人 Katie Jacobs Stanton 表示：「据我所知，YC 并未正式追踪辍学数据，但从近几批学员的情况来看，有太多创始人会特意强调自己从大学、研究生院甚至高中辍学的经历。辍学本身已成为一种资历，体现出创业者对事业的坚定信念和投入。我认为在风投圈，这被视为相当正面的特质。」&lt;/p&gt;&lt;p&gt;这些人的辍学动机不难理解：留在学校完成学业，可能意味着错过 AI 创业周期中最关键的窗口期。创办 Scale AI 的 Alexandr Wang、Lucy Guo 就是其中代表。&lt;/p&gt;&lt;p&gt;一位投资人表示，「大家普遍有一种紧迫感，或许还有错失恐惧症（FOMO）。现在的算盘很简单：要么完成学业，要么直接开始做产品。」&lt;/p&gt;&lt;p&gt;这种焦虑正催生极端案例。一位顶尖大学的教授近期透露，一名学生在最后一个学期放弃了学位。这位学生深信，拥有文凭反而会降低他获得融资的机会。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVydCwPkHBlP50wiaKI2icZxkduWicCyeqb7bamE8CjdIuzV5ceR6kibp6Brw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526546" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d5a1318d-a0db-4380-9c0d-189cf2b78241/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不过，也有投资人认为市场并没有如此极端。负责 General Catalyst 种子轮投资策略的 Yuri Sagalov 表示，风投其实没那么执着于「辍学」这个标签，尤其是对于即将毕业的学生：「对于大四才辍学的人，我从来没觉得他们和顺利毕业的人有什么本质区别。」&lt;/p&gt;&lt;p&gt;Sagalov 认为，即便是技术天才能够在没有正规教育的情况下创业，大学提供的社交网络和学校品牌仍然具有价值 &amp;mdash;&amp;mdash; 即使创始人最终没有拿到文凭。他说：「你依然能获得大部分社交价值&amp;hellip;&amp;hellip; 因为你可以标注自己曾就读于那所学校。大多数人在 LinkedIn 上看你的履历时，并不会太在意你是否真正毕业。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyPmsyjDBVL2WmIuS1yhFQW75qq6NvibqS1mfZE0lDRMO9D6ZFtZhFibrQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0333333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526547" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/76a11474-9b4a-49a8-92db-7f54d3db19e3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;尽管如今许多投资人认为创业者可以不要大学文凭，但并非所有风投都认同年轻创始人在当前市场具有优势。FPV Ventures 联合创始人 Wesley Chan 对投资辍学者并不那么热衷，因为他更看重一种大多数年轻创始人尚未具备的特质：智慧。Chan 认为，这种智慧通常存在于「更年长的创始人，或那些经历过挫折、身上带着伤疤的人」身上。&lt;/p&gt;&lt;p&gt;当然，需要指出的是，尽管许多引领 AI 浪潮的创始人都是年轻人，但大多数仍然选择完成学业。例如，Cursor 的 CEO Michael Truell 毕业于 MIT，而 Cognition 的联合创始人 Scott Wu 则毕业于哈佛大学。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVykyrFvXUtQZxytX4RdVrMeiaR2gOS1VkzgbbUyCVgx9j0psnZWQA5M5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526548" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/dba2aef9-242e-405e-b9ae-fa8f15f3bbc6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyaG0YpZk6e5k73wrwQ86KxPyssgqwvot9lu5SqPElia9zxNG3T0U1QMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.36018518518518516" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526549" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4086ffd1-e465-438a-95b5-51a2bee59aaf/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;也有人指出，今天所说的「辍学」其实和早些年已经完全不一样了，那些「辍学」的人只是换了个地方，还是继续做原来的事情，而且是在资源更丰富的工业实验室。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyTSTXvcR5pvthe36ibVG9ib0jyK2hWymZWkx83sPS0k2IzJRSL8VzHxQQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.387037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526550" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/689ebafe-794b-4636-8e9b-4aac28483f45/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;所以归根结底，「辍学」永远只是表象。真正决定成败的，是创始人能否在正确的时间窗口、用正确的资源、做正确的事。无论是拿着文凭走出校门，还是中途转身投入创业，学位从来都不是核心变量 &amp;mdash;&amp;mdash; 能力、判断力、时机，以及能否接入真正有价值的人脉和资源网络，才是。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://techcrunch.com/2025/12/31/college-dropout-has-become-the-most-coveted-startup-founder-credential/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让模型自己找关键帧、视觉线索，小红书Video-Thinker破解视频推理困局</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:33:36 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/fc89c8f2-f91d-4563-89ea-7a50a7de9d01/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着多模态大语言模型（MLLM）的飞速发展，&amp;ldquo;Thinking with Images&amp;rdquo; 范式已在图像理解和推理任务上取得了革命性突破 &amp;mdash;&amp;mdash; 模型不再是被动接收视觉信息，而是学会了主动定位与思考。&lt;/p&gt;&lt;p&gt;然而，当面对包含复杂时序依赖与动态叙事的视频推理任务时，这一能力尚未得到有效延伸。现有的视频推理方法往往受限于对外部工具的依赖或预设的提示词策略，难以让模型内生出对时间序列的自主导航与深度理解能力，导致模型在处理长视频或复杂逻辑时显得捉襟见肘。&lt;/p&gt;&lt;p&gt;为攻克这一难题，来自小红书的研究团队提出了 Video-Thinker：一种全新的 &amp;ldquo;Thinking with Videos&amp;rdquo; 范式，旨在通过强化学习激发 MLLM 在视频推理中的内生智能。&lt;/p&gt;&lt;p&gt;与传统方法不同，&lt;strong&gt;Video-Thinker 不依赖构建和调用外部工具，而是将 &amp;ldquo;时序定位（Grounding）&amp;rdquo; 与 &amp;ldquo;视觉描述（Captioning）&amp;rdquo; 这两种核心能力内化在模型的思维链（CoT）中，使其能在推理过程中自主寻找关键帧并提取视觉线索&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;团队精心构建了包含 10K 高质量样本的 Video-Thinker-10K 数据集，并采用 &amp;ldquo;监督微调 + 强化学习&amp;rdquo; 的两阶段训练策略。这一方法成功让模型在无外部辅助的情况下，实现了对视频内容的自主探索与自我修正。&lt;/p&gt;&lt;p&gt;实验结果显示，Video-Thinker-7B 凭借极高的数据效率，在 Video-Holmes 等多个高难度视频推理榜单上显著超越了现有基线，确立了 7B 量级 MLLM 的 SOTA（State-of-the-Art）性能，为视频大模型的动态推理开辟了新路径。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeNwpbTmrmBCnMgEmjJQIicQmMkibvO2253iaiaLpHloBfM8XREabmjbZGJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526141" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4e333a4e-1dbb-4044-8312-4f2479fb5ff9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://www.arxiv.org/abs/2510.23473&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址：https://huggingface.co/ShijianW01/Video-Thinker-7B&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/DeepExperience/Video-Thinker&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、背景：视频推理的 &amp;ldquo;工具依赖困局&amp;rdquo; 与破局需求&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在多模态大语言模型（MLLM）进化的浪潮中，&amp;ldquo;Thinking with Images&amp;rdquo; 范式已经让模型在静态图像的理解与推理上取得了令人瞩目的突破。当模型学会了在像素间主动定位与思考，静态画面不再是信息的黑盒。&lt;/p&gt;&lt;p&gt;然而，当我们试图将这种范式延伸至视频领域时，情况却变得复杂得多。视频不仅仅是图像的简单堆叠，更包含了复杂的时序依赖、动态的叙事逻辑以及稍纵即逝的视觉细节。面对这种高维度的信息流，现有的视频推理方法正面临着难以突破的瓶颈。&lt;/p&gt;&lt;p&gt;当前主流的视频大模型在处理复杂推理任务时，往往陷入了一种对 &amp;ldquo;外部辅助&amp;rdquo; 的过度依赖。为了弥补模型对长视频处理能力的不足，研究者们通常采用挂载外部视觉工具（如检测器、追踪器）或设计繁复的预设提示词策略来辅助模型。这种做法虽然在一定程度上缓解了信息获取的难题，却在本质上造成了推理过程的 &amp;ldquo;割裂&amp;rdquo;：模型并非真正 &amp;ldquo;看见&amp;rdquo; 并 &amp;ldquo;理解&amp;rdquo; 了视频的时间脉络，而是被动地接收外部工具提取的碎片化特征，或是机械地遵循预设步骤进行填空。&lt;/p&gt;&lt;p&gt;这种缺乏内生主动性的架构，导致模型在面对长视频或需要深度逻辑推演的任务时显得捉襟见肘。由于缺乏对时间序列的自主导航能力，模型无法像人类一样根据当前的思考线索去主动 &amp;ldquo;快进&amp;rdquo;、&amp;ldquo;倒带&amp;rdquo; 或聚焦于某个关键帧。它无法自主决定何时通过 &amp;ldquo;Grounding（时序定位）&amp;rdquo; 来锁定证据，也无法灵活地利用 &amp;ldquo;Captioning（视觉描述）&amp;rdquo; 来提炼线索。这种感知与推理的脱节，使得模型难以在动态变化的视频内容中构建起连贯的思维链，最终限制了视频大模型向更高阶智能的跃升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何让模型摆脱对外挂拐杖的依赖，内生出在时间流中自由探索与自我修正的能力，成为了视频推理领域亟待攻克的难题。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、方法：内生能力导向的 &amp;ldquo;数据 - 训练&amp;rdquo; 全链路设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Video-Thinker 的核心愿景在于实现 &amp;ldquo;能力内化&amp;rdquo;：打破传统视频大模型对外部视觉工具的依赖，将 &amp;ldquo;时序定位（Grounding）&amp;rdquo; 与 &amp;ldquo;视觉描述（Captioning）&amp;rdquo; 这两大核心能力直接植入模型的思维链（CoT）中。为达成这一目标，团队设计了一套精密的 &amp;ldquo;数据 - 训练&amp;rdquo; 协同机制：首先构建 Video-Thinker-10K 高质量结构化数据，随后通过 &amp;ldquo;监督微调（SFT）+ 组相对策略优化（GRPO）&amp;rdquo; 的两阶段训练范式，成功让模型学会了在动态视频流中自主导航、主动思考。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeznIic2mDNVxqTzFEicSk00iah47dUE5K6XjOpm5ClbJ2ReumqCve4Fxrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8074074074074075" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526142" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1a618c93-1f5f-4f6a-bd8b-049035bb50f8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;数据炼金：Hindsight-Curation 驱动的思维链构建&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeho4a2hXCQ52OnREjTPuc8Wk8EKE3dVUYW8qib0o1O11a2maUnibhd9jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.24444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526143" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f373897f-9b7a-4b5d-a6b7-ce3a296f4ed2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;要让模型真正掌握视频场景下的复杂推理能力，构建高质量的训练数据是必经之路。然而，现有的开源视频数据集普遍存在 &amp;ldquo;二元割裂&amp;rdquo; 的结构性缺陷：一类是以 ActivityNet、YouCook2 为代表的描述型数据，虽然拥有精确的时间段标注和画面描述，但缺乏需要深度思考的逻辑问答；另一类是以 STAR、LVBench 为代表的问答型数据，虽然问题极具挑战性，却往往缺失了支撑答案的关键帧定位与视觉细节。为了弥补这一鸿沟，团队整合了六大主流数据集，构建了 Video-Thinker-10K。该数据集并未止步于简单的拼接，而是引入了一套 &amp;ldquo;后见之明（Hindsight-Curation）&amp;rdquo; 的自动化流水线，通过 &amp;ldquo;补全 - 合成 - 验证&amp;rdquo; 的严密闭环，生产出兼具精准时序定位（Grounding）与详尽视觉描述（Captioning）的结构化推理数据，确保模型在学习过程中能够建立起从视觉证据到逻辑结论的完整映射。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1: 双向信息补全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对不同源数据特性的差异，团队将 ActivityNet、TutorialVQA,、YouCook2、STAR、ScaleLong 和 LVBench 六大主流数据集划分为互补的两类，并实施了 &amp;ldquo;缺什么补什么&amp;rdquo; 的数据增强策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;针对 &amp;ldquo;有描述无推理&amp;rdquo; 的数据（如 ActivityNet、TutorialVQA、YouCook2）：这类数据具备精确的时间段标注和详尽的动作描述，但缺乏深度的逻辑问答。团队利用 DeepSeek-R1 强大的逻辑推理能力，以原有的细粒度片段描述为上下文，合成出需要跨越多个时间片段进行综合分析的复杂多跳问题，将单纯的感知任务升级为逻辑推理任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;针对 &amp;ldquo;有问答无细节&amp;rdquo; 的数据（如 STAR、ScaleLong、LVBench）：这类数据虽然包含极具挑战性的推理问答，却往往缺失了支撑答案的具体视觉描述。团队借助 Gemini-2.5-Flash-Lite 的长窗口视觉理解能力，以标准答案为锚点进行反向推导，为关键时间窗口生成了与答案强相关的精细化视觉描述（Answer-Conditioned Captions），填补了推理过程中视觉证据的空白。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Step 2: 结构化思维链合成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在完成了基础信息的双向补全后，系统调用 DeepSeek-V3 执行 &amp;ldquo;反向推理合成（Reverse-Curation Generation）&amp;rdquo;。模型接收标准答案、时序标注以及生成的视觉描述作为输入，被要求倒推并生成一条逻辑严密、逐步展开的推理轨迹。这条轨迹并非自由发散，而是必须严格遵循预定义的结构化格式，显式地将推理过程拆解为三个关键动作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&amp;lt;time&amp;gt;：执行时序定位任务，精确划定包含关键信息的视频时间窗口，明确模型 &amp;ldquo;关注哪里&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;lt;caption&amp;gt;：执行视觉证据提取任务，对该时间窗口内的核心视觉线索进行总结与描述，阐述模型 &amp;ldquo;看到了什么&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;lt;think&amp;gt;：执行深度分析任务，基于提取的时空线索进行逻辑推演与综合判断，连接视觉证据与最终答案，解释 &amp;ldquo;意味着什么&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Step 3: 后见之明验证机制（Hindsight Curation）&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这是保障数据质量的关键防线。为了确保合成的推理轨迹真实有效而非 &amp;ldquo;自说自话&amp;rdquo;，团队引入了创新的 &amp;ldquo;后见之明&amp;rdquo; 验证流程，替代了昂贵的人工抽检。具体而言，系统使用 Qwen2.5-VL-7B-Instruct 充当 &amp;ldquo;独立验证官&amp;rdquo;，在屏蔽原始视频输入的情况下，仅将上一步生成的 &amp;lt;time&amp;gt; 时序标签和 &amp;lt;caption&amp;gt; 视觉描述作为上下文输入给模型。系统随后检测验证官能否仅凭这些提取出的线索推导出正确的标准答案。如果验证失败，意味着生成的视觉线索不足以支撑推理结论，系统将自动触发再生流程，进行最多三次的迭代修正。&lt;/p&gt;&lt;p&gt;这种 &amp;ldquo;以结果验证过程&amp;rdquo; 的闭环机制，有效剔除了无效或低质量的样本，确保了最终保留在 Video-Thinker-10K 中的每一条数据，其视觉证据与逻辑结论之间都具备严密且可复现的因果关系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;监督微调建立结构化思维范式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;监督微调（SFT）阶段旨在完成模型的 &amp;ldquo;冷启动&amp;rdquo; 初始化。由于预训练的多模态大模型本身并不具备输出特定标签（如 &amp;lt;time&amp;gt; 或 &amp;lt;caption&amp;gt;）的习惯，SFT 阶段的主要任务是通过强制教学，让模型习得 Video-Thinker 独有的结构化思考范式。&lt;/p&gt;&lt;p&gt;对于每一个样本 (V, Q, T, Y)，其中 V 是视频，Q 是问题， T 是包含 &amp;lt;time&amp;gt;，&amp;lt;caption&amp;gt; 和 &amp;lt;think&amp;gt; 的思维链， Y 是最终答案。SFT 的优化目标是最小化思维链与答案的负对数似然：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeARibnW5JBqicZEoRNSl9BPCg6f2wTwwBoKiaicwy3X08cXztia9h8rJpfgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1388888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526144" data-aistatus="1" data-original-style="width: 478px;height: 66px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8e47ec95-fe26-4f1d-bf75-a64671afe036/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;通过这一阶段的训练，模型不再将视频视为一个模糊的整体进行黑盒猜测，而是建立起了一套严谨的 &amp;ldquo;定位 - 感知 - 推理&amp;rdquo; 标准动作序列：即先通过 &amp;lt;time&amp;gt; 标签主动定位关键片段，再利用 &amp;lt;caption&amp;gt; 标签提取视觉细节，最后通过 &amp;lt;think&amp;gt; 标签进行逻辑整合。这种显式的思维约束，不仅教会了模型如何使用内部工具，更有效抑制了其在缺乏证据时直接生成答案的幻觉倾向，为后续的强化学习奠定了坚实的策略基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习激发内生智能与 &amp;ldquo;顿悟&amp;rdquo; 时刻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然 SFT 赋予了模型结构化的表达形式，但仅凭监督微调，模型往往只能 &amp;ldquo;模仿&amp;rdquo; 训练数据的表面模式，难以应对分布外的复杂场景。真正的智能源于在探索中自我优化，因此训练进入第二阶段：采用组相对策略优化（Group Relative Policy Optimization, GRPO）激发模型的内生潜能。&lt;/p&gt;&lt;p&gt;不同于传统 PPO 算法依赖庞大的价值网络来评估状态价值，GRPO 采用了一种更为高效的策略：它通过对同一输入并行采样多组不同的推理轨迹，利用组内输出的相对优势来指导梯度更新。这种 &amp;ldquo;摒弃 Critic 模型&amp;rdquo; 的设计不仅大幅降低了显存占用和计算成本，更关键的是，它允许模型在反复的试错与自我博弈中，自主探索出如何更高效地调用 &amp;lt;time&amp;gt; 和 &amp;lt;caption&amp;gt; 锚点来解决新问题，从而将机械的格式遵循升华为灵活的视频思维能力，真正实现对视频内容的自主导航。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;采样与双重奖励设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于每个输入 (V, Q)，模型采样生成 G 组不同的推理轨迹&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe6e6EW8oRib2KSXmTz3KFaU02ImAZLN2o9sDTF18B9F1uoaSGqQicgMRg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.21081081081081082" data-s="300,640" data-type="png" data-w="370" type="block" data-imgfileid="503526145" data-aistatus="1" data-original-style="width: 123px;height: 26px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1651b25c-d2aa-4b15-9dbd-a83c75b73d56/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 14.85%;"&gt;。为了兼顾推理的准确性与格式的规范性，团队设计了复合奖励函数：&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeZt54UAZibgxlenzPds0iaZNqgJelBLuLXOgYxlkCU4HgjmY0HTwGmxhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.164" data-s="300,640" data-type="png" data-w="500" type="block" data-imgfileid="503526146" data-aistatus="1" data-original-style="width: 144px;height: 24px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/70ebcd5e-349e-4f81-ba3e-dc3c303c167b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 20.07%;"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeicZib8KDZehCay61uCs7bKTMJyMG2VnaulmahUSQcudQibHoOeWYF8ia9g/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.4878048780487805" data-s="300,640" data-type="png" data-w="328" type="block" data-imgfileid="503526147" data-aistatus="1" data-original-style="width: 47px;height: 23px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6515691f-f9ce-450e-b9fe-e15f89295f28/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 7.47%;"&gt;&amp;nbsp;：结果导向，奖励最终答案是否命中真值 Y。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6miberBMKw0f2BLUo4GrJr3s1D4IbW8LabOZNdUhenXicEos262JVgOQM00g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5111821086261981" data-s="300,640" data-type="png" data-w="313" type="block" data-imgfileid="503526148" data-aistatus="1" data-original-style="width: 45px;height: 23px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3c4a17dc-0791-4025-a32a-1d0dcd04b694/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 8.03%;"&gt;&amp;nbsp;：过程约束，惩罚未遵循 &amp;lt;time&amp;gt; 和 &amp;lt;caption&amp;gt; 结构的行为，确保模型不偏离思考轨道。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;策略优化目标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最终的优化目标通过最大化裁剪后的代理目标函数来更新参数&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6miberTCzibFUYpeIQib2KP0SLAYhGCdMh4b5xAYbCCv6CLPm52IYZTs8ccWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.08" data-s="300,640" data-type="png" data-w="50" type="block" data-imgfileid="503526149" data-aistatus="1" data-original-style="width: 20px;height: 22px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/1c83d20c-4346-4acd-a758-df2c1501730e/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.39%;"&gt;&amp;nbsp;，并引入 KL 散度约束防止策略突变：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeFOj66iaSo8icrF9cEJibyovibC0uRSNTzmvypiabrF0R03jva1iaVyoELTibg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.08148148148148149" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526150" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/1cdc5647-a994-4a73-93ac-1b7830ee7680/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibes3Oobroq77qymvib8ic9D0MNMLv73Isp4mXlS2jlQqt0Xicplw3DxNuMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.32113821138211385" data-s="300,640" data-type="png" data-w="492" type="block" data-imgfileid="503526151" data-aistatus="1" data-original-style="width: 77px;height: 25px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/e0296e3c-373e-456a-a978-401ff04a7123/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 14.21%;"&gt;代表新旧策略的概率比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;涌现的 &amp;ldquo;Aha Moment&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;经过 GRPO 的强化训练后，Video-Thinker 开始涌现出类似人类的高阶认知行为 &amp;mdash;&amp;mdash; 我们称之为 &amp;ldquo;顿悟时刻（Aha Moment）&amp;rdquo;。与传统模型线性的、单向的生成过程不同，Video-Thinker 在面对复杂推理时，不再是一条路走到黑。我们观察到，模型开始在思维链中自发展现出元认知（Metacognition）特征：它会对其初步生成的时序定位或视觉描述进行 &amp;ldquo;回头看&amp;rdquo;，主动发起自我质疑与修正。&lt;/p&gt;&lt;p&gt;这种动态的内部反馈机制，使得模型不再是被动的信息接收者，而是主动的探寻者。正是这种内生的反思能力，让 Video-Thinker 能够在仅有 7B 参数量且仅使用 10K 训练数据的情况下，打破了参数规模的限制，在 Video-Holmes 等高难度视频推理基准上，大幅超越了依赖海量数据训练的现有基线模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、评测：全面验证，7B 模型刷新视频推理 SOTA&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了全方位验证 Video-Thinker 的视频推理能力，研究团队构建了包含域内（In-Domain）与域外（Out-of-Domain）的双重评估体系。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;训练配置： 研究选用 Qwen2.5-VL-7B-Instruct 作为基础模型。训练过程严格遵循 &amp;ldquo;两阶段&amp;rdquo; 范式：首先在 Video-Thinker-10K 数据集上进行 1 个 epoch 的监督微调（SFT），让模型习得结构化的思考格式；随后引入 GRPO 算法进行强化学习训练，以激发模型自主视频推理的潜能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;评测数据集：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;域内评测：基于 ActivityNet、Star、ScaleLong、YouCook2、LVBench 等五个训练数据集构建了测试集（Held-out test sets），用于评估模型在熟悉领域内的表现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;域外评测：精选了 Video-Holmes、CG-Bench-Reasoning、VRBench、SciVideoBench、VideoTT、VideoMME 等六个具有挑战性的高难度复杂视频推理基准，重点考察模型在未知场景下的泛化能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基线模型： 对比阵容强大，涵盖了 InternVL、Qwen2.5-VL 等 5 个主流开源多模态基础模型，以及 Video-R1、VideoChat-R1、Temporal-R1 等 12 个开源视频推理模型，确保了比较的公平性与广泛性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;总体性能对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验结果表明，Video-Thinker-7B 在各项视频推理基准上均展现出显著优势，成功确立了 7B 参数量级模型的新 SOTA（State-of-the-Art）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心发现与数据解读：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;域外泛化能力的质变&lt;/strong&gt;： Video-Thinker 在处理未见过的复杂任务时表现尤为惊艳。在侦探推理类的 Video-Holmes 榜单上，模型取得了 43.22% 的准确率，超越了次优基线模型 4.68 个百分点；在综合性基准 VRBench 上，准确率高达 80.69%，大幅领先最佳基线 11.44%。这充分证明了 Video-Thinker 并非仅仅 &amp;ldquo;记住&amp;rdquo; 了训练数据，而是真正习得了通过 &amp;ldquo;定位&amp;rdquo; 和 &amp;ldquo;描述&amp;rdquo; 来解决通用视频问题的能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;SFT 与 RL 的协同效应&lt;/strong&gt;： 消融实验揭示了一个关键结论：&lt;strong&gt;仅靠 SFT 无法实现强泛化&lt;/strong&gt;。Video-Thinker-SFT-7B 版本在多个基准上的表现甚至低于基础模型，这说明 SFT 的主要作用在于 &amp;ldquo;规范格式&amp;rdquo;。而随后的 &lt;strong&gt;GRPO 强化学习阶段才是性能飞跃的关键&lt;/strong&gt;，它使模型在 Video-Holmes 上的性能提升了 11.70%，在 VRBench 上提升了 18.29%。这种 &amp;ldquo;先通过 SFT 立规矩，再通过 GRPO 练内功&amp;rdquo; 的组合，被证明是提升大模型复杂推理能力的必由之路。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe7HRFtMCxAVCsXrrzog3Y0IW8D5vZ3E4F9zKmIWqf7lCyIy8Rsrdyqg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6935185185185185" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe7HRFtMCxAVCsXrrzog3Y0IW8D5vZ3E4F9zKmIWqf7lCyIy8Rsrdyqg/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="372" data-imgfileid="503526222" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/30d57f97-f037-4aa6-9373-d76fc563aea8/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;推理帧数鲁棒性分析：更高效的时序信息整合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视频理解往往受限于输入帧数。为了探究 Video-Thinker 是否依赖高帧率输入，团队对比了模型在 16 帧、32 帧和 64 帧设置下的表现。实验数据表明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;正向的 Scaling Law&lt;/strong&gt;： 随着输入帧数从 16 增加到 64，绝大多数模型的性能均呈上升趋势，说明更丰富的时序信息确实有助于推理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全方位的性能压制&lt;/strong&gt;： 值得注意的是，Video-Thinker-7B 在所有帧数档位上均持续优于对比基线（Qwen2.5-VL 和 Video-R1）。即使在仅输入 16 帧的受限条件下，Video-Thinker 依然能保持高水准的推理精度。这意味着该模型具备更高效的时序信息整合机制，无论是在计算资源受限的低帧率场景，还是信息丰富的高帧率场景，都能稳定发挥。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeKDEL6iakWh3NuzJMkBuA6eZdd5zD2uJaGLFnByuicgIlh1hYLx6nyIsA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.3907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526153" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/117b98f0-85da-403e-86da-b539d1510d16/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;深度归因分析：定位与描述能力的显著增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Video-Thinker 的核心假设是：强大的视频推理源于对视频内容的精准 &amp;ldquo;定位（Grounding）&amp;rdquo; 和细致 &amp;ldquo;描述（Captioning）&amp;rdquo;。为了验证这一假设，研究团队不仅评测最终答案的准确率，还专门针对这两项中间过程能力进行了定量评测。评测结果表明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;时序定位（Grounding）：在要求模型输出关键时间片段的任务中，Video-Thinker-7B 的平均交并比（mIoU）达到了 48.22%，相比基础模型（27.47%）提升了 75.5%。在 Recall@0.3 指标上，Video-Thinker 更是达到了 79.29%，几乎是基础模型的两倍。这表明模型在回答问题前，确实精准锁定了视频中的关键线索，而非盲目猜测。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;内容描述（Captioning）：在视频片段描述任务中，Video-Thinker 在 BLEU、METEOR 和 ROUGE-L 三大指标上全面领先。与基础模型相比，其整体描述质量提升了 31.2%；与 Video-R1 相比，提升幅度更是达到了 61.0%。生成更准确、更相关的中间描述，为模型进行后续的逻辑推理提供了坚实的信息基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiawm0qc8hvJxsF00GQKaMY3q1TwcWJSGh5ibRLKBvglBNyABpVialj1XQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.2740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526220" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/634098dc-cc09-4243-b617-b56bfdf48819/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;消融实验：内生能力 vs 外部工具&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然 &amp;ldquo;定位&amp;rdquo; 和 &amp;ldquo;描述&amp;rdquo; 如此重要，是否可以直接给基础模型外挂现成的专用工具（如专门的 Grounding 模型或 Captioning 模型）来达到同样的效果？研究团队进行了一组反直觉但极具价值的对比实验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 简单外挂工具的 &amp;ldquo;负优化&amp;rdquo; 陷阱&lt;/strong&gt;：实验结果首先打破了 &amp;ldquo;工具越强效果越好&amp;rdquo; 的迷思。当团队尝试 &amp;ldquo;基础模型 + 即插即用工具（Plug-and-play Tools）&amp;rdquo; 的组合时，模型性能不升反降。例如，使用 Temporal-R1-7B 配合 SkyCaptioner-V1-8B 时，准确率跌至 30.58%；即便调用参数量大十倍的 Qwen2.5-VL-72B-Instruct 作为专家工具，其 33.96% 的得分依然未能超过仅使用 7B 基础模型的效果。这表明简单的工具堆叠会造成信息割裂，导致推理链路效率降低。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 现有工具调用方法的局限&lt;/strong&gt;：为了进一步验证，团队对比了现有的代表性工具使用方法 &amp;mdash;&amp;mdash; VideoMind-7B。虽然 VideoMind-7B 通过更复杂的工具调用策略，将 Video-Holmes 的得分提升到了 38.98%，成功超越了基础模型和简单的外挂方案，但相比于 Video-Thinker 它依然存在明显差距（落后约 4.2%）。这说明即便是成熟的外部工具调用方式，在信息传递的连贯性和推理深度上仍存在天花板。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Video-Thinker 内生思维链的压倒性优势&lt;/strong&gt;：最终，通过训练获得内生能力的 Video-Thinker-7B 展现了统治级的表现。它在 Video-Holmes 上取得了 43.22% 的全场最高分（红色加粗），不仅远超外挂工具方案，也显著优于 VideoMind-7B；同时在 VRBench 上更是达到了 80.69% 的高分。实验有力地证明，在视频推理任务中，将 &amp;ldquo;感知 - 定位 - 描述 - 推理&amp;rdquo; 无缝融合的内生思维链（Endogenous CoT），比简单的工具堆叠甚至 VideoMind 这种外部调用方法都更为高效可靠。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeFias9Ahic98lWr7Pj0Flx7BiaNYpLiaGVwB9g9WGBZc3rksOlRh4aTTNIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526154" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/11ecb2b4-0d01-4eca-8bf5-34bde63fe7fb/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、结语：内生智能引领视频推理新方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Video-Thinker 的核心价值，在于打破了 &amp;ldquo;视频推理必须依赖外部工具&amp;rdquo; 的固有认知，通过 &amp;ldquo;高质量数据合成 + 精准强化训练&amp;rdquo; 的全链路设计，让 MLLM 真正实现内生 &amp;ldquo;时序定位&amp;rdquo; 与 &amp;ldquo;片段描述&amp;rdquo; 能力，实现了端到端的自主视频思考。其 7B 参数模型在多领域基准上刷新 SOTA 的表现，证明了视频推理能力并非依赖 &amp;ldquo;大参数 + 大数据&amp;rdquo; 的堆砌，而是在于对核心内生能力的精准培养。未来，随着技术迭代，Video-Thinker 有望进一步集成音频、字幕等多模态信息，拓展至小时级长视频推理场景，让 &amp;ldquo;用视频思考&amp;rdquo; 成为 MLLM 的基础能力。这种内生智能驱动的技术路径，不仅为视频推理领域提供了新范式，更将加速 AI 在安防监控、智能教育、工业运维等领域的落地应用，真正赋能千行百业的智能化升级。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Meta重磅：让智能体摆脱人类知识的瓶颈，通往自主AI的SSR级研究</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:26:06 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/54185399-a0f2-4a8a-ac62-b3f0aeaf4876/1767370954770.png" style="width: 700%;" class="fr-fic fr-dib"&gt;众所周知，「超级智能」是 Meta 持续不变的宏大愿景。&lt;/p&gt;&lt;p&gt;为了尽早达到构建超级智能的目标，扎克伯格在这一年里可谓是大刀阔斧，搞得 Meta 研究部门鸡飞狗跳。&lt;/p&gt;&lt;p&gt;前 Meta FAIR 领军人物 Yann LeCun 锐评：「通往超级智能&amp;hellip; 在我看来完全是胡扯，这条路根本行不通。」&lt;/p&gt;&lt;p&gt;不过，Meta 决定构建「超级智能」，一个真正能够超越人类专家水平的自主 AI 智能体，是人工智能研究中最具雄心的前沿目标。&lt;/p&gt;&lt;p&gt;AI 智能体执行任务最具代表性的落地领域就是编程了。目前，基于 LLM 的编程智能体已经展现出令人瞩目的自动化能力，但它们在本质上仍然受到一个根本性限制：&lt;strong&gt;高度依赖人类的训练数据&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;学习自 GitHub 等真实编程数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;需要手工撰写的 Bug 报告、Issue 描述；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;用已有的测试用例来反馈。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种依赖关系形成了一道关键瓶颈，使得这些系统只能不断打磨和复现既有人类知识，而难以真正走向自主发现新问题、探索新解法的道路。&lt;/p&gt;&lt;p&gt;为此，来自&lt;strong&gt; Meta FAIR 和 Meta TBD 实验室&lt;/strong&gt;的的一项全新研究工作，打破了这一关键瓶颈，提出了 &lt;strong&gt;SSR（自对弈 SWE-RL）&lt;/strong&gt;，旨在通过使软件代理能够自主生成学习经验，从而&lt;strong&gt;摆脱人类数据的限制&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;SSR 借鉴了 AlphaGo 等自对弈系统的成功经验，提出了一条通往「超智能软件智能体」的途径，这些智能体可以在无需现有问题描述、测试或人工监督的情况下，通过与真实代码库的交互来学习和改进。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ8obcqSDsUxwicg4yNArPAvjE63TUDiccibzy3G2KqNlv9I7D2uoYkVXGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4203703703703704" data-type="png" data-w="1080" data-width="1138" data-height="478" data-imgfileid="503525401" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5a01971b-9342-4e1b-aab2-4b37a74c1b1e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Toward Training Superintelligent Software Agents through Self-Play SWE-RL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.18552&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在本文中，研究团队&lt;strong&gt;提出了 Self-play SWE-RL（SSR），作为迈向超级智能软件智能体训练范式的第一步&lt;/strong&gt;。该方法几乎不依赖人工数据，仅假设能够访问带有源代码与依赖环境的沙盒化代码仓库，而不需要任何人工标注的 issue 或测试用例。&lt;/p&gt;&lt;p&gt;基于这些真实世界代码库，通过一种自博弈（self-play）的强化学习框架训练单一 LLM 智能体，使其能够不断自主注入并修复复杂度逐步提升的软件缺陷。在该过程中，每个缺陷均通过测试补丁（test patch）进行形式化描述，而非使用自然语言的 issue 描述。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SSR 的博弈方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SSR 的核心思想，是让大模型智能体通过一个持续循环的过程来自我进化。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ3gQgQL7pS1HiaPKhpu5943ZAl4WB70z2zuCxGVnzCRrL34lthFdWic2A/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.22037037037037038" data-type="jpeg" data-w="1080" data-width="1106" data-height="244" data-imgfileid="503525402" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0864f449-b7f7-48ac-9c0a-a5edb67a9c62/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 自对弈 SWE-RL（SSR）框架概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如图所示，同一个 LLM 策略被拆分成两个角色：Bug 注入智能体（bug-injection agent） 和 Bug 修复智能体（bug-solving agent）。这两个角色共享同一个容器化运行环境和同一套工具，但它们接收到的任务说明和目标约束不同。&lt;/p&gt;&lt;p&gt;具体来说：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bug 注入智能体&lt;/strong&gt;首先获得一个隔离的原始代码库环境，它的任务是通过生成一个包含必要文件的 &amp;ldquo;工件（artifact）&amp;rdquo; 来人为引入一个 Bug。随后系统会通过实际执行来验证该工件的一致性 &amp;mdash;&amp;mdash; 确保该 Bug 真实存在、可被复现。通过一致性验证的 Bug 工件会被视为有效样本，并提交给 Bug 修复智能体。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZVsFbm3fXrv5BicAwh0lsw7ka9KfK2h97de9TvBQJnicZmZQRRrgicmx9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3277777777777778" data-type="png" data-w="1080" data-width="1106" data-height="363" data-imgfileid="503525403" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b10d2d33-15b8-4a8c-9022-4488df054fee/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SSR 采用的两种主要 bug 注入策略：面向移除的方法（左）移除大量代码块，而历史感知方法（右）有选择地恢复 git 日志中的历史更改以引入真实的 bug 模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bug 修复智能体&lt;/strong&gt;则针对该 Bug 生成最终补丁，补丁是否成功由该 Bug 所定义的测试结果来验证。若修复失败，该失败过程会被视为一种 &amp;ldquo;高阶 Bug（higher-order bug）&amp;rdquo;，促使智能体在新的上下文中再次尝试。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ1gh1LHM8NwYMWicYI7W4s5ekaO9gwDml4YvDw3FwGBDG2KYKtSjQC8w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.13518518518518519" data-type="png" data-w="1080" data-width="2090" data-height="282" data-imgfileid="503525404" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/62ba6918-5d36-4af4-a324-1ce5cf9992d8/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 智能体 bug 修复过程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;最终，Bug 注入阶段的奖励信号 由一致性验证结果与修复结果共同构成，用于激励更高质量的 Bug 提案；Bug 修复阶段的奖励信号 则主要依赖测试结果。底层的同一个 LLM 策略模型会在这两种奖励信号的共同作用下进行联合更新。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;评估与测试&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 SWE-bench Verified 与 SWE-Bench Pro 两个基准测试上，对基础模型（Base Model）、传统强化学习方法（Baseline RL），以及 SSR 方法进行了系统对比。&lt;/p&gt;&lt;p&gt;Baseline RL 与 CWM 中的标准智能体强化学习类似，可以访问自然语言问题描述、通过测试与失败测试信息，以及评测脚本，强化学习过程本质上只是检查生成的解决方案是否通过这些给定测试。&lt;/p&gt;&lt;p&gt;相比之下，SSR 仅接触最原始的环境镜像，模型必须在完全没有任何问题描述和测试用例的情况下，通过自我对弈来自主发现问题、构造解决方案并进行验证。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZlnXpoSlia5tTO9AqGRnHO0uWhVAPlFBUP9PDXzC4tUHMibM3uyibghYew/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.375" data-type="png" data-w="1080" data-width="2168" data-height="812" data-imgfileid="503525405" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/da1614a9-ba21-476f-b674-158cf8565376/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如图所示，实验结果呈现出两个关键现象：&lt;/p&gt;&lt;p&gt;首先，即便在完全没有任务相关训练数据的情况下，SSR 在整个训练过程中仍然表现出&lt;strong&gt;稳定而持续的自我提升能力&lt;/strong&gt;。这表明，大型语言模型可以仅凭与原始代码库的交互，就逐步增强自身的软件工程能力（例如问题定位与修复能力）。&lt;/p&gt;&lt;p&gt;其次，在整个训练轨迹中，SSR 在两个基准测试上&lt;strong&gt;始终优于传统 Baseline RL&lt;/strong&gt;。这意味着，由模型自主生成的学习任务，比人工构造的数据提供了更丰富、更有效的学习信号。&lt;/p&gt;&lt;p&gt;在 &lt;strong&gt;SWE-bench Verified 与 SWE-Bench Pro &lt;/strong&gt;基准测试上，SSR 展现出显著的自我提升能力（分别&lt;strong&gt;提升 +10.4 与 +7.8 个百分点&lt;/strong&gt;），并在整个训练过程中持续超越依赖人工数据的基线方法 &amp;mdash;&amp;mdash; 尽管模型的评测对象仍然是自然语言描述的问题，而这些描述在自博弈训练阶段完全未出现过。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZibWfyOcWrU4t1oy3wKhu0aWgDnMUQMwe5zXqN8ROqIxGDeM68eqhhSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.2953703703703704" data-type="png" data-w="1080" data-width="1938" data-height="572" data-imgfileid="503525406" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c2c1cb48-6eee-467b-8438-c7b18dfa5fd6/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Self-play SWE-RL 的消融实验结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;消融实验结果表明，仅注入训练会降低整体性能，因为模型无法从任何 Bug 修复尝试中学习；仅修复训练同样表现较差，因为它缺乏由自我对弈持续生成的动态任务分布。&lt;/p&gt;&lt;p&gt;相比之下，自我对弈要求智能体不仅要修复 Bug，还要不断提出具有挑战性的 Bug，而这个过程本身就蕴含着丰富的学习内容：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;识别哪些测试可以通过；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以有意义的方式破坏系统功能；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;甚至刻意削弱测试以隐藏 Bug。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些行为不断扩展训练信号，并让模型持续暴露在新的失败模式之下。结果表明：一个持续进化、在线生成 Bug 并解决 Bug 的训练过程，是模型实现长期自我提升的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SSR 代表着在开发能够无需直接人工监督进行学习和改进的真正自主人工智能系统方面迈出了重要一步。&lt;/p&gt;&lt;p&gt;通过证明大型语言模型可以从真实世界的软件仓库中生成有意义的学习经验，这项工作为将人工智能训练扩展到人类策划数据集之外开辟了新的可能性。&lt;/p&gt;&lt;p&gt;该方法解决了当前人工智能开发中根本性的可扩展性限制。人工标注的训练数据昂贵、有限且可能存在偏差，为开发更强大的系统制造了瓶颈。SSR 的自生成课程有可能使训练在比目前通过传统数据收集方法更可行的问题上，数量级地更多样化和更具挑战性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZc3mtBCTdzB2fmhcx73Il2GIlvkP640ARSFP9PPdw80l6kAMJKddVmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.2824074074074074" data-type="png" data-w="1080" data-width="1154" data-height="326" data-imgfileid="503525407" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5cadd92b-f859-4f92-9a39-57a98620e499/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;随着 AI 系统能力日益增强，从真实世界环境中自主学习的能力对于开发能够在复杂问题解决场景中真正提供帮助甚至主导的智能体变得至关重要。SSR 的演示表明这种自主学习在软件领域是可行的，这为在其他技术领域实现类似能力指明了有前景的方向，尤其是在那些正式验证和迭代改进可行的领域。&lt;/p&gt;&lt;p&gt;尽管仍属早期成果，这些结果表明：未来的软件智能体或将能够在真实代码仓库中&lt;strong&gt;自主获取海量学习经验&lt;/strong&gt;，最终发展为在系统理解、复杂问题求解乃至从零构建全新软件方面超越人类能力的超级智能系统。&lt;/p&gt;&lt;p&gt;更多信息，请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>告别KV Cache枷锁，将长上下文压入权重，持续学习大模型有希望了？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:19:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a423d1bd-2785-49d7-bc2f-3b2bb71ced4b/1767370436779.png" style="width: 700%;" class="fr-fic fr-dib"&gt;人类已经走上了创造 AGI（通用人工智能）的道路，而其中一个关键方面是持续学习，即 AI 能通过与环境互动而不断学习新的知识和能力。&lt;/p&gt;&lt;p&gt;为此，研究社区已经在探索多种不同的道路，比如开发能够实时更新状态的循环神经网络（RNN），或者试图通过极大的缓存空间来容纳海量历史。然而，真正的 AGI 或许不应仅仅被动地「存储」信息，而应像人类一样在阅读中「进化」。&lt;/p&gt;&lt;p&gt;想象一下你生命中的第一次机器学习讲座：你或许记不清教授开口说的第一个单词，但那场讲座留给你的直觉和逻辑，此刻正潜移默化地帮助你理解这篇复杂的论文。这种能力的本质在于&lt;strong&gt;压缩&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;近日，Astera 研究所、英伟达、斯坦福大学、加州大学伯克利分校、加州大学圣地亚哥分校的一个联合团队提出的&lt;strong&gt;TTT-E2E（端到端测试时训练）&lt;/strong&gt;沿着这条 AGI 的必经之路迈出了重要一步。它彻底打破了传统模型在推理时静态不变的局限，让长上下文建模从一种「架构设计」进化为一种「学习问题」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526436" data-ratio="1.1814946619217082" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L91pFPQo6nVmntfVwrDZKta2wT0jpib9zHePeJsYwufXW0vz0F1miaGEg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=1" data-type="png" data-w="843" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d86dbfee-54e9-443e-9a3e-d72d6ce4a240/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该方法可以在测试阶段通过给定上下文的下一个 token 预测持续学习，&lt;strong&gt;将读取的上下文信息压缩至权重参数中&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LbnCnuMwLIJstLKBXAUzTfzRzZ30fmjP52urgw2ZVX26Gz9ibkJLGTuw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.24722222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526435" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8b5cd203-4aa8-4e8c-bed8-fe7193cb721e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：End-to-End Test-Time Training for Long Context&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.23675&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/test-time-training/e2e&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;困难是什么？召回与效率的永恒博弈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文开篇明确了当前长上下文建模的两难境地。&lt;/p&gt;&lt;p&gt;Transformer 的全注意力机制虽然在长文本上表现优异，但其推理成本随长度线性增长，这在处理 128K 甚至更长的上下文时会产生巨大的延迟压力。为了解决效率问题，业界曾转向循环神经网络（RNN）或状态空间模型（SSM，如 Mamba）。这些模型虽然拥有恒定的每 token 计算成本，但在处理超长文本时，性能往往会大幅下降，无法像 Transformer 那样有效利用远距离的信息。&lt;/p&gt;&lt;p&gt;这种性能下降的根源在于&lt;strong&gt;「压缩率」的固定&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;传统的 RNN 将无限的序列压缩进固定大小的状态向量中，这不可避免地会导致信息丢失。&lt;/p&gt;&lt;p&gt;于是，该团队思考：是否能找到一种方案，既能像 RNN 一样拥有恒定的推理延迟，又能像 Transformer 一样通过增加「存储空间」来维持长距离性能？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端到端的测试时训练（TTT-E2E）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TTT-E2E&amp;nbsp;&lt;/strong&gt;的核心思想是将模型在测试阶段（推理阶段）的行为定义为一个在线优化过程。&lt;/p&gt;&lt;p&gt;具体而言，当模型读取长上下文时，它不仅仅是在做前向传播，还在同步进行梯度下降。&lt;/p&gt;&lt;p&gt;这种方法基于这样一个逻辑：如果我们将上下文看作一份学习资料，那么模型在预测下一个 token 之前，可以先在已经读过的 token 上进行自监督学习。&lt;/p&gt;&lt;p&gt;通过这种方式，上下文中的信息就被编码进了模型的权重 W 中，而不是存储在外部的 KV Cache 里。这就像是在阅读一本书时，你不断根据新读到的内容修正自己的认知模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LxLWGXZfhRTtEtzVljVlSPeupTL0vASd976OUHUflVZlCJkfibajLN6w/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.5686274509803921" data-s="300,640" data-type="png" data-w="867" type="block" data-imgfileid="503526437" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1d492afd-8f97-4fca-9fc3-ef687273168e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lxyia5k9tWvPTHx6UnzibQw33DRUgLI5g2nIn583I1qicIlmUbZLhhNLSw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.8155452436194895" data-s="300,640" data-type="png" data-w="862" type="block" data-imgfileid="503526438" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7bcd8f11-c4f6-47fb-9a95-289c968f38f9/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了使这一构想在工程上可行且高效，团队引入了两大核心技术支撑。&lt;/p&gt;&lt;p&gt;首先是&lt;strong&gt;元学习（Meta-Learning）&lt;/strong&gt;。传统的模型在预训练时并未考虑测试时的更新逻辑，这会导致训练与测试的脱节。TTT-E2E 通过外层循环（Outer Loop）优化模型的初始化参数，使得模型「学会如何学习」，即经过少量测试时梯度更新后，能达到最优的预测效果。&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;架构的微调与滑动窗口的结合&lt;/strong&gt;。该团队意识到，如果完全摒弃注意力机制，模型会丧失局部精确记忆能力。因此，TTT-E2E 采用了一种混合架构：使用一个固定大小（如 8K）的滑动窗口注意力（SWA）来处理短期记忆，确保局部逻辑的严密；而对于超出窗口的长期记忆，则交给 TTT 更新后的 MLP 层来承担。这种设计模仿了生物记忆系统的层级结构：滑动窗口如同瞬时感官记忆，而动态更新的权重则如同长期经验。&lt;/p&gt;&lt;p&gt;为了平衡计算开销，团队在实现细节上也极具匠心。他们并非更新模型的所有层，而是&lt;strong&gt;仅针对最后四分之一的 Transformer 块进行 TTT&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;同时，他们为这些块设计了&lt;strong&gt;双 MLP 结构&lt;/strong&gt;，一个保持静态以锁定预训练知识，另一个则作为「快速权重」在测试时动态更新，从而解决了知识遗忘的问题。&lt;/p&gt;&lt;p&gt;详细的数学描述请参阅原论文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：性能与速度的双重飞跃&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验数据证明了 TTT-E2E 的强大潜力。研究团队在 3B 参数规模的模型上进行了系统性扩展实验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LBlO3Wevm1keiaQjmYcs6ic0PibnAiaoKZXRnRQnmGDNfId7HewRrdJonOQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=5" data-ratio="0.5962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526439" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3dd6a39f-ed30-4ba8-922d-bf25373714c4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在性能扩展性方面，TTT-E2E 展现出了与全注意力 Transformer 几乎一致的性能曲线。&lt;/p&gt;&lt;p&gt;随着上下文长度从 8K 扩展到 128K，其他 RNN 基准模型（如 Mamba 和 Gated DeltaNet）的测试损失在达到 32K 之后开始显著回升，这意味着它们无法处理更长的序列。而 TTT-E2E 的损失函数则持续下降，始终保持着对 Transformer 的追赶态势，甚至在某些指标上更优。&lt;/p&gt;&lt;p&gt;在推理效率方面，TTT-E2E 展现了压倒性优势。&lt;/p&gt;&lt;p&gt;由于它不需要存储海量的 KV Cache，其推理延迟不随上下文长度增加而改变。在 128K 上下文的测试中，TTT-E2E 的处理速度比全注意力 Transformer 快了 2.7 倍。&lt;/p&gt;&lt;p&gt;这意味着开发者可以在不牺牲模型表现的前提下，极大地降低长文本应用的响应时间。&lt;/p&gt;&lt;p&gt;然而，研究也坦诚地指出了天下没有免费的午餐。尽管推理极快，但 TTT-E2E 的训练成本目前仍然较高。由于训练时需要计算「梯度的梯度」（二阶导数），其在短上下文下的训练速度比传统模型慢得多。&lt;/p&gt;&lt;p&gt;不过，该团队提出，可以通过从预训练好的 Transformer 节点开始微调，或者开发专门的 CUDA 内核来弥补这一短板。&lt;/p&gt;&lt;p&gt;此外，在大海捞针（NIAH）这类极端依赖精确召回的任务中，全注意力模型依然是无可争议的霸主。这进一步印证了作者的观点：TTT 的本质是压缩和理解，而非逐字的暴力存储。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LbN3HxMh55ia9RC4wFVOBGLLDElMhCib6cnRNqkTSIaeicb4CdMJ49iajDw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.41203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526440" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/98bad152-abff-4727-ad5d-34b2188851d7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;通往无限长度的未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;TTT-E2E 的意义远不止于一个更快的算法。它标志着&lt;strong&gt;大模型正在从静态模型转变为动态个体&lt;/strong&gt;。在这一框架下，模型处理长文档的过程，本质上是一次微型的自我进化。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyyqS9585cwgmWiaoCh9ZVrX0rNyryWicekTbZU5vYMhr0q4fAfknaxh5g/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=7" data-ratio="0.3435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526542" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/768ba919-b815-4acf-bf61-cbe68df628b8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;这种「&lt;strong&gt;以计算换存储&lt;/strong&gt;」的思路，为我们描绘了一个充满想象力的未来：或许有一天，我们可以让模型在阅读一万本书的过程中不断调整自身，最终将人类的整个文明史浓缩进那跳动的参数矩阵之中，而无需担心硬件缓存的枯竭。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
