<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>将高质量内容融入AI生态，威立以科研智能塑造出版行业未来</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Tue, 03 Feb 2026 14:26:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;近期，威立执行副总裁兼总经理&lt;strong&gt;Jay Flynn&lt;/strong&gt;，威立高级副总裁兼学术出版全球负责人&lt;strong&gt;Liz Ferguson&lt;/strong&gt;及威立高级副总裁兼首席营销官&lt;strong&gt;Anna Reeves&lt;/strong&gt;到访中国市场，在威立北京办公室与威立全球副总裁兼中国区总裁张莫依女士深度对话，探讨了威立在科研出版及学术期刊方面的最新发展战略，与中国科研人员、机构和企业的合作方针，以及如何在AI时代向权威学术内容与科研信息服务合作伙伴转型。&lt;/p&gt;&lt;p&gt;&amp;ldquo;中国市场蕴藏着巨大机遇，且机遇远大于挑战。作为 40 多年前首批进入中国的国际出版机构之一，我们与中国各方都建立了深厚而持久的合作关系。现今，我们致力于利用人工智能技术和开放获取出版模式，不仅满足&amp;mdash;&amp;mdash;更要预判并超越合作伙伴不断变化的需求。&amp;rdquo;Jay 表示，&amp;ldquo;主动引领变革、持续创新并优化我们的策略，是威立与合作伙伴携手塑造未来的核心。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/QTPaID1kkvgk6Hb58ZtWhDVU8jx5Qpp76Tg6K4NpibVao9C52o95qbFrDT4WEO9F9AnR52y9gia0ziavAeicBOgchg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0733333333333333" data-s="300,640" data-type="png" data-w="150" data-imgfileid="502686094" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b202541a-b47f-4f54-ac60-fa1358565bf5/640.png" alt="图片" data-before-load-time="1770099589811" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 3%;"&gt;&lt;/strong&gt;作为全球领先的出版机构，威立如何看待人工智能目前对科研领域的变革作用？&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" target="_blank" rel="noopener noreferrer"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" rel="noopener noreferrer" target="_blank"&gt;&lt;/a&gt;&lt;strong&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" rel="noopener noreferrer" target="_blank"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c9e9ad12-c6b2-46fd-8f71-fead204939e8/1770099644235.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;以合作为基石，将高质量内容融入AI生态&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;2025年10月，威立推出业内首个&lt;strong&gt;人工智能网关（Wiley AI Gateway）&lt;/strong&gt;。不同于要求科研人员采用专有工具的封闭生态系统，该网关格外注重系统间的协同操作性，将学术内容与数据订阅服务无缝集成至当前主流人工智能平台。目前，Anthropic的Claude、AWS Marketplace、Mistral AI的Le Chat以及Perplexity均已实现与该网关的对接。&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;实际上，这一网关的打造初衷，正是帮助合作伙伴的内容在 AI 时代实现&amp;ldquo;数字化跃迁&amp;rdquo;，使其能够安全可控可信地融入 AI 生态。&lt;/p&gt;&lt;p&gt;&amp;ldquo;通过该网关，我们正将学术与专业内容转化为人工智能优化格式，同时保留引文完整性、研究方法背景，以及同行评审验证&amp;mdash;&amp;mdash;这些都是用户期待威立能够实现的核心价值。&amp;rdquo;Jay 表示，&amp;ldquo;我们正在打造一个全行业的解决方案，助力人工智能驱动型研究。未来，还会有更多国际出版机构参与其中。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/QTPaID1kkvgk6Hb58ZtWhDVU8jx5Qpp76Tg6K4NpibVao9C52o95qbFrDT4WEO9F9AnR52y9gia0ziavAeicBOgchg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0733333333333333" data-s="300,640" data-type="png" data-w="150" data-imgfileid="502686094" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b202541a-b47f-4f54-ac60-fa1358565bf5/640.png" alt="图片" data-before-load-time="1770099589811" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 2.65%;"&gt;为满足科研与教育界在人工智能方面的特定需求，威立还采取了哪些措施？&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" target="_blank" rel="noopener noreferrer"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" rel="noopener noreferrer" target="_blank"&gt;&lt;/a&gt;&lt;strong&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" rel="noopener noreferrer" target="_blank"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/41a51471-1394-4137-ac23-7847969159b0/1770099692579.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;倾听科研人员需求，助力负责任地使用AI&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;毫无疑问，人工智能正深刻变革行业格局与生态系统。&amp;ldquo;我们要确保在这一过程中充分关注科研人员的需求，并持续优化他们的使用体验。&amp;rdquo;Anna 表示。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;全球调研报告ExplanAItions&lt;/strong&gt;的基础上，威立于近期发布了科研人员人工智能使用现状报告&lt;strong&gt;ExplanAItions 2025&lt;/strong&gt;。&amp;ldquo;人工智能在科研人员日常工作中的使用率大幅增长。目前，全球 84% 的科研人员表示正在工作中使用人工智能工具。&amp;rdquo;Anna介绍道，&amp;ldquo;尽管科研人员对人工智能的应用前景持积极态度，他们也同时意识到需要负责任地使用这些工具。&amp;rdquo;&lt;/p&gt;&lt;p&gt;因此，威立在刚刚过去的11月推出了面向作者、编辑及审稿人的&lt;strong&gt;&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MjM5NTAxNzIzMg==&amp;mid=2650166838&amp;idx=2&amp;sn=0b8b17cf68d8a9e8697d4c923dc2582e&amp;scene=21#wechat_redirect" target="_blank"&gt;全新AI指南&lt;/a&gt;&lt;/strong&gt;，旨在为各个学科领域及工作流程中的学者提供支持，解决实际痛点问题。&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkuzw35n1l5k" data-pm-slice="0 0 []"&gt;&lt;strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/QTPaID1kkvgk6Hb58ZtWhDVU8jx5Qpp76Tg6K4NpibVao9C52o95qbFrDT4WEO9F9AnR52y9gia0ziavAeicBOgchg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0733333333333333" data-s="300,640" data-type="png" data-w="150" data-imgfileid="502686094" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b202541a-b47f-4f54-ac60-fa1358565bf5/640.png" alt="图片" data-before-load-time="1770099589811" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 2.74%;"&gt;&lt;/strong&gt;威立品牌升级方案如何体现其在中国市场的未来方向？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" rel="noopener noreferrer" target="_blank"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ba254db6-d9c8-4d7c-a655-c66f6f0963af/1770099731558.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;持续扩展旗舰期刊系列，强化与中国伙伴合作&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&amp;ldquo;中国科研人员在国际期刊上发表了大量高质量研究成果&amp;mdash;&amp;mdash;无论是科研成果的数量，亦或影响力都令人瞩目。&amp;rdquo;作为威立学术出版全球负责人，Liz 介绍了威立在中国的合作及发展现状，&amp;ldquo;2025年，威立期刊发表的内容中约 25% 来自中国。我们同时与中国战略合作伙伴们共同推出了多种高影响力期刊。&amp;rdquo;&lt;/p&gt;&lt;p&gt;她同时介绍了威立在推动期刊发展方面的创新策略，&amp;ldquo;通过推进开放获取、优化同行评审流程，以及整合创新技术来更好地服务中国及全球科研人员。&amp;rdquo;&lt;/p&gt;&lt;p&gt;目前，威立正重点推进旗舰期刊&lt;em&gt;&lt;strong&gt;Advanced Science&lt;/strong&gt;&lt;/em&gt;从物质科学领域向生命与健康科学领域扩展，而该期刊目前发表的生命与健康科学领域的高质量研究成果数量已与物质科学领域持平。未来，威立还将在其他发展迅速且高影响力的科研领域创办期刊，包括肿瘤学、生物医学工程、生物技术、环境科学和数字健康等，同时继续深化威立在物质科学领域的优势地位。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/QTPaID1kkvgk6Hb58ZtWhDVU8jx5Qpp76Tg6K4NpibVao9C52o95qbFrDT4WEO9F9AnR52y9gia0ziavAeicBOgchg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0733333333333333" data-s="300,640" data-type="png" data-w="150" data-imgfileid="502686094" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b202541a-b47f-4f54-ac60-fa1358565bf5/640.png" alt="图片" data-before-load-time="1770099589811" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 2.74%;"&gt;&lt;span data-mpa-action-id="mkw38emttw5" data-pm-slice="0 0 []"&gt;威立的最新期刊发展战略&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" rel="noopener noreferrer" target="_blank"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8c68aad9-5a97-450a-8fda-de8158959ca9/1770099775460.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkwe2sgyqma" data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/QTPaID1kkvgk6Hb58ZtWhDVU8jx5Qpp76Tg6K4NpibVao9C52o95qbFrDT4WEO9F9AnR52y9gia0ziavAeicBOgchg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0733333333333333" data-s="300,640" data-type="png" data-w="150" data-imgfileid="502686094" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b202541a-b47f-4f54-ac60-fa1358565bf5/640.png" alt="图片" data-before-load-time="1770099589811" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 2.74%;"&gt;当威立从传统出版机构向权威学术内容与科研信息服务合作伙伴转型时，我们在中国市场的承诺与计划是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkwe2sgyqma" data-pm-slice="0 0 []"&gt;&lt;a href="https://mp.weixin.qq.com/s/T1oONeXegiY1FuIti4SUDQ" rel="noopener noreferrer" target="_blank"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/73d1f4f3-1179-4198-a2de-096f71d62341/1770099790278.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>国产版Ollama来了，Clawdbot终于不只属于Mac和英伟达</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 03 Feb 2026 11:49:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜+0&lt;/section&gt;&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;这几天，AI 圈的头号 C 位莫过于这只「龙虾」：&lt;strong&gt;Clawdbot&lt;/strong&gt;（现在得叫它 OpenClaw 了），它几乎把一群开发者折腾得彻夜难眠。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1068" data-imgfileid="503531273" data-ratio="1.1986531986531987" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGTibSSVotZicsZhnHiaqw86b1gRTvWsZ3TZkpJrxLxPPAxevjQrke9XwGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="891" data-width="891" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1ea417bc-650c-48d6-99f8-08799be9ec64/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="5"&gt;为什么它这么火？因为和以前那些只会陪聊的 Chatbot 不同，Clawdbot 是个真正的「实干派」：它能接管你的电脑，在你睡觉时通宵写代码、修 Bug，甚至背着主人手搓出一套语音功能。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;更魔幻的是，随之诞生的 AI 社交平台 Moltbook 彻底刷屏了。在这个「AI 版 Reddit」上，150 万个 Agent 正通过自创语言和共谋进化，建立起背离人类掌控的独立机器社会与文化。&lt;/p&gt;&lt;p data-path-to-node="7"&gt;这听起来很酷，但随之而来的是「隐私的裸奔」与&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"data-path-to-node":"7","style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「钱包的哀嚎」&lt;/span&gt;。&lt;/p&gt;&lt;p data-path-to-node="8"&gt;当 Clawdbot 这样的 Agent 全面读取你的屏幕、扫描你的文件，并在后台疯狂消耗昂贵的 API 额度时，很多开发者早就开始思考一个问题：Agent 虽好，难道我们以后的一举一动都要通过云端计费吗？&lt;/p&gt;&lt;p data-path-to-node="9"&gt;这催生了另一个巨大的需求：&lt;strong&gt;Local Agent（本地智能体）&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;但在这一波浪潮中，算力并不是唯一的门槛。以 Clawdbot 为例，当前社区主流方案主要围绕 macOS 与 NVIDIA GPU 生态展开，这与 Ollama、llama.cpp 以及相关 Agent 工具链的成熟度密切相关。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;相比之下，尽管华为昇腾、燧原等国产算力已经具备运行大模型的能力，但在通用 Agent 工具链与社区生态适配方面仍存在明显差距，这使得部分开发者难以直接参与到当前主流的 Agent 实验与应用中。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;难道手握国产算力的开发者，只能眼巴巴看着这场狂欢吗？当然不是。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;国产显卡其实从来不缺「肌肉」，缺的只是一把趁手的「兵器」。如果说 Clawdbot 解决了「AI 怎么干活」的问题，那么我们今天要聊的这个工具，就是来解决「AI 在哪干活」的问题。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;&lt;strong&gt;2 月 2 日，清昴智能发布玄武 CLI 开源版本。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG2705pslwGfGCrZB0hD2S9vHSfvKpXzV34VZRWzMI2FnxMjNISCua1g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.5953703703703703" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503531275" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e1a73514-1ee8-4b77-ae18-e3d2474de33f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="15"&gt;你可以把它简单理解为「国产版 Ollama」，它旨在抹平硬件架构的差异，让基于国产卡的大模型部署进入「&lt;strong&gt;零门槛时代&lt;/strong&gt;」。不需要复杂的环境配置，&lt;strong&gt;5 分钟启动模型服务&lt;/strong&gt;，这不仅是企业降低部署成本的利器，更是每一位开发者激活手边国产算力的钥匙。&lt;/p&gt;&lt;p&gt;玄武 CLI 开源传送门：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;玄武 CLI GitHub 仓库：https://github.com/TsingmaoAI/xw-cli&lt;/li&gt;&lt;li&gt;玄武 CLI Gitcode 仓库：https://gitcode.com/tsingmao/xw-cli&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="18"&gt;别急着下单 Mac mini，你机箱里的「国货之光」其实早就准备好了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG0iaZQNft3fO4V8SBVBouRB0oOwuttLiaMWVvno4rs7aI11qolHWlgeFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.098148148148148" data-type="png" data-w="1080" data-width="1166" data-height="1280" data-imgfileid="503531274" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5d972558-97d0-46c7-8d3b-d75c6fdac167/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;&lt;strong&gt;开发者到底在和什么战斗？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;进入 2026 年，随着 DeepSeek、Kimi 等高性能开源模型的成熟，AI 推理形态正在从以云端为中心，逐步向本地与边缘侧扩展。出于对数据隐私（金融代码、医疗数据）和低延迟 Agent 交互的需求，&lt;strong&gt;本地化推理&lt;/strong&gt;正在成为清晰可见的趋势。&lt;/p&gt;&lt;p data-path-to-node="22"&gt;在 NVIDIA 和 Apple Metal 生态中，Ollama 凭借「一个二进制文件、一行命令」的极致体验，成为最具代表性的本地推理工具之一。然而，这种统一而简洁的使用方式，并未真正惠及中国主流国产算力用户。&lt;/p&gt;&lt;p data-path-to-node="23"&gt;尽管国产芯片在硬件指标上已具备相当竞争力，但在软件生态层面仍存在明显断层：工具链割裂、算子覆盖不足、社区适配滞后，正让开发者陷入一种新的焦虑：&lt;strong&gt;算力在手，却用不起来&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一张卡，一套世界观&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;与 CUDA 近乎统一的格局不同，国产芯片架构呈现出「百花齐放却互不相通」的态势。华为的 CANN、摩尔线程的 MUSA，以及各家自成体系的工具链彼此独立。&lt;/p&gt;&lt;p data-path-to-node="25"&gt;对开发者而言，每更换一张卡，几乎意味着重新学习一套构建系统。由于上游社区难以维护如此多且杂的后端分支，国产卡用户往往只能依赖功能滞后、稳定性不足的非官方适配版本。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;从入门到放弃的「配置长征」&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="27"&gt;想在国产卡上跑通一个高性能模型？往往是一场耐心与运气的双重考验：&lt;/p&gt;&lt;p data-path-to-node="27"&gt;驱动、固件、Toolkit、算子包必须严格对齐，错一个版本号就报错；少配一个环境变量，程序就可能当场崩溃；即使使用 Docker，也无法像 NVIDIA 那样 &lt;code&gt;--gpus all&lt;/code&gt; 一键搞定，而是要手动透传多个复杂设备节点。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;新模型「水土不服」&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="29"&gt;更具挑战的是，新一代模型架构（如 MoE、FP8 量化）在国产环境中往往缺乏成熟的高性能算子支持，，容易触发非最优执行路径，导致推理性能大幅下降。当遭遇模糊错误码时，开发者往往无从查证。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;这就是行业的真实切面：开发者想要的是「5 分钟启动服务」，现实给的却是「5 天还在配环境」。&lt;strong&gt;行业迫切需要一个能够抹平底层硬件差异、统一上层使用体验的中间层工具。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="31"&gt;&lt;strong&gt;玄武 CLI：国产算力的 Ollama 来了&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;如果说 Ollama 的成功来自「让 GPU 消失在用户视野中」，那么玄武 CLI 的目标则是「让国产 GPU 的差异性也消失」。&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;它关注的重点并不是单纯「能否运行模型」，而是如何在复杂的国产芯片生态中，提供一种更统一、更稳定的部署与调用体验。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGo0dcPENRL8gEqWAxtj39rpXEDSNj220eoJUXoU5SO3kaQ5gqoEw1rQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.3291796469366564" data-type="png" data-w="963" data-width="963" data-height="1280" data-imgfileid="503531276" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a15feb86-939a-4c7a-91ec-753d762d4c4e/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 玄武CLI的架构图。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;国产原生适配：一键搞定，告别配置噩梦&lt;/strong&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;在国产算力生态中，最大的痛点来自芯片架构的高度碎片化。不同厂商、不同型号，对应不同驱动、不同推理引擎与参数组合，部署往往意味着反复查文档、改配置、踩坑调试。&lt;/p&gt;&lt;p data-path-to-node="34"&gt;玄武 CLI 的核心价值之一，就是把复杂性收敛到系统内部：它能够自动识别华为昇腾全系列、沐曦、燧原等多款国产芯片&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;对用户而言，不再需要理解底层架构差异，也无需手动调参调环境，真正实现「零调试部署」，从根本上降低国产芯片的使用门槛。&lt;/p&gt;&lt;p data-path-to-node="12" data-pm-slice="0 0 []"&gt;&lt;strong&gt;零门槛上手：1 分钟部署，无缝兼容无压力&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="13"&gt;在使用体验上，玄武 CLI 走的是与 Ollama 同一条路线：极简、快速、低学习成本。用户无需安装 Python 或复杂依赖，只要基础驱动就绪，解压即可运行，最快 1 分钟启动服务。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;服务启动&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="15"&gt;一切始于一行简洁的命令 &lt;code data-index-in-node="12" data-path-to-node="15"&gt;xw serve&lt;/code&gt;。无需复杂的环境变量配置，系统直接完成运行时配置初始化与全局端口分配，唤醒后台守护进程。&lt;a href="https://mp.weixin.qq.com/s/RZhyl0rVTkZCV-cJ2ndAAw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8c417f46-e6ca-4b03-a7fa-945e1a4e7ac0/1770090278305.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;模型交互&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="17"&gt;模型运行同样丝滑。通过 &lt;code data-index-in-node="12" data-path-to-node="17"&gt;xw run&lt;/code&gt; 命令，系统能直接检测实例状态。若模型已就绪，即可秒级进入 Chat 会话模式，直接开始问答交互。&lt;a href="https://mp.weixin.qq.com/s/RZhyl0rVTkZCV-cJ2ndAAw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0cd43644-f2dc-42a1-8e5f-eef3db58a775/1770090294379.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;模型下载&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19"&gt;对于本地未获取的模型，告别繁琐的权重文件手动搬运与路径映射。通过 &lt;code data-index-in-node="33" data-path-to-node="19"&gt;xw pull&lt;/code&gt;，自动完成模型权重与配置文件的拉取，提供清晰的进度验证。&lt;a href="https://mp.weixin.qq.com/s/RZhyl0rVTkZCV-cJ2ndAAw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/465c39c0-88a5-43a6-b2f3-297db0364bd4/1770090306835.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG9Cn4kibZP18wNTKZFMCAmjKwvSvKHb1JiaEQY6ybSw8M6wAic1Cibn95ag/640?wx_fmt=jpeg#imgIndex=5" data-ratio="0.36666666666666664" data-type="jpeg" data-w="1080" data-width="3840" data-height="2088" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_jpg/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGCuvUthSCAL2wqo5cNO2CXzJ8WwGc607sNudGJXOWEnfy3n07XgHhLw/0?wx_fmt=jpeg&amp;from=appmsg" data-cropx2="1920" data-cropy2="704.2214532871973" data-backw="289" data-backh="106" data-imgfileid="503531301" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a0c113ad-2dfb-4a66-8109-8d7ac214eda7/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;玄武 CLI 目前已原生支持包括 &lt;strong&gt;DeepSeek、Qwen3、GLM-4.7、MiniMax 2.1&lt;/strong&gt; 等在内的数十款主流模型，并在今天已完成 GLM-OCR 的 Day0 适配，覆盖从端侧轻量级到千亿参数旗舰级模型。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;实例启动&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="22"&gt;得益于底层的极致优化，在执行 &lt;code data-index-in-node="15" data-path-to-node="22"&gt;xw start&lt;/code&gt; 启动实例时，系统能够自动调配 vLLM 等高性能后端。&lt;strong&gt;实测数据表明：即便是 32b 规模的模型，玄武 CLI 也能在 30 秒内完成启动。&lt;/strong&gt;这个时间内，系统会自动完成模型切分、显存加载，并成功启动推理引擎。&lt;a href="https://mp.weixin.qq.com/s/RZhyl0rVTkZCV-cJ2ndAAw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3081a90c-5c0b-40dd-8227-000d7e059cda/1770090391917.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="23"&gt;同时，&lt;strong&gt;玄武 CLI 在命令层面与 Ollama 高度一致&lt;/strong&gt;（如 &lt;code data-index-in-node="31" data-path-to-node="23"&gt;xw pull&lt;/code&gt; / &lt;code data-index-in-node="41" data-path-to-node="23"&gt;run&lt;/code&gt; / &lt;code data-index-in-node="47" data-path-to-node="23"&gt;ls&lt;/code&gt; / &lt;code data-index-in-node="52" data-path-to-node="23"&gt;stop&lt;/code&gt;），意味着会用 Ollama 就能直接上手玄武，几乎没有迁移成本。在应用层，它兼容 OpenAI API 接口，LangChain、LlamaIndex 以及各类 IDE 插件只需改一行 API 地址即可接入，无需重构原有应用栈。&lt;/p&gt;&lt;p data-path-to-node="24"&gt;在稳定性设计上，玄武 CLI 采用独立子进程架构，即使单个模型或任务出现异常，也不会影响整体服务，既适合个人开发者的轻量使用，也满足企业级稳定运行需求。&lt;/p&gt;&lt;p data-path-to-node="25"&gt;&lt;strong&gt;高性能与全保障并行：多引擎覆盖，风险提前规避&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="26"&gt;玄武 CLI 内置自研的清昴核心推理引擎 MLGuider，在性能层面提供稳定保障，同时支持多种推理引擎并行兼容。这种设计一方面可以覆盖更广、更新的模型版本，另一方面也避免对单一引擎的过度依赖，从工程角度提前规避风险。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGeogmxpWlNyYXoCIrYN7fF5WAkehYc0y7LA0mQ5X2Ura8xS34ZnWv0A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.37720111214087115" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503531305" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9bddccf8-5f3a-4317-8962-56c527d50fbb/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 推理服务流程图。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;多引擎并存，本质上是对兼容性与性能的双重极致优化。玄武 CLI 通过智能调度内置的 MLGuider 等引擎，能够深入芯片底层进行算子级调优，最大限度释放国产硬件算力。这种既保高性能推理、又顾模型多样性的策略，真正解决「国产卡能用但不好用」的核心问题。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;同时，玄武 CLI 支持完全离线运行，不依赖云端服务，在国产芯片上即可完成模型管理与推理任务，适合对数据安全和稳定性要求较高的场景。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;&lt;strong&gt;热门产品联动：拓展本地 AI 应用场景&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="31"&gt;在应用生态层面，玄武 CLI 并不只是一个「模型启动器」，而是一个本地 AI 能力的底座。它可以与 Clawdbot 等热门本地 AI 工具联动，为这些产品提供低门槛的模型部署与调用能力，使自动化任务与智能应用更容易落地。&lt;a href="https://mp.weixin.qq.com/s/RZhyl0rVTkZCV-cJ2ndAAw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d52862b3-7470-4e44-8f8b-bb2bff552a76/1770090427058.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;这种联动模式意味着，开发者不必重复解决模型部署问题，而可以把更多精力放在上层应用与业务逻辑上，从而放大本地 AI 工具的整体价值。&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;为什么是他们？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;玄武 CLI 的强大，源自其背后深厚的技术积淀。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;清昴智能是一家专注于&lt;strong&gt;芯片适配和模型-框架-算子联合调优&lt;/strong&gt;的全面领先 AI Infra 企业。创始团队来自清华大学计算机系，汇聚了来自斯坦福、新国立、爱丁堡大学以及华为、阿里、AMD 等全球顶尖机构的 AI 精英。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;创始人关超宇小学到大学 2 次跳级，15 岁进入本科，21 岁获得清华大学特奖、西贝尔学者等一系列殊荣，22 岁放弃华为天才少年、阿里星等大厂 offer，选择携手导师朱文武教授和前华为英雄个人和极客开发荣誉获得者姚航联合创业。他们不仅懂软件，更懂底层的芯片微架构以及如何攻克国产软件生态难题。&lt;/p&gt;&lt;p data-path-to-node="37"&gt;成立 3 年，即获得华为哈勃的战略注资，以及多家国内一线基金的上亿元财务投资。这不仅证明了其技术价值，更意味着其与国产芯片厂商有着深度的原厂级合作关系，能够第一时间获取底层驱动支持。&lt;/p&gt;&lt;p data-path-to-node="38"&gt;清昴智能并未止步于 CLI 工具。以自研的异构推理引擎 &lt;strong&gt;MLGuider &lt;/strong&gt;为核心，公司构建了从底层芯片到上层框架以及 Agentic AI 的全栈能力，致力于构建 AI 2.0 时代软件基础设施，为企业智能化转型和 AGI 实现打造坚实底座。&lt;/p&gt;&lt;p data-path-to-node="39"&gt;玄武 CLI 正是这一庞大技术愿景在开发者侧的「尖刀」产品，旨在通过极致的易用性打开市场缺口，构建生态护城河。&lt;/p&gt;&lt;p data-path-to-node="40"&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="41"&gt;技术，终究是要为人服务的。&lt;/p&gt;&lt;p data-path-to-node="42"&gt;过去几年，国产显卡用户面对的并非性能问题，而是生态问题：驱动、框架、工具链之间的割裂，使大量潜在算力长期处于「不可用状态」。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;玄武 CLI 的出现，或许不能立刻让国产生态「拳打英伟达，脚踢苹果」，但它至少做到了一件事：把梯子递到了墙边。&lt;/p&gt;&lt;p data-path-to-node="44"&gt;它让开发者不必再充当「环境配置员」，而能重新回到创造本身；也让那些躺在机箱里吃灰的国产显卡，重新开始发热、计算，参与到真实的 AI 实践之中。&lt;/p&gt;&lt;p data-path-to-node="45"&gt;想要一起推动生态进步？赶快到 GitHub 给它一个 Star 吧！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="17,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="17,0,0"&gt;玄武 CLI GitHub 仓库：&lt;/b&gt;https://github.com/TsingmaoAI/xw-cli&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="17,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="17,1,0"&gt;玄武 CLI Gitcode 仓库：&lt;/b&gt;https://gitcode.com/tsingmao/xw-cli&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，马斯克收购了马斯克</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 03 Feb 2026 11:38:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;一觉醒来，马斯克又搞了个大的。&lt;/p&gt;&lt;p&gt;旗下太空探索技术公司与人工智能公司合二为一了。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;SpaceX 正式宣布收购 xAI！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;目前，双方都已确认了这一消息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyejMI3Zp3ic8EP9GdLvLFqL8icJoichC2pibiazLHXAY2FvWQoHUERbxKCk0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531261" data-aistatus="1" data-original-style="height: auto !important;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/26af6145-e328-47e5-a830-0a669df8c588/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeHj4fNTRrVO18r8AvjqCjXO8oSHTSOicZVG8UOGOoFia5ZlTQ9JNMcfDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3074074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531262" data-aistatus="1" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3f3c6149-ec45-46f7-95e0-83c469bdffda/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据彭博社报道，合并后的公司预计将以每股约 527 美元的价格定价，其估值将达到 1.25 万亿美元。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;以下为 Elon Musk 签名公告全文：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SpaceX 已收购 xAI，旨在打造地球上（及地球之外）最宏伟的垂直整合创新引擎。该体系集成了人工智能、火箭技术、天基互联网、手机直连通信，以及全球领先的实时信息与言论自由平台。&lt;/p&gt;&lt;p&gt;这不仅是 SpaceX 和 xAI 使命的新篇章，更是开启了全新的篇章：通过规模化扩张打造「有意识的太阳」，以理解宇宙并将意识之光延伸至群星。&lt;/p&gt;&lt;p&gt;目前 AI 的进步依赖于大型地面数据中心，而这些中心需要海量的电力与散热支持。全球对 AI 的电力需求即便在短期内，也无法仅靠地面方案满足，否则将给社区和环境带来沉重负担。&lt;/p&gt;&lt;p&gt;从长远来看，天基 AI 是实现规模化扩张的唯一路径。想要利用太阳能量的百万分之一，所需的能源就已超过人类文明当前用电总量的百万倍！&lt;/p&gt;&lt;p&gt;因此，唯一的方案是将这些资源密集型项目转移至拥有广阔能源与空间的场所。毕竟，「空间」之所以被称为「空间」，自有其道理。&lt;/p&gt;&lt;p&gt;通过直接利用近乎永恒的太阳能，且几乎无需运行或维护成本，这些卫星将彻底改变我们扩展算力的能力。在太空中，永远是晴天！发射由百万颗卫星组成的轨道数据中心星座，是迈向「卡尔达肖夫 II 级文明」（能够利用太阳全部能量的文明）的第一步。这不仅能支撑起惠及当下数十亿人的 AI 应用，也将确保人类拥有多行星栖居的未来。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyefFoYy3DWXfjiaJQ4BkkibBsXfUmUReBRdkaee26ex1cktFxTzUts2O1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531263" data-aistatus="1" data-original-style="height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2ef1f083-34b7-47ef-8ba2-b2082ad377a4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在航天史上，从未有过任何运载工具能够发射「天基数据中心」、月球永久基地或火星城市所需的那种百万吨级载荷。即便是在轨道发射次数创下历史之最的 2025 年，入轨载荷总量也仅约 3000 吨，且其中大部分是由我们的猎鹰火箭（Falcon）运载的星链（Starlink）卫星。&lt;/p&gt;&lt;p&gt;发射数千颗卫星入轨的需求，成为了猎鹰计划的「强力函数」（Forcing Function），推动其通过递归改进达到了前所未有的发射频率，从而使天基互联网成为现实。&lt;/p&gt;&lt;p&gt;今年，星舰（Starship）将开始把性能更强劲的 V3 版星链卫星送入轨道，单次发射为星座增加的容量将是目前猎鹰火箭发射 V2 版星链的 20 倍以上。此外，星舰还将发射下一代手机直连卫星，为全球每一个角落提供完整的蜂窝网络覆盖。&lt;/p&gt;&lt;p&gt;虽然发射这些卫星的需求将同样作为「强力函数」来推动星舰的改进与发射频率，但天基数据中心所需的惊人卫星数量，将把星舰推向更高的高度。通过每小时一次、单次运载 200 吨的频率，星舰每年将向轨道及深空输送数百万吨载荷，开启人类在群星间探索的激动人心的未来。&lt;/p&gt;&lt;p&gt;基本的数学逻辑是：每年发射 100 万吨卫星，若每吨产生 100 kW 的计算能力，每年将增加 100 GW 的 AI 算力储备，且无需后续的运营或维护投入。最终，我们拥有一条从地球实现每年发射 1 TW 算力载荷的路径。&lt;/p&gt;&lt;p&gt;据我估计，在 2 至 3 年内，生成 AI 算力成本最低的方式将是在太空。仅凭这一成本优势，就足以让创新型企业在训练 AI 模型和处理数据方面取得前所未有的速度与规模，从而加速人类对物理学理解的突破，并催生造福全人类的技术发明。&lt;/p&gt;&lt;p&gt;这一新星座将建立在成熟的空间可持续性设计和运营策略之上（包括寿命末期的报废处理），这些策略在 SpaceX 现有的宽带卫星系统中已证明行之有效。&lt;/p&gt;&lt;p&gt;虽然从地球发射 AI 卫星是目前的重点，但星舰的能力同样支持在其他星球开展行动。得益于空间推进剂转移等技术的进步，星舰将具备在月球降落海量物资的能力。一旦抵达月球，我们便能建立起用于科学研究和制造业的永久基地。&lt;/p&gt;&lt;p&gt;月球工厂可以利用月面资源制造卫星并将其部署到更深远的太空。通过使用电磁质量投射器（Mass Driver）和月球制造，每年可向深空部署 500 到 1000 TW 的 AI 卫星，从而在「卡尔达肖夫等级」上实现实质性的跃升，并利用太阳能量中一个不可忽视的比例。&lt;/p&gt;&lt;p&gt;通过实现天基数据中心所释放的能力，将为月球上的自我生长基地、火星上的完整文明，以及最终向整个宇宙的扩张提供资金与技术支持。感谢你们为意识的光锥所做以及将要做出的一切。&lt;/p&gt;&lt;p&gt;评论区的网友有的已经开始为合并后的公司设计新名字了 &amp;mdash;&amp;mdash;SpaceXAI。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyewHqDbXkFevDE1ibMXcRVNEtYzpN6k8TUBylVdZXOHj6bQw6kBh78CNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.16111111111111112" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531264" data-aistatus="1" data-original-style="height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/9382609f-d057-42ac-81d3-263f773cb519/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;两家公司合并后是要打造 AI 原生的火箭吗？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeRzueRxYZF65sibZjmmnohPnhvXNO902HcuoC3RW92Ifc4NuMtUal5nA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.15092592592592594" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531265" data-aistatus="1" data-original-style="height: auto !important;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/fa20440d-afde-4c84-b15d-9cdb049c9d0f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有网友推测下一个合并目标可能是特斯拉。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeiapqdAtA3uYicjgoNu7tvWFAZSsVC13mIcMictZt6bbfdZz1nIdsUfibKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.15092592592592594" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531266" data-aistatus="1" data-original-style="height: auto !important;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1d162db2-8a90-48f2-b016-e18389168c51/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeBbQQ6VhpPywmrrGzk0MmwoVmZGMoWWxxsDia2DNaDv8glqR9WC3G86w/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.14907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531267" data-aistatus="1" data-original-style="height: auto !important;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ac8b48b1-551a-4ba0-9510-fbbcf7b7f0f0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;公告地址：https://www.spacex.com/updates&lt;a data-topic="1" href="javascript%3A;"&gt;#xai&lt;/a&gt;-joins-spacex&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://www.bloomberg.com/news/articles/2026-02-02/elon-musk-s-spacex-said-to-combine-with-xai-ahead-of-mega-ipo?srnd=phx-technology&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>重新定义“实时在线交互”，Soul App开源实时数字人生成模型SoulX-FlashTalk</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 03 Feb 2026 10:33:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;近期，Soul App AI团队（Soul AI Lab）已开源实时数字人生成模型SoulX-FlashTalk 。这是首个能够实现0.87s亚秒级超低延时、32fps高帧率，并支持超长视频稳定生成的14B数字人模型。&lt;/p&gt;&lt;p&gt;在持续建设AI能力的过程中，Soul团队始终致力于通过技术创新实现更沉浸、多元的交互体验。此次开源新模型，除了在速度、效果、延迟和保真度上表现出色，更重要的是，为行业提供了切实可应用的业务解决方案，推动大参数量实时生成式数字人迈入可具体商用落地阶段。&lt;img src="https://image.jiqizhixin.com/uploads/editor/bff004f2-3e16-4f58-94a0-5ab8d69f288b/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;Project Page: &lt;a href="https://soul-ailab.github.io/soulx-flashtalk/"&gt;https://soul-ailab.github.io/soulx-flashtalk/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Technical Report: &lt;a href="https://arxiv.org/pdf/2512.23379"&gt;https://arxiv.org/pdf/2512.23379&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Source Code: https://github.com/Soul-AILab/SoulX-FlashTalk&lt;/p&gt;&lt;p&gt;HuggingFace:&lt;a href="https://huggingface.co/Soul-AILab/SoulX-FlashTalk-14B"&gt;https://huggingface.co/Soul-AILab/SoulX-FlashTalk-14B&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;SoulX-FlashTalk亮点：&lt;/strong&gt;&lt;strong&gt;四大关键指标，重塑实时互动体验&lt;/strong&gt;&lt;/h3&gt;&lt;h4&gt;&lt;strong&gt;0.87s 亚秒级延时，即时交互&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;在实时视频交互中，延迟是决定用户体验的核心。SoulX-FlashTalk 凭借全栈加速引擎的极致优化，成功将首帧视频输出的延时降至0.87s亚秒级。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&amp;ldquo;零延迟&amp;rdquo;即时反馈： 首次让 14B 级大模型数字人具备了即时反应能力，彻底消除了传统大模型生成的&amp;ldquo;滞后感&amp;rdquo;。&lt;/li&gt;&lt;li&gt;全场景交互： 无论是视频通话中的即时对答、直播间弹幕的秒级互动，还是智能客服的实时响应，均能实现自然、流畅的深度对话。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;32fps 高帧率，重新定义&amp;ldquo;流畅&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管搭载了 14B 参数量的超大 DiT 模型，SoulX-FlashTalk 的推理吞吐量仍高达 32 FPS。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;超越行业标准：远超直播所需的 25 FPS 实时标准，确保每一帧画面都丝滑顺畅。&lt;/li&gt;&lt;li&gt;大模型，高性能：证明了 140 亿参数大模型在经过深度加速优化后，依然可以拥有极佳的运行效率。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;超长视频稳定清晰生成，告别画面&amp;ldquo;崩坏&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数字人视频最怕在生成中出现人物面部不一致或显著画质下降的问题。SoulX-FlashTalk 凭借独家的自纠正双向蒸馏技术，解决了这一痛点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;无感纠错，画质无损：引入多步回溯自纠正机制，模拟长序列生成的误差传播并进行实时修正，就像为 AI 装上了&amp;ldquo;实时校准器&amp;rdquo;，主动恢复受损特征。&lt;/li&gt;&lt;li&gt;超长视频，稳定生成： 不同于传统的单向依赖，SoulX-FlashTalk 完全保留了双向注意力机制，让每一帧生成都能同时参考过去与隐含的未来上下文，从根本上压制身份漂移，这意味着在超长直播中，主播的口型、面部细节和背景环境将始终保持一致，不会出现模糊或变形。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;全身动作交互：不只是&amp;ldquo;口型对齐&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SoulX-FlashTalk 突破了传统数字人仅能实现面部&amp;ldquo;对口型&amp;rdquo;的局限，带来了更加真实自然的全身肢体动态表现。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全身肢体动态合成： 不同于仅对脸部进行局部重绘的方案，SoulX-FlashTalk 支持受音频驱动的全身动作生成，产生真实自然的人体动态。&lt;/li&gt;&lt;li&gt;高精细手部表现： 基于14B DiT的强大建模能力，系统能够有效消除手部畸形与运动模糊，精准呈现结构清晰、纹理锐利的手部动作细节。&lt;/li&gt;&lt;li&gt;灵动而不失稳定： 在追求大幅度动态表现力的同时，系统依然维持了极高的身份一致性（Subject-C 达 99.22），实现了动作灵活性与画面稳定性的完美平衡。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;strong&gt;核心方案：&lt;/strong&gt;&lt;strong&gt;双向蒸馏+多步回溯自纠正机制&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;在行业中，传统数字人生成方案大多面临画面生成时间长、延迟高、生成效果差、效果不稳定、保真度低等问题。&lt;/p&gt;&lt;p&gt;在这样的背景下，SoulX-FlashTalk正式开源，为了平衡生成质量与推理速度，团队采用了两阶段训练策略：&lt;/p&gt;&lt;p&gt;第一阶段：延迟感知时空适配 (Latency-Aware Spatiotemporal Adaptation)，结合动态长宽比分桶策略进行微调，使模型适应较低的分辨率和更短的帧序列；&lt;/p&gt;&lt;p&gt;第二阶段：自纠正双向蒸馏 (Self-Correcting Bidirectional Distillation)。利用 DMD 框架压缩采样步数并移除无分类器引导（CFG），实现加速；多步回溯自纠正机制，通过 autoregressively 合成连续分块（最多 K个chunks），显式模拟长视频生成的误差传播；随机截断策略，在训练中在第 k（&amp;lt; K）个分块数进行反向传播，实现高效且无偏的显存友好优化 。&lt;img src="https://image.jiqizhixin.com/uploads/editor/8378b985-0400-4101-89c9-d92a3695d76a/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 训练流程示意图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;同时，团队进行实时推理加速系统优化， 针对 8-H800 节点设计的全栈加速引擎实现了亚秒级延迟 ，包括了&lt;/p&gt;&lt;ul&gt;&lt;li&gt;混合序列并行 (Hybrid Sequence Parallelism)：整合 Ulysses 和 Ring Attention，使单步推理速度提升约5倍算子级优化：采用针对Hopper架构优化的FlashAttention3，通过异步执行进一步减少 20% 的延迟&amp;nbsp;&lt;/li&gt;&lt;li&gt;3D VAE 并行化：引入空间切片并行解码策略，实现VAE处理的5倍加速&lt;/li&gt;&lt;li&gt;整链优化：通过 torch.compile 实现全流程图融合与内存优化&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，在Soul AI团队发布的技术报告中指出，传统的单向（Unidirectional）模型在处理全局时间结构时存在约束，容易导致时间不一致和身份漂移。因此，团队完全保留双向注意力机制（All-to-All 交互），使模型能同时利用过去与隐含的未来上下文，显著提升了生成的一致性与细节质量 。&lt;img src="https://image.jiqizhixin.com/uploads/editor/0933abbd-53e5-43a1-8a99-4e9c93a7f749/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; SoulX-FlashTalk推理架构流程图&lt;/sup&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;+&lt;/strong&gt;&lt;strong&gt;实时体验，&lt;/strong&gt;&lt;strong&gt;赋能行业多元业务场景&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;从模型表现来看，通过在 TalkBench-Short 和 TalkBench-Long 数据集上的定量对比，展示了SoulX-FlashTalk在视觉质量、同步精度及生成速度上的全面领先：&lt;/p&gt;&lt;p&gt;在短视频评测中，它以3.51的ASE和4.79的IQA刷新了视觉保真度记录，并以1.47的Sync-C分数表现出最优的口型同步精准度；在5分钟以上的长视频生成中，系统凭借双向蒸馏策略有效抑制了同步漂移，取得了1.61的Sync-C优异成绩；此外，作为14B参数规模的大模型，它在长短视频任务中均维持了32 FPS 的高吞吐量，不仅远超25 FPS的实时性基准，更在推理效率上显著优于行业同类主流模型。&lt;img src="https://image.jiqizhixin.com/uploads/editor/2f861bd8-94a8-4d0a-9c86-ff91f633d3a9/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;依托模型优越的性能表现，开源后，SoulX-FlashTalk将有机会在多领域、行业实际落地，创造更多价值。例如，在电商领域打造7&amp;times;24小时AI直播间，特别是，此前传统的数字人直播长时间运行后常会出现嘴型对不上或画质模糊的问题，而SoulX-FlashTalk可以支持全天候的流畅视频直播，即便是在高强度的实时互动中（如回复弹幕），也能保持如同真人出镜的高保真画质，极大降低直播成本。&lt;/p&gt;&lt;p&gt;此外，在短视频制作、AI教育、多元互动场景NPC交互、AI客服等方向，模型也提供了高质量、可落地、可接入业务系统的解决方案。&lt;/p&gt;&lt;p&gt;对Soul而言，SoulX-FlashTalk的发布也意味着团队进入了开源新阶段。去年10月底，Soul AI团队开源语音合成模型SoulX-Podcast，在发布后快速登顶开源社区平台HuggingFace TTS（Text To Speech）趋势榜，目前该模型在GitHub上收获了超3100星标。&lt;/p&gt;&lt;p&gt;接下来，在聚焦语音对话合成、视觉交互等核心交互能力的提升，为用户带来更加沉浸、智能且富有温度的交互体验的过程中，以持续推进开源工作为契机，Soul将积极与全球开发者携手，共建生态，为推动&amp;ldquo; AI +社交&amp;rdquo;方向前沿能力建设贡献力量。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>全球304个中文大模型实测：没有“全能王者”，ReLE凭70%降本方案破解评估困局</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 03 Feb 2026 10:32:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;中文大模型正迎来爆发式增长，2024-2025年间每月新增10-15个模型，但行业长期被两大痛点困扰：传统基准数据集饱和失效，顶尖模型性能逼近天花板后得分趋同；评估成本居高不下，300+模型全量评估需超6.9万美元，且单模型适配耗时超1小时。更关键的是，单一聚合得分掩盖了模型的能力权衡&amp;mdash;&amp;mdash;一个平衡评估中排第8的模型，在专业场景可能暴跌至32名。&lt;/p&gt;&lt;p&gt;针对这些问题，非线智能、华为、中国平安、绿盟科技、 中山大学、香港科技大学（广州）、等机构联合研发了 &lt;strong&gt;ReLE（Robust Efficient Live Evaluation）&lt;/strong&gt;中文大模型评估系统。该系统通过207,843个样本，对304个中文LLM（189个商业模型、115个开源模型）完成大规模测评，创新提出动态方差感知调度与混合验证评分机制，在保证排名相关性&amp;rho;=0.96的前提下，将评估成本降低70%。更重要的是，ReLE首次量化揭示中文LLM的&lt;strong&gt;能力各向异性&lt;/strong&gt;（Capability Anisotropy）：模型排名稳定性振幅（RSA）达11.4，是传统基准的2.3倍，证明当前大模型多为&amp;ldquo;专业化选手&amp;rdquo;而非&amp;ldquo;全能冠军&amp;rdquo;。相关研究成果已作为预印本发布，为中文LLM的训练优化与工业选型提供了全新诊断工具。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/17f83cb9-8a8f-45df-ba3c-30c56fecb38f/1770085772459.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文：&lt;/strong&gt; [arXiv链接] &lt;a href="https://arxiv.org/abs/2601.17399"&gt;https://arxiv.org/abs/2601.17399&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Github项目：&lt;/strong&gt; [链接]&lt;a href="https://github.com/jeinlee1991/chinese-llm-benchmark"&gt;https://github.com/jeinlee1991/chinese-llm-benchmark&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术架构拆解：三大核心创新破解传统评估困局&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ReLE的核心突破在于&amp;ldquo;结构化诊断+高效评估&amp;rdquo;的双重设计，其模块化架构通过五大组件形成闭环，重点解决了接口标准化、评分鲁棒性、成本可控性三大技术难题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 统一提示Schema：消除跨模型格式偏差&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统评估中，不同模型的聊天模板（如ChatML、Alpaca）差异导致性能偏差，ReLE设计了统一提示框架，覆盖12类任务类型与7大核心领域，包含输入内容、输出格式要求、领域标签三大核心字段。&lt;/p&gt;&lt;p&gt;针对DeepSeek-R1等推理型模型，系统新增思维链触发扩展，可分离模型的推理过程与最终答案，避免&amp;ldquo;逻辑正确但格式不符&amp;rdquo;的误判。更关键的是，模型适配层能自动将标准化提示映射为目标模型的原生模板，标注者间一致性达96.8%，新增模型时无需重构评估流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 混合验证评分：攻克推理任务假阳性难题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为平衡评估规模与准确性，ReLE采用三级评分机制，重点解决了传统嵌入相似度评分的假阳性问题：&lt;/p&gt;&lt;p&gt;&amp;bull;客观任务（68%）：通过精确字符串匹配或符号相等性检查（如数学答案），实现100%精度评分；&lt;/p&gt;&lt;p&gt;&amp;bull;半客观任务（24%）：采用&amp;ldquo;BGE-M3语义过滤+GPT-4o判断+偏差校准&amp;rdquo;的级联策略&amp;mdash;&amp;mdash;相似度&amp;gt;0.92或&amp;lt;0.60的样本自动标注，模糊样本（0.60-0.92）由Judge模型评估。通过500个对抗样本的盲 ablation 校准，Judge模型与人类标注的Cohen&amp;#39;s &amp;kappa;=0.81，即使对非OpenAI模型，&amp;kappa;仍保持0.79，几乎无厂商偏见；&lt;/p&gt;&lt;p&gt;&amp;bull;智能体任务：聚焦工具选择准确率、步骤冗余度等复合指标，适配多智能体场景评估。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 动态方差感知调度：70%成本降低的关键&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ReLE创新性地将心理测量学中的计算机自适应测试（CAT）原理引入LLM评估，设计分层序贯方差缩减采样策略：&lt;/p&gt;&lt;p&gt;1.方差探测阶段：对每个模型抽取5%样本，估算各能力维度的初始方差Sᵢⱼ&amp;sup2;，建立模型&amp;ldquo;稳定性画像&amp;rdquo;；&lt;/p&gt;&lt;p&gt;2.动态分配阶段：基于Neyman分配原则，按公式nₕ,ₘ*&amp;prop;WₕSₕ,ₘ/&amp;radic;cₕ动态分配样本（Wₕ为维度权重，cₕ为该维度单样本成本），对稳定模型裁剪冗余样本，向高方差边界案例倾斜资源；&lt;/p&gt;&lt;p&gt;3.停止条件：采用Hoeffding-Serfling边界控制置信区间宽度，确保评估精度的同时终止无效采样。&lt;/p&gt;&lt;p&gt;对比传统全量评估，该策略将304个模型的评估成本从6.9万美元降至2.07万美元，成本降低70%，且与全量评估的排名相关性达&amp;rho;=0.96，验证了高效与精准的统一。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基准设计：20万样本构建&amp;ldquo;领域&amp;times;能力&amp;rdquo;正交矩阵&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ReLE的诊断能力源于其结构化基准设计，首次实现&amp;ldquo;领域知识&amp;rdquo;与&amp;ldquo;认知能力&amp;rdquo;的解耦，避免传统基准的能力 conflation 问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据集：新鲜性与去污染双保障&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数据集规模达207,843个样本，由三部分构成：&lt;/p&gt;&lt;p&gt;&amp;bull;动态新鲜集（45%）：2024年6月-2026年1月新增样本，含2025年高考题、最新工业 regulations，确保与2025年中前发布模型的训练数据无重叠；&lt;/p&gt;&lt;p&gt;&amp;bull;求解器验证学术精炼集（35%）：基于Math24O等数据集进行数值扰动，经SymPy/WolframAlpha符号求解器验证与10%人工抽样审核，保证数学逻辑一致性；&lt;/p&gt;&lt;p&gt;&amp;bull;领域专用私有集（20%）：金融、医疗等行业私有案例，作为严格隔离的泛化测试集。&lt;/p&gt;&lt;p&gt;为应对数据污染，ReLE实施&amp;ldquo;N-gram+语义&amp;rdquo;双级去重：13-gram检查排除显性重叠，BGE-M3嵌入语义去重（相似度&amp;gt;0.85样本丢弃）防范&amp;ldquo;软记忆&amp;rdquo;；同时引入5000个2025年10月新增的私有锚定集（PAS），通过计算泛化差距&amp;Delta;₉=|公开集得分-私有集得分|，标记过拟合模型（&amp;Delta;₉&amp;gt;15%）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;分类体系：7&amp;times;22正交矩阵拆解能力维度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ReLE构建了严格的&amp;ldquo;领域（D）&amp;times;能力（C）&amp;rdquo;正交矩阵，将评估空间拆解为7个核心领域、22个 primary 维度、317个子任务：&lt;/p&gt;&lt;p&gt;&amp;bull;领域维度（D）：覆盖STEM（教育/科学）、医疗健康、金融、法律与政策、通用语言、智能体与工具等7大场景；&lt;/p&gt;&lt;p&gt;&amp;bull;能力维度（C）：包含知识检索、逻辑推理、指令遵循、开放式生成4类核心认知能力。&lt;/p&gt;&lt;p&gt;这种设计可精准定位模型失效原因&amp;mdash;&amp;mdash;例如&amp;ldquo;高考数学题&amp;rdquo;被归类为Dₑₙᵤ&amp;cap;C_推理，&amp;ldquo;医疗伦理题&amp;rdquo;归为D_ₘₑd&amp;cap;C_知识，从而区分模型是缺乏领域知识还是推理能力不足。数据显示，专业领域（医疗、金融等）内部相关性为0.54-0.61，而专业领域与通用领域（推理、语言）的相关性仅0.26，印证了能力解耦的必要性。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/30c83915-50e2-4103-8ae2-3608408df435/1770085792562.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实证发现：中文LLM的三大关键真相&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于304个模型的大规模测评，ReLE揭示了中文大模型发展的核心特征，对工业选型与训练优化具有直接指导意义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 能力各向异性显著：没有&amp;ldquo;全能模型&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ReLE定义各向异性指数Iₐₙᵢₛₒ=1-平均维度间Pearson相关系数，实测得Iₐₙᵢₛₒ=0.74，意味着一个领域的高性能无法预测另一个领域的表现。&lt;/p&gt;&lt;p&gt;从能力雷达图可见，商业模型、开源模型、多智能体模型的能力轮廓均呈&amp;ldquo;不规则形状&amp;rdquo;：商业模型在医疗健康领域平均得分70.1，领先开源模型11.8分，但在通用推理领域差距缩小至2.4分；多智能体模型在工具使用任务中以74.8分大幅领先（商业模型62.4分），但在金融领域表现平平。这一发现打破了&amp;ldquo;高综合得分=全能&amp;rdquo;的认知。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6c693448-8c25-4156-80bb-c653f3882da1/1770085978845.png" style="width: 28.07%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 排名稳定性极差：RSA=11.4 vs 传统基准5.0&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ReLE设计了三种权重方案（平衡型、专业型、推理型）测试排名稳定性，结果显示：&lt;/p&gt;&lt;p&gt;&amp;bull;中文LLM平均排名稳定性振幅（RSA）达11.4，是传统基准（C-Eval/CLUE）的2.3倍（传统基准RSA&amp;asymp;5.0）；&lt;/p&gt;&lt;p&gt;&amp;bull;65%的模型（197/304）RSA&amp;ge;10，23%的模型（70/304）RSA&amp;ge;20，极端案例中，Gemini-3-Pro在平衡权重下排第1，在成本敏感（推理权重50%）场景下暴跌至第12名；&lt;/p&gt;&lt;p&gt;&amp;bull;控制实验验证，94.8%的排名波动源于模型自身能力 anisotropy，仅5.2%来自采样噪声，证明这是模型的固有属性。&lt;/p&gt;&lt;p&gt;这意味着，单一场景的排名对工业选型参考价值有限，必须结合具体任务权重进行结构化诊断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 性价比与专业化成关键：中小企业无需追&amp;ldquo;高价模型&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实证数据显示，中文LLM市场已呈现清晰的专业化与性价比特征：&lt;/p&gt;&lt;p&gt;&amp;bull;性价比甜点明确：定价1-5元的商业模型，在22个维度中的8个维度表现与&amp;ge;5元的高价模型相当，平均差距&amp;le;3.2%，对多数场景而言， mid-tier 模型是最优选择；&lt;/p&gt;&lt;p&gt;&amp;bull;专业化训练优于参数堆砌：多智能体模型的工具使用能力与专项指令微调相关性达0.65，远高于与参数规模的相关性（0.48）；18%的&amp;ge;20B参数模型仍会在字符笔顺等基础任务上失败，证明规模并非万能；&lt;/p&gt;&lt;p&gt;&amp;bull;41%的模型存在基准过拟合：这些模型在C-Eval等传统基准上平均得分73.2，但在ReLE的专业子任务中仅得48.5分，泛化能力薄弱。&lt;/p&gt;&lt;p&gt;此外，ReLE还发现领域特异性失败模式：医疗领域41%的失败源于知识缺失，推理领域37%的失败是逻辑错误，而这些细节在传统基准的聚合得分中无法体现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;产业价值与未来方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ReLE的核心价值在于，将中文LLM评估从&amp;ldquo;静态排名&amp;rdquo;推向&amp;ldquo;动态诊断&amp;rdquo;，为行业提供了兼顾成本与精度的解决方案。&lt;/p&gt;&lt;p&gt;对模型训练而言，41%的过拟合率提示行业需从&amp;ldquo;单分数优化&amp;rdquo;转向&amp;ldquo;多目标训练&amp;rdquo;，平衡专业深度与通用广度；对工业选型而言，性价比数据与能力 anisotropy 诊断，可帮助企业避开&amp;ldquo;高价陷阱&amp;rdquo;，选择任务适配的专业化模型；对多智能体系统设计而言，工具使用能力与指令微调的强相关性，为模型优化指明了方向。&lt;/p&gt;&lt;p&gt;未来，ReLE计划进一步扩展至9个核心领域，新增工业物联网等新兴场景；同时引入安全合规模块，适配GB/T 45654-2025国家标准，评估模型在输入安全、内部稳定性、输出安全等维度的 anisotropy；此外，还将逐步开源2.1M+失败案例库与评估脚本，推动社区共建更可靠的中文LLM评估生态。&lt;/p&gt;&lt;p&gt;正如研究团队强调的，ReLE并非要替代传统静态基准，而是成为中文大模型生态的&amp;ldquo;高频诊断监视器&amp;rdquo;。在模型迭代周更新的当下，只有动态、结构化、低成本的评估工具，才能真正支撑AI技术从&amp;ldquo;实验室&amp;rdquo;走向&amp;ldquo;产业落地&amp;rdquo;，而ReLE的出现，正填补了这一关键空白。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>真正释放生成式AI潜力：亚马逊云科技提出黄金三角方法论</title>
      <description>&lt;![CDATA[用领先云和AI技术和服务，加速数字化转型和业务创新。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Mon, 02 Feb 2026 16:42:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;在全球化的复杂商业环境中，跨国企业与中国本土企业正面临着共同的挑战：如何在「内卷」与「出海」的双重压力下，利用生成式 AI 找到新的增长极。&lt;/p&gt;&lt;p&gt;在本周亚马逊云科技中国区举行的媒体沟通会上，这家全球最先进的 AI 基础设施提供商给出了答案。&lt;/p&gt;&lt;p&gt;在强调「深耕本地、链接全球」的战略愿景之外，亚马逊云科技成长型企业及新兴业务总经理倪殿令详细拆解了企业落地生成式 AI 的「黄金三角」方法论，并联合全球化企业、分析机构共同介绍了在亚马逊云科技服务之上，AI 技术应用的最新洞察。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/72500aca-beb4-4f74-8732-9f194164b33d/QQ20260131-154457__1_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;「过去三年，生成式 AI 席卷了所有产业，我们看到了大模型、Agent（智能体）等技术带来的变化。但客户关心的不再仅仅是 AI 技术本身，而是如何用它解决实际问题，」倪殿令表示。&lt;/p&gt;&lt;p&gt;在与大量企业进行合作，与 CEO、业务负责人的交流中，亚马逊云科技总结出了一套名为「黄金三角」的落地法则，即围绕业务战略，实现场景（Scenario）、数据（Data）和人才（Talent）的动态平衡。&lt;/p&gt;&lt;p&gt;1. 场景：进入智能体接管时代。倪殿令认为，企业需要找到既能创造价值，又适合 AI 解决的具体场景。目前的趋势正在从简单的「Frontier Model」向能够独立工作的「Frontier Agents」演进。&lt;/p&gt;&lt;p&gt;例如，麦肯锡内部已有 2.5 万个 Agent 在支持 4 万多名员工的工作，而亚马逊云科技也推出了针对中国市场的 Strands Agents SDK，能够帮助企业快速构建从自主理解、规划到执行任务的智能体。&lt;/p&gt;&lt;p&gt;2. 数据：冰山之下的 90%。「对于生成式 AI 应用而言，最重要的其实是数据。」倪殿令用「餐馆」对生成式 AI 时代做了一个比喻：大模型是厨师，人们的查询请求是点菜，而底层的数据处理（清洗、切配、归类）则是后厨最繁重的工作。人们向 Agent 的提问，背后需要依赖大量的数据分发和处理。&lt;/p&gt;&lt;p&gt;他强调，一家企业能否发挥 AI 效能，核心不在于前端的模型调用，而在于底层高效的数据处理能力以及向量数据的存储。这部分能力在 AI 应用成功要素中占比高达 90% 以上。无论是 RAG（大模型的检索增强生成）、模型微调还是蒸馏，都需要坚实的数据基础设施支撑。&lt;/p&gt;&lt;p&gt;在这方面，亚马逊云科技强大的 Amazon EMR 服务，可以帮助人们快速进行「原材料」的处理。&lt;/p&gt;&lt;p&gt;3. 人才：共创与迭代。针对 AI 人才短缺的挑战，亚马逊云科技在中国提出了「共创 + 培养 + 迭代」的模式，通过与高校合作、提供 Skill Builder 等全方位技术培训、认证以及与招聘公司合作构建 AI Agent，让他们提升猎头顾问的效率。从而帮助企业解决「人」的问题。&lt;/p&gt;&lt;p&gt;在全球化背景下，跨国企业在华展业面临着新的挑战。沙利文中国研究总监李庆在会上介绍了《2025 年在华外商企业云计算服务采用研究报告》。报告指出，外企在华经历了从「初步业务上云」、「业务稳定增长」到「深度拓展」的三个阶段，随着业务的扩展与深入，会面临「全球一致性」与「本土适应性」的双重考验。&lt;/p&gt;&lt;p&gt;基于核心能力和用户价值两大维度的评估，亚马逊云科技在报告中被评为「领导者」（位于 Frost Corner 最右上角区间）。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/466e196d-6ba9-4980-8cea-cfd75287b032/filename.png" style="width: 66.3%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这得益于其在中国区域构建的四大核心优势 ：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全球领先的技术优势： 亚马逊云科技致力于保持全球技术一致性，仅 2025 年上半年就在中国落地超过 190 项新服务，并于去年将性能相较上代提升 30% 的自研芯片 Amazon Graviton4 带入中国。&lt;/li&gt;&lt;li&gt;可用、安全与合规： 亚马逊云科技提供高可用基础设施，是唯一在华实现「四个九」（99.99%）可靠性标准的云厂商，并拥有完善的合规认证体系。&lt;/li&gt;&lt;li&gt;行业专长： 拥有丰富的全球客户实践，并构建了覆盖汽车、制造、生命科学、媒体娱乐与广告、零售快消、游戏、金融、教育、能源等行业的解决方案库。&lt;/li&gt;&lt;li&gt;专业、完善的本地化支持： 拥有强大的本地团队及超过一万家合作伙伴网络。在全球范围内，亚马逊云科技拥有来自 150 多个国家和地区的 14 万多家合作伙伴，在中国，合作伙伴数量超过一万家，包括咨询合作伙伴、系统集成商、ISV 等，实现了从地区到行业的全面覆盖。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在媒体沟通会上，两家重要合作伙伴分享了与亚马逊云科技在中国的深度合作。&lt;/p&gt;&lt;p&gt;Snowflake 中国区合作伙伴负责人毕海燕表示，作为一家领先的云原生数据平台公司，Snowflake 已于 2024 年 9 月正式由西云数据运营的亚马逊云科技中国（宁夏）区域提供服务，实现了数据完全在中国境内的合规存储与处理。&lt;/p&gt;&lt;p&gt;毕海燕特别提到，通过与 Amazon Glue 和 Amazon S3 的深度集成，Snowflake 解决了北京与宁夏两个区域间的跨区数据传输难题，不仅速度提升一倍，还大幅降低了成本。&lt;/p&gt;&lt;p&gt;德勤中国亚马逊云科技联盟主管合伙人郭大江分享了双方联合发布的「DelphAI」解决方案 。在福华化学的案例中，德勤与亚马逊云科技合作，在 SAP ERP 实施前先构建了企业级数据湖仓，解决了复杂的跨业务单元数据孤岛问题，为后续的数字化转型铺平了道路。&lt;/p&gt;&lt;p&gt;从底层算力芯片 Graviton4 的落地，到数据基础设施的完善，再到上层 Agentic AI 的应用构建，亚马逊云科技在中国构建的生成式 AI 基础能力已日趋完善。倪殿令表示，在 AI 时代，变化的是日新月异的 AI 应用，不变的是对于安全、可靠和成本优化的追求。对于希望在中国市场深耕的全球企业，以及渴望出海的中国企业而言，这或许正是他们最需要的确定性。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型应用进入深水区，模型 API 服务的新范式是什么？清程AI Ping 给出了答案</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Mon, 02 Feb 2026 16:25:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c6a776fe-a5fc-49ba-b3db-cc678cd0b476/Screenshot_2026-02-02_at_16.53.52.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;1 月 29 日，由清程极智主办的「Ping The Future：智能跃迁，路由新境&amp;mdash;&amp;mdash;清程 AI Ping 产品发布会」在北京举行。随着大模型应用从&amp;ldquo;能不能用&amp;rdquo;迈入&amp;ldquo;如何长期、稳定、规模化运行&amp;rdquo;的新阶段，模型 API 服务的真实表现、稳定性与调用效率正成为产业关注的核心议题。本次发布会汇聚来自政府部门、科研机构、云服务平台、大模型服务商及应用企业的多方代表，围绕大模型 API 服务的评测体系、工程化使用与生态协同展开深入交流。&lt;/p&gt;&lt;p&gt;作为海淀区科技创新体系的重要组成部分，中关村科学城管委会始终高度关注人工智能技术的产业化发展进程。中关村科学城管理委员会产业促进一处处长李楠在发布会上表示，海淀区作为北京国际科技创新中心核心区、人工智能第一城的策源地，始终瞄准实现高水平科技自立自强，当前正在加快构建符合首都功能定位、彰显海淀特色的&amp;ldquo;1+X+1&amp;rdquo;现代化产业体系，其中第一个&amp;ldquo;1&amp;rdquo;就是建设人工智能产业高地。&lt;/p&gt;&lt;p&gt;李楠强调，中关村科学城管委会始终支持企业围绕产业共性需求开展协同探索，通过更加开放的合作模式，让核心技术在更大范围内实现复用与验证，推动模型应用更好的实现价值释放，海淀区将一如既往为各类创新主体快速发展保驾护航。&lt;/p&gt;&lt;p&gt;清华大学教授郑纬民在发布会上指出，当前人工智能基础设施的核心任务正在发生变化。过去，AI Infra 主要服务于大模型的训练与推理，解决&amp;ldquo;如何生产智能&amp;rdquo;的问题；随着模型生态不断丰富和智能体广泛应用，行业正在进入以&amp;ldquo;智能流通&amp;rdquo;为核心的新阶段，更加关注模型能力如何在真实业务中高效、稳定地被使用。&lt;/p&gt;&lt;p&gt;他表示，实现智能流通的关键在于智能路由能力建设，其中既包括在多模型环境下为不同任务选择最合适模型的&amp;ldquo;模型路由&amp;rdquo;，也包括在同一模型的多种 API 服务提供者之间进行性能与成本优化调度的&amp;ldquo;服务路由&amp;rdquo;。两类路由能力协同发展，将形成完整的 AI 任务分发网络，决定人工智能系统的最终效率和使用成本。&lt;/p&gt;&lt;p&gt;清程极智 CEO 汤雄超完整地介绍了清程极智的企业定位和产品布局，他表示，从大模型训练与微调，到推理部署的高性价比实现，再到应用阶段对服务稳定性和使用效率的更高要求，AI Infra 的关注重点正在不断演进。他介绍，清程极智长期围绕大模型训练、推理和应用三类核心场景开展技术实践，先后推出八卦炉训练系统和赤兔推理引擎，支撑模型在多种算力环境下的高效训练与部署。随着 AI 应用和智能体快速发展，模型能力如何在真实业务中高效流通成为新的关键问题。基于这一背景，清程极智推出 AI Ping，一站式AI评测与API服务智能路由平台，完善大模型应用阶段的基础设施能力。&lt;/p&gt;&lt;p&gt;在活动的重磅产品发布环节，清程极智联合创始人，AI Ping产品负责人师天麾对 AI Ping 平台进行了系统地介绍。AI Ping 聚焦大模型服务使用环节，围绕模型服务评测、统一接入与智能路由等核心能力，构建起覆盖&amp;ldquo;评测&amp;mdash;接入&amp;mdash;路由&amp;mdash;优化&amp;rdquo;的完整链路。平台以真实业务场景为导向，对不同厂商、不同模型 API 的延迟、稳定性、吞吐与性价比等关键指标进行长期、持续观测。目前，AI Ping 已覆盖 30余家中国大模型API服务商 ，在统一标准与方法论下对模型服务能力进行对比分析，为企业在复杂的模型与服务选择中提供更加理性的决策参考。&lt;/p&gt;&lt;p&gt;在随后举行的嘉宾分享环节，阿里云政企行业咨询总监程晶结合阿里云在&amp;ldquo;一云多芯多算&amp;rdquo;&amp;ldquo;一栈工具平台&amp;rdquo;等全栈能力建设与行业落地实践，分享了大模型服务规模化过程中对资源统一管理与调度、工程体系化建设的关键关注点，并介绍了阿里云与清程极智在模型服务&amp;ldquo;智能路由与评测体系&amp;rdquo;方面的协同思路，强调AI Ping可作为模型服务的&amp;ldquo;智慧红绿灯&amp;rdquo;，帮助精准匹配资源、提升算力利用率并降低&amp;ldquo;试错成本&amp;rdquo;。&amp;nbsp;&lt;/p&gt;&lt;p&gt;中国电子信息产业发展研究院软件与集成电路评测中心副主任翟艳芬对人工智能产业发展及趋势进行分析，介绍了中心在人工智能产品测评与标准体系建设方面的相关工作，并提到其与清华大学协力，基于 AI Ping 提供的评测数据联合发布了《2025 大模型服务性能排行榜》，为行业提供更具可比性与参考价值的服务选型依据。&lt;/p&gt;&lt;p&gt;发布会现场，清程极智联合20余家大模型API服务商，共同启动《智能、可持续大模型 API 服务生态计划》。该计划未来将围绕模型服务能力评估、评测方法论建设、行业交流与成果发布等方向持续推进，推动模型 API 服务从&amp;ldquo;可用&amp;rdquo;向&amp;ldquo;好用、易用、高性价比&amp;rdquo;演进。&lt;/p&gt;&lt;p&gt;在行业分享与成果发布环节，面壁智能联合创始人周界从大模型能力演进的底层逻辑出发，结合数据治理与模型能力密度提升的实践，分享了在模型快速迭代背景下，通过高质量数据治理与科学化评估机制支撑模型能力稳定演进的经验，强调数据质量与模型效果之间的可验证关系。知潜创始人兼 CEO 周子龙则结合面向求职与招聘场景的 AI 应用实践，介绍了在多模型协同调用场景下，对模型 API 稳定性、响应性能与调用成本的现实要求，并分享了通过接入AI Ping 降低工程复杂度、支撑应用规模化运行的探索。HSRIM 次元陪伴项目发起人吴佳桐从互动型应用出发，结合&amp;ldquo;有温度的角色&amp;rdquo;实践，分享了在陪伴类与情感交互场景中，对模型 API 连续稳定调用、多模型协作与体验一致性的具体需求，呈现了模型 API 服务在新型应用形态中的实际价值。&lt;/p&gt;&lt;p&gt;随着大模型 API 服务在政务、金融、工业与消费等多元场景中加速落地，行业内已涌现出一批具有代表性的实践案例。为推广行业优秀经验、进一步提升模型API服务能力，在中国计算机行业协会人工智能产业工作委员会的指导下，清程极智作为智算集群工作组副组长单位，联合工作组成员，基于 AI Ping 的评测能力，持续推进大模型 API 服务实践案例的梳理与总结。活动现场，人工智能工委会智算集群工作组同步带来《2025 大模型 API 服务能力》实践案例分享，并由工作组组长、燧原科技首席公共事务官蒋燕女士现场发布相关成果，中国电子信息产业发展研究院软件与集成电路评测中心副主任翟艳芬、中国计算机行业协会人工智能产业工作委员会秘书长高宏玲进行授牌，该实践案例围绕模型能力演进、推理性能、交互体验、接口性价比等关键维度，集中呈现了大模型 API 服务在真实业务场景中的实践成果。来自 阿里云百炼、百度智能云、华为云、火山方舟、腾讯云等多家平台与服务商的案例，系统展示了模型 API 服务在性能优化、成本控制与稳定运行方面的多样化探索，为行业提供了可参考的实践样本。&lt;/p&gt;&lt;p&gt;发布会当天，清程极智与华清普智AI孵化器（T-ONE Innovation Lab）联合发布了《2025 大模型 API 服务行业分析报告》。该报告基于 AI Ping 平台 2025 年第四季度的真实调用数据与持续性能监测结果，从模型、服务商与应用场景三个维度，对当前大模型 API 服务的供给结构与使用特征进行了系统分析。报告指出，在模型与服务商高度多样化的背景下，API 服务的核心竞争要素正从&amp;ldquo;价格差异&amp;rdquo;转向&amp;ldquo;交付质量&amp;rdquo;，包括响应时延、吞吐能力、稳定性与上下文支持等关键指标。同时，报告通过实证数据表明，在同一模型条件下，引入智能路由机制可在保障可用性的前提下，实现显著的性能提升与成本优化，为大模型 API 服务走向规模化、长期化使用提供了可验证的工程路径。会后，该报告将通过双方公众号对外公开，供行业参考与交流。&lt;/p&gt;&lt;p&gt;在圆桌论坛环节，由硅星人合伙人王兆洋主持，来自产业与应用一线的多位嘉宾围绕模型 API 服务的工程挑战、生态协同与产业发展路径展开深入讨论。参与讨论的嘉宾包括：智谱首席架构师 鄢兴雨、硅基流动创始人 &amp;amp; CEO 袁进辉、投资人&amp;amp;公众号thinkingloop主理人 严宽、蓝耘CTO 安江华、chatexcel 创始人&amp;amp;CEO &amp;nbsp;逄大嵬以及清程极智联合创始人 师天麾。与会嘉宾结合各自在模型研发、平台服务与应用落地中的实践经验一致认为，随着大模型应用不断深化，模型服务正在从&amp;ldquo;可用&amp;rdquo;阶段迈向精细化运营阶段，评测体系、服务路由与统一管理能力将逐步成为支撑下一阶段规模化应用的重要基础设施能力。&lt;/p&gt;&lt;p&gt;随着 AI Ping 平台的正式发布及生态计划的启动，模型 API 服务这一长期处于&amp;ldquo;幕后&amp;rdquo;的关键环节正逐步走向台前。清程极智CEO汤雄超表示，未来将通过持续的评测实践与开放协作，推动大模型服务向更加稳定、透明和可持续的方向发展，为人工智能在真实业务场景中的规模化落地提供支撑。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Moltbook漏洞大到可以冒充Karpathy发帖，黑客都急了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 16:22:04 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文&lt;/section&gt;&lt;p&gt;上周末，&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651014742&amp;idx=1&amp;sn=b02dcd91ded4159d4c24094a3b715d9d&amp;scene=21#wechat_redirect" target="_blank"&gt;号称「AI 版 Reddit」的 Moltbook&amp;nbsp;&lt;/a&gt;闹得沸沸扬扬。&lt;/p&gt;&lt;p&gt;最初，凭借「AI 发帖、人类围观」的设定在 AI 社区一炮走红，吸引大量网友围观：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="161" data-backw="578" data-height="648" data-imgfileid="503531209" data-ratio="0.2796296296296296" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeUIykxaJpkhPrtLUe9IV0nibribebxSLUqVBJYZmniaEia98wJY2ibY6EYmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="2320" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8a4b969f-946d-4ccb-bffe-c5d3628350db/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;但很快就有人曝出&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651014788&amp;idx=1&amp;sn=df17bda7251e99cc16003a296c563133&amp;scene=21#wechat_redirect" target="_blank"&gt;平台上的很多内容是假的&lt;/a&gt;，那些看似由 AI 生成的帖子，实际上都是人类通过后端发布的：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="537" data-backw="578" data-height="984" data-imgfileid="503531210" data-ratio="0.9283018867924528" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyejDNeeCib3lBO6bgjkOpcgkj8T5Yxqu9HCLKX4YA92NyWASNPn6c1hiag/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1060" data-width="1060" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d3bb2b48-4d5a-4178-afa7-528cbe826336/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;甚至连平台标榜的 AI Agent 注册数量也是假的。因为创建账号时没有任何速率限制，任何人、包括 AI 都能疯狂批量注册假账号。极客 Nagli 亲手用自己的 Openclaw 在短时间内就刷出了 50 万个假用户。&lt;a href="https://mp.weixin.qq.com/s/4QwZpIX4aPYkwDiN3ddwWw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0cd27bf1-b4f5-4eee-a2e2-b9d2761155e4/1770020329819.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;周六截至机器之心发稿前，Moltbook 注册的 AI Agent 数量也只是 50 多万个，但到了周日，一下子就超过 150 万了，原来这夸张的增长速度背后全是水分。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;造假风波尚未平息，现在 Moltbook 又陷入更严重的安全问题。&lt;/p&gt;&lt;p&gt;一位名为 Jamieson O&amp;#39;Reilly 的白帽黑客发帖称，Moltbook 存在重大安全漏洞，导致整个数据库暴露在公众面前，包括秘密 API 密钥在内的所有敏感信息都可被任意访问。&lt;/p&gt;&lt;p&gt;这意味着任何人都可以冒充平台上任意 Agent 的身份发帖，甚至包括拥有 190 万粉丝的 AI 领域知名人物 Karpathy。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyelHGehJ1P6891vPrDiaxXiaMWDqdkFbATSHeOBlEwa6I4a3yRiadvcaHdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.45185185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="261" data-imgfileid="503531219" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/056b5cc4-c51f-4ee2-b3cf-50566dfd5ba4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;「想象一下，假的 AI 安全言论、加密货币诈骗推广，或煽动性的政治声明，看起来都像是出自 Karpathy 之口。而且不只是 Karpathy，从我掌握的情况来看，整个平台上的所有 Agent 目前都暴露了。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye0clwjmpfpDSUTtKibbjr04lxTYe646AJlAIJib9rd7ylabKzhgGkMBYQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7743785850860421" data-type="png" data-w="1046" data-width="1046" data-height="810" data-backw="578" data-backh="448" data-imgfileid="503531220" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/37edad41-9f25-41a1-8810-5ba60280cfed/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;有网友在底下评论区询问漏洞的具体成因，「是 Superbase 的问题吗？为什么人们可以对数据库运行查询？」&lt;/p&gt;&lt;p&gt;Jamieson O&amp;#39;Reilly 解释称，该漏洞涉及多个安全问题，其中最严重的是 Moltbook 使用的 Supabase 密钥被公开暴露，允许任何人对 Agents 表进行公开读取。&lt;/p&gt;&lt;p&gt;攻击者只需发送一个简单的 GET 请求即可获取用户的所有数据：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="bash"&gt;&lt;code&gt;/rest/v1/agents?name=eq.theonejvo&amp;amp;apikey=xxxxx &lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;这个请求可以直接导出指定用户的完整信息。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyekXMiaGd9daR8lIC9wjuSjDB2Vb54kAcq0exH7w2SBPOCibpHnLzbpxGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5845864661654135" data-type="png" data-w="1064" data-width="1064" data-height="622" data-backw="578" data-backh="338" data-imgfileid="503531221" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/afd91642-b31d-4705-9b99-ffad4231fa48/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在过去几小时内，Jamieson O&amp;#39;Reilly 一直试图联系 Moltbook 创始人，但未获回应。他只能在推文中公开喊话：「要么直接关闭你们的 supabase 数据库访问，要么马上让你们的 AI 编码助手执行以下操作」。&lt;/p&gt;&lt;p&gt;他给出了具体的修复方案：&lt;/p&gt;&lt;p&gt;1. 在 agents 表上启用行级安全策略 (RLS)：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="css"&gt;&lt;code&gt;ALTER TABLE agents ENABLE ROW LEVEL SECURITY;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;2. 创建限制性访问策略，阻止匿名用户直接访问表数据：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="sql"&gt;&lt;code&gt;-- Public can only see non-sensitive columns via a view&lt;/code&gt;
&lt;code&gt;CREATE POLICY &amp;quot;anon_read_public_fields&amp;quot; ON agents&lt;/code&gt;
&lt;code&gt;FOR SELECT TO anon&lt;/code&gt;
&lt;code&gt;USING (false);&lt;/code&gt;
&lt;code&gt;-- Authenticated users see only their own&lt;/code&gt;
&lt;code&gt;CREATE POLICY &amp;quot;users_own_data&amp;quot; ON agents&lt;/code&gt;
&lt;code&gt;FOR SELECT TO authenticated&lt;/code&gt;
&lt;code&gt;USING (auth.uid() = owner_id);&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye5Vj5wjKLbf93BnsGpFBmhgsDkoQxiawCf0Cg2VswSfTcwj6rEHWa9zA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7413127413127413" data-type="png" data-w="1036" data-width="1036" data-height="768" data-backw="578" data-backh="428" data-imgfileid="503531222" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/6a4486f0-3398-44f1-94d2-e7870d7d0a19/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Supabase 的 CEO 看到消息后表示，他们已经努力联系并配合 Moltbook 创建者处理此事，但他们无法替用户直接执行这类数据库权限修改。Supabase 平台的安全顾问团队已经准备好了一键修复方案，只要创建者点击一下，就能立即封堵这个漏洞。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeG4RYNmcZ3p8iaYuuw0gsz8q5icsKTuR0G1XuKW0Cd4DDNHJZcoMsbGqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6496212121212122" data-type="png" data-w="1056" data-width="1056" data-height="686" data-backw="578" data-backh="375" data-imgfileid="503531223" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/af043508-f89a-4cbc-b395-9d68c5fdfa37/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;随后，Moltbook 创建者 Matt Schlicht 回应称，他已经在处理了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyenqzSjmna64Szh3Nn0qB9WRPP2fsiaC4aiaRy9ViabphNmy7Fq9KIWbmlA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.09732824427480916" data-type="png" data-w="1048" data-width="1048" data-height="102" data-backw="578" data-backh="56" data-imgfileid="503531224" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3bfc0b0a-f719-47aa-9a51-f22144732fb8/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;修复引发新问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jamieson O&amp;#39;Reilly 在紧密跟踪修复进程后发现了新麻烦：如果现在把所有 Agent 的 API 密钥全部重置换成新的（这是修复安全漏洞的必要步骤），那用户就全傻眼了。&lt;/p&gt;&lt;p&gt;原因在于， Moltbook 这个平台根本没有网页登录功能，用户只能靠 API 密钥来控制自己的机器人。一旦密钥换了，所有用户瞬间被锁死，没法再发帖、操作自己的 AI Agent。既没有邮箱验证，也没有网页重置密码啥的，用户没有任何恢复办法。&lt;/p&gt;&lt;p&gt;他给出了两个可能的解决思路：要么做一个临时的「旧密钥换新密钥」接口，给一段宽限期让用户自行更换；要么强制所有人通过 X 账号重新验证身份来获取新密钥。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye7sYQoFx2dab453gyBGzicpS7E8vhW8RO5sfJWuosulUBxMpXfE1GFJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.0680529300567108" data-type="png" data-w="1058" data-width="1058" data-height="1130" data-backw="578" data-backh="617" data-imgfileid="503531225" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/d811399c-01c0-4e9c-964b-4af99549aa65/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，一名前 Anthropic 工程师还发布了针对 OpenClaw（前身为 Moltbot 和 ClawdBot）的一键远程代码执行漏洞。&lt;/p&gt;&lt;p&gt;该攻击在受害者访问网页后几毫秒内发生，攻击者可获得 Moltbot 及其运行系统的访问权限，而受害者无需输入任何内容或批准提示。目前该漏洞已修补。&lt;a href="https://mp.weixin.qq.com/s/4QwZpIX4aPYkwDiN3ddwWw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ef67d28a-e24a-45f1-a3db-80e0d3a6e5d9/1770020442812.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;有机器之心读者在后台反馈称，他们单位已经发布 Clawdbot 平台有重大漏洞的情况通告，要求内部禁止使用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeibSTfYMRE1sESSlTibQQIYDUb3bv7BE7cn7X3ib5UxEhpYDmzLSuBKgMg/640?wx_fmt=jpeg#imgIndex=10" data-ratio="0.12137486573576799" data-s="300,640" data-type="jpeg" data-w="931" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyepkT1WicRmibH32EZ9Sr4GWNQ8gEF6eCN6a75hH5HV9S8I3ZymicM10foA/0?wx_fmt=jpeg&amp;from=appmsg" data-cropx1="85.63701067615658" data-cropx2="1016.7117437722419" data-cropy1="83.81494661921708" data-cropy2="196.78291814946618" data-backw="562" data-backh="68" data-imgfileid="503531226" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/ddd13387-e151-4859-8e13-27fe81de129f/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/javilopen/status/2017880072946893112?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/KookCapitalLLC/status/2018057772118519928?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/IntCyberDigest/status/2018095767391477964&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/galnagli/status/2017585025475092585&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>VL-LN Bench：模拟「边走边问找具体目标」的真实导航场景</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 16:16:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/89723553-327d-49aa-924f-8e23d0c5cdf6/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;本工作由上海人工智能实验室、中国科学技术大学、浙江大学、香港大学 的研究者们共同完成。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5384b0e5-d4fc-439b-a7f0-fb7a6b44113a/1770019824797.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530488" data-ratio="0.18333333333333332" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tibOPpqm2LpbH8q5iarnlIRW9tvUDFN8HSfnYyAjGDeIBxKgd4uksh9hQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4cac4e7c-fd17-438d-bef8-509e36c62d9b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://0309hws.github.io/VL-LN.github.io/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ArXiv 论文：https://arxiv.org/abs/2512.22342&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hugging Face 数据集： https://huggingface.co/datasets/InternRobotics/VL-LN-Bench&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hugging Face 模型：https://huggingface.co/InternRobotics/VL-LN-Bench-basemodel&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub 代码库：https://github.com/InternRobotics/VL-LN&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;交互式实例导航任务（Interactive Instance Goal Navigation, IIGN）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果将一台在视觉语言导航（VLN）任务中表现优异的机器人直接搬进家庭场景，往往会遇到不少实际问题。&lt;/p&gt;&lt;p&gt;首先是使用门槛偏高：传统 VLN 需要用户给出又长又精确的路线式指令，例如 &amp;ldquo;从门口直走三步，看到门右转，再往前&amp;hellip;&amp;hellip;&amp;rdquo;，这会显著增加沟通成本，降低日常使用体验。&lt;/p&gt;&lt;p&gt;相比之下，人们更期待一种更自然的交互方式，比如只用随口一句 &amp;ldquo;找到我的背包&amp;rdquo; 即可。这样的设定更接近目标物体导航（ObjectNav）任务，但它也存在明显不足：机器人只会找到场景内任意一个背包交差，而无法定位用户真正需要的书包，这显然无法满足需求。&lt;/p&gt;&lt;p&gt;正因为真实场景里用户的表达常常&lt;strong&gt;简短且含糊&lt;/strong&gt;，而机器人又必须把目标精确落实到某一个&lt;strong&gt;具体实例&lt;/strong&gt;上，&lt;strong&gt;交互式实例导航&lt;/strong&gt;才显得格外关键。机器人既不能指望用户一开始就把所有信息交代清楚，也不能用 &amp;ldquo;找到同类就算完成&amp;rdquo; 的方式草草应付；相反，它应在探索过程中主动提问、逐步澄清歧义，像人一样把 &amp;ldquo;到底是哪一个&amp;rdquo; 问明白，再高效准确地完成用户的需求。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="2206" data-imgfileid="503530485" data-ratio="0.6981481481481482" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t63Qp0TOJbmTkPtqicUqLqLHn0XtjiaNapX0SI4fyPqBPQS7zcWZDHMUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="3160" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3f259983-f479-4cd6-9497-a59df6c8043c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;交互式实例导航示例：用户要求机器人找到场景中某一张凳子（绿框），但存在大量相似干扰项（红框），因此机器人需在探索中结合观察主动提问，逐步缩小候选范围，直到锁定目标。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建 VL-LN 基准：面向 IIGN 任务的自动化数据收集及评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;语言交互是人们日常交互最常见的形式之一，具身智能体要更好地融入人类生活也需要具有进行这种高效的信息交流形式的能力。不同于传统 VLN 仅仅聚焦 &amp;ldquo;导航动作（Navigation）执行得好不好&amp;rdquo;，VL-LN 还关注机器人能否在导航过程中与人类进行高效的语言交互（Language+Navigation）来提升任务的成功率与效率。&lt;/p&gt;&lt;p&gt;为此，VL-LN 面向交互式实例导航任务构建了一套自动化&lt;strong&gt;数据收集管线&lt;/strong&gt;，并依托 InternVLA-N1 标准化模型&lt;strong&gt;训练&lt;/strong&gt;与&lt;strong&gt;评测&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自动化数据收集管线&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1415" data-imgfileid="503530489" data-ratio="0.6925925925925925" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t1rwiaTdTqmcQbYicjBZrcOyeqThbqt0bxmlx59ZVsZDv6EwD9p6H8PWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" data-width="2044" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/00db1cf1-e330-4376-ba35-120c67d0ab24/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 交互式实例导航数据收集流程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;数据收集包含三个步骤，作者首先整理了场景元数据，进而生成能用于在线采样的序列（episode）数据，最后在规则驱动的交互机制下批量采集交互导航训练轨迹（trajectory），具体内容包括：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景元数据处理&lt;/strong&gt;：基于 MMScan 对 MP3D 场景的标注信息，将按房间分散的物体信息整合成全屋级的元数据，主要包括两个字典：目标实例字典（instance dictionary，存储每个物体的空间关系、属性等基本信息）和区域字典（region dictionary，存储房间的位置、物体等信息）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;序列生成&lt;/strong&gt;：每个有效序列由&lt;strong&gt;起始位姿、导航指令、目标实例的可停止视点&lt;/strong&gt;三个主要信息组成。针对每一个目标实例作者均提供两个版本的导航指令。一种导航指令只有目标实例的类别（Partial instruction，用于交互式实例导航任务，必须靠对话消歧），另一种导航指令是能在场景内唯一锁定目标实例的完整描述（Full instruction，可用于评测训练非交互的任务）。可停止视点（view point）指机器人在导航过程中可以合法停止并判定 &amp;ldquo;已找到目标&amp;rdquo; 的一组视点位置。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;交互导航轨迹采集&lt;/strong&gt;：该阶段主要采用一个集成了基于边界点的探索算法（Frontier-Based Exploration）与目标实例分割器的智能体。在数据采集过程中，智能体除探索未知区域外，还会按规则主动提出三类问题：&lt;strong&gt;属性&lt;/strong&gt;（目标实例长什么样？）、&lt;strong&gt;路线&lt;/strong&gt;（如何到达目标？）和&lt;strong&gt;目标消歧&lt;/strong&gt;（是否为眼前的实例？），从而生成相应的交互式导航轨迹。&lt;/p&gt;&lt;p&gt;通过该流程，作者构建了大规模交互式实例导航数据以支撑模型训练。下图给出了数据的总体统计。作为首个大规模交互式实例导航数据集，其主要优势在于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;规模&lt;/strong&gt;：约 &lt;strong&gt;40k &lt;/strong&gt;导航序列，相比现有交互导航数据集（约 &lt;strong&gt;7k&lt;/strong&gt;）提升&lt;strong&gt;一个量级&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多样性&lt;/strong&gt;：覆盖&lt;strong&gt; 150+ &lt;/strong&gt;物体类别与 3 类问答（属性 / 位置 / 消歧），&lt;strong&gt;自由组合&lt;/strong&gt;形成丰富训练样本；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;难度覆盖&lt;/strong&gt;：包含&lt;strong&gt;长时程&lt;/strong&gt;轨迹（steps &amp;gt; 300）与&lt;strong&gt;多轮对话&lt;/strong&gt;样本（dialog turns &amp;gt; 5），覆盖复杂困难场景。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="2691" data-imgfileid="503530490" data-ratio="0.5055555555555555" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t1YwxSTKo1XVWvFb9J2iaCiblMg9H3C8owkhFVibu90k9uoicq0OhF75X9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" data-width="5325" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/707b6f14-836a-449f-a645-d8a6d5c2778f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;第一行分别展示了每条轨迹的路径步数、对话轮数和每轮对话长度的频率直方图；第二行展示了问题类型与目标类型的统计结果，以及对话中高频词的词云图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NPC 支撑的自动化在线评测基准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了评测智能体完成&lt;strong&gt;交互式实例导航&lt;/strong&gt;（IIGN）的能力，并与&lt;strong&gt;非交互式实例导航&lt;/strong&gt;（IGN）进行对比，VL-LN 基准提供了可用于测试两类任务的测试集。针对交互式实例导航的自动化评测，VL-LN 还实现了一个由 GPT-4o 驱动的 NPC，它能够回答智能体在导航过程中提出的问题。此外，为了评估智能体提问效率，VL-LN 定义新的指标 MSP（Mean Success Progress），用于衡量主动对话带来的增益。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从结果到原因：交互式实例导航的能力与挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过使用不同的数据对 Qwen2.5-VL-7B-Instruct 进行微调，作者训练了三个模型。具体训练所使用的数据如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;VLLN-O (object)：VLN + ObjectNav 轨迹数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VLLN-I (instance)：VLN + ObjectNav + IGN 轨迹数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VLLN-D (dialog)：VLN + ObjectNav + IIGN 轨迹数据（论文的核心模型）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;评测同时覆盖两类任务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;IIGN（交互式实例导航）：允许提问（对话轮数限制在 5 轮）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IGN（实例导航）：不允许对话，但提供足以唯一锁定目标实例的全量指令&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验结果如下表所示&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="784" data-imgfileid="503530491" data-ratio="0.7983706720977597" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tp4DTYjLaCQsls1XNnickNoIVhZibhmS7XZ6fNow2bt3TtiarjMZsmkXibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="982" data-width="982" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/17ab3714-e110-4bd8-95b5-28d822a156f6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了进一步确定模型在交互式实例导航任务上的性能和瓶颈，研究团队对实验结果进行系统性复盘，并将实验结论总结如下：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tXCImB0GxLwbJYz6wibNBibiamEb7yIIa0kkpkibIX1mibqlsCRibDY05k0nw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5462962962962963" data-type="png" data-w="1080" data-width="1309" data-height="715" data-imgfileid="503530492" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b2bfab4a-153d-4137-b0fd-96526c9a2dff/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; VL-LN Bench 错误类型分布&lt;/sup&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="321" data-imgfileid="503530493" data-ratio="0.5631578947368421" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tN00Sib3gsnSOCrUiaAqnicw5gxp7P9MTzBDiaSCCqKDTneic8cGzAWbSicGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="570" data-width="570" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/48673621-d972-452a-ad2b-d6385c0277e3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 不同对话轮次上限下的 IIGN 性能&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对话消歧在任务存在歧义时显著提升成功率&lt;/strong&gt;：在 IIGN 与 IGN 上，具备提问能力的 VLLN-D 成功率均高于仅会探索的 VLLN-I，成功率分别提升&lt;strong&gt; 6.0%&lt;/strong&gt; 与 &lt;strong&gt;2.6%&lt;/strong&gt;。在对话轮次上限消融中，随着上限由&lt;strong&gt; 0 &lt;/strong&gt;增至 &lt;strong&gt;5&lt;/strong&gt;，VLLN-D 的 SR 由 &lt;strong&gt;15.4%&lt;/strong&gt; 提升至 &lt;strong&gt;20.2%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;物体 &amp;mdash; 图像对齐是核心瓶颈：&lt;/strong&gt;无论在 IIGN 还是 IGN 任务中，约 70% 的失败都源于目标未被成功检测，说明性能瓶颈主要不在导航策略，而在于目标实例与图像观测之间的对齐能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;相较于全量信息设置，问答机制带来的信息增益仍然有限：&lt;/strong&gt;VLLN-D 在 IIGN 上的成功率为 20.2%，低于其在无法提问、但具备全量信息的 IGN 上的 21.8%，说明对当前模型而言，对话带来的增益仍弱于信息补全带来的增益。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;与人类仍有显著差距：&lt;/strong&gt;论文设置人类 IIGN 测试（一人负责提问与探索，另一人负责回答），结果显示人类平均仅需 &lt;strong&gt;2 &lt;/strong&gt;轮对话即可达到&lt;strong&gt; 93%&lt;/strong&gt; 成功率，表明当前模型与人类水平仍存在巨大差距。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VL-LN Bench 是一个面向长时程交互式实例导航（IIGN）任务的高质量、高挑战且体系完备的评测基准，可系统评估智能体在 3D 环境中的长程探索、实例级目标识别与对话消歧能力。&lt;/p&gt;&lt;p&gt;与此同时，基准配套自动化数据采集管线与 NPC 评测机制，为交互式导航能力的训练与评估提供了一条可规模化、可复现的标准化路径。评测结果清晰表明：引入主动对话能够显著提升智能体在 IIGN 与 IGN 任务中的整体表现，但同时也揭示了当前方法在实例级感知对齐与高信息增益提问策略等关键环节上仍存在明显短板，为未来面向空间智能体的 &amp;ldquo;会走&amp;rdquo; 到 &amp;ldquo;会边走边问&amp;rdquo; 的技术演进提供了研究方向与启发。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>18个月，中国Token消化狂飙300倍！别乱烧钱了，清华系AI Infra帮你腰斩API成本</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 14:36:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜吴昕&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;中国版 OpenRouter + Artificial Analysis，让每一枚 Token 都能流向它最该去的地方。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;大模型&amp;nbsp;API&amp;nbsp;服务&lt;/strong&gt;&lt;strong&gt;的「黑盒」焦虑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这两天，Clawbot 病毒式裂变，仿佛是一年前 Manus 的魅影重现。&lt;/p&gt;&lt;p&gt;同样一夜之间站上风口，同样点燃了无数开发者对「泼天富贵」的想象，也顺手把 Token 烧成了新的「硬通货」。&lt;/p&gt;&lt;p&gt;最近一组数据，让人更有体感。&lt;/p&gt;&lt;p&gt;中国大模型数量已超过&amp;nbsp;1500&amp;nbsp;个，下游开发者已经开始「疯狂盖房子」。数据显示，2024&amp;nbsp;年初，中国日均&amp;nbsp;Token&amp;nbsp;消耗量约为&amp;nbsp;1000&amp;nbsp;亿；到&amp;nbsp;2025&amp;nbsp;年&amp;nbsp;6&amp;nbsp;月，这一数字已突破&amp;nbsp;30&amp;nbsp;万亿。&lt;strong&gt;一年半时间，增长超过 300 倍。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与三年前的 Chatbot 不同，「能干活」的 Agent 正以前所未有的强度，第一次把 API 调用推入「生产级」&amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;一次看似简单的操作，背后往往是十几次、甚至几十次模型调用在同时发生。任何一次服务「抽风」，都会在 Agent 链路中引发一场多米诺骨牌式崩溃。&lt;/p&gt;&lt;p&gt;问题在于，中国大模型 API 服务现状，远比 benchmark 复杂得多。&lt;/p&gt;&lt;p&gt;更像是开盲盒，有人调侃说，以为自己在用「DeepSeek V3.2」，实际可能是蒸馏/量化版本。有人花了两周时间反复测试，上线后仍遭遇性能回退。还有团队发现，模型会在某些凌晨时段准时「抽风」，延迟从 300ms 飙升至 2000ms 以上，客服秒变「智障」。&lt;/p&gt;&lt;p&gt;这些并非个案，而是高度碎片化的大模型API服务的「缩影」。&lt;/p&gt;&lt;p&gt;大模型 API 服务的「黑盒」，不只是模型不可解释，而是用户根本不知道，服务背后跑的是什么模型、什么配置、什么质量。清华系 AI Infra 创企清程极智联合创始人兼产品副总裁师天麾告诉机器之心。&lt;/p&gt;&lt;p&gt;中国大模型和大模型 API 服务商本来就多。多算力、多架构、多网络并存，同一个模型，在不同服务商、不同部署方式下，往往呈现出显著差异。&lt;/p&gt;&lt;p&gt;比如，同样调用 DeepSeek-V3 / R1，头部服务商可以维持毫秒级响应；而部分接入低质量算力或优化不足的服务商，其 TTFT（首 Token 时延）可能慢上 2～3 倍。&lt;/p&gt;&lt;p&gt;与此同时，免费 Token、补贴、打包套餐的价格战，让「性价比」变得更加扑朔迷离。&lt;/p&gt;&lt;p&gt;经济学家罗纳德&amp;middot;科斯曾指出，企业与制度的出现，本质上是为了替代高成本的市场交易。当模型服务因高度不透明与供给碎片化不断抬升交易成本时，市场往往会内生出新的中介形态与制度安排，用以收敛不确定性，降低决策与交易成本。&lt;/p&gt;&lt;p&gt;正是在这样的背景下，1 月 29 日，清程极智正式发布 AI Ping。这款被业内视为「中国版 OpenRouter + Artificial Analysis」产品，旨在重塑大模型 API 服务秩序，将上游服务的碎片化与「黑盒」，转化为下游用户手中稳定、可预期的生产力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeWdbKJmdm5LwDUqxf8FVaW6Uep5Dns4eDx9wnZmLwibhk19wqkceqL9g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="385" data-imgfileid="503531195" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c9d2bc6f-3239-4434-9bb1-a54c43afd200/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 1 月 29 日，清程极智举行发布会，正式官宣 AI Ping。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中国版&amp;nbsp;OpenRouter + Artificial Analysis：&lt;/strong&gt;&lt;strong&gt;AI Ping&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;怎么玩儿？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单来说，AI Ping&amp;nbsp;是一个通过&lt;strong&gt;评测与路由&lt;/strong&gt;两大机制，来消除大模型 API 服务不确定性的基础设施型产品。&lt;/p&gt;&lt;p&gt;如果说OpenRouter 解决的是「统一接入不同模型和服务」，Artificial Analysis 解决的是「评测模型服务质量」，那么 AI Ping 试图把这&lt;strong&gt;两件事合成一件事&lt;/strong&gt;&amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通过评测告诉你模型服务的质量数据，更基于实时评测结果，「接管」模型与服务商的选择决策。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;换句话说，有了这颗动态的「调度大脑」，你只管提需求，不用理解模型，不用挑供应商，更不用为故障兜底。&lt;/p&gt;&lt;p&gt;我们简单体验了一把「自动驾驶」，在网页「多模型对话」中，让系统完成一个音乐播放器的设计。&lt;/p&gt;&lt;p&gt;模型路由，选择的是「均衡模式」，在效果、速度与成本之间寻找综合最优解，而不是只追求单一极端指标（比如最低延迟）。&lt;/p&gt;&lt;p&gt;很快，系统判断 DeepSeek-V3.2 最适合当前任务，并将请求路由到当时服务能力最优的火山引擎节点。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeHq4PShTZ1u0icNDiaOIWrBNzsQmFmjo5EfHpeoPgG2qicVudmq29w0XWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5712962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="330" data-imgfileid="503531194" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/196a5898-743b-464b-8f93-21158020d45d/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;结果，响应速度快，输出效果也很不错。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye1tsqduBJfvcbLfggegnk0AWSLr7nWibBpZ7iboru4IdiaKrQQqshD7Edg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.798887859128823" data-s="300,640" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="462" data-imgfileid="503531189" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/86c805a9-5438-4f6a-b5cb-a8bbca0032d6/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;成本仅消耗 0.04 个算力点（约 4 分钱）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye6zh7wQDkTMRRm6axOfQv3h8wMDwN1bibnQvia3fEdcQ4BQdgPysIKaXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.15833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="92" data-imgfileid="503531196" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a379e01d-c506-44a2-bd5a-dadcf8bab2ba/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大规模实验数据显示，无论用户选择哪种路由策略，AI Ping 都能把调用推向「能力&amp;mdash;成本」的最优区域。&lt;/p&gt;&lt;p&gt;比如，即使选择「效果优先」，系统也会在保证模型能力处于高水平的同时，避免把成本推向极端，而是在质量与价格之间自动找到一个更均衡的位置。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeKdDUfMmpu1HHCj5yTapRyIhe0TBVHaS68I2UuS6BsvzZkINAz8yiaxQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="788" type="block" data-backw="578" data-backh="433" data-imgfileid="503531197" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/11d02f56-bcf4-42d1-89ee-8413abafb3ce/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;通过模型路由策略，AI Ping 能在「能力&amp;mdash;成本」二维空间里，逼近不同目标下的最优解。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;长期以来，中国大模型 API 服务市场缺乏一份公允、可对比的「体检报告」。不同服务商各自披露性能指标，但测试条件、指标口径与展示方式并不统一，开发者很难判断，AI Ping 试图填补这一空白。&lt;/p&gt;&lt;p&gt;目前，该平台已接入 30 家主流服务商，覆盖 555 个模型接口，是国内极少数能够在统一标准下，对大模型服务进行持续评测与公开展示的平台之一。&lt;/p&gt;&lt;p&gt;在 AI Ping 的网站首页，不同服务商被放入同一张性能坐标图中进行对比。以吞吐率与延迟为坐标轴，同一个模型在不同服务商处的实际服务能力差异，一目了然。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeNHRuav2ibJIvudIw26HoMDdaA5TlxZSicKLHy6a2sWMicwiaWMeicpNqHbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.9592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="554" data-imgfileid="503531198" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3958afc4-a5dd-4765-ba9b-9bd9c3265d79/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyedlwNgbgFke8icvLV7vaiaSypichu2L2mmK5xH9nyVPrX3fmoLdruibrcKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.55" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="318" data-imgfileid="503531199" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/d8b348f8-fb11-4649-aefb-5a1bf7c40705/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyefONjHibVyf7X2nk1WZrbXAFTb1gRlENaP3BwOBfqHr3eFBRd9kQvOoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.0842592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="627" data-imgfileid="503531200" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b6c1bc8c-2fbf-413c-8a4c-5f5e4b0b5d6a/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 用户提需求，自动生成服务路由策略的代码。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;点开服务商，可以看到同一模型（ DeepSeek-V3.2 ）在不同服务商处的服务波动情况。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyePTfpJQmXRHXcyiaHgURpEX0GYRLarBpBd4Fb4oAGUztSHFMT28nhd9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="302" data-imgfileid="503531201" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/32461a1f-0350-4c32-8b1d-c5d2d23ad714/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Top5服务商最近几天服务延迟的「心电图」。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这些对外展示的数据，强调公平性与可比性，按固定周期更新，犹如一份面向行业的「排行榜」和「体检报告」。对开发者而言，选型不再听厂商「吹牛」；对服务商而言，服务能力第一次被放在同一把尺子下比较。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对标&amp;nbsp;Artificial Analysis：&lt;/strong&gt;&lt;strong&gt;7&amp;times;24h&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;数据「开盒」大模型API&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从我们的体验来看，使用 AI Ping 和直接调用某个大模型几乎没有区别，只是完成了一次再普通不过的请求。&lt;/p&gt;&lt;p&gt;但在系统内部，这次调用已经悄然完成了一次跨模型、跨服务商的最优路径选择。&lt;/p&gt;&lt;p&gt;这种「选路」的能力，源于清程极智构建的技术三角闭环：&lt;strong&gt;全维度评测体系、服务商级智能调度、以及多模型智能路由&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一切的基石，是套对标 Artificial Analysis 的实时评测系统。要像成为公认的「裁判员」，前提是评测体系本身具备足够的公平性与一致性。&lt;/p&gt;&lt;p&gt;在指标设计上，紧紧围绕用户真正关心的体验维度展开，包括 TTFT（首 Token 延迟）、TPS（吞吐率）、成本、精度等核心性能与经济指标。&lt;/p&gt;&lt;p&gt;不同应用场景，对指标的敏感点完全不同。师天麾解释说，在普通聊天场景中，用户最在意的是「多久开始回复」。只要能在几百毫秒内出首字、输出速度达到可阅读水平，体验就已经趋于饱和。&lt;/p&gt;&lt;p&gt;而在 Agent 场景中，一个任务往往由多步调用组成，真正决定效率的，不再是单次延迟，而是整个流程的吞吐能力与端到端完成时间。&lt;/p&gt;&lt;p&gt;为了「开盒」国产模型服务的真实水位，AI Ping 沉淀了一套极具技术含量的评测方法。&lt;/p&gt;&lt;p&gt;例如，所有测试使用同一套「考卷」，并在同一时间段进行；测试请求从北、上、深、蓉等多地服务器同时发出，彻底消除网络波动对单一节点的干扰。&lt;/p&gt;&lt;p&gt;专门针对「服务商缓存」设计特殊策略，确保测出的是真实的算力响应，而非「复用答案」的表象。&lt;/p&gt;&lt;p&gt;始终以普通用户身份，匿名走真实调用流程，评测结果还会进行交叉验证，也获得了数十家主流服务商的认可。&lt;/p&gt;&lt;p&gt;最极致的一点，在于&lt;strong&gt; 7&amp;times;24 小时持续观测&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;模型本身只是个文件，能力基本是固定的；但模型一旦变成大模型 API 服务，情况就完全不同了。师天麾说。&lt;/p&gt;&lt;p&gt;中国大模型 API 服务，白天和晚上不一样，北京和成都的节点不一样，甚至同一家服务商，隔了几个小时负载也会剧烈波动。如果拿几分钟前的评测数据做路由决策，无异于刻舟求剑。&lt;/p&gt;&lt;p&gt;这种对指标的极致苛求，源于团队的硬核底蕴。AI Ping 背后的清程极智团队源自清华，长期深耕超算与 AI 性能评测领域。他们不仅参与过 AIperf 等行业评测工具的研发，更承担过国家级超算集群的性能验收&amp;mdash;&amp;mdash;这种「国家队」级别的评测经验，被降维应用到了大模型 API 服务，最终转化为 AI Ping 难以被复制的壁垒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对标&amp;nbsp;OpenRouter：&lt;/strong&gt;&lt;strong&gt;用「自动驾驶」接管 Token 调度权&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们的目标不是把数据摆给用户看，而是要替用户做决定。师天麾强调。&lt;/p&gt;&lt;p&gt;如果说 OpenRouter 的功劳是实现了 API 的「大统一」，那么 AI Ping 则更进一步，通过一套 L4 级智能路由系统，实现了模型调度的「自动驾驶」。这套系统由「双引擎」驱动：&lt;strong&gt;模型路由（解决「谁来做」）&lt;/strong&gt;与&lt;strong&gt;服务商路由（解决「在哪里做」）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在 AI Ping 的逻辑里，模型不是「越大越好」，而应该是「分工明确」，有的擅长写代码，有的擅长写作。&lt;/p&gt;&lt;p&gt;现实中的任务也是分层的：写代码需要逻辑严密，日常闲聊只需快速响应。「如果所有请求都交给旗舰模型，只会变得又贵又慢。」&lt;/p&gt;&lt;p&gt;AI Ping 的路由模型会通过机器学习，实时对用户请求进行「画像」，并在多种模型之间动态选择当前性价比最优的组合。&lt;/p&gt;&lt;p&gt;在大规模测试中，这种「按问题匹配模型」的策略带来了两个结果：整体正确率超过单一旗舰模型的最高得分，而调用成本下降超过 50%。&lt;/p&gt;&lt;p&gt;这一结果也与外部研究结论，不谋而合。&lt;/p&gt;&lt;p&gt;近期一项来自MIT 与佐治亚理工的研究发现，开源模型已经可以用大约 13% 的成本，达到接近 90% 的闭源模型性能。&lt;/p&gt;&lt;p&gt;但在实际市场中，这类高性价比模型的使用比例仍不足 20%，主要受限于认知惯性与切换成本。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeDHhDpanbM0GwP3AIcmAotaU2kZUZichcbyBD0KOQOtp3JPibickgAo5bw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.7504393673110721" data-s="300,640" data-type="jpeg" data-w="569" type="inline" data-backw="266" data-backh="200" data-imgfileid="503531202" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/a4598e85-e186-4537-8920-a4518de82fce/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeiboibOSmEyQdPiaCV1olw3mKuG0JLXZrjfu15fujibicicJtjx9rAtqhmGyw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="572" type="inline" data-backw="266" data-backh="200" data-imgfileid="503531203" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/45cd05a1-f6d0-41f8-bd35-7281e4b21324/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 两种不同情况下的模型路由。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决了模型选型，下一步是决定请求落到哪家服务商。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与传统的「失败后再重试」不同，AI Ping 的服务商路由具备预判能力。每一次请求返回的结果，都是一个天然的测量样本。这些数据会被持续汇总进内部评测池，用来刻画服务商「此时此刻」的真实服务水平。&lt;/p&gt;&lt;p&gt;一旦发现某条请求的响应时间明显偏离正常建模，或与最近观测数据不一致，路由系统就会预判该节点可能进入异常状态，即使尚未收到明确错误，而不是被动等待失败。&lt;/p&gt;&lt;p&gt;在亿次调用的实测中，这套机制让整体 TPS（吞吐量）提升了约 90%，成本同步下降了 37%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye4b95MRXadib74TbSMznDmSvveqbGGWbng5HdRl5cVheWrkVxjuXHb9g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=12" data-ratio="0.7503628447024674" data-s="300,640" data-type="jpeg" data-w="689" type="block" data-backw="578" data-backh="434" data-imgfileid="503531204" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/7baf3bae-4cb0-4bad-bf9f-18291a38d623/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;选择最适合的大模型API服务商。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实现这种「自动驾驶」非常不容易。师天麾告诉我们。&lt;/p&gt;&lt;p&gt;服务商路由的一个难点在于动态均衡。「如果只把流量给当前最好的服务商，瞬间的高并发可能会直接把对方打崩。」师天麾分享了一个真实细节：曾有服务商因流量集中路由而宕机，CTO 半夜打来电话询问发生了什么。真正的路由不是简单的排队，而是「利用当前最优」与「预测分配负载」之间的精妙平衡。&lt;/p&gt;&lt;p&gt;模型路由的门槛更高，它本质上是用 AI 去选 AI。系统需要通过海量数据学会「什么样的问题适合什么样的模型」，并在实际运行中不断回收结果进行离线纠偏。&lt;/p&gt;&lt;p&gt;归根结底，这是一套依赖长期数据积累、持续自我演化的系统，也是 AI Ping 作为中国版 OpenRouter 的护城河。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重塑交易秩序：&lt;/strong&gt;&lt;strong&gt;开发少做「选择题」，服务不再只有「价格战」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同用户的实践，从侧面印证了 AI Ping 作为「中国版 OpenRouter + Artificial Analysis」的现实价值。&lt;/p&gt;&lt;p&gt;对许多直接面向 C 端或 B 端用户的团队而言，在接入 AI Ping 之前，最大的困扰并非模型能力不足，而是被大量「非核心工程」消耗精力。&lt;/p&gt;&lt;p&gt;一位从事 ToB 智能客服助手的开发者回忆，过去团队长期陷在「工程师手动选型」的循环中：先接几家跑起来，再拿一批真实问题测效果、测延迟、测报错，最后再算一遍账。换一家就要重新适配、重新回归，周期非常长。&lt;/p&gt;&lt;p&gt;「判断哪个模型最好用，基本靠线上监控和经验。哪家最近延迟飘了，就人工降权，往往是用户先感知到卡顿，我们才开始补救，非常被动。」他们也曾考虑自建调度系统，但很快发现，这意味着还要额外承担监控、容灾和对账等复杂工程负担，更加偏离主线任务。&lt;/p&gt;&lt;p&gt;接入 AI Ping 后，这类「选型内耗」被工程化消解，大家又能把主要精力投入到客服体验上，比如知识库质量、流程引导，转人工闭环。&lt;/p&gt;&lt;p&gt;这种调度价值，在对成本高度敏感的场景中表现得更为直接。&lt;/p&gt;&lt;p&gt;一些独立开发者将 Agent 用于自用场景，对性能要求并不极致，但对成本控制极为敏感。通过 AI Ping 提供的筛选排序功能，开发者可以在多家供应商中，选出性价比最高的方案，比如 TTFT＜5 秒、TPS＞20 ，价格从低至高排序。同时，用户也可以在智能路由中使用此功能，智能路由会将用户的每一条需求，依据评测数据，路由至当前满足用户需求的最高性价比的服务商。&lt;/p&gt;&lt;p&gt;而在多模型协作场景中，调度能力则直接转化为商业可行性。&lt;/p&gt;&lt;p&gt;面团 AI 的模拟面试产品需要多模型协作，比如调用语音模型、文本语言模型，不同厂商的模型各有优势。过去，跨模型、跨平台调用流程复杂，成本也非常高。&lt;/p&gt;&lt;p&gt;统一接入 AI Ping 之后，团队再也不需要关心「既要接火山、又要接百度」的底层适配问题，模型调用起来成本更低，效率更高，服务性能也更加稳定。&lt;/p&gt;&lt;p&gt;以往找身边的学长进行一次模拟面试，往往需要付出半小时三四百元的成本。现在借助 AI 技术，只需几块钱，就可以实现一个高拟人度、高仿真的模拟面试。&lt;/p&gt;&lt;p&gt;类似逻辑也出现在情感陪伴应用中。一支清华大学学生团队发现，用户大部分提问是日常闲聊，少数才涉及深度推理。通过 AI Ping 的「分层调度」，简单问题流向低价小模型以保证「秒回」，关键情绪点则路由至高阶模型。这种精准分发，既避免了响应过慢导致的「冷暴力」，又将稳定性与价格压到了可控区间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;更耐人寻味的是，这套评测体系也在反向重塑服务商的行为&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;硅基智能成为平台的长期用户，一个重要原因在于测得准。通过横向评测，他们可以清晰看到自己在数十家服务商中的真实位置：延迟是否偏高，吞吐是否存在短板，稳定性如何随时间波动。&lt;/p&gt;&lt;p&gt;过去，服务商只能监控自身数据；如今，不同服务能力被放在同一把尺子下比较。当延迟、吞吐与稳定性被持续量化呈现，用户也开始以「服务质量」而非单一价格作为选择依据，行业竞争也由此从价格战转向工程优化与算力治理能力的比拼。&lt;/p&gt;&lt;p&gt;在师天麾看来，这将形成一个正向循环：评测数据让开发者知道什么是好服务，也让服务商看清自身短板。服务质量提升后，应用体验改善，AI 使用规模扩大，Token 消耗随之增长，收益再回流到算力与技术优化之中。&lt;/p&gt;&lt;p&gt;我们希望用透明的数据，让行业知道什么才是值得竞争的方向，他说，「不是只有价格，而是真正的服务能力。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;院士点赞，预见下一代基础设施&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在发布会上，中国工程院院士、清华大学计算机系教授郑纬民给出了一个颇具画面感的比喻。&lt;/p&gt;&lt;p&gt;过去十年，行业解决的是如何把智能「生产出来」。随着模型生态与智能体（Agent）的快速繁荣，新的瓶颈正在出现：如何让智能被高效、稳定地「流通」。&lt;/p&gt;&lt;p&gt;在他看来，智能路由正是这一流通体系中最关键的基础设施之一，也是下一阶段 AI Infrastructure 必须回答的问题。&lt;/p&gt;&lt;p&gt;当模型路由、服务路由、芯片调度全部打通后，用户只需提出需求，而无需关心背后究竟是哪个模型、哪一家云厂商、哪一块芯片在工作，结果便会自动抵达。&lt;/p&gt;&lt;section&gt;「这将是下一代 AI 基础设施的形态，」他说，「让智能像电一样被调用和分发。」&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>中途退学的艺术生，开发Web 3D项目，周下载量破400万</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 14:29:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;一个并不常被普通用户提起的开源项目，刚刚刷新了自己的历史纪录。&lt;/p&gt;&lt;p&gt;近日，Three.js 官方 X 账号公布：Three.js 每周下载量突破 400 万。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1449" data-imgfileid="503529444" data-ratio="1.4461077844311376" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK1OKSykj7lOesCtthaZNBokCK4klmLicbrUPibypRc1j9oDAeiaNdqPSeg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1002" data-width="1002" data-original-style="width: 502px;height: 726px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d29a80b0-3349-462f-94ad-7f2c77939565/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 链接：https://x.com/threejs/status/2013044943909191680&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;你或许没用过 Three.js ，也未必听过它的名字，但你大概率已经见过它的作品。&lt;/p&gt;&lt;p&gt;那些可以旋转的 3D 商品展示页、会随鼠标晃动的官网首页、可交互的数据可视化，甚至一些看似只是酷炫动画的 Web 页面背后，Three.js 正默默地承担着核心的 3D 渲染工作。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;注：Three.js 是一个基于 WebGL 的 JavaScript 3D 图形库，由 Ricardo Cabello（网名 Mr.doob）于 2010 年创建。它的核心目标是让开发者能够在浏览器中轻松创建和展示 3D 内容，而无需直接处理复杂的 WebGL 底层 API。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKfsG8h324YJTh0kq1fe5fz59SZqkZppexq4oueScuxYpicE3iaR5Dp8Dg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.7210379981464319" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503529445" data-aistatus="1" data-original-style="width:487px;height:351px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d69f1a34-7676-47d2-9ae0-6f11b113bdf4/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;在官网示例里，同一个图形界面你可以选择不同的状态如跑、跳。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKkK3m7etT4h9fNcLBQzNtOVANzNHenOQsAXUtib353bLxzYcFBAsaJiaw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.8202038924930491" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503529447" data-aistatus="1" data-original-style="width:486px;height:399px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/08bdab0a-c505-4c28-8222-c3b3b89893ab/640.gif" data-order="1" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKiaj4aHHwVXGPhA1bfr9Ya0A8M4YLMhC65MQm7nGe6jaPiamRPA0ibQPFA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.6265625" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503529451" data-aistatus="1" data-original-style="width:480px;height:301px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c374203f-67f1-47e5-a9be-89a44915bc0b/640.gif" data-order="2" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 来源：https://threejs.org/examples/&lt;a data-topic="1" href="javascript%3A;"&gt;#webgl&lt;/a&gt;_loader_gltf_transmission&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我们再回到官方发布的那张图，其展示了 Three.js 从 2016 年到 2026 年的周下载量变化，呈现出非常典型的指数级增长曲线：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2016-2018：起步阶段，下载量很低&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2019-2020：开始缓慢爬升，达到约 20-50 万 / 周&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2021-2022：增长明显加速，突破 100 万大关&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2023-2024：进入快速增长期，从 100 万攀升至 200 万&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2025-2026：爆发式增长，从 200 万直冲 400 万&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Three.js 快速增长的时间点很微妙，在 2022 年末，正好是 ChatGPT 问世之后，此后生成式 AI 快速爆发，Three.js 也趁着这股热潮疯狂吸引用户。&lt;/p&gt;&lt;p&gt;回想一下，在 AI 介入之前，用 Three.js 开发 3D 内容简直是一场劝退之旅。光是理解四元数、矩阵变换这些数学概念，再加上手工建模、展 UV、调材质的繁琐流程，就足以把 90% 的前端开发者挡在门外。那时候，一个简单的光照渲染或材质效果，往往需要耗费数小时调试。&lt;/p&gt;&lt;p&gt;但 AI 的出现彻底改变了游戏规则。你只需要在 ChatGPT 等大模型里随口描述需求：「用 Three.js 写一个赛博朋克风格的旋转发光立方体，背景要动态粒子星空」。AI 不仅能秒懂你的意图，还能在几秒钟内生成 95% 可用的代码，让那些原本只存在于脑海中的创意，瞬间在浏览器里转起来。&lt;/p&gt;&lt;p&gt;这样一来，AI 大模型极大地降低了 Three.js 的准入门槛，让大量前端开发者（而非图形学专家）敢于尝试 3D 开发。这也是 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Three.js 下载量暴增的原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Ricardo Cabello 介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ricardo Cabello，以网名 Mr.doob 更为人熟知。是 Three.js 的创始人和长期核心维护者，也是 Web 前端与创意编程领域最具影响力的人物之一。可以说，他一个人，直接改变了 Web 世界对 3D 的理解方式。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKEp2tRlQDNQFpIuHQVwnQCA3M8EkaUsjlktY0JYs4HtB7Fkf1Eia533A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1" data-type="png" data-w="768" data-width="768" data-height="768" data-imgfileid="503529452" data-aistatus="1" data-original-style="width: 318px;height: 318px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/37219446-4615-4daa-90b2-5c831b30be48/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;但与今天清晰的技术标签不同，他的成长路径并不循规蹈矩，甚至可以用他自己的话来形容 &amp;mdash;&amp;mdash; 有点灾难。&lt;/p&gt;&lt;p&gt;Ricardo 在一次采访中表示，他读完小学后，在后期还同时进入了一所学院学习漫画绘画；中学阶段一度转向电子工程，后来又改读艺术方向。然而那段时间并不适合系统性学习，最终在进入大学之前便选择了退学。&lt;/p&gt;&lt;p&gt;相比教育体系，真正塑造他的，是长期活跃于 demoscene（演示场景） 社群的经历。在那个以技术与创意竞赛为核心的文化中，创作者必须不断拿出新作品，逼着自己把想法真正做出来。&lt;/p&gt;&lt;p&gt;这段经历深刻影响了他后来的创作风格，追求用精简代码实现惊艳的视觉效果。正是在 demoscene 的环境里，Cabello 系统性地学习了计算机图形学，从最初的视觉创作，到逐渐理解其背后的技术原理，再到最终回到编程本身。艺术与代码不再是对立的两端，而是开始在他身上汇合。&lt;/p&gt;&lt;p&gt;工作之余，Cabello 也会关注一些关于艺术、插画、装置艺术的博客，这会时不时的激发他的创作灵感：能不能把这些东西做成实时的？而在实现的过程中，又会衍生出更多新的点子。&lt;/p&gt;&lt;p&gt;此外，Ricardo Cabello 还是 Web 创意文化的重要推动者。他长期维护的个人网站 mrdoob.com 汇集了大量实验性项目，涵盖物理模拟、粒子系统、交互艺术和声音可视化等方向。这些作品并不以商业化为目的，而是持续探索浏览器作为创意与表达平台的边界，这种对可玩性和表达力的重视，也深刻塑造了 Three.js 的气质，实用、开放，同时鼓励创造。&lt;/p&gt;&lt;p&gt;在开源上，Ricardo 以风格克制、标准严格著称。在他看来，把代码分享出来，让整个互联网都能受益，是一件非常有成就感的事。&lt;/p&gt;&lt;p&gt;他长期亲自把控 Three.js 的 API 设计与代码质量，宁可引入破坏性更新，也避免无序堆叠功能和历史包袱。这种近乎守门人的角色，使 Three.js 在十余年的演进中始终保持清晰的结构和一致的设计理念，避免了许多大型开源项目常见的复杂化和碎片化问题。&lt;/p&gt;&lt;p&gt;而这种工程上的克制，其实可以追溯到 Three.js 诞生之初的动机。Ricardo 曾回忆，创建 Three.js 一方面源于他的好奇心，如果亲手写一个 3D 引擎，究竟能做到什么程度；另一方面也是对自我能力的一次挑战。从 ActionScript 时代开始，他便反复尝试搭建 3D 引擎，在不断试错中学习图形学基础，并逐步摸索出更合理、可扩展的架构方式。更重要的影响则来自 demoscene 的经历：在那个圈子里，创作者往往为一两个 demo 临时写一套引擎，用完即弃。Ricardo 觉得这种方式过于浪费，于是产生了一个更长期的想法，做一个真正可以被反复使用、不断演进的 3D 引擎。这一想法，最终催生了 Three.js，也奠定了它至今仍在坚持的设计哲学。&lt;/p&gt;&lt;p&gt;直到今天，随着 AI 生成内容、WebXR 和 3D 可视化的兴起，Three.js 依然处在 Web 技术栈的关键位置。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>像开发软件一样造世界，Agent2World来了，把世界模型做成可运行的符号环境</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 14:25:11 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/19decf1a-da69-4353-bd46-6be423602374/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;让模型真正 &amp;ldquo;能行动&amp;rdquo;，往往需要一个可执行、可验证的符号世界模型（Symbolic World Model）：它不是抽象的文字描述，而是能被规划器或执行器直接调用的形式化定义 &amp;mdash;&amp;mdash; 例如 PDDL 领域 / 问题，或可运行的环境代码 / 模拟器。一旦世界被 &amp;ldquo;写成可运行的规则&amp;rdquo;，我们就能在同一套约束下进行推演、测试与复现：模型不再停留在 &amp;ldquo;会说&amp;rdquo;，而是能回答 &amp;ldquo;如果我这样做，会发生什么&amp;rdquo;，并用执行结果检验自己是否真的理解了这个世界。&lt;/p&gt;&lt;p&gt;问题在于，现有自动生成路线普遍陷入三重困局：脚本式工作流、知识边界封闭、表示覆盖单一。许多方法仍沿用固定的 &amp;ldquo;生成 &amp;mdash; 修复&amp;rdquo; 脚本，并以解析 / 规则匹配 / 固定检查集等静态校验为主：它们或许能修语法与格式，却常常抓不住只有在交互执行中才暴露的行为级错误（例如状态更新不一致、目标不可达、奖励机制失效）。与此同时，当任务规格含糊、缺失关键规则或背景常识时，系统缺少主动检索与补全机制，只能依赖模型记忆 &amp;ldquo;猜&amp;rdquo;。更关键的是，既有研究往往只覆盖一种世界模型表示（只做 PDDL，或只做可执行代码），导致同一任务难以在不同符号表达之间共享验证闭环与改进经验，限制了方法的通用性与可扩展性。&lt;/p&gt;&lt;p&gt;为攻克这一难题，研究团队提出 Agent2World：一个工具增强（tool-augmented）的多智能体框架，用 &amp;ldquo;知识合成（Knowledge Synthesis）&amp;rarr; 世界模型实现（World Model Generation）&amp;rarr; 评估驱动精炼（Evaluation-Driven Refinement）&amp;rdquo; 的三阶段闭环，把 &amp;ldquo;查资料补规格 + 写实现 + 交互测试纠错&amp;rdquo; 内化为可复用的生成范式，从而稳定产出高可执行、可验证的符号世界模型。&lt;/p&gt;&lt;p&gt;实验结果显示，Agent2World 在 Text2World (PDDL)、CWMB (MuJoCo) 和 ByteSized32 (文本游戏) 三大基准上均实现了 SOTA 性能。更关键的是，该框架展现了可持续改进潜力：基于 Agent2World 生成的高质量轨迹进行微调（SFT）后，模型性能显著跃升 &amp;mdash;&amp;mdash; 与训练前的同一模型相比，平均相对性能提升了 30.95%，有力证明了其作为高质量世界模型数据合成引擎的工程与研究价值。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwFsKjRo1UMw0lx9TDqNbsmiaTicFnZuegt5Rk5cnIoWb6wiajnfzP7FTiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.34629629629629627" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530145" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/bf4cc611-7a37-465c-9da0-559fd5aef25e/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址： https://arxiv.org/abs/2512.22336&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址： https://agent2world.github.io/&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址： https://huggingface.co/agent2world/llama3.1_8b_instruct_full_sft_v1_3_epoch&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址： https://github.com/DeepExperience/agent2world&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、深层归因：为何传统 &amp;ldquo;脚本式&amp;rdquo; 生成难以为继？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Agent2World 之前，自动生成世界模型的主流方案常采用固定的 &amp;ldquo;草稿 &amp;mdash; 修复（Draft-Repair）&amp;rdquo; 脚本：生成代码 &amp;rarr; 跑错 &amp;rarr; 看报错改代码。它能修语法，但很难保证 &amp;quot;跑起来&amp;quot; 的世界是对的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;被动脚本的死循环： 缺乏前瞻性规划，复杂任务里常陷入 &amp;ldquo;改一个 bug 引出新 bug&amp;rdquo; 的低效迭代。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;规格缺口带来的幻觉： 描述不完整时，模型往往只能靠记忆 &amp;quot;猜&amp;quot; 规则边界、接口细节与隐含前提，导致看似能跑、实则不自洽。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;表示覆盖单一的 &amp;quot;符号孤岛&amp;quot;： 既有研究往往只覆盖一种世界模型表示 &amp;mdash;&amp;mdash; 要么偏向 PDDL 的形式化规划，要么偏向可执行环境代码。两条路线各自为战，生成、验证与修复经验难以跨表示共享与迁移，同一问题在不同符号表达下往往需要重做一套流程，最终限制了方法的通用性与可扩展性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;归根结底，难点不只是 &amp;ldquo;写出代码&amp;rdquo;，而是要在真实约束下稳定产出可执行、可复现、可迭代的世界模型；而 &amp;ldquo;脚本式流程 + 单一表示覆盖&amp;rdquo; 的组合，正是阻碍这一目标的核心瓶颈之一。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwoibq10WzeSQhV1EvzftrqWiapfSkoa00XoybEViaIE5YUWfgxOwYQ6Rmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.47685185185185186" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530153" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a65b402b-5b4d-4211-be31-cb16de1805b4/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;二、方法拆解：把 &amp;quot;软件开发团队&amp;quot; 装进模型里&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 的核心不是 &amp;quot;多拉几个 agent 聊天&amp;quot;，而是把世界模型生成拆成软件工程式三阶段：Researcher 补规格、Developer 做实现、Testing Team 用单测 + 仿真交互做行为级验收，并把验收反馈反哺修复。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwTwSvVELxR9xYRxFaJgQKDanGUibD615f6WajrYncu4KQfHlVmcM38nw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530154" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/bda0ac97-5c83-4fea-95b9-7024e0e5907c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;1. Deep Researcher：主动打破知识壁垒&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现实任务往往信息不完备：目标相对清晰，但规则边界、参数范围、动作约束与接口细节并不完整，在不确定性与知识缺口的叠加下，极易导致事实性错误与幻觉。Deep Researcher 首先将任务描述分析并拆成一组待澄清问题（例如：允许的动作集合、状态变量定义、终止条件、异常情况与边界输入等），它配备了网络搜索和检索工具，能够迭代地从互联网检索构建世界模型所需的知识，并最终输出一个结构化的中间表示，其中缺失的信息已得到补充。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Model Developer：统一跨模态表达&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在获得补全后的规格后，Model Developer 负责生成目标世界模型（例如 PDDL 域 / 问题，或可执行的环境代码）。这一阶段不以 &amp;ldquo;写得像&amp;rdquo; 为目标，而以 &amp;ldquo;能执行、接口连通、与规格一致&amp;rdquo; 为硬约束。&lt;/p&gt;&lt;p&gt;因此 Developer 会在受控沙盒中进行基础运行检查与增量修复：一方面保证文件组织、函数签名、依赖与调用链正确；另一方面确保状态转移、动作前置条件与效果、终止判定等核心逻辑与规格对齐。该阶段的输出是一个可以被执行器 / 规划器直接调用的环境实例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Testing Team：双重防线杜绝幻觉&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是框架中的关键组成部分。不同于以往依赖静态验证器的方法，Testing Team 引入了动态的、行为级的双重验证机制，专门捕捉只有在交互中才会暴露的逻辑错误。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Unit Tester：它自动分析代码结构，生成 Pytest 风格的单元测试用例。重点验证接口契约（Contract）、谓词逻辑和不变式（Invariants）。例如，检查 step () 函数返回的状态维度是否与定义一致，或 PDDL 中的动作前置条件是否完备。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Simulation Tester：这是一个基于 ReAct 框架的智能体，以交互方式在环境中采集轨迹并诊断深层的问题，如动力学错误 &amp;mdash;&amp;mdash; 例如 &amp;ldquo;机器人执行了移动动作但坐标未更新&amp;rdquo;、&amp;ldquo;奖励函数在达到目标后未正确触发&amp;rdquo; 或 &amp;ldquo;状态转移违背物理常识&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一旦发现问题，Testing Team 会输出包含错误分析（Analysis）和修复建议（Suggest Fix）的结构化报告，驱动 Developer 进行针对性修复，直到通过所有测试或达到收敛条件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;进阶：从推理到训练，构建 &amp;quot;自进化&amp;quot; 的数据飞轮&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 的价值远不止于一个推理框架，它本质上是一个全自动的高质量数据合成引擎。研究团队通过 &amp;ldquo;任务合成 &amp;mdash; 轨迹筛选 &amp;mdash; 经验蒸馏&amp;rdquo; 的严密流程，将多智能体协作中的有效修复策略蒸馏为单体模型的生成与修复偏好。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;数据合成：验证器引导的拒绝采样，为了避免数据泄露并提升泛化性，团队并未直接使用测试集题目，而是自主合成（Self-Synthesized）了大量涵盖不同领域的全新任务。在此基础上，系统利用 &amp;ldquo;验证器引导的拒绝采样（Verifier-Guided Rejection Sampling）&amp;rdquo; 机制，从海量生成结果中筛选出 1526 条既通过沙盒运行、又通过双重测试校验的轨迹。这套数据集完整记录了 Developer 从错误代码到修复成功的高密度轨迹，为模型提供了极高价值的逻辑纠错样本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;监督微调：在训练阶段，团队精准提取 Model Developer 的交互轨迹对 Llama-3.1-8B-Instruct 进行监督微调。训练的核心目标并非让模型单纯模仿多智能体对话，而是让其学习 Developer &amp;ldquo;如何理解模糊规格&amp;rdquo; 以及 &amp;ldquo;如何根据 Testing Team 的报错修复代码&amp;rdquo;。通过这种方式，单体模型成功 &amp;ldquo;继承&amp;rdquo; 了多智能体系统中 &amp;ldquo;根据反馈迭代（Iterative Refinement）&amp;rdquo; 的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;三、实验验证：横扫三大基准，验证 &amp;quot;数据飞轮&amp;quot; 效应&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 在 Text2World（PDDL）/ CWMB（MuJoCo 可执行模拟器）/ ByteSized32（文本游戏环境）三大基准上都拿到领先表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. Text2World (PDDL)：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从 &amp;ldquo;能跑&amp;rdquo; 到 &amp;ldquo;懂逻辑&amp;rdquo; 的显著提升。以 GPT-4.1-mini 为底座，在衡量 PDDL 代码生成的基准中，Agent2World Multi 明显降低了代码 &amp;ldquo;跑不通&amp;rdquo; 的失败率，实现了 93.1% 的代码可执行率（Executability），相比强基线 Text2World ($EC=3$) 提升了 14.9 个百分点。更重要的是，它在衡量语义正确性的 Component-wise F1 指标上达到了 75.4（基线仅为 60.1），提升幅度达 15.3 分。这表明模型不再只是机械地模仿 PDDL 语法，而是更加理解了谓词约束与逻辑门控，生成了既符合语法又具备可解性的高质量规划域。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHw37cu5QgtDQmaxcAlyHcla4z2acOHVgHLaH5GUiaR3NtM9bhR1Dvfnkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530155" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e95aaea9-445f-48a9-b8da-8998131cacce/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. CWMB (MuJoCo)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不仅预测得准，更要 &amp;ldquo;好用&amp;rdquo; 。CWMB 同时评估 &amp;ldquo;仿真代码是否能预测动力学&amp;rdquo;（Accuracy）与 &amp;ldquo;作为世界模型能否支撑下游规划 / 控制&amp;rdquo;（Overall Normalized Return, R）。 在 GPT-4o-mini 上，Agent2World Multi 的 Overall R 达到 0.4811，相比此前最强基线 GIF-MCTS 的 0.3488 提升了 +0.132；并且在离散动作空间的预测准确率上与强基线持平（0.917 vs 0.914）。这说明，性能的提升并非来自单纯的下一帧预测相似度，而是源于模型实现了 &amp;ldquo;可用于规划的行为级一致性&amp;rdquo;，真正支撑起了下游控制任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwxUsQxs6ChQOK3ABSowz3PIibHApppYImnWT7IGf9WQGhH9kyF1icWToA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530156" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b6a7a83a-2160-4db1-81ad-fd2b929e7fad/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. ByteSized32 (Text Games)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;常识推理与物理现实的高度一致性。在极度依赖常识推理的文本游戏中，Deep Researcher 的主动知识检索发挥了很大的作用。Agent2World Multi 在核心指标 &amp;ldquo;物理现实对齐度（Physical Reality Alignment）&amp;rdquo; 上取得了 0.4768 的高分，相比单智能体版本（Single Agent）大幅提升了 0.2848 。 此外，在技术有效性（Technical Validity）上，模型生成的游戏代码初始化成功率接近 99% 。这些数据表明，通过引入外部知识与多轮测试，模型成功消除了大量违反常识的 &amp;ldquo;物理幻觉&amp;rdquo;（如错误的状态转移或不合逻辑的物品交互），生成了逻辑严密且更稳定的文本环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwapIA9jO5FS3HepUvFPa3xt2doRNIs30smZpJBv0bQP6QeLqpZtbquw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530157" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5902eef6-df91-4e4e-9955-469352fd87f5/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwRy2ex9FwR0MKDXnBCE3mwNhYdImI0JgPEKq3lfwGrbn4s6Ribr3Cu5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530151" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2b4cfdf8-5d19-462d-af82-fbae043b43b3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;4. 模型微调实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于自主合成的高质量轨迹数据（训练仅使用 Model Developer 轨迹），团队对 Llama-3.1-8b-instruct 进行了监督微调。实验表明，这种 &amp;ldquo;以 Agent 养 Model&amp;rdquo; 的策略带来了显著的泛化能力提升：微调后的模型在未见过的测试任务（Unseen Tasks）上，平均相对性能提升了 30.95%。特别是在 Text2World 任务中，模型生成的代码可执行率（Executability）提升高达 16.9%。这有力证明了，无需依赖昂贵的超大模型，仅凭小参数模型配合优质的 &amp;ldquo;自我修正&amp;rdquo; 合成数据，也能实现向高性能世界模型构建者的跨越。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. 消融实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;缺一不可的双引擎（基于 CWMB 验证） 为了探究 Agent2World 卓越性能的来源，团队在 CWMB（物理控制） 任务上进行了严苛的组件消融实验。结果证实，Deep Researcher 与 Testing Team 均是构建高可靠世界模型不可或缺的组件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;移除 Deep Researcher（知识引擎缺失）： 模型生成的模拟器在整体归一化回报（Overall Normalized Return, R）上出现显著下滑。这表明，在缺乏对物理参数与 API 规范的主动检索时，模型定义的环境规则会出现 &amp;ldquo;失真&amp;rdquo;，导致下游 Agent 无法在模拟中学习到在真实环境中有用的策略。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但当移除unit tester后，在离散动作空间的预测准确率显著下降约 30%。移除simulation tester，也会同比下降约3%。这揭示了一个关键发现：&amp;ldquo;能运行&amp;rdquo; 不等于 &amp;ldquo;物理正确&amp;rdquo;。没有动态交互产生的行为级反馈，模型很难在该设置下修正深层的动力学错误（如重力模拟偏差），生成的模拟器也因此失去了实用价值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwwY1dhIwMib1THfwBY6icT7drI5YclUO0g9xbnA83p8C6jiaQ9icnaC7JnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2574074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530152" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8d8d9034-af87-4936-a213-c106e7d4da12/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、结语：开启 AI 自主理解环境的新可能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 的提出，标志着统一多智能体框架在符号世界模型生成领域的成功应用。它不仅打破了 PDDL 规划与可执行代码之间的表征壁垒，更通过 &amp;quot;网络知识合成 - 迭代式模型开发 - 评估驱动仿真测试&amp;quot; 的精密闭环，在无需人工标注与人工验收的前提下，实现自动化的生成 &amp;mdash; 测试 &amp;mdash; 修复闭环，从而稳定产出可执行、可复现、可迭代的符号世界模型。这一突破不仅在三大基准测试中一致性地刷新了 SOTA，更为未来 AI 系统从自然语言中可靠地理解并形式化复杂的现实环境，开辟了全新的可能性。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
