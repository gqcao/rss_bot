<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>咖啡机变聪明后，我连咖啡都喝不上了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:50:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Sia&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;section&gt;目前还没有人真正解决这个问题：如何让 LLM 知道什么时候该精确、什么时候可以随机。&lt;/section&gt;&lt;/blockquote&gt;&lt;p data-pm-slice="0 0 []"&gt;这真是一个让人当场破防的早晨。&lt;/p&gt;&lt;p&gt;一位 The Verge 的科技记者起床、走进厨房、对着支持 Alexa 的博世咖啡机说了句，煮杯咖啡。&lt;/p&gt;&lt;p&gt;没有即兴发挥，也没提什么复杂要求，她只是希望机器老老实实执行一个早就设好的程序，结果，被拒绝了。&lt;/p&gt;&lt;p&gt;而且不是一次。&lt;/p&gt;&lt;p&gt;自从升级到 Alexa Plus（亚马逊的生成式 AI 语音助手）之后，这种对话几乎成了她的晨间固定项目。&lt;/p&gt;&lt;p&gt;每一次要它煮咖啡，Alexa 都能给出不同理由，以惊人的创造力告诉你，不行。&lt;/p&gt;&lt;p&gt;&lt;img alt="58 个梗图点子| 幽默, 搞笑, 迷因" data-aistatus="1" data-backh="229" data-backw="236" data-imgfileid="503525832" data-ratio="0.9703389830508474" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrOg05AAm5TMAVSnoU8227QfUMeibIdxVNv1mUnAXPxicbicUXMaoZn3ppg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="236" data-original-style="width: 259px;height: 251px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b60d4185-d146-49fb-a0ec-8077d05daa21/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/p&gt;&lt;p&gt;2025 年都快过去了，AI 会写论文、会写代码、会陪人聊天、会教书，却在清晨败给了一句&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;煮杯咖啡&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;在社区讨论中，类似吐槽场面非常壮观，可谓怨声载道。&lt;/p&gt;&lt;p&gt;开灯这个事儿，完全成了重灾区。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="225" data-backw="578" data-imgfileid="503525833" data-ratio="0.3895131086142322" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrtQmxicjhoOZ5ScCqJKGRSwtUVUqxmF6Rn6UCUbLzUR009Mic9sGPwofA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="801" type="block" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9eadcde3-3cbd-4f1d-83ac-8a90576d0ef8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrbsbDFaicYzYamX105u1icGYwSQljM33TNgznZZqM10gT8U1xX5icNDsXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5131086142322098" data-type="png" data-w="801" data-width="801" data-height="411" data-backw="562" data-backh="288" data-imgfileid="503525817" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/efdf8f11-258e-469d-a8dc-6e7a59140f88/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="286" data-backw="562" data-height="453" data-imgfileid="503525820" data-ratio="0.5084175084175084" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrgX6ibqlosK907iaCIgdBbk8ABlc7ib2P2ViakUuu405QfMbrux18fwgCpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="891" data-width="891" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/024e96c0-27c4-491a-b905-98d89f59aefb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr3UG3Argc2sKHNM2DGkhBqe5YLOzgEVkEHr73eWkBBBNPGicfA1tBkkA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.12222222222222222" data-type="png" data-w="1080" data-width="1128" data-height="138" data-backw="562" data-backh="69" data-imgfileid="503525818" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a311f228-643c-4362-8aec-6261d9e92be4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="278" data-backw="562" data-height="510" data-imgfileid="503525823" data-ratio="0.4941860465116279" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrMC3Wq7XKkb7ktz3icnpk6Qyk2d6nkiatTrEBNCgWYyzvCnvGhJCC6qEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1032" data-width="1032" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1cb4b4af-351e-4aec-b55e-07a23756a93b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="70" data-backw="562" data-height="141" data-imgfileid="503525821" data-ratio="0.12407407407407407" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrVPAvQrib9j6gQsxKRjXWwiaw5Adk325d2aTsgXxDRe7INSyD38gqp0tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" data-width="1134" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ec10f489-fafd-4cb0-bd43-53ebb547ddf5/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;播放歌曲也是艰难。&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="127" data-backw="562" data-height="243" data-imgfileid="503525819" data-ratio="0.22562674094707522" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrsGh85LiaQNcl9iaoIeyx2g1TflMFd7LVfoibibclETaY1QCnBN6qB2WkVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1077" data-width="1077" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7ab0151d-d713-475e-8a22-4bb3ea6bce01/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;定个时也这么难了啊。&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="72" data-backw="562" data-height="144" data-imgfileid="503525816" data-ratio="0.1287037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrSuBKq1rbLq1FL3QfwrI6NMpGRa0nbGbfU2tFY1XRTAnc13J2zltdRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="1080" data-width="1116" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/8754d53c-d337-4645-a30e-15b06dca65aa/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;彻底心灰意冷的也有。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-backh="61" data-backw="578" data-imgfileid="503525866" data-ratio="0.10555555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrf7AauzZZCVsjUlRfiayWR8GIWldK6xSnv1mfh5mlU98h4KHmn94u9PA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9e739da4-2121-48bf-950f-cde94939cabe/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;显然，现实与大家对 AI 的直觉预期，构成了鲜明反差。&lt;/p&gt;&lt;p&gt;传统助手虽然笨吧，但高度确定，只要你把（有点傻的）&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;咒语&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;念对，结果总是可以预期的。&lt;/p&gt;&lt;p&gt;现在好了，以 LLM 为核心的生成式AI助手，智商是高了，理解是深了，表达是丰富了，却偏偏在它们原本最擅长的事情上频频翻车：&lt;/p&gt;&lt;p&gt;开灯、设定计时器、播报天气、播放音乐、运行 Routine。&lt;/p&gt;&lt;p&gt;&lt;img alt="港產片｜這些經典對白梗圖你知道出處嗎？ | 影視時尚| 潮遊生活| 當代中國" data-aistatus="1" data-backh="317" data-backw="562" data-imgfileid="503525868" data-ratio="0.5635416666666667" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr06ywibZXIziczXneOAWJnxEIR4n4mom6rhuKBc4Ae4LZzGLkOiav3TYYg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-type="jpeg" data-w="960" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/ad4dd05d-8c58-4b7b-806f-44fe6c80113e/640.png" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;为什么会这样？&lt;/p&gt;&lt;p&gt;因为，LLM 天生引入了大量随机性。它能理解更多含义，也允许更自由的表达，但代价是：解释空间被极大放大了，包括误解的可能性。&lt;/p&gt;&lt;p&gt;你向 ChatGPT 提出同一个问题，今天和明天得到不同答案，这正是它的价值所在。但当这种特性被用于控制一台咖啡机时，就有问题了。&lt;/p&gt;&lt;p&gt;在要求即时、可重复、零容错的控制场景下谈概率，本身就是一个大 bug。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-height="192" data-imgfileid="503525822" data-ratio="0.17037037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrVdUeqfe45qhxAXfZPNwEPViarwVPxp5awMNiaBzZ6NKQJ7W9I858NP8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" data-width="1125" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/657530c7-7b33-4480-b710-dceed29393d9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;相比之下，传统语音助手的本质，其实是模板匹配器。它们并不理解，只是识别关键词，然后填参数。&lt;/p&gt;&lt;p&gt;比如你说&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;播放广播&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;，系统非常清楚，后面只可能跟&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;电台名称&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;为了弥补生成式模型在确定性上的短板，亚马逊和谷歌都尝试将 LLM 与智能家居 API 深度绑定。但这又引入了新的问题。&lt;/p&gt;&lt;p&gt;LLM 确实不擅长在每一次请求中，都生成完全一致、语法严格正确的系统调用。&lt;/p&gt;&lt;p&gt;而当它们被要求直接生成 API 调用、去控制真实设备时&amp;mdash;&amp;mdash;哪怕是一个极小的偏差，都可能导致整个操作失败。&lt;/p&gt;&lt;p&gt;这正是为什么，你的咖啡机有时就是死活不肯给你做咖啡。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="200" data-backw="562" data-height="399" data-imgfileid="503525824" data-ratio="0.35555555555555557" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrJQ4ElmQgLsTjqakGgvMaAXytcC8bUWcQq0aIKfSXcqFDss44aooZcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" data-width="1122" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/35ab64d9-397b-4c44-a6aa-23c5281afd4f/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;理论上，让新助手达到旧助手那样的可靠性，并非不可能，但这需要极其大量的工程投入、约束设计和失败兜底。&lt;/p&gt;&lt;p&gt;而在资源有限、 &lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;做点更刺激、也更赚钱的事情&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;诱惑又足够大的现实里， 最简单的路径就是先把技术推到现实世界中，再让它慢慢自我修正。&lt;/p&gt;&lt;p&gt;换句话说，我们正在集体扮演一个角色：AI 的长期内测用户。&lt;/p&gt;&lt;p&gt;目前还没有人真正解决&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;如何让 LLM 知道什么时候该精确、什么时候可以随机&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;的问题。所以，大家可能要在相当长的一段时间里，不断和它较劲、和血压搏斗。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="204" data-backw="350" data-imgfileid="503525934" data-ratio="0.5828571428571429" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvruvgz6GGT4RpoYZMtJBxK7eEaUGstLxeFVHPLhln9bJh3ib75aStxssA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-type="gif" data-w="350" type="block" data-original-style="width:441px;height:257px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/b2fd925a-05e3-446e-897e-f30323866f0c/640.gif" data-order="0" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;既然如此，为什么还要坚定地抛弃旧技术？&lt;/p&gt;&lt;p&gt;两个字：潜力。&lt;/p&gt;&lt;p&gt;所谓的代理式 AI（Agentic AI），让系统具备服务链式调用的能力：它能够理解复杂任务之间的内在关系，并在此基础上动态生成执行逻辑。&lt;/p&gt;&lt;p&gt;这也是旧技术路线必须被放弃的根本原因。&lt;/p&gt;&lt;p&gt;过去，基于固定规则与关键词匹配的语音系统，在架构层面就被限定为&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31);font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif;font-size: 15px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-align: start;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;display: inline !important;float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「&lt;/span&gt;&lt;/span&gt;单指令执行器&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;，它们无法理解目标、拆解任务，更不可能在运行时生成新的行动路径。&lt;/p&gt;&lt;p&gt;这不是一次简单的技术升级，而是一次能力范式的切换。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="300" data-backw="300" data-imgfileid="503525933" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrWHLXEvlPETpaxh3nHll3vRDJUgibc6ROeLKFfjyVkK2dw4ZzuLZTMTA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=15" data-type="gif" data-w="300" type="block" data-original-style="width:378px;height:378px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/4b615278-c574-4d08-b93e-beef9648b7da/640.gif" data-order="1" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;回到社区舆论，虽然连最基本的指令都出错，但网友们也承认，升级后的语音助手在理解复杂命令这件事上，确实更强了。&lt;/p&gt;&lt;p&gt;比如你说，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;这里调暗一点，温度再高一点。&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt; 它可以同时调灯和调恒温器。&lt;/p&gt;&lt;p&gt;当质问&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;Alexa，你到底在干嘛？为什么不关掉我的音乐？！&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt; 它真的会去查一下发生了什么。&lt;/p&gt;&lt;p&gt;放在过去，这些都是不可想象的。&lt;/p&gt;&lt;p&gt;最为人称道的是是摄像头通知功能的变化。&lt;/p&gt;&lt;p&gt;传统系统往往只有一句高度概括的废话，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;后院检测到运动。&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;于是你不得不：打开 App &amp;rarr; 点开视频 &amp;rarr; 回看 &amp;rarr; 发现是一只猫。&lt;/p&gt;&lt;p&gt;现在，新系统会直接告诉你，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;门口出现了不熟悉的面孔，但没有进入院子。&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;用语音设置复杂 Routine，也确实比在 Alexa App 里一层层点设置来得轻松，哪怕这些 Routine 运行起来并不那么稳定。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="512" data-backw="512" data-imgfileid="503525935" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr1ZRhMQelUklrxZnk6zad4ZsvV160PgTzH9I6ib06lkbnyAdevEEQL1g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=16" data-type="gif" data-w="512" type="block" data-original-style="width:435px;height:435px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/6cddca10-f848-49f4-a9c3-5d789ec1290e/640.gif" data-order="2" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在大量用户讨论中，也逐渐形成了一个相对温和的共识：问题不在于是否引入 AI，而在于&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;边界&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;、是否试图用 AI 替代一切。&lt;/p&gt;&lt;p&gt;一些用户认为，更合理的方向不是&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;去按钮化&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;&amp;mdash;&amp;mdash;取代那些已经被验证过的、确定性的执行机制，而是让 AI 帮助人理解系统。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="148" data-backw="562" data-height="303" data-imgfileid="503525825" data-ratio="0.2638888888888889" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrib6tLj2YEiaj1DIyHRoDgibM80cvKr08BeYDllNbnIPrqrpYnC9nuQWcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-type="png" data-w="1080" data-width="1149" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/05ec9e55-444b-423b-8a36-8c4c8566188c/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当前出现的混乱，或许并不是生成式 AI 的失败，而是其被放置在了一个并不适合它的核心位置。&lt;/p&gt;&lt;p&gt;不过，至少在今天，这条清醒的边界远未被勾勒出来，也不知什么时候能被画出来。&lt;/p&gt;&lt;p data-end="237" data-pm-slice="0 0 []" data-start="205"&gt;那么，你的智能家具还好吗？有没有过类似的抓狂瞬间？欢迎来评论区唠唠。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/tech/845958/ai-smart-home-broken&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/technology/comments/1pvh1c8/how_ai_broke_the_smart_home_in_2025_the_arrival/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026｜相聚新加坡，探讨AI时代最核心难题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:45:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;活动 1&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题：在 AI 重构人类主体性的时代，如何捍卫我们的自主决断权？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在人工智能潜移默化地重构人类能动性 (Human Agency) 的当下，我们该如何保留有意义的人类自主决断权？&lt;/p&gt;&lt;p&gt;诚邀您参加由 AI Singapore 主办的「&lt;strong&gt;工作、学习、拥有与选择的权利&amp;rdquo; (The Right to Work, Learn, Own &amp;amp; Choose)&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;研讨会。本次会议旨在探讨技术型 AI 社区与 AI 治理社区如何深度融合，共同推动尊重人类主体性，并维护我们在工作、学习、所有权及选择权方面权益的 AI 系统发展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFZAFDCG3BZRSTRfD33ovjVzmAoHEDFuIn01qyYJvLP3UIwTFIIAFaicQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.4148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528551" data-aistatus="1" data-original-style="width:523px;height:740px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/dd72b408-a8c8-48b3-a83d-8a0e0515b55a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;本次研讨会邀请了多位重量级嘉宾，包括 Ashok Goel (佐治亚理工学院)、Jungpil Hahn (新加坡国立大学计算机学院)、Luke Zettlemoyer (华盛顿大学 &amp;amp; Meta FAIR) 以及 Djallel Bouneffouf (IBM 研究院)。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF0pJVKg7kn3nbPrG3HaynUdelpa18xX4YYUItLnKM8Ep7Wia8QkWjG3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528552" data-aistatus="1" data-original-style="width:535px;height:757px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5f2f70bd-7228-43ee-b26a-c35b6047497f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;会议详情： &lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;日期： 2026 年 1 月 23 日（星期五）&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;时间： 08:30 - 13:30&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;地点： 新加坡国立大学 COM3 多功能厅 (11 Research Link, Singapore 119391)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现场将提供午餐及茶点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注册链接：&lt;/strong&gt; https://luma.com/xyon5cw4 (截止日期：2026 年 1 月 22 日)&lt;/p&gt;&lt;p&gt;主办方将发送确认邮件以确认您的名额。&lt;/p&gt;&lt;p&gt;注：本次活动是新加坡 AI 研究周 (Singapore AI Research Week) 的一部分，与 AAAI2026 同期举行。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动 2&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题：探索 Agentic AI、自主智能体与多智能体系统的前沿融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;想要了解基于大语言模型 (LLM) 的智能体的前沿进展，以及构建和部署这些系统的经验教训吗？&lt;/p&gt;&lt;p&gt;诚邀您参加由新加坡国立大学人工智能研究所 (NAII)、DSO 国家实验室与亚马逊云科技 (AWS) 联合举办的专题研讨会：「&lt;strong&gt;Agentic AI meets Autonomous Agents and Multiagent Systems。&lt;/strong&gt;」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF8SMH1Pv1IY1ZxficxiaaKz2Dt6VIxwBKq1IXwzWxneQSYyHzInWtROfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.413888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528553" data-aistatus="1" data-original-style="width:498px;height:704px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/59d7d801-f6d3-42d3-aee9-78f3b53480f7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;现代 &amp;quot;Agentic AI&amp;quot; 系统（例如 LLM 驱动的智能体、使用工具的 Copilot 以及自主工作流）正从精心编排的演示 (Demos) 走向实际部署。这一转变要求系统具备长程规划能力、可靠的工具使用能力，以及与人类和环境进行稳健交互的能力。&lt;/p&gt;&lt;p&gt;本次研讨会不仅关注当下的 Agentic AI，更将其作为审视机器人学、具身智能 (Embodied AI) 以及多智能体系统 (Multiagent Systems) 中长期挑战的透镜。通过连接这些视角，我们旨在发掘共同面临的开放性问题，并激发跨领域合作，推动 Agentic AI 向更可靠、安全和高性能的方向发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;特邀演讲嘉宾：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Leslie Kaelbling (麻省理工学院 MIT)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Bo Li (伊利诺伊大学香槟分校 UIUC)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Pang Wei Koh (华盛顿大学 &amp;amp; Ai2)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Frank Dignum (瑞典于默奥大学)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFic38EMfO6tsEZX1EOKGJ1dGnx95FBbUrM9U1lQBpXUPHkCCZe1WqBWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.413888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528554" data-aistatus="1" data-original-style="width:500px;height:707px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4fd8ee4a-d22b-4505-a07e-d2dd2d7f6844/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;活动详情：&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;日期： 2026 年 1 月 21 日（星期三）&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;时间： 13:00 - 18:00&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;地点： 新加坡国立大学 COM3 多功能厅 (11 Research Link, Singapore 119391)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现场将提供茶点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;立即注册&lt;/strong&gt;： https://luma.com/9hz1jyvg&lt;/p&gt;&lt;p&gt;主办方将发送确认邮件以确认您的名额。&lt;/p&gt;&lt;p&gt;注：本次活动是新加坡 AI 研究周 (Singapore AI Research Week) 的一部分，与 AAAI2026 同期举行。&lt;/p&gt;&lt;p&gt;以上邀请是 &amp;ldquo;on behalf of 新国立副校长 Bryan Low &amp;nbsp;,助理教授 刘钿渤 &amp;rdquo;。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谷歌工程师抛出5个残酷问题：未来两年，软件工程还剩下什么？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:42:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;软件行业正站在一个颇为微妙的拐点上。AI 已经从自动补全代码，演进为能够自主执行开发任务的智能体。&lt;/p&gt;&lt;p&gt;在这一变化之下，初级开发者和高级开发者正同时被推入各自不同、却同样棘手的困境之中。&lt;/p&gt;&lt;p&gt;对初级开发者而言，最大的挑战不在于会不会写代码，而在于还没来得及成长，练级空间就被压缩了。企业不再愿意为学习成本买单，初级岗位要么减少，要么被要求一上来就能独立产出。&lt;/p&gt;&lt;p&gt;而对高级开发者来说，处境同样不好过。AI 并没有让他们更轻松，而是让责任进一步集中。当团队规模缩小、初级人手减少，高级工程师往往既要做架构决策，又要兜底 AI 和自动化系统带来的各种隐性风险，代码质量、性能、安全、合规。写代码的比例在下降，但判断、评审和决策的压力却在上升，一旦系统出问题，责任仍然落在人身上。&lt;/p&gt;&lt;p&gt;接下来会发生什么，充满了不确定性。&lt;/p&gt;&lt;p&gt;Addy Osmani，来自谷歌的一名软件工程师，在一篇文章中提出了 5 个可能在 2026 年前重塑软件工程的关键问题，并为每个问题给出两种截然不同的走向。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="399" data-imgfileid="503528238" data-ratio="0.3453703703703704" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiczH3BljB58qB12ATwIAHhVjuyFBWSghCgia6xgZwZlCUXhGXbgg6td0w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1154" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/abc09958-2bd4-4bc7-8c6d-a5ec751cc27d/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;文章链接：https://addyosmani.com/blog/next-two-years/&lt;/p&gt;&lt;p&gt;这五个问题都指向同一件事，软件工程正在从写代码的职业，转变为驾驭复杂系统与 AI 的职业。未来不是单一答案，而是多种路径并存，谁能适应变化，谁就能留下来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;初级开发者之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;结论很直接：随着 AI 开始自动化入门级任务，初级开发者的招聘可能会出现崩塌；也可能随着软件渗透到几乎所有行业而重新反弹。这两种未来都存在，但对应的生存策略完全不同。&lt;/p&gt;&lt;p&gt;像传统路径，学会编程、拿到初级岗位、逐步成长为高级工程师正在动摇。一项覆盖 6200 万名劳动者的哈佛研究发现，当企业采用生成式 AI 后，在六个季度内，初级开发者的就业人数下降了大约 9%&amp;ndash;10%，而高级开发者的就业几乎没有变化。过去三年，大型科技公司招聘的应届毕业生数量减少了 50%。正如一位工程师略带讽刺地说：既然一个 AI 编码智能体的成本更低，为什么还要花 9 万美元去雇一个初级工程师？&lt;/p&gt;&lt;p&gt;这并不只是 AI 的问题。像利率上升等宏观因素，在 2022 年左右就已出现影响，那时 AI 工具还未大规模普及。但 AI 加速了这一趋势。如今，一名配备 AI 辅助的高级工程师，产出已经相当于过去一个小团队的工作量。相比裁员，许多公司更常见的做法是悄悄地不再招聘初级开发者。&lt;/p&gt;&lt;p&gt;反过来的情景是：AI 在所有行业，而不仅仅是科技行业，释放出对开发者的巨大需求。医疗、农业、制造业、金融业都开始大规模嵌入软件和自动化。AI 不是取代开发者，而是成为一种放大器，把开发工作扩展到过去几乎不雇程序员的领域。初级岗位会更多出现，但形式不同：那些能快速为特定细分场景构建自动化和集成方案的 AI 原生开发者。&lt;/p&gt;&lt;p&gt;美国劳工统计局预计，2024 年到 2034 年间，软件相关岗位将增长约 15%。如果企业选择用 AI 来扩大产出，而不是单纯压缩人力规模，它们仍然需要人类去把握 AI 创造的新机会。&lt;/p&gt;&lt;p&gt;但悲观情景的一个长期风险常常被忽视：今天的初级开发者，就是 5 到 10 年后的高级工程师和技术领导者。如果完全切断人才培养管道，最终会造成领导力真空。行业老兵将这种现象称为缓慢衰退，一个停止培养接班人的生态系统。&lt;/p&gt;&lt;p&gt;如何应对？&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要让自己具备 AI 使用能力并保持多面性。证明一名初级开发者 + AI 的组合，能够匹配一个小团队的产出。使用 AI 编码智能体（如 Cursor、Antigravity、Claude Code、Gemini CLI）来构建更大的功能模块，但要理解并能解释其中的每一行代码，至少是大部分代码。把重心放在 AI 不容易替代的能力上：沟通能力、问题拆解能力、领域知识。将相邻岗位（如 QA、开发者关系、数据分析）视为切入口。建立作品集，尤其是包含 AI API 集成的项目。考虑学徒制、实习、合同制工作或参与开源项目。不要成为又一个需要大量培训的应届生，而要成为一个能够立刻产生价值、并且学习速度很快的工程师。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，初级人员减少意味着更多基础性工作会落到自己身上。要用自动化来应对日常事务，但不要什么都自己做。搭建 CI/CD、代码规范检查工具以及 AI 辅助测试，以捕捉基础问题。通过开源项目或辅导其他部门的同事，进行非正式的指导。如果未来初级岗位需求回升，要准备好高效地进行入职引导，并以结合 AI 的方式进行任务分配。你的价值不在于自己写了多少代码，而在于放大整个团队的产出。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528242" data-ratio="0.5895765472312704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicPgNrXjoliaeCr6aXeuCPkDmqD7qWnmSPm7zUSRbl57AQATosCkZmC3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="921" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ef33c45d-7e16-4101-b86a-fd474139c8b0/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;技能之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：当 AI 编写了大部分代码之后，编程基本功要么会逐渐退化，要么会因为人类开发者转向监督与把关而变得比以往任何时候都更重要。接下来的几年，将决定我们究竟是用理解力换速度，还是在效率提升的同时守住理解。&lt;/p&gt;&lt;p&gt;如今，已有 84% 的开发者在日常工作中经常使用 AI 辅助。对许多人来说，面对一个 Bug 或新功能时的第一反应，不再是从零开始写代码，而是先写一个提示词，把 AI 生成的代码片段拼接起来。入门级开发者正在跳过最难的那条路：他们可能从未亲手实现过一棵二叉搜索树，也从未独立排查过一次内存泄漏。&lt;/p&gt;&lt;p&gt;技能结构正在发生迁移：从实现算法，转向知道如何向 AI 提出正确的问题，并验证它的输出。职业阶梯的第一步，不再要求展示纯粹的编码能力，而是能够熟练地提示 AI、校验结果。一些资深工程师担心，这会催生出一代无法独立高质量写代码的开发者，一种事实上的去技能化。而 AI 生成的代码往往会引入隐蔽的 Bug 和安全漏洞，经验不足的开发者很容易忽略这些问题。&lt;/p&gt;&lt;p&gt;另一种对立的情景是：当 AI 处理掉 80% 的常规工作后，人类将专注于最困难的那 20%。架构设计、复杂集成、创造性设计、边界情况 &amp;mdash;&amp;mdash; 这些仍然是机器单独难以解决的问题。AI 的普及并不会让深度知识过时，反而会让人类专家的价值更加凸显。这正是高杠杆工程师：他们把 AI 当作放大器，但必须对系统有深入理解，才能真正驾驭它。&lt;/p&gt;&lt;p&gt;如果每个人都能使用 AI 编码智能体，真正区分优秀开发者的，是能否判断 AI 何时是错误的，或次优的。一位资深工程师曾这样说过：最好的软件工程师，不是写代码最快的人，而是最清楚什么时候不该相信 AI 的人。&lt;/p&gt;&lt;p&gt;编程工作的重心正在转移：更少时间用来敲模板代码，更多时间用来审查 AI 输出是否存在逻辑错误、安全缺陷，或与需求不匹配的问题。关键能力逐渐变成软件架构、系统设计、性能调优和安全分析。AI 可以很快生成一个 Web 应用，但只有经验丰富的工程师，才能确保它遵循了安全最佳实践，没有引入竞态条件。&lt;/p&gt;&lt;p&gt;在 2025 年，开发者社区的讨论明显分裂。一些人坦言自己几乎不再手写代码，认为面试和考核方式也应该随之演进；另一些人则认为，跳过基础训练会导致在 AI 输出失效时陷入更频繁、更痛苦的救火。整个行业开始期待工程师同时具备两种能力：AI 带来的速度，以及支撑质量的基础智慧。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要把 AI 当作学习工具，而不是拐杖。当 AI 编码智能体（如 Cursor、Antigravity、Claude Code、Gemini CLI）给出代码时，主动复盘它为什么能工作、哪里可能存在问题。偶尔关闭 AI 辅助，亲手实现关键算法。优先夯实计算机科学基础：数据结构、算法、复杂度分析、内存管理。一个项目可以做两遍，一遍借助 AI，一遍不借助 AI，对比差异。学习提示词工程和工具使用技巧。同时训练严谨的测试习惯：编写单元测试，在不立刻求助 AI 的情况下阅读堆栈信息，熟练使用调试器。深化 AI 难以复制的互补能力：系统设计、用户体验直觉、并发问题的推理能力。向外界证明，你既能借助 AI 高效产出，也能在它失效时解决棘手问题。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要将自己定位为质量与复杂性的守门人。持续打磨核心专长：架构、安全、可扩展性以及领域知识。练习在系统中引入 AI 组件时的整体建模，并提前思考失败模式。持续关注 AI 生成代码中暴露出的新型漏洞。主动承担导师和评审者的角色，明确哪些场景可以使用 AI，哪些场景必须人工审查（例如支付或安全相关代码）。把精力更多放在创造性和战略性工作上，让初级开发者 + AI 的组合去处理常规的 API 对接，而你来决定应该构建哪些 API。投资软技能和跨领域知识，持续跟进新工具和最佳实践。最终，进一步强化那些让人类开发者不可替代的能力：稳健的判断力、系统级思考，以及培养他人的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528243" data-ratio="0.6175925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicfIzSfXLNBHxg6YrSL2VuNkCFJrdHAuib940tYnYlqiaDYBgmWHic2ILiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cb39a5be-5ca3-4655-9ece-519525cececc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;角色之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：开发者这一角色，可能会收缩为一种有限的审计岗位（主要负责监督 AI 生成的代码），也可能扩展为一个关键性的编排者角色，负责设计和治理由 AI 驱动的系统。无论走向哪一种未来，创造价值都不再只是写代码本身。&lt;/p&gt;&lt;p&gt;这里的两种极端非常鲜明。在其中一种设想中，开发者的创造性职责被明显削弱。他们不再真正构建软件，而是主要负责审计和看护 AI 的输出。AI 系统承担实际生产；人类开发者检查自动生成的代码，查找错误、偏见或安全问题，并批准部署。创造者变成了检查者，写代码的乐趣被风险管理的焦虑所取代。&lt;/p&gt;&lt;p&gt;已经有报道称，一些工程师花在评估 AI 生成的 pull request 和管理自动化流水线上的时间越来越多，而从零开始写代码的时间却越来越少。编程逐渐不像是一种创造性的问题求解，更像是一种合规性工作。一位工程师曾无奈地感叹：我不想最后变成一个代码清洁工，只是收拾 AI 扔过来的烂摊子。&lt;/p&gt;&lt;p&gt;另一种未来则要有意思得多：开发者进化为高层次的编排者，融合技术、战略与伦理责任。随着 AI 工人的出现，人类开发者承担起类似架构师或总承包商的角色，负责设计整体系统，决定哪些任务交给哪一个 AI 或软件组件，并将众多运转中的部件编织成一个完整方案。&lt;/p&gt;&lt;p&gt;一位低代码平台的 CEO 曾这样描述这一愿景：在 Agentic 的开发环境中，工程师会成为作曲家，指挥由多个 AI 智能体和软件服务组成的合奏。他们不会亲自写下每一个音符，但会定义旋律 &amp;mdash;&amp;mdash; 系统架构、接口，以及各个智能体如何交互。这个角色本身具有跨学科和创造性：既是软件工程师，又是系统架构师，同时还是产品战略制定者。&lt;/p&gt;&lt;p&gt;更乐观的看法是：当 AI 接管重复性劳动后，开发者的角色将被迫转向更高价值的活动。工作本身反而可能变得更有意思。总得有人决定 AI 应该构建什么，验证产品是否合理，并不断对其进行改进。&lt;/p&gt;&lt;p&gt;最终走向哪一条路，很大程度上取决于组织如何选择整合 AI。把 AI 视为劳动力替代品的公司，可能会缩减开发团队规模，让留下来的工程师负责维持自动化系统运转；而把 AI 当作团队放大器的公司，则可能保持相近的人员规模，但让每位工程师承担更宏大的项目。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要主动寻找不只是写代码的机会。可以自愿参与测试用例编写、CI 流水线搭建或应用监控等工作，这些能力都与审计者 / 看护者角色高度契合。同时，通过个人项目保持对创造性编码的热情，避免失去构建的乐趣。培养系统思维：学习各个组件如何通信，理解什么样的 API 才算设计良好。多阅读工程博客和系统设计案例。熟悉代码生成之外的 AI 与自动化工具，例如编排框架和 AI API。提升书面和口头沟通能力，写文档时假设读者是另一个人。向资深同事请教时，不只问我的代码能不能跑，而要问我是不是考虑到了该考虑的事情。为自己做好准备，成为验证者、设计者和沟通者，而不仅仅是写代码的人。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要主动拥抱领导力和架构层面的责任。塑造 AI 和初级成员遵循的标准与框架，制定代码质量清单和负责任使用 AI 的规范。持续关注 AI 生成软件在合规与安全方面的新问题。把重心放在系统设计和集成能力上，主动梳理跨服务的数据流并识别潜在失效点。熟练使用各种编排平台，如 Kubernetes、Airflow、无服务器框架以及智能体编排工具。进一步强化技术导师的角色：更多代码评审、设计讨论和技术规范输出。打磨快速评估他人（或 AI）代码并给出高层次反馈的能力。同时培养产品和业务意识，理解为什么要做某个功能，以及用户真正关心什么。可以旁听产品经理的工作，或参与用户反馈会议。通过原型开发、黑客松或前沿技术研究，保护并延续自己的创造热情。从写代码的人，进化为指挥全局的指挥家。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;专才还是通才之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：过于狭窄的专才，面临其细分领域被自动化或淘汰的风险；而在一个快速变化、深度融入 AI 的环境中，更受青睐的是 T 型工程师，既具备广泛的适应能力，又在一两个方向上有深度专长。&lt;/p&gt;&lt;p&gt;在模型、工具和框架不断兴衰更替的背景下，把整个职业生涯押注在单一技术栈上，风险越来越高。某个传统框架的专家，可能会突然发现，当新的 AI 工具几乎不需要人工干预就能处理那套技术时，自己的需求度迅速下降。那些只专注于某一个技术栈、某一个框架或某一个产品领域的开发者，可能一觉醒来就发现，这个领域正在衰退，甚至变得多余。&lt;/p&gt;&lt;p&gt;回想一下 COBOL 开发者、Flash 开发者，或那些在行业转向时未能及时转型的移动游戏引擎专家。不同之处在于，如今变化的速度更快。AI 自动化可以让某些编程任务变得极其简单，从根本上削弱那些围绕这些任务建立起来的岗位。一个只会做一件事的专家（比如精调 SQL 查询，或把 Photoshop 设计稿切成 HTML），可能会发现 AI 已经承担了其中 90% 的工作。&lt;/p&gt;&lt;p&gt;招聘市场总是在追逐最新的细分领域。几年前，云基础设施专家炙手可热；如今，AI/ML 工程师成为焦点。那些只深耕于昨日技术的人，往往会在该领域失去吸引力时陷入停滞。&lt;/p&gt;&lt;p&gt;与此相对的是一种新的专业化形态：多面手式的专才，或者说 T 型开发者。他们在一到两个领域具备深度专长（纵向的一笔），同时对许多其他领域有广泛了解（横向的一笔）。这类工程师往往成为跨学科团队中的胶水，能够与不同方向的专家沟通，在需要时填补空白。&lt;/p&gt;&lt;p&gt;企业不再需要要么过于浅尝辄止、要么过度狭窄的开发者，而是希望工程师既有坚实的核心能力，又能在整个技术栈中协同工作。原因之一是效率：T 型工程师往往可以端到端解决问题，而不必等待频繁的交接；另一个原因是创新：不同领域知识的交叉，往往能催生更好的解决方案。&lt;/p&gt;&lt;p&gt;AI 工具实际上更能放大通才的能力，让一个人同时处理多个组件变得更加容易。后端工程师可以借助 AI 辅助生成可用的 UI；前端工程师也能让 AI 生成服务器端的样板代码。在一个 AI 高度充沛的环境中，人们可以更广泛地工作。相反，深度专才可能会发现自己的细分领域被部分自动化，却很难顺利横向扩展。&lt;/p&gt;&lt;p&gt;如今，接近 45% 的工程岗位都期望候选人具备多领域能力：比如既会编程，又懂云基础设施；或者以前端为主，但对机器学习有一定了解。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要尽早打下宽广的基础。即便是因某个具体角色被录用，也要有意识地走出自己的竖井。如果你做移动端，就去学一些后端基础；如果你做前端，试着写一个简单的服务器。了解部署流程，熟悉 Docker、GitHub Actions 等工具。找出一两个真正让你产生兴趣的方向，持续深入，这将成为你的纵向专长。把自己定位成复合型角色，例如侧重云安全的全栈开发者，或具备 UX 专长的前端工程师。利用 AI 工具快速进入新领域：当你对后端还很陌生时，可以让 ChatGPT 生成入门级 API 代码并加以学习。培养持续再学习的习惯。通过黑客松或跨职能项目，强迫自己进入通才模式。主动告诉你的经理，你希望接触项目的不同部分。在职业早期，适应能力本身就是一种超能力。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要系统性地梳理自己的技能图谱：哪些领域是你的强项，哪些相邻领域只是浅尝辄止。选择一到两个相关方向，投入精力做到能对话、能上手。如果你是后端数据库专家，可以去熟悉一个现代前端框架，或学习机器学习流水线的基础。借助 AI 辅助，在自己薄弱的领域做一个小项目。把你的深度专长放到新的语境中：如果你擅长 Web 性能优化，就去探索这些能力如何应用到 ML 推理优化上。主动推动或设计更具跨职能属性的角色定位，争取成为多领域项目的整合负责人。在指导他人、扩散技能的同时，也从他们身上学习新东西。更新简历，突出你的多面性。利用经验识别可迁移的模式和知识。最终，成为 T 型工程师的榜样：在专长领域足够深入，带来权威和信任；同时不断横向延展自己的能力边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;教育之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：计算机科学（CS）学位是否仍会是进入软件行业的黄金标准，还是会被更快的学习路径（训练营、在线平台、企业培训）所取代？在一个每隔几个月就发生变化的行业面前，大学可能越来越难跟上节奏。&lt;/p&gt;&lt;p&gt;长期以来，四年制计算机科学学位一直是进入软件岗位的主要通行证。但这一传统正在受到质疑。&lt;/p&gt;&lt;p&gt;其中一种未来是：大学仍然重要，但越来越难保持相关性。学位依然是默认的资质门槛，但课程内容落后于飞速变化的行业需求，受限于缓慢的课程更新周期和繁琐的审批流程。学生和雇主都会感觉，学术界与产业脱节，教授的要么是纯理论，要么是已经过时、无法直接转化为工作能力的实践。&lt;/p&gt;&lt;p&gt;许多应届毕业生表示，在整个本科学习期间，他们从未接触过云计算、现代 DevOps 或 AI 工具。如果大学要求学生投入高昂的时间和金钱，却提供低相关度的教育，就有可能被视为昂贵的看门人。但由于惯性，许多公司仍然要求学士学位，于是弥补技能差距的负担被转嫁给学生，他们不得不通过训练营、在线课程和自学项目来补齐短板。&lt;/p&gt;&lt;p&gt;企业每年要花费数十亿美元来培训新员工，因为毕业生并不具备职场所需的技能。大学可能会加一门 AI 伦理课，或开一门云计算选修课，但等到真正落地时，行业工具往往已经更新换代。&lt;/p&gt;&lt;p&gt;更具颠覆性的情景是：传统教育体系被越来越多的新系统所替代，编程训练营、在线认证、自学作品集，以及由雇主主导的培训学院。许多知名企业（如 Google、IBM）已经在部分技术岗位上取消了学历要求。到 2024 年，接近 45% 的公司计划在至少一部分岗位上取消学士学位门槛。&lt;/p&gt;&lt;p&gt;编程训练营本身也在成熟。它们培养出的毕业生，已经可以与科班 CS 毕业生一起进入顶级公司工作。这类项目周期更短（例如 12 周的高强度训练），重点放在实用技能上：当前流行的框架、云服务以及团队协作。招聘中的硬通货正在转向实时作品集、微证书和可验证技能。一份强有力的 GitHub 作品集或被认可的认证，已经可以绕过学位要求。&lt;/p&gt;&lt;p&gt;由雇主驱动的教育模式正在出现：公司建立自己的培训管道，或与训练营合作。一些大型科技公司已经为非传统背景的候选人开设了内部大学。AI 本身也带来了新的学习方式：AI 导师、交互式编程沙盒、个性化教学，使学习不再局限于大学校园。&lt;/p&gt;&lt;p&gt;一个模块化的学习生态，比昂贵的四年制学位更加普惠。一个身处缺乏优质 CS 大学国家的孩子，也可以修同样的 Coursera 课程，构建与硅谷学生同样水平的作品集。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于有志或刚入行的开发者来说，如果你身处传统 CS 项目中，不要完全依赖它。用真实项目来补充课程：做一个 Web 应用，参与开源项目，争取实习或带薪实训。如果课程体系没有覆盖热门方向，就通过在线平台自学。获取行业认可的认证（如 GCP、AWS、Azure），向雇主证明你的实操能力。如果你是自学或来自训练营，重点打造有说服力的作品集，至少要有一个体量不小、文档完善的项目。积极参与开发者社区：贡献开源、撰写技术文章，通过 LinkedIn、线下聚会和开发者活动建立人脉。争取让一位有经验的开发者为你背书。持续学习，因为技术技能的半衰期很短。把 AI 当作你的私人导师，用作品集、认证以及对自己项目的清晰讲述来证明能力，这些都会为你打开机会之门。&lt;/p&gt;&lt;p&gt;对于资深开发者和管理者来说，单靠既有学历不会一直奏效。要持续投入学习：在线课程、研讨会、技术大会和认证。用新的方式验证自己的能力，做好准备应对以真实问题检验当前水平的面试。保持使用新技术的副项目。重新审视招聘要求：你真的需要新员工拥有 CS 学位，还是你真正需要的是某些技能和持续学习的能力？推动以技能为先的招聘方式，扩大人才池。支持内部培训项目或学徒制岗位，为没有传统背景的初级开发者搭建导师网络。积极与高校和替代教育体系互动：参与顾问委员会、做客座分享、反馈课程与行业需求之间的差距。也要在自身职业发展中体现这一点：真实世界的成果和持续学习，比再拿一个学位更重要。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://addyosmani.com/blog/next-two-years/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>红杉合伙人：2026，AGI已经来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:39:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;我们常问：AGI 什么时候到来？你有没有想过，可能它已经来了。&lt;/p&gt;&lt;p&gt;最近，红杉资本合伙人 Pat Grady、Sonya Huang 联合发表了一篇博客，指出 AGI 已经到来，就在此刻。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528672" data-ratio="0.725925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFCb9l5v589m0Y81ebia13JeOtibXibWSjK3aNBPOx3ra84j0nH3ePMEHIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/afd414e8-a6bf-4682-b544-0616b4d22218/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在他们看来，AGI 不需要一个玄乎的技术定义 &amp;mdash;&amp;mdash; 它的本质就是「能把事情搞清楚的能力」。而以 Claude Code 为代表的长周期智能体，正是这种能力的第一批例证。&lt;/p&gt;&lt;p&gt;文中举了一个例子：一位创始人让智能体帮他找一个开发者关系负责人。智能体先在 LinkedIn 上搜索，发现职位头衔说明不了问题；于是转向 YouTube 找技术演讲，筛选出互动数据亮眼的演讲者；再与 Twitter 交叉比对，找出真正有品味、有粉丝的人；然后检查谁最近发帖变少了 &amp;mdash;&amp;mdash; 这往往意味着对现职的倦怠；最后锁定一位刚经历公司裁员、专业方向完全匹配的候选人，起草了一封精准的挖角邮件。&lt;/p&gt;&lt;p&gt;全程 31 分钟。 没有人告诉它该怎么做，它自己形成假设、验证、碰壁、转向，直到找到答案。这就是「把事情搞清楚」。而长周期智能体已经具备了这种能力。&lt;/p&gt;&lt;p&gt;更令人振奋的是，他们给出了一条清晰的指数曲线：长周期智能体的能力每 7 个月翻一番。按此推算，2028 年智能体能完成人类专家一天的工作，2034 年能完成一年的工作。&lt;/p&gt;&lt;p&gt;这意味着什么？&lt;strong&gt;你对 2030 年的梦想，2026 年就能实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个博客得到了一些从业者的认同。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528673" data-ratio="0.3907407407407407" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF9cku6iahJjwuRcIgPfMDia7eOlLYLRLOrIFrgGoicqAI0n0CjtOBMcJ4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/10a8d6ba-6715-4659-84ae-ac10e10a3772/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528674" data-ratio="0.4583333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFAL8kGEiaibBjKzPWdAtJJHDa0bSRZtB2zic07TBfGjNqY5QbYI4DR9hog/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/14c409be-0b2f-4f91-b2d2-f65fbfc0c678/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但也有人认为其中忽略了一些东西，对于未来的预测过于乐观。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528675" data-ratio="1.0462962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFgH1QVx63ZMw8XWpIehXXA07TaB5A59hj0zq04lTjk3icOAZcQ8Lxl5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f319deac-c4f5-4bc7-8f02-c8f257b6e597/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528676" data-ratio="0.9481481481481482" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFs1Crr1oxUCXwUkRBwX2jWIBfDML6RyIYezZAk1SXNqkcCkbOKpJEKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/dc2e73cf-3f1e-4dc0-9bf8-8f7ae39ff805/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;大家可以读完原文自行判断。&lt;/p&gt;&lt;p&gt;以下是博客内容：&lt;/p&gt;&lt;p&gt;几年前，一些顶尖研究者告诉我们，他们的目标是 AGI。我们急切地想听到一个清晰的定义，天真地问道：「你们如何定义 AGI？」他们顿了顿，彼此试探性地对视，然后给出了一个后来成为 AI 领域某种「箴言」的回答：「嗯，&lt;strong&gt;我们每个人都有自己的定义，但我们看到它的时候就会知道&lt;/strong&gt;。」&lt;/p&gt;&lt;p&gt;这段小插曲，正是我们追寻 AGI 具体定义之旅的缩影。这个定义始终难以捉摸。&lt;/p&gt;&lt;p&gt;然而，尽管定义难以捉摸，现实却并非如此。&lt;strong&gt;AGI 已经到来，就在此刻&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;编程智能体是第一个例证。更多案例正在涌现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长周期（long-horizon）智能体在功能上就是 AGI，而 2026 年将是它们的元年。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不受细节拖累&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在继续之前，有必要承认：我们没有资格提出 AGI 的技术定义。&lt;/p&gt;&lt;p&gt;我们是投资人。我们研究市场、创始人，以及两者碰撞的产物：商业。&lt;/p&gt;&lt;p&gt;因此，我们给出的是一个功能性定义，而非技术性定义。新的技术能力引出了 Don Valentine（红杉资本创始人、硅谷风险投资之父）的经典问题：So what？那又怎样？&lt;/p&gt;&lt;p&gt;答案在于现实世界的影响。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI 的功能性定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI 就是能把事情搞清楚的能力。就这么简单。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们深知，如此不精确的定义无法平息任何哲学争论。但从务实的角度来说，当你想完成某件事时，你想要什么？一个能把事情搞清楚的 AI。至于它是如何做到的，远不如它确实做到了来得重要。&lt;/p&gt;&lt;p&gt;一个能把事情搞清楚的人，拥有一定的基础知识、基于这些知识进行推理的能力，以及迭代找到答案的能力。&lt;/p&gt;&lt;p&gt;一个能把事情搞清楚的 AI，拥有一定的基础知识（预训练）、基于这些知识进行推理的能力（推理时计算），以及迭代找到答案的能力（长周期智能体）。&lt;/p&gt;&lt;p&gt;第一个要素（知识 / 预训练）推动了 2022 年 ChatGPT 横空出世的时刻。第二个要素（推理 / 推理时计算）随着 2024 年底 o1 的发布而到来。&lt;strong&gt;第三个要素（迭代 / 长周期智能体）则在过去几周内到来 &amp;mdash;&amp;mdash;Claude Code 和其他编程智能体跨越了一个能力门槛。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具有通用智能的人可以连续自主工作数小时，发现和修正自己的错误，无需被告知下一步该做什么就能自行判断。具有通用智能的智能体也能做到同样的事情。这是全新的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「把事情搞清楚」意味着什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一位创始人给他的智能体发消息：「我需要一个开发者关系负责人。技术能力要强到能赢得资深工程师的尊重，但又真正喜欢玩 Twitter。我们的客户是平台团队。去吧。」&lt;/p&gt;&lt;p&gt;智能体从显而易见的地方入手：在 LinkedIn 上搜索优秀开发者优先公司的「Developer Advocate」和「DevRel（高级开发者关系）」&amp;mdash;&amp;mdash;Datadog、Temporal、Langchain。找到了数百份简历。但职位头衔无法揭示谁真正擅长这份工作。&lt;/p&gt;&lt;p&gt;它转向寻找信号而非资历。它在 YouTube 上搜索技术大会演讲。找到了 50 多位演讲者，然后筛选出演讲互动数据亮眼的那些。&lt;/p&gt;&lt;p&gt;它将这些演讲者与 Twitter 进行交叉比对。一半人的账号不活跃，或者只是转发公司博客。这不是我们要的。但有十几个人拥有真正的粉丝群 &amp;mdash;&amp;mdash; 他们发表真实观点，与人互动，获得开发者的关注。而且他们的帖子很有品味。&lt;/p&gt;&lt;p&gt;智能体进一步缩小范围。它检查谁在过去三个月发帖频率下降。活跃度下降有时意味着对当前工作的倦怠。三个名字浮出水面。&lt;/p&gt;&lt;p&gt;它调研这三个人。一个刚宣布了新职位 &amp;mdash;&amp;mdash; 来晚了。一个是刚刚完成融资的公司创始人 &amp;mdash;&amp;mdash; 不会离开。第三位是一家 D 轮融资公司的 DevRel 人员，该公司刚刚在营销部门进行了裁员。她最近的演讲正好是关于这家创业公司所瞄准的平台工程领域。她有 1.4 万 Twitter 粉丝，发的梗图能让真正的工程师互动。她的 LinkedIn 两个月没更新了。&lt;/p&gt;&lt;p&gt;智能体起草了一封邮件，提到了她最近的演讲、与创业公司理想客户画像的重合度，以及关于小团队能提供的创作自由的具体说明。建议先随便聊聊，不是推销。&lt;/p&gt;&lt;p&gt;总耗时：31 分钟。创始人得到的不是挂在招聘网站上的一份 JD，而是一份只有一个人的候选名单。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这就是「把事情搞清楚」的含义。在模糊中导航以达成目标 &amp;mdash;&amp;mdash; 形成假设，验证假设，走进死胡同，然后转向，直到某些东西奏效。&lt;/strong&gt;智能体没有遵循脚本。它运行的是一位优秀招聘者脑中同样的循环，只不过它不知疲倦，31 分钟就完成了，且无需被告知如何做。&lt;/p&gt;&lt;p&gt;需要说明的是：&lt;strong&gt;智能体仍然会失败。它们会产生幻觉，丢失上下文，有时会信心满满地冲向完全错误的方向。但趋势是明确的，而且这些失败越来越可以被修复。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们是如何走到这一步的？从推理模型到长周期智能体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在去年的文章中，我们将推理模型描述为 AI 最重要的新前沿。长周期智能体将这一范式推进得更远，让模型能够采取行动并随时间迭代。&lt;/p&gt;&lt;p&gt;让模型思考更长时间并非易事。基础推理模型可以思考几秒或几分钟。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;两种不同的技术路径似乎都在奏效并能良好扩展：强化学习和智能体框架。&lt;/strong&gt;前者通过训练过程中的不断调整，从本质上教会模型保持更长时间的专注。后者则围绕模型的已知局限（记忆交接、压缩等）设计特定的脚手架。&lt;/p&gt;&lt;p&gt;扩展强化学习是研究实验室的领域。他们在这方面取得了非凡进展，从多智能体系统到可靠的工具使用。&lt;/p&gt;&lt;p&gt;设计优秀的智能体框架是应用层的领域。当今市场上一些最受欢迎的产品正是以其精心设计的智能体框架而闻名：Manus、Claude Code、Factory 的 Droids 等。&lt;/p&gt;&lt;p&gt;如果要押注一条指数曲线，那就是长周期智能体的性能曲线。METR 一直在细致追踪 AI 完成长周期任务的能力。进步速度呈指数级增长，大约每 7 个月翻一番。&lt;strong&gt;如果我们沿着这条指数曲线推算，到 2028 年，智能体应该能够可靠地完成人类专家需要一整天的任务；到 2034 年完成一整年的任务；到 2037 年完成一个世纪的任务。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那又怎样？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很快你就能「雇佣」一个智能体了。这是 AGI 的一个试金石。&lt;/p&gt;&lt;p&gt;你今天就可以「雇佣」GPT-5.2、Claude、Grok 或 Gemini。更多例子正在涌现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;医疗：OpenEvidence 的 Deep Consult 扮演专科医生&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;法律：Harvey 的智能体扮演律师助理&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;网络安全：XBOW 扮演渗透测试员&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;运维：Traversal 的智能体扮演 SRE&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;销售：Day AI 扮演业务开发代表、售前工程师和收入运营负责人&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;招聘：Juicebox 扮演招聘官&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数学：Harmonic 的 Aristotle 扮演数学家&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;芯片设计：Ricursive 的智能体扮演芯片设计师&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 研究：GPT-5.2 和 Claude 扮演 AI 研究员&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从「说话者」到「行动者」：对创始人的启示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这对创始人有着深远的影响。&lt;/p&gt;&lt;p&gt;2023 和 2024 年的 AI 应用是「说话者」。有些是非常老练的对话者！但它们的影响力是有限的。&lt;/p&gt;&lt;p&gt;2026 和 2027 年的 AI 应用将是「行动者」。它们会给人同事的感觉。使用频率将从每天几次变成全天候、每一天，同时运行多个实例。用户不是这里省几个小时、那里省几个小时 &amp;mdash;&amp;mdash; 而是从作为个人贡献者工作，变成管理一个智能体团队。&lt;/p&gt;&lt;p&gt;还记得那些关于「出售工作成果」的讨论吗？现在这成为可能了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你能完成什么工作？&lt;/strong&gt;&amp;nbsp;长周期智能体的能力与模型的单次前向传播截然不同。在你的领域，长周期智能体能解锁哪些新能力？哪些任务需要持久性，哪些任务的瓶颈是持续的注意力？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你将如何把这些工作产品化？&lt;/strong&gt;&amp;nbsp;当工作的用户界面从聊天机器人演进到智能体委派时，你所在领域的应用界面将如何演变？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你能可靠地完成这些工作吗？ &lt;/strong&gt;你是否在痴迷地改进你的智能体框架？你是否有强大的反馈循环？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你如何销售这些工作？&lt;/strong&gt; 你能否根据价值和成果来定价和打包？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;扬鞭策马！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;是时候驾驭长周期智能体的指数级增长了。&lt;/p&gt;&lt;p&gt;今天，你的智能体大概可以可靠地工作约 30 分钟。但它们很快就能完成一天的工作量 &amp;mdash;&amp;mdash; 最终是一个世纪的工作量。&lt;/p&gt;&lt;p&gt;当你的计划以世纪为单位衡量时，你能实现什么？一个世纪，是 20 万项从未被交叉引用的临床试验。一个世纪，是所有客户支持工单，终于被挖掘出信号。一个世纪，是整部美国税法，被重构得条理清晰。&lt;/p&gt;&lt;p&gt;你路线图上那个雄心勃勃的版本，刚刚变成了现实可行的版本。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;原文链接：https://x.com/HungamaHeadline/status/2011533578279272652&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>VerseCrafter：给视频世界模型装上4D方向盘，精准运镜控物</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:35:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/45e44809-61bc-453c-9ad4-83cc931a3c9d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;视频世界模型领域又迎来了新的突破！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;复旦大学与腾讯 PCG ARC Lab 等机构的研究者们提出了 VerseCrafter&lt;/strong&gt;，这是一个通过显式 4D 几何控制（4D Geometric Control）实现的动态逼真视频世界模型。它不仅能像「导演」一样精准控制运镜，还能同时指挥场景中多个物体的 3D 运动轨迹，为视频生成引入了物理世界维度。&lt;/p&gt;&lt;p&gt;自 Sora 问世以来，视频世界模型（Video World Models）成为了 AI 领域最热门的研究方向之一。我们希望 AI 不仅能生成视频，更能理解和模拟真实的物理世界。然而，现有的视频模型往往面临一个核心困境：&lt;strong&gt;视频是在 2D 平面上播放的，但真实世界是 4D（3D 空间 + 时间）的。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现有的方法（如 Voyager、Yume 等）虽然引入了 3D 几何结构来辅助生成，但往往难以在一个统一的框架下同时实现&lt;strong&gt;精准的相机控制和多物体运动控制&lt;/strong&gt;。要么是控制了镜头但物体不动（静态场景），要么是控制了物体但镜头受限，或者依赖于刚性的 3D 边界框和人的参数化模型（如 SMPL），难以应对复杂的真实世界物体。&lt;/p&gt;&lt;p&gt;为了打破这一僵局，&lt;strong&gt;来自复旦大学、上海创智学院、香港大学和腾讯 PCG ARC Lab 的研究团队提出了 VerseCrafter&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528437" data-ratio="0.20833333333333334" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDBxfibqaW4QRcrzmqyicrFGUVdictaHqhFuV8PQErncOdqkofpWSNgYpLQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9696f006-6cfa-4f2a-8e6e-d4b33470329e/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址： https://arxiv.org/pdf/2601.05138&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页： https://sixiaozheng.github.io/VerseCrafter_page/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库： https://github.com/TencentARC/VerseCrafter&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/33bbe3ce-35f5-423a-bbc7-b843b57789cd/1768739502008.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;VerseCrafter 的核心理念在于：&lt;strong&gt;用一个统一的 4D 几何世界状态（4D Geometric World State）以此驱动视频生成&lt;/strong&gt;。 它利用静态背景点云和每个物体的 3D 高斯轨迹，实现了对相机和物体运动的解耦与协同控制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何构建 4D 可控的世界模型？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VerseCrafter 的魔法源于其独特的&lt;strong&gt;&amp;nbsp;4D 几何控制（4D Geometric Control） 表示和轻量级的 GeoAdapter 架构&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 统一的 4D 几何控制表示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的控制信号通常是 2D 的（如光流、轨迹点、掩码），缺乏 3D 空间的一致性。VerseCrafter 创新性地提出了一种基于 &lt;strong&gt;3D 高斯（3D Gaussians）&lt;/strong&gt; 的表示方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;：&amp;nbsp;使用静态背景点云（Background Point Cloud）来表示环境几何。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物体&lt;/strong&gt;： 使用&lt;strong&gt;每物体 3D 高斯轨迹（Per-object 3D Gaussian Trajectories）&lt;/strong&gt;来编码物体运动。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528441" data-ratio="0.3851851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDMw2FXF6ahH4JLRbA8H1jMQJjicdiatgFcGYVYuEic0ZE9VSJc2PPs9W9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0114b19f-02f3-4a64-9119-0ad6cc59bc51/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;VerseCrafter 的框架图。通过将 4D 几何控制渲染为多通道图，并通过 GeoAdapter 注入到冻结的 Wan2.1 主干网络中。&lt;/p&gt;&lt;p&gt;相比于刚性的 3D 边界框，3D 高斯轨迹提供了一种软性、灵活且类别无关的表示方式。它的均值定义了运动路径，协方差则捕捉了物体随时间变化的形状和方向。这意味着无论是汽车、行人还是动物，VerseCrafter 都能以概率分布的形式描述其在 3D 空间中的占据情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 冻结的 Wan2.1 主干 + GeoAdapter&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了保证视频生成的画质和真实感，VerseCrafter 并没有从头训练一个大模型，而是巧妙地利用了强大的开源视频生成模型 &lt;strong&gt;Wan2.1-T2V-14B&lt;/strong&gt; 作为冻结的视频先验（Frozen Video Prior）。&lt;/p&gt;&lt;p&gt;研究团队设计了一个轻量级的 GeoAdapter：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;首先将 4D 几何控制信息（背景 RGB / 深度、物体高斯轨迹 RGB / 深度、控制掩码）渲染为 2D 序列图；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;利用 GeoAdapter 对这些几何信息进行编码；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;将其作为残差注入到 Wan2.1 的特定 DiT 模块中。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这种设计既保留了 Wan2.1 强大的生成能力，又以极小的代价引入了精确的 4D 控制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据集：VerseControl4D&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练这样一个 4D 世界模型，最大的瓶颈在于数据 &amp;mdash;&amp;mdash; 我们去哪里找大量带有精确 4D 标注（相机参数 + 多物体 3D 轨迹）的真实世界视频？&lt;/p&gt;&lt;p&gt;为了解决这个问题，团队构建了 &lt;strong&gt;VerseControl4D 数据集&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528442" data-ratio="0.687962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDXD9e3OGCopuhHIxXOlKDKicdZCYvYfwq5MFM8FicXoDJxyaiaSudZ6cqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7ba2f96e-6d43-4e72-99ee-311beb2c2c38/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;VerseControl4D 数据集的自动化构建流程&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据源&lt;/strong&gt;：&amp;nbsp;基于 Sekai-Real-HQ 和 SpatialVID-HQ 等高质量视频数据集；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自动化标注引擎&lt;/strong&gt;：&amp;nbsp;结合了 Qwen2.5-VL-72B（生成描述）、Grounded-SAM2（物体分割）、MegaSaM（深度和相机位姿估计）等最先进的工具，自动从视频中提取 4D 几何信息；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;规模&lt;/strong&gt;： 包含&lt;strong&gt;&amp;nbsp;35,000 个&lt;/strong&gt;训练视频片段，涵盖了丰富的动态和静态场景。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一数据集的构建，填补了真实世界 4D 几何控制数据的空白，为模型的训练提供了坚实的基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：SOTA 级的控制力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验表明，VerseCrafter 在各项指标上均超越了现有的 SOTA 方法（如 Perception-as-Control、 Yume、 Uni3C 等）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 动态场景联合控制对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在同时控制相机运镜和物体运动的复杂场景下，VerseCrafter 展现出了惊人的稳定性。&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fbec2e85-1101-4739-a565-6ff283e07011/1768739596595.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;动态场景对比。第一行从左至右：相机轨迹、GT、Perception-as-Control、Yume，第二行从左到右：Uni3C（第 1，2 列）、VerseCrafter（第 3，4 列）。可以看到 VerseCrafter（右下）的物体运动和背景稳定性最好。&lt;/p&gt;&lt;p&gt;从对比视频中可以看出：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Perception-as-Control&amp;nbsp;&lt;/strong&gt;生成的帧质量较低，运镜不准。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Yume&lt;/strong&gt; 虽然能大致遵循文本描述的运动，但缺乏精确的相机控制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Uni3C&amp;nbsp;&lt;/strong&gt;仅限于单人体运动控制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VerseCrafter&amp;nbsp;&lt;/strong&gt;能够精确地让物体沿着预设的 3D 高斯轨迹移动，同时完美执行相机运镜，且背景保持几何一致。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 静态场景运镜对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;即使在没有移动物体的静态场景中，作为单纯的「场景漫游」工具，VerseCrafter 的表现也优于专门的 ViewCrafter 和 Voyager 等模型。&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5d59027c-2b04-43a9-a53a-90ceec1b1891/1768739618300.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;静态场景运镜对比。第一行从左至右：相机轨迹、GT、ViewCrafter，第二行从左到右：Voyager、FlashWorld、VerseCrafter。VerseCrafter 在大幅度运镜下依然保持了建筑结构的笔直和纹理的清晰。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 多视角一致性（Multi-Player View）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;得益于统一的 4D 世界坐标系，VerseCrafter 还支持多玩家视角（Multi-Player View）生成。对于同一个动态事件，可以从完全不同的两个视角分别生成视频，两者在时间、空间和物体动作上保持高度一致。&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3a6025d0-faf7-4462-ad22-1b0e924e58f0/1768739632674.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;两者在同一时间轴上展现了完全一致的世界动态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VerseCrafter 的出现，标志着视频生成向&lt;strong&gt;可控 4D 世界模拟&lt;/strong&gt;迈出了重要一步。通过将显式的 3D 几何先验（点云与高斯）与强大的 2D 视频生成模型（Wan2.1）相结合，它不仅解决了复杂场景下的控制难题，也为游戏制作、电影预演和具身智能模拟提供了新的可能性。&lt;/p&gt;&lt;p&gt;目前，项目代码与模型权重均已开源，感兴趣的读者可以前往项目主页体验。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AI 视频生成时代，留给人类的只有演技？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 17 Jan 2026 17:57:16 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-17-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-17-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜泽南、杨文&amp;nbsp;&lt;/p&gt;&lt;p&gt;总有人说直播网红是「换头怪」，全靠滤镜整容，现在 AI 给你直接换个人，你受得了吗？&lt;/p&gt;&lt;p&gt;最近，社交媒体上疯传的一些视频让无数人感到震惊。&lt;/p&gt;&lt;p&gt;有网友做出任意表情、动作，然后无缝替换到《怪奇物语》中的米莉・博比・布朗、芬恩・伍夫哈德等多位演员身上，实现零成本的「无限角色互换」。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a8c6444c-b8e8-4e1b-a52d-aaf905d100fd/1768643679897.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这已经不是普通的 3D 皮套了，很多视频生成 AI 已经实现了实时换脸的能力：只需要找到一张参考的照片，你就可以在视频中直接「扮演」这个人。&lt;/p&gt;&lt;p&gt;现在 AI 可以精准地捕捉像眨眼、张嘴、侧脸等微表情，效果和画面背景之间也没有任何的割裂感，几乎看不出破绽来。&lt;/p&gt;&lt;p&gt;有的人已经把这些技术整合成了 APP。比如这个叫 levelsio 的人就展示了一系列 AI 直播的效果，并表示，虚拟网红的时代已经来临。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2c53409c-a434-499e-8d4f-87483b7b3c2c/1768643691686.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;真实到有一点点可怕。&lt;/p&gt;&lt;p&gt;风险投资机构 a16z 合伙人 Justine Moore 直言：「我们对 AI 如何迅速改变生产流程完全没有准备好。一些最新的视频模型已经对好莱坞产生了直接而重大的影响，角色可以无限替换，成本却几乎可以忽略不计。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OgrOjtvzx4MJ36Q0iaiceFTX4Xflo8wEg3e9zK6VgIjR7JaY11xxhP8kw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3209647495361781" data-type="png" data-w="1078" data-width="1078" data-height="346" data-backw="578" data-backh="186" data-imgfileid="503528744" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/bb4a47e2-e8fe-42b0-a1b6-3c882c5cba60/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在 X 上，这类视频动辄就能获得超百万播放量，评论区也两极分化严重。有人惊讶技术进步的飞速，有人则担心深伪用于诈骗与破坏信任，「连人类身份都难以证明」，有人甚至提到以后或许需要「眼球扫描」来验证真实性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「好莱坞完了」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这波换脸技术的核心突破，主要来自快手推出的 Kling Motion Control，只需上传任意一段视频以及一张目标角色的照片，AI 即可生成一个「角色替换」视频。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26077537-1635-4077-bdbb-44e3289a26f2/1768643706281.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;国外网友已经玩疯了。&lt;/p&gt;&lt;p&gt;电影制作人 Arut 用这个工具复刻了 2023 年奥斯卡热门片《坠落的审判》（Anatomy of a Fall）里的那段标志性单镜头争吵场景。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8ae4f61e-4fc2-401c-b82e-a42df86b1682/1768643716316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这段 25 秒的视频，全靠 Kling 2.6 Motion Control Pro 实现，它能精准控制长达 30 秒的肢体动作和面部表情。这也意味着，以前需要专业团队、摄影棚、灯光道具才能完成的镜头，现在只要一部手机和一个 AI 工具就行。&lt;/p&gt;&lt;p&gt;看来时代真的变了。&lt;/p&gt;&lt;p&gt;AI 电影制作人 Uncanny Harry AI 的演示更夸张，他穿着睡衣，顶着乱糟糟的头发，在家里用 AI 让自己一人分饰两角：一个中年光头男人和一个红发女职员。&lt;/p&gt;&lt;p&gt;两个角色上演了一场气氛紧张的对话，唇部同步完美、微表情和肢体语言均高度一致。&lt;/p&gt;&lt;p&gt;而他本人既不是训练有素的专业演员，视频也未经过专业的音效处理。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8cf588a0-c733-43a4-a583-c0f00f685125/1768643727854.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;还有人用 AI 生成的一个 K-pop 偶像做鬼脸的视频，比如嘟嘴、吐舌、眨眼&amp;hellip;&amp;hellip; 每个动作表情都自然流畅。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1d746823-bdca-4f52-93cd-0dd1daefe5fd/1768643738751.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;有人做了不完全的统计，现在包括 Kling 2.6、Deep-Live-Cam、DeepFaceLive、Swapface、SwapStream、VidMage 和 Video Face Swap AI 在内的一系列工具，都可以根据实时网络摄像头画面生成实时的 AI 换脸视频，或是基于静态的图片，以及人们的文字提示，按照需求生成从几十秒到几分钟的视频。&lt;/p&gt;&lt;p&gt;这些工具的价格也越来越亲民，每月费用在 10 美元到 40 美元之间。&lt;/p&gt;&lt;p&gt;这方面的技术在过去一年里取得了显著进步，唇形同步效果更好，眨眼和表情也更加自然。现在它足以以假乱真，骗过很多人。当然，不同的 AI 也各有自己擅长的方面，比如 Sora 2 能够更好地模拟物理效果，Kling 的运动比较真实等等。&lt;/p&gt;&lt;p&gt;或许过不了多久，建模质量就不再是你的必选项，火不火全都取决于整活了。&lt;/p&gt;&lt;p&gt;可以预见，随着 AI 视频生成内容的不断进步，很多前所未有的创意和想法将会变成现实。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Arutkaran_/status/2010705052374286587&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Uncanny_Harry/status/2008881579095961934?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/IamEmily2050/status/2002968479276937403?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/AIMevzulari/status/2012105893882536266?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>贴广告的ChatGPT，一夜之间让全球网友破了防</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 17 Jan 2026 13:32:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-17-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-17-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南、杨文&lt;/section&gt;&lt;p&gt;这一天终于还是来了。&lt;/p&gt;&lt;p&gt;周六凌晨，OpenAI 的一则公告引起轩然大波：他们计划在 ChatGPT 里加广告了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="684" data-backw="578" data-height="1394" data-imgfileid="503528701" data-ratio="1.1833333333333333" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OrYlwlbcKaQfWJiciaTuGl12ExfYj5UXWXtjTQWgNm842nXuBdQ8WNdmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1178" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/312ae896-b172-4160-ba9d-b04d0635b534/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对此，网友们感到很受伤。有人表示，现在大家用大模型的一个重要原因就是能够避免广告，更好地查询信息，现在 ChatGPT 又把广告加回来是几个意思？&lt;/p&gt;&lt;p&gt;也有人认为，加广告的这件事表明了 OpenAI 目前的营收压力很大。&lt;/p&gt;&lt;p&gt;华盛顿大学教授荣誉退休教授、知名 AI 学者 Pedro Domingos 吐槽道：OpenAI 终于实现了 AGI，不过此 AGI 非彼 AGI，而是 Ad-Generated Income.&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OiczQSsU2sd3CzyZ1myQP1cpOasScMjMuiaibwR2jQvuDwAn2jwuatFwqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.15221579961464354" data-type="png" data-w="1038" data-width="1038" data-height="158" data-backw="578" data-backh="88" data-imgfileid="503528702" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dcd0e81f-e197-4aa3-9097-8ea8a1262683/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;OpenAI 的公告指出，广告测试将在未来几周内率先在美国启动，能看到广告的用户包括免费版，还包括一种新的付费层级 &amp;mdash;&amp;mdash;ChatGPT Go 的用户。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ChatGPT「小会员」，每月 8 美元&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在广告出现之前，OpenAI 官方宣布 ChatGPT Go 已在全球上线，在所有支持 ChatGPT 的国家可用。&lt;/p&gt;&lt;p&gt;ChatGPT Go 是他们的低价订阅计划，每月 8 美元，提供比免费版多 10 倍的消息额度、文件上传和图像生成功能、更大的内存、更长的上下文窗口，以及可以无限使用 GPT 5.2 instant 模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OuzlMiatEXJZuz4PsXUF1xUfjNCPNMmdfAcD4icMkws5xaUrmwjplZcEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.575925925925926" data-type="png" data-w="1080" data-width="1199" data-height="690" data-backw="578" data-backh="333" data-imgfileid="503528704" data-aistatus="1" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/76016e3c-2ca1-4a7c-a191-85e04d140c4d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;需要注意到的是，Go 版用户仍然无法使用 GPT‑5.2 Thinking 模型。&lt;/p&gt;&lt;p&gt;另外，OpenAI 指出，除了免费版和 ChatGPT Go 以外，Plus、Pro、Business 和 Enterprise 版本的付费用户将不会看到广告。所有 ChatGPT 中的回复不会受到广告的影响。&lt;/p&gt;&lt;p&gt;看 OpenAI 的说法，ChatGPT 的广告和 Google 等搜索引擎上的很像。广告不会打断对话流，而是会出现在 AI 生成的回复的底部，并标注好「Sponsor」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OibX7IJmwXoU2g5o0lESibGhdtZ8oiaWs2ECJ70cWrBVzahiaOfqAlC9sGg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.562037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503528717" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3ad8598b-05b1-43ff-a5d3-4fbf5a33f85b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;OpenAI 承诺广告商无法影响 ChatGPT 生成的答案内容，此外，用户的具体对话内容不会被直接发送给广告商，只会用于匹配相关性。&lt;/p&gt;&lt;p&gt;虽然 AI 的回复内容里不会有广告内容，但 ChatGPT 显示的广告将根据你的对话上下文进行匹配，比如你在问食谱的时候会出现相关食材或配送服务的广告。&lt;/p&gt;&lt;p&gt;另外，在涉及健康、心理健康、政治等敏感话题的对话中，不会显示广告。&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;理想与现实的妥协&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 的这一决定，是在公司面临巨大的财务压力和商业化转型的背景做出的。&lt;/p&gt;&lt;p&gt;尽管 OpenAI 的估值即将达到 7500 亿美元，但考虑到其在算力和数据中心上的投入是天文数字（在 2025 年就有高达 1.4 万亿美元的基础设施建设承诺），去年奥特曼预计的 200 亿美元收入显然远远不够。&lt;/p&gt;&lt;p&gt;为了维持运营并继续扩展 AI 大模型能力，加广告可能是唯一的办法。&lt;/p&gt;&lt;p&gt;看起来很合理，但是在这件事情上，山姆・奥特曼仍然食言了。&lt;/p&gt;&lt;p&gt;作为一个致力于解决 AGI 大问题公司的舵手，奥特曼在不久之前还曾在多个场合公开表达过对于加广告的厌恶。在 2024 年与 Lex Fridman 的播客访谈时，他提到自己对广告有一种「精神上的厌恶（spiritual dislike）」。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OcM1nSCWJ7SUo79ria00eSj33VLNe7rV7gXQ7coRvXiblZiahbdKkvZbKw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.6276747503566333" data-type="gif" data-w="701" type="block" data-backw="578" data-backh="363" data-imgfileid="503528705" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/402f4bab-fcbe-4e6d-b474-271a87bd914c/640.gif" data-order="0" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;奥特曼解释说，这主要是针对当时互联网上那些「糟糕的交互界面（crappy interfaces）」，他认为广告往往会干扰用户获取信息，破坏产品的纯粹性。&lt;/p&gt;&lt;p&gt;他当时强调了一个核心逻辑：「我喜欢用户付费使用 ChatGPT，因为这样他们就知道答案没有被广告商影响。」他担心一旦引入广告，AI 的回答可能会为了讨好广告主而出现偏向性。&lt;/p&gt;&lt;p&gt;这也是所有普通用户所担心的问题。在今天 OpenAI 的声明之后，不知大家该作何感想。&lt;/p&gt;&lt;p&gt;在奥特曼介绍 ChatGPT 广告的推文下，有网友还扒出了 2024 年 5 月奥特曼在哈佛大学演讲里的内容，当时他说：广告对我们来说是一种商业模式的最后选择。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OKbueXDpgiaKia086Ghr7a8hEVjkxVUb8ibtib2PHmJayiataxMy2BLQYvBw/640?wx_fmt=jpeg#imgIndex=6" data-ratio="0.13953488372093023" data-s="300,640" data-type="png" data-w="602" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OB9Qjd2kVkCJLHIPnjds8MMBKw0Tj9APgj0vjf6WKV2aH3XgNFlr1nw/640?wx_fmt=png&amp;from=appmsg" data-cropx2="602" data-cropy1="21.423487544483987" data-cropy2="104.97508896797153" data-backw="578" data-backh="101" data-imgfileid="503528718" data-aistatus="1" data-original-style="width:562px;height:78px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/daa182bd-d474-4da1-a385-02377a3a5d02/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;马斯克和奥特曼又在 X 上「升堂」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除了 ChatGPT 要加广告这事，今天最热的新闻之一还得是马斯克和 OpenAI 旷日持久的官司。&lt;/p&gt;&lt;p&gt;近日，加州北部地区法院解封逾百份文件，包括 OpenAI 总裁 Greg Brockman 2017 年的私人日记摘录。&lt;/p&gt;&lt;p&gt;这些记录显示，Brockman 曾在日记中写道：「这是我们摆脱 Elon 的唯一机会&amp;hellip;&amp;hellip; 从财务角度，什么才能让我达到 10 亿美元？」并讨论转向营利结构，以避免马斯克的控制「破坏经济利益」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6O376DfCdL4zj8Y1SPwbMslSvTz5N4HZSIQAVprdR1lIictiauMvrE4ReA/640?wx_fmt=jpeg#imgIndex=7" data-ratio="0.8916666666666667" data-type="png" data-w="1080" data-width="1200" data-height="1200" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6Oz8kqMeCZpJMdKsUpzibpbbzkZhqyhCWdqb0IDencXsZdxUpEYBnhOlw/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1180.782918149466" data-cropy2="1052.6690391459074" data-backw="578" data-backh="578" data-imgfileid="503528706" data-aistatus="1" data-original-style="width:553px;height:493px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b013d60c-8440-4a01-8cbb-d1975387a994/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Brockman 还总结道：「在马斯克不知情或不同意的情况下，把非营利组织从他手里偷走、强行改成营利性公司，这种做法是错误的，那样做会显得相当道德败坏，而且他真的不是傻子。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OJ8eun9gAKHRJebFLczcVKTjgVrLvq5wiaMdzTOyw1t4eBg6vf3picj9Q/640?wx_fmt=jpeg#imgIndex=8" data-ratio="1.0601851851851851" data-type="png" data-w="1080" data-width="1454" data-height="2078" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OOGDiaoJ6YeOSibLSw7TzWVNHia1r0QO6dCwjfNLFSwibZYkhtFkfshSeAQ/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1420.3665480427046" data-cropy2="1505.743772241993" data-backw="578" data-backh="826" data-imgfileid="503528708" data-aistatus="1" data-original-style="width:549px;height:582px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/4d55166e-d9d0-4061-97b7-481459363056/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;马斯克在 X 上直接评论：「他们偷了一个慈善组织，就这么简单。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OPb7l9griaYwFZ9vJzZSNbFcNyfqQibPLr1Yv0NREr8JR8sN5teTtREUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.29887218045112784" data-type="png" data-w="1064" data-width="1064" data-height="318" data-backw="578" data-backh="173" data-imgfileid="503528710" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/886c4eb9-6eb0-43c2-aec8-6687a1b74af1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;奥特曼回应称，马斯克在断章取义地抹黑 Greg Brockman，实际情况的完整版是马斯克自己当时大力推动公司改成新的结构，Greg 和 Ilya 花了大量精力去研究、讨论能不能接受或满足 Elon 提出的那些苛刻条件。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6Otu5u9zUKKD5evYfFojE0MlzZicaA1HDYa0PSYc3XaWZXUfxztDg5qhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.7262357414448669" data-type="png" data-w="1052" data-width="1052" data-height="764" data-backw="578" data-backh="420" data-imgfileid="503528711" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/f312ffd2-c647-4db0-91c7-176aa9f46818/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;「我之前记得很多这些细节，但这个部分我完全忘了：『Elon 说，他需要攒到 800 亿美元来建一个能在火星上自给自足的城市，他认为自己需要、也配得上多数股权。他还说必须有完全的控制权，因为以前没控制权吃过大亏。在聊到公司继任、接班问题时，他突然提到要让他的孩子们来掌控 AGI，这让我们挺震惊的。』我觉得大家直接说清楚自己想要什么挺好的，这样才能真正解决问题或看清没法解决。但 Elon 当时提出这些要求，正是 Greg Brockman 纠结、思考公司未来方向的重要背景。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OaaLwMPaurZ4K65e13rkz8x1G2gYIBWDsBUAHj9JRDWgYgoBe263hwQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4261682242990654" data-type="png" data-w="1070" data-width="1070" data-height="456" data-backw="578" data-backh="246" data-imgfileid="503528712" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/9629e6b6-11bf-4e10-bbca-4a69b5c88cf2/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;关于双方的纠葛，MenloVentures 合伙人 Deedy 的评论一针见血：说到底，这一切都和钱有关。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OdqQhXiatR4O71psicbIThz6rf9CEgsFJBohAFNdIMPE4lN7NCbXpZ3Vw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3308270676691729" data-type="png" data-w="1064" data-width="1064" data-height="352" data-backw="578" data-backh="191" data-imgfileid="503528713" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/cd7ad919-9043-4081-925e-0a497602d5f6/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;由于解封出的文件存在「足以让陪审团相信可能存在违约行为」的嫌疑，美国地区法官 Yvonne Gonzalez Rogers 已于 2026 年 1 月正式裁定拒绝 OpenAI 的撤诉请求。该案件将于 2026 年 4 月 27 日进入陪审团审判。&lt;/p&gt;&lt;p&gt;最后，我们再回到ChatGPT加广告这事。你认为，OpenAI 在未来，终究也会走回科技巨头的「老路」吗？&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考信息：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/OpenAI/status/2012223373489614951?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/news/863466/openai-chatgpt-go-global-release&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/deedydas/status/2012074556106924233?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/XFreeze/status/2012209234134409475?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/elonmusk/status/2012173548039622685?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/sama/status/2012272451363709377&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>开源8300小时标注数据，新一代实时通用游戏AI Pixel2Play发布</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 17 Jan 2026 13:29:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-17-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-17-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3a2d7c6d-3d8e-42d8-a13f-278ea4507571/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着人工智能在代码以及图片生成方面日益成熟，越来越多的研究人员也开始关注 AI 模型在游戏领域中的表现。实际上，游戏在 AI 的发展早期就已经是一个重要的研究方向，许多前期研究聚焦在 Atari，星际争霸，Dota 等热门游戏，并成功训练出了表现超越人类玩家的专用模型。然而，这类模型通常只能在单一游戏环境中运行，缺乏跨游戏的泛化能力。&lt;/p&gt;&lt;p&gt;另一方面，虽然 ChatGPT 和 Gemini 这类模型通用模型在众多任务上已经展现出了卓越的能力，它们却难以在游戏环境中取得好的表现，即便是很简单的射击游戏。&lt;/p&gt;&lt;p&gt;为了解决这一问题，来自 Player2 的研究员们提出了 &lt;strong&gt;Pixel2Play（P2P）&lt;/strong&gt;模型，该模型以游戏画面和文本指令作为输入，直接输出对应的键盘与鼠标操作信号。在消费级显卡 RTX 5090 上，P2P 可以实现超过 20Hz 的端到端推理速度，从而能够真正像人类一样和游戏进行实时交互。P2P 作为&lt;strong&gt;通用游戏基座模型&lt;/strong&gt;，在超过 &lt;strong&gt;40&lt;/strong&gt; 款游戏、总计 &lt;strong&gt;8300 +&lt;/strong&gt; 小时的游戏数据上进行了训练，并能够以零样本（zero-shot）的方式直接玩 Roblox 和 Steam 平台上的多款游戏。&lt;/p&gt;&lt;p&gt;为了促进领域的发展，Open-P2P 团队在没有使用许可限制的情况下&lt;strong&gt;开源了全部的训练与推理代码，并公开了所有的训练数据集&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;接下来请看 P2P 模型的人机对战：(在 Roblox Rivals 游戏中)&lt;a href="https://mp.weixin.qq.com/s/QNPkAtbvvTMV-gFtZsdGcg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/29f5b78e-5937-4489-8750-9110907af4db/1768627654314.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文题目：Scaling Behavior Cloning Improves Causal Reasoning: An Open Model for Real-Time Video Game Playing&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://elefant-ai.github.io/open-p2p/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文代码：https://github.com/elefant-ai/open-p2p&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文数据：https://huggingface.co/datasets/elefantai/p2p-full-data&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;训练数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练游戏 AI 模型需要高质量的&lt;strong&gt;游戏画面、文本指令&lt;/strong&gt;以及对应的&lt;strong&gt;操作数据&lt;/strong&gt;。与海量公开的图文数据不同，这类&lt;strong&gt;&amp;nbsp;&amp;ldquo;画面 - 操作&amp;rdquo; 数据&lt;/strong&gt;在互联网上很少见。尽管已有通过游戏视频反推动作的开源数据集，但开源的大规模高质量人工标注操作数据却还是空缺。为了弥补这一空缺，Open-P2P 项目开源了全部的训练数据集。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiciax1NZVI7OqKibNqY9UaVwBlDiciciaQVZzFg5E1dyEiad3K1upN64oeGoEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.34965034965034963" data-s="300,640" data-type="png" data-w="858" type="block" data-imgfileid="503528276" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/06e5a735-43bd-402d-9c04-c98d5aa5e0ac/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如图所示，P2P 所用的训练数据同时包括游戏图像画面与对应的文本指令，并提供了精确的键盘鼠标操作标注&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型设计&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicJRP4akVFNVGKaJOM3xQ8ujc4Tu9MWbbkiarFmYluMJXM56ImGaAH9Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.34558823529411764" data-s="300,640" data-type="png" data-w="680" type="block" data-imgfileid="503528277" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/25a75100-b692-47dd-a6d5-c0368586e3e0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为了保证模型可以做到快速的推理速度&lt;/strong&gt;，P2P 选择了轻量级模型框架并从零开始训练。&lt;/p&gt;&lt;p&gt;模型主体由一个解码器 Transformer 构成（左图所示），并额外接入一个轻量化的 action-decoder 来生成最终的操作信号。该结构使得模型在推理时只需要对主体模型进行一次前向计算，即可生成 action-decoder 所需的表征信号，从而使得整体推理速度提升 5 倍。&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了实现跨游戏通用性，P2P 采用了&lt;strong&gt;自回归的离散 token&amp;nbsp;&lt;/strong&gt;序列作为操作输出空间。具体来说，每个操作由 8 个 token 表示：4 个对应键盘按键，2 个对应鼠标在水平与垂直方向上的离散位移，最后两个对应鼠标按键。这样的设计可以涵盖绝大部分游戏的操作需求。&lt;/p&gt;&lt;p&gt;在输入方面，除了当前帧图像与文本指令 token 外，P2P 还会输入&lt;strong&gt;真实操作 token&lt;/strong&gt;，这使得模型能够根据历史操作来做决策，从而更贴近人类玩家的操作习惯。为了保证模型的因果关系，训练时使用了&lt;strong&gt;特殊的掩码机制&lt;/strong&gt;（右图所示），以确保模型在预测时仅能看见历史真实操作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;P2P 共训练了四个不同规模的模型，参数量分别为 150M，300M，600M 和 1.2B。在实测中，150M 模型可以达到 80Hz 的端到端推理速度，而最大的 1.2B 模型也能达到 40Hz，完全满足与游戏环境实时交互的需求。&lt;/p&gt;&lt;p&gt;模型评估的标准主要是人工评估，评估环境选取自四款游戏&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Steam 平台上的 Quake，DOOM&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Roblox 平台上的 Hypershot，Be a Shark&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;模型行为评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 DOOM 和 Quake 中，每个官卡设置了四个不同的起始位置（Roblox 游戏因联网机制无法固定起点），模型需从指定起点操作至下一个目标点。&lt;/p&gt;&lt;p&gt;人工评估采取了两两比较的方式：将 1.2B 模型生成的游戏录像与另外三个相对较小的模型录像进行人工比对。结果显示，1.2B 模型分别以 80%，83% 与 75% 的偏好度优于 150M，300M 和 600M 模型。下方视频展示了对比片段：&lt;a href="https://mp.weixin.qq.com/s/QNPkAtbvvTMV-gFtZsdGcg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c2752123-ee3b-45cf-936d-2ef2f659271d/1768627724774.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令遵循评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究还测试了 P2P 模型理解并执行文本指令的能力。评估环境选择了 Quake 的一个迷宫关卡，该关卡要求玩家依次点亮三个红色按钮才能开门。&lt;/p&gt;&lt;p&gt;这个任务对于仅凭借视觉信息的模型来说很有挑战，因为 &amp;ldquo;按下按钮&amp;rdquo; 和 &amp;ldquo;不按按钮&amp;rdquo; 在行动轨迹上几乎没有区别。所以，未接受指令的模型通过率只有 20%。而当模型接收到 &amp;ldquo;按下红色按钮&amp;rdquo; 的文本指令后，模型的通过率可大幅提高到 80%，显示出了优秀的文本指令理解和执行能力。&lt;/p&gt;&lt;p&gt;下方视频对比了 1.2B 模型在有指令（左）和无指令（右）的情况下各运行 5 次的表现。&lt;a href="https://mp.weixin.qq.com/s/QNPkAtbvvTMV-gFtZsdGcg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4fd6570a-2385-49ab-92fc-cf9acfbfd5d5/1768627736180.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;因果混淆分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因果混淆是行为克隆中常见的难题，在高频的交互环境中尤其突出。例如，一个简单的策略就是直接复制上一帧的操作，这种模型在训练时，但在真实环境测试时表现就会很差。&lt;/p&gt;&lt;p&gt;论文对此进行了系统的研究，发现扩大模型的规模与增加训练模型的数据量能够有效提升模型对因果关系的理解能力，使其不再依赖着泪虚假关联，从而学到更好的操作策略。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicCeJY6Ce0vVibMyVNGfNYoVcs9iaKpW9nvTIZyFA2c2hNJ574jRicoM0LQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6" data-s="300,640" data-type="png" data-w="1000" type="block" data-imgfileid="503528278" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/e5e42a92-3fbe-4bcd-bd73-8b7bfc333f99/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如图所示，随着训练数据增多与模型参数量增加，P2P 模型在因果推断评估中的表现呈上升趋势。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于作者&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文第一作者岳煜光现任初创公司 Player2 研究员，负责游戏模型的开发和研究。在加入 Player2 之前，他曾先后在 Amazon 和 Twitter 担任研究人员，致力于语言模型与推荐系统的相关研究。&lt;/p&gt;&lt;p&gt;岳煜光博士毕业于德州大学奥斯汀分校（UT-Austin），师从周明远教授，研究方向是强化学习以及贝叶斯统计；此前他于加州大学洛杉矶分校（UCLA）取得硕士学位，本科毕业于复旦大学数学系。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicnaqfc89Gd0h33fAiaFfj4A8Ft4mlYDKOmIeibu1hKJ5guRfRPOQ3cDhg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="1.3324074074074075" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528279" data-aistatus="1" data-original-style="width:412px;height:549px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c625d8cd-0673-42e7-ba08-074b29b1c907/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型听懂语音却反而变笨？港中深与微软联合解决语音大模型降智问题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 17 Jan 2026 13:25:23 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-17</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-17</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="height: auto !important;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/6f56de25-e42e-4fcb-bf63-74319a5f905d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从 GPT-4o 开启全能（Omni）交互时代至今，Speech LLM 虽然在拟人化和低延迟上取得了长足进步，但面临一个令人困扰的现象：&lt;strong&gt;当大语言模型（LLM）被赋予 &amp;ldquo;听觉&amp;rdquo; 后，它的智商下降了。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;即便是同样的底层模型，一旦输入从文本变成语音，其逻辑推理能力（Reasoning）往往会显著衰退。这种现象被称为&lt;strong&gt; &amp;ldquo;模态推理鸿沟&amp;rdquo;（Modality Reasoning Gap）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这个难题并非仅存在于学术界，而是 OpenAI、Google、Meta 等行业巨头都在试图跨越的 &amp;ldquo;天花板&amp;rdquo;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;根据 &lt;strong&gt;Big Bench Audio&lt;/strong&gt; 评测，以 GPT-4o 为例，在纯文本任务（Text-to-Text）的准确率达 &lt;strong&gt;92%&lt;/strong&gt;；但一旦切换到端到端语音模式（Speech-to-Speech），其得分跌至&lt;strong&gt; 66%&lt;/strong&gt;。这中间&lt;strong&gt; 26%&lt;/strong&gt; 的巨大跌幅，就是模型引入语音而付出的代价。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Google Gemini 团队在技术分享中将其定义为 &lt;strong&gt;Intelligence Gap&lt;/strong&gt;；而 Meta 研究员在 NeurIPS 2025 上更是直言这是一种 &lt;strong&gt;Intelligence Regression&lt;/strong&gt;，并提出了一个生动的概念 &lt;strong&gt;Multimodal Tax&lt;/strong&gt;，即引入音频等多模态数据往往会 &amp;ldquo;挤占&amp;rdquo; 模型用于纯推理的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDyd5pzGQm2vlHuyN4sY5tgLnErSSAOXS4ufiaXAkYykRviboxQ2Rod2IA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.575" data-type="jpeg" data-w="1080" data-width="3098" data-height="1782" data-imgfileid="503528464" data-aistatus="1" data-original-style="height: auto !important;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/55b56e75-0aea-4991-be92-dfd55de0bf32/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDm4WDUEH8ib38t6bXu0NktQaGA9NOrvB1ygvq1dAMj0icjTIVvLlyo3xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5611111111111111" data-type="png" data-w="1080" data-width="2152" data-height="1208" data-imgfileid="503528466" data-aistatus="1" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/300f0f2a-6187-4b04-b4a8-8001fb617cb9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了解决这一核心痛点，香港中文大学（深圳）与微软团队联合提出了 &lt;strong&gt;TARS&lt;/strong&gt; (Trajectory Alignment for Reasoning in Speech)。这是一项基于强化学习（RL）的全新对齐框架，它不依赖死记硬背的监督微调，而是通过对齐 &amp;ldquo;思维轨迹&amp;rdquo;，成功将语音输入的推理表现 &lt;strong&gt;100% 恢复甚至超越&lt;/strong&gt; 了纯文本基座水平。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDV2S227l4PibnrJ03HmUcZESWKnvQE2t2zBvbPc8IPcoHENTy7UTB19Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.2074074074074074" data-type="png" data-w="1080" data-width="1648" data-height="342" data-imgfileid="503528476" data-aistatus="1" data-original-style="height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7f244bca-44a3-48fa-b879-8a62a445a540/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文题目： Closing the Modality Reasoning Gap for Speech Large Language Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接： https://arxiv.org/abs/2601.05543&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心痛点：为什么模型 &amp;ldquo;听&amp;rdquo; 得越多，&amp;ldquo;想&amp;rdquo; 得越偏？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前的语音大模型（Speech LLM）通常采用 &amp;ldquo;语音编码器 + 适配器 + LLM&amp;rdquo; 的三段式架构。理论上，这应该能让语音输入无缝借用 LLM 强大的推理大脑。但现实是：&lt;strong&gt;引入语音模态后，推理能力出现了断崖式下跌。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;此前的研究主要试图从两个方向修补这一鸿沟，但都存在缺陷：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 输入端强行对齐（Input Fusion）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;试图让语音特征在输入层就长得和文本 Embedding 一样。但语音天然包含语气、停顿等富语言信息，与紧凑的文本本质不同。仅依靠输入对齐这种表面功夫，无法解决深层的&lt;strong&gt;表征漂移（Representation Drift）&lt;/strong&gt;&amp;mdash;&amp;mdash; 随着 Transformer 层数加深，语音激发的隐藏状态（Hidden States）会逐渐偏离文本的思考轨迹（即相同语义纯文本输入时，文本激发的隐藏状态），导致 &amp;ldquo;想岔了&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 输出端死记硬背（SFT / 蒸馏）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是最主流的做法，即通过监督微调（SFT）利用静态的 &amp;ldquo;语音 - 文本&amp;rdquo; 数据对进行训练，或者通过知识蒸馏（Distillation）让文本分支作为 &amp;ldquo;老师&amp;rdquo; 来指导语音分支这个 &amp;ldquo;学生&amp;rdquo;。这些本质上都属于 Off-policy（离线策略），试图强行让语音分支去模仿文本的 Token 输出分布。但这有两个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;目标不可达&lt;/strong&gt;： 语音的噪声和副语言特征决定了其输出分布不可能和纯文本完全一致。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Exposure Bias&lt;/strong&gt;： 这种静态监督无法容错。推理时只要错一个 Token，模型就会跌入训练未见过的状态，导致后续回复全盘崩溃。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TARS 的核心洞察在于： 既然死记硬背行不通，能不能用强化学习（RL），让模型自己在 &amp;ldquo;思考过程&amp;rdquo; 中去动态对齐文本的轨迹，而不是对齐具体的字？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TARS：用强化学习重塑语音推理轨迹&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;TARS 是一个基于&lt;strong&gt; On-policy RL（具体采用 GRPO）&lt;/strong&gt; 的对齐框架。它巧妙地利用模型自身的文本分支作为 &amp;ldquo;动态导师&amp;rdquo;，通过三个关键创新，把语音分支的 &amp;ldquo;脑回路&amp;rdquo; 掰回来。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDNkegWFGnTEZ5ACF40r37m1gHWjiaO3sAwbaMbbszvY8vxXNHjWTLAtg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3388888888888889" data-type="png" data-w="1080" data-width="1634" data-height="554" data-imgfileid="503528467" data-aistatus="1" data-original-style="height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2d0fae51-0c86-4eab-a0e3-c80f30867b53/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;创新一：表征对齐（Representation Alignment）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然 Gap 和 &amp;ldquo;表征漂移&amp;rdquo; 相关，TARS 选择直接从模型内部开刀。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;做法&lt;/strong&gt;： 计算语音作为输入，推理过程中&lt;strong&gt;每一层的隐藏状态（Hidden States）&lt;/strong&gt;，与同一模型在文本输入下（文本输入和语音输入在语义上完全相同）的隐藏状态计算余弦相似度，作为表征对齐奖励。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDMESPdfuiaTL98DjdeqZhLOk8DQ0f14icVXqNjZBxg8PmfcgWzCmw6ZPw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.21518987341772153" data-type="png" data-w="790" data-width="790" data-height="170" data-imgfileid="503528468" data-aistatus="1" data-original-style="width: 323px;height: auto !important;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e9dbf90f-a51e-4a94-81fb-feae46564523/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;作用&lt;/strong&gt;： 这就像给语音分支装了一个 &amp;ldquo;导航仪&amp;rdquo;。它不再只关注结果，而是引导语音分支的每一层思维路径都时刻紧跟文本分支的轨迹，防止跑偏。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;创新二：行为对齐（Behavior Alignment）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了避免 SFT 的死板，TARS 在输出端引入了更灵活的对齐标准。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;做法&lt;/strong&gt;： 不再要求 Token 级的一一对应，而是利用外部 Embedding 模型（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDCmqX1GEsOIDQHiaiaJT3UvSfjmhgLiahzSWFxibDlqlUz4nQTpWBuSGwSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="2" data-s="300,640" data-type="png" data-w="34" type="block" data-imgfileid="503528470" data-aistatus="1" data-original-style="width: 20px;height: auto !important;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/070aa210-e699-4302-aee3-d454ac63e623/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 1.96%;"&gt;, e.g., Qwen3-Embedding-0.6B）判断语音推理与文本参考的&lt;strong&gt;语义一致性&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD1dx55obibwUC5h1mDY86WgvZv90MRRWibiaeCDvfrPvmGPCicfHIOPVg1g/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.12987012987012986" data-type="png" data-w="770" data-width="770" data-height="100" data-imgfileid="503528469" data-aistatus="1" data-original-style="width: 325px;height: auto !important;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/99e72732-7c22-44f6-97a5-6617ab1c2cbf/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;作用&lt;/strong&gt;： 解决了 &amp;ldquo;目标不可达&amp;rdquo; 的问题。允许语音和文本在措辞上有差异，只要逻辑对、意思对就能拿分。这让模型在探索中学会了自我修正，而非机械模仿。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;创新三：非对称奖励与模态归一化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 RL 训练设计上，TARS 针对模态差异做了对应优化：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 非对称奖励（Asymmetric Reward）&lt;/strong&gt;： 文本分支只拿基础奖励（保住基本盘），语音分支额外拿对齐奖励（拼命追赶文本）。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDkW0vPJPIiaMhiavIzUaibV2HNcMWjF2HBII1NypmrX2E8wO3VQAIM1aFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.10925925925925926" data-type="png" data-w="1080" data-width="1080" data-height="118" data-imgfileid="503528471" data-aistatus="1" data-original-style="width: 356px;height: auto !important;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/71640305-93c3-4924-a294-48dd31e9c579/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. 模态特定归一化（Modality-Specific Normalization）&lt;/strong&gt;： 这一点至关重要。由于语音推理更难，往往得分较低，如果混合归一化，语音分支会一直收到负梯度。TARS 将两者分开归一化，让语音分支 &amp;ldquo;自己跟自己比&amp;rdquo;，保证了持续的优化梯度 &amp;mdash;&amp;mdash; 即使在所有样本任务准确率都为 0 的极端困难情况下，对齐奖励依然能指导模型进步。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDibVfcgEer7xkz1DIAicL6vLQAThyoVJoR1nEypsrYSlP5K7CicwBaSicQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.11203703703703703" data-type="png" data-w="1080" data-width="1392" data-height="156" data-imgfileid="503528472" data-aistatus="1" data-original-style="width: 311px;height: auto !important;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/46e3b692-c22a-43b6-bc2d-6e47b13b6ebf/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果：推理能力 100% 复原&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;团队在 &lt;strong&gt;UnifiedQA&lt;/strong&gt; 数据集上训练，并在 &lt;strong&gt;MMSU &lt;/strong&gt;和 &lt;strong&gt;OBQA&lt;/strong&gt; 两个高难度语音推理榜单上进行了验证。实验基于 Qwen2.5-Omni 和 Phi-4-MM 架构。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心战绩：MRR 突破 100%&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDq50XzfBNUElL92wpF3OQN2kmCjhwST6a16nbdyTibh2IXacD0dropibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6768518518518518" data-type="png" data-w="1080" data-width="2094" data-height="1418" data-imgfileid="503528473" data-aistatus="1" data-original-style="height: auto !important;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/71efa43b-742e-4357-a9fe-790de39fa826/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD1RZsl8X8PgGZexoFZticuapP2gbgwf8Bw87PibokwrYqbEeicYxkk5JTw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5212962962962963" data-type="png" data-w="1080" data-width="2092" data-height="1090" data-imgfileid="503528474" data-aistatus="1" data-original-style="height: auto !important;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3a73ea56-7a14-45d3-bdb3-085c30201a9a/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;模态恢复率（MRR）&lt;/strong&gt;： TARS 在 7B 模型上达到了 &lt;strong&gt;100.45%&lt;/strong&gt;（Table 1 最后一行）。这意味着，语音输入的推理能力不仅完全填补了引入音频带来的坑，甚至略微超过了文本基座的表现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;碾压基线&lt;/strong&gt;： 相比 SALAD、AlignChat、KD 等 SOTA 方法，TARS 在 Phi-4-MM 上的准确率达到了 &lt;strong&gt;79.80%&lt;/strong&gt;（Table 1 最后一行），稳居 7B 规模模型第一，且显著优于 SFT 和 DPO 基线（Table 2）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TARS 不是在拆东墙补西墙！&lt;/p&gt;&lt;p&gt;实验发现，TARS 的对齐并不是 &amp;ldquo;拆东墙补西墙&amp;rdquo;。在使用 TARS 训练后，模型的&lt;strong&gt;文本准确率也同步提升&lt;/strong&gt;（Qwen: +2.39%, Phi: +5.43%）。这证明语音模态学习到的知识，能够同时增强文本的推理能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;TARS 的提出标志着语音大模型研究的一个转折点：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 范式转变&lt;/strong&gt;： 证明了 &lt;strong&gt;On-policy RL&lt;/strong&gt; 在解决模态对齐问题上优于传统的 Off-policy（SFT / 蒸馏）方法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 轨迹对齐&lt;/strong&gt;： 提出的 &amp;ldquo;表征（过程）+ 行为（结果）&amp;rdquo; 对齐策略，有效消除模态推理鸿沟。&lt;/p&gt;&lt;p&gt;TARS 证明了语音大模型完全可以拥有和纯文本模型同等的 &amp;ldquo;智商&amp;rdquo;。对于致力于打造全能型 Omni 模型的研究者而言，TARS 提供了一条通往&lt;strong&gt;高智商语音交互&lt;/strong&gt;的可行路径。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>面向临床的心电图AI，上智院、复旦等提出CLEAR-HUG框架实现诊断性能与可解释性双突破</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 16 Jan 2026 14:04:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;作者团队丨上海科学智能研究院、复旦大学团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;在心血管疾病诊断中，心电图（Electrocardiogram, ECG）是无可替代的基础工具，其中 12 导联心电图是临床使用的金标准。作为观察心脏电活动的&amp;ldquo;视角&amp;rdquo;，导联是由一正一负两个电极构成的一个记录电路，12 导联心电图即是通过体表 10 个电极组合构建出 12 个独特的电信号&amp;ldquo;视角&amp;rdquo;，同步捕捉心脏的电活动，形成一套多维度的波形图谱。&lt;/p&gt;&lt;p&gt;然而，面对海量的心电图数据，现有基于自监督学习的分析方法尽管提供了无需大规模标注数据的解决方案，其局限仍非常明显：它们往往未能充分建模心脏传导过程中细微的个体心搏差异，也缺乏与临床&amp;ldquo;从心搏到导联，再从导联到整体&amp;rdquo;的递进诊断逻辑相对齐的推理结构，导致在复杂病例诊断中表现受限。&lt;/p&gt;&lt;p&gt;为此，上海科学智能研究院（下称上智院）与复旦大学联合提出了&amp;nbsp;CLEAR-HUG&amp;nbsp;双阶段框架。该框架从心电图信号的生理本质出发，在预训练阶段显式建模心脏传导特征，并在诊断阶段紧密贴合临床判读的层级思维，实现了从信号表征到诊断推理的全流程优化。实验表明，该方法在六个权威公开数据集上平均性能提升达 6.84%，为开发高性能、可解释的 AI 辅助心电图诊断工具开辟了新路径。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwbq3I3xMYn2EEdMvYDHosYd9icVCcwicvRTNoTm5Unqmibh3tTIftjcibBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3507246376811594" data-s="300,640" data-type="png" data-w="690" type="block" data-imgfileid="100027166" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ca340fbd-0641-4440-92d0-a210c54acfbb/640.png" alt="图片" data-before-load-time="1768543434374" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.24002&lt;/p&gt;&lt;p&gt;该研究成果已被 AAAI 2026 接收。研究项目由星河启智科学智能开放平台和复旦大学 CFFF 智算平台提供技术和算力支持。&lt;/p&gt;&lt;p&gt;星河启智平台链接：https://aistudio.ai4s.com.cn&lt;/p&gt;&lt;p&gt;&lt;strong&gt;现有方法的两大局限&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既往的心电图自监督学习（electrocardiogram self-supervised learning, eSSL）方法虽取得一定进展，但存在两个面向临床的关键短板：&lt;/p&gt;&lt;p&gt;一是忽视个体差异。&lt;/p&gt;&lt;p&gt;现有方法学会了看&amp;ldquo;大概&amp;rdquo;和&amp;ldquo;通常&amp;rdquo;，却难以识别那些&amp;ldquo;例外&amp;rdquo;与&amp;ldquo;异常&amp;rdquo;，而后者往往是临床诊断中更需要关注的信号。具体来说，现有方法主要让模型学习心电图信号中重复出现和普遍存在的模式&amp;mdash;&amp;mdash;比如不同导联之间波形的同步性，或连续心搏间的形态相似性，却忽略了一个生理事实：每个心搏的传导路径存在自然的细微差异，而不同导联观察的解剖角度也本就不同。这些细节往往承载着重要的生理与病理信息，例如，一个偶发的、形态异常的室性早搏，在标准心电图中看起来就&amp;ldquo;很不合群&amp;rdquo;，但这恰恰是临床诊断需要捕捉的关键线索。&lt;/p&gt;&lt;p&gt;二是脱离临床逻辑。&lt;/p&gt;&lt;p&gt;为确保诊断的精确性和全面性，心电图临床诊断通常遵循&amp;ldquo;心搏&amp;rarr;单导联&amp;rarr;多导联组合&amp;rdquo;的层级流程：医生首先观察单个心搏的形态细节，判断其是否异常；然后在一个特定的导联上，分析连续心搏的节律和模式，确认异常是否持续存在；最后，综合所有 12 个导联的信息，像拼图一样将不同导联的发现进行组合与空间对应，从而精确定位心脏的病变部位并做出最终诊断。但是，现有模型在下游任务中常忽视这一递进式诊断逻辑，导致特征提取与诊断需求脱节。&lt;/p&gt;&lt;p&gt;为解决这些问题，研究团队从心脏传导机制和临床诊断规范双重视角出发，构建了 CLEAR-HUG 框架，实现从信号表征到诊断推理的全流程优化。该框架与人类专家的知识体系对齐，使得医生不仅能够获知&amp;ldquo;诊断结果是什么&amp;rdquo;，更能理解&amp;ldquo;模型为何做出该诊断&amp;rdquo;，从而推动心电图AI分析更加可解释。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwRicPy0zOAOoPf4CDVQVceOgMqK7tUwnuGnHyWsZZnXXH3bwicgqdQClw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3898550724637681" data-s="300,640" data-type="png" data-w="690" type="block" data-imgfileid="100027167" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5524a1bb-927d-44a8-91d3-ab922c221416/640.png" alt="图片" data-before-load-time="1768543434426" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：心脏传导机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLEAR-HUG 的双阶段创新设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CLEAR-HUG 框架包含预训练和微调两个阶段，分别对应特征学习与诊断适配，形成完整的技术闭环。&lt;/p&gt;&lt;p&gt;第一阶段，团队设计了名为&amp;ldquo;传导-导联重构器&amp;rdquo;（Conduction-LEAd&amp;nbsp;Reconstructor, CLEAR）的自监督模型，该模型能同时捕捉心跳的特异性变异与普遍共性。通过将每个心搏视为独特实体，该模型采用简洁高效的稀疏注意力机制，在排除其他心搏干扰的情况下重构信号。&lt;/p&gt;&lt;p&gt;第二阶段，团队构建了&amp;ldquo;分层导联统一分组头&amp;rdquo;（Hierarchical lead-Unified&amp;nbsp;Group head,&amp;nbsp;HUG头）诊断模块，模拟临床诊断流程。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwNf0uia802TYFBZlyoQdFCCrSt4KfiaZO3vCzGJwjpKBTsibcqmpxGunlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4608695652173913" data-s="300,640" data-type="png" data-w="690" type="block" data-imgfileid="100027168" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ca8a9df8-69dc-42ec-be49-7980b6057463/640.png" alt="图片" data-before-load-time="1768543434443" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：双阶段训练&lt;/p&gt;&lt;p&gt;1.CLEAR 预训练，捕捉传导级细微特征&lt;/p&gt;&lt;p&gt;预训练阶段的核心是 CLEAR 模型，通过传导引导和视角引导的双重信息学习，精准重建心电图信号：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;双重视角建模：将心电图信号分解为传导引导信息（同一心搏在各导联的时间同步特征）和视角引导信息（同一导联的空间异质性特征），全面捕捉信号本质。&lt;/li&gt;&lt;li&gt;稀疏注意力机制：设计专属注意力掩码，确保心搏重建仅依赖对应的心搏传导信息和导联全局上下文，避免其他心搏干扰，高效提取特异性特征。&lt;/li&gt;&lt;li&gt;掩码重建训练：采用 80% 的高掩码率，通过重建被掩盖的心搏 token，迫使模型学习深层生理特征而非表面模式，提升表征鲁棒性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2.HUG 微调 ，模拟临床诊断流程&lt;/p&gt;&lt;p&gt;微调阶段引入 HUG 头，完全贴合临床心电图诊断的层级逻辑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;导联分组：按临床标准将 12 导联分为 3 组（双极肢体导联、加压单极肢体导联、胸前导联），每组通过独立线性层学习特征并平均。&lt;/li&gt;&lt;li&gt;成对组合：将三组特征进行两两组合，进一步捕捉导联间的互补信息。&lt;/li&gt;&lt;li&gt;全局聚合：整合所有组合特征，形成完整的多导联全局表征，作为最终诊断依据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种层级设计不仅提升了模型的可解释性，更让特征提取过程与医生诊断思维高度一致，实现从数据驱动到临床驱动的转变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在六大数据集上超越现有最优方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本研究在 MIMIC-IV-ECG 数据集上完成预训练后，于 PTB-XL、CPSC2018 及 CSN 三个公开数据集的六个下游任务上进行了系统评估，结果全面超越了现有最优方法（SOTA）。&lt;/p&gt;&lt;p&gt;具体而言，模型在平均性能上较当前 SOTA 提升了 6.84%，其中 CLEAR 单模型在预训练阶段贡献了 3.94% 的提升，而加入 HUG 诊断头后性能得到进一步改善，充分验证了双阶段设计的有效性。在低数据场景下，该方法展现出卓越的少样本迁移能力，例如，在仅使用 1% 训练数据的 PTBXL-Rhythm 任务中，CLEAR-HUG 较 SOTA 提升超 17%。&lt;/p&gt;&lt;p&gt;同时，在细粒度疾病分类任务上，层级分组策略的价值尤为凸显&amp;mdash;&amp;mdash;在 CSN 数据集的 38 类疾病分类中，使用 1%、10% 与 100% 训练数据时，HUG 头相较基础模型分别带来 9.21%、5.81% 与 3.18% 的性能增益。&lt;/p&gt;&lt;p&gt;此外，该方法在关键特性上也表现出显著优势。其一，模型具有更强的稳健性，即使在部分导联缺失、仅保留两个核心导联的极端情况下，其性能仍优于现有 SOTA，能够很好地适应临床中数据不完整的实际场景。其二，模型展现出高度的临床适配性，通过激活可视化，HUG 头对不同疾病所激活的导联组合模式，与临床诊断标准高度一致，显著提升了模型的可解释性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心模块的必要性验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为验证 CLEAR-HUG 框架中各核心组件的贡献，本研究进行了系统的消融实验。该方法遵循控制变量原则，通过逐步移除或调整模型中的特定设计，量化评估每个创新模块的实际价值。主要实验结果与发现如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;传导建模的有效性验证：对比基础掩码自编码器，CLEAR 预训练通过传导引导稀疏注意力，在心律分析任务中提升 17.4%，证明了传导机制建模的重要性。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwQ72U1DKyK2Nrpxw9ZeGONMq7jxibAcwUgibm9BicWODBxG2y7UOb7vOkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.8040201005025126" data-s="300,640" data-type="png" data-w="398" type="block" data-imgfileid="100027169" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7c793868-6b77-4442-b38d-b6588dc02ef6/640.png" alt="图片" data-before-load-time="1768543434802" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/li&gt;&lt;li&gt;层级诊断结构的作用分析：移除 HUG 头后，模型在细分类任务中性能明显下降，验证了层级分组策略对复杂疾病诊断的关键作用。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwwqZUPMb8eibzghJOt0R8GccKxB8iazArLuNWegPdiavtVCyMkbnpCibefQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7106481481481481" data-s="300,640" data-type="png" data-w="432" type="block" data-imgfileid="100027170" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1f3e4794-2bf2-40f6-9953-0a2647ed45f9/640.png" alt="图片" data-before-load-time="1768543434942" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/li&gt;&lt;li&gt;预训练掩码策略的优化验证：不同掩码率实验表明，80% 的掩码率能平衡特征学习深度与训练稳定性，是最优选择。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些实验从多个维度证实，CLEAR 与 HUG 两个核心模块均不可或缺，其设计共同支撑了模型在各项任务中的性能提升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CLEAR-HUG 的成功，并不依赖于复杂的模型架构，而是根植于对医学本质的深刻洞察与巧妙融合。&lt;/p&gt;&lt;p&gt;首先，模型从生理机制出发，紧扣心脏传导这一心电信号的核心生成原理，使特征学习过程更贴合生理本质。其次，通过将模型流程与医生诊断逻辑深度对齐，在提升性能的同时也显著增强了结果的可解释性。此外，其轻量化设计与对缺失导联的适应能力，兼顾了效率与临床实用性，为实际部署扫除了障碍。&lt;/p&gt;&lt;p&gt;该研究不仅为心电分析提供了新的技术路径，也印证了 AI 医疗发展的关键方向&amp;mdash;&amp;mdash;唯有将领域知识与人工智能技术深度融合，才能开发出真正赋能临床的实用工具。&lt;/p&gt;&lt;p&gt;展望未来，研究团队计划将本框架扩展至更多心血管疾病诊断场景，并探索与多模态医疗数据的融合应用，从而为智能医疗的落地持续注入新动力。&lt;/p&gt;&lt;p&gt;作者信息：&lt;/p&gt;&lt;p&gt;上智院实习生、复旦大学人工智能创新与产业研究院博士生潘覃和孙翊轩，为共同第一作者。&lt;/p&gt;&lt;p&gt;代码地址：&lt;/p&gt;&lt;p&gt;https://aistudio.ai4s.com.cn/galaxy-model/partner/galaxy-model-frontend/model/CLEAR-HUG&lt;a data-topic="1" href="javascript%3A;"&gt;#heading&lt;/a&gt;-1&lt;/p&gt;&lt;p&gt;https://github.com/Ashespt/CLEAR-HUG&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>神同步OpenAI！中国团队Deep Principle领衔发布LLMs for Science评测，引爆外网</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 16 Jan 2026 14:03:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;最近，一篇由中国团队领衔全球 24 所 TOP 高校机构发布，用于评测 LLMs for Science 能力高低的论文，在外网炸了！&lt;/p&gt;&lt;p&gt;当晚，Keras （最高效易用的深度学习框架之一）缔造者 Fran&amp;ccedil;ois Chollet 转发论文链接，并喊出：「我们迫切需要新思路来推动人工智能走向科学创新。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6T07oR3O8SToy6MOcEdaCia3MFibcqNpJn09ZfERm9oTKF1y8BD2cBklpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6963087248322147" data-s="300,640" data-type="png" data-w="596" type="block" data-imgfileid="100027148" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/42dae098-8008-456b-b948-ab8794d333ee/640.png" alt="图片" data-before-load-time="1768543355556" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;AI 领域 KOL Alex Prompter 分享论文核心摘要后，NBA 独行侠队老板 Mark Cuban 跟帖转发，硅谷投资人、欧洲家族办公室、体育媒体同时涌进评论区。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TEqsW5RwicCMFdr2pMGHCAptN835wBptmNlKIiam8Fl6TEmXfESZdOZbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.6446850393700787" data-s="300,640" data-type="png" data-w="1016" type="block" data-imgfileid="100027149" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/99212310-ea85-4c65-8425-672c41048151/640.png" alt="图片" data-before-load-time="1768543355562" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;仅一夜，累计阅读量逼近 200 万。&lt;/p&gt;&lt;p&gt;值得一提的是，同一时间窗里，OpenAI 也发布了对于 AI 在科学发现领域能力评测的论文《FrontierScience: Evaluating Al&amp;#39;s Ability to Perform Scientific Research Tasks》概述，指出现有评测标准在 AI for Science 领域失灵。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TKUNcXnKX4X5P4lialI0hzJcO4VJRYW2z06d3Nx3g8X7wGHMlg6raKow/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.1327731092436975" data-s="300,640" data-type="png" data-w="595" type="block" data-imgfileid="100027150" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2de8dc8d-f04b-4938-9839-bdce91aa4dcd/640.png" alt="图片" data-before-load-time="1768543355562" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;神同步 OpenAI、海外讨论出圈，究竟是什么样的一份工作成果，搅动了全球 AI 舆论场？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 距离可以助力科学发现还有多远？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前段时间，美国推出「创世纪计划」，号称要调动「自阿波罗计划以来最大规模的联邦科研资源」，目标是在十年内将美国科研的生产力和影响力翻倍。&lt;/p&gt;&lt;p&gt;但在人工智能估值泡沫隐现、能耗与产出比饱受质疑的当下，一面是资本的狂欢，另一面却是 AI 能力困于「文生图」等表层应用的尴尬；一面是各类大语言模型频繁霸榜 GPQA、MMMU 等题库式 Benchmark 的层出不穷，另一面却是现有 LLMs 还无法准确解析简单核磁图谱的尴尬现状。&lt;/p&gt;&lt;p&gt;人们不禁要问：能在题库拿高分，就能助力科学发现吗？现在的模型距离科学发现还有多远？究竟什么样的 AI 模型可以胜任，拓宽人类的生存边界？这些讨论，在中美 AI 竞争白热化的当下变得愈发浓烈。&lt;/p&gt;&lt;p&gt;在此背景下，由中国 AI for Science 领域的初创企业「深度原理&amp;nbsp;Deep Principle」领衔麻省理工学院、哈佛、普林斯顿、斯坦福、剑桥、牛津等全球 24 所科研院校共同发布的《Evaluating LLMs in Scientific Discovery》论文，正式回答该时代之问。&lt;/p&gt;&lt;p&gt;论文推出了 LLM for Science 首套评测体系&amp;nbsp;SDE（Scientific Discovery Evaluation），从科学问题到研究项目，对 GPT-5、Claude-4.5、DeepSeek-R1、Grok-4 等全球主流大语言模型在生物、化学、材料、物理领域的科学研究与发现能力完成摸底。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TIBotoxAD2nzVI4EUpCfb92oCE7RAK9ztkTIQPCE2VfjTeC96IDddDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027151" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/88674268-ed99-48c6-ad30-303eeb250907/640.png" alt="图片" data-before-load-time="1768543355622" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同以往评测体系不同的是，SDE 对模型能力的考量，从简单的问答式，引向了具体的「假设 -&amp;gt; 实验 -&amp;gt; 分析」实验场景。&lt;/p&gt;&lt;p&gt;研究发现，GPT-5、Claude-4.5、DeepSeek-R1、Grok-4 平均准确率 50&amp;ndash;70%，远低于它们在 GPQA、MMMU 等题库上的 80&amp;ndash;90%；在 86 道「SDE-Hard」难题中，最高分不足 12%，共同暴露出多步推理、不确定性量化和实验与理论闭环的短板。&lt;/p&gt;&lt;p&gt;更值得警惕的是，模型规模与推理能力的提升已呈现明显的「边际效益递减」。&lt;/p&gt;&lt;p&gt;GPT-5 相较于前一代模型，参数规模和推理算力显著增加，但在 SDE 基准的四大科学领域中，平均准确率仅提升 3%-5%，部分场景（如 NMR 结构解析）甚至出现性能下滑。&lt;/p&gt;&lt;p&gt;换句话说，当前大语言模型在推动科学发现方面的表现，还不如一个普通的本科生。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;能领衔 24 所顶尖科研院校发布的背后团队是谁？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;《Evaluating LLMs in Scientific Discovery》论文通讯作者段辰儒，是「深度原理 Deep Principle」创始人兼 CTO。早在 2021 年，在 MIT 攻读化学博士期间，他就已在图灵奖得主 Yoshua Bengio 的支持下，发起了 AI for Science 社区的建立，并在 NeurIPS 上举办 AI for Science workshop。&lt;/p&gt;&lt;p&gt;2024 年初，他与 MIT 物理化学博士贾皓钧回国，共同创立「深度原理 Deep Principle」。贾皓钧任 CEO，段辰儒任 CTO，两人虽为 95 后，但已在全球 AI for Science 创业领域小有名气。&lt;/p&gt;&lt;p&gt;创业一年半以来，其已获得线性资本、高瓴创投、蚂蚁集团等多家知名机构的投资，且与晶泰科技、深势科技等 AI for Science 领域的知名企业建立战略合作关系。&lt;/p&gt;&lt;p&gt;「深度原理 Deep Principle」从创立之初，就带着全球 AI for Science 头部研究者们的期待。目前「深度原理 Deep Principle」已深入全球材料研发中的第一线，将生成式人工智能同量子化学结合起来，致力于推动材料发现等领域进入新纪元。&lt;/p&gt;&lt;p&gt;在过去的一年中，他们在 Nature 大子刊和 JACS 等顶级期刊上不断扔出重磅成果，宣告着他们的技术领先和开放交流的「95 后创业公司」心态。从开拓扩散生成模型（Diffusion Models）在化学反应的生成，证明「不止要生成材料，更需要生成材料的合成路径」，到机器学习势（Machine Learning Potentials, MLPs）和扩散生成模型的直接对比，证明传统的机器学习势不是「万能」的，再到现在组织各大顶级学者和高校推出 SDE，证明传统一问一答的 Benchmark 不能带领我们走向科学超级智能，精准切入 AI for Science 领域的核心冲突。&lt;/p&gt;&lt;p&gt;但同时，对于所有的 AI4S 公司而言，在商业真金白银的检验中，AI 能否真正解决新产品研发问题、满足客户期待，是日复一日必须面对的拷问。&lt;/p&gt;&lt;p&gt;随着与行业头部客户的商业化合作落地，「深度原理 Deep Principle」的数据库中已经汇聚了来源于客户与自己实验室、大量来自第一线的真实工业研发场景数据和模型应用经验。&lt;/p&gt;&lt;p&gt;学术圈的深耕与在 AI for Science 商业化第一线的积累，让「深度原理 Deep Principle」在提出要构建一把新尺子评测 LLMs for Science 能力时，一呼百应，摇来了 23 家全球 TOP 科学发现机构的 50 余位科学家，成立了制定 SDE 的「梦之队」。&lt;/p&gt;&lt;p&gt;这其中，不乏活跃在 LLM 领域的大牛学者们，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;孙欢（Huan Sun），MMMU 发起人，俄亥俄州立教授&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;杜沅岂（Yuanqi Du），康奈尔博士，AI4Science 社区「运营大管家」&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;王梦迪，普林斯顿最年轻教授，AI+Bio Safety 先驱者&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Philippe Schwaller，IBM RXN&amp;nbsp;之父，EPFL 教授&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而「深度原理 Deep Principle」前期积累的科学发现场景，成为了后来 SDE 评测体系的前身。&lt;/p&gt;&lt;p&gt;在经历近 9 个月的跨高校跨学科跨时区的协作后，《Evaluating LLMs in Scientific Discovery》论文正式发布，通讯单位赫然写着：深度原理，杭州，中国。 &amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TZ9Bm2yttmJFP3pDLWM7byticdciah5xjfw72YVdibVFibYKLUINKWaC5RA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.2836601307189544" data-s="300,640" data-type="png" data-w="765" type="block" data-imgfileid="100027152" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d3809a4e-b413-4edc-a284-f3928d5b7b14/640.png" alt="图片" data-before-load-time="1768543355960" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;自此，汇聚着全球顶级科学发现机构的集体智慧，来自中国的创业团队「深度原理 Deep Principle」，和大洋彼岸的 OpenAI，同时站在了向 AI for Science&amp;mdash;&amp;mdash; 这一人类通往终极 AGI 顶峰攀登的起跑线。&lt;/p&gt;&lt;p&gt;或许千百年后，当人类回望 AGI 时代，在 21 世纪的四分之一结束的当口，这场由中美团队共同呼应的，对于 AI for Science 的严肃讨论，把 LLMs 在各类问答式榜单上的内卷，向真正科学发现的星辰大海推近了一步。&lt;/p&gt;&lt;p&gt;至于怎么通往彼岸，段辰儒表示：「当大语言模型在各种科学问答榜单表现饱和，但还不能有效支持科学发现时，就像『考试成绩好』不等于『顶级研究者』，说明我们需要新的评测体系与训练路径。」&lt;/p&gt;&lt;p&gt;「深度原理 Deep Principle」与 20 多所机构的 50 多位合作者的研究证明了，目前 LLM 的发展路径并不能「顺便攻克」科学发现。&lt;/p&gt;&lt;p&gt;这条通往科学超级智能之路，需要更多有识之士共同并肩而行。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>美团又上新模型，8个Thinker齐开工，能顶个诸葛亮？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 13:27:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜Panda、杨文&lt;/p&gt;&lt;p&gt;临近春节，各家 AI 厂商进入冲刺阶段，纷纷亮出最新大模型成果。&lt;/p&gt;&lt;p&gt;1 月 15 日，美团也重磅更新自家模型 &amp;mdash;&amp;mdash;&lt;strong&gt;LongCat-Flash-Thinking-2601&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这是一款强大高效的大规模推理模型，拥有 5600 亿个参数，基于创新的 MoE 架构构建。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="577" data-backw="578" data-height="790" data-imgfileid="503528594" data-ratio="0.9974747474747475" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFQiaIPufWNEx5nXFtOFwKd4OicLiboTvab6kPuaMT4NYcNIjSnoMviaD8SA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="792" data-width="792" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/275c3b6b-dcec-48ac-8b3c-9c130905a63b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该模型引入了强大的&lt;strong&gt;重思考模式（Heavy Thinking Mode）&lt;/strong&gt;，能够同时启动 8 路思考并最终总结出一个更全面、更可靠的结论。目前重思考模式已在 LongCat AI 平台正式上线，人人均可体验。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFmqZPpibEj5OYFVcN288Mp0XrgjzSq1p38TKhVDVFyDjS2MZicA4icYZJg/640?wx_fmt=jpeg#imgIndex=2" data-ratio="0.2175925925925926" data-type="png" data-w="1080" data-width="1936" data-height="622" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFNDqkW8A2TgiaGuB6n8ZAib2jqzS17sIFMhEtAcLNZMZuJ4sS5Cp3Uk3g/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1932.5551601423488" data-cropy1="55.11743772241993" data-cropy2="475.38790035587186" data-backw="578" data-backh="186" data-imgfileid="503528596" data-aistatus="1" data-original-style="width:561px;height:122px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ae0abd23-88b6-46c3-8223-bfbb4e6ba50c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 仅选择「深度思考」时才会触发重思考模式。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;体验链接：https://longcat.ai&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址：https://huggingface.co/meituan-longcat/LongCat-Flash-Thinking-2601&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;GitHub：&lt;/span&gt;https://github.com/meituan-longcat/LongCat-Flash-Thinking-2601&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不仅如此，该模型的&lt;strong&gt;智能体能力&lt;/strong&gt;还获得了重大提升：在智能体工具调用、智能体搜索和工具集成推理等基准测试中达到顶尖性能，而且在任意的 OOD（分布外）真实智能体场景中实现了泛化能力的显著提升。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="331" data-backw="578" data-height="1668" data-imgfileid="503528603" data-ratio="0.5731481481481482" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFGBdBP9ZcnNaOuicRldOwIK2icNjA6mNlpMoPaDe5Iez6B9ibk1k5NIb3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" data-width="2910" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9e441ac3-653d-4d99-bc5f-be25c5da21a1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队还专门提出了一种全新的智能体模型泛化能力评测方法。&lt;/p&gt;&lt;p&gt;通过构建自动化的环境和任务合成流程，基于给定关键词，随机生成任意的复杂任务。每个生成的任务都配备对应的工具集与可执行环境。&lt;/p&gt;&lt;p&gt;这种高度随机化的评测方式，能够更真实地检验模型在未知场景下的适应能力。&lt;/p&gt;&lt;p&gt;实验结果表明，LongCat-Flash-Thinking-2601 在该评测中始终保持领先性能。&lt;a href="https://mp.weixin.qq.com/s/4CWGglF95Knyrc-ERzgI2w"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/cf151250-3fbc-4395-bb13-ec52c4b3cb93/1768540936715.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;接下来，我们就把模型拉到真实场景里实测一番。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测：这只龙猫有点强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们先来试试数理逻辑推理，顺便看看这个&lt;strong&gt;重思考模式&lt;/strong&gt;到底是怎么一回事。&lt;/p&gt;&lt;p&gt;「运动会招募志愿者，第一次招募了不到 100 人，其中男女比例为 11:7；补招若干女性志愿者后，男女比例为 4:3。问最多可能补招了多少名女性志愿者？」&lt;/p&gt;&lt;p&gt;在 longcat.ai 上开启「深度思考」后，便进入了重思考模式，此时 8 个 Thinker 同时开工，每个都表现出不同的思考风格。有的按常规解题，有的则直接写了个 Python 脚本。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="372" data-backw="578" data-imgfileid="503528624" data-ratio="0.6435185185185185" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFgA3zzbayLGicGbib66o51opoLcwDE1BWib9S6n8pu1lOoqr65gELibicIzg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-type="gif" data-w="1080" type="block" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f70f27a1-5a0f-4bc9-9e28-e0be32c60b08/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大部分 Thinker 给出了答案 5，其中 3 号和 6 号 Thinker 还写出详细的推导过程。待 8 个 Thinker 执行完任务后，模型再验证不同 Thinker 的思考过程，形成最终答案。&lt;/p&gt;&lt;p&gt;整个过程就像一个团队开会讨论问题，最后达成共识，最终给出的解答也更靠谱得多。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="407" data-backw="578" data-imgfileid="503528628" data-ratio="0.7034291010194624" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFKibNFTmdwC7kw3SRavgr5DhjN0PiciavksQUibAhewBvhfZXB26Onnlq8A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-type="gif" data-w="1079" type="block" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/13872103-c641-4b0c-9169-8e9087998aa7/640.gif" data-order="1" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;下面是道逻辑推理题。「A 的手机号码最后 5 位，由五个不同的数字组成。B 说：我猜它是 84261。C 说：我猜它是 26048。D 说：我猜它是 49280。A 说：巧了，你们每人都猜对了位置不相邻的两个数。你知道这五位号码是多少？」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFcaMqlbS1gelqhBicMR0ycIxD7ghkr3GvUFmcFmjbuib1hib9hEVhs7WGw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.7025" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="406" data-imgfileid="503528630" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/791ad904-7aff-4ecb-ace1-faa978567054/640.gif" data-order="2" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;8 个 Thinker 再次启动，各自从不同角度切入。&lt;/p&gt;&lt;p&gt;模型没有简单地按照「少数服从多数」的原则采纳意见，而是调用一段代码，系统验证答案是否满足所有约束条件，并穷举所有可能的组合，确认 86240 是唯一解。&lt;/p&gt;&lt;p&gt;这种将单个模型调用八次的模型编排方式，在技术实现上虽直接，却在实际效果上发挥出「三个臭皮匠顶过诸葛亮」的优势。&lt;/p&gt;&lt;p&gt;实测过程中，我们还发现了重思考模式的一种有趣玩法：投票。&lt;/p&gt;&lt;p&gt;举个例子，我们可以开启「深度思考」模式，然后让模型选出 2000 年代最优秀的华语流行歌手。&lt;/p&gt;&lt;p&gt;我们发现不同的 Thinker 会给出很不一样的答案，比如有一个仅选出了周杰伦、蔡依林、孙燕姿、王菲、陈奕迅五位代表，而另一个则直接列出了一长串名单。&lt;/p&gt;&lt;p&gt;最终，经过模型在总结阶段的汇总整理，LongCat-Flash-Thinking-2601 给出了一份涵盖多维度评估的名单，颇具参考性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="518" data-backw="578" data-height="758" data-imgfileid="503528629" data-ratio="0.8970414201183432" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFmv58OTa4YRSHqagiagSAXpPrHbhQVMDlUv0WvN38nznupcOFUOHaqsA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="845" data-width="845" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3a7b1b3d-03ea-4415-8e49-c31f14a73a4a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们又试了下该模型的编程能力。先让它生成一个 Flappy Bird 小游戏，效果很不错。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="743" data-backw="578" data-imgfileid="503528626" data-ratio="1.2854291417165669" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFt9PPiboKmSX8FgicAUt9AlEqia55ZEly1ThrVEU0C7A1VMiawLrJPKFTRg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-type="gif" data-w="1002" type="block" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d9f0fef8-0e95-4abe-bf88-97a246b252da/640.gif" data-order="3" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; Prompt：Make a game like flappy bird using HTML/CSS/JS in a single HTML file.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;接下来我们又试了试让其编写一个康威生命游戏：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="642" data-backw="578" data-imgfileid="503528632" data-ratio="1.1106666666666667" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFNH8wpOb6icSnWu12s2yp081G8BbQsC3zNZ1AybHoJ2o6WIuFtLCrEqg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-type="gif" data-w="750" type="block" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/a35afce7-5e91-43fc-bcd4-2cbdbebb4694/640.gif" data-order="4" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;Prompt：用 Python 写一个 Conway 生命游戏，提供可视化网格、暂停、单步和参数调节功能。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但实事求是地说，使用 8 个 Thinker 来完成编程任务的计算成本应当是比较高的，可能并不适合大规模应用（尽管目前该模型对普通用户免费），但是我们认为这种模式却非常适合医疗、金融、法律等可能需要多次深度思考来保证准确性的场景。&lt;/p&gt;&lt;p&gt;最后，我们再来测试一下 LongCat-Flash-Thinking-2601 模型主打的 &lt;strong&gt;Agent 能力&lt;/strong&gt;，其中的核心便是工具调用。&lt;/p&gt;&lt;p&gt;为了方便用户测试，美团专门构建了一个「大模型工具使用测试」平台。该平台能基于关键词随机生成复杂的 OOD（分布外）任务，专门用来试探模型在陌生环境下的行动能力。&lt;/p&gt;&lt;p&gt;我们随机生成了一个「营养补给方案」任务。平台瞬间拉起了一个包含近 30 个工具的复杂图谱。从页面右侧的依赖关系可以看出，这并非简单的线性调用，模型需要像经验丰富的营养学家，理清儿童营养需求分析、食物营养成分计算、过敏食物筛选等工具之间环环相扣的逻辑。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="321" data-backw="578" data-height="1055" data-imgfileid="503528634" data-ratio="0.5555555555555556" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFunpDTtaVUv3KYcUINP40dszjA9vVqHaYSicv3DiaEHp2iaEAcdndia3ybA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" data-width="1899" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/de029fc0-a874-4628-8ba2-280ba2efdde5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更有趣的是，该平台还支持模型对比，让用户可以轻松地将 LongCat-Flash-Thinking 与其它模型放在同一起跑线上进行对比。&lt;/p&gt;&lt;p&gt;这里我们将其与当前大模型界的顶级选手 Claude 4.5 Opus 放在了同一个赛道上，进行同步竞技。&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/4CWGglF95Knyrc-ERzgI2w"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/04f8acb8-c2cd-471d-ad49-0c9987b48d7a/1768541012889.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 8 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;视频展示了两个模型在高频调用工具时的思考流。在任务完成后，系统会调用 AI 评估员，从执行速度与任务达成度两个维度进行复盘。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="167" data-backw="578" data-height="532" data-imgfileid="503528635" data-ratio="0.2898148148148148" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFNjBhgan3o2TBV69fTh6JO4hkFoZEicXXGLviaLEsEgbl56B1tBWhn6Aw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="1080" data-width="1838" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/77f9b14a-03c2-49f6-8bc5-f8e97b47fb19/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在这个具体案例中，两个模型都交出了高分答卷，但 LongCat 成功达到了 100% 的标准覆盖率，而 Claude 4.5 Opus 却未能成功为用户创建健康档案，仅达到了 80% 的覆盖率。整体而言，LongCat 在处理工具依赖关系的响应节奏上展现出了更强的稳定性。&lt;/p&gt;&lt;p&gt;深入细节，我们可以看到这些工具的调用和输出都采用了标准的 JSON 格式，这也是当前大量的 MCP 或 API 工具采用的主流格式。这也意味着，我们可以非常轻松地将 LongCat-Flash-Thinking-2601 整合进到现有的工作流程中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="465" data-backw="578" data-height="583" data-imgfileid="503528636" data-ratio="0.8041379310344827" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFULhPyN2ibjE5J7mQmicPuMvaXkczKwE03aVeYKYrbNxQsEibae0n4PHEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="725" data-width="725" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/25bda444-9071-4d07-8911-efacd54d0c0a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;强大实力的根基：重思考 + 智能体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么，表现如此亮眼的 LongCat-Flash-Thinking-2601 究竟是如何炼成的？&lt;/p&gt;&lt;p&gt;正如其推文总结的那样，我们先给出几个关键词：&lt;strong&gt;并行思考、迭代式总结、环境规模扩展（Environment Scaling）、多环境大规模强化学习（Multi-Environment RL Scaling）、课程学习（Curriculum Learning）&lt;/strong&gt;。另外，还有即将发布的 &lt;strong&gt;ZigZag Attention&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;作为 LongCat-Flash-Thinking 的最新版本，2601 版本继承了上一版本的领域并行训练方案，而技术底座同样是参数总量达 560B 的高性能混合专家（MoE）架构模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFGt3yXoJlsOQwCribsLqRxGJq8MA9qT2YkOeG72se7YMaB2f3Ow3EaAQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4074074074074074" data-type="png" data-w="1080" data-width="1322" data-height="539" data-backw="578" data-backh="236" data-imgfileid="503528650" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/6994cebf-0049-4b2a-bc0a-3737fcf0e9a5/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 来自 LongCat-Flash-Thinking 技术报告&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在此基础上，如上文评测所示，除了一些细节上的优化，这个新版本重点引入了两大改进：&lt;strong&gt;重思考模式&lt;/strong&gt;和&lt;strong&gt;智能体能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;该模型新引入的重思考模式别具一格，我们目前还未见其它任何模型显式或开源地提供类似模式。&lt;/p&gt;&lt;p&gt;而在智能体能力方面，美团引入了一套精心设计的流程。该流程结合了环境规模扩展与后续任务合成，并会在此之上进行可靠且高效的大规模、多环境强化学习。为更好地适应真实世界智能体任务中固有的噪声与不确定性，美团 LongCat 团队还对多种类型和不同强度的环境噪声进行了系统分析，并采用课程式训练，使模型在非理想条件下依然保持稳健表现。&lt;/p&gt;&lt;p&gt;下面我们就来更具体地看看美团的这些核心技术。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重思考模式：推理广度与深度的协同扩展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;打开 longcat.ai 「深度思考」后开始体验，你第一时间就会被同时冒出的 8 个 Thinker 吸引注意。这正是 LongCat 团队提出的 &lt;strong&gt;Heavy Thinking Mode（重思考模式）&lt;/strong&gt;的外在表现。它不仅看起来炫酷，更重要的是将推理能力推向了新的边界。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFMt6tPrwNo6BKPIssY1k6uxThenV8ibuxunclUDc4wF5XFBal0T9qtWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.1347222222222222" data-type="png" data-w="720" data-width="720" data-height="817" data-backw="578" data-backh="656" data-imgfileid="503528652" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/04195b9d-a1b0-4087-93ea-2801532ac7ef/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大致来看，其与 AI 大牛 Andrej Karpathy 实验性的&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651003281&amp;idx=1&amp;sn=3d21baa1164c2afbbfc15c7b2fb5c847&amp;scene=21#wechat_redirect" target="_blank"&gt;大模型议会&lt;/a&gt;项目有相似之处，但不同的是，Karpathy 的大模型议会是通过模型编排方式来向不同模型构成的集体提出问题，让它们各自发言并讨论后给出最终解答，而 LongCat-Flash-Thinking-2601 新引入的重思考模式则是&lt;strong&gt;并行地调用一个模型 8 次&lt;/strong&gt;来实现高强度的并行思考。&lt;/p&gt;&lt;p&gt;如此一来，便可以同时获得多条相互独立的推理路径并进行交叉验证，从而显著降低偶然性错误，提升在复杂问题上的稳定性、可靠性与最终答案质量。如此一来，可以进一步提升模型在极具挑战性任务上的表现。&lt;/p&gt;&lt;p&gt;具体来说，该模式会将高难度问题求解分解为两个互补阶段：&lt;strong&gt;并行思考&lt;/strong&gt;与&lt;strong&gt;总结&lt;/strong&gt;，从而同时扩展推理的深度与宽度。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在&lt;strong&gt;推理宽度&lt;/strong&gt;方面，重思考模式会并行生成多条独立轨迹，以广泛探索不同推理路径，并采用相对较高的推理温度以保证多样性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在&lt;strong&gt;推理深度&lt;/strong&gt;方面，总结阶段生成的精炼轨迹可以递归反馈给总结模型，形成支持逐步加深推理的迭代推理回路。LongCat 团队还专门设计了额外的强化学习阶段来训练总结能力，进一步释放该模式的潜力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;智能体能力提升：环境规模扩展与多环境强化学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体能力&lt;/strong&gt;方面，LongCat 团队精心设计了一套自动化环境规模扩展链路，并构建了一组多样且高质量的环境，作为工具调用类任务强化学习的训练场，使模型能够习得高层次、可泛化的智能体能力。&lt;/p&gt;&lt;p&gt;每个环境包含多达 60 余种工具，并以高密度依赖图的形式组织，提供了足够的复杂度以支持多样化任务构建与大规模探索。实验表明，随着训练环境数量的增加，模型在分布外（OOD）任务中的表现会持续提升（&lt;strong&gt;Environment Scaling&lt;/strong&gt;）。&lt;/p&gt;&lt;p&gt;高质量任务构建&lt;/p&gt;&lt;p&gt;为确保训练任务集的质量，LongCat 团队对任务复杂度和多样性进行显式控制。每个任务都定义在从高质量环境中采样得到的连通子图之上，任务复杂度通过要求在该子图内尽可能多地协同使用工具来调节。为促进任务多样性，已选工具的再次采样概率会逐步降低。&lt;/p&gt;&lt;p&gt;LongCat 团队还构建了配套数据库以确保任务的可执行性，并验证每个任务至少存在一种可执行解。然而，当环境中包含大量工具时，跨数据库的一致性维护会变得困难，可能导致部分任务无法验证。针对这一问题，LongCat 团队设计了专门的应对策略，使训练的稳定性和有效性得到了充分保障。&lt;/p&gt;&lt;p&gt;多环境强化学习&lt;/p&gt;&lt;p&gt;在保持高效异步训练和流式 rollout 特性的同时，LongCat 团队进一步扩展了其强化学习基础设施 DORA（异步弹性共卡系统），以支持环境规模扩展下的大规模多环境智能体训练（&lt;strong&gt;Multi-Environment RL Scaling&lt;/strong&gt;）。&lt;/p&gt;&lt;p&gt;具体而言，来自多个环境的任务会在每个训练批次中以平衡的方式混合，并根据任务复杂度和当前训练状态分配不同的 rollout 预算。&lt;/p&gt;&lt;p&gt;下图展示了该模型的多环境混合强化学习训练曲线，可以看到上涨的趋势非常稳定，这表明美团构建的基础设施和算法可以有效保证训练的稳定性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFcfza8FKCIxF5pFjSBiaqqj1Klu2KX7d3B4VWNWtH7yUyibFswMFHIcbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5907407407407408" data-type="png" data-w="1080" data-width="1695" data-height="1002" data-backw="578" data-backh="342" data-imgfileid="503528658" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/96191e0a-3f35-4e6e-aee4-dc3f72d1c536/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;下图则展示了多环境强化学习训练下，模型在不同 OOD 测试集上的 RL Scaling 表现，效果非常明显。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFtmlLrjVLYTfEVt8D8lcKOUYIcviae0EKibc17Nc6PWudENq3sxzbDm4A/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.8333333333333334" data-type="png" data-w="1080" data-width="1940" data-height="1616" data-backw="578" data-backh="481" data-imgfileid="503528660" data-aistatus="1" data-original-style="width:100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/31d7c3b1-93da-4c8a-bf77-550a5b21d359/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;面向噪声环境的稳健训练&lt;/p&gt;&lt;p&gt;真实世界的智能体环境天然存在噪声和缺陷，仅在理想化环境中训练模型往往难以获得足够的稳健性。为此，LongCat 团队在训练过程中显式引入环境不完美因素，以提升模型的稳健性。&lt;/p&gt;&lt;p&gt;具体而言，LongCat 团队系统分析了智能体场景中真实世界噪声的主要来源，并设计了一套自动化流程，将这些噪声注入训练环境。在强化学习阶段，LongCat 团队采用课程式策略，随着训练推进逐步增加噪声的类型和强度。&lt;/p&gt;&lt;p&gt;下图展示了模型是否采取面向噪声环境的稳健训练，在带噪声 / 无噪声评测集下的表现对比，其中不同的评测集上依据特性添加了不同类型的噪声。可以看到，带噪声环境下未经过稳健训练的模型的表现会出现大幅衰减，Claude 也无法适应全部的噪声类型。而经过稳健训练后，LongCat-Flash-Thinking-2601（Training w/ Noise 组） 对环境的噪声和不确定性展现出了强大的适应能力，并在各类非理想条件下取得更优表现。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFsRiassxnzUsn2Q7UIRf9ib8GqTcibL65UqhPZPFXjicc6uvuaC6ZHAoyIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.7583333333333333" data-type="png" data-w="1080" data-width="2586" data-height="1960" data-backw="578" data-backh="438" data-imgfileid="503528661" data-aistatus="1" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/8b458c58-2f92-4f01-978e-e49888b68429/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;得益于这些改进与创新，LongCat-Flash-Thinking-2601 不仅在智能体工具使用、智能体搜索以及工具融合推理等基准测试中达到顶尖水平，还在任意的 OOD（分布外）真实世界智能体场景中展现出显著提升的泛化能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LongCat ZigZag Attention：实现超长上下文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LongCat ZigZag Attention&lt;/strong&gt;，顾名思义，是一种注意力机制，根据其官方推文描述，其一大核心亮点是能「实现 100 万 token 上下文」。据悉，LongCat ZigZag Attention 已被成功用于训练当前 LongCat-Flash-Thinking 模型的一个分支，我们也将很快见证这个分支版本面世。细节详见论文：https://arxiv.org/abs/2512.23966&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFhJjqx1o17x61wJVVk9gEGFxxMBfH4ZH0nZTzhsp2VuWPMA4Dk3FjGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.3638888888888889" data-type="png" data-w="1080" data-width="1340" data-height="487" data-backw="562" data-backh="204" data-imgfileid="503528662" data-aistatus="1" data-original-style="width:100%;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/7b5a15ff-c5bc-4a8b-b184-a49818137abd/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;One More Thing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回头来看，美团大模型站到台前时间并不算长但节奏清晰，首次亮相在 2025 年 9 月，此后保持了每月一更的开源节奏，不断扩容自己的能力库：从强调响应速度的 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650988704&amp;idx=1&amp;sn=da107de5f4054028060a334398147912&amp;scene=21#wechat_redirect" target="_blank"&gt;LongCat-Flash-Chat&lt;/a&gt; 到专注逻辑的 Thinking 版本，再到图像和视频模型以及覆盖多模态的 Omni 版本，每一步迭代都在让这只龙猫能够更好地理解这个世界，并让复杂的现实生活变得更加可计算。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFfOYSu1DWxHx5a4s1ibcsZ7t8T4tQOvRpPiaSseITGBZlk5jIoZfW1Qibg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=19" data-ratio="0.6433041301627034" data-type="gif" data-w="799" type="block" data-backw="578" data-backh="372" data-imgfileid="503528665" data-aistatus="1" data-original-style="width: 100%;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/023ad478-89cf-43a1-a59b-63a47a6699ca/640.gif" data-order="5" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;美团在 Hugging Face 上的论文页面&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一次，龙猫聚焦 Agent 与 Thinking 能力进行全面提升，也是实现了一次从理解到融入真实世界的跃迁。&lt;/p&gt;&lt;p&gt;或许，美团现在追求的，就是一种确定性：能够用技术在真实世界中又好又快地解决问题，终有一天让「模型即服务」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
