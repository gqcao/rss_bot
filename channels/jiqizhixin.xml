<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>Sakana让AI互相「猎杀」，而它们开始了趋同进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:59:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3068ed3b-cfe2-4d99-89f8-d577333542b7/1768139698064.png" style="width: 700%;" class="fr-fic fr-dib"&gt;想象一下，一群 AI 程序在一台虚拟计算机里相互猎杀，目标只有一个：&lt;strong&gt;生存&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是 Sakana AI 与 MIT 合作的最新研究：&lt;strong&gt;Digital Red Queen（DRQ）&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagibdw6SsGTU6xk0b1YGDb2wEeZ1J1dzUQBib0icyibw4tkRVPzTrPwQrp4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.25" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527661" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/adfc502c-97d9-40e5-ab6e-194779bd3adf/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他们重拾了 1984 年的经典编程游戏《Core War》，利用大模型驱动了一场跨越维度的「军备竞赛」。&lt;/p&gt;&lt;p&gt;在这里，没有预设的标准答案，只有不断进化的对手。简单来说，他们提出了一种自演化汇编代码的方法。该方法通过在《Core War》中不断战斗来迭代代码演化。与静态优化目标不同，通过训练新「战士」对抗不断变化的对手，可以生成既健壮又通用的「战士」。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7f4932a6-6d4a-4df7-bf4b-b321845c4d76/1768139718803.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种「自博弈」模式产生出的汇编代码，不仅展现出了惊人的复杂性，更揭示了人工生命中一种有趣的现象：&lt;strong&gt;趋同进化&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVaggSsQIxt8ZYZrsggf3MmE4HibalBH8DhgPIGPMhicHk3GCuybXj9QybHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.24351851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527663" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8d7cb0f6-e4ca-496a-b3a4-1eb06759f949/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.03335&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/SakanaAI/drq/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;博客地址：https://sakana.ai/drq/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;《Core War》 是一款诞生于 1984 年的竞技编程游戏，在这款游戏中，被称为「战士」（warriors）的程序在一个虚拟计算机中争夺控制权。参赛者需要使用一种名为 Redcode 的专用汇编语言来编写程序。&lt;/p&gt;&lt;p&gt;在这项研究中，Sakana 探索了一个全新设定：&lt;strong&gt;当 LLM 驱动这个游戏时，会发生什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于静态评测基准，他们构建了一个动态的对抗演化环境，在其中程序不断适应、进化，以击败逐渐累积的对手历史，而非一组固定敌人。然后发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;这一动态对抗过程促使模型产生了越来越通用的策略；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不同的程序实现最终会趋向于相似的高性能行为模式，展现出类似趋同进化（convergent evolution）的现象；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;整体演化过程符合红皇后动态（Red Queen dynamics），即各个智能体不断适应彼此，持续进化但始终处于竞争状态。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终，本研究将《Core War》定位为一个用于研究人工系统中红皇后（Red Queen）动力学的实验沙盒，为分析 AI 智能体在现实世界对抗性环境（例如网络安全）中的演化方式，提供了一个安全且可控的研究环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag3BiazjJ4Z09GrNBUXKwxvJuPhicOOImubykFrMrgxcvvBgf7PyWNQMhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527664" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/36693e3e-a3c6-4a92-90a9-3ebc4d97b6b3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVaglsxiazYcEdB9U8DEcaWf0FArENhaRnqs7ZORWicmYLm4QuUhfJTTT1lA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4981481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527665" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1e534a9f-00f0-4ae8-9d43-fa1a2054bf6d/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;由 DRQ 生成的两个「战士」程序：Ring Warrior Enhanced v9 和 Spiral Bomber Optimized v22。选取这两个示例是为了展示 DRQ 的两个互补特性：其在单个程序中合成质量上截然不同的策略的能力，以及其生成整体表现良好的「战士」程序的能力。请注意，注释部分由大语言模型生成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/db02af18-13a9-4d9b-abcc-946712c2a368/1768139751093.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;在一个隔离的《Core War》沙盒环境中模拟，演化得到的「战士」程序。用户可以交互式地查看鼠标光标所在位置附近的「战士」汇编语言代码（Redcode）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「战士」程序相互竞争 &amp;nbsp;争夺一台虚拟机的控制权&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人类是一场非凡的进化军备竞赛的产物，在与其他生物体持续不断的竞争中被塑造而成。然而，进化并没有停止：竞争仍然在各个层面持续存在，从病毒与细菌，到人类个体、公司之间多方面展开博弈。&lt;/p&gt;&lt;p&gt;随着越来越多的人工智能系统被部署到现实世界中，它们也将不可避免地进入这一竞争格局。这些 AI 系统将以直接或间接的方式相互竞争，从而引发一种全新的演化动态。&lt;/p&gt;&lt;p&gt;为了为这样的未来做好准备，并研究其中演化过程，Sakana 使用 LLM 来演化一组程序，让它们在《Core War》的游戏中相互竞争，这些竞争者的任务是在尽可能长的时间里保持自身进程活跃的同时，尝试使对手程序崩溃，从而取得对一台虚拟计算机的控制权。&lt;/p&gt;&lt;p&gt;整个模拟过程通过交替执行各个程序中的一条指令来运行。一个「战士」可以通过向对手占据的内存位置写入非法指令（如 DAT 命令）来发起攻击，一旦对手程序执行到该位置就会崩溃。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/14b2adbf-7651-4530-a5d9-7aae7db9ff90/1768139769993.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;在《Core War》中相互对战的已发现「战士」示例。在本研究中，Sakana 使用 LLM，通过 Digital Red Queen 的自博弈算法来演化「战士」。这一过程促使出现了多种多样且复杂的策略，包括定向轰炸、自我复制以及大规模多线程。在这里，本文展示了一些被发现的「战士」在《Core War》对战中的表现。图中符号表示指令操作码，颜色表示最后一次修改每个内存地址的「战士」。代码和数据之间没有区分，使得该环境高度动态且不稳定。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，在《Core War》中，代码和数据之间没有界限，因此「战士」程序会在运行过程中频繁地修改自己和对手的代码。&lt;/p&gt;&lt;p&gt;这使得自我修改甚至自我复制成为可能，但也造就了一个极度不稳定的环境，程序必须在这种条件下设法生存下来。&lt;/p&gt;&lt;p&gt;此外，《Core War》是图灵完备的，也就是说，从理论上它可以支持任意复杂的策略。&lt;/p&gt;&lt;p&gt;多年来，人类玩家在《Core War》中设计出了许多巧妙的策略，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;向随机内存位置投放炸弹；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;编写可自我复制的程序；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不断扫描内存，侦测对手位置并发起攻击。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些策略的诞生，实际上是一场由人类主导的元军备竞赛，玩家不断尝试新策略，测试哪些能奏效、哪些不行。&lt;/p&gt;&lt;p&gt;那么，如果我们让 LLM 也参与这样一场军备竞赛，会发生什么？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新提出的方法：数字红皇后（DRQ）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在进化生物学领域，&lt;strong&gt;「红皇后假说（Red Queen Hypothesis）」认为物种必须不断进化，仅仅是为了在千变万化的竞争对手面前生存。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该假说指出，仅仅适应当前环境是不够的。相反，生物必须持续进化 &amp;mdash;&amp;mdash; 不是为了获得优势，而仅仅是为了在这个变幻莫测的世界中维持相对的适应度。&lt;/p&gt;&lt;p&gt;这个概念完美捕捉了对抗性军备竞赛的本质：&lt;strong&gt;即「适应」永远不是一种永久状态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个名字源于《爱丽丝镜中奇遇记》，红皇后对爱丽丝说：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;「在这个国度，你必须拼命奔跑，才能留在原地。」&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4a06ca7a-2459-4b73-8743-41f5e5889139/1768139804308.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;受生物学启发，Sakana 构建了一种名为数字红皇后（DRQ）的简单算法，它在计算环境中体现了这一思想。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DRQ 利用 LLM 来在持续的环境变化中让「战士」进化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体来说：它从一个初始战士开始，然后进化出第二个战士来击败第一个。接着，再进化出第三个战士，使其在对抗前两个战士时表现出色，以此类推。这一过程产生了一个战士世系，其中每个后代都适应于由其所有前代定义的不断变化的环境。&lt;/p&gt;&lt;p&gt;Sakana 表示：「DRQ 本身并非旨在成为一种全新的算法。相反，它是先前多智能体和自博弈方法的最小化实现。它被适配到《Core War》领域，旨在隔离并研究持续协同进化（coevolution）的动态。」&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a72f29f3-6f01-40ce-82c1-715e75ceba91/1768139818850.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究发现，&lt;strong&gt;随着 DRQ 运行轮次的增加，战士们逐渐变得更具通用稳健性&lt;/strong&gt;（这一指标通过与未见过的、由人类设计的战士对抗来衡量）。&lt;/p&gt;&lt;p&gt;这提供了一种稳定且持续生产稳健程序的途径，而无需进行「在测试集上训练」（即直接针对大量人类设计的程序进行优化）。&lt;/p&gt;&lt;p&gt;更令人惊讶的是，实验中还观察到独立运行的多个 DRQ 实验（每个实验都从不同的战士开始初始化）会随时间推移，慢慢趋向于演化出具有相似行为的战士。值得注意的是，这种趋同并没有发生在源代码层面，这表明趋同的是「功能」而非「实现」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagJz8eOMUkAibXvfvYPic4SW09ozOhvUPd9H4APEXAu4EicIPcQlnqZgayw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.32314814814814813" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527667" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e789c70d-7800-47b7-8429-f20edef43d25/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;DRQ 的趋同进化：随着轮次增加，DRQ 产生的战士具有更强的通用稳健性。同时，不同独立运行的 DRQ 实验之间，战士行为的差异在减小，表明出现了趋同。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag7NSRuerZmQWszkoNYq7GqnLE1BFA0frTqG9DF2MWIrFPsf3dK3xsBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.45185185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527668" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/35a870f6-c879-448e-9ff4-adb1fc45d915/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表型趋同（Phenotypic Convergence）：轮次增加带来的趋同仅体现在战士的「表型」（行为）上，而非「基因型」（源代码）。这类似于生物学中功能上的趋同，而非 DNA 的趋同。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一结果让人联想到生物学中的趋同进化 &amp;mdash;&amp;mdash; &lt;strong&gt;即相似的功能特征通过不同的机制独立进化了多次。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;例如，鸟类和蝙蝠各自独立进化出了翅膀；蜘蛛和蛇独立进化出了毒液。&lt;/p&gt;&lt;p&gt;在这些案例中，由于环境变化施加的功能需求倾向于这些解决方案，进化最终达成了相似的通用目的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;讨论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「红皇后（Red Queen）」动态及其引发的趋同进化现象在自然界中普遍存在，这表明 DRQ 算法和 Core War 领域的结合，可能为研究对抗性军备竞赛其他特性提供了一个极具潜力的实验环境。通过模拟得到的宏观洞察，可以帮助我们预测 LLM 在现实世界中的军备竞赛将如何展开与演变。像 DRQ 这样的算法，甚至有助于在系统部署到现实世界之前，实现自动化的红队测试（red-teaming）。&lt;/p&gt;&lt;p&gt;在《Core War》这样的沙盒中进行此类研究的好处是，它完全自成体系：所有程序都在一台使用人造语言的虚拟机器上运行，因此生成的任何内容都无法在沙盒外执行。这提供了一个安全的环境，可以探索那些在现实世界中进行可能具有风险的对抗性动态。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4ebd7700-3793-4f63-a48f-c1e0d0470d35/1768139852297.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;在沙盒化的《Core War》环境中，可以模拟进化出来的「战士」程序，并将它们的行为可视化。用户可以交互式地可视化这些「战士」的汇编语言（Redcode），并通过鼠标光标所在的位置进行查看。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;尽管基础版 DRQ 算法本身较为简单，但它在《Core War》中表现出乎意料得好，这表明：&lt;strong&gt;即便是最简单的自对弈循环，也能揭示出复杂且鲁棒的策略。&lt;/strong&gt;这使得 DRQ 成为探索其他竞争性多智能体仿真（如人工生命、生物学、药物设计、现实世界网络安全或市场生态系统）的有力候选方案。&lt;/p&gt;&lt;p&gt;未来的工作还可以探索更丰富的设置，让多个智能体能够同时共进化，从而更好地模拟现实世界 &amp;mdash;&amp;mdash; 在那里，大规模种群是并行适应的，而不是沿着单一的演化线发展。最终，所获得的洞察将有助于更好地掌握未来，并帮助我们理解这些进化性军备竞赛背后的科学原理。&lt;/p&gt;&lt;p&gt;更多信息，可查看原论文获悉！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>不做人形、不跳舞：他家的具身智能凭什么在100+城市卖出400万杯咖啡？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:53:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a9465250-5bc6-473b-a7f2-37609d609788/1768139402887.png" style="width: 700%;" class="fr-fic fr-dib"&gt;新年刚开局，AI 行业就直接拉满强度。&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;在 CES 这个全球科技风向标上，机器人 &amp;times; AI 成了真正的主角。在拉斯维加斯的霓虹灯下，中国机器人军团走到舞台中央&amp;mdash;&amp;mdash;不靠堆概念，而是带着订单和规模化落地速度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzcBeHwutPYK2ISjAt65dsn2pKWVRBpsS92Jpklw2Mnk3Pc098bBZLow/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6445945945945946" data-s="300,640" data-type="png" data-w="740" type="block" data-imgfileid="503527777" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/cc53e6d8-1897-4033-9997-5c891dd464d1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;CES创新奖评委Chris Pereira 指出，中国厂商正在把新兴技术，快速转化为能量产、能交付、能在全球市场销售的成熟产品。&lt;/p&gt;&lt;p&gt;与此同时，AI 正退到幕后，成为产品底层能力，真正的竞争，落在实用性、设计与可靠执行力上。&lt;/p&gt;&lt;p&gt;在展会现场，最吸睛的依旧是「人形」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzdLzDmFzia9Y7AQxlYH5Tttan1R5WGn3sgTr8n9oSEzxGLs7Wsxp8obw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.734" data-s="300,640" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="367" data-imgfileid="503527802" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dc1b1cc3-e4a3-498b-aa43-56c10d44055a/640.gif" data-order="0" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 波士顿动力（现在已经属于韩国现代集团）的新版Atlas亮相。&amp;nbsp;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但在同一空间内，另一条路线也在同步展开。&lt;/p&gt;&lt;p&gt;在影智 XBOT 的透明橱窗前，人群一层层围拢过来。这是全球首个支持冷热双杯同出的具身机器人，也是目前一众具身智能中最落地的一种呈现。&lt;/p&gt;&lt;p&gt;有人举着手机录像，有人已经在讨论要把什么图案印在咖啡上。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzdYbS4OcbD7yg8xWhrNYPZFyZ4qLvqGwk6WiaQsFJv37QdjgwBAOadsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527784" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1deb982b-b175-4e30-a09b-15fafae87957/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp;影智 XBOT Lite 系列印花咖啡机器人&amp;mdash;&amp;mdash;全球首个支持冷热双杯同出的具身机器人。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;玻璃之后，两只机械臂分工协作，打奶、印花、出杯，动作连贯得像一段被反复打磨过的编舞。110 秒后，一杯冰美式和一杯热拿铁同时完成，杯面上浮现出由 AI 生成的专属印花&amp;mdash;&amp;mdash;每一杯都不重样。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzxkod1MibBBPSSozsX6iaYbfNFBrfibr7dZxIUREibOoibtSs4dFjOSuhGpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.1479028697571745" data-s="300,640" data-type="png" data-w="906" type="block" data-backw="578" data-backh="663" data-imgfileid="503527799" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e0aec6b6-c4c2-479c-bab2-2090ed690f86/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;「这玩意儿太酷了。」队伍里有人忍不住感叹，「能在咖啡上打印照片，绝对是游戏规则改变者。」有人已经等不及拍照发社交平台。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzxicKZT4h4EjHUkPdut5ztPDKBrxiaXOzjzfNaJ3j5ajzibjtLbTGmZXpA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.562962962962963" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527789" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e423c481-29a0-4956-a0f0-7718fdfac865/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;机器人继续出杯，节奏稳定。「你能把公司 logo 印在咖啡上，这杯咖啡一下子就成专属的了，谁会不喜欢？」 有顾客说。「而且不用付小费&amp;mdash;&amp;mdash;对顾客对老板都是好事。」 有人从更现实的角度补了一句。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzeZ13htRHjyf7eX1DPiaia2CgGUuIMV3pMia0t71mjicU38oP7EUfziaoStw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="434" data-imgfileid="503527781" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/871c0b0e-8dcc-431a-92b2-2c3b9cc4cfe4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;喝完咖啡，又尝了旁边影智&amp;nbsp;XBOT&amp;nbsp;冰淇淋机器人做的冰淇淋，人群里笑声不断。「这哪是咖啡机？」有人指着橱窗笑道，「这是个能把人吸过来的娱乐中心。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzic2E9uz3agKogCoApTZiaYOInWd9aeGM8uXpKoKhkRMkwKl83DtmndGQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="562" data-backh="316" data-imgfileid="503527782" data-aistatus="1" data-original-style="width:100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/0e15d811-a619-47a7-9dcf-f48f7976e0c7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;与多数人形机器人仍在努力「看起来很未来」不同，影智XBOT并不追求形似人类，而是成为一台&lt;strong&gt;可以全天候运转的生产工具&lt;/strong&gt;&amp;mdash;&amp;mdash;不跳舞、不表演，直接把一杯口感稳定、好喝的咖啡，端到你面前。&lt;/p&gt;&lt;p&gt;而这套逻辑，已经在真实世界里跑了很久。&lt;/p&gt;&lt;p&gt;从天安门广场、国家图书馆到成都锦里，影智XBOT经历的不是短暂的 show time，而是数百万次的反复出杯。&lt;/p&gt;&lt;p&gt;目前，影智XBOT已在 &lt;strong&gt;15&amp;nbsp;个以上国家、100多个城市&lt;/strong&gt;落地，部署量超过 &lt;strong&gt;600&amp;nbsp;台&lt;/strong&gt;，累计制作咖啡 &lt;strong&gt;400&amp;nbsp;万杯以上&lt;/strong&gt;，在部分核心点位甚至实现了&lt;strong&gt;数月回本&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在具身智能普遍面临商业化难题的当下，影智XBOT用一组明确的数据证明：它是目前行业内&lt;strong&gt;商用落地速度最快的具身智能机器人之一&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzdxpuvfDnarCmJypiaU58ferCP3QF14xqYiczZfEuHUIjqTz9rgoG86icQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-ratio="0.666270783847981" data-type="jpeg" data-w="842" data-backw="421" data-backh="280" data-imgfileid="503527764" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/eec1b48e-219f-4f6c-97f7-c5255547ce0a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 2025年8月影智科技发布年度新品之一：影智XBOT Lite系列印花咖啡机器人。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;回归商业常识：具身智能不等于「人形」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在当下关于具身智能的讨论中，「人形」几乎成了一种默认答案。但在「操刀」影智XBOT的影智科技看来，这条路径更多源于技术想象，而非商业理性。&lt;/p&gt;&lt;p&gt;这一判断，来自公司创始人唐沐长期积累的产品与商业经验。&lt;/p&gt;&lt;p&gt;作为 2022 年福布斯中国十佳设计师，唐沐曾掌舵腾讯用户体验设计中心（CDC），并担任小米生态链副总裁。他既是 QQ 头像、微信表情包等现象级符号的缔造者，也是小米路由器、小爱智能音箱等亿级爆款产品的重要推动者。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzc0yWrNAcQH62eeMXibiax0OFopFqICt0vEbbnSyAMVVtaEGn9d2eQciaA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=9" alt="图片" data-ratio="0.5628539071347678" data-type="jpeg" data-w="883" data-backw="442" data-backh="249" data-imgfileid="503527763" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2e0fdd02-5ff0-44b4-b93a-128ba777a93d/640.png" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;公司创始人唐沐和影智XBOT咖啡机器人。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;长期站在技术、产品与规模化商业的交汇点，也塑造了他极其务实的产品观：一切产品必须从真实场景出发、目标要指向大众市场，并且要经得起规模化、可靠性与成本结构的严格检验。&lt;/p&gt;&lt;p&gt;这也构成了影智科技切入具身智能领域的基本原则&amp;mdash;&amp;mdash;回归商业常识。先解决人的需求，解决人的问题，在一个足够垂直的场景中把事情做到极致，再去讨论所谓的「终极形态」。&lt;/p&gt;&lt;p&gt;在唐沐看来，机器人的进化路径不该从「像人」出发，而应回到「是否真正有用」。具身智能的价值，并不取决于外形是否拟人，而在于是否能够围绕具体问题展开，在真实环境中灵活适应、精准执行。&lt;/p&gt;&lt;p&gt;在大量现实的消费与服务场景中，工程复杂度高、成本更高并伴有不可控风险的人形设计，反而会成为商业化落地的负担。&lt;/p&gt;&lt;p&gt;至于「为什么是精品咖啡」，也是多条现实线索叠加后的选择。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑市场，首先要足够大，其次必须是一个成长型市场&lt;/strong&gt;，咖啡符合这两个前提。它本身是一个高度全球化、已被充分验证的成熟消费市场，而中国市场还在快速增长。&lt;/p&gt;&lt;p&gt;数据显示，2023 年我国人均年咖啡消费量约为 16.74 杯，几乎是 2016 年的两倍；到 2024 年，这一数字已提升至 22.24 杯以上。即便在瑞幸、库迪等品牌快速扩张的背景下，中国咖啡门店的整体密度，依然明显低于日本和韩国等成熟市场，增长空间可观。&lt;/p&gt;&lt;p&gt;需求持续走高的同时，供给侧却长期受制于人力瓶颈。&lt;/p&gt;&lt;p&gt;咖啡师培养周期长、流动性高，岗位留存率普遍偏低；在高度内卷的竞争环境中，咖啡店拼的是出单量与运营效率，对人力的挤压不断加剧，也放大了系统性的运营矛盾。&lt;/p&gt;&lt;p&gt;咖啡消费还呈现出明显的波峰与波谷。高峰期排队几乎成为常态，品质波动难以避免。尤其是在拉花这类对毫米级精度和连续轨迹高度敏感的操作中，人类不可避免的生理性抖动，会直接放大为线条断裂或形变。&lt;/p&gt;&lt;p&gt;而对大多数用户而言，他们关心的不是「谁在做咖啡」，而是出杯是否足够快、品质是否始终稳定。以出杯量为例，每天三百杯以上的稳定输出，对人类咖啡师而言几乎不可持续；而对机器人来说，这只是一个连续、可复制的标准工作负载。&lt;/p&gt;&lt;p&gt;在这样的背景下，大模型的出现，让产品「升维」&amp;mdash;&amp;mdash;从底层重新定义一套面向消费服务场景的具身智能系统&amp;mdash;&amp;mdash;成为可能。&lt;/p&gt;&lt;p&gt;市面上多数咖啡机，本质上仍是工业自动化设备，考虑的是「怎么把咖啡做完」。具身智能除了关心效率，还关心「这杯咖啡是给谁喝的、在什么情境下喝、怎样才算一次好的体验」。咖啡这一日常消费场景，&lt;strong&gt;第一次有机会迈入以用户体验为核心的重构阶段&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;历经两年多研发，影智XBOT问世并成功出圈，唐沐也因此多了一个被媒体反复引用的标签：「具身智能消费机器人第一人」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;具身智能的「三位一体」：&lt;/strong&gt;&lt;strong&gt;为什么能做到万杯如一？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从原料开始，影智XBOT就在为「稳定性」服务。&lt;/p&gt;&lt;p&gt;目前，影智XBOT全部采用阿拉比卡咖啡豆，设备内设置两个豆仓：一个拼配豆，一个单品豆（瑰夏），以覆盖不同用户的口味偏好；牛奶则与蒙牛合作统一供应。无论是在北京、上海，还是成都，下单后端到手里的那杯咖啡，都能保持高度一致的风味。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzZMhfPKzX8ruZvwAn6bc4Uic8E4ezCSKl6QDmHz5g3cpCsib5uPbZXw1g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.5633802816901409" data-s="300,640" data-type="gif" data-w="568" type="block" data-backw="568" data-backh="320" data-imgfileid="503527803" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/680749ac-ca0e-47d3-ad8e-d9959a324826/640.gif" data-order="1" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这种「万杯如一」的表现，并不是靠单一环节实现，而是依赖一套完整的具身智能技术体系：&lt;strong&gt;负责理解与决策的「大脑」、统筹执行的操作系统（OS），以及完成精细物理动作的「小脑」。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;影智XBOT的「大脑」，并不是传统点单系统，而是一套面向真实世界运行的具身智能餐饮大模型，核心目标是更好地理解用户需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzicVz1cKVtiamRKlptoib6bia6VNicQYq4jricZgEbauHM4waukickO9sWtib0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.41505791505791506" data-s="300,640" data-type="png" data-w="1036" type="block" data-backw="578" data-backh="240" data-imgfileid="503527783" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/2e1a0412-b001-41c0-afc8-3a6ac828f93a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当你说出一句模糊需求&amp;mdash;&amp;mdash;比如「我想来一杯热带风情的咖啡」&amp;mdash;&amp;mdash;系统会在毫秒级调取完整的饮品知识体系，覆盖公开菜单、配方逻辑与标准化制作 SOP，并理解「热带风情」意味着椰子、热带水果、冰感与较高甜度。&lt;/p&gt;&lt;p&gt;接下来，大模型会调用口味拼配算法，在现有原料约束下寻找最优解：比例如何控制？先加什么、后加什么，才能在不破坏咖啡骨架的前提下，呈现「热带」风味？&lt;/p&gt;&lt;p&gt;这些原本高度依赖咖啡师经验与手感的判断，被转化为一组可计算、可推演的决策过程。算法甚至「知道」一些已经被反复验证的美味公式，如生椰与拿铁是绝配。&lt;/p&gt;&lt;p&gt;最终，你的抽象需求会被翻译成一连串精确到秒的动作调用：咖啡液多少秒、椰乳多少秒，冰、糖与水如何配合。每一个动作，都是机器人已经掌握的能力模块，可以被反复调用、稳定复现。&lt;/p&gt;&lt;p&gt;在「揽客」上，AI 数字人承担「意图入口」的角色。它具备长记忆能力，能识别老顾客与偏好&amp;mdash;&amp;mdash;「Hi，Thomas，还是要上次的橙 C 冰美式吗？」甚至能在连续对话中保持上下文一致。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOziaYq0Cl4WhaibjErD78J0gvriabvE1uwRKcgW9MqIUXsA2eCVleeFcxJA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="384" type="block" data-backw="384" data-backh="216" data-imgfileid="503527805" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c65bf97c-7e8d-4238-8b37-7869831d58fa/640.gif" data-order="2" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;数字人还能根据状态做出情境化推荐，如夜深时建议一杯 double 浓缩。结合 AIGC，用户「随口一说」的创意，也能被实时「打印」成咖啡印花。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzu3ic4ibpOorZCTThKgUAHbDL73K0aiaoNbKrI3TbsvaByo0BsMayxKwjQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="1.7777777777777777" data-type="gif" data-w="504" type="block" data-backw="504" data-backh="896" data-imgfileid="503527814" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/8c86ba50-843a-4573-aaec-452d4321a96f/640.gif" data-order="3" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 将自拍变成独一无二的咖啡印花。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如果说「大脑」解决的是「逻辑上该怎么做」，那么影智XBOT&lt;strong&gt;操作系统&lt;/strong&gt;（LU BAN OS）要解决的是&lt;strong&gt;在真实世界中能不能这么做&lt;/strong&gt;&amp;mdash;&amp;mdash;这是双臂机器人实现落地的关键一环。&lt;/p&gt;&lt;p&gt;它更像一套神经中枢。当「大脑」给出高层指令后，OS并非简单转发，而是介入执行层，在复杂的真实环境中进行&lt;strong&gt;全局编排：&lt;/strong&gt;统一调度机械臂、咖啡机、奶泡器、糖浆泵、制冰机、印花机等设备，确保每一个步骤、每一个动作，都发生在安全、合理且可控的物理条件之内。&lt;/p&gt;&lt;p&gt;做出一杯咖啡，看似线性的流程，背后其实是一套&lt;strong&gt;高并发的任务调度系统&lt;/strong&gt;。通过底层运动算法，OS实现了双机械臂的&lt;strong&gt;空间解耦与时间同步&lt;/strong&gt;。即便在狭窄的操作空间内，两只手臂也能在毫秒级反馈下实时避障，像人类双手一样默契配合。&lt;/p&gt;&lt;p&gt;OS真正强大的地方，在于赋予了双臂「&lt;strong&gt;柔性作业&lt;/strong&gt;」的能力。在不同调度策略下，双臂可以进行高度非对称的协同，互不干扰地同时制作两款完全不同的饮品。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzBciczibpQIo4ICNU1DGgOicADNkcnkWInqFhU1UXv2tf0b8qP1Hhpib1ow/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527791" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/a7bc3a91-7e27-4973-9841-dc2155952e6d/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;在写字楼早高峰，OS可以同时处理一杯热美式和一杯冰拿铁，将单杯等待时间大幅压缩。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;与此同时，OS还会持续监控设备状态，记录运行数据，提前识别潜在异常，并为下一单完成预准备，等等。正是这套&lt;strong&gt;全局感知与调度能力&lt;/strong&gt;，使影智XBOT即便在无人值守的情况下，也能长期稳定地支撑高并发出杯。&lt;/p&gt;&lt;p&gt;当这套通用底座逐渐成熟，咖啡也就不再是它的唯一应用场景。冰淇淋、奶茶、鸡尾酒、面食，乃至教育、陪伴等更广泛的消费与服务领域，本质上都只是同一套具身智能系统之上的「技能插件」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在此之下，「小脑」承担的是具身智能中最贴近物理世界的一层任务&lt;/strong&gt;：在液体流动、奶泡阻力与原料状态不断变化的真实环境中，依然把口味与视觉表现锁定在同一标准，实现真正意义上的「万杯如一」。&lt;/p&gt;&lt;p&gt;在硬件层面，团队自研双六轴定制工业机械臂，重复定位精度达到&lt;strong&gt;&amp;plusmn;0.03&amp;nbsp;毫米&lt;/strong&gt;；配合高精度运控算法，整体操作精度达到 &lt;strong&gt;0.1毫米&lt;/strong&gt;，远超人类生理极限。&lt;/p&gt;&lt;p&gt;在萃取阶段，粉量误差被压缩至极小范围。糖浆添加与拉花动作被控制在毫米级精度。拉花时，机械臂的移动速度与喷头挤出节奏始终保持同步，一旦感知到液体阻力或流速偏移，系统便即时修正电机输出，确保线条连续、不抖动。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzWJvleF6r0zF1heiaWzgLzaBlh1PSBLibmwSModjXGzOnNWmiaiaSQ1vSBQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=15" data-ratio="0.5134529147982063" data-s="300,640" data-type="gif" data-w="446" type="block" data-backw="446" data-backh="229" data-imgfileid="503527809" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/d7bd9244-a175-4822-8b51-3c76ee607d5b/640.gif" data-order="4" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了教会机器人各种餐饮手艺，比如「审美级」拉花能力，团队搭建了一套顶级红外光学动捕系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz5tXAsIdgocDsKQGGXH8rFEE1twqMr8lIFdmYVWibN2MBxiaMDUHDKVYA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=16" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="320" type="block" data-backw="320" data-backh="180" data-imgfileid="503527808" data-aistatus="1" data-original-style="width: 100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/2f001dea-9b22-48fe-b2da-c37c25f543b0/640.gif" data-order="5" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;75秒内复刻大师级的拉花咖啡技艺。机器人6个小时就能掌握一款新的拉花方式，而人类咖啡师需要6个月。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;通过 11 组高精度摄像头，将顶级咖啡师最细微的手部摆动与力度变化，以毫米级精度完整记录下来，再借助自研算法，将这些大师级技巧翻译为机械臂可执行的控制指令，还实现了跨型号的自动校准。&lt;/p&gt;&lt;p&gt;最终，原本只存在于老师傅经验中的「手感」，被沉淀为可规模复制、稳定复现的工业级能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计美学&amp;nbsp;&amp;times;&amp;nbsp;商业策略：&lt;/strong&gt;&lt;strong&gt;让具身智能真正成为一门生意&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说，技术解决的是「能不能把事做对」，那么工业设计解决的，其实是「这东西能不能被真正用起来」。而后一个问题，才是 2B 商家是否掏出真金白银的分水岭。&lt;/p&gt;&lt;p&gt;商家的目标很简单，用尽可能确定、低摩擦的方式赚钱。因此，影智XBOT是否能够被设计成一台全年无休、稳定运转的生产设备，是否能持续替代人力，把那些琐碎、重复、长期消耗精力的管理问题一并吞掉，远比「看起来有多先进」更重要。&lt;/p&gt;&lt;p&gt;也正因如此，作为少数同时拿下 iF、红点 Best of the Best、IDEA、CMF 等国际设计大奖的团队，影智科技并没有把工业设计当作外观层面的加分项，而是将其视为一套用于降低商业摩擦成本的方法论。&lt;/p&gt;&lt;p&gt;这种思路，最先落到一个极其「现实」的指标上：空间效率。&lt;/p&gt;&lt;p&gt;通过高度紧凑的内部架构，影智XBOT将机械臂、咖啡机、制冰机、印花机等完整模块，压缩进约 1.35㎡&amp;ndash;2.5㎡ 的占地范围内。在寸土寸金的商业环境中，这是直接影响坪效、租金模型，甚至点位是否成立的关键变量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzpSm6nrqtBRSC2Hfj8wSO5l3wjOZh4RJGTrYqyyHjwbkTy9JdFZ2w4A/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527792" data-aistatus="1" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/43343029-3603-4d01-8f93-0686dbfd2f01/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;设计并未止步于「塞得下」，而是与商业运维深度绑定。&lt;/p&gt;&lt;p&gt;通过全模块化架构，将复杂硬件拆解为标准化服务组件，故障模块可在&lt;strong&gt;60&amp;nbsp;分钟内快拆更换&lt;/strong&gt;；配合远程&amp;nbsp;OTA，实现系统、动作路径与配方的一键升级。同时，预留扩展接口，支持未来扩容料仓或接入其他服务设备，让单体机器不被功能锁死，具备持续演进的商业弹性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzWWbiaStOHt2cXoMoT7yLicib6DKwPFQogVaBaz6EsiaW3q5TLklP3eu44g/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527793" data-aistatus="1" data-original-style="width: 100%;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/6c29f053-32dd-44fa-b309-8bd6d1231ebd/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在商业模式上，影智科技并未停留在「卖一台机器」，而是搭建了一套更贴近真实商业世界的三层结构：设备销售、联营模式，以及持续性的增值服务。&lt;/p&gt;&lt;p&gt;其中，「7S」服务体系是一个首创。通过将大量原本由运营者承担的风险前移至平台侧，释放出一个明确信号：咖啡机器人并不是在「与人抢工作」，而是在用技术降低创业门槛，让小生意重新变得可控。它瞄准的，正是那些有创业意愿、却缺乏技术、管理与抗风险能力的中小创业者&amp;mdash;&amp;mdash;过去，这类人往往在高启动成本与不确定风险中迅速出局。&lt;/p&gt;&lt;p&gt;在传统「4S」基础上，「7S」补齐了三项关键能力：用数据运营替代经验判断；通过金融服务，将近 20 万元的初始投入拆解为更轻量的运营方案；通过回购与升级机制，赋予设备流动性与持续迭代空间，明确机器人是一种可持续优化的资产，而非一次性消耗品。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz3uKvDeT5UiceIHZH0anHeOMiambccVGNobOB7ZwZ9vL0VVur8TrEjYeA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=19" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="434" data-imgfileid="503527794" data-aistatus="1" data-original-style="width: 100%;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/d56eb503-0099-4df3-8ee3-cad6237c36bc/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;把具身智能先安放在当下&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说人形机器人代表的是远方，那么影智科技更像是把具身智能先安放在当下。&lt;/p&gt;&lt;p&gt;它代表了另一类具身智能公司：不沉迷概念叙事，也不等待终极形态，而是用当下可行的技术，在复杂、开放、不可控的真实世界中，反复验证可复制的商业模式。&lt;/p&gt;&lt;p&gt;从底层运控算法、工业设计，到产品形态与商业模式，影智科技在一条全链路上不断打磨同一个问题&amp;mdash;&amp;mdash;当具身智能真正进入现实生活，它如何成为一门成立的生意。至少在咖啡这门生意里，这个问题已经有了被市场验证的答案。&lt;/p&gt;&lt;p&gt;也许正是这些并不「人形」、却能持续运转的「中间态」产品，正在把具身智能从想象中的未来，一步步带进现实世界。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>挑战GRPO，英伟达提出GDPO，专攻多奖励优化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:46:19 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/cfd67a67-0432-42e4-ba90-81a9bbc2a059/1768139025502.png" style="width: 700%;" class="fr-fic fr-dib"&gt;GRPO 是促使 DeepSeek-R1 成功的基础技术之一。最近一两年，GRPO 及其变体因其高效性和简洁性，已成为业内广泛采用的强化学习算法。&lt;/p&gt;&lt;p&gt;但随着语言模型能力的不断提升，用户对它们的期待也在发生变化：不仅要回答正确，还要在各种不同场景下表现出符合多样化人类偏好的行为。为此，&lt;strong&gt;强化学习训练流程开始引入多种奖励信号&lt;/strong&gt;，每一种奖励对应一种不同的偏好，用来共同引导模型走向理想的行为模式。&lt;/p&gt;&lt;p&gt;但英伟达的一篇新论文却指出，在进行多奖励优化时，GRPO 可能不是最佳选择。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgwcrGKTl0WsS2udQZMvenV8eygrt1cLLokwBuBYSJH3tVicfTgT9iadrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.675" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527626" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a88d43fc-f1b5-4760-aee3-88bd2aa1cad3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;具体来说，在多奖励优化场景中，GRPO 会将不同的奖励组合归一化为相同的优势值。这会削弱训练信号，降低奖励水平。&lt;/p&gt;&lt;p&gt;为了解决这一问题，他们提出了一种新的策略优化方法 &amp;mdash;&amp;mdash; 组奖励解耦归一化策略优化（&lt;strong&gt;GDPO&lt;/strong&gt;）。该方法通过对各个奖励信号分别进行归一化，避免了不同奖励之间被混合「抹平」，从而更真实地保留它们的相对差异，使多奖励优化更加准确，同时显著提升了训练过程的稳定性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgicB6ib7yL4erYF4OcT2cSeh4lsicRr2iakWg5ev0639RRAnu7blcOuJ5zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4475374732334048" data-s="300,640" data-type="png" data-w="934" type="block" data-imgfileid="503527611" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/31194a14-4194-44b7-b8fc-c4aeb5452ebe/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2601.05242&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/NVlabs/GDPO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目链接：https://nvlabs.github.io/GDPO/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace 链接：https://huggingface.co/papers/2601.05242&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在工具调用、数学推理和代码推理这三类任务上，论文将 GDPO 与 GRPO 进行了对比评测，既考察了正确性指标（如准确率、缺陷比例），也评估了对约束条件的遵守情况（如格式、长度）。结果显示，在所有设置中，GDPO 都稳定地优于 GRPO，验证了其在多奖励强化学习优化中的有效性和良好泛化能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg3xCXUfIia3WTYxvlWSwwZraZPw3M8txypAMR09uz9gJ5z5xAEDpia3HQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527609" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8b340b41-3f7c-4e9f-9565-313505052ed5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;GRPO 有什么问题？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，GRPO 主要被用于优化单一目标的奖励，通常聚焦于准确率。然而，随着模型能力的持续提升，近期研究越来越倾向于同时优化多个奖励 &amp;mdash;&amp;mdash; 例如在准确率之外，还考虑响应长度限制和格式质量，以更好地与人类偏好保持一致。现有的多奖励强化学习方法通常采用一种直接的策略：将所有奖励分量相加，然后直接应用 GRPO 进行优化。&lt;/p&gt;&lt;p&gt;具体而言，对于给定的问答对，行为策略会为每个问题采样一组响应。假设存在 n 个优化目标，则第 j 个响应的聚合奖励被计算为各目标奖励之和。随后，通过对群组级别的聚合奖励进行归一化，得到第 j 个响应的群组相对优势。&lt;/p&gt;&lt;p&gt;作者首先重新审视了这种将 GRPO 直接应用于多奖励强化学习优化的常见做法，并发现了一个此前被忽视的问题：&lt;strong&gt;GRPO 本质上会压缩奖励信号，导致优势估计中的信息损失。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了说明这一点，他们从一个简单的训练场景开始，然后推广到更一般的情况。假设为每个问题生成两个 rollout 来计算群组相对优势，且任务涉及两个二值奖励（取值为 0 或 1）。因此，每个 rollout 的总奖励可取 {0, 1, 2} 中的值。&lt;/p&gt;&lt;p&gt;如图 2 所示，作者列举了一个群组内所有可能的 rollout 奖励组合。尽管在忽略顺序的情况下存在六种不同的组合，但在应用群组级奖励归一化后，只会产生两个唯一的优势组。具体来说，(0,1)、(0,2) 和 (1,2) 会产生相同的归一化优势值 (-0.7071, 0.7071)，而 (0,0)、(1,1) 和 (2,2) 则全部归一化为 (0, 0)。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgDzffSENdCCPL1aCxqws83ZgGXj8C7mlOiaVW2knA858bibgdTCQ8w7bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6861111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527612" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cd8c6cff-5c7d-4fb3-a063-26c4ff7d0072/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这揭示了 GRPO 优势计算在多奖励优化中的一个根本性局限：它过度压缩了丰富的群组级奖励信号。&lt;/p&gt;&lt;p&gt;从直觉上讲，(0,2) 应该比 (0,1) 产生更强的学习信号，因为总奖励为 2 意味着同时满足了两个奖励条件，而奖励为 1 仅对应达成一个。因此，当另一个 rollout 只获得零奖励时，(0,2) 应该产生比 (0,1) 更大的相对优势。这种局限性还可能因优势估计不准确而引入训练不稳定的风险。如图 5 所示，当使用 GRPO 训练时，正确率奖励分数在约 400 个训练步后开始下降，表明出现了部分训练坍塌。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgDrmib8L0ZzNt3ItJ1YibjsZb07xvDia25OcqaB6EyOL3dVc6ojiawB1IPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.4222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527613" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/381d8ad6-c11d-46ed-8ea6-9d0e127f152f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近期，Dr.GRPO 和 DeepSeek-v3.2 采用了 GRPO 的一个变体，移除了标准差归一化项，使得优势直接等于原始奖励减去均值。尽管这些工作引入此修改是为了缓解问题级别的难度偏差，但乍看之下，这一改变似乎也能解决上述问题。具体而言，移除标准差归一化确实在一定程度上缓解了问题：(0,1) 和 (0,2) 现在分别产生 (-0.5, 0.5) 和 (-1.0, 1.0) 的不同优势值。&lt;/p&gt;&lt;p&gt;然而，当将此设置推广到更多 rollout（保持奖励数量固定）时，如图 3 所示，作者观察到这种修复方法相比标准 GRPO 仅略微增加了不同优势组的数量。在固定 rollout 数量为 4、逐步增加奖励数量的设置下，也观察到类似趋势 &amp;mdash;&amp;mdash; 不同优势组的数量仅有适度改善。作者还在第 4.1.1 节中实证检验了移除标准差归一化项的效果，发现这一修改并未带来更好的收敛性或更优的下游评估表现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKglJ4JwGjPiaSjTT8mOPFeeMpu7hu8fic8JkXcWsefkxxPmmrf5dwvzVlQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527614" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1912da0b-533f-43e5-9a3b-d8ffd2ebb8d4/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;GDPO是怎么做的？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了克服上述挑战，作者提出了群组奖励解耦归一化策略优化（GDPO），这是一种旨在更好地保持不同奖励组合之间区分度、并更准确地在最终优势中捕捉其相对差异的方法。&lt;/p&gt;&lt;p&gt;与 GRPO 直接对聚合奖励和进行群组级归一化不同，GDPO 通过在聚合之前对每个奖励分别进行群组级归一化来解耦这一过程。具体而言，GDPO 不是先将所有 n 个奖励相加再进行群组级归一化得到总优势，而是为第 i 个问题的第 j 个 rollout 的每个奖励分别计算归一化优势，如下所示：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgBSBr2U8IxTKhbaYZ5q4VavIkY4wNhnIAy4elgdeLyqzl9R5MiaX6icSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.10185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527615" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b40c08db-e8df-4aea-b636-b7ff8290c6fa/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;用于策略更新的总体优势通过以下方式获得：首先将所有目标的归一化优势相加，然后对多奖励优势之和应用批次级优势归一化。这确保了最终优势的数值范围保持稳定，不会随着额外奖励的引入而增长。从实证角度，作者还发现这一归一化步骤能够改善训练稳定性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通过分离每个奖励的归一化，GDPO 缓解了 GRPO 优势估计中存在的信息损失问题&lt;/strong&gt;，如图 2 所示。从图中可以看到，当采用 GRPO 时，不同的奖励组合（如 (0,2) 和 (0,1)）会导致相同的归一化优势，从而掩盖了它们之间的细微差异。相比之下，GDPO 通过为每种组合分配不同的优势值来保留这些细粒度差异。&lt;/p&gt;&lt;p&gt;作者通过在两种实验设置下比较 GDPO、GRPO 和「无标准差 GRPO」产生的不同优势组数量，进一步量化了 GDPO 的有效性，如图 3 所示。在两个奖励、rollout 数量变化的场景中，GDPO 始终产生显著更多的不同优势组，且随着 rollout 数量增加，差距不断扩大。另一方面，当固定 rollout 数量为 4 并增加奖励数量时，也呈现出类似的模式 &amp;mdash;&amp;mdash;GDPO 随着目标数量增长表现出逐步增大的优势粒度。这表明论文所提出的解耦归一化方法在所有强化学习设置中都能有效增加不同优势组的数量，从而实现更精确的优势估计。&lt;/p&gt;&lt;p&gt;除了这些理论改进之外，作者还观察到使用 GDPO 能够持续产生更稳定的训练曲线和更好的收敛性。例如，在工具调用任务中，GDPO 在格式奖励和正确率奖励上都实现了更好的收敛，如图 4（见实验部分）所示。GDPO 还消除了 GRPO 在数学推理任务中观察到的训练坍塌问题，如图 5（见实验部分）所示，使用 GDPO 训练的模型在整个训练过程中持续改善正确率奖励分数。实验部分的更多实证结果进一步证实了 GDPO 在广泛的下游任务上实现更强目标偏好对齐的能力。&lt;/p&gt;&lt;p&gt;到目前为止，论文假设所有目标具有同等重要性。然而在实际应用中，这一假设并不总是成立。在论文中，作者系统地概述了如何调整与不同目标相关的奖励权重，或修改奖励函数以强制优先考虑更重要的目标。论文还讨论了当底层奖励在难度上存在显著差异时，这两种设计选择的不同行为表现。具体内容可参见论文第三章。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验部分，作者首先在工具调用任务上评估 GDPO 与 GRPO 的效果，然后在数学推理任务上进行比较，最后将优化奖励数量扩展到三个，在代码推理任务上进行对比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;工具调用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从图 4 的训练曲线可以看到，GDPO 在所有运行中都能在格式奖励和正确率奖励上收敛到更高的值。尽管 GDPO 在格式奖励收敛所需步数上表现出更大的方差，但最终达到的格式合规性优于 GRPO。对于正确率奖励，GDPO 在早期阶段表现出更快的改善，并在后期达到比 GRPO 基线更高的奖励分数。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg1ODCeFd1K9khH1KtlXz1V9KSQskF1ew1CrpmfbtuHDRQ9rAk8992cw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527616" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ae9a14a4-fba6-4211-ba13-5f5b79e0eb8c/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在表 1 的 BFCL-v3 评估中，GDPO 也持续提升了平均工具调用准确率和格式正确率。对于 Qwen2.5-Instruct-1.5B 的训练，GDPO 在 Live/non-Live 任务上分别取得了近 5% 和 3% 的提升，在整体平均准确率上提高了约 2.7%，在正确格式比例上提高了 4% 以上。3B 模型上也观察到类似的改进。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgVC7Rfuu3au6GeRJxwmDEQt2NK0NDLwU8pcf0qJ4MLMm5GzOdIDg78g/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.27870370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527617" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0c42a132-0137-41bd-9311-49cf0e32ffab/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;关于移除标准差归一化项的效果：从图 4 可以观察到，虽然「无标准差 GRPO」收敛到与 GDPO 相似且高于标准 GRPO 的正确率奖励，但它在格式奖励上完全失败。这导致在 BFCL-v3 上的正确格式比例为 0%（见表 2），表明模型未能学习所需的输出结构。这说明简单地移除标准差归一化项以增加优势多样性可能会给训练引入不稳定性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgE9N44nkN0gP8O4wvqOKnHribtqq3EmISlt4XgR82g1R9ibXhHhrDBDNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.2222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527618" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/91e35c43-fc55-41a9-add1-2136498c0fd3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;数学推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从图 5 中 DeepSeek-R1-1.5B 的训练曲线可以看到，模型倾向于最大化更容易的奖励。在本例中，长度奖励更容易优化，GRPO 和 GDPO 都在大约前 100 个训练步内达到满分长度奖励。长度奖励的快速上升伴随着正确率奖励的早期下降，表明这两个奖励存在竞争关系。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgW1B5AZgiaLzsiaSiaREdrTSP3O5FFTQO62M7ia1qySvWer1QpD8xn0eiaibg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527619" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d34ae5e0-1639-4b32-8f35-451d34c37507/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;然而，从正确率奖励轨迹来看，GDPO 比 GRPO 更有效地恢复了正确率奖励。作者还观察到 GRPO 训练在 400 步后开始不稳定，正确率奖励分数逐渐下降，而 GDPO 则继续改善。此外，尽管两者都保持了近乎完美的长度分数，但 GRPO 的最大响应长度在约 400 步后开始急剧增加，而 GDPO 的最大响应长度则持续下降。图 9 和图 10 中 DeepSeek-R1-7B 和 Qwen3-4B-Instruct 的训练曲线也显示出类似的观察结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHc3TPnEmTj8xZXylahFFnI39A328TiabmoQ4KLicq2apibhWlWbCQPTNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527620" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/f3f8f78d-29d5-4fc5-9749-009a2752c25c/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;表 3 的基准测试结果表明，GDPO 训练的模型不仅在推理效率上比原始模型取得显著提升（AIME 上超长比例降低高达 80%），而且在大多数任务上也取得了更高的准确率。对于 DeepSeek-R1-1.5B，GDPO 在所有基准测试上都优于 GRPO，在 MATH、AIME 和 Olympiad 上分别取得了 2.6%/6.7%/2.3% 的准确率提升。DeepSeek-R1-7B 和 Qwen3-4B-Instruct 也呈现类似趋势，GDPO 在更具挑战性的 AIME 基准测试上将准确率提高了近 3%，同时将超长率分别降低至 0.2% 和 0.1%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgLFZOABdEjpLYW6fu01EH525xWHZZcwT6zwmLDTaM8gfaECiala5opvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527621" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/d1ef9794-5d6d-4fa2-878a-9b09df39bd32/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;代码推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者在代码推理任务上检验 GDPO 在优化两个以上奖励时是否仍然优于 GRPO。如表 5 所示，在双奖励设置下，GDPO 在所有任务上都提升了通过率，同时保持相似的超长比例。例如，GDPO 在 Codecontests 上将通过率提高了 2.6%，而超长比例仅增加 0.1%；在 Taco 上取得了 3.3% 的通过率提升，同时将超长违规降低了 1%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgYfn0EBn7lBibBic40Q3ibYdGHzIibvpPXxKHsetk7pbj3WciaFEaZkhueEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527622" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/3c57865f-037b-4def-8e3b-2a1a1047bb24/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在三奖励设置下也呈现类似模式，GDPO 在所有目标上都实现了更有利的平衡，在保持与 GRPO 相似通过率的同时，显著降低了超长比例和 bug 比例。&lt;/p&gt;&lt;p&gt;总体而言，这些结果表明 GDPO 在奖励信号数量增加时仍然有效，在双奖励和三奖励配置中都始终比 GRPO 实现更优的跨目标权衡。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>联邦学习不再安全？港大TPAMI新作：深挖梯度反转攻击的内幕</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:42:06 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/4fe10834-5f13-4fbc-8eac-573aab0b10c4/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;本文第一作者郭鹏鑫，香港大学博士生，研究方向是联邦学习、大模型微调等。本文共同第一作者王润熙，香港大学硕士生，研究方法是联邦学习、隐私保护等。本文通讯作者屈靓琼，香港大学助理教授，研究方向包含 AI for Healthcare、AI for Science、联邦学习等 (个人主页：https://liangqiong.github.io/)。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;联邦学习（Federated Learning, FL）本是隐私保护的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;救星」，却可能因梯度反转攻击（Gradient Inversion Attacks, GIA）而导致防线失守。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;近日，&lt;strong&gt;香港大学、香港科技大学（广州）、南方科技大学、斯坦福大学、加州大学圣塔克鲁兹分校&lt;/strong&gt;的研究团队合作，在人工智能顶级期刊 &lt;strong&gt;IEEE TPAMI&lt;/strong&gt; 上发表重磅工作，对 GIA 进行了全方位的分类、理论分析与实验评测，并提出了切实可行的防御指南。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg7MK4kcIa1ntiauRiadcuEzX19Mica2TQibzDwkj3aPZd4dOUNlqNan5MRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527517" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d2f645f1-94dc-4c87-8ff5-ad982cdfb949/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题： Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址： https://ieeexplore.ieee.org/document/11311346&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页： https://pengxin-guo.github.io/FLPrivacy/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;01 背景：联邦学习真的安全吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;联邦学习（FL）作为一种隐私保护的协同训练范式，允许客户端在不共享原始数据的情况下共同训练模型。然而，近年来的研究表明，&lt;strong&gt;「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;不共享数据」并不等于 「&lt;/span&gt;&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;绝对安全」&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;攻击者可以通过&lt;strong&gt;梯度反转攻击（GIA）&lt;/strong&gt;，仅凭共享的梯度信息就能重建出客户端的私有训练数据（如人脸图像、医疗记录等）。尽管学术界提出了许多 GIA 方法，但一直缺乏对这些方法的系统性分类、深入的理论分析以及在大规模基准上的公平评测。&lt;/p&gt;&lt;p&gt;为了填补这一空白，本研究对 GIA 进行了&lt;strong&gt;抽丝剥茧般的深度剖析&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgdQP8bVgdaOkLHAfmviaXicZDBO9W1UYWcaRcQAIcTEUEW9LsEuPfVwdw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5694444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527518" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dd1bef59-0933-4313-b64d-48a80c4b6216/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;02 方法分类：GIA 的三大门派&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队首先对现有的 GIA 方法进行了系统性梳理，将其归纳为三大类：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 基于优化的攻击 (OP-GIA)：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：通过迭代优化虚拟数据，使其产生的梯度与真实梯度之间的距离最小化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;代表作&lt;/strong&gt;：DLG、Inverting Gradients、GradInversion 等。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 基于生成的攻击 (GEN-GIA)：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：利用预训练的生成模型（GAN 或 Diffusion Model）作为先验，来生成近似的输入数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;细分&lt;/strong&gt;：优化隐向量 z、优化生成器参数 W、或训练逆向生成模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 基于分析的攻击 (ANA-GIA)：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：利用全连接层或卷积层的线性特性，通过解析解（Closed-form）直接恢复输入数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;：通常需要恶意的服务器修改模型架构或参数。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;03 理论突破：误差边界与梯度相似性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于以往的经验性研究，本文在理论层面做出了重要贡献：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Theorem 1（误差边界分析）&lt;/strong&gt;：首次从理论上证明了 OP-GIA 的重建误差与&lt;strong&gt; Batch Size（批量大小）和图像分辨率&lt;/strong&gt;的平方根呈线性关系。这意味着，Batch Size 越大、分辨率越高，攻击难度越大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgPgI4bCn3MruUicmVyMBVXBribcLMicHIpNXG3Alu4ecL0RLMLFDfaicicXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527520" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9311e11a-9e23-4f01-b579-08c3ddd9894c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Proposition 1（梯度相似性命题）&lt;/strong&gt;：揭示了模型训练状态对攻击的影响。如果不同数据的梯度越相似（例如在模型训练后期），攻击恢复数据的难度就越大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgylZpX9tBEXyEk88sFashdFJLFSibf1p8BEwxkE1o4CCqAtLB3cx9Atw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527521" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/42be48fa-b8f8-467b-a54b-f77113452334/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;04 实验发现：谁是真正的威胁？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 CIFAR-10/100、ImageNet、CelebA 等数据集上，针对不同攻击类型进行了广泛的实验（涵盖 ResNet、ViT 以及 LoRA 微调场景）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgKv6WzUg3YTutnINde067VibicO7U7WMzdyic7GDLMkmyxOBDAqqkf7YsQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3194444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527522" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2b91461c-5e83-40ab-92c5-7e13e3413843/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;关键结论（Takeaways）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;OP-GIA 最实用，但受限多&lt;/strong&gt;：它是最实用的攻击设置（无额外依赖），但效果受限于 Batch Size 和分辨率。且在&amp;nbsp;&lt;strong&gt;Practical FedAvg&lt;/strong&gt;（多步本地训练）场景下，其威胁被大幅削弱。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;GEN-GIA 依赖重，威胁小&lt;/strong&gt;：虽然能生成高质量图像，但严重依赖预训练生成器、辅助数据集或特定的激活函数（如 Sigmoid）。如果目标模型不用 Sigmoid，很多 GEN-GIA 方法会直接失效 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;ANA-GIA 效果好，易暴露&lt;/strong&gt;：通过修改模型架构或参数，ANA-GIA 可以实现精准的数据恢复。但这种「做手脚」的行为非常容易被客户端检测到，因此在实际中难以得逞 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;PEFT (LoRA) 场景下的新发现&lt;/strong&gt;：在利用 LoRA 微调大模型时，攻击者可以恢复低分辨率图像，但在高分辨率图像上往往失败。且预训练模型越小，隐私泄露风险越低 。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg4D6OEAjdsnliajkxXqPI5ibfRI7TpBfFbhsbOXTkjnAXdhGJe4L7m3Xg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6111111111111112" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527546" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/fe9aa2a1-1c9c-410e-b4c1-0af944eb538f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;05 防御指南：三步走策略&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于上述深入分析，作者为联邦学习系统的设计者提出了一套「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;三阶段防御流水线」，无需引入复杂的加密手段即可有效提升安全性 ：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 网络设计阶段：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;拒绝 Sigmoid&lt;/strong&gt;：避免使用 Sigmoid 激活函数（易被 GEN-GIA 利用）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;增加复杂度&lt;/strong&gt;：采用更复杂的网络架构，增加优化难度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 训练协议阶段：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;增大 Batch Size&lt;/strong&gt;：根据理论分析，大 Batch 能有效混淆梯度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多步本地训练&lt;/strong&gt;：采用 Practical FedAvg，增加本地训练轮数，破坏梯度的直接对应关系。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 客户端校验阶段：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型检查&lt;/strong&gt;：客户端在接收服务器下发的模型时，应简单校验模型架构和参数，防止被植入恶意模块（防御 ANA-GIA）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;06 总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项发表于 TPAMI 的工作不仅是对现有梯度反转攻击的一次全面体检，更是一份实用的联邦学习安全避坑指南。它告诉我们：虽然隐私泄露的风险真实存在，但通过合理的设计和协议规范，我们完全可以将风险控制在最低水平。&lt;/p&gt;&lt;p&gt;更多细节，欢迎查阅原论文！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>在谷歌深耕14年，华人研究员创立视觉AI公司，计划融资5000万美元</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:37:48 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/616f5b85-a9cf-4ed4-b8ad-700ae60b5143/1768138551245.png" style="width: 700%;" class="fr-fic fr-dib"&gt;最新消息，两名华人前谷歌资深研究员正创立一家全新的视觉 AI 公司，致力于打造能够同时理解和处理文本、图像、视频与音频的前沿 AI 模型。&lt;/p&gt;&lt;p&gt;这两位华人是：在 Google DeepMind 工作 14 年后离职的资深 AI 研究员 &lt;strong&gt;Andrew Dai（戴明博）&lt;/strong&gt;，以及前苹果 AI 研究科学家，曾在谷歌研究部门工作的 &lt;strong&gt;Yinfei Yang （杨寅飞）&lt;/strong&gt;。&lt;/p&gt;&lt;p data-pm-slice="2 2 []"&gt;戴明博表示，这家名为 &lt;strong&gt;Elorian&lt;/strong&gt; 的新公司目前正在与投资人洽谈，计划完成一轮约 &lt;strong&gt;5000 万美元的种子融资&lt;/strong&gt;。知情人士透露，由前 CRV 普通合伙人 Max Gazor 于去年 10 月创立的风投机构 Striker Venture Partners 正在洽谈领投该轮融资。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzxY6hQLUU8rWkKu9b5RsuKMcVMCq7cf4a0fTfibBFF7zVN8wZhA11YLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.562037037037037" data-type="png" data-w="1080" data-width="1800" data-height="1012" data-imgfileid="503527786" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/885220f9-7441-43ed-8ff9-72335808b205/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;戴明博本科毕业于英国剑桥大学计算机科学专业，随后在爱丁堡大学获得机器学习方向博士学位。在攻读博士期间，他曾两次在谷歌进行软件工程实习，博士毕业后&lt;strong&gt;于 2012 年正式加入谷歌，开启了长达 14 年的职业生涯&lt;/strong&gt;，在公司内部从技术研发逐步成长为核心科研管理者。&lt;/p&gt;&lt;p&gt;在 Google DeepMind，他担任&lt;strong&gt;首席研究科学家 / 主任级别研究管理职务&lt;/strong&gt;，负责领导与 Gemini 大型 AI 模型研发相关的数据团队工作，这一项目是 DeepMind 和 Google 在多模态大模型方向的重要战略成果。&lt;/p&gt;&lt;p&gt;作为深度学习与自然语言处理领域的资深研究人员，戴明博不仅在工业级 AI 项目中扮演关键角色，还与业内其他顶尖研究者合作发表过多篇学术论文，积累了丰富的科研和工程融合经验。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzJUcCgsdygsvD3ZOQoibgib2u5bNRia7rNrIiac96EKWzfPnITyAcdXJrNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.3333333333333333" data-type="png" data-w="1080" data-width="1195" data-height="1593" data-imgfileid="503527788" data-aistatus="1" data-original-style="width: 223px;height: 297px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e37fc732-0ac8-49cb-ae16-e00a67521025/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;杨寅飞是一位资深的人工智能研究科学家，曾在&lt;strong&gt;&amp;nbsp;Apple AI/ML 担任研究科学家/多模态负责人&lt;/strong&gt;，主要从事视觉与语言基础模型的研究与开发。&lt;/p&gt;&lt;p&gt;在加入苹果之前，他也&lt;strong&gt;曾在 Google Research 担任研究科学家&lt;/strong&gt;，在自然语言处理、语义检索、多语言表示学习与多模态表示学习等方向有深入的研究与实践。 &amp;nbsp;他还在 Amazon 和 Redfin 担任机器学习与计算机视觉相关的软件工程师/数据科学工程师，积累了丰富的工业研发经验。&lt;/p&gt;&lt;p&gt;他在视觉&amp;ndash;语言联合表示和大规模多模态学习方面具有重要贡献，其代表性研究成果《Scaling up visual and vision-language representation learning with noisy text supervision》推动了多模态表示学习的发展。&lt;/p&gt;&lt;p&gt;值得注意的是，戴明博与杨殷飞目前都已在 LinkedIn 上将公司状态更新为「隐身（stealth）」，其中戴明博的资料显示其担任 CEO。就连戴明博的社交媒体上都标注了「隐身模式」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzjQLUDN8DtlOC2kMSM1iaqJYp58t6qVvOibHH1Ms7kEkMlJDiahGnYJlVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7212962962962963" data-type="png" data-w="1080" data-width="1162" data-height="838" data-imgfileid="503527790" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/170c5e0d-4e80-4cc3-b5bb-a8d0dd5cf192/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在上周六的一次电话采访中，戴明博表示，Elorian 的核心目标是构建能够通过&lt;strong&gt;同时处理图像、视频与音频，对现实世界进行视觉理解与分析的多模态 AI 模型&lt;/strong&gt;。虽然机器人也是其潜在应用方向之一，但公司还设想了更多应用场景，暂未对外披露具体细节。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theinformation.com/articles/former-google-apple-researchers-raising-50-million-new-visual-ai-startup?rc=jn0pp4&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://sites.google.com/site/yinfeiyang/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.linkedin.com/in/andrewdai&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>无需人工标注，轻量级模型运动理解媲美72B模型，英伟达、MIT等联合推出FoundationMotion</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:31:48 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8d35ccec-e2f7-470a-941d-38dbe31b5867/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当前的视频大模型发展迅速，但在面对复杂的空间移动和物理规律时，依然 &amp;ldquo;看不懂&amp;rdquo; 物体如何运动。&lt;/p&gt;&lt;p&gt;它们或许能描述视频中发生了什么，但如果你问它：&amp;ldquo;红色的车是在蓝色车转弯之前还是之后通过路口的？&amp;rdquo; 或者 &amp;ldquo;那个皮球的抛物线轨迹最高点在哪里？&amp;rdquo;，很多模型就开始 &amp;ldquo;胡言乱语&amp;rdquo; 了。&lt;/p&gt;&lt;p&gt;究其根本，在于高质量运动数据的极度匮乏。现有的数据集要么规模太小，要么依赖昂贵的人工标注，难以支撑模型去学习真实世界中细粒度的物理运动。&lt;/p&gt;&lt;p&gt;针对这一痛点，来自 &lt;strong&gt;MIT、NVIDIA、UC Berkeley&lt;/strong&gt; 等机构的研究者提出了 &lt;strong&gt;FoundationMotion&lt;/strong&gt;：一套完全不依赖人工标注的自动化数据管线。&lt;/p&gt;&lt;p&gt;令人惊讶的是，仅靠这套管线生成的数据微调后，&lt;strong&gt;15B 参数的视频模型竟在运动理解任务上，超越了 Gemini-2.5 Flash 以及 72B 参数的开源大模型：NVILA-Video-15B: 90.6% on AV-Car benchmark， Gemini-2.5-Flash: 84.1%，Qwen-2.5-VL-72B: 83.3%&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg9FJOic4UUMkkM12d1FdGJjJpOIibe6NzPcUxotsyXraOMoL9ckdM1A9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.26481481481481484" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527509" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8afb5876-6856-4cfb-afab-2f0a67d8ffd8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;项目主页： https://yulugan.com/projects/FoundationMotion.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文： https://arxiv.org/abs/2512.10927&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码： https://github.com/Wolfv0/FoundationMotion&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;视频模型的 &amp;ldquo;物理盲&amp;rdquo; 危机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2024 年至今，被认为是视频生成模型的爆发期。从 OpenAI 的 Sora 到各类国产模型，AI 已经能够生成极其逼真的动态画面。然而，在华丽的像素背后，一个长期被忽视的问题逐渐暴露出来：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这些模型并不真正理解物体的运动。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;例如，在测试中研究人员发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;它们可以生成高速行驶的赛车，却难以判断刹车究竟是发生在碰撞之前还是之后；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;它们能描绘复杂的街景，却常常搞错行人的移动方向与相对位置关系。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;比如我们上传一段一辆汽车在夜间行驶，变道，超过了前方车辆的视频给 Gemini 3 Pro Preview，问 &amp;ldquo;What is the primary driving behavior demonstrated by the ego vehicle in the video?&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgZQ8JJuia79Dnsgc4CGsuq5nzrFRVDCcEwfJlzGakkHIY0ibibcJNz5ibbA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.1875" data-s="300,640" data-type="gif" data-w="960" type="block" data-imgfileid="503527512" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a8ab3d3b-efc4-4d34-b2b3-42ae04948d4c/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgDSuH96icVDwLzq52SVFdwaHYoLh6Ls605H9XfWITMl9GfBFLGzKNWGg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="1.038888888888889" data-s="300,640" data-type="gif" data-w="720" type="block" data-imgfileid="503527513" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a3625f8d-dc72-41a5-b1cf-71b1e55c10ad/640.gif" data-order="1" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Gemini 3 Pro Preview 的回答是这辆车正在它的车道上行驶，完全没有理解这个视频最主要的运动：变道与超车。&lt;/p&gt;&lt;p&gt;正如心理学家 Barbara Tversky 在《Mind in Motion》中所指出的：&lt;strong&gt;空间与运动是人类理解世界的基础&lt;/strong&gt;。 而这一能力，恰恰是当前视频模型最薄弱的部分。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgQtwDuATBrrGtuFhULqX5jZzexicWSAyAntVG7qjcXhhlicmlWwePxHicQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527514" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8831c544-d45b-47b6-948c-0d4a0a969d3f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;问题的根源在于&lt;strong&gt;数据&lt;/strong&gt;。现有视频数据要么只包含静态描述（如 &amp;ldquo;一只狗在草地上&amp;rdquo;），要么高度依赖昂贵、难以扩展的人工标注，使得大规模、细粒度的 &amp;ldquo;运动理解&amp;rdquo; 数据几乎无法获得。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;FoundationMotion &amp;nbsp;一座全自动的 &amp;ldquo;运动数据工厂&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决这一瓶颈，研究团队提出了 FoundationMotion&amp;mdash;&amp;mdash; &lt;strong&gt;一套端到端、无需人工参与的自动化数据生成系统&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;它的工作流程可以被形象地拆解为四步：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgibRYMd86iceZFP2LQX7DN9icib1BE4neJBJiaJfk1T60K9ensZgNewRfyEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.4740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527515" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e95df3aa-8fcb-44d6-9439-9f0b502cb05e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;1 &amp;amp; 2. 预处理 &amp;amp; 先把 &amp;ldquo;运动&amp;rdquo; 精确地抓出来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先，使用成熟的目标检测与跟踪模型，对视频进行逐帧分析，将人、车辆、手部、机械臂等关键物体转化为连续的&lt;strong&gt;时空轨迹（Trajectories）&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;输入： 任何视频。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出： 每个物体在视频中的精确运动坐标。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 把轨迹 &amp;ldquo;讲给&amp;rdquo; 语言模型听&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;仅有数字坐标对语言模型来说过于抽象，FoundationMotion 采用了&lt;strong&gt;多模态融合策略&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;将轨迹转化为结构化的文本描述；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;同时将视频帧与轨迹信息作为 Prompt 输入。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这相当于为模型提供了一份 &amp;ldquo;运动说明书&amp;rdquo;，让它不仅看到画面，还能结合坐标理解物体究竟是如何移动的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 让模型生成标注与问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队利用 GPT-4o-mini，在轨迹与视频的基础上，自动生成两类高质量数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;精细化运动描述：包含速度变化、方向、终止位置等细节；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多维度运动理解问答：覆盖动作识别、时序关系、动作 - 物体关联、空间位置以及重复计数等关键能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终，团队基于 InternVid 构建了约 &lt;strong&gt;50 万&lt;/strong&gt;条高质量运动理解数据，形成了 FoundationMotion 数据集。&lt;/p&gt;&lt;p&gt;数据样例：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg3BJOlObT4JK2d73rzpC6bvD4nomyqW1b0wPrcFoI4BZVBUaP2dqCbw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.573093220338983" data-s="300,640" data-type="gif" data-w="944" type="block" data-imgfileid="503527516" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/79001193-014c-4bee-84d3-b288c234804a/640.gif" data-order="2" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;小模型，击败大模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验环节，研究人员使用 FoundationMotion 生成的数据微调了多个开源视频模型，包括 NVILA-Video-15B 与 Qwen2.5-7B。&lt;/p&gt;&lt;p&gt;结果显示，高质量数据带来的提升是巨大的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;越级挑战： 微调后的 7B/15B 模型在多个运动理解基准上，超越了 Gemini-2.5 Flash 与 Qwen2.5-VL-72B。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;纯数据驱动： 这一提升不依赖额外的模型结构设计或复杂的推理策略，完全归功于数据的质量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;强泛化性： 在自动驾驶、机器人操作、日常活动等不同领域均具备良好表现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无损通用能力： 在增强物理感知的同时，并未损害模型原本的通用视频理解能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;通向 &amp;ldquo;物理 AI&amp;rdquo; 的关键一步&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FoundationMotion 的意义远不止于刷榜。&lt;/p&gt;&lt;p&gt;在自动驾驶与机器人领域，&amp;ldquo;理解物体如何运动&amp;rdquo; 直接关系到系统的安全与决策能力。&lt;/p&gt;&lt;p&gt;FoundationMotion 提供了一条低成本、可扩展的路径，让 AI 能够通过观看海量视频，逐步建立对物理世界的直觉。这套管线未来可广泛用于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;视觉语言模型（VLM）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;视觉 - 语言 - 动作模型（VLA）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;世界模型（World Models）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这被认为是构建真正的具身智能（Embodied AI）的基础设施。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，唐杰、杨强、杨植麟、林俊旸和刚回国的姚顺雨坐一起都聊了啥？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 23:27:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ee8a5b00-e8eb-4362-a1d3-d1eded846c24/1768058508308.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2026 年 AI 的进化，势必会超过我们的想象。&lt;/p&gt;&lt;p&gt;1 月 10 日下午，在由清华大学基础模型北京市重点实验室、智谱 AI 发起的 AGI-Next 前沿峰会上，汇聚了刚刚上市两天的智谱、领跑独角兽月之暗面、全球开源大模型顶流 Qwen 的创始人、CEO 和负责人。&lt;/p&gt;&lt;p&gt;智谱 AI 的唐杰、月之暗面的杨植麟、阿里云通义千问的林俊旸等正处于聚光灯下的中国大模型掌舵者，以及张钹院士、杨强等学界泰斗罕见地同台亮相。&lt;/p&gt;&lt;p&gt;刚刚履新腾讯 AI 首席科学家、曾以「思维树」（Tree of Thoughts）和《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650965529&amp;idx=1&amp;sn=eb553785af462d8fdba2793990754823&amp;scene=21#wechat_redirect" target="_blank"&gt;AI 下半场&lt;/a&gt;》闻名的姚顺雨，也在此迎来了回国后的对外首秀。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagIZwRXaw61XM86tGgFa3kox4yTCH5e3bSG4BgfHIQ3hlhI59UaFwibvA/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="341" data-imgfileid="503527676" data-ratio="0.4546296296296296" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagIZwRXaw61XM86tGgFa3kox4yTCH5e3bSG4BgfHIQ3hlhI59UaFwibvA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5c589d13-5933-48da-ae2c-084b72d7931f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;本周国内 AI 创业公司接连上市，DeepSeek 又刚刚曝出即将发布全新一代大模型，人工智能的热度还在持续升温，但另一方面，AI 技术似乎来到了一个临界点：一边是大规模预训练 (Pre-training)、强化学习对齐（Alignment/RLHF）等范式带来的爆发期即将结束，另一方面，新的提升范式似乎还未启动。&lt;/p&gt;&lt;p&gt;如果说 2025 年的大模型技术以一种近乎「暴力美学」的方式撕开了 AGI 大门的一角，那么 2026 年开年这场峰会，就像是一次冷静后的复盘与再出发。&lt;/p&gt;&lt;p&gt;无论是演讲时的独白，还是圆桌上的激辩，几位掌舵者目及的方向不约而同：从「聊天机器人」进化为「干活的智能体」；从单纯堆砌算力转向追求 AI「自我学习」的新探索；让 AI 从预测下一个词，变为真正理解并改变物理世界的智能生命体。&lt;/p&gt;&lt;p&gt;但与此同时，他们给出的解法却各不相同。&lt;/p&gt;&lt;p&gt;这场峰会传递出一个清晰的信号：单纯的参数竞赛已成过去，前沿公司和团队正在扎堆进入新航路。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;唐杰：让机器像人一样「思考」与「做梦」&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagDzNicIbnzr4IMhZJ1LOrBe2MVOFCNhsF0pY0sAmrGDKLiagVduQic4g3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527677" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/025979a6-a388-4f1d-949a-a267e19c03bd/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为学术界与产业界的双重代表，清华大学计算机系教授、智谱创立发起人兼首席科学家唐杰教授将大模型的进化比作人类认知的成长过程。他回顾了 AI 的发展历程，认为&lt;strong&gt;我们正在从「系统 1」（基于直觉的快思考）向「系统 2」（基于逻辑的慢思考）进化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;唐杰抛出了一个引人深思的观点：「Scaling 可能是一个最轻松的办法，是我们人类偷懒的办法。」他认为，单纯依靠堆砌数据和算力的已知 Scaling 路径虽然有效，但更本质的方法可能是找到新的知识压缩方式，探索未知的 Scaling 范式。&lt;/p&gt;&lt;p&gt;为此，他重点介绍了 &lt;strong&gt;RLVR&lt;/strong&gt;（Reinforcement Learning with Verifiable Rewards，可验证奖励的强化学习）。在数学、编程等「可验证」的场景下，模型可以通过自我探索突飞猛进。智谱 AI 最新的 GLM-4.7 正是这一思路的产物，它在 Coding 和 Agent 任务上展现了惊人的能力。但唐杰也坦承，未来的挑战在于如何将这种能力扩展到「半自动验证」甚至「不可验证」的广阔领域。&lt;/p&gt;&lt;p&gt;在移动端 Agent 方面，唐杰展示了 &lt;strong&gt;AutoGLM&lt;/strong&gt; 的野心。未来的 AI 不应该只是一个聊天框，而应该是一个渗透到设备底层的幽灵。他们采用了一种「API + GUI」的混合模式：对 AI 友好的环节走 API，对人类友好的环节则模拟人手点击 GUI（图形用户界面）。演示中，AutoGLM 可以在手机后台静默执行长达 40 步的复杂操作 &amp;mdash;&amp;mdash; 从查询攻略、打开地图、比价、到最终下单订票，一气呵成。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagYWic0sPPz0Jtyv0NYiayYIyZGWCcIHXeK3ARJoACo7JtzsAPUNLwIy9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527679" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/483a3847-dfd2-464d-ae8e-b6e70c57fb30/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;演讲中一大迷人的部分在于唐杰对「&lt;strong&gt;机器睡眠&lt;/strong&gt;」的构想。他认为人脑之所以聪明，是因为有睡眠机制，在无意识中整理记忆、进行自学习。未来的 AI 也应该具备类似的机制，通过「自反思」和「自学习」来消化数据，而不仅仅是被动地接受训练。他强调，如果没有这种机制，人类的长期记忆可能只是一堆噪音，无法转化为真正的知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagkXcf1DEZbicwIMkvp1B94UUrqialZxfIXvLgQy5pPibrJwFrSU1XjsbxA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527680" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/092f552f-337f-4512-a6c6-668787731901/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管中国开源模型在 2025 年席卷了各大榜单，前五名几乎被中国模型包揽，但唐杰依然保持着清醒。他提醒道，我们是在开源的游乐场里玩得很高兴，但与顶尖闭源模型的实际差距可能并没有想象中那么小。只有去探索那些未知的 Scaling 范式，才能真正缩小这一差距。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;杨植麟：智能是不可替代的 Token，我们在寻找最美的 Loss 曲线&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag3xQ4xkJGCjPh0jgrPiaT8kf1zmpB7BdGn3WJSrx8VG6sk5Wj0bHeFWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527681" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e1ae983b-c817-489b-bfbe-aa6a28e54613/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;一如既往，杨植麟的演讲充满了第一性原理的极客浪漫。这位 90 后创始人没有过多罗列商业数字，而是将大模型的发展回归到最本质的物理规律。他认为从 2019 年至今，&lt;strong&gt;所有大模型的第一性原理依然是 Scaling Law&lt;/strong&gt;，这本质上是一个「将能源转换为智能」的过程。如果拥有更好的芯片、更优的架构，就能以更少的能源置换出更高级的智能。&lt;/p&gt;&lt;p&gt;他特别提到了 Kaplan 早期的经典论文，对比了 Transformer 与 LSTM 在 Scaling Law 下的表现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagPhO551GHvs1XzS0DqtxHISBlEaPR6cDW52b5CuicPJrTLhGomUP9Flw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527682" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5f35752a-ae59-415c-b026-1ea21330702a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在短 Context（上下文）下，两者差异不大；但当 Context 拉长到 1000 甚至更长时，Transformer 的优势才显露无遗。这种「长程优势」，正是 Agent（智能体）时代的胜负手。因为很多 Agent 任务本质上是搜索问题，而更好的预训练模型能提供更强的先验，帮助我们在茫茫的搜索空间中快速剪枝。&lt;/p&gt;&lt;p&gt;为了追求极致的「Token Efficiency」（Token 效率），杨植麟展示了月之暗面在 2025 年的两大杀手锏。首先是&amp;nbsp;&lt;strong&gt;Muon 优化器&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagfwWPuqKuOhG4jRQPaUrkBNlM9pgBdiac9K5zDx1Yb8UehCtKbeBskAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527683" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c6ae9a3c-9a7e-425f-8ecd-ab70146ead74/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;相比于统治了业界十年的 Adam 优化器，这个全新的二阶优化器实现了「两倍的 Token 效率提升」。这意味着，达到同样的智能水平，它只需要一半的数据量。为了解决二阶优化器常见的训练不稳定问题，团队引入了创新的「QK Clip」机制，动态调整梯度。杨植麟指着屏幕上一张完全平稳下降、没有任何毛刺（spike）的 Loss 曲线图，动情地说道：「这张图是我 2025 年见过的最美的东西，它是一个完全平稳下降的 Loss 曲线。当你有一个优雅的方法，就可以得到一个优雅的结果。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagQnlvRUxg3fuCv3NsebGsxReibyhHpoG4LaQvMLK8IEVUc0ufTNWmTbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527684" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/4fe980f1-62bf-43b5-945f-3e106263d3a0/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;另一个突破则是&lt;strong&gt; Key-Value Cross Attention&lt;/strong&gt;。针对长上下文任务，这种新架构不仅克服了传统线性注意力在长距离任务上「掉点」的顽疾，甚至在超长 Context 下的表现超越了全注意力（Full Attention）机制，且速度提升了 6 到 10 倍。&lt;/p&gt;&lt;p&gt;在演讲的最后，杨植麟谈到了 AGI 的「品味」。&lt;/p&gt;&lt;p&gt;他认为&lt;strong&gt;做模型本质上是在创造一种世界观&lt;/strong&gt;。智能与电力不同，电力是同质化的，深圳的一度电和北京的一度电没有区别；但&lt;strong&gt;智能是非同质化的&lt;/strong&gt;，一位音乐家产生的智能与一位程序员产生的智能截然不同。他透露，基于这些理念打造的 &lt;strong&gt;Kimi K2&lt;/strong&gt; 模型，在极高难度的 HLE（Humanity&amp;#39;s Last Exam）基准测试中达到了 45% 的准确率，超越了 OpenAI 等美国前沿公司。&lt;/p&gt;&lt;p&gt;面对 AI 可能带来的风险，他引用了 Kimi 给他的回答：这不仅是工具，更是人类认知的延伸，我们不应因恐惧而停滞不前，放弃人类文明的上限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;林俊旸：通往通用智能体（General Agent）之路&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag08mxhdExURgqJ8qSgMjjibyqndz1brWvr7p5Ijiab19t26ykyQeDRzDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527685" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0a7f71fd-2aa2-4fee-aa8f-23fa7c34c2d8/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;阿里云通义千问（Qwen）的林俊旸则带来了一股浓厚的产品主义气息。作为开源界的「卷王」，他直言「&lt;strong&gt;模型即产品&lt;/strong&gt;」，并分享了 Qwen 如何通过开源社区的反馈完成自我进化的故事。&lt;/p&gt;&lt;p&gt;针对 2026 年的主力模型 &lt;strong&gt;Qwen-3&lt;/strong&gt;，林俊旸透露团队正在全力打磨 &lt;strong&gt;Hybrid Architecture（混合架构）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种架构极有可能是将 Transformer 与 Mamba 或类似的线性注意力机制以 3:1 的比例混合，旨在解决无限长文本（Infinite Long Context）带来的显存和计算瓶颈。他特别自豪地提到了「不降质」的突破 &amp;mdash;&amp;mdash; 在增强视觉和语音能力的同时，模型的文本推理能力不再像过去那样出现倒退，真正实现了多模态与智力的同步提升。&lt;/p&gt;&lt;p&gt;「人有眼睛和耳朵才能更好地理解世界，模型也一样。」林俊旸展示了 Qwen 在 &lt;strong&gt;Omni（全能） 模型&lt;/strong&gt;上的进展。&lt;/p&gt;&lt;p&gt;他放出了两张对比图，一张是 8 月份生成的「AI 味」浓重的图片，另一张是 12 月份生成的「宿舍女生自拍」风格图片，后者逼真程度令人咋舌。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagiaj4zyaZTqnC2RIXcDLAj99bpD4lKxURlAje1ncwbKsOIhibcNb8BUtg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527687" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/fec7b670-e8f1-495d-aa1f-d011fce6aae4/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更重要的是，&lt;strong&gt;Qwen 正在尝试将「生成」与「理解」打通&lt;/strong&gt;。例如在解几何题时，如果模型卡住了，它可以自己画一条辅助线（生成），然后基于这张新图继续推理（理解）。这种「理解-生成一体化」被林俊旸视为通向 AGI 的重要台阶。&lt;/p&gt;&lt;p&gt;林俊旸还分享了一个关于开源社区「反哺」的有趣案例。用户曾反馈图片编辑功能中「手放下来位置歪了」的问题，这让团队意识到即使是微小的像素级偏移，在真实应用中也是不可接受的。这种算法与 Infra（基础设施）的联合优化，让 Qwen 在迭代速度上保持了惊人的优势。&lt;/p&gt;&lt;p&gt;对于 AI 的未来，林俊旸的愿景非常接地气：「如果你的想法不是帮助全人类，那不如不做大模型。」他希望未来的模型不仅仅是通过考试的学霸，更是一个能真正帮助人类的 Agent。他观察到旧金山已经进入了 Vibe Coding（氛围编程）时代，没人再手写代码，而国内尚未普及。他坚信，能够操作电脑、写代码、甚至在物理世界里端茶倒水的 &lt;strong&gt;Embodied AI（具身智能）才是 AI 走向现实世界的终极形态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;圆桌激辩：从硅谷的富人创新到 Agent 的终局&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说演讲环节是各位掌舵者对自家技术版图的宣示，那么随后的圆桌对话则是一场卸下防备的坦白局。&lt;/p&gt;&lt;p&gt;这场对话的阵容堪称豪华：学界泰斗杨强、刚刚履新腾讯 AI 首席科学家的姚顺雨（线上参加，这也是姚顺雨告别 OpenAI 加入腾讯后的首次公开露面）、通义千问负责人林俊旸，以及智谱 AI CEO 唐杰。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagEZBiajb6OHFbDOBV5yXYUrL1ff8L4Odu8v87t5ia6jcx1ticqYpPHS6vQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527686" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/1ee9fd57-642f-4543-aa51-0652f778b18f/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在主持人的追问下，四位嘉宾围绕模型分化、下一代范式、Agent 的商业落地以及中美 AI 差距等敏感话题，展开了一场超过 70 分钟的思想交锋。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ToC 的温吞与 ToB 的激进：姚顺雨的首秀观察&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为横跨中美、经历过 OpenAI 核心研发团队的科学家，姚顺雨的视角显得尤为犀利。对于当前大模型在 ToC（面向消费者）和 ToB（面向企业）市场的表现，他给出了一个极其鲜明的判断：ToC 端的体验正在趋于平缓，而 ToB 端的生产力革命已经发生。&lt;/p&gt;&lt;p&gt;「大家都有一个感觉，今天用 ChatGPT 和去年用 ChatGPT，对大部分人大部分时候其实感受的变化已经没有那么强烈了。」姚顺雨直言不讳。对于普通用户来说，模型在抽象代数或范畴论上的能力提升是「无感」的，它更像是一个搜索引擎的加强版。但 ToB 领域则完全不同，尤其是 Coding 场景，「&lt;strong&gt;Coding 革命已经开始&lt;/strong&gt;，它正在重复整个计算机行业做事的方式 &amp;mdash;&amp;mdash; 不再写代码，而是用英语和电脑交流。」&lt;/p&gt;&lt;p&gt;他用一个生动的例子解释了为什么企业愿意为最强的模型支付溢价：如果一个员工年薪 20 万美元，每天处理 10 个任务。顶级模型（如 OpenAI o1）能做对 9 个，而差一点的模型只能做对 5 个。「问题在于你不知道错的那 5 个是哪 5 个。」在这种情况下，企业宁愿支付高昂的溢价来换取确定性。因此，姚顺雨预判：「在 ToB 市场上，强模型和弱模型的分化会变得越来越明显。」&lt;/p&gt;&lt;p&gt;对于这一观点，阿里云的林俊旸表示认同，他还从「基因」的角度解读一下。对于姚顺雨的「腾讯肯定还是 To C 基因更强的公司」的看法，他半开玩笑地说道：「顺雨到了腾讯，腾讯可能就变成了有顺雨基因的公司。」他认为，无论是 ToB 还是 ToC，最终服务的都是真实的人类，关键在于能否解决长尾问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一个范式：是「间谍」还是「核爆」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当话题转向 2026 年可能出现的技术范式转移时，&lt;strong&gt;自主学习（Self-learning）&lt;/strong&gt;成为了全场共识的关键词。但这个范式将以何种面貌出现？&lt;/p&gt;&lt;p&gt;姚顺雨提供了一个非常独特的视角。他认为自主学习可能不会像 AlphaGo 那样以「平地惊雷」的方式出现，而更像是一个「潜伏的间谍」。&lt;/p&gt;&lt;p&gt;「这个事情其实已经在发生了。」姚顺雨指出，ChatGPT 利用用户数据不断拟合聊天风格，Claude Code 编写了自己项目 95% 的代码，这些都是自主学习的雏形。他将未来的 AI 系统比作两部分：一部分是神经网络（大脑），另一部分是调用这个神经网络的代码库（身体）。当有一天，AI 开始自己编写那部分「调用自己的代码」时，质变就会发生。「这可能更像是一个间谍渗透的过程，而不是一次突发的突破。」&lt;/p&gt;&lt;p&gt;对此，智谱 AI 的唐杰则表现得更加审慎。他坦言自己对 2026 年出现巨大的范式革新持怀疑态度。他提出了&lt;strong&gt;「智能效率」（Intelligence Efficiency）&lt;/strong&gt;的概念，即投入多少资源能获得多少智能增量。目前的 Scaling 虽然有效，但本质上是「最笨的方法」。真正的范式革命，应该是找到一种能用极少投入换取巨大智能增量的新路径。&lt;/p&gt;&lt;p&gt;林俊旸则从安全角度表达了对「主动性 AI」的担忧。「我最担心的不是 AI 学了什么，而是它主动做了一些该做或是不该做的事。」他举例说，如果 AI 主动发现会场有个炸弹，这固然是好事；但如果它产生了其他不可控的主动意图，这将是巨大的安全隐患。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 的终局：从工具到「职场人」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于 2026 年被寄予厚望的 &lt;strong&gt;Agent（智能体）&lt;/strong&gt;，杨强教授提出了一个清晰的四阶段演进论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;目标和规划都由人定义；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;目标由人定义，规划由 AI 辅助；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 观察人的工作流程（Process Data），自动学习规划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;终极阶段：目标和规划都由大模型内生定义。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;目前的 Agent 大多处于第一、二阶段。姚顺雨认为，Agent 要真正产生经济价值，瓶颈往往不在模型本身，而在环境和教育。他在 Scale AI 实习的经历让他意识到，即使模型能力不再提升，仅靠将现有模型部署到各种企业环境中，就能产生巨大的经济效益。&lt;/p&gt;&lt;p&gt;「人和人的差距正在拉大，不是 AI 替代了人的工作，而是会使用工具的人在替代不会使用工具的人。」姚顺雨发出了这样的呼吁。他认为，当下中国最有意义的事情之一，就是教育公众如何更好地使用 AI 工具，填平这道认知鸿沟。&lt;/p&gt;&lt;p&gt;林俊旸则补充了长尾理论。他认为 Agent 的核心价值在于解决那些通用模型无法覆盖的、极其个性化的长尾需求。「如果我寻遍各处都找不到解决方案，但在那一刻，AI 帮我解决了，这就是 AI 最大的魅力。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中美差距的灵魂拷问：胜算如何&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;圆桌的高潮出现在最后一个话题：3 到 5 年后，全球最领先的 AI 公司是一家中国公司的概率有多大？&lt;/p&gt;&lt;p&gt;林俊旸认为比较困难，他给出的理由却发人深省。他将其比作美国的「富人创新」与中国的「穷人创新」。&lt;/p&gt;&lt;p&gt;硅谷拥有顶级的显卡储备，甚至在有些浪费地使用算力探索下一代范式；而中国团队往往是在资源受限的情况下，被逼出了极致的算法优化和工程落地能力。「穷则思变，创新往往也发生在资源受限的地方。」林俊旸认为，软硬结合（如 AI 与 MCU 芯片的结合）或许是中国突围的一个机会。&lt;/p&gt;&lt;p&gt;姚顺雨对此则更为乐观。他认为，硬件（如光刻机）的瓶颈是客观且可解决的，真正的差距在于主观的冒险精神和研究文化。&lt;/p&gt;&lt;p&gt;「在中国，大家还是更喜欢做安全的事情。如果这个事情已经被证明可以做出来，我们几个月就能复现并做到极致。但如果让你去探索一个未知的领域，比如长期记忆，大家就会犹豫。」姚顺雨犀利地指出了中国研究界的痛点：&lt;strong&gt;过分关注榜单和数字，而忽视了什么是正确的事情。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;他回忆起在 OpenAI 的经历，那里的人更在乎「能不能创造出新的东西」，而不是「能不能在榜单上高出一分」。他呼吁中国的研究者走出榜单的束缚，「DeepSeek 做得就很好，他们没有那么关注榜单，而是关注用户体验和什么是正确的技术路径。」&lt;/p&gt;&lt;p&gt;唐杰教授则以「最不幸的一代」自嘲：上有老一辈学者还在工作，下有 00 后天才少年横空出世，夹在中间的 80 后、90 后研究者好像被「无缝跳过了」，世界已经交给下一代了。但他同时指出，中国 00 后一代展现出的&lt;strong&gt;冒险精神&lt;/strong&gt;令人欣慰。&lt;/p&gt;&lt;p&gt;「如果在这个时间点，有一群聪明人真的愿意做特别冒险的事，而且国家能提供更好的容错环境，哪怕概率只有 20%，我们也有机会抓住那个三五年一遇的窗口期。」唐杰最后总结道。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;尾声：未完成的答卷&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这场圆桌对话并没有给出一个确定的答案，却留下了一份沉甸甸的思考。&lt;/p&gt;&lt;p&gt;从姚顺雨对「榜单文化」的批判，到林俊旸对「富人创新」的羡慕与不甘，再到杨强和唐杰对学术界使命的再定义，我们看到的是中国 AI 力量在追赶过程中的焦虑、清醒与韧性。&lt;/p&gt;&lt;p&gt;正如主持人李广密所言：「过去我们是在追赶，是在补课。但当科技能力追上来之后，2026 年，我们期待看到中国不仅有更强的火箭，更要有自己的 Payload（有效载荷）和 Product（产品）。」&lt;/p&gt;&lt;p&gt;在 Scaling Law 依然有效的今天，中国 AI 正在从刷榜走向落地，从复现走向探索。虽然胜算或许充满了不确定性，但正如那条被杨植麟称赞的「最美 Loss 曲线」一样，只要方向正确，下降就是必然的趋势。&lt;/p&gt;&lt;p&gt;同样重要的是，通过把自己最先进的大模型开源出来，国内科技公司正在从全球 AI 技术的跟随者转变为推动者。也同样是随着这个过程，在「六小虎」之后，我们已经可以逐渐看出国内 AI「开源四巨头」正脱颖而出。&lt;/p&gt;&lt;p&gt;除了 DeepSeek 之外，包括智谱、月之暗面和 Qwen，他们今天有三个都在台上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从杨植麟眼中那条「最美的 Loss 曲线」，到唐杰构想中「会做梦的机器」，林俊旸致力打造的「全能智能体」，再到姚顺雨所预言的如「间谍」般潜行的自主学习新范式，这场 AGI-Next 峰会为 2026 年的 AI 战事定下了基调。&lt;/p&gt;&lt;p&gt;过去几年，我们忙于教 AI「读书」，试图将人类文明的知识灌输给它；而接下来的篇章，则是教它「做事」，让它在物理世界的真实反馈中像人一样思考、规划与行动。参数的军备竞赛或许已经降温，但关于智能本质的探索才刚刚开始。&lt;/p&gt;&lt;p&gt;正如几位演讲者在圆桌上的共识：智能的上限远未到达，也是那些愿意「走出榜单、寻找正确之事」的探索者们（像姚顺雨所呼吁的那样）正在努力的方向。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CES 2026「最烂」产品大赏</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:24:07 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/739a206e-e227-42fd-85e5-44a0a94709df/1768051302246.png" style="width: 700%;" class="fr-fic fr-dib"&gt;说实话，现在有些创新我是真看不懂。&lt;/p&gt;&lt;p&gt;在 CES 2026 展会中，各大厂商卖力吆喝着「AI 改变世界」的同时，一群较真的消费者权益倡导者却颁出了一份另类榜单：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最烂产品奖。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;先来说说评审团颁发的&lt;strong&gt;「全场最烂产品奖」&lt;/strong&gt;&amp;mdash;&amp;mdash; 三星的 Bespoke AI Family Hub 冰箱。&lt;/p&gt;&lt;p&gt;有一说一，它能获此「殊荣」，好像也不冤得慌。&lt;/p&gt;&lt;p&gt;这台冰箱的智能卖点是语音控制开门，听起来很赛博朋克，但在 CES 现场，如果周围环境噪声过大，它就直接装聋，无法识别用户的语音指令。&lt;/p&gt;&lt;p&gt;你在那对着冰箱狂吼「Open the door！」它岿然不动。&lt;/p&gt;&lt;p&gt;三星回应称，展会现场与消费者家庭环境很不一样，Bespoke AI 体验旨在简化家居决策，它让生活更便利、更愉快。&lt;/p&gt;&lt;p&gt;俺这个乡巴佬就纳闷了，开冰箱门是多费劲的事吗？为啥要搞这么复杂？&lt;/p&gt;&lt;p&gt;当然，这台冰箱还有其他功能，比如使用计算机视觉追踪食物库存，库存不足，它会推荐替代品。&lt;/p&gt;&lt;p&gt;嗯。。。这也大可不必。&lt;/p&gt;&lt;p&gt;冰箱真的是瞎创新的「重灾区」，有给冰箱装上屏幕，让人仰着脖子在上面刷抖音的：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgQ6lkK84ahCicwjc769CmopeLFWmVsBEdQdvy34icrUFfW3ib4VON11ib4A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="1.778" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="889" data-imgfileid="503527604" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e55dc746-ebbb-4619-bf52-7e925fa417ac/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;有给冰箱连 wifi 的，脱口秀演员都看不下去了，「一个冰箱为什么要连 wifi？是怕苹果在里面信号不好吗？」&lt;a href="https://mp.weixin.qq.com/s/OjhjM7gQ3YghWmWKVShnrQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b31c3040-a6f1-4d9b-aac8-3a7ffa317dd8/1768051329190.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;有带语音交互功能的，但就是死活听不懂不标准的普通话：&lt;a href="https://mp.weixin.qq.com/s/OjhjM7gQ3YghWmWKVShnrQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/33e03a5a-2621-4651-84e9-ca7131fc5329/1768051338713.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;一个原本只需要给食物保鲜的电器，真的需要这么多智能功能吗？当基本功能的可靠性因为堆砌 AI 特性而受到影响时，这种创新的意义何在？哦，价格贵了。&lt;/p&gt;&lt;p&gt;你以为只有冰箱乱搞创新？其他家电也净整些没用的。&lt;/p&gt;&lt;p&gt;比如这款 Wan AIChef 的微波炉。它运行在看起来很像安卓的系统上，配备食谱推荐、烹饪指导，还有内置摄像头让你实时监控加热进度。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHxOnKibfEdcJYFHbX0AS9AHnlg0SMVqOA6B8Uz2eWXGkE6qyl5uicoLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1080" data-height="720" data-backw="578" data-backh="385" data-imgfileid="503527583" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e87c5610-c5c1-41f8-b33c-3fb9723cc3f0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这看起来挺智能的，但其实只是个微波炉。它啥烹饪也帮不上，唯一能做的就是把食物加热到恰到好处的温度，按官方说法是正负 3 摄氏度的精准控制。&lt;/p&gt;&lt;p&gt;它还提供餐食计划、食物追踪和卡路里计算功能，但前提是得保证自己的所有餐食都用这台 AI 微波炉来加热。&lt;/p&gt;&lt;p&gt;如果说智能冰箱、微波炉只是过度设计，那么亚马逊 Ring 门铃摄像头的新功能则触碰到了更敏感的隐私红线。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgVF4kDtxsQUtvgZRLLSjEfLS69QKTMeiaMsWV9PlkUWM6oChBiaYfI69A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1440" data-height="960" data-backw="578" data-backh="385" data-imgfileid="503527585" data-aistatus="1" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/e6d8b94a-c9aa-4478-8d60-89f56a54cc5b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这款产品斩获了&lt;strong&gt;「隐私类最烂产品奖」&lt;/strong&gt;，理由是「加倍入侵隐私，并支持了『更多监控总是更安全』的错误观念」。&lt;/p&gt;&lt;p&gt;评审团列举了 Ring 的一系列「罪状」，比如新增的「AI 异常事件警报」功能号称能检测意外访客或事件，但这背后包含了面部识别；Ring 还推出了一个应用商店，允许第三方开发者为门铃开发更多应用，这意味着，你家门口的摄像头可能会被用于你完全不知情的用途。&lt;/p&gt;&lt;p&gt;AI 时代，人们对隐私问题越发敏感。&lt;/p&gt;&lt;p&gt;Merach 的联网跑步机就因为隐私政策获得了&lt;strong&gt;「安全类最烂产品奖」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这款跑步机号称拥有行业首个由大语言模型驱动的 AI 教练，不仅能与用户对话，还能根据心率变化主动调整速度和坡度。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgOWfr7vOPrJzmW4vFvDlP3KicBBbVXXwmOja85FXwMhQ0OW7lEMExriaw/640?wx_fmt=jpeg#imgIndex=4" data-ratio="0.9088541666666666" data-type="png" data-w="384" data-width="388" data-height="400" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHUf9zZiag3zDPFOysZPhpVA3OuYKImyEibibxfnYjJdrVFVQaW5YEKJ6Q/0?wx_fmt=png&amp;from=appmsg" data-cropx2="385" data-cropy1="13" data-cropy2="362" data-imgfileid="503527586" data-aistatus="1" data-original-style="width:385px;height:349px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f457eb01-6fe6-4e0d-9626-a8421aa860f9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;听起来很不错，但它的隐私政策中写着「我们无法保证您个人信息的安全」，这意味着你的心率数据、运动习惯、身体状况等生物特征信息都在被收集，却得不到安全保障。&lt;/p&gt;&lt;p&gt;还有那款名为 Ami 的 AI 伴侣，也因为隐私问题赢得&lt;strong&gt;「人民选择最烂产品奖」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这款产品以「永远在线的 3D 灵魂伴侣」为卖点，在弧形屏幕上呈现一个女性虚拟形象，专为远程办公者设计，承诺提供私密和共情的互动。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgMd15OTVpN8q1SZPpuYvEFurlufVq2IjrktoScIMTLhFpSPWtAfqibjQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5425" data-type="png" data-w="400" data-width="400" data-height="217" data-imgfileid="503527588" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/cb52c04c-407f-461c-b2a9-daa4fb9f2cf0/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;它会追踪你的眼球运动、分析你的语音语调，试图理解你的情绪状态。但评审团直言不讳地批评「竟敢暗示一台桌面 AI 视频监控设备可以成为任何人的灵魂伴侣」。&lt;/p&gt;&lt;p&gt;虽然这款产品配备了物理摄像头遮挡装置，但「永远在线」的营销话术让人感到不安。&lt;/p&gt;&lt;p&gt;这种陪伴类 AI 产品不在少数，CES2026 中还有个 AI 马斯克（迷你版）吸引不少人关注。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgID6FxvV6Ceu07xZMoaTZZkJDarDwTsvibzmNKKVzAk6z9Vmia9J4y6lw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-type="jpeg" data-w="1080" data-width="2200" data-height="1467" data-backw="578" data-backh="385" data-imgfileid="503527590" data-aistatus="1" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8626f01c-c9a1-480a-a718-8c983da2392c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;迷你马斯克只是 Luka AI 魔方提供的众多虚拟形象之一，还有宫崎骏、《我的世界》里的史蒂夫、哈利・波特等等。&lt;/p&gt;&lt;p&gt;孩子们可以跟这些 AI 聊天，倾诉一天的经历，寻求建议。AI 方块还带摄像头，孩子可以把画面分享给 AI，让虚拟形象知道他们在哪儿、在干什么。Luka 宣称这既是娱乐工具也是教育工具，包含各种教育活动和多语言选项。&lt;/p&gt;&lt;p&gt;不过有人质疑：真的该信任任何一家公司，让他们的 LLM 去接触你的孩子吗？更何况最近 Grok 被指责帮人生成不当图像。&lt;/p&gt;&lt;p&gt;活了三十年，第一次见会唱歌的棒棒糖。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgNmBwUqLezjHJDnFMy5Fic0DicRZVYw3Vw0sDe1Z6CnsUqN1pcwaibxiaGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1248" data-height="702" data-backw="578" data-backh="325" data-imgfileid="503527592" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/284c1fb5-fac4-4cbb-ae65-561f8ca37d52/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Lollipop Star 这款会唱歌的棒棒糖使用骨传导技术，让你在咀嚼时通过后槽牙「听到」音乐。&lt;/p&gt;&lt;p&gt;官方称，他们已与全球流行音乐偶像合作，每个售价 8.99 美元的棒棒糖都有自己独特的节奏、口味。比如桃子味的棒棒糖会播放 Ice Spice 的音乐，蓝莓味的会播放 Akon 的歌。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgJWkgk9yYqia1gZQibKPtXhVpdJicGZr1Zsyc8vibp3iahXpLR5p5dyQGpLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.587037037037037" data-type="png" data-w="1080" data-width="1999" data-height="1173" data-backw="578" data-backh="339" data-imgfileid="503527594" data-aistatus="1" data-original-style="width:100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/09b531b3-a5f9-47c2-9467-4bc4a0422b8e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;创意确实新奇，但问题在于吃完糖后，这根内置电子元件的棒子既不能充电也不能重复使用，只能扔掉。&lt;/p&gt;&lt;p&gt;在全球电子垃圾问题日益严峻的今天，为了几分钟的新奇体验而制造一个无法回收的电子产品，代价未免有点大，正因如此，这款棒棒糖拿下&lt;strong&gt;「环境类最烂产品奖」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;德国科技公司博世一口气拿下了两个「最烂产品奖」。&lt;/p&gt;&lt;p&gt;一个是因为给浓缩咖啡机加入订阅服务和亚马逊 Alexa 语音助手，另一个是因为在电动自行车应用程序上加入防盗和电池锁定功能，让正常维修变得困难重重。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgLO4FuyglXuF8RmnIrnOvpRvkha8aCD8k2T6pRUmtes75NSicpEXpuPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1440" data-height="960" data-backw="578" data-backh="385" data-imgfileid="503527596" data-aistatus="1" data-original-style="width:100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/5c6f9d36-6d1a-4b91-a309-744be0f25d10/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不过博世称这些功能都是可选的，而就浓缩咖啡机而言，这些功能已经很受欢迎。&lt;/p&gt;&lt;p&gt;除此之外，这届 CES 展会上还有各式各样的奇葩发明。&lt;/p&gt;&lt;p&gt;比如这个 Glyde 智能理发器，号称全球首款真正的智能理发器。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgmibILE30UHuWq6wQAHRZWXibgklicDwiccsTP8mz6yHyn9qaS6skBficxicA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.6666666666666666" data-type="jpeg" data-w="1080" data-width="2200" data-height="1467" data-backw="578" data-backh="385" data-imgfileid="503527597" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5008d203-a20e-42f7-b4da-c89c456d2af6/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其核心技术在智能刀片系统，内置传感器会实时追踪你的移动速度、倾斜角度和方向，并自动调整刀片深度，一次避免剪得坑坑洼洼的。&lt;/p&gt;&lt;p&gt;操作仅需三步，打开 App 选发型，App 里有各种流行发型，都是针对不同头型和发质测试过的，可以挑现成的，也能自己定制；戴上渐变带，标记好起始位置；然后开机，从下往上滑就行了。&lt;a href="https://mp.weixin.qq.com/s/OjhjM7gQ3YghWmWKVShnrQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/81acfdad-6eeb-4321-97e4-e47f6b6e8929/1768051390419.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;官方还表示，他们正在开发 AI 语音控制功能，以后连发型都不用自己选了，直接跟理发器说话，它会根据脸型、发质啥的，用 AI 推荐发型。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/tech/858315/most-dubious-ai-tech-ces-2026&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://apnews.com/article/ces-worst-show-ai-0ce7fbc5aff68e8ff6d7b8e6fb7b007d&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/technology/comments/1q7ofw9/worst_in_show_ces_products_include_ai/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>前谷歌研究员发文：算力崇拜时代该结束了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:19:42 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6b8fb529-cfef-4bc2-a6a9-dbf2b80e654c/1768051060339.png" style="width: 700%;" class="fr-fic fr-dib"&gt;过去十年，我们几乎把 AI 领域的创新简化成一条公式：更多参数、更多数据、更多算力。可未来的突破，是否仍然只能从训练算力中产生，其实并不清楚。&lt;/p&gt;&lt;p&gt;这个问题之所以重要，是因为「算力驱动进步」的信念，已经深刻改变了整个领域的研究文化。学术界因缺乏算力逐渐被边缘化，研究参与在地域上高度集中；巨额资本投入也让原本开放的发表传统变得愈发封闭。&lt;/p&gt;&lt;p&gt;在过去的一段时间，前谷歌大脑研究员、Cohere 前 AI 研究负责人 Sara Hooker 一直在呼吁大家重视这个问题。最近，她还把自己之前的演讲内容写成了文章。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527416" data-ratio="1.1578947368421053" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gtzlOub5wa2stBwtBNia4viaKnXI6ZWicj8Dxj83FkkWnhgqO8cn2DHAVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1064" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5798ef54-27fa-4511-bdeb-fd6295380b82/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;文章标题：On the slow death of scaling.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;文章链接：https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5877662&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;文章中提到，对于深度神经网络而言，持续扩展训练计算资源效率极低。我们花费大量资源来学习那些低频特征的长尾部分，而所有迹象都表明，我们正处于收益递减的时期。在模型规模不再逐年翻倍的世界里，模型如何从环境中学习并有效地从新知识中适应，就显得尤为重要。在文章中，她探讨了一些未来有价值的方向。&lt;/p&gt;&lt;p&gt;以下是文章内容节选。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一个不容忽视的趋势：小模型的崛起&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;声称 scaling 正在走向终结，这在许多领域都存在争议。因为过去十年的所有证据都表明，扩展计算能力能够解锁更大的模型规模或数据集。增加计算能力也恰好符合行业季度规划的节奏，相比提出一种替代的优化技术，提议训练更大的模型风险更小。&lt;/p&gt;&lt;p&gt;但仅仅依靠计算资源会忽略规模与性能之间的关系正在发生的一个关键转变。更大的模型并不总能带来更好的性能。最近几年出现了很多大模型被规模小得多的小模型超越的案例。如下图 3b 所示，随着时间推移，这类小模型数量激增。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527418" data-ratio="0.6296296296296297" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gdxsV9Nmk4GQfib912Oyia8F1ZbdftSnEBQQKiayQRyoJwYrmHibPIiaPYyw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/34e5b9dc-f052-4bc6-a31c-ec90cef7e2b2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;要理解为什么会出现这种情况，我们必须弄清楚在过去十年中，哪些关键变量一直在推动性能的提升。在计算资源回报递减的时代，优化和架构上的突破决定了单位计算资源的回报率。而正是这种回报率，对发展速度以及额外计算资源所带来的风险水平最为关键。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527419" data-ratio="1.1398148148148148" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gjCAHkhMJcKic16sxbmt6YuIGysN4WleCmWJqZZVqPfWTxvI7hDt5RVw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3eee99c5-49e6-4200-8c88-08091cb33dbc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;哪些因素会影响算力回报率？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在复杂系统中，孤立地操控一个变量并预见所有影响是极具挑战性的，人们对计算量的推崇也是如此。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增大模型规模正面临收益递减&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去十年，模型参数量从早期 Inception 的 2300 万暴增至 Qwen3-235B 的 2350 亿。尽管更大模型确实带来了性能提升，但额外的参数数量与泛化能力之间的关系仍不清楚。&lt;/p&gt;&lt;p&gt;令人困惑的是：训练结束后，我们可以删除大部分权重而几乎不损失性能；但若一开始就不启用这些权重，则无法达到相同效果。研究发现，仅用一小部分权重就能预测网络中 95% 的权重，说明存在大量冗余。这可能反映的是深度学习技术本身的低效 &amp;mdash;&amp;mdash; 如果有更好的学习方法，我们可能根本不需要这么大的网络。&lt;/p&gt;&lt;p&gt;增大模型规模是学习长尾分布的一种成本极高的方式。深度神经网络的学习效率极低。它们能快速学会常见特征，却需要大量算力和时间来学习罕见特征。这是因为训练基于平均误差最小化，所有样本被同等对待，导致低频特征的信号在批量更新中被稀释。而现实世界中，大多数属性恰恰是低频的 &amp;mdash;&amp;mdash; 人类智能的独特之处正是能高效处理这类长尾数据。深度网络在这方面最为吃力，训练的大部分算力都被消耗在以极高代价记忆长尾数据上，如同「搭梯子登月」般低效。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据质量降低了对计算资源的依赖&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在质量更高的数据上训练的模型不需要那么多计算资源。大量研究表明，改进训练语料库的一些工作，包括去重、数据修剪或数据优先级排序，可以弥补模型规模的不足。这表明，可学习参数的数量并非提升性能的绝对限制因素；对更高数据质量的投入能够减少对更多（计算资源等）的需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新的算法技术弥补了计算量的不足&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去几年的进展，既得益于算法的改进，也得益于计算能力的提升。这包括通过指令微调扩展预训练，以教会模型遵循指令；利用更大、性能更强的「教师」模型生成的合成数据进行模型蒸馏，来训练能力强、规模小的「学生」模型；思维链推理；增加上下文长度；检索增强生成；以及通过偏好训练使模型与人类反馈保持一致等。&lt;/p&gt;&lt;p&gt;所有这些技术都弥补了对大量权重或昂贵的长时间训练的需求。在所有条件相同的情况下，与未使用这些优化技巧且在相同计算量下训练的模型相比，这些技术已被证明能显著提升模型性能。我们正用相同数量的资源做着多得多的事情。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;架构在决定可扩展性方面起着重要作用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;架构在确定单位计算量下的整体性能回报率方面起着巨大作用。它在决定进步上限方面也至关重要。新架构设计的引入可以从根本上改变计算量与性能之间的关系，并使任何现有的 scaling law 变得无关紧要。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Scaling Law 的局限性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;巴菲特曾说过一句话：「别问理发师你需不需要理发。」同样的道理，也别去问计算机科学家或经济学家能不能预测未来。人们往往会被「我能预测」的诱惑牵着走，而忽视了对预测边界应有的谦逊。关于模型规模与性能关系的 scaling law 正是这种自信膨胀的体现。它试图用算力规模去推断预训练损失的变化，或预测下游能力如何随规模出现，但现实远比公式复杂。&lt;/p&gt;&lt;p&gt;Scaling Law 之所以流行，很大程度上源于人们过度相信算力是推动进步的核心变量。它逐渐成了一个万能说法，被用来为巨额投资甚至政策决策背书。其吸引力也不难理解，如果能力真的能随算力精确预测，资本配置就会显得异常清晰。但问题在于，我们几乎从未准确预测过性能究竟会提升多少，这让「算力投入的回报率」在科学上难以站得住脚。&lt;/p&gt;&lt;p&gt;更关键的是，Scaling Law 真正被反复验证的，只是对预训练测试损失的预测，也就是模型补全文本的能力。一旦换成真实的下游任务表现，结果往往混乱且不一致。所谓的「涌现能力」，常被用来解释这种落差，看似是能力突然出现，实际上等于承认 Scaling Law 并不能告诉我们未来会发生什么。即便只预测测试损失，在数据分布假设略有变化时，结果的可复现性也会出现问题。越来越多研究发现，许多能力的提升曲线并不平滑，甚至根本不符合幂律。&lt;/p&gt;&lt;p&gt;对于需要向未来外推的复杂系统来说，小误差会不断累积，而样本数量又极其有限。每一个数据点都是一整个模型，高昂的计算成本意味着很多 scaling 结论建立在不到百个样本之上，统计支撑本身就很脆弱。因此，不同领域中 Scaling Law 的可靠性差异巨大。比如代码生成在极大算力跨度内表现出相对稳定的幂律关系，而其他能力则显得更加不可预测。&lt;/p&gt;&lt;p&gt;在架构、优化方法和数据质量保持不变的短期受控环境下，Scaling Law 对规划训练规模仍有一定价值。但一旦拉长时间尺度，它们就很难经得起检验。Scaling Law 的频繁失效提醒我们，单纯堆算力并不是一条直线式的进步路径。那些过度依赖 Scaling Law 的前沿 AI 公司，可能正在低估其他创新方向的价值，而真正的突破，往往正藏在这些被忽视的地方。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;未来前进方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在计算机科学中，我们长期把算力当成银弹。&lt;/p&gt;&lt;p&gt;但现实正在发生分化。一方面，至少在短期内，人们仍会继续把模型做得更大，试图从逐渐老化的架构中榨取最后的性能；另一方面，算力与性能之间的关系却越来越紧绷，也越来越难以预测。单纯依赖算力，正在变成一条不稳定的道路。&lt;/p&gt;&lt;p&gt;真正有可能引领下一轮创新的前沿实验室，不会把赌注只压在算力上。更有价值的进展，来自对优化空间的根本性重塑，也就是范式层面的转变。与以往不同的是，计算机科学家如今需要同时优化的「工具箱」大幅扩展，这不仅会决定他们把时间花在哪里，也会影响「发现」本身是如何发生的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新的优化空间&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如今，越来越多的计算并不是花在训练阶段，而是花在训练之外、推理之中。过去，模型性能的提升几乎等同于更多数据、更长训练或更大参数规模，而现在，一个明显的转向正在发生：通过在推理时投入更多算力，用搜索、工具调用、多智能体协作或自适应计算来提升表现，而不必改动模型本身。更重要的是，这些方法大多不依赖梯度更新，彻底偏离了过去三十年以训练为中心的进步路径。已有研究表明，仅靠推理阶段的计算放大，就可能带来数倍甚至一个数量级的性能提升，而所需算力远低于重新预训练的成本。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527420" data-ratio="0.5787037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gGNCkGtQbicz5ibqQvSU1cyon3Iibe752icO2c3nyAsKVj5kcTC6Y3KcRnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/729d932a-8bbc-4712-9641-6bf531d33b22/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;与此同时，数据也不再是不可触碰的「静态背景」。长期以来，高质量标注数据稀缺且昂贵，训练集往往被视为对世界的固定快照，从 MNIST、ImageNet 到 SQuAD，AI 的进步建立在这些冻结的数据之上。但现实使用中，模型最擅长的始终是训练分布，而推理时真正重要的场景却常常数据不足，训练与使用之间由此产生结构性错位。随着合成数据成本大幅下降，数据空间本身开始变得可塑，我们可以有意识地生成、引导和放大那些原本稀少却关键的分布区域，这也动摇了机器学习中关于 IID 样本的基础假设。&lt;/p&gt;&lt;p&gt;最后，智能系统的核心正在从「更强的模型」转向「更会与世界互动的系统」。算法本身不再是全部，交互方式、界面设计以及多组件系统的协同，正在成为决定智能上限的重要因素。曾经属于 UX 或人机交互的小众问题，正在走到计算机科学研究的正中央。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;只要还用 Transformer，scaling 就会变得没有意义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在以 Transformer 为核心架构的前提下，只要我们仍局限于 Transformer 这种架构，继续扩大计算规模就没有意义。现有架构已经明显出现边际收益递减，再投入算力也难以换来成比例的进步。深度神经网络主导了过去十年的发展，但越来越多迹象表明，下一次真正的跃迁需要一种全新的架构。随着模型开始持续与世界互动，如何避免灾难性遗忘成为关键挑战，而依赖全局参数更新的深度网络，在持续学习和知识分化上先天受限，很难像大脑那样形成相对独立、可专门化的知识区域。&lt;/p&gt;&lt;p&gt;与此同时，训练算力「scaling 退潮」并不等于 AI 的环境影响会随之减轻。需要区分的是，算力与性能关系的变化，并不等同于整个 AI 系统的计算开销下降。即便模型本身变得更小、更高效，AI 也会被部署到越来越多的场景中。真正的能耗大头，往往不在训练，而在模型上线后的生产化与大规模服务阶段。当数十亿用户同时使用 AI 时，即使单个模型更轻量，总体能耗仍可能持续上升，这依然是一个不容忽视的现实问题。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>因为AI编程，Tailwind CSS差点死了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:16:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dd3916f2-1c34-47c7-af88-4490095c6182/1768050684566.png" style="width: 700%;" class="fr-fic fr-dib"&gt;在生成式 AI 狂飙突进的 2026 年，如果你让一个 AI 编程智能体来写网页应用，它很大概率会用到 &lt;strong&gt;Tailwind CSS&lt;/strong&gt;。要知道，其如今的周下载量已经超过了惊人的&lt;strong&gt; 2600 万&lt;/strong&gt;次。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527523" data-ratio="0.5962962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgKibPoLibZTCYziceiabRKKxHrGMjVl3Xc9o9jZBXoJNVaw55icKQaReiaDiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1a7e49dc-3621-4288-92f6-728198ec355f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;然而，这个备受 AI 智能体欢迎的 CSS 框架背后的团队日子却并不好过。&lt;/p&gt;&lt;p&gt;前两天，Tailwind CSS 创始人 Adam Wathan 在一条 GitHub 评论中揭示了一个辛酸的现实：Tailwind 已经裁掉了 &lt;strong&gt;75%&lt;/strong&gt; 的团队成员。这并非因为产品不再流行，恰恰相反，Tailwind 比以往任何时候都受欢迎。导致这一局面的核心原因在于，AI 带来的巨大流量与商业转化彻底脱钩：&lt;strong&gt;AI 在写代码，就没有人类会去访问文档，也就没人为他们的付费产品买单&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;整体来说：&lt;strong&gt;流量下降 40%，收入损失 80%&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgsPwnAYAwKGeoltsARregZzSG7MIrHy3dAxzrMXmXCrQuWE4jkwViaLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527525" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0f377517-5261-47f5-823a-f7533eeea974/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 注：本截图以及以下多张截图原本是英文，由机器翻译为中文&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一事件撕开了 AI 时代开源软件商业模式最隐秘也最痛楚的一角。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「我们没时间做不能维持生计的事」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;危机的爆发源于一个看似普通的 Pull Request。&lt;/p&gt;&lt;p&gt;2025 年 11 月，一位用户 quantizor 希望新增一个 llms.txt 接口，用于向大模型提供经过优化的项目文档内容，方便 LLM 更好地理解和使用该项目。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgsVabyrqK77qlS5iatIssa7j1wZcM0l0TpEEs9vDRS4cyfdX7DTgUODg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5203703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527524" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/78fa3e3b-c204-454f-baae-3d2387bd65a2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; https://github.com/tailwindlabs/tailwindcss.com/pull/2388&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;然而，该 Pull Request 并未被即时处理，而是被搁置了一个多月，便有用户发起了评论问询。&lt;/p&gt;&lt;p&gt;这时候，Adam Wathan 现身解答了疑惑，并表示 Tailwind 公司已经陷入了财务困境，而让 LLM 更容易阅读文档会让问题更加严重。Tailwind 的商业模式依赖于开发者访问官方文档，进而在页面上接触到他们的付费产品（如 UI 组件库 Tailwind UI）。然而，随着 Cursor 等 AI 编程工具的普及，开发者不再需要查阅文档，AI 可以直接生成代码。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgzuMXguNDIqWZ4t7IZaZM52VIK4thsx9ictou144rrEEW283dUAqXh5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.26296296296296295" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527527" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/de867928-dc59-45fa-bdbf-e07106f91b32/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Wathan 的评论引发了更多讨论，这也让他有机会进一步解释其公司面临的困难：他们&lt;strong&gt;刚刚在前一天裁掉了 75% 的工程团队&lt;/strong&gt;，而原因是「AI 对我们业务造成了极其残酷的冲击」。&lt;/p&gt;&lt;p&gt;Wathan 写道：「尽管 Tailwind 比以往任何时候都更受欢迎，但与 2023 年初相比，我们文档的访问量下降了大约&lt;strong&gt; 40%&lt;/strong&gt;。文档是人们了解我们商业产品的唯一途径，没有客户，我们就无法负担维护这个框架的成本。」更具体而言：「Tailwind 的增长速度比以往任何时候都快，规模也比以往任何时候都大，但我们的收入却下降了将近 &lt;strong&gt;80%&lt;/strong&gt;。」&lt;/p&gt;&lt;p&gt;他还在这条评论中表达了担忧：「这个项目在没有人再受雇来维护它的情况下，最终只会变成一个无人维护、被遗弃的软件。」&lt;/p&gt;&lt;p&gt;最终，为了生存，他拒绝了那个让 AI 更方便「白嫖」知识的请求，关闭了这个 Pull Request。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开源项目的商业模式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这里，我们看到了 AI 编程智能体大爆发时代的另一面。&lt;/p&gt;&lt;p&gt;这一事件自然引发了网友的高度关注和争议。&lt;/p&gt;&lt;p&gt;有开发者直言不讳地在下面评论说 Wathan 拒绝这个 Pull Request 并将其归因于 AI 的做法是错的，他表示：「这件事唯一应该受到指责的人是 Tailwind 的 CEO / 主要维护者。他们做出了错误的决定，雇佣了程序员却不知道如何才能赚到足够的钱来支付他们的工资。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgicmvc40iaiadtXbUACfXLQOxVibtEllkib3rTMlZNpwhjro17tEA9rE4nmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.43148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527528" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/138e6c60-c54d-4032-ac80-f403725b9020/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;甚至还有人恶语相向。最后，Wathan 选择了锁帖。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg20EzmhcdTMiaibffMKSXXuNA18e5MwVpNASROCj0xsv5rGSCOys5NY0Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21420118343195266" data-s="300,640" data-type="png" data-w="845" type="block" data-imgfileid="503527526" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/39de52f8-3097-42cd-87d7-65dc72a80647/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但事件并未就此平息，只是转移了位置，其中很多讨论都围绕着&lt;strong&gt;开源项目的商业模式&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在 X 上，技术作家 Bilgin Ibryam 评论说：「这并非技术失败，而是商业模式的失败。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgbt0LtubL4sgI3iamnAM89JBEB9vuDBbMNIsicj0OicG6iaGqiaAficgbGiboQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.332470892626132" data-s="300,640" data-type="png" data-w="773" type="block" data-imgfileid="503527530" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2212e39d-0d26-45a9-9daf-421c178921b4/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在过去，开源软件通过「免费软件 + 付费服务/托管」的模式生存。而在 Web 开发领域，像 Tailwind 这样的项目，其商业通常闭环是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工具开源&lt;/strong&gt;：吸引海量开发者使用&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文档引流&lt;/strong&gt;：开发者为了查阅用法访问官网&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;转化变现&lt;/strong&gt;：在官网展示高质量的付费模版和组件库&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;但在 2026 年，AI 成了用户。&lt;/p&gt;&lt;p&gt;正如 Ibryam 所言，AI 在不知不觉中使用了开源项目，但 AI 从不访问网站，从不看广告，更不可能掏出信用卡购买一套 UI 组件包。对于 AI 而言，文档只是训练数据，而非消费入口。&lt;/p&gt;&lt;p&gt;当中间的文档引流环节被 AI 截断，后端的商业转化自然归零。Tailwind 实际上变成了一个为 AI 及其背后的巨头免费提供基础设施，却无法从中获取任何价值的「假奶牛」。&lt;/p&gt;&lt;p&gt;下面展示了更多网友讨论：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgpcf0ALjPUIkkQX86PM3HgtTJ2Cib4OFIezJe9sXiasdqIvHU6ibby8O7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2857142857142857" data-s="300,640" data-type="png" data-w="791" type="block" data-imgfileid="503527529" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7bb532bb-efb5-4d9c-a519-7740a4ae0a59/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgMDw4c0nD7W0icWibfkRgOJK0ibGhmwwwibSfx5MT3DtgAz2Cx3OiafD4NMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.30828025477707005" data-s="300,640" data-type="png" data-w="785" type="block" data-imgfileid="503527531" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/3b331d5b-c730-452e-ba1c-1308d2a05956/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgoLLGUM2QGq7ABSCibgS3OkHUaonSIBsGbsERkjqLBdRr1vLVBRBic1Qg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.21546261089987326" data-s="300,640" data-type="png" data-w="789" type="block" data-imgfileid="503527532" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/bb6afca9-6920-4ea5-afe1-325f82520121/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgpCQNJliaqCUWdCic9wXiaX85KtZ7UySfQagiaNh6sQJayxpdVjJzs4YIpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.516497461928934" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527533" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/b8764fd6-e84d-4791-bd0d-c50685c34077/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有一些人分享了自己的点子，试图帮助 Tailwind 渡过难关：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgUwrFU62eCib0SF6YfsaPS24iboXhAXN4XA8llRa9nuxEJx0jUPzBQuFA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5734355044699873" data-s="300,640" data-type="png" data-w="783" type="block" data-imgfileid="503527534" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/565e39b6-0b88-413e-8518-422c2836ccc3/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgotAxavANZKZiaFbP7Jyvkkock8hE94Zt4hw3OgAzmGgMIGibWkwIvXNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.47715736040609136" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527536" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/2072c393-eb27-44b8-92d6-4f1accb046b1/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;也有人觉得 Wathan 的言语过于夸张，说是裁掉了 75% 的人，其实是裁掉了 4 人中的 3 人。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgmeTESDqZo2nnbqP3q5iacTg0akM5X0wia11dN8KnI36zY2ibknqibRaibvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.3729096989966555" data-s="300,640" data-type="png" data-w="598" type="block" data-imgfileid="503527535" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/a9f5f5cf-b3b0-42a1-8889-a65d13eab529/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;但也有网友对 Tailwind 的遭遇表达了同情和关切：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgTx9ckibC7hxaB5OdEY5JnVczcjZOnVd1flFkMxQbZI0dZice38v64Cyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.2987179487179487" data-s="300,640" data-type="png" data-w="780" type="block" data-imgfileid="503527537" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/b2ce2979-39c9-4be0-83c5-c6e4f40e7f7d/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgBcWVOKb9C7E4AynCUzia6Kor8EXtGRaIQQticy1sMYgTlnoyayXc02dQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.4844903988183161" data-s="300,640" data-type="png" data-w="677" type="block" data-imgfileid="503527538" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/ed862744-d773-4be8-8e27-034d40cb36a2/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;多家公司伸出援手&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个故事略显悲伤，但却有一个还算不错的暂时结局：Tailwind 的呼救被听到了，谷歌等多家公司伸出了援手。&lt;/p&gt;&lt;p&gt;前天，Adam Wathan 就已经在 X 上晒出了一份赞助者名单，其中可以看到 Cursor、Shopify、CodeRabbit 等多家知名 AI 和科技公司。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgq7szoQXgkngibdYDX3kxe0PH6V1qONPyz0Lyic3IPOzhceoS89RjqibgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="1.217005076142132" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527539" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/8489a1c7-37ab-49a2-a405-18203aa6f72f/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而各档位的赞助金额如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgOk4NFwnwCcK6c2HunibYG7t2MyQUViayDtVWfFVuRKgkywnpibvXt8iaVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.6203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527540" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/4e4a0631-e8e1-4c60-8117-4e774d8efa02/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;9 号上午，谷歌 AI Studio 产品负责人 Logan Kilpatrick 也宣布了赞助 Tailwind 项目（每年 5000 美元的 Partner 档位）。对于像谷歌和 Cursor 这样直接受益于高质量 AI 编程体验的公司来说，确保 Tailwind 继续维护显然符合他们的利益。毕竟，如果底层框架死了，AI 生成的代码质量也会随之下降。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgeL5YHgrsreBqvPozlRVIJwiahnGTfThWk31aTBmxy8RbyJv6bysMpNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.3059125964010283" data-s="300,640" data-type="png" data-w="778" type="block" data-imgfileid="503527541" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/3bfc0bf8-db24-47d4-8bc2-1231a0fbaabe/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，该公司前些天推出的每年 120 美元的个人订阅服务「Tailwind Insider」也已经收获了更多新客户。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgofCjd9ym87l0FmnDCVXeDGw7ou9aPYaE84UexrgTRwFEJEWKxxWqzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.12222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527542" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/b04ff4ba-d145-4f9c-93d6-b8db950afd1e/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这些赞助和收入应该可以缓解该公司的燃眉之急。至于被裁掉的工程师，也有可能会被重新招募回来。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg8Z5KDoVp8fiatCdUicxorcibsChoZVSTqyMYGo5Kgfggv9H7do6Np0iadA/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.45790816326530615" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503527543" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/17ac231f-fd2c-4620-80c5-ec7240072bbe/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但这也并不是一个十分完美的结局，Tailwind 还是需要自己努力寻找合适的商业模式，正如 Wathan 所言，这些支持让公司感到「很安心」，他们不需要被拯救，而是获得了一些喘息的时间来探索新的方向。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgB5OucGicKL0W5A7JUO2AE8sLFQxgaMjOKv96I1sW9Ko3rH7mZmo8Gkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.7936305732484077" data-s="300,640" data-type="png" data-w="785" type="block" data-imgfileid="503527544" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/b8fae2a8-3ca5-4e7e-8328-08b941b4a008/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;又或者等待被某家大公司收购？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgUasAYaKzzedTJjlKicgiaDqGLuKlcl8SBWDHXVLDiaRFPt7WV6sxaXOEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.9886075949367089" data-s="300,640" data-type="png" data-w="790" type="block" data-imgfileid="503527545" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/8112687e-0b90-4493-bf84-83737233887d/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;警钟为谁而鸣&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tailwind 的故事有了一个暂时温暖的结局，但它留给行业的思考却是有些寒冷的。&lt;/p&gt;&lt;p&gt;当 AI 能够完美地消化信息、生成代码、甚至替代交互时，所有依附于「人类注意力」和「人类访问量」的商业逻辑都面临着重构的风险。&lt;/p&gt;&lt;p&gt;对于开源维护者而言，2026 年的新课题已经摆在桌面上：当你的用户变成不知疲倦且一毛不拔的 AI 时，你该向谁收费？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>打破学科壁垒！400篇参考文献重磅综述，统一调查「人脑×Agent」记忆系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:10:06 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ee3d5c61-1547-41a6-b608-a0d0f7ff2db9/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;跨学科突破：神经科学如何让 Agent 拥有「人类式」记忆？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你是否想过 Agent 能像人类一样积累经验、不断成长？如今，这一愿景正加速走向现实。但是，现有研究要么只聚焦 AI 技术本身，要么对人脑记忆机制的借鉴浮于表面，两个学科之间始终缺少真正的灵感碰撞。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;哈工大、鹏城实验室、新加坡国立、复旦、北大&lt;/strong&gt;联合发布了一篇重磅综述&lt;strong&gt;《AI Meets Brain: A Unified Survey on Memory System from Cognitive Neuroscience to Autonomous Agents》&lt;/strong&gt;，首次打破认知神经科学与人工智能之间的学科壁垒，系统性地将人脑记忆机制与 Agents 记忆统一审视，为设计真正「类人」的 Agent 记忆系统奠定理论基石。&lt;/p&gt;&lt;p&gt;全文横跨认知神经科学与人工智能两大领域，涉猎相关文献共 400 篇。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527382" data-ratio="0.3814814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gAQQFXpYlgj1FlY3bzznK6pGHDqwAeKkhZxbRnXbwVpJousAU40QQSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5f6adbb3-e00a-4e24-9790-ebecf1f7ed51/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：http://arxiv.org/abs/2512.23343&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github 链接：https://github.com/AgentMemory/Huaman-Agent-Memory&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;什么是记忆？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综述重新定义了记忆。记忆不仅仅是数据的存储，它也是认知的纽带。综述从认知神经科学到 Agent 对记忆进行了剖析：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.认知神经科学角度：连接过去与未来的桥梁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在人脑中，&lt;strong&gt;记忆不仅仅是回放信息，其本质是大脑存储和管理信息的过程。&lt;/strong&gt;记忆是连接过去经验与未来决策的认知桥梁。它分为两个阶段：在第一阶段，当大脑获得新概念或遇到新事件时，它会快速形成特定的神经表征，同时整合和存储这些信息。在第二阶段，大脑对存储的表征进行操作，要么随着时间的推移巩固它们，要么根据类似的未来情况检索它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.LLM 视角：三种形态的并存&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于大语言模型，记忆并非单一的存储结构，而是表现为三种形式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数记忆（Parametric Memory）&lt;/strong&gt;：内化在神经网络权重中的知识，对应人类的抽象长期记忆。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工作记忆（Working Memory）&lt;/strong&gt;：基于上下文窗口，负责实时推理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;显式外部记忆（Explicit External Memory）&lt;/strong&gt;： RAG 是典型代表，通过解耦计算与存储，使 LLM 从「知识库」变为「知识调度器」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3.Agent 视角：从存储到认知的跃迁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent 的记忆超越了 LLM 的简单存储，它是一个动态的认知架构，该综述选择沿着三个核心维度解构记忆：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;结构化存储&lt;/strong&gt;：旨在将非结构化自然语言交互转换为易于机器索引和理解的有效格式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;动态调度&lt;/strong&gt;：解决了有限的注意力资源和大量记忆存储之间的冲突，模拟了人脑的遗忘与唤醒机制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;认知进化&lt;/strong&gt;：Agent 必须深入反思、抽象和重组记忆内容，从而推动其行为策略的持续更新。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Agent Memory vs RAG&lt;/strong&gt;：传统的 RAG 侧重于将 LLM 连接到静态的知识库进行查询，而 Agent Memory 是嵌入在 Agent 与其环境之间的动态交互过程中，不断地将 Agent 操作和环境反馈生成的信息合并到记忆容器中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;记忆有何用？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在认知神经科学中，记忆构成了大脑编码、存储和检索信息的神经过程，使个体能够保留过去的经验并利用它们来指导正在进行的行为并为未来的决策提供信息。&lt;/p&gt;&lt;p&gt;在 LLM 驱动的 Agent 中，模型原生的无状态性与复杂、长期任务所需的连续性需求之间存在着天然的鸿沟。因此，记忆超越了其作为桥接历史交互的被动存储库的角色，而是充当 Agent 认知架构中的关键主动组件。因此，给 Agent 装上记忆系统，并非只是为了记住，而是为了实现三大核心作用：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527383" data-ratio="0.5555555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g7QFIGjBHHHuia4SicgraNicgjoE9WSa5r3Djb0ErNxweBWLR8HybCcEicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3ef56602-9912-48c7-ba7d-aa9aca19e02b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1. 记忆通过减轻上下文窗口限制、实现长期个性化以及驱动基于经验的推理来扩展 Agent 的能力。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.突破上下文窗口的限制&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;启发式上下文设计&lt;/strong&gt;：通过设计启发式规则来管理记忆。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自主记忆优化&lt;/strong&gt;：让 Agent 把记忆管理提升为可学习的内在能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.构建长期个性化画像：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;画像构建&lt;/strong&gt;：&amp;nbsp;Agent 能从碎片化的历史对话中，提炼出你的核心特质和信息。它不仅会记录发生了什么，还会定期反思，推测你话语背后的潜在动机，从而在脑海中建立一个个性化档案。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;偏好对齐执行&lt;/strong&gt;：当 Agent 替你执行任务时，记忆库会充当隐形指挥棒。不需要反复叮嘱，它会自动调用记忆中的偏好约束决策。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3.驱动基于经验的推理：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;战略指导&lt;/strong&gt;：检索历史上相似的成功案例或从中提炼的高层经验，指导当前的决策，避免重蹈覆辙。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;程序固化&lt;/strong&gt;：将成功的推理过程转化为可复用的技能或可执行的结构。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;记忆的分类学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在谈论 Agent 记忆的分类之前，综述首先梳理了认知神经科学对记忆的经典定义。&lt;strong&gt;人脑的记忆并不是一个单一的黑盒，而是一个分工明确的复杂系统。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.基于认知神经科学的分类：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;记忆的概念最初源于认知神经科学，它被广泛地定义为大脑存储和管理信息的认知过程，允许在原始刺激或事件不再存在后访问和使用这些信息，通常分为短期记忆和长期记忆。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.短期记忆&lt;/strong&gt;&lt;strong&gt;（Short-term Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：大脑的临时工作台。它负责在极短的时间窗口（约 15～20 秒）内维持和处理信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征&lt;/strong&gt;：容量非常有限（通常只能容纳 4～9 个单位的信息）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.长期记忆&lt;/strong&gt;&lt;strong&gt;（Long-term Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：大脑的永久档案馆。它可以存储从几分钟到几十年的信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征&lt;/strong&gt;：没有严格的容量限制，且结构高度组织化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长期记忆可继续分为情景记忆和语义记忆&lt;/strong&gt;：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;情景记忆（Episodic Memory）&lt;/strong&gt;：指对个人亲身经历过的特定事件的记忆。此类记忆通常不仅包括有关事件本身的详细信息，还包括其时间和空间背景，即事件发生的时间和地点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;语义记忆（Semantic Memory）&lt;/strong&gt;：指对所学事实知识、概念和规则的记忆。这些记忆与获取的特定时间和地点无关，并且它们的检索并不伴随着对过去特定事件的生动重新体验。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;2.Agent 的双维度记忆分类&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综述中指出，连贯的记忆分类对于系统地理解和设计 Agent 系统中的记忆机制至关重要。为了适应复杂的自主任务，综述提出了一套双维度的分类法。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527384" data-ratio="0.5824074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gDnyWkmWpicHybMpkNDbmsXSsia0825054RlcM7txMKKgsaRjLGJcE4LA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/45143a0f-847d-4993-9d0c-02627cd95664/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2. (a) 基于性质的分类法，根据编码的信息类型对记忆进行分类。 (b) 基于范围的分类，根据记忆的应用范围来区分。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（1）.基于「性质」的分类（Nature-based）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是直接对齐人脑「情景和语义」的分类方式，决定了 Agent 在推理时使用的是「经验」还是「知识」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.情景记忆（Episodic Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：任务式数据库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：完整的交互轨迹（Trajectory）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：提供过程性知识，即「How to」&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.语义记忆（Semantic Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：存储 Agent 的知识库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：事实、概念、规则和常识&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：提供陈述性知识，即「What-is」&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;（2）.基于「范围」的分类 (Scope-based)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是基于记忆在任务流中的生命周期和适用范围进行的划分。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.轨迹内记忆（Inside-trail Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：临时工作区&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：当前任务的中间步骤、临时变量和即时的观察结果&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;作用域&lt;/strong&gt;：仅在当前任务或会话中有效&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;：用完即走。当情景结束时，该记忆通常会被清除或重置&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.跨轨迹记忆（Cross-trail Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：永久存储库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：可概括的模式、学习的策略、可重用的知识&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;作用域&lt;/strong&gt;：跨越多个任务、多个对话，甚至跨越 Agent 的整个生命周期&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：提供陈述性知识，即「What-is」&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;记忆的存储机制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;记忆存储的关键在于记忆的存储位置和记忆的存储形式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.认知神经科学中的记忆存储&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在人脑中，记忆存储是一个跨脑区的动态协作过程。&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;短期记忆&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储位置&lt;/strong&gt;：分布在感觉皮层和额顶网络（Sensory-frontoparietal network）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机制&lt;/strong&gt;：感觉皮层保留细节，额顶网络支持跨模式表示，允许不同通道信息在共享表示空间中链接和操作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储形式&lt;/strong&gt;：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;持续活动（Persistent activity）&lt;/strong&gt;：保持高水平的放电活动&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;活动 - 沉默突触连接（Synaptic connection weights）&lt;/strong&gt;：仍可能有用的项目可以默默存储并在需要时重新激活&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;长期记忆&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储位置&lt;/strong&gt;：海马体（Hippocampus） + 新皮层（Neocortex）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机制&lt;/strong&gt;：海马体不是仓库，而是索引。新机制先在海马体暂存，通过系统巩固，慢慢转移到新皮层这个永久仓库中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储形式&lt;/strong&gt;：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;事件单元（Event-based unit）&lt;/strong&gt;：把连续的生活切片成一个个独立的事件包。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;认知地图（Cognitive map）&lt;/strong&gt;：人脑把概念和知识也画成了地图，通过认知距离表示关系的远近。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527385" data-ratio="0.6268518518518519" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g3ALiaQM4nySjBpqqHapr2qEWUQZib2lZq2azr0ibUxmS3ApVcGcziaFfTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/255c0ed1-d8ac-446c-a8d8-7e2e699a7606/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 3. 认知神经科学中的记忆存储机制概述，包括短期和长期记忆的存储位置和存储格式。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.Agent 中的记忆存储&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于人脑浑然天成的神经网络，Agent 的记忆系统是显式的工程构建。不仅要解决存在哪的物理限制，还要在怎么存上进行复杂的数据结构选型，以在计算成本和推理能力之间寻找最优解。&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;存储位置&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;上下文窗口（Context Window）&lt;/strong&gt;：对应轨迹内记忆。主要存放当前的对话流。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;记忆库（Memory Bank）&lt;/strong&gt;：对应跨轨迹记忆。外挂的存储库，容量近似无限。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;存储形式&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文本（Text）&lt;/strong&gt;：自然语言形式，比较直观&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;图结构（Graph）&lt;/strong&gt;：实体和关系组成的结构化网络，支持关系提取和模式发现，能够识别节点之间的隐式链接，从而辅助复杂的逻辑信息查询&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数（Parameters）&lt;/strong&gt;：模型权重，通过训练内化记忆&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;隐式表示（Latent Representation）&lt;/strong&gt;：高维向量，检索速度快&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;记忆的管理系统&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;记忆不是一个静态的仓库，而是一条奔流不息的河流&lt;/strong&gt;。在人类大脑中，记忆通过海马体的重播和新皮层的巩固，不断被重写和重构。而在 Agent 中，记忆管理则是提取（Extraction）、更新（Updating）、检索（Retrieval）、应用（Application）的精密闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.认知神经科学：大脑的动态循环&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人脑的记忆管理不是简单的「写入」和「读取」，而是一个充满可塑性的动态过程。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527386" data-ratio="0.6611111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gGdKBIEurjKy7q2PfKGhd4Y0DictJldDUYLrozkExENvuQr4sicEOib4xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/67911d58-4ae8-466b-8347-4e1f1dee62d6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4. 认知神经科学中的记忆管理概述。该框架阐释了信息处理的动态循环，包括记忆形成、更新和检索，通过这个循环，长期记忆支持对外部环境的灵活适应。&lt;/sup&gt;&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;p&gt;记忆形成（Memory Formation）&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;记忆并非一蹴而就，它经历了三个阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;编码（Encoding）&lt;/strong&gt;：海马体将新皮层内分布的感觉特征结合成统一的表征，并选择性地调节其与感觉皮层的相互作用，以放大未来高效用的表征。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;巩固（Consolidation）&lt;/strong&gt;：在清醒休息或睡眠等离线状态下，海马体通过重播，不断与新皮层同步活动，重新组织和调整新信息，使其稳定下来。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;整合（Integration）&lt;/strong&gt;：通过海马体与内侧前额叶皮层的协作，将巩固的记忆痕迹转化为有组织的关联知识，并最终将其重新分配至新皮层以实现持久的抽象存储。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆更新（Memory Updating）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;大脑如何修正错误的记忆？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机制&lt;/strong&gt;：预测误差（Prediction Error）是核心驱动力。当发现现实与记忆不符，大脑就会触发更新机制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;策略&lt;/strong&gt;：分化是为相似的新旧事件建立互斥的神经表征，防止混淆。整合是将新旧知识与预测误差整合为一体。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆检索（Memory Retrieval）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;检索即重构。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;重构性&lt;/strong&gt;：回忆不是回放录像，而是根据线索（Cue）利用海马体进行模式完成（Pattern Completion），重新构建当时的场景。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;再巩固（Reconsolidation）&lt;/strong&gt;：每当回忆一次，这段记忆就会变得不稳定，容易被修改或增强。这也解释了为什么 &amp;ldquo;常回忆&amp;rdquo; 能加深记忆，但也可能会植入虚假细节。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.Agent 记忆管理：记忆管理的精密闭环&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与在受限窗口内执行瞬态处理的标准大语言模型不同，Agent 通过显式管理机制实现体验的持久调节。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527388" data-ratio="0.4722222222222222" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69ghHCB3acmTU9YiacKtfRjd7RfOn0a7C2yEd7dVhmP0oBq13ng4ibrw7CA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/dac32bed-f2cc-4583-bb59-c893f18a551a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5. Agent 中记忆管理的概述。该框架形成了一个由记忆提取、更新、检索和利用组成的闭环管道，从而实现持久的经验调节和长期推理。&lt;/sup&gt;&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;p&gt;记忆提取（Memory Extraction）&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Agent 不能把所有 Log 都存下来，它需要提炼：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;扁平提取（Flat）&lt;/strong&gt;：直接将原始信息记录到存储中或应用摘要和分段等轻量级预处理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分层提取（Hierarchical）&lt;/strong&gt;：通过多粒度抽象机制将碎片化信息组织成层次结构，旨在模拟人类在宏观背景和微观细节之间灵活切换的认知能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;生成式提取（Generative）&lt;/strong&gt;：旨在在推理过程中动态重建上下文，从而缓解因过大上下文长度带来的计算开销和注意力稀释问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆更新（Memory Updating）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;遗忘是为了更好地记住，更新机制分为两层：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;轨迹内更新（Inside-Trial）&lt;/strong&gt;：针对上下文窗口，像人类选择性注意一样，实时过滤无关噪声，或在窗口快满时触发摘要工具，腾出工具。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨轨迹更新（Cross-Trial）&lt;/strong&gt;：针对外部记忆库，引入遗忘机制，自动剔除低价值或长时间未访问的记忆节点。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆检索（Memory Retrieval）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;不仅仅是 Embedding 的相似度，主要分为两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基于相似度（Similarity-based）&lt;/strong&gt;：计算余弦相似度，找 Top-k，但相当于只懂字面意思，不懂逻辑结构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多因素检索（Multi-factor）&lt;/strong&gt;：根据时间、重要性、相关性，结构效率和预期奖励等因素确定记忆优先级&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆应用（Memory Application）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;记忆怎么用，主要有两种作用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;上下文利用（Context Utilization）&lt;/strong&gt;：将记忆视为被动参考的传统检索增强生成范式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数内化（Parameter Internalization）&lt;/strong&gt;：该范式借鉴终身学习将显性记忆转化为隐性参数。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Agent 记忆系统评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综述将现有的 Benchmark 分为了两类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;面向语义（Semantic-oriented）&lt;/strong&gt;：重点关注 Agent 如何构建、维护和利用其内部记忆中的信息状态。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;面向情景（Episodic-oriented）&lt;/strong&gt;：旨在评估复杂下游应用场景（使用外部工具完成任务）中 Agent 上记忆系统的实际性能增益。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527389" data-ratio="0.7037037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69guJLTCHXeIFOWH7MpRlY7IsphWwc6BhViahK1z7CbAZt8jQmrb9aoc9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/881950d9-e24e-49aa-bef3-f8aa5b8db653/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表 1. 面向语义的基准&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527390" data-ratio="0.3037037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gFuPufDxtdPmLDePiaDVCOMr8ib5UpeDZayGvRCnKMQxrKOWISJJNDe4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/6d8d98d3-f1ea-4660-8ae5-d2a81793c671/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表 2. 面向情景的基准&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 记忆的安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 攻击&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着 Agent 被部署在长期任务中，记忆成为了攻击。其主要的攻击方式分为两类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;窃取攻击（Extraction-based Attack）&lt;/strong&gt;：把隐私「套」出来，攻击者的目标是 &amp;ldquo;偷数据&amp;rdquo;，其手段是利用精心设计的 Prompt 诱导 Agent。例如，黑客可能伪装成系统管理员，套取 Agent 长期记忆中存储的用户敏感信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;投毒攻击（Poisoning-based Attack）&lt;/strong&gt;：把思想「改变」，攻击者的目标是「坏脑子」。首先第一种是后门植入：向记忆库中注入带有「触发器」的恶意数据，平时 Agent 表现正常，一旦遇到特定的指令，就会触发恶意行为。其次是注入大量噪声或偏见数据的认知污染：让 Agent 的判断力退化，变得糊涂或产生严重的价值观偏差。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 防御&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对这些威胁，综述提出了有三道防线，构筑起从源头到输出的闭环防御体系。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;检索防御（Retrieval-based）&lt;/strong&gt;：在 Agent 读取记忆之前进行清洗。例如，通过多路检索验证一致性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;响应防御（Response-based）&lt;/strong&gt;：在 Agent 生成回答时进行监控。通过引入审查机制或利用自我反思机制，在输出前预测潜在后果，拦截包含恶意意图的响应。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;隐私防御（Privacy-based）&lt;/strong&gt;：在底层存储上做文章。将记忆分为「公有」和「私有」区域，对敏感数据进行匿名化处理，确保了 Agent 在协作时只传递必要信息，不泄露核心隐私。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;未来展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.多模态记忆&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;未来的 Agent Memory 需要打破模态的界限。目前的 Agent 在面对视频、音频等非结构化数据时，往往采用「暴力压缩」或「转写为文字」的方式，这会导致大量丰富的视觉细节（如微表情、光影变化）和听觉情感在转换中丢失。未来的记忆系统应该是&lt;strong&gt;全模态 (Omni-modal) &lt;/strong&gt;的，不仅存文本，还存储压缩后的视觉 / 听觉特征向量，其终极目标是使 Agent 不仅能「读」懂，还能「看」见，真正理解物理世界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.Agent Skills&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现在的 Agent memory 往往是孤立。训练好一个专为写代码的 Agent，它的经验（记忆）很难直接传给另一个专为数学的 Agent，这导致了严重的重复造轮子。&lt;/p&gt;&lt;p&gt;这是因为不同的 Agent 之间的异构性，导致记忆接口的不一致，因此记忆很难直接移植重用。论文借用了 Anthropic 提出的「Agent Skills」概念，即 Agent 将指令集、可执行脚本和相关资源封装到结构化目录单元中。这就好比游戏里的「装备」或「技能书」可以在不同玩家间重复使用。&lt;/p&gt;&lt;p&gt;综述提出两个可能的未来研究方向：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多模态信息的统一存储与表示&lt;/strong&gt;：当前的记忆系统主要是为文本形式设计的。如何构建支持多模态信息的统一存储框架，包括文本、图像、音频和视频，同时设计跨模态检索和推理机制，是支持跨模态 skills 迁移的关键。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨 Agent 的 skills 转移和适应机制&lt;/strong&gt;：不同的 Agent 结构，例如那些建立在不同基础模型上的 Agent，表现出差异在能力特征和接口规范方面。设计通用的 skills 描述语言，使 skills 能够无缝地转移并且跨异构代理的重用构成了实现真实代理的关键挑战 skill-sharing 生态系统。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>DeepSeek-OCR是「长文本理解」未来方向？中科院新基准VTCBench给出答案</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 20:56:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ab84ca9b-ce9c-42f0-9e42-757e7fd6dbe7/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;DeepSeek-OCR 的视觉文本压缩（VTC）技术通过将文本编码为视觉 Token，实现高达 10 倍的压缩率，大幅降低大模型处理长文本的成本。但是，视觉语言模型能否理解压缩后的高密度信息？中科院自动化所等推出 VTCBench 基准测试，评估模型在视觉空间中的认知极限，包括信息检索、关联推理和长期记忆三大任务。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;近期，DeepSeek-OCR 凭借其创新的「视觉文本压缩」（Vision-Text Compression, VTC）范式引发了技术圈的高度关注，以极少的视觉 Token 实现高效的文本信息编码，为长文本处理开辟了新路径。&lt;/p&gt;&lt;p&gt;这一突破性进展让大模型处理超长文本的成本大幅降低，但也抛出了一个核心问题：&lt;strong&gt;当长文本被高度压缩为 2D 图像后，视觉语言模型（VLM）真的能理解其中的内容吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解答这一疑问，来自&lt;strong&gt;中科院自动化所、中国科学院香港创新研究院等机构的研究团队推出了首个专门针对视觉 - 文本压缩范式的基准测试 &amp;mdash;&amp;mdash;VTCBench。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gSLXEev4kibGvoBtcNDzn1cfy4GxNAeyTQjMeZL7xVxtuYHk70iaQibChA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527415" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/96c6a5f7-d28c-4bb3-a93d-d6979ab7c73c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2512.15649&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VTCBench 链接: https://github.com/Moenupa/VTCBench&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VLMEvalKit 链接：https://github.com/bjzhb666/VLMEvalKit&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Huggingface 链接: https://huggingface.co/datasets/MLLM-CL/VTCBench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527417" data-ratio="0.3194444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gxV4xsUQM34fZghJkhUV4nO9BrsQEWlYIGP2Xv3C5OcPicwiahy5uyHSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bf625483-9a68-4fbb-9632-2731679aa28a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：视觉 - 文本压缩 (VTC) 流程演示及 VTCBench&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;与传统大模型直接读取成千上万的纯文本 Token 不同，VTC 范式（如 DeepSeek-OCR）先将长文档渲染 （Rendering）为高密度的 2D 图像，再由视觉编码器转化为少量的视觉 Token。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;该技术可实现 2 倍至 10 倍的 Token 压缩率&lt;/strong&gt;，显著降低了长文本处理时的计算与显存开销。&lt;/p&gt;&lt;p&gt;VTCBench 现已在 GitHub 和 Huggingface 全面开源，其衍生版本 VTCBench-Wild 是一个统一的、全方位评估模型在复杂现实场景下视觉文本压缩的鲁棒性，现已集成到 VLMevalkit。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心使命&amp;mdash;&amp;mdash;衡量「看得见」之后的「看得懂」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前的 VLM 也许能出色地完成 OCR 识别，但在处理 VTC 压缩后的高密度信息时，其长文本理解能力仍存疑。&lt;/p&gt;&lt;p&gt;VTCBench 通过三大任务，系统性地评估模型在视觉空间中的认知极限：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Retrieval (信息检索)&lt;/strong&gt;：在视觉「大海」中寻找特定事实的「针」（Needle-in-a-Haystack），测试模型对空间分布信息的捕捉能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Reasoning (关联推理)&lt;/strong&gt;：挑战模型在几乎没有文本重叠的情况下，通过关联推理寻找事实，超越单纯的词汇检索；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Memory (长期记忆)&lt;/strong&gt;：模拟超长对话，评估模型在视觉压缩框架下，抵御时间与结构性信息衰减的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此外，团队同步推出了 VTCBench-Wild，引入 99 种不同的渲染配置（涵盖多种字体、字号、行高及背景），全方位检测模型在复杂现实场景下的鲁棒性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;揭秘视觉压缩背后的认知瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gbqrAOxuCJGZ1Xnwp3zSfibIEjZLFF2Niaiatv1O6308L9nkBA3Riag1BdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.36574074074074076" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527427" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d0a7a926-9533-43de-bd7c-2dca5f7bdc2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：VTCBench 针对模型在长图像中检索信息的热力图。横轴代表上下文长度，纵轴代表关键事实（Needle）在文档中的深度。展现了模型表现的「迷失」与突破。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;测试结果呈现出显著的 「U 型曲线」：与文本模型类似，视觉语言模型（VLM）能够精准捕捉开头和结尾的信息，但对于中间部分的事实，理解能力会随着文档变长而剧烈衰退。&lt;/p&gt;&lt;p&gt;这证明了&lt;strong&gt;即使在视觉空间，模型依然存在严重的「空间注意力偏见」，是未来 VTC 架构优化的关键方向。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行业洞察 &amp;mdash;&amp;mdash; 视觉压缩是长文本的终局吗？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527430" data-ratio="0.7342592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gjbrkawkian3iaRV30iaJceVDLc31ZQckxIB07M1GBIHt3cTqNtv4BZTOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d9770352-f624-427e-bd65-4fe473d74555/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;通过对 GPT、Gemini、Claude、QwenVL、InternVL、Gemma、KimiVL、Seed1.5 等 10 余种尖端模型的深度评测，可以发现：&lt;/p&gt;&lt;p&gt;虽然 VTC 极大提升了效率，但现有 VLM 在复杂推理和记忆任务上的表现仍显著弱于纯文本 LLM；&lt;/p&gt;&lt;p&gt;消融实验证明，&lt;strong&gt;信息密度是决定模型性能的关键因素，直接影响视觉编码器的识别精度；&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini-3-Pro 在 VTCBench-Wild 上表现惊艳，其视觉理解能力已几乎追平其纯文本基准，证明了 VTC 是实现大规模长文本处理的极其可行的路径！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说传统的长文本处理是「逐字阅读」，那么， DeepSeek-OCR 所引领的 VTC 范式就是「过目成诵」的摄影式记忆。&lt;strong&gt;VTCBench 的出现，正是为了确保模型在拥有这种「超能力」的同时，依然能够读懂字里行间的微言大义。&lt;/strong&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
