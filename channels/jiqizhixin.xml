<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>从「被动」到「主动」，为什么给耳机装上「眼睛」后AI范式变了？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 14:44:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/76faa914-85ab-4639-b140-468b4bef28ab/1767508636102.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;h4&gt;先行一步&lt;/h4&gt;&lt;p&gt;Sam Altman 与 Jony Ive 联手探索的无屏 AI 硬件，正在被逐步揭开。供应链信息显示，这款产品并没有选择屏幕，而更像是一种可穿戴设备：体积接近 iPod Shuffle，可以放入口袋或随身佩戴；内置麦克风与摄像头，持续感知用户所处的真实环境，与之并肩工作，主动给出建议。&lt;/p&gt;&lt;p&gt;在「无屏、主动式 AI」这条路径上，中国公司其实已经先行一步。&lt;/p&gt;&lt;p&gt;12 月底，光帆科技在北京发布了 Lightwear AI 全感穿戴设备。这是一套由 AI 耳机、智能手表以及设计独特的充电盒组成的组合式终端。其中，AI 耳机也是全球首款具备视觉感知能力的主动式 AI 耳机。&lt;/p&gt;&lt;p&gt;三款设备实时协同，扮演一个「始终在场」的 AI 助理 ，与你一同观察世界，并主动参与日常生活与决策。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526619" data-ratio="0.6330935251798561" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvhMxvDpLfFpAEAcCFBCISzgia3Fj2GbUAR8J4ibiaPv0MWe0n4U22RlndA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="556" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1529d019-91c2-4d8f-9374-2f07fafa078e/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;des&gt;Lightwear AI 全感穿戴设备，这是一个由 AI 耳机、智能手表以及设计独特的充电盒组成的套装。&lt;/des&gt;&lt;p&gt;「喂，晓帆。」一名戴着耳机的女孩在超市里购物，拿起一瓶饮料，随口喊了一句。发布会现场，出现了这样一个场景。&lt;/p&gt;&lt;p&gt;「在呢。」 隐身在耳机里的 AI 助理被唤醒。&lt;/p&gt;&lt;p&gt;「这个在网上咋卖？」女孩问。AI 「看」了一眼她手中的商品：识别出商品名称，随即在网上搜索同款价格 &amp;mdash;&amp;mdash;500 毫升 15 瓶，57.9 元，更便宜。&lt;/p&gt;&lt;p&gt;在女孩的确认下，AI 直接完成下单。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvd9lefoRI8wMagiasbJ5X3MXZzexRPWzIicmYyxGBdKucbpjDeiawNIIHQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.4981949458483754" data-s="300,640" data-type="jpeg" data-w="831" type="block" data-imgfileid="503526618" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6fab65ae-bc54-4225-9f82-2902dd8a3cc2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;des&gt;耳机黑色部分就是 AI 的眼睛，为 AI 提供视觉感知的摄像头。&lt;/des&gt;&lt;p&gt;类似的主动能力，并不只体现在购物场景中。耳机盒内置 GPS，当用户快到家时，晓帆会主动提醒有快递要取。&lt;/p&gt;&lt;p&gt;在另一个更长任务的演示中，用户只用表达需求，AI 主动把事情完成，并告诉你结果，中间沟通个一两次就行。&lt;/p&gt;&lt;p&gt;整个流程从一句「XX 问你什么时候有空和王总吃饭」开始。晓帆自动检查日程冲突，发现约饭时间与一场产品会议重叠后，按用户要求调整了会议安排。&lt;/p&gt;&lt;p&gt;随后，它继续主动询问是否需要一并处理机票和酒店：机票按照「再早一点」的要求重新预订；酒店则直接按「常住的那一家」定了两晚。&lt;/p&gt;&lt;p&gt;这些场景，都映射出光帆科技试图呈现的主动式 AI 雏形。&lt;/p&gt;&lt;p&gt;发布会之后，这家创业公司也迅速受到关注。其创始人董红光是小米早期员工（第 89 号），长期负责操作系统与智能化相关核心工作，几乎贯穿了小米多个关键技术阶段。成立仅一年多时间，光帆科技便吸引了一批颇具分量的投资机构入局，也为这条「无屏、主动式 AI」路径增添了更多现实注脚。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvTHxwSz9as1HXDtTA5dwS1bqdL9iaVoN4PiaoXFiaDXpV2nUQeCUXWa31A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6658653846153846" data-s="300,640" data-type="png" data-w="832" type="block" data-imgfileid="503526620" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f9f51a58-3d52-4be6-a015-d4f81846504d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;AI 硬件大爆发，被动式 AI 面临挑战&lt;/h4&gt;&lt;p&gt;在光帆科技压轴登场之前，仅在 2025 年这一年里，全球范围内就已密集涌现出一批 AI 硬件产品。阿里推出夸克 AI 眼镜，字节加码 AI 耳机、AI 手机，同时还有 AI Pin、戒指、项链、手环等更具「脑洞」的新形态。&lt;/p&gt;&lt;p&gt;AI 正在加速脱离屏幕，为自己寻找新的「肉身」。而这场 「物种大爆发」，并非偶然。&lt;/p&gt;&lt;p&gt;一方面，大模型能力持续跃迁，终于能够支撑复杂场景的理解，以及长链路任务的稳定执行（如 AI Agent）；响应速度也被拉进「1 秒俱乐部」，交互体感开始逼近真人对话。&lt;/p&gt;&lt;p&gt;另一方面，推理与部署成本持续下探，再叠加中国在制造与供应链上的系统性优势，让中国玩家在这一轮 AI 硬件竞赛中显得尤为活跃。&lt;/p&gt;&lt;p&gt;但问题，也同样清晰。&lt;/p&gt;&lt;p&gt;大多数 AI 硬件已经足够贴身，却并不「始终在场」；看起来随时可用，却仍在等待一道清晰的命令。这依然是一种被动式智能，存在认知摩擦。&lt;/p&gt;&lt;p&gt;比如，你需要先掏出手机、打开 App，再用近乎「产品经理式」的方式，把真实需求拆解成一段段包含关键词的 Prompt；又或者，只有在你主动提问「这是什么？」时，AI 眼镜才会启动识别并给出反馈。至于耳机，更是高度依赖语音唤醒和明确指令。&lt;/p&gt;&lt;p&gt;主动式智能正试图消除的就是这种负担。它会持续进行云端计算，感知、理解用户所处的情境（「你现在在超市」）+ 记忆（「你记得要买果汁」），在合适的时机（「你路过商店」），在你尚未开口之前主动介入 &amp;mdash;&amp;mdash;「别忘了，顺手买果汁。」&lt;/p&gt;&lt;p&gt;事实上，谷歌的 Project Astra 一直在尝试构建这样一个主动的 AI 助手：拥有眼睛、耳朵和声音，能够与你共处、理解你正在经历的世界。这与光帆科技所追求的、带有「活人感」的 AI 助理 &amp;mdash;&amp;mdash; 全天候、全感知、主动智能 &amp;mdash;&amp;mdash; 在理念上高度一致。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvJuMc47djI1LmLHU1nFJ76utuQo6NKJOxR5a79ID58twJcYljdriciaSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5755395683453237" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526621" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4e41af5d-9ebd-4830-9984-2c2f5094b93b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;只不过，Project Astra 尚未脱离手机；而光帆科技的选择，是让 AI 不再依附于手机、建立新的交互范式。但是，这样的 AI 硬件，究竟该如何搭建？&lt;/p&gt;&lt;p&gt;他们先从「AI 需要感知什么、怎么感知」出发，逐步决定是否要做加法、怎么加。&lt;/p&gt;&lt;h4&gt;「看得见」，是主动智能的门票&lt;/h4&gt;&lt;p&gt;在硬件形态上，光帆科技没有选择已有手机做加法，或是更为主流的眼镜，而是对耳机进行「改造」，在上面装上摄像头。看似反直觉的选择背后，隐藏着他们的清晰认知：视觉感知，是主动智能的门票。&lt;/p&gt;&lt;p&gt;而要做到随时看、随时听、随时跟用户说话，手机和眼镜很难满足。&lt;/p&gt;&lt;p&gt;手机，是为触控交互而生，依赖显式唤醒、依赖用户主动将注意力集中到一块屏幕上，从根本上限制了 AI 的「持续观察力」。而且，手机大部分时间都放在口袋里，无法主动感知，用户也无法随时与之交流。&lt;/p&gt;&lt;p&gt;眼镜似乎更为自然，包括 AI 大厂和初创都很看好，但从长期来看，也并非「最优解」。&lt;/p&gt;&lt;p&gt;首先，在用户接受度上就不太友好，尤其是很多非近视人群根本没有戴眼镜的习惯，而且重。技术层面，精密结构下，电池容量、重量、功耗（尤其叠加 AR 后）之后，很难平衡。而一旦进入「持续视觉扫描」状态，摄像头正对路人，隐私与伦理压力几乎不可避免。&lt;/p&gt;&lt;p&gt;耳机就不同了。用户体量大、接受度高、佩戴自然，选择给耳机装上摄像头，并非简单的硬件堆砌，而是一套围绕感知能力的重构 &amp;mdash;&amp;mdash; 在耳机已有听觉感知的基础上，在左右耳塞各置一枚 200 万像素摄像头，实现双目视觉感知，并配合充电盒进行辅助定位。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvgXLzlDCTasHxr4jibb9fJmibpGHHTdNwKc0N3pbS43fdDzGHiaEEve4ng/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6258992805755396" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526622" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3ecfe787-2b3b-4cad-b353-93f23075b30e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这里的摄像头拍摄，不是给人看，是让 AI「看」，用以理解物理世界的空间与物体，支持「阅后即焚」，不必担心隐私问题。&lt;/p&gt;&lt;p&gt;只有 200 万像素，其实是蕴含着一个重要的「低像素哲学」：更强调「语义理解」而非「光学美感」，AI 无需欣赏 4K 画质的电影，只需要能分辨出用户手中拿的是橙汁、咖啡，还是药品，就足够了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvoRkmsicfgkc6mwz0Dd9kcnatR0SxGTTON3FEAm9icVqOkdRFFicdIEzKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.697841726618705" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526623" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/2f4b7ac4-878c-4835-9986-8951da2a4006/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;真正的关键在于 &amp;mdash;&amp;mdash; 只叠加了一个「视觉感知」，一切都因此而变得不同，因为，视觉是「主动性」的唯一基石。&lt;/p&gt;&lt;p&gt;主动智能的本质，在于主动感知环境、理解上下文并预测行动时机。而这一能力首先依赖对真实世界空间结构、物体关系与动态变化的持续感知，这些关键信息只有视觉能够提供。&lt;/p&gt;&lt;p&gt;而耳机「双目」的视觉高度，恰好与人类视野持平 &amp;mdash;&amp;mdash; 你看到什么，它就看到什么。于是，AI 可以实时理解你所处的情境，建立稳定的世界模型，判断你的关注焦点，形成「共同注意力」。&lt;/p&gt;&lt;p&gt;没有视觉，AI 无法真正理解世界；没有世界模型，就不可能有真正的主动协作。语音、记忆、推理，只有嵌入视觉框架，才会产生质变。&lt;/p&gt;&lt;p&gt;比如，当用户在路过超市时，AI「看到」用户所处的环境，其「记忆」模块才能被激活，主动发出提醒，「该买橙汁了。」&lt;/p&gt;&lt;p&gt;当用户看到心仪餐厅，想要进一步了解，发出「帮我看下这家餐厅怎么样」的提问指令时，AI 只有「看到」餐厅后，才能启动实现个性化口味比对、附近更优餐厅推荐、餐厅位置准确告知等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvPc8lgnqGu3OV5EYpia9kPYUF675JJSB4lgRC72iaKUibibeibDNUNACqib0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5503597122302158" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526624" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/d15a90d5-85a6-4809-9d39-5b1b5baf1ccb/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;从单兵作战到多感官协同，主动智能的必经之路&lt;/h4&gt;&lt;p&gt;要实现真正的主动式 AI，只「薅」一个硬件显然不够。&lt;/p&gt;&lt;p&gt;哪怕是最核心的耳机，也会不可避免地面临感知盲区 &amp;mdash;&amp;mdash; 比如身体出现异常，AI 根本无从得知。&lt;/p&gt;&lt;p&gt;更现实的问题是，人在睡觉、洗澡、刚起床等场景下，并不会持续佩戴耳机；一些关键信息，也很难长期依赖记忆来维持。&lt;/p&gt;&lt;p&gt;只有走向多感官协同，主动智能才可能真正成立，并逐步逼近全天候、全感知的状态。基于这一判断，在为耳机补上视觉能力之外，光帆科技还为系统引入了一块手表：耳机负责「听」和「看」，手表负责「显示」和「触控」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvbPYzcEXXqhj8yiaUX61shz8mh7lINxvNga4PuOfD18kdN2NESvIDfiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6942446043165468" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526625" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3ccd22bd-06ea-48ef-9e98-d8b853b5a714/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;首先，手表补齐了语音交互的短板。&lt;/p&gt;&lt;p&gt;那些并不适合通过声音完成的信息交互 &amp;mdash;&amp;mdash; 例如购物验证码、导航定位、简单提示 &amp;mdash;&amp;mdash; 可以直接在屏幕上呈现，降低打扰，也提升效率。&lt;/p&gt;&lt;p&gt;更关键的是，手表本身是一枚持续工作的身体传感器。&lt;/p&gt;&lt;p&gt;如果 AI 想要更主动、更贴近个体，就必须理解「人」的状态，而不仅仅是环境。通过持续采集心率、血氧、睡眠、压力等数据，AI 才能感知身体变化，并在合适的时刻给出针对性的提醒与建议。例如在运动中心率异常升高时，主动介入。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tv6rJ99B3uRWXRQFUO2VTNwy2n1xhxeHcVjPQiasr2ZRsIPUdA2buqmcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6546762589928058" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526626" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/893704d9-c217-4d21-870b-cedb0886aa90/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;与此同时，光帆科技还对耳机充电盒进行了功能重构。&lt;/p&gt;&lt;p&gt;它内置 2020mAh 电池， eSIM 卡与定制化 AI 通信协议，可脱离手机直接联网，还内置高精度 GPS；同时集成算力、独立麦克风和扬声器，即便不佩戴耳机，也可以通过语音与 AI 进行交互。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvEVic4tYPFyMoahibY9nUsGzSW8A07FSxLyKcld9DM2icPMAficTsz5xuhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.7913669064748201" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526627" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/16d229c7-7940-42fa-bf99-8e623f9edcbb/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tviatn4vibPVYVRFh6WSomRyP59YXKySLVywyuzId61tItVsibxk0HVqiceQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.60431654676259" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526628" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/6f51e4a5-7428-470c-a7d0-7e3e9e241bc1/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;des&gt;充电盒上的独立麦克风。&lt;/des&gt;&lt;p&gt;因此，在洗澡、起床、阅读等「不想戴耳机」的场景下，用户依然可以与 AI 保持基本互动，例如询问当天的天气或日程安排。&lt;/p&gt;&lt;p&gt;这种分布式协作的思路，并非个案。&lt;/p&gt;&lt;p&gt;在 Meta 的 Orion 项目中，除了眼镜本体，还配套了一个手势追踪腕带，以及一个遥控器大小的计算模块，三者通过无线方式协同工作。其中，腕带用于读取与手势相关的神经信号，帮助 AI 更精准地理解用户意图。&lt;/p&gt;&lt;p&gt;从这个角度看，手表、耳机、眼镜，乃至充电盒，并不是彼此替代的竞争关系，而是在不同位置、不同维度，分别承担 AI 助理的「感官」与「分身」。它们分工协作、彼此补位，最终目标是一件事：让 AI 真正「在场」，并主动融入生活。&lt;/p&gt;&lt;p&gt;再往远处看，设备的边界只会持续模糊。光帆科技对主动智能的判断是：未来一定是多设备联动，由一个统一的 AI 大脑进行调度。基于自研操作系统，他们后续还将接入更多形态的终端 &amp;mdash;&amp;mdash; 例如脖挂、眼镜、项链等。&lt;/p&gt;&lt;h4&gt;无人区的艰难跋涉&lt;/h4&gt;&lt;p&gt;主动智能，不属于某一件硬件，而属于一个协同运作的分布式系统。&lt;/p&gt;&lt;p&gt;而做这样一套分布式 AI 硬件，并不是把耳机、手表、充电盒简单叠加，而是一场关于算力如何分配、设备如何低功耗通信，以及人机工程学如何取舍的极限运动。&lt;/p&gt;&lt;p&gt;其中最核心、最根本的问题是：如何让一个只有几克重的设备，承载起接近大模型的「灵魂」？&lt;/p&gt;&lt;p&gt;光帆科技的解法，是自研一套端云结合的操作系统：Lightware OS，不是把所有能力都塞进单一设备，而是建立一种类似「生物神经系统」的层级分工与调度机制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvV7zW8rsu438yIUeJPgYSfCGtp37jd19axTJeXFO5mW031CbAGx0Ylw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6546762589928058" data-s="300,640" data-type="png" data-w="556" type="block" data-imgfileid="503526629" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b00dd2d2-2ffd-4e9b-b7ce-99e9217eb595/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最「聪明」、算力最强的大脑，放在云端，负责调用不同的大模型，完成语音与图像理解、意图识别，以及复杂推理与决策。&lt;/p&gt;&lt;p&gt;比如，结合你的位置、你看到的招牌，以及历史评价等信息，判断这是一家什么类型的餐厅、口碑如何、值不值得走进去 &amp;mdash;&amp;mdash; 这些都交给云端完成。&lt;/p&gt;&lt;p&gt;随身携带的充电盒，同样具备算力，但它并不负责「深度思考」，而是反应足够快、兜底足够稳。&lt;/p&gt;&lt;p&gt;内置 4G eSIM 保证「永不掉线」。它是流量的调度站，在毫秒级内判断请求类型（是查地图还是听歌），瞬间将音视频流推向云端。同时，在网络波动时利用本地算力进行「行为缓冲」，避免 AI 变成「人工智障」。&lt;/p&gt;&lt;p&gt;至于耳机，更像是全天候的「感官末梢」，负责「听」和「看」，只跑最轻量的 AI 任务（如语音唤醒、低像素物体轮廓识别），让这些能力在后台长时间「静默运行」，以极低功耗换取随时在场的体验。&lt;/p&gt;&lt;p&gt;另一个同样棘手的问题，是如何恰如其分地与用户交互。&lt;/p&gt;&lt;p&gt;一个缺乏分寸感的 AI 助手，很快就会从「贴心」变成「打扰」，最终被用户关闭。&lt;/p&gt;&lt;p&gt;因此，在 Lightware OS 中，系统层必须具备对场景的判断能力：用户是否忙碌？当前是否适合打断？这一次介入是否真的有价值？这种对「干扰优先级」的判断，无法只靠给大模型写一段 Prompt 解决，而必须被写进系统的底层逻辑中。&lt;/p&gt;&lt;p&gt;如何让这套分布式硬件长期、可靠地作为一个整体运行，同样是一道工程难题。&lt;/p&gt;&lt;p&gt;哪怕只看端侧，多设备之间的实时通信本身就已经足够复杂；更现实的是，单个设备内部往往也不止一颗芯片，芯片之间如何高效协作，直接决定了系统稳定性。这不是「写好一个程序」就能解决的问题，而是必须在硬件层、驱动层、通信层同时成立。&lt;/p&gt;&lt;p&gt;还有硬件工艺上的「极限平衡」。在耳机这样极度受限的形态中加入摄像头，意味着必须同时权衡体积、重量、续航、散热与佩戴舒适度。&lt;/p&gt;&lt;p&gt;最终，加入摄像头和更大电池后，单只耳机重量被控制在 11g，远低于常见智能眼镜约 40g 的重量，佩戴舒适度和行业头部的耳挂式耳机相当，并无明显不适和异物感。&lt;/p&gt;&lt;p&gt;这几年，CES 一直是「杀手级 AI 硬件」想象力的集中展示场。在众多方向中，个人穿戴与随身设备始终是焦点。而耳机这一高频入口，也正在被重新定义。&lt;/p&gt;&lt;p&gt;2026 年 1 月 6-9 日，光帆科技将携全球首款主动式 AI 耳机亮相 CES。下一代 AI 硬件的方向，或许正藏在这些看似熟悉、却正在被重新塑造的随身设备之中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvab5d5XwYqic0lzcG0qq497NicAgrIg8S1SRd8ibFiaglwTktGLjszSqAwg/640?wx_fmt=jpeg#imgIndex=13" data-ratio="1.256578947368421" data-s="300,640" data-type="jpeg" data-w="1064" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvgL6rGq8ZMicqicXzG4G9apbtRUA3iacF2icz9Z2XL0ib2JWeYwHXC8CWwmg/640?wx_fmt=jpeg&amp;from=appmsg" data-cropx2="1064.626334519573" data-cropy2="1337.508896797153" data-imgfileid="503526649" data-aistatus="1" data-original-style="width: 554px;height: 696px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/cc78cd38-3509-4ee8-ad25-7d04606273bf/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>500万人在线围观，Claude Code创建者的13条独家实战秘籍爆火</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 14:35:26 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3b47561e-e621-4bed-a5a7-80f80ca0bdee/1767508320970.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;2026 新年第三天，Claude Code 创建者、负责人 Boris Cherny 开展「线上教学」，亲自示范他自己使用这个 AI 编程工具的工作流。&lt;/p&gt;&lt;p&gt;他表示，自己的配置可能出乎意料地「素」（即简单）！Claude Code 开箱即用非常出色，所以他个人并没有做太多自定义。&lt;/p&gt;&lt;p&gt;使用 Claude Code 没有所谓的「标准答案：在设计时就希望它是可定制、可 Hack 的。用户完全可以按自己的喜好来使用。事实上，Boris 团队里的每个人用它的方式都大不相同。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526654" data-ratio="0.6037037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvyn9wtvqPlSWeqyZj7kja3xeAgjFZIU085cdK98KrtE3UkASxMryic6w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/35ed452a-2eed-4b32-be5b-399952ec60f0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;一、五线并行&lt;/h4&gt;&lt;p&gt;在终端里同时运行 5 个 Claude 窗口，给这些标签页排上 1 到 5 号，并开启系统通知，这样当某个 Claude 需要他输入指令时，便会立刻收到提醒。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvG8Sv1yicOauH1iaDQBelJD3Ttb2NF2IHOvicxmFjaLBfAW3jFbooZXF0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526655" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b2b6bffd-e804-4785-95cc-b71b5a0ccca7/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;二、多端无缝衔接&lt;/h4&gt;&lt;p&gt;除了本地终端，他还会同时在网页端（&lt;a href="http://claude.ai/code"&gt;http://claude.ai/code&lt;/a&gt;）运行 5 到 10 个 Claude 任务。&lt;/p&gt;&lt;p&gt;在终端写代码时，他经常用 &amp;amp; 把本地会话交给后台，或者直接在 Chrome 里启动新会话。有时还会使用 --teleport 命令在两者之间「传送」进度。&lt;/p&gt;&lt;p&gt;每天早上甚至会用手机（iOS 版 Claude App）启动几个会话，之后再回电脑上查看进度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvsd1gpoRWh50Cia9ibINIQdnl2zoIxZVkicUSUibw1fUyaInicPHbjmVMCAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0144927536231885" data-s="300,640" data-type="png" data-w="966" type="block" data-imgfileid="503526657" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/df3ac330-9a86-43dc-9bb8-41f039aa0ea7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;三、全力投入 Opus 4.5&lt;/h4&gt;&lt;p&gt;他会给所有任务开启 Opus 4.5 (带 Thinking 模式)，这是他用过的最强编程模型。&lt;/p&gt;&lt;p&gt;虽然它比 Sonnet 更大、更慢，但同时它更聪明、更擅长调用工具，不需要费心去引导它，所以从结果来看，它通常反而比小模型更快完成任务。&lt;/p&gt;&lt;h4&gt;四、共享知识库：CLAUDE.md&lt;/h4&gt;&lt;p&gt;团队共用一个 CLAUDE.md 文件。他们把它存放在 Git 仓库里，团队成员每周都会多次更新。只要发现 Claude 哪里做错了，他们就把规矩写进 CLAUDE.md，确保它下次不再犯同样的错误。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tv3tUEcbMm3zwKntEAzoO8BSxvJQRT15BmNBwH512icTXpyVUUic4HEXpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7775700934579439" data-s="300,640" data-type="png" data-w="1070" type="block" data-imgfileid="503526659" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/70ff3d4b-5fc0-4d94-98fe-9cab550d3988/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;五、持续复利：代码评审&lt;/h4&gt;&lt;p&gt;在代码评审（PR）时，他经常会 @.claude，让它把同事 PR 中的一些规范沉淀到 CLAUDE.md 中。他们通过 /install-github-action 安装了 Claude Code 的 GitHub Action。这就是他们版本的「复利工程」（Compounding Engineering）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tv1LibgFWfqPeEF9uvxN7pSScYFiaGibRcibAqYQicXpG9kPmeRPuqqlecZ7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.8453703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526660" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6b028417-91dd-4d44-8af4-6f236389cbae/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;六、谋定而后动：Plan 模式&lt;/h4&gt;&lt;p&gt;大多数任务都从 Plan 模式开始（连按两次 Shift+Tab）。如果目标是写一个 PR，他会先在 Plan 模式下反复和 Claude 沟通，直到认可它的方案。&lt;/p&gt;&lt;p&gt;之后，他会切换到自动接受修改模式（auto-accept edits），Claude 通常能直接「一波带走」。一个好的方案至关重要！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvric5j52YQwmYpvrrJpxFndeGKoM4NrypAZJRybmia9tvxSHXUDvca67Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.30580357142857145" data-s="300,640" data-type="png" data-w="896" type="block" data-imgfileid="503526661" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/489a1733-5eee-46b0-b5f0-c39bed4a0b11/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;七、打造自己的斜杠命令（Slash Commands）&lt;/h4&gt;&lt;p&gt;他会把每天重复多次的 &amp;ldquo;内环&amp;rdquo; 工作流都封装成斜杠命令。这让他免于重复输入提示词，也让 Claude 能直接调用这些流程。这些命令存放在 .claude/commands/ 下并提交到 Git。&amp;nbsp;&lt;/p&gt;&lt;p&gt;比如，他和 Claude 每天会用几十次 /commit-push-pr。这个命令利用内联 Bash 预先计算 Git 状态等信息，运行极快，避免了反复对话。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvov7xy0rL7ElPwuXbly8DYibYYnEOiaUIFiaXrIyqcwqvGxcQwtrMKWwSw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.24375" data-s="300,640" data-type="png" data-w="960" type="block" data-imgfileid="503526662" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c8149617-2640-4650-a4e9-454b4dc6a01c/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;八、善用子智能体（Subagents）&lt;/h4&gt;&lt;p&gt;他经常使用特定的子智能体：比如 code-simplifier 用来在完成后简化代码，verify-app 用来端到端测试。和斜杠命令一样，子智能体本质上是把 PR 中最常见的流程自动化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvlzQgUuHpe58Daaic4vjZk14TdIfePpwEicfiaiafPiblCDSruic1jzYHnmRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6883116883116883" data-s="300,640" data-type="png" data-w="462" type="block" data-imgfileid="503526663" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/5a9a4174-ec60-418c-a203-c76d82209940/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700px;"&gt;&lt;/section&gt;&lt;h4&gt;九、自动代码美化&lt;/h4&gt;&lt;p&gt;他们使用了 PostToolUse 钩子来格式化代码。虽然 Claude 写的代码格式已经很好了，但这个钩子能搞定最后 10% 的细节，避免在 CI（持续集成）阶段报错。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvPz1OdeRurGN7wCyTlFkVr3wAALugW2QwtEo8jjiaAoAGicjia45681ibRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.47300215982721383" data-s="300,640" data-type="png" data-w="926" type="block" data-imgfileid="503526665" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/a03e8dbf-9a53-4572-974e-722d4c5ad6de/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700px;"&gt;&lt;/section&gt;&lt;h4&gt;十、权限管理&lt;/h4&gt;&lt;p&gt;他不用 --dangerously-skip-permissions（危险跳过权限提示）。相反会用 /permissions 预先授权一些在当前环境下安全的常用 Bash 命令。这些配置保存在 .claude/settings.json 中，团队共享。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tv9V5ln0HfOw2g0C5lyLVufSkzHxqkmPRDpskJIpVAmfzIS8uUrlCjAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.832258064516129" data-s="300,640" data-type="png" data-w="930" type="block" data-imgfileid="503526666" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/eefc7a10-235d-4411-a116-77fffbe39315/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700px;"&gt;&lt;/section&gt;&lt;h4&gt;十一、工具全家桶&lt;/h4&gt;&lt;p&gt;Claude Code 会帮他操作所有工具，经常通过 MCP 服务器搜索并发送 Slack 消息，运行 bq 命令行执行 BigQuery 查询，或者从 Sentry 抓取报错日志。Slack 的 MCP 配置保存在 .mcp.json 中供团队使用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvM1icqtu1CGIODff8FfF3ZpJW3FOL6BLwmUACUM38cQxkyPqr1Z246Tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.37445887445887444" data-s="300,640" data-type="png" data-w="924" type="block" data-imgfileid="503526667" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/60f43706-cf48-4c37-9d81-af8324173915/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700px;"&gt;&lt;/section&gt;&lt;h4&gt;十二、长时间任务&lt;/h4&gt;&lt;p&gt;对于耗时较长的任务，他会：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;让 Claude 在完成后启动一个后台智能体进行验证；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用 Stop 钩子进行确定性检查；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用 ralph-wiggum 插件。 在这种情况下，使用 --permission-mode=dontAsk 或在沙盒环境中使用跳过权限模式，这样 Claude 就能心无旁骛地「输出」，不会被权限弹窗卡住。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tve1TGUZkicXzmtNevnU1ibiaR5KiawMhffu4WksXxSHIrEOibNDUluOKb3Ew/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.2199248120300752" data-s="300,640" data-type="png" data-w="1064" type="block" data-imgfileid="503526668" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/14be42d2-bb41-47c5-837f-fcb5fc52ddd8/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;最后：构建反馈闭环&lt;/h4&gt;&lt;p&gt;最后一点，也是拿到高质量结果的关键：给 Claude 一个验证自己工作的途径。如果有反馈闭环，结果的质量能提升 2 到 3 倍。 Claude 在更新网页版代码时，会通过 Chrome 插件测试每一个改动：它会自动打开浏览器，测试 UI，不断迭代，直到代码跑通且交互体验丝滑。&lt;/p&gt;&lt;p&gt;验证方式因领域而不同：可能是运行一段 Bash 脚本、跑测试套件，或者在模拟器里运行 App。请务必花精力把「验证流程」做得坚如磐石。&lt;/p&gt;&lt;p&gt;感兴趣的开发者，可以在日常使用 Claude Code 时，以 Boris Cherny 的做法作为一个参考。&lt;/p&gt;&lt;p&gt;原推链接：&lt;a href="https://x.com/bcherny/status/2007179832300581177"&gt;https://x.com/bcherny/status/2007179832300581177&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026 | 小鹏联合北大，专为VLA模型定制视觉token剪枝方法，让端到端自动驾驶更高效</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 14:29:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-ym-citation="1"&gt;&lt;img alt="图片" data-aistatus="1" data-backh="321" data-backw="562" data-ratio="0.5703703703703704" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=0" data-w="1080" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/a26e0896-a6f0-44e2-9314-ea5b06c87f46/640.png" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-ym-citation="3"&gt;VLA 模型正被越来越多地应用于端到端自动驾驶系统中。然而，VLA 模型中冗长的视觉 token 极大地增加了计算成本。但现有的视觉 token 剪枝方法都不是专为自动驾驶设计的，在自动驾驶场景中都具有局限性。&lt;/p&gt;&lt;p data-ym-citation="5"&gt;小鹏汽车联合北京大学计算机科学学院多媒体信息处理国家重点实验室发表论文《FastDriveVLA》，不仅为自动驾驶 VLA 模型中的高效视觉 token 剪枝建立了新的范式，也为特定任务的剪枝策略提供了有价值的洞察。&lt;/p&gt;&lt;p data-ym-citation="7"&gt;受人类驾驶员主要关注前景区域而非背景区域的启发，研究团队做出假设：对于自动驾驶而言，与前景信息相关的视觉 token 比与背景内容相关的视觉 token 更有价值。为了验证这个假设，研究团队构建了大规模自动驾驶标注数据集 nuScenes-FG（包含来自 6 个摄像头视角的、带有前景区域标注的 24.1 万个图像 - 掩码对），通过 MAE 风格的像素重建策略和新颖的对抗性前景 - 背景重建策略，训练出了一个适用于不同 VLA 模型的、可以即插即用的视觉 token 剪枝器 ReconPruner。&lt;/p&gt;&lt;p data-ym-citation="9"&gt;实验结果显示，在不同剪枝比例下，FastDriveVLA 在 nuScenes 开环规划基准测试中均取得了 SOTA 性能。FastDriveVLA 也非常高效，当视觉 token 数量从 3249 减少至 812 时，FastDriveVLA 的 FLOPs 直降约 7.5 倍；在 CUDA 推理延迟方面，FastDriveVLA 将预填充（prefill）时间减少了 3.7 倍、将解码（decode）时间减少了 1.3 倍，显著提升了推理效率。&lt;/p&gt;&lt;p data-ym-citation="11"&gt;该篇论文被 AAAI 2026 录用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LE7TcWeJl10kLRRsn7Oqnl13BbKHpglU95Bl2jnB3eicZlGQfEQHJjxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.27575757575757576" data-s="300,640" data-type="png" data-w="990" type="block" data-backw="578" data-backh="159" data-imgfileid="503526433" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6fa23cde-cca6-4352-bd87-b84f502bf3c1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-ym-citation="14"&gt;论文标题：FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-ym-citation="15"&gt;论文链接：https://arxiv.org/pdf/2507.23318&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-ym-citation="17"&gt;研究背景与问题&lt;/h4&gt;&lt;p data-ym-citation="19"&gt;端到端自动驾驶最近展现出巨大潜力，有望彻底改变未来的交通系统。与传统的模块化自动驾驶系统不同，端到端方法在一个统一的框架中学习整个驾驶流程，这种设计不仅减少了模块之间信息传递时的误差，还增强了系统的简洁性。&lt;/p&gt;&lt;p data-ym-citation="21"&gt;然而，现有的 VLA 模型通常将视觉输入转换为大量的视觉 token，这种方法导致了巨大的计算开销和推理延迟的增加，对真实场景的车端部署提出了重大挑战，因为计算资源和推理速度都受到严重限制。&lt;/p&gt;&lt;p data-ym-citation="23"&gt;已经有大量研究尝试通过减少视觉 token 来加速 VLM 的推理，但在自动驾驶场景中都具有局限性：引入新设计的多模态投影器需要重新训练整个模型，基于注意力的剪枝策略容易受到无关信息的影响，基于相似性的剪枝策略会错误保留与驾驶无关的信息。&lt;/p&gt;&lt;p data-ym-citation="25"&gt;为了解决这些挑战，我们专为端到端自动驾驶 VLA 模型定制了一个新型的、基于重建的视觉 token 剪枝框架 FastDriveVLA。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lu0d2cqJ7ggdZ8oOKcJtEnVSQiaz5gCqu6gZtFhl9kofxgict7qT41g0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="213" data-imgfileid="503526441" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8aa04b62-b73d-4101-80ca-caf7392eaf73/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-ym-citation="27"&gt;图 1：不同视觉 token 剪枝策略的对比，（c）为基于重建的剪枝策略&lt;/p&gt;&lt;h4 data-ym-citation="29"&gt;方法与创新&lt;/h4&gt;&lt;p data-ym-citation="31"&gt;&lt;strong&gt;nuScenes-FG 数据集&lt;/strong&gt;&lt;/p&gt;&lt;p data-ym-citation="33"&gt;受人类驾驶员主要关注前景区域而非背景区域的启发，我们首先对自动驾驶场景中的「前景区域」进行了明确定义。这些区域包括行人、道路、车辆、交通标志（含交通信号灯）以及交通障碍物（如位于车道上或紧邻车道的障碍物）等对驾驶决策具有直接影响的元素。相比之下，建筑物、天空、行道树等背景区域即使被完全遮挡，通常也不会显著影响人类驾驶员的判断。然后，借助 Grounded-SAM 对 nuScenes 场景进行细粒度、语义一致的前景分割，构建了 nuScenes-FG 数据集。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LRVvEAVpDcJVILqCiaTdbcGFEvAdlRVp5MnqHI6Q8d9acHSqa4WI52lA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.010185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="584" data-imgfileid="503526442" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/91053c96-58b0-48d9-81fd-6751bb4c8457/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-ym-citation="35"&gt;图 2：nuScenes-FG 数据集，为 nuScenes 场景提供了 24.1 万个前景分割标注。&lt;/p&gt;&lt;p data-ym-citation="37"&gt;&lt;strong&gt;基于重建的剪枝器 ReconPruner&lt;/strong&gt;&lt;/p&gt;&lt;p data-ym-citation="39"&gt;我们提出了一种轻量级的、可即插即用的剪枝器 ReconPruner，主要目标是让 ReconPruner 能够有效识别并选择包含有意义前景信息的视觉 token，因此借鉴 Masked Image Modeling（掩码图像建模）方法设计了 MAE 风格的像素重建策略。在训练过程中，我们选取 ReconPruner 预测的可获得高分的视觉 token 子集，用于掩码前景重建。该子集上的重建误差作为监督信号，鼓励 ReconPruner 为真正对应前景内容的视觉 token 打高分。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LgfN1fJaGrFFq6DsJILHa82Pyz3ic38QdpfkljbJSQrNQS1bpqiagRSOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8092592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="468" data-imgfileid="503526443" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/36fff5cd-254c-4bcd-a5a0-ea38f7401312/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-ym-citation="41"&gt;图 3：FastDriveVLA 框架。在训练阶段，提出了一种新颖的「前景 - 背景对抗重建」策略，以增强 ReconPruner 对前景视觉 token 的感知能力；在推理阶段，ReconPruner 可直接嵌入自动驾驶 VLA 模型，用于 token 剪枝。&lt;/p&gt;&lt;p data-ym-citation="43"&gt;&lt;strong&gt;对抗性前景 - 背景重建策略&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p data-ym-citation="45"&gt;但若仅仅依赖前景重建，ReconPruner 可能会采取捷径，不加区分地为所有视觉 token 打高分。我们从生成对抗网络（GANs）中汲取灵感，提出了对抗性前景 - 背景重建策略。具体来说，ReconPruner 还需要使用获得低分的视觉 token 来重建背景区域。这种对抗性设置增强了 ReconPruner 区分前景 token 和背景 token 的能力。&lt;/p&gt;&lt;h4 data-ym-citation="47"&gt;实验结果&lt;/h4&gt;&lt;p data-ym-citation="49"&gt;&lt;strong&gt;实验设置&lt;/strong&gt;&lt;/p&gt;&lt;p data-ym-citation="51"&gt;我们采用 Impromptu-VLA 作为视觉 token 剪枝的基础模型，在专为城区自动驾驶设计的大规模基准测试数据集 nuScenes 上对不同剪枝方法进行了评估。nuScenes 数据集包含 1000 个驾驶场景、每个场景约持续 20 秒。测试时，我们总计使用了 6019 个测试样本，并通过 L2 轨迹误差、碰撞率、路外率三个指标来评估开环规划的性能。&lt;/p&gt;&lt;p data-ym-citation="53"&gt;我们使用余弦调度器以 2e-5 的学习率训练 FastDriveVLA，总计进行了 10 轮训练，仅在两块 H800 GPU 上运行 3 小时就完成了训练。&lt;/p&gt;&lt;p data-ym-citation="55"&gt;不同剪枝方法在 nuScenes 数据集上的对比&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LVkt3Jl1V3ujCfuNG2IZzEiadU4YHWuspPItcvsseVGu5K9VLWmsNHzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="342" data-imgfileid="503526451" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/33832c03-2372-4c17-8982-63b3a1f60a61/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-ym-citation="57"&gt;FastV、SparseVLM 是基于注意力的基线，DivPrune、VisPruner 是基于相似性的基线。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-ym-citation="59"&gt;当剪枝 25% 时，FastDriveVLA 在所有评估指标上均表现最佳，尤其在 L2 轨迹误差和碰撞指标上分别比未剪枝的原始模型低了 0.1% 和 1.0%，这证明了聚焦于与前景相关的视觉 token 是提升自动驾驶性能的关键。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-ym-citation="60"&gt;当剪枝 50% 时，FastDriveVLA 在碰撞指标上的表现优于剪枝 25%。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-ym-citation="61"&gt;当剪枝 75% 时，FastDriveVLA 在路外率指标上的表现优于剪枝 50%。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-ym-citation="63"&gt;总体来看，FastDriveVLA 在各种剪枝比例下均优于现有方法。特别值得注意的是，当剪枝 50% 时，FastDriveVLA 在所有指标上的表现都更加均衡。因此，我们建议，在实际部署自动驾驶系统时采用 50% 这一剪枝比例，以实现性能与效率的最佳平衡。&lt;/p&gt;&lt;p data-ym-citation="65"&gt;&lt;strong&gt;效率分析&lt;/strong&gt;&lt;/p&gt;&lt;p data-ym-citation="67"&gt;为了展示 FastDriveVLA 的高效，我们从 FLOPs 与 CUDA 延迟的角度对不同剪枝方法进行了效率分析。当视觉 token 数量从 3249 减少至 812 时，FastDriveVLA 的 FLOPs 直降约 7.5 倍。在 CUDA 推理延迟方面，FastDriveVLA 将预填充提速 3.7 倍、解码提速 1.3 倍，实际推理效率显著提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lficapu9c0pgcOT8hmM0BqKcjLpXG0rib5js2LdmdAxyt8uHdxRzCwqjg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4749455337690632" data-s="300,640" data-type="png" data-w="918" type="block" data-backw="578" data-backh="275" data-imgfileid="503526452" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/dc4f3966-788d-45a7-9a39-9003f069f925/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-ym-citation="70"&gt;&lt;strong&gt;定性可视化分析&lt;/strong&gt;&lt;/p&gt;&lt;p data-ym-citation="72"&gt;ReconPruner 几乎完整留下了前景 token ，把背景压成极稀疏的色块，重建画面依旧清晰，证明它能在减少 token 冗余的同时保留关键信息，如图 4 所示。&lt;/p&gt;&lt;p data-ym-citation="74"&gt;再把 FastV（基于注意力）、DivPrune（基于相似性）和 FastDriveVLA 放到图 5 中进行对比，可以看到：我们的点密密麻麻落在车道、车道线和车身；FastV 几乎漏掉了车辆；DivPrune 虽然撒点更多，却几乎没往车道线上靠。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LywOqxiasiam6xowFySJa3Xphvz9eBrBw4xEfeHFpVuawDLSe5Cd0LLUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9239130434782609" data-s="300,640" data-type="png" data-w="920" type="inline" data-imgfileid="503526455" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b539e93a-6b79-4820-b980-ad7e789df51f/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 350px;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LbrU56ycqgicbb1pUdTvibPicwuLGGHbyEQ0ficjoNN5HaOualdQaP7Jdiag/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.9528907922912205" data-s="300,640" data-type="png" data-w="934" type="inline" data-imgfileid="503526454" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/34f12197-d7c9-4c64-94ab-2af05fc39f32/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 350px;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>统一结构与上下文信息的计算平台，德国慕尼黑大学等提出端到端的单细胞扰动分析框架</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Sun, 04 Jan 2026 14:06:02 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1SYeQdiaOD7Tx47rMGNvib0BIp6VibOgibdqcBWbmPx94ezotVnAaDdicrnDUC9V5unpU7BenHPQJ6Zw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5574074074074075" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="322" data-imgfileid="100027048" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/56c150de-fe6d-47a4-b0dc-12527369dc7a/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;随着单细胞技术的发展，研究者可以在数以万计的细胞中同时测量多个基因或分子标记，并且通过遗传、化学或环境干扰（perturbation）引入实验变量，深入理解细胞反应机制。&lt;/p&gt;&lt;p&gt;这种类型的数据不仅体量巨大，而且结构复杂，不同实验条件、不同细胞类型和干扰策略之间的差异，使得传统的分析工具难以有效覆盖整体流程。现有方法大多只针对单个任务，或者专注于某种类型的环境干扰，而缺乏一个&lt;strong&gt;能够统一管理、分析和解释&lt;/strong&gt;各种单细胞扰动实验的平台。&lt;/p&gt;&lt;p&gt;考虑到现有的生物背景，德国慕尼黑亥姆霍兹中心（Helmholtz Center Munich）与慕尼黑工业大学等（Technical University of Munich）提出了一个基于 Python 的模块化框架&amp;nbsp;pertpy，可用于分析大规模单细胞扰动实验。&lt;/p&gt;&lt;p&gt;相关研究内容以「Pertpy: an end-to-end framework for perturbation analysis」为题，于 2025 年 12 月 31 日发布在《Nature Methods》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1SYeQdiaOD7Tx47rMGNvib0500MH5ObnqgGdCUzEQNkoH7icTCoto3CDTxURjzczxpax3LS9icJmnCg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4162330905306972" data-type="png" data-w="961" data-width="961" data-height="400" data-imgfileid="100027045" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/9e21bd17-98be-4274-acc9-471805f27c57/640.png" alt="图片" data-before-load-time="1767506733433" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41592-025-02909-7&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端到端的框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;单细胞技术的进步，尤其是 Perturb-seq、CROP-seq&amp;nbsp;等高通量扰动技术的出现，让科学家能够以前所未有的规模进行&amp;ldquo;细胞实验&amp;rdquo;。他们可以同时敲除成千上万个基因，或施加数百种药物，并在单细胞分辨率下观察结果。这为系统性理解基因功能、药物机制和疾病通路提供了革命性的窗口。&lt;/p&gt;&lt;p&gt;但这种实验常被数据的庞大数量级冲垮。现有的工具，如&amp;nbsp;MUSIC、ScMAGeCK 等，只擅长处理特定类型的扰动或解决单一问题。而为了解决扩展性与通用性的框架缺失问题，pertpy 团队给出了自己的看法。&lt;/p&gt;&lt;p&gt;团队的解决方案并非简单地堆积功能，pertpy 的设计哲学是模块化、互操作与可扩展。它包含分析单一和组合扰动的方法，涵盖多种扰动数据类型，包括遗传敲除、药物筛选和疾病状态。该框架设计灵活，提供 100 多个可组合且互作的分析功能，组织成模块，进一步简化后续的解释和可视化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1SYeQdiaOD7Tx47rMGNvib0ibASHTmLvtBAgh2S1d9iahQPUkYficQb6Ekic5QlLrtwa6icqljRMg5aicMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.2598540145985402" data-type="png" data-w="685" data-width="685" data-height="863" data-backw="546" data-backh="688" data-imgfileid="100027043" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2e6e209b-eb28-4c64-8d3b-e03a358aa9ad/640.png" alt="图片" data-before-load-time="1767506733460" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：pertpy 框架的模块。&lt;/p&gt;&lt;p&gt;团队表示，尽管设计中 pertpy 主要设计用于探索遗传改造、药物治疗等扰动，但其效用也扩展到多种扰动环境，包括未应用实验扰动的多种疾病状态。所有这些功能通过 JAX 库实现 GPU 加速，其速度相较于原始实现有数量级提升。&lt;/p&gt;&lt;p&gt;首先，框架通过数据转化，将引导 RNA（gRNA）分配给细胞。接下来，它会处理诸如技术变异、其他单细胞特异性质量控制问题等不受欢迎的混杂因素。&lt;/p&gt;&lt;p&gt;经过严格的质量控制后，pertpy 开始对细胞系本体或药物本体进行扰动注释处理，并用来自癌症依赖地图的额外元数据丰富扰动。而为了迎接扰动数量增加带来的挑战，pertpy 提供了多种不同方式来学习生物学上可解释的扰动空间，这些方法不同于细胞的个体主义视角，而是每个扰动生成一个单一嵌入，汇总细胞反应。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为验证 pertpy 学习有意义扰动空间的能力，团队分析了最初由 Norman 等人公开发布的&amp;nbsp;CRISPRa&amp;nbsp;筛查数据集。，包含 111,255 个 K562 细胞的单细胞转录组，经历了 287 次单基因和基因对扰动。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1SYeQdiaOD7Tx47rMGNvib0icCENcCHGXqE00wcykTmyXlrZgkf9RLxt892HNJ0rXCx6YW86q6eb0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9255474452554745" data-type="png" data-w="685" data-width="685" data-height="634" data-backw="546" data-backh="505" data-imgfileid="100027046" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8d973935-89c8-4f62-8d16-ec9c0f12a058/640.png" alt="图片" data-before-load-time="1767506733497" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：通过 pertpy 的扰动空间流水线，学习组合 CRISPRa 扰动 scRNA-seq 数据中的统一扰动空间。&lt;/p&gt;&lt;p&gt;团队测试了多种针对微扰的处理策略，并利用基于多层感知子（MLP）的判别器分类器，将剩余细胞的归一化基因表达投射到扰动空间中。&lt;/p&gt;&lt;p&gt;结果表示，所有策略产生的微扰空间相似。这表明对于该数据集，不依赖基于微扰特征的单元过滤方法更为可取。&lt;/p&gt;&lt;p&gt;而面对复杂的微扰实验的发现流程， pertpy 同样以极高的效率分析了包含 172 个细胞系和 13 种药物治疗的数据集。这只需要几个步骤：注释、可视化、比较分析。这其中还允许用户将其细胞系的 RNA 谱与已建立的公开数据集进行比较，从而提供快速的质量控制功能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1SYeQdiaOD7Tx47rMGNvib0liaUNIwoJzVwnFFlELD9HUKiczTX1IZHkZ8C4Dib0uJTHqsBjkPeXMzqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.1883211678832117" data-type="png" data-w="685" data-width="685" data-height="814" data-backw="546" data-backh="649" data-imgfileid="100027044" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9f97c465-b80a-4fcc-bb25-e1747537f288/640.png" alt="图片" data-before-load-time="1767506733512" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 3：scRNA-seq 药物筛选数据中存活性相关反应特征的解卷积。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可扩展的单细胞扰动分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为一款开源的分析工具，pertpy 将过去分散的单细胞 perturbation 分析方法整合到一个结构化、可重复、易扩展的框架中。它极大地降低了领域门槛，为构建大规模扰动图谱奠定了基础。&lt;/p&gt;&lt;p&gt;Pertpy 不仅为研究者提供了工具链，还为未来算法的开发和集成奠定了基础，是单细胞 perturbation 研究数据层面解决方案的重要一步。它提供的丰富距离度量和分析模块，正是评估这些模型预测是否具有生物学意义的标尺。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>前OpenAI CTO押注的赛道，被中国团队抢先跑通，AI「下半场」入场券人人有份</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 12:58:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/aaff880e-a3ff-4059-80a7-9f1b4a0e6a28/1767502380182.png" style="width: 700px;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;section&gt;在大公司一路高歌猛进的 AI 浪潮里，小创业者和高校研究者正变得越来越迷茫。就连前段时间谷歌创始人谢尔盖・布林回斯坦福，都要回答「大学该何去何从」「从学术到产业的传统路径是否依然重要」这类问题。&lt;/section&gt;&lt;p&gt;AI，真的只是大公司的游戏吗？被算力掣肘的其他研究者、创业者，机会在哪里？在「强化学习」后训练引领「下半场」的当下，这个问题变得愈发重要。&lt;/p&gt;&lt;p&gt;好在，国内外都有专业团队在关心这个问题，比如前 OpenAI CTO Mira 创办的 Thinking Machines Lab，前段时间就推出了一个叫「Tinker」的产品，专注于解决后训练 Infra 的复杂性。&lt;/p&gt;&lt;p&gt;而在国内，一群由 95 后青年科学家组成的团队做出了足以对标甚至超越 Tinker 的竞品，成为&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;世界第一家能够对标 Thinking Machines Lab 的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;这个研究中心叫 Mind Lab，是 Macaron AI 背后的实验室。1 月 1 日，他们发布了亮相以来的第一款产品&amp;mdash;&amp;mdash;Mind Lab Toolkit（MinT）。这是一个用 CPU 的机器就能高效训练万亿参数模型的后训练平台，且成本优化了十倍，一天即可轻松完成一轮训练。此外，它比 Thinking Machines 更早实现了 1T LoRA-RL，是业界在万亿参数模型上进行高效强化学习的第一个成果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6k7TmyajrYuWWKFGUGB91HagqfeUYIeiaOuhAibpNZib2lMJrQKNvtwaFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7796296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526612" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7786e930-5dc5-45ca-9dd1-bd0fc1b150d9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如果你是 Agent 领域创业公司或高校顶尖实验室的成员，并且被算力限制了想象力，那你将是 MinT 的首批受益者。它的应用场景涵盖基础研究到垂直行业的广泛领域，已经在圈内做出了一些成果。&lt;/p&gt;&lt;p&gt;细看一下，Mind Lab 的创始团队也堪称豪华。创始人 Andrew 毕业于 MIT，目前担任深圳清华大学研究院的研发中心主任，代表工作有和姚顺雨合作的 Agent 微调的经典工作之一 FireAct。&lt;/p&gt;&lt;p&gt;首席科学家马骁腾博士则毕业于清华大学自动化系，常年深耕强化学习领域。团队成员来自清华、MIT、CMU等高校，并有OpenAI、DeepMind、Seed 等顶尖实验室的工作经历。&lt;/p&gt;&lt;p&gt;团队累计发表论文超 100 篇，总引用量超 3 万次。&lt;/p&gt;&lt;p&gt;这样一个团队打造的 MinT，正以极致的工程效率，将 AI 下半场的入场券交还到每一位研究者手中。&lt;/p&gt;&lt;h4&gt;预训练时代结束，AI 下半场开启&lt;/h4&gt;&lt;p&gt;过去几年，预训练一直是 AI 领域的主旋律 &amp;mdash;&amp;mdash; 更大的模型、更多的数据、更长的训练周期。&lt;/p&gt;&lt;p&gt;如今，这一阶段已趋于饱和：开源社区已经拥有万亿参数级别的模型，能够编写代码、总结文档、通过标准化考试。&lt;/p&gt;&lt;p&gt;但当这些系统被部署到真实产品中，新的瓶颈开始显现。模型一旦完成训练，参数就被 &amp;#39; 冻住 &amp;#39; 了，不停重复着相同的错误，也无法适应不断变化的用户需求，实际使用效果只能靠抽卡。&lt;/p&gt;&lt;p&gt;强化学习，正是破局的关键。&lt;/p&gt;&lt;p&gt;DeepSeek R1 的发布更是向业界证明，强化学习能够带来惊人的泛化性和样本效率 &amp;mdash;&amp;mdash; 模型不再只是 &amp;ldquo;记住&amp;rdquo; 数据，而是学会了在复杂任务中进行推理。&lt;/p&gt;&lt;p&gt;在 Gemini、DeepSeek V3.2、Kimi K2 等多个前沿模型的技术报告中都反复强调：后训练仍是一片蓝海，强化学习还没看到天花板。&lt;/p&gt;&lt;p&gt;2026 年的主旋律，是后训练。&lt;/p&gt;&lt;h4&gt;后训练时代的基础设施&lt;/h4&gt;&lt;p&gt;强化学习这么重要，为什么没普及？答案是：算法太复杂，训练太不稳定。&lt;/p&gt;&lt;p&gt;为了解决这个问题，前 OpenAI CTO Mira 创立的 Thinking Machines 发布了 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650993756&amp;idx=1&amp;sn=4bd29a2b9fdaf00b29f97f6f2139decb&amp;scene=21#wechat_redirect" target="_blank"&gt;Tinker&lt;/a&gt;，定义了后训练 API 的新范式，迅速获得美国学界和硅谷创业公司的热捧。&lt;/p&gt;&lt;p&gt;在 OpenAI 经历了 Sam Altman 被解雇又回归的内部动荡后，Mira 选择离开，并迅速组建了一支 &amp;ldquo;梦之队&amp;rdquo;&amp;mdash;&amp;mdash; 核心成员包括 OpenAI 前研究副总裁 John Schulman、Lilian Weng 等业界顶尖人才。资本市场对这家公司的追捧堪称疯狂。2025 年 7 月，Thinking Machines 完成了硅谷历史上最大的种子轮融资 &amp;mdash;&amp;mdash;20 亿美元，估值 120 亿美元。&lt;/p&gt;&lt;p&gt;他们押注的，正是后训练赛道。2025 年 10 月，Thinking Machines 发布了首款产品 Tinker，12 月面向所有用户开放。如果说 OpenAI 定义了大模型的推理 API 范式，那么 Tinker 定义的就是模型的训练 API 范式，让所有模型训练共享。&lt;/p&gt;&lt;p&gt;Tinker 已经获得了学术界和工业界的广泛认可，成为了硅谷和美国顶尖高校的训练新范式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LlwU7iawaLO1ofZSo8284JlqOyYuDyJO8ezbf85vqIgwzLsaSq2weSZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9625" data-s="300,640" data-type="png" data-w="720" type="block" data-imgfileid="503526461" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b4eea727-56ad-4e66-9e8b-bf974454a2df/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;Mind Lab 与 MinT，国产后训练基础设施的崛起&lt;/h4&gt;&lt;p&gt;Tinker 在海外大火的同时，国内也涌现出了对标甚至超越的力量 &amp;mdash;&amp;mdash;Mind Lab 推出的 MinT（Mind Lab Toolkit）。&lt;/p&gt;&lt;p&gt;Mind Lab 秉持 &amp;ldquo;From Static &amp;#39;Brains&amp;#39; to Adaptive &amp;#39;Minds&amp;#39;&amp;rdquo; 的理念，致力于让 AI 系统能够从真实世界的经验中不断成长。&lt;/p&gt;&lt;p&gt;在他们看来，当前大模型最大的问题是：训练完就 &amp;quot;冻住&amp;quot;，无法从真实交互中持续学习进化。&lt;/p&gt;&lt;p&gt;MinT，正是为解决这个问题而生。&lt;/p&gt;&lt;p&gt;MinT 和 Tinker 是什么关系？可以从两个层面理解：&lt;/p&gt;&lt;p&gt;兼容性上，MinT 做到了模型够大够全、接口完全一致 &amp;mdash;&amp;mdash; 与 Tinker API 完全兼容。这意味着使用 Tinker 的开发者可以几乎零成本地迁移到 MinT，享受国产基础设施带来的便利。&lt;/p&gt;&lt;p&gt;技术领先性上，MinT 不是简单的 &amp;ldquo;国产替代&amp;rdquo;。事实上，早在 2025 年 12 月 1 日，Mind Lab 就比 Thinking Machines 更早实现了 1T LoRA-RL，是业界在万亿参数模型上进行高效强化学习的第一个成果。&lt;/p&gt;&lt;p&gt;相关实现方案已经开源，并获得了 Nvidia 官方转载。&lt;/p&gt;&lt;p&gt;具体方案详见 Mind Lab 的技术报告：https://macaron.im/mindlab/research/building-trillion-parameter-reasoning-rl-with-10-gpus&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6fQjTAArySmqus1SJKvVHTMfDNVliaH0KIzS3FrX4zXrkiapXdlYEG16A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5768518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526613" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9dcc18d7-aa65-455e-ae03-072a1b3bce33/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;MinT 解决了什么问题？&lt;/h4&gt;&lt;p data-pm-slice="0 0 []"&gt;MinT 的核心价值可以用一句话说清：不论模型是1B还是1T，需要调度多少GPU，你只管数据和算法，基础设施的复杂工程全交给平台。&lt;/p&gt;&lt;p&gt;具体来说：用户只需在本地 CPU 机器上写几行 Python 代码，MinT 就会自动把计算任务分发到大规模 GPU 集群执行。集群调度、资源管理、容错恢复，这些让开发者和研究人员头疼的工程问题，统统由 MinT 搞定。切换不同的模型，只需修改代码中的一个字符串。&lt;/p&gt;&lt;p&gt;技术路线上，MinT 采用 LoRA 技术，使多个训练和推理任务可以共享同一计算资源池，从而显著降低成本。LoRA 在选择最优学习率的情况下，训练进程与全参数微调几乎完全一致，这为大规模高效后训练奠定了理论基础。&lt;/p&gt;&lt;h4&gt;目前，MinT 已支持 Kimi K2 Thinking（万亿参数级别的 MoE 推理模型）、Qwen3-VL 系列视觉语言模型等前沿开源模型，并全面兼容 Tinker API。值得一提的是，MinT 还优先支持了 &amp;pi;0 等具身 VLA 模型，这也体现出了中国公司在具身智能上的领先优势。&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LTibznqTsmeKhpl1LRmV9KWwibEF7ndPM1w4ia9ibSXbClo1NiaoCgglJCUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526463" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/ef80e279-c142-4717-ba05-6d61f04251e4/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;为什么需要 1T LoRA-RL？&lt;/h4&gt;&lt;p&gt;强化学习被视为让大模型从 &amp;ldquo;背题&amp;rdquo; 走向 &amp;ldquo;推理&amp;rdquo; 的关键，但现实里有三大难题：训练不稳，小模型难以收敛，算力成本高。LoRA 提供了一条低成本路径，只训练少量低秩适配器即可显著提升下游任务表现，且在 RL/Agent 训练上几乎不损失性能。&lt;/p&gt;&lt;p&gt;Mind Lab 在 Kimi K2（万亿参数 MoE）上实现了端到端 LoRA 强化学习，带来三点突破：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;成本：仅用常规全参 RL 约 10% 的 GPU 资源，64 块 H800 即可完成训练。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;稳定性：奖励与任务成功率平稳提升，无灾难性发散；在 held-out 基准上既提升特定任务，又保持基座模型通用能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;系统：统一调度张量 / 流水线 / 专家 / 序列并行，针对 MoE 路由不均衡与通信压力做了专项优化。相关技术已贡献至 NVIDIA Megatron-Bridge 与火山引擎 verl 等开源项目。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LicQl5utTv09mc7ZmfDdJPTKGmLpQhScehrZbosymeYRiaZrFWlAaibb2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.762962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526464" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/788c9863-a97c-45dd-bbb1-5ac255b6fc1a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;为什么选择 MinT？&lt;/h4&gt;&lt;p&gt;MinT 的产品设计围绕一个核心目标：把后训练和强化学习的门槛打下来。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;验证成本上：MinT 允许开发者仅用 CPU 机器进行训练验证，告别配置 GPU 驱动和 OOM 的烦恼。这让团队可以在投入大规模 GPU 资源前，先低成本验证算法可行性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;工程效率上：MinT 将采样、训练、回写与发布无缝串联，减少了工程拼装成本。并行策略、权重管理、optimizer state 管理、滚动训练、日志与可复现性等，都按工程标准打通。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开发体验上：MinT 完全兼容 Tinker API，现有代码可快速适配，切换不同模型只需一行代码。目前已支持 Qwen、Kimi 等先进的开源大模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;迭代速度上：采用 LoRA-RL 技术让模型迭代周期从 &amp;ldquo;按周&amp;rdquo; 缩短到 &amp;ldquo;按天&amp;rdquo;，真正服务于快节奏的产品开发需求。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LZG22NWxVibjZYMKv2QwOTF0iakB8mWHibjf78vSIt9TDMNdn1kpXz0Yaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.26851851851851855" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526465" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/f48c1560-3737-41d5-ab51-b0e097428da1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;h4&gt;谁是 MinT 最大的受益者？&lt;/h4&gt;&lt;p&gt;第一批使用 MinT 的受益者，一定是 Agent 领域的创业公司和研究模型的高校顶尖实验室。&lt;/p&gt;&lt;p&gt;它们共同的特点是：掌握核心的数据和问题的设定。他们并非不了解前沿算法，而往往是被算力与训练框架难住了。&lt;/p&gt;&lt;p&gt;据 Mind Lab 官网介绍，目前 MinT 已经获得了顶尖高校和多个创业公司的认可，应用场景涵盖基础研究到垂直行业的广泛领域。&lt;/p&gt;&lt;p&gt;在学术机构方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;清华大学人工智能学院黄高副教授&lt;/strong&gt;团队（CVPR best paper 以及 NeruIPS best paper runner up 获得者）利用 MinT 开展了 RL 如何突破 Base model 知识边界的研究。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;上海交通大学副教授、上海创智学院全时导师蔡盼盼&lt;/strong&gt;的 RoPL 实验室使用 MinT 在具身决策大模型和决策世界模型方面展开研究。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在行业应用方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;硅谷创业公司 &lt;strong&gt;Eigen AI&amp;nbsp;&lt;/strong&gt;合作探索运用 MinT 和 Data Agent 合成数据在 1T 模型上进行 agentic RL 训练。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;脑机接口公司&lt;strong&gt;姬械机&lt;/strong&gt;利用 MinT 支持了他们的脑机接口 Agent &lt;strong&gt;BCI-Love&lt;/strong&gt;，可以进行情感交互对话。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;瑞铭医疗&lt;/strong&gt;利用 MinT 对医疗编码模型进行了基于 RL 的后训练，显著提升了医疗编码的准确率，&lt;strong&gt;并落地到数十家三甲医院&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些案例展现了 MinT 的通用性 &amp;mdash;&amp;mdash; 从基础研究到垂直行业，都能用。&lt;/p&gt;&lt;h4&gt;中国团队引领后训练浪潮&lt;/h4&gt;&lt;p&gt;如何让模型真正 &amp;ldquo;理解&amp;rdquo; 而非只是 &amp;ldquo;记住&amp;rdquo;，是众多创业团队与科研工作者共同面对的核心问题。强化学习被视为解决这一问题的关键路径，但其高门槛、高成本与不稳定性，长期限制了它在真实产品和中小团队中的落地。&lt;/p&gt;&lt;p&gt;2025 年，中国团队在开源模型上大放异彩。&lt;/p&gt;&lt;p&gt;2026 年，后训练将是中国 AI 弯道超车的下一个关键战场。&lt;/p&gt;&lt;p&gt;Mind Lab 选择了 LoRA-RL 这一技术路径，在超大规模模型上完成了万亿参数级别的探索与验证，再次证明了中国团队在前沿研究上的工程能力与原创实力。MinT 正是 Mind Lab 希望将这些研究成果系统化、工具化的产物 &amp;mdash;&amp;mdash; 让后训练和强化学习不再只属于少数头部机构，而是成为更多公司与实验室可以日常使用的能力。&lt;/p&gt;&lt;p&gt;这正是 Mind Lab 真正布局的方向：让先进研究转化为可用工具，让中国团队在模型后训练与强化学习这一关键技术浪潮中，实现自主可控。&lt;/p&gt;&lt;section&gt;可以访问以下链接了解更多：&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;section&gt;Mind Lab 官网：&lt;a href="https://macaron.im/mindlab"&gt;https://macaron.im/mindlab &lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;相关文档：&lt;a href="https://mint.macaron.im/doc"&gt;https://mint.macaron.im/doc&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>ControlNet作者张吕敏最新论文：长视频也能实现超短上下文</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:39:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3a90df6c-40f3-401f-a574-a08345c9959e/1767461789356.png" style="width: 700%;" class="fr-fic fr-dib"&gt;大部分的高质量视频生成模型，都只能生成上限约15秒的视频。清晰度提高之后，生成的视频时长还会再一次缩短。&lt;/p&gt;&lt;p&gt;这就让尝试AI视频创意的创作者们非常苦恼了。要想实现创意，必须使用分段生成，结合首尾帧，不仅操作起来很麻烦，而且需要来回抽卡来保证画面的一致性。&lt;/p&gt;&lt;p&gt;那么，限制视频生成时长的瓶颈在哪里？&lt;/p&gt;&lt;p&gt;大家可能不知道的是，一段 60 秒、480p、24 帧/秒的视频，在模型内部会被拆解成 &lt;strong&gt;超过 50 万个「潜在 token」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这些 token 就像一条极长的记忆胶带，模型想要保持剧情连贯、画面一致，就必须从头到尾保存上下文记忆。但代价是：算力直接爆炸，普通显卡根本扛不住。&lt;/p&gt;&lt;p&gt;这正是当前自回归视频生成模型的核心矛盾。一边是越长的上下文，画面越连贯；另一边是越长的上下文，计算成本越高。&lt;/p&gt;&lt;p&gt;于是，研究者们不得不做出妥协：要么用滑动窗口切掉大部分历史，换取可运行的算力；要么对视频进行激进压缩，牺牲清晰度和细节。&lt;/p&gt;&lt;p&gt;问题在于，这些压缩方法往往最先丢掉的，正是决定画面真实感与一致性的高频细节。&lt;/p&gt;&lt;p&gt;也正是在这一困境下，&lt;strong&gt;苏州大学校友，斯坦福大学博士，ControlNet 创作者张吕敏团队&lt;/strong&gt;为此投入了研究&lt;strong&gt;，&lt;/strong&gt;提出了一种新的解决思路，给出了&lt;strong&gt;专为长视频设计的记忆压缩系统，在压缩的同时尽可能保留精细视觉信息。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6ntzwTaPZrJSGJWibn6Sh0xFuawwkzzOvn1B0pVevz8OSrHLPPIMKbmQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.21296296296296297" data-type="png" data-w="1080" data-width="1694" data-height="360" data-imgfileid="503526567" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/de2b4df6-f147-4d93-8755-19dd14bdb9eb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Pretraining Frame Preservation in Autoregressive Video Memory Compression&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2512.23851v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队提出了一种神经网络结构，用于将长视频压缩为短上下文，并设计了一种显式的预训练目标，使模型能够在任意时间位置保留单帧中的高频细节信息。&lt;/p&gt;&lt;p&gt;基线模型可以将一段&lt;strong&gt;&amp;nbsp;20 秒的视频压缩为约 5k 长度的上下文表示&lt;/strong&gt;，同时支持从中随机检索单帧，并在&lt;strong&gt;感知质量上保持良好的外观保真度&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种预训练模型可以直接微调为自回归视频模型的记忆编码器（memory encoder），从而以较低的上下文成本实现长历史记忆建模，并且仅带来相对较小的保真度损失。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6nEyUzOSCvIiaIiaXO1A1wuch9icnJt4CXNj3oA0KJeiclIdDoibQb5q764Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.49166666666666664" data-type="png" data-w="1080" data-width="1142" data-height="562" data-imgfileid="503526570" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/617126f8-783a-41c4-8658-37a0a5138fd1/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;该视频是使用完整历史上下文（不切割任何历史帧）逐秒自回归生成的。20 多秒的历史被压缩为 &amp;sim; 5k 上下文长度，并由 RTX 4070 12GB 处理。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全新的记忆压缩架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体而言，研究团队采用&lt;strong&gt;两阶段策略&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;首先，预训练一个&lt;strong&gt;专用的记忆压缩模型&lt;/strong&gt;，其目标是在任意时间位置上尽可能保留高保真帧级细节信息。&lt;/p&gt;&lt;p&gt;该预训练目标通过对从压缩历史中随机采样的帧最小化其特征距离来实现，从而确保模型在整个序列范围内都能稳健地编码细节信息。&lt;/p&gt;&lt;p&gt;在网络结构设计上，提出了一种&lt;strong&gt;轻量级双路径架构&lt;/strong&gt;：模型同时处理低分辨率视频流和高分辨率残差信息流，并通过将高分辨率特征直接注入 Diffusion Transformer 的内部通道，绕过传统 VAE 所带来的信息瓶颈，从而进一步提升细节保真度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;预训练记忆压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6VYclIm3XC3ojia6Y7ohfHTfRzmffPiaom5XDGoNqVicbCZXOpvOtsqcUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9779116465863453" data-type="png" data-w="996" data-width="996" data-height="974" data-imgfileid="503526569" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/55a28b11-a6bf-41e6-852e-e62f2369ca20/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;记忆压缩模型的预训练。记忆压缩模型需要将长视频（例如 20 秒）压缩成短上下文（例如长度为 5k）。预训练的目标是在任意历史时间位置检索具有高频细节的帧。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;该方法的&lt;strong&gt;核心创新在于其预训练目标设计&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;研究团队观察到，衡量视频压缩机制保留上下文细节能力的一个合适的指标是其任意时间位置高质量帧检索的能力。对于高压缩率，完美检索变得不切实际，因此目标变为最大化任意帧的检索质量。&lt;/p&gt;&lt;p&gt;给定一段长视频历史 H，记忆压缩模型 &lt;span data-meta-block-props='{"blockId":"973803be-232b-42a2-92a2-2756fcc10998","blockType":"EQUATION_BLOCK","initData":{},"props":{"data":{"equation":" \\phi(\\cdot)\n"},"displayMode":"inline","viewType":"inline"}}'&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6qEr9AMGBrcRsPehaEvu0E6KQlSpPn1HicTMgSiabGmMxatg9NK6ibHiaOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9444444444444444" data-s="300,640" data-type="png" data-w="108" type="block" data-imgfileid="503526582" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f00003e1-8c99-4012-8698-552ed010ab03/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;&lt;/span&gt;学习将其压缩为一个紧凑的上下文表示 &lt;span data-meta-block-props='{"blockId":"172ef25e-499d-4cbe-b735-6f3987ebd742","blockType":"EQUATION_BLOCK","initData":{},"props":{"data":{"equation":" \\phi(H)\n"},"displayMode":"inline","viewType":"inline"}}'&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX60y81u8hqicy3e5QHpAzUMyzrs6JG0vkIVia09OzXvsKUpkibicf2qMrL4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7692307692307693" data-s="300,640" data-type="png" data-w="156" type="block" data-imgfileid="503526583" data-aistatus="1" data-original-style="width:38px;height:29px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d25f0cba-e318-4cee-8651-794a54f60db6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 4.95%;"&gt;&lt;/span&gt;，同时仍然保持对&lt;strong&gt;任意时间位置帧&lt;/strong&gt;进行重建的能力。&lt;/p&gt;&lt;p&gt;在训练过程中，模型从历史序列中随机选择一组帧索引 &amp;Omega;，并对其余所有帧进行噪声掩蔽处理；模型必须仅依赖压缩后的表示来重建这些被选中的帧。&lt;/p&gt;&lt;p&gt;如上图所示，帧选择 &amp;Omega; &lt;span data-meta-block-props='{"blockId":"ef138d7a-f199-4790-8aa4-a155e3c33c09","blockType":"EQUATION_BLOCK","initData":{},"props":{"data":{"equation":"\\Omega\n\n"},"displayMode":"inline","viewType":"inline"}}'&gt;与检索过程 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX63Td8IxhnG3eibQNMOqH4KuZHYR9f3X7tehZT7qZ7wicHeL8WFm3081HQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4152542372881356" data-s="300,640" data-type="png" data-w="236" type="block" data-imgfileid="503526584" data-aistatus="1" data-original-style="width:64px;height:27px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e9124a17-0edd-4689-a739-31f69946103f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 7.7%;"&gt;&lt;/span&gt; 可以被构建为一个&lt;strong&gt;自回归视频扩散框架&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;本文采用以噪声作为掩蔽的方法：为被掩蔽帧加入服从&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6jengnEYaUyPacWRm8EPP4s8EDRAGAPztexgw99icfdvmNeheCqffvkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.43902439024390244" data-s="300,640" data-type="png" data-w="246" type="block" data-imgfileid="503526585" data-aistatus="1" data-original-style="width:65px;height:29px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/74cd78bf-119a-4e09-a27e-f0f10fe536e1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 7.06%;"&gt;的潜在噪声水平。&lt;/p&gt;&lt;p&gt;随后，研究团队将所选的干净帧复制作为扩散模型的目标，使扩散系统能够在任意时间位置重建目标帧。该过程可表示为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX69NAwLh9R5DuVcF2DdvNxwqwDsE9V8TosxJbOCGl8DZufesWQYACibeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.15399239543726237" data-type="png" data-w="1052" data-width="1052" data-height="162" data-imgfileid="503526566" data-aistatus="1" data-original-style="width: 397px;height: 61px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3647232f-0613-4358-bdb4-32bb3993bd38/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这种随机化选择机制有效防止模型通过仅编码易于访问的帧（例如首帧或末帧）来「投机取巧」，从而迫使模型学习一种能够在整个时间序列范围内持续保留细节信息的表示方式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6mBSA9c9Lz9EZjbtXGhicx4ick1miccIfoMMIyKxA7mozlvmnJpDNoqXWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.4718875502008032" data-type="png" data-w="996" data-width="996" data-height="470" data-imgfileid="503526568" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/acd7f2ec-afc7-4244-8735-a5349aab1f63/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;内存压缩模型的架构。使用 3D 卷积、SiLU 和注意力机制来构建一个轻量级的神经网络结构，作为基准压缩模型。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;视频扩散模型的微调&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6owEAkic3p28rgL6ZicKpgKunRXKF14yrnbbKdaicBYXGDDiarjJY2Fibiauw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3965863453815261" data-type="png" data-w="996" data-width="996" data-height="395" data-imgfileid="503526572" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/714d42ff-c701-4d71-ab06-55af827343b5/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;微调自回归视频模型。展示了最终自回归视频模型的微调和推理过程。记忆压缩模型的预训练在微调之前完成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;借助预训练完成的记忆压缩模型&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6qEr9AMGBrcRsPehaEvu0E6KQlSpPn1HicTMgSiabGmMxatg9NK6ibHiaOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.9444444444444444" data-s="300,640" data-type="png" data-w="108" type="block" data-imgfileid="503526582" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/cf660150-e057-4dcb-82dc-0ebb3bd2933e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.85%;"&gt;&amp;nbsp;，可以通过对视频扩散模型（例如 WAN，并结合 LoRA 微调）以及该压缩模型作为历史记忆编码器进行联合微调，从而构建一个自回归视频生成系统。&lt;/p&gt;&lt;p&gt;由此得到的视频生成模型具备超长历史窗口（例如超过 20 秒）、极短的历史上下文长度（例如约 5k），并且对帧检索质量进行了显式优化。&lt;/p&gt;&lt;p&gt;该扩散过程亦可按照公式表示为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6tATcP3WDMxpibVjOZzszibWpCf17SAE1xZP3Tm606OeDUSpVNnpqYrMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.1364522417153996" data-type="png" data-w="1026" data-width="1026" data-height="140" data-imgfileid="503526571" data-aistatus="1" data-original-style="width:393px;height:54px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/60846920-f904-47e0-b40c-e001106fcf54/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验中，研究团队使用 8 &amp;times; H100 GPU 集群进行预训练，并使用 1 &amp;times; H100s 或 A100s 进行 LoRAs 微调。所有实验均在 HunyuanVideo和 Wan 系列的基础模型上进行。&lt;/p&gt;&lt;p&gt;数据集由来自多个网站的约 500 万互联网视频组成。其中约一半是竖屏短视频，其余为普通横屏视频。数据经过质量清洗，然后使用 Gemini-2.5-flash VLM 对高质量部分进行字幕标注，剩余部分使用本地 VLM（如 QwenVL）进行处理。测试集包括由 Gemini-2.5-pro 编写的 1000 个故事板提示和 4096 个未在训练数据集中出现过的视频。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定性与定量评估&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6lX4ug0torwlpIJR98PiaWNSG2PDnJAWhB7uIg8oMrfBYRmPLvEJlvvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.42592592592592593" data-type="png" data-w="1080" data-width="1142" data-height="486" data-imgfileid="503526575" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/09264eff-cf7e-43ad-8ba7-7aa032b6f1d2/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;故事板上的定性结果。通过从故事板中流式传输提示来展示结果。故事板是一组提示，其中每个提示涵盖一定数量的帧。故事板可以由外部语言模型编写。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在定性评估方面，如图所示，研究者证明了模型能够处理多种多样的提示和故事板，同时在角色、场景、物体和情节线方面保持一致性。&lt;/p&gt;&lt;p&gt;在定量评估方面，研究者们从 VBench、VBench2等平台引入了多个视频评估指标，并进行了一些修改。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6DgLECiaGe7sl6qJDW6GNaaaToHm73ibeAr9Na8s6Bs16CqLcFviaAl2Dw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.4351851851851852" data-type="png" data-w="1080" data-width="1506" data-height="656" data-imgfileid="503526574" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/db1ef678-34e7-4e7a-b3d1-c3689e1f3767/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;视频内容一致性的定量评测结果。其中，Qwen 中的 「1p」 表示仅使用 1 张图像 作为图像模型输入。由于部分方法存在严重伪影，因此未将其纳入人工 ELO 评分统计。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如表所示，本文提出的方法在多个一致性指标上表现出合理的分数。Wan+Qwen 组合在实例分数上似乎具有领先分数，这可能是由于图像模型不会显著改变或移动对象，从而避免了 VLM 问答检测到的伪影。本文的方法在对象一致性方面表现出有竞争力的分数。此外，用户研究和 ELO 分数验证了本文提出的架构，证实它在压缩和质量之间实现了有效的权衡。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;消融实验&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6MleyBBiajl9POicKZD2k8Lsb9ySJFKjTOeGNXl5tqvkesvBTsOHXrvQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.4824074074074074" data-type="png" data-w="1080" data-width="1232" data-height="594" data-imgfileid="503526573" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/63980fb6-5535-484a-867a-1c1f3682cbaa/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 压缩结构的定量结果。展示了使用不同消融压缩架构的数值测试。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;评测结果如表所示。结果表明，本文方法在 PSNR、SSIM 等指标上取得了相对更优的性能。此外，即便在 4&amp;times;4&amp;times;2 的较高压缩率条件下，该方法仍然能够有效保持原始图像结构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6mnbEia2xBbwLjA8Gd3qrnJEgdRkD1dSZiaOia1Fv8YfqC7lofODFu2VWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.5046296296296297" data-type="png" data-w="1080" data-width="1142" data-height="576" data-imgfileid="503526578" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/6612af3d-77e7-4185-9224-739802d64b5b/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;压缩重建的视觉比较。展示了使用不同可能的神经网络结构和各种压缩设置进行预训练后的重建结果。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6Jb4ocwSOpPOE0abwBuYw2f9JseuBu78WxhJz3b5TpteibHXegoD7uRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.3787037037037037" data-type="png" data-w="1080" data-width="1142" data-height="433" data-imgfileid="503526577" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/7e02e277-3ecb-4536-9eca-a8b612251f23/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;记忆压缩模型预训练的影响。展示了使用或未使用记忆压缩模型预训练的结果。输入是相同的 20 秒历史视频，在输出帧中可视化中间帧。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;除此以外，研究团队还在论文中讨论了不同神经网络架构设计之间的权衡取舍。&lt;/p&gt;&lt;p&gt;更多信息，请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>4个月烧掉30亿Token，这位「菜鸟」程序员做出50多个产品，360万人围观</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:33:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e6620652-ba3e-4b71-842d-7b7d65629045/1767461471804.png" style="width: 700%;" class="fr-fic fr-dib"&gt;长久以来，代码世界的大门似乎只对少数掌握秘术的人敞开。我们被告知：你必须先理解内存、掌握语法、忍受枯燥的文档，才配谈论创造。&lt;/p&gt;&lt;p&gt;现在，随着大模型的发展，编程不再是一场苦修，而是一场大型即时策略游戏。在这个游戏里，很多人学会了与 AI 并肩作战，学会了用一种更纯粹、更直抵本质的方式去构建自己想要的世界。&lt;/p&gt;&lt;p&gt;Ben Tossell（Factory 开发者关系主管）就是其中一员。他是一位不怎么会写代码的人，在过去四个月里，却消耗了 30 亿个 Token。&lt;/p&gt;&lt;p&gt;这意味着每一分、每一秒，他都在通过终端窗口，观察 AI Agent 写下那些他凭一己之力永远无法写出的复杂代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="765" data-imgfileid="503526606" data-ratio="0.770392749244713" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6cCmAhoj1l7IB4QYrY5AJ8hCWSHoJY0R3Z2TSa6pZeRFn4iamUQkgQ5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="993" data-width="993" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6a89c0f5-f5a9-43dc-bd1c-4f74601d3093/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;或许有人会将这种方式贬低为所谓的氛围编程（Vibe-coding），但在 Tossell 看来，这个词带有某种傲慢的偏见。它像极了 2019 年人们对无代码（No-code）的刻板印象 &amp;mdash;&amp;mdash; 而正是那一年，他创办了自己的无代码教育公司并最终被 Zapier 收购。这种偏见选择性地忽视了隐藏在交互与调度背后的核心技能。&lt;/p&gt;&lt;p&gt;在 Tossell 看来，编程新范式下，衡量一个人的技术能力不再是看他能否默写语法，而是看他能否驾驭系统。&lt;/p&gt;&lt;p&gt;从无代码时代的先行者，到如今 30 亿 Token 的调度者，Ben Tossell 证明了一件事：在 AI 时代，通向代码世界的最高通行证不是专业背景，而是那种为了探索而探索的欲望。&lt;/p&gt;&lt;p&gt;为了记录这些体验，Tossell 还专门写了一篇文章，其在 X 上的浏览量已经超过了 360 万。接下来我们看看文章内容。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实际交付的产品&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然烧掉了 30 亿 Token，但 Tossell 表示自己也是收获满满，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;个人网站：Tossell 重新设计了个人网站，使其看起来像一个终端 CLI 工具。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Feed：Tossell 构建了一个简单的社交媒体追踪器，跟踪 subreddit 帖子和 GitHub 问题。它是开源的，得到了 100 多个 stars，很多人也克隆了这个项目。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Factory Wrapped：Tossell 构建了 Factory 产品的第一个版本，展示给团队后他们非常喜欢，并决定将其融入到实际产品中，现在已经上线。Tossell 还添加了新的指南，重新整理了一些内容。虽然这看起来不像传统的编码，但对 Tossell 来说，它依旧是编码，整个过程没有变。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;定制 CLI 工具：创建了一些 CLI 工具，例如 Pylon CLI，团队用它来帮助处理客户支持请求。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;加密追踪器：Tossell 投资了一家能够准确预测金融、天气、健身和蛋白质折叠等动态数据中正面、负面或中性信号的公司。Tossell 基于这些预测构建了一个加密追踪器，能够自动根据预测开设和关闭多空仓位，类似一个迷你对冲基金。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Droidmas：这是一个 12 天的实验或游戏，围绕 X 上人们讨论的不同主题展开，记忆、上下文管理、vibe coding 等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 指导的视频演示系统：简单来说，给它一个提示，它会创建一个视频。该系统作为自己的导演、制片人和编辑，能实时观看录制过程，并根据情况做出反应。如果遇到问题、bug，或者需要等待响应，它会处理。Tossell 用这个系统制作了一段视频，并由 OpenAI 发布。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，Tossell 还做了大约 50 个其他项目，其中有些已经被遗弃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;完全使用 CLI 来工作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tossell 的战场不在花哨的网页界面，而是在纯粹的 CLI（命令行界面）。他认为终端胜过网页界面，并且还能看到它的工作过程。&lt;/p&gt;&lt;p&gt;每当 Tossell 有一个新的想法，或者遇到一个问题，Tossell 就会在 Droid（Factory 的 CLI）中启动一个新项目。他会与模型交流几次，提供上下文，然后切换到规范（spec）模式，制定构建计划。&lt;/p&gt;&lt;p&gt;在规范模式下，Tossell 会提出很多问题，比如他不理解这个是什么，为什么需要这个而不是那个，难道不能这样做吗？等等。&lt;/p&gt;&lt;p&gt;接着，在运行时，Tossell 让 Opus 4.5 在高自主性模式下运行，查看发生了什么，并在遇到错误时介入，最后进行测试，提供反馈并迭代。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;agents.md 设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tossell 花了很多时间来思考如何设置最佳的 agents.md，因为这基本上就是操作手册。&lt;/p&gt;&lt;p&gt;Tossell 本地有一个 repos 文件夹，所有的编码项目都放在那里。在这个文件夹中，有一个 agents.md 文件，里面明确规定了每个新仓库的设置流程，做什么、不做什么，如何使用 GitHub、如何提交代码之类的内容，还会标明是否使用工作 GitHub 账户或个人 GitHub 账户。&lt;/p&gt;&lt;p&gt;端到端测试是 Tossell 以前没有特别关注的事情，但现在他非常希望在每个项目中都进行端到端测试。&lt;/p&gt;&lt;p&gt;基于他目前的知识和能力，很多时候在构建和测试过程中，总会有一些本应该早早发现的低级 bug，如果一开始就做了测试，可能就能避免这些问题。&lt;/p&gt;&lt;p&gt;Tossell 表示，他也经常查看他人的 agents.md 文件，看看有哪些可以借鉴的地方。Tossell 一直在努力改进自己的文档，从而让每次新的工作会话更加顺畅。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Tossell 学到了什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tossell 主要通过 CLI 而非 MCP 进行工作，不过他曾经使用过 MCP，但现在更倾向于使用 CLI 版本，因为它简单且更高效。比如在 Supabase、Vercel 和 GitHub 上，Tossell 总是使用 CLI 而非 MCP。&lt;/p&gt;&lt;p&gt;他还经常为自己的需求创建 CLI 工具。比如，他构建了自己的 Linear CLI，这样就能通过终端查询问题并执行任务，而不需要进入桌面或网页界面。&lt;/p&gt;&lt;p&gt;Bash 命令：Tossell 在处理变更日志的过程中真正理解了 Bash 命令的工作原理。这是一个重复的过程，最终理解了工作流程。Tossell 让 Droid 创建了一个斜杠命令流程，这是 Tossell 第一次正确使用的命令，它运行多个 Bash 命令，并提示模型做一些特定的任务，比如查看 GitHub 差异、检查功能标志的状态，或者将新功能和 bug 修复放到正确的部分。&lt;/p&gt;&lt;p&gt;VPS：Tossell 之前对 VPS 有一个抽象的理解，知道它是一个 24 小时运行的远程计算机。直到 Tossell 真正需要使用 VPS 时，Tossell 才深入了解它的用途。现在，Tossell 使用 VPS 来运行加密追踪器，获取每分钟的数据，同时保持它始终在线。使用 Droid Telegram 机器人时，Tossell 也依赖 VPS，通过 SyncThing 同步本地的仓库到 VPS，这样 Tossell 的仓库总是保持最新状态，能够随时接着上次的状态继续工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新的可编程抽象层&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在看到 Andrej Karpathy 的推文时，Tossell 深有感触 &amp;mdash;&amp;mdash; 现在有了一个新的可编程抽象层需要掌握。&lt;/p&gt;&lt;p&gt;在无代码时代，抽象层是像 Webflow、Zapier 和 Airtable 这样的拖拽工具，将它们拼接在一起，让它看起来像真实的软件（直到你遇到限制）。&lt;/p&gt;&lt;p&gt;但现在，我们不再认为自己必须从零开始学习编写代码才能做这些事情，实际上，需要学习的是如何与 AI 合作。如何给它提供合适的提示？如何确保它拥有正确的上下文？如何把各个部分结合起来以及如何随着时间推移不断优化系统等等。&lt;/p&gt;&lt;p&gt;为了更好的掌握 AI 编程技能，Tossell 还会阅读像 Peter Steinberger 这样的程序员的帖子。从他的帖子中，Tossell 看到了他系统的简洁性：他只是和模型互动，让模型做事。这一发现让 Tossell 感到非常有信心，也让 Tossell 明白自己不需要一个复杂的系统。&lt;/p&gt;&lt;p&gt;Tossell 表示，在 X 上，你会看到很多人不断优化，甚至可能是过度优化自己的系统。对于像 Tossell 这样的人来说，这有时会感到很有压力，但他也认为这正是这个系统的魅力所在：它是一个完全可定制的系统，你可以根据自己的需要，让它按照你希望的方式工作。你可以像 Kieran 一样创建一个计划模式，或者像 Peter 一样直接与模型对话。&lt;/p&gt;&lt;p&gt;不过，他有时也会遇到 bug 和问题，但他明白这些问题其实是用户知识的空白，而不是自己当前能力的局限。&lt;/p&gt;&lt;p&gt;Tossell 的任务是识别这些空白，找到它们，并思考：如何确保这种问题永远不会再发生？或者如何确保自己足够理解这部分系统，以便下次发生时能及时发现。&lt;/p&gt;&lt;p&gt;所以，我们需要做什么呢？其实你只需要问模型。模型知道你不知道的所有东西。你可以不断向它提问。它是你永远耐心的、在你肩膀上的专家程序员。 你可以在 agents.md 中写道：Tossell 不是程序员，你需要非常简单地解释给 Tossell 听。你可以根据自己的需求完全定制它&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们学习的方式改变了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;以往，Tossell 尝试过很多次学习编程，每次都是输入这些字符，按下回车，看看是不是显示 hello world。但 Tossell 觉得这和今天的学习方式差别很大。&lt;/p&gt;&lt;p&gt;如果按照传统的方式来学习编程，想要达到现在能构建的程度，可能需要花费数月甚至数年的时间才能有信心自己写代码。&lt;/p&gt;&lt;p&gt;而现在，Tossell 是从理解代码构建项目的系统思维角度来学习的。Tossell 在经营无代码教育公司时，无意中学到了这一点。你依然要理解：Webflow 是前端，Zapier 是 API 路由和连接层，数据流动，而 Airtable 是数据库。所以 Tossell 之前学会了这些系统化的思维，今天可以帮助他理解这些组件。&lt;/p&gt;&lt;p&gt;有太多东西可以学习了，但也是没有任何软件是不可达成的。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;学会提出那些「愚蠢」的问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人们常会冒出一些看似笨拙的问题，那些资深程序员或许早已习以为常，不再追问。&lt;/p&gt;&lt;p&gt;比如：既然框架是为了简化人类的工作，而现在的 LLM 已经如此强大且智能，为什么我们不干脆抛弃沉重的框架，让它直接写出最纯粹、零依赖的代码？这样不是能大大减少 Bug 和维护成本吗？&lt;/p&gt;&lt;p&gt;后来 Tossell 逐渐意识到，这并非一个傻问题。框架的存在，不仅是工具，更是共识与生态。LLM 的智慧源于海量的训练数据，而这些数据大多根植于现有的成熟框架之中。&lt;/p&gt;&lt;p&gt;这就是 Tossell 构建认知的过程。以前，Tossell 总觉得自己是代码世界的门外汉，甚至觉得这个领域高不可攀；而现在，通过这些直抵本质的提问，Tossell 正一步步拆掉思维的围墙。他不再只是一个使用者，而是正真实地成为这个工程世界的一部分。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于氛围编程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然现在氛围编程这个词很火，但 Tossell 总觉得它没能触及灵魂。我们所做的，远不止于凭感觉，而是在深度理解系统 &amp;mdash;&amp;mdash; 去拆解它的逻辑，去改进它的构造。作为新时代的技术阶层，我们究竟该如何定义自己？&lt;/p&gt;&lt;p&gt;Tossell 不想称自己为非技术人员，但 Tossell 也不想被框在程序员这个传统标签里。他更像是一个处在某种无名阶层中的探索者。如果说无代码曾是一种误读，那么 Vibe Coding 现在也正带着某种傲慢的偏见。&lt;/p&gt;&lt;p&gt;对 Tossell 来说，编程更像是一场真实存在的宏大游戏。&lt;/p&gt;&lt;p&gt;这种新范式迷人之处在于：每一个创意都能被即刻实践，每一个念头都能深入探索。它不需要从一开始就追求完美，因为在这个过程中，掌握系统真谛才是重要的。就像代码未必都要上传 GitHub，有时候，它们只是通往某个系统深处的路标。&lt;/p&gt;&lt;p&gt;我们不要再为了工具而去生产工具。就像看到别人的 React 抓取工具，Tossell 不再只是感叹，而是会问自己： 我能做一个属于自己的吗？它的原理是什么？这种为了探索而探索的自由，正是新技术赋予我们的最高权限。&lt;/p&gt;&lt;p&gt;以前，学会编程更像是一种重资产投入。Tossell 曾以为，如果我们费尽心力做出了一个想法的简陋原型，结果却无人问津，那我们一定会因为投入了太多情感和成本而无法放手。&lt;/p&gt;&lt;p&gt;但在无代码时代，Tossell 第一次尝到了快节奏的甜头：一两个小时，一个周末，快速成型。如果市场不买单，那就随它去吧。因为投入极低，所以放手极快。&lt;/p&gt;&lt;p&gt;而现在，AI 让这种反馈循环达到了光速。&lt;/p&gt;&lt;p&gt;我们正处于软件大爆炸的前夜。你会看到平庸的作品泛滥，但更会看到无数惊艳的项目井喷。那些资深的程序员正以前所未有的速度发布着令人赞叹的开源工具。这意味着，我们拥有了一个取之不尽的灵感库和零件厂，可以随时克隆、调整、重混。&lt;/p&gt;&lt;p&gt;比起从读写文件这种最底层的语法练起，这种以结果为导向的重组效率高得惊人。反馈是即时的，输出是持续的。你不需要在起跑线上纠结太久，你只需要不断地去尝试，去碰撞。&lt;/p&gt;&lt;p&gt;在这个范式下，每一个创意都不再是沉重的负担，而是可以随时抛出的探针。如果你想，你可以随时随地、随心所欲地去构建一切。&lt;/p&gt;&lt;p&gt;Tossell 坚信，每个渴望进入技术世界的人都能做到这一点。你不需要计算机学位，你只需要一份允许自己去玩的许可。把编程看作一场游戏：去注册一个 CLI 智能体，告诉它你想做一个 RSS 追踪器、健身应用或个人网站。然后，按下启动键。&lt;/p&gt;&lt;p&gt;在这个过程中，你会撞上无数 Bug，但这正是最精彩的部分。你不再被错误困扰，而是开始好奇：为什么会这样？你要知道，即便顶尖专家也难逃 Bug 的围攻，而你拥有 ChatGPT 或 Claude 这样的多维智囊团。你可以从不同模型中获取视角，在无数种方案中做出选择。&lt;/p&gt;&lt;p&gt;在工具的丛林里，准则只有一条：最快、最简、最远。&lt;/p&gt;&lt;p&gt;面对琳琅满目的工具，没必要陷入选择瘫痪。选定一个，深挖下去。如果觉得缺了什么，尝试自己去造。&lt;/p&gt;&lt;p&gt;Tossell 最后总结说：「这整件事对我而言，是一场巨大的、令人享受的学习实验。不断构建，不断向前失败，然后不断把新作品推向世界。」&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://x.com/bentossell/status/2006352820140749073&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>LeCun在Meta还有论文：JEPA物理规划的「终极指南」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:29:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5606dbf9-4c0f-472c-89ad-f665d94b1d77/1767461152128.png" style="width: 700%;" class="fr-fic fr-dib"&gt;长期以来，AI 领域一直怀揣着一个宏大的梦想：创造出能够像人类一样直观理解物理世界，并在从未见过的任务和环境中游刃有余的智能体。&lt;/p&gt;&lt;p&gt;传统的强化学习方法往往比较笨拙，需要通过无数次的试错和海量的样本才能学到一点皮毛，这在奖励信号稀疏的现实环境中简直是灾难。&lt;/p&gt;&lt;p&gt;为了打破这一僵局，研究者们提出了「&lt;strong&gt;世界模型&lt;/strong&gt;」这一概念，即让智能体在脑海中构建一个物理模拟器，通过预测未来状态来进行演练。&lt;/p&gt;&lt;p&gt;近年来，虽然能够生成精美像素画面的生成式模型层出不穷，但对于物理规划而言，沉溺于无关紧要的细节（如背景烟雾的流动）往往是低效的。真正的挑战在于，如何在错综复杂的原始视觉输入中提取抽象精髓。&lt;/p&gt;&lt;p&gt;这便引出了本研究的主角：&lt;strong&gt;JEPA-WM（联合嵌入预测世界模型）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;从名字也能看出来，这个模型与 Yann LeCun 的 &lt;strong&gt;JEPA（联合嵌入预测架构）&lt;/strong&gt;紧密相关。事实上也确实如此，并且 Yann LeCun 本人也是该论文的作者之一。更有意思的是，在这篇论文中，Yann LeCun 的所属机构为 Meta FAIR。不知道这是不是他在 Meta 的最后一篇论文？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX68YxNjugbtXkMjk0dMp0GGdRictyDWnRclVzOc4KPPywtgGo16ed5rEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.38055555555555554" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526588" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2403494c-94f8-4be4-aac9-cf23f974f9cb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.24497&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;JEPA-WM 继承了 JEPA 的衣钵，不再纠结于像素级的重建，而是&lt;strong&gt;在高度抽象的表征空间内进行预判&lt;/strong&gt;。在这项研究中，团队试图通过对架构、目标函数和规划算法的全方位扫描，揭示究竟是什么驱动了物理规划的成功，并试图为机器人装上一个更理性的「大脑」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;JEPA-WM 核心方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该团队将 JEPA-WM 的训练与规划流程形式化为一套统一的「终极指南」，重点在于如何在学习到的特征空间中模拟动力学。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 层次化的编码与预测架构&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6m0DCDB1rO2PjSb4bpE7KbhpKTD5Wf39c6LOM3CVCJ6xqibxNP4jcd7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5027777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526589" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1cb180f9-e7e4-4829-9fa8-269446845f43/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在训练阶段，模型主要由四部分交织而成：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉编码器&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6Sh1picVvKKxS6DeJmf4eib3TY4KGHWzNgk3gzJ20jibGnRtX212Y3baWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6962962962962963" data-s="300,640" data-type="png" data-w="135" type="block" data-imgfileid="503526587" data-aistatus="1" data-original-style="width: 35px;height: 24px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/26c8bc0a-1fc5-4001-8991-b4fa80bf993c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 5.23%;"&gt;：使用预训练且冻结的 ViT 权重（如 DINOv2 或 DINOv3）来提取空间特征，确保模型具备敏锐的视觉感知力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;本体感受编码器&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6XdHVYRHd6ORX4icLNX7Zl23KJA9ibwrNKnIiafmtmsAm4pJ0XrYq1bickg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5272727272727272" data-s="300,640" data-type="png" data-w="165" type="block" data-imgfileid="503526590" data-aistatus="1" data-original-style="width: 43px;height: 23px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7adfe226-d658-4b59-ac10-3b86361b8ca2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 6.63%;"&gt;：一个浅层网络，用于捕捉机器人自身的关节角度和位姿，这与视觉信息共同构成了全局状态嵌入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;动作编码器 &lt;/strong&gt;A_&amp;theta;：将机器人的控制指令转化为同维度的特征向量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;预测器 &lt;/strong&gt;P_&amp;theta;：这是模型的心脏。它接收过去窗口内的观测序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6lsaA7j2br8pUhZTqqxkIJg3QF94pAaTMfMc8ibDUleyibicagNqY0RERA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3090909090909091" data-s="300,640" data-type="png" data-w="110" type="block" data-imgfileid="503526591" data-aistatus="1" data-original-style="width: 76px;height: 23px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/54435c81-cb97-4179-8f1f-e95927d2e1aa/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 10.46%;"&gt; 和动作序列&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6pV75vaHjK0sv1aKOIVc2cRA3Gfy5CicW1JE8oA0DCtGj5AzwROaR2aA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.32075471698113206" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503526592" data-aistatus="1" data-original-style="width: 65px;height: 21px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/2fc6422e-f46b-41b9-b7a6-fcf91c012816/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 10.55%;"&gt;&amp;nbsp;，在因果掩码的保护下，并行预测下一时刻的状态嵌入。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 多步展开与动作调节细节&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了让模型不至于「走一步看一步」，研究者引入了多步展开损失&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX662uNuU6G1v2DWy1n0ia00QWxtu4MlibD2RfbKLVMMbpemAodSF6voVIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9565217391304348" data-s="300,640" data-type="png" data-w="46" type="block" data-imgfileid="503526593" data-aistatus="1" data-original-style="width: 26px;height: 25px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/d3e2acf4-d952-4da3-9154-896c1cda9c4f/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.21%;"&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6HAgWXTllUgVgpKHWRQCBe72oXs0fCiaO5ic6J1KRKqaP7ZxibwXgzibwbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.13165829145728644" data-s="300,640" data-type="png" data-w="995" type="block" data-imgfileid="503526594" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ad619104-4b01-4067-8d3c-492a307a0dbb/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在训练时，模型不仅要预测下一帧，还要学会在没有真实观测反馈的情况下，基于自己的预测结果递归生成后续状态。为了提高效率，采用了截断反向传播（TBPTT），即只针对最后一步的预测误差计算梯度，而切断之前的累积梯度。&lt;/p&gt;&lt;p&gt;在动作信息如何干预预测过程上，该团队对比了三种关键方案：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征调节（Feature Conditioning）&lt;/strong&gt;：将动作向量直接拼接到每一个视觉特征向量上，增加了预测器的隐藏层维度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;序列调节（Sequence Conditioning）&lt;/strong&gt;：将动作作为一个独立的 Token 插入到 ViT 的输入序列中，通过注意力机制进行信息分发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自适应层归一化（AdaLN）&lt;/strong&gt;：动作嵌入被投影为缩放和偏移参数，在每一个 Transformer 块中动态调制归一化统计量，这能有效防止动作信号在深层网络中「淡出」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 规划逻辑：在嵌入空间中寻找最优解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;规划被建模为一个在动作空间 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6BEtwOLy7qiauayBTIWiafBr4APxqYEibicQhAAIjgxjwu6tPobsP2gBFxA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.3761467889908257" data-s="300,640" data-type="png" data-w="109" type="block" data-imgfileid="503526595" data-aistatus="1" data-original-style="width: 62px;height: 23px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c50ce09b-7f81-4606-9059-2be7da1962bc/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 6.6%;"&gt; 上的优化问题。给定初始观测 o_t 和目标图像 o_g，智能体会在其内部模型中「试运行」N 条候选路径。评价标准是预测终点的嵌入向量与目标嵌入向量之间的距离&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX60b7YzibOjlKSlWvV5aaLMKE82FXSl859DZU8u7WnyGoWbCU3xnmhE4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.21794871794871795" data-s="300,640" data-type="png" data-w="234" type="block" data-imgfileid="503526596" data-aistatus="1" data-original-style="width: 123px;height: 27px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/14104433-63b2-4b8c-9592-f8ec17190b1a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 12.47%;"&gt;。通过多轮迭代，优化器会不断收敛动作分布，最终输出最优的第一步或前 m 步动作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验与结果：从模拟器到真实机械臂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 Metaworld（42 个操纵任务）、Push-T（物体推送）、PointMaze（导航）以及 DROID（真实机械臂数据集）上进行了评估。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 规划器之争：梯度 vs 采样&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验结果揭示了一个有趣的现象：在像 Metaworld 这种成本曲线相对平滑的任务中，基于梯度的 Adam 或 GD 优化器表现惊人，因为它们能顺着梯度迅速找到目标。但在 2D 导航（Wall, Maze）任务中，梯度法极易卡在局部极小值（例如对着墙猛撞而不懂得绕过门口），此时&lt;strong&gt;基于采样的交叉熵方法（CEM）&lt;/strong&gt;凭借其探索能力完胜。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWictGgomjsDDxhRKpchgqbX66nLeiahjria1mGzUqhrAhuFILarTlRmZ1niaOoAzqfnFDiaDT5qpfXiaxaA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.44537037037037036" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526601" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/98c77a15-ec3e-4b20-ad48-b5ed6b21d6c5/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，新引入的&lt;strong&gt; Nevergrad（NG）&lt;/strong&gt;规划器在无需调参的情况下展现了与 CEM 相当的实力，尤其适合跨任务迁移。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 关键因素的「贡献度」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了量化不同设计决策对智能体最终表现的影响，研究团队采用了一种严谨的控制变量法。&lt;/p&gt;&lt;p&gt;他们以一个基础配置（DINO-WM 结合 ViT-S 编码器及 6 层预测器）为基准，独立改变每一个核心组件，从而在复杂的系统工程中剥离出真正驱动性能增长的关键因子。通过在 Metaworld、Push-T 等多种异构环境下进行数以万计的幕（Episode）测试，实验揭示了世界模型在处理物理逻辑时的内在偏好。以下是影响物理规划成败的核心贡献因素：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;本体感受的显著增益&lt;/strong&gt;：引入机器人内部状态信息（如关节角度、末端位姿）能够一致性地提高规划成功率。在 Metaworld 任务中，这能有效减少机械臂在目标点附近震荡的情况，提供更精准的距离感知。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6I4CRzCs7NnLArxjqW5X4OalfGvdz15rx36qRnKCLWTA59AYBpYJE8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.4222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526597" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/431501cc-df38-40c7-8822-32fd030cbc94/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;编码器架构&lt;/strong&gt;：DINO 系列编码器（DINOv2/v3）在所有任务中均表现出对 V-JEPA 等视频编码器的明显优势。这归功于 DINO 强大的细粒度目标分割能力，这对于需要精确感知物体位置的操纵和导航任务至关重要。在视觉复杂度更高的真实数据（DROID）中，DINOv3 的优势进一步扩大。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;动作调节技术的微妙差异&lt;/strong&gt;：实验发现 AdaLN（自适应层归一化）调节技术在平均性能上表现最强，且计算效率更高。它通过在 Transformer 的每一层注入动作信息，有效防止了控制信号在深层网络传递过程中的消失，相比传统的特征拼接（ftcond）或序列拼接（seqcond）更具稳健性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6BJsmkchtauialiaQwDYY0duEUqZ0MPIbtynEfw1SCXXVdLxfbPPxuCVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4546296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526598" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/9b7f24c9-4896-4ce1-b9a1-1160ef9ded68/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;训练上下文长度的权衡&lt;/strong&gt;：预测器需要至少 2 帧上下文来推断速度信息，这在 W=1 与 W=2 之间的巨大性能鸿沟中得到了印证。然而，&lt;strong&gt;盲目增加上下文长度（如 W &amp;gt; 5）反而有害&lt;/strong&gt;，因为这会减少训练中看到的独特轨迹数量，并可能引入无用的梯度噪声。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6ASiaZ9gCydTDkc0787DSCbN0NiakkALDMsq2ib6G0SVicfVrmF2cn9Hiahw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.4564814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526599" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/6ad53ecd-62c4-4f20-afd8-0ca360e0b253/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;模型规模&lt;/strong&gt;：这是一个令人意外的发现：&lt;strong&gt;在简单的模拟环境（如 Maze, Wall）中，增大模型规模（从 ViT-S 到 ViT-L）非但没有帮助，反而可能由于嵌入空间过于复杂而导致规划效率下降&lt;/strong&gt;。但对于复杂的现实数据（DROID），大容量的编码器和更深的预测器则展现出了明确的正相关收益，说明任务的物理复杂度决定了智能体所需的智力上限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多步损失的对齐作用&lt;/strong&gt;：在训练中加入 2 步展开损失能显著改善预测器的长时稳定性，使其训练任务与测试时的递归规划任务更加对齐。对于最复杂的 DROID 任务，最佳的展开步数甚至需要达到 6 步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 提出的最优解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究最终汇总所有洞察，提出了针对不同任务的最优配置：&lt;strong&gt;在模拟器中使用 ViT-S 配以 AdaLN，而在真实复杂场景中使用 DINOv3 ViT-L 配以 12 层深度的预测器。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWictGgomjsDDxhRKpchgqbX6PgkuHVyd2aD1v9wHU2vtYGa1DOhHk2JmicLhunA96KcctDOtTYoic4Ug/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.22962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526600" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/06fdad66-87ca-47e8-9099-86c87ea0e617/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在与 DINO-WM 和 V-JEPA-2-AC 的直接较量中，该模型在几乎所有维度上均取得了领先。&lt;/p&gt;&lt;p&gt;更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>微信炼出扩散语言模型，实现vLLM部署AR模型3倍加速，低熵场景超10倍</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:23:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/a37674ca-a177-4add-b12f-94e3516a5105/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;腾讯微信 AI 团队提出 WeDLM（WeChat Diffusion Language Model），通过在标准因果注意力下实现扩散式解码，在数学推理等任务上实现相比 vLLM 部署的 AR 模型 3 倍以上加速，低熵场景更可达 10 倍以上，同时保持甚至提升生成质量。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;自回归（AR）生成是当前大语言模型的主流解码范式，但其逐 token 生成的特性限制了推理效率。扩散语言模型（Diffusion LLMs）通过并行恢复多个 mask token 提供了一种替代方案，然而在实践中，现有扩散模型往往难以在推理速度上超越经过高度优化的 AR 推理引擎（如 vLLM）。&lt;/p&gt;&lt;p&gt;问题的关键在于：大多数扩散语言模型采用双向注意力机制，这与标准的 KV 缓存机制不兼容，导致并行预测的优势无法转化为实际的速度提升。&lt;/p&gt;&lt;p&gt;近日，腾讯微信 AI 团队提出了 &lt;strong&gt;WeDLM&lt;/strong&gt;（WeChat Diffusion Language Model），这是&lt;strong&gt;首个在工业级推理引擎（vLLM）优化条件下，推理速度超越同等 AR 模型的扩散语言模型&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe0anhK0cBcVt1P9PTmdMiaCCNDTjrU97HrXYiciajZeSxy1PFzOgsKxODg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5176991150442478" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526249" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/24aaf4a5-5411-4106-a5b0-b5f3982a6a51/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文作者：刘瑷玮、何明桦、曾少勋、张思钧、张林昊、武楚涵、贾巍、刘源、周霄、周杰（腾讯微信 AI）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://wedlm.github.io&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub：https://github.com/tencent/WeDLM&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型权重：https://huggingface.co/collections/tencent/wedlm&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以下是模型效果：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9EricQXXByphb4tN0ha6mibe79dCBcQmEC2tPPkyY3g1kJLtJR0eUsZMowFYdARekNDeIynVWf06sA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.6265060240963856" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503526250" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c42cb496-b8e8-4bf1-8e24-809266f55ba3/640.gif" data-order="0" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;上图展示了vLLM 部署的 Qwen3-8B-Instruct（左） 与 &amp;nbsp;WeDLM-8B-Instruct（右） 在相同 prompt 下的实时生成对比。可以直观看到，WeDLM 的生成速度明显更快。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心思路：让扩散解码兼容 KV 缓存&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 的核心洞察是：&lt;strong&gt;mask 恢复并不需要双向注意力&lt;/strong&gt;。扩散式解码只需要让每个 mask 位置能够访问所有已观测的 token，这完全可以在标准因果注意力下实现。&lt;/p&gt;&lt;p&gt;研究团队提出了一个关键指标 &amp;mdash;&amp;mdash; &lt;strong&gt;前缀可缓存性（Prefix Cacheability）&lt;/strong&gt;：在 KV 缓存解码中，只有形成连续左到右前缀的 token 才能被缓存复用。因此，真正影响推理效率的不是「每步预测多少 token」，而是「有多少预测能够转化为可缓存的前缀」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeetiaeODtfAUpE9O0ZXqTeclE7DszONyNSEMp6xKZvcsj0YL3BLuDvQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.45185185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526257" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f528027b-5ecb-4b85-a491-8cf70b4fbedb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图：WeDLM-8B 在数学推理任务上实现约 3 倍加速，同时在准确率和推理速度上显著超越 LLaDA、Dream 等扩散模型。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术方案&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;拓扑重排序（Topological Reordering）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 通过拓扑重排序在保持因果注意力的同时，让 mask 位置能够访问完整的观测上下文。具体而言，将所有已观测 token 移动到物理序列的前端，同时通过 RoPE 位置编码保留其逻辑位置。这样，在标准因果 mask 下，每个待预测位置都能看到所有已知信息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeicv2fialD73zw2k3HdgTDTYKYr8vkYDMUItqsxCdNaVvIScLBWOZiazhg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.497787610619469" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526258" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e8acc538-8319-499c-a0f3-80f111161419/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;双流掩码（Dual-Stream Masking）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为缩小训练与推理的分布差异，WeDLM 设计了双流训练策略：构建一个干净的「记忆流」和一个带 mask 的「预测流」，两者共享位置编码。预测流中的每个 block 从记忆流获取干净的历史上下文，而非可能带噪的中间预测结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;流式并行解码（Streaming Parallel Decoding）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;推理阶段，WeDLM 采用流式并行解码策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;距离惩罚机制&lt;/strong&gt;：优先解码靠左的位置，促进左到右的前缀增长&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;即时缓存&lt;/strong&gt;：在因果注意力下，已解码 token 立即成为有效缓存&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;动态滑动窗口&lt;/strong&gt;：持续填充新的 mask 位置，避免 block 边界的等待开销&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeh9LBDDv1J9FucEr9AGOKFnRzCf77L8S3VMib70tTF8pkmfB1RJKh4sA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3827433628318584" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526259" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/05e437b2-7d5a-4a94-bd3d-8b768c4f9228/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图：传统 block 解码需要等待整个 block 完成才能提交，而 WeDLM 的流式解码可以即时提交已解析的前缀。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生成质量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 基于 Qwen2.5-7B 和 Qwen3-8B 进行训练，使用 100B token 进行继续预训练，10B token 进行 SFT。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeNQSWsYTQ3LsdIiaWJSQEPByUXibsXjwDqTBZA005L4TSrclS9K3icNzbA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5796460176991151" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526260" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/2acecb41-5efb-4d21-b342-a3017bdf0ce0/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 base 模型评测中，&lt;strong&gt;WeDLM-8B 平均得分 74.72，超越 Qwen3-8B（72.61）2.1 个点&lt;/strong&gt;。在数学推理任务上提升尤为显著：GSM8K 提升 4.2 个点，MATH 提升 2.8 个点。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibemqRY2ibBVEJUf1ePdSZAuibc3mZ7t66J5XunVvyztIZYiaTIT0tA66hGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5176991150442478" data-s="300,640" data-type="png" data-w="904" type="block" data-imgfileid="503526261" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/e7516cce-d36b-4ec0-ba61-c7305e6e808d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 instruct 模型评测中，&lt;strong&gt;WeDLM-8B-Instruct 平均得分 77.53，超越 Qwen3-8B-Instruct（75.12）2.4 个点&lt;/strong&gt;，也领先于 SDAR-8B-Instruct（74.22）等扩散模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理速度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;关键亮点：所有速度对比均基于 vLLM 部署的 AR 模型基线，而非未优化的实现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeaS02hxlXDSZBSL8fFHiaQ8MJ3Btjy8F5yMVxVnYcF8eoByJCgiaAxRKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.27564102564102566" data-s="300,640" data-type="png" data-w="936" type="block" data-imgfileid="503526262" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7a316bf7-058a-4c8c-a9d0-5aa1c741036d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队在论文中展示了不同熵值场景下的速度差异：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低熵场景（如计数任务）：由于输出高度可预测，模型可以大胆并行预测并接受多个 token，实测达到 1673.3 tokens/s&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中熵场景（如数学推导）：结构化的推理步骤仍然具有较好的可预测性，实测 745.2 tokens/s&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高熵场景（如开放问答）：语义多样性高，并行接受率下降，实测 197.8 tokens/s&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;快速上手&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;安装方式非常简单，只需通过 pip 从 GitHub 安装即可。安装完成后，可使用 Python API 快速调用模型进行推理。详细的使用文档和示例代码请参见项目 GitHub 主页。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WeDLM 的贡献可以归纳为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;因果扩散框架：在标准因果注意力下实现 mask 恢复，天然兼容 KV 缓存和现有推理基础设施（FlashAttention、PagedAttention、CUDA Graphs 等）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;流式并行解码：通过距离惩罚和动态滑动窗口，最大化前缀提交率&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;首次在速度上超越工业级推理引擎部署的 AR 模型：在 vLLM 优化条件下的公平对比中，数学推理实现 3 倍以上加速，低熵场景超过 10 倍&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队指出，这项工作表明「前缀可缓存性」应当作为并行文本生成的一等设计目标。未来的扩散语言模型应更多地被视为高效的多 token 预测机制 &amp;mdash;&amp;mdash; 并行生成 token 的价值，取决于这些 token 能多快地转化为可缓存的前缀。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>陶哲轩：AI让数学进入「工业化」时代，数学家也可以是「包工头」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 01:19:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/941dfc0f-d694-481c-a585-dedc852f0e3f/1767460311831.png" style="width: 700%;" class="fr-fic fr-dib"&gt;很多人提到数学研究，脑子里浮现的还是那个画面：一个人，一块白板，来回踱步，等灵感突然降临。&lt;/p&gt;&lt;p&gt;但当今世界最伟大的数学家之一、菲尔兹奖得主陶哲轩却告诉我们：这种「手工业时代」的数学研究模式正处于崩溃边缘，一场由 AI 和形式化证明语言（如 Lean）引领的「工业革命」已经悄然开启。&lt;/p&gt;&lt;p&gt;这一洞察来自陶哲轩最近的一次访谈：&lt;a href="https://mp.weixin.qq.com/s/wVTRbVtMZX3-WISdtrjbNg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0d5c4674-19d4-402a-a7fd-70fbb68fe850/1767460324061.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;视频标题：Terry Tao on the future of mathematics&lt;/p&gt;&lt;p&gt;视频链接：https://www.youtube.com/watch?v=4ykbHwZQ8iU&lt;/p&gt;&lt;p&gt;在访谈中，陶哲轩指出，数学研究中存在大量的重复性劳动，如查阅文献、调整他人论文中的参数以及繁琐的计算。通过 LLM 辅助的自动形式化（Auto-formalization），这些琐碎的工作正逐渐变得轻松。&lt;/p&gt;&lt;p&gt;与此同时，Lean 等形式化证明语言与 AI 的深度融合正在改变数学协作的本质。形式化并不只是「把证明写得更严格」，而是&lt;strong&gt;把数学拆成了可以独立验证的原子步骤&lt;/strong&gt;。这种原子化让分布式科研第一次变得可行。&lt;/p&gt;&lt;p&gt;陶哲轩预见到，数学界将出现类似软件工程的分工模式。未来的数学家可能扮演「架构师」或项目经理的角色，领导大型协作项目。这种模块化的研究方式可能允许「公民数学家」（非专业领域专家但具备某些技能的人）参与到前沿研究中，降低进入门槛。如此一来，数学研究的进展或显著加速。&lt;/p&gt;&lt;p&gt;参与访谈的另外两位数学家分别是前 OpenAI 研究科学家、Morph Labs 创始人 Jesse Han，以及斯坦福大学助理教授 Jared Duker Lichtman。&lt;/p&gt;&lt;p&gt;以下是机器之心整理的访谈记录。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从几十年到 18 个月 &amp;nbsp;数学研究正被加速&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;： 说实话，在我整个学术生涯中，我一直觉得我们做数学的方式少了点什么。我们在研究一个数学问题时，总想找到那个能打开问题大门的精妙想法。但在那之前，有大量枯燥的苦力活。比如文献综述，比如你在别人论文里看到一个技巧想用到自己的问题上，但所有的输入条件都有点不一样，你就得手动调整所有的论证。还有那些计算 &amp;mdash;&amp;mdash; 它们确实有用，能帮你建立直觉，但很多时候就是硬磨，不停地算啊算。我以前也试过写一些小程序来加速某些计算，但那时候技术还不成熟。&lt;/p&gt;&lt;p&gt;大概两年前，就在 IPAM（纯粹与应用数学研究所）这里，我们办了一个机器辅助证明的会议，我是组织者之一。在那次会议上，我们接触到了各种各样的尝试 &amp;mdash;&amp;mdash;SAT 求解器、计算机辅助软件包、大语言模型。ChatGPT 刚问世，还有 Lean。那是一个令人兴奋的世界，你突然发现很多事情变得可能了，而且正在发生。比如 Peter Scholze 刚完成了一个长达 18 个月的项目，把他的一个重要定理形式化了 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：液态张量实验。&lt;/p&gt;&lt;p&gt;陶哲轩： 对，液态张量实验。这是个大工程，一个定理花了 18 个月。但这已经被认为是巨大的突破了，因为 &lt;strong&gt;20 世纪的那些形式化项目，动辄要花几十年才能完成。所以这本身就是一个巨大的提速&lt;/strong&gt;，部分原因是我们已经学会了如何使用软件工程的那些工具，比如 GitHub，以及更智能地组织这些项目。从那以后，我对 AI 和形式化都产生了浓厚的兴趣 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;： 就是因为那次会议。&lt;/p&gt;&lt;p&gt;陶哲轩： 对，没错。我开始相信这就是数学的未来，也开始接受一些采访谈这个话题。但到了某个时候，你不能光说不练，得真正动手。所以我就去学了 Lean，花了大概一个月，但其实挺好玩的。这让我想起了写本科分析教材的经历 &amp;mdash;&amp;mdash; 真的是从基础开始，把每一步都做到完全严格。感觉就像在玩电子游戏。我记得 Kevin Buzzard 说过，Lean 是世界上最好玩的电子游戏，大概是这个意思。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;： 让人完全上瘾。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;： 对某类人来说确实非常上瘾。而在过去一年里，&lt;strong&gt;大语言模型追上来了，它们现在可以自动形式化单个证明步骤，真正开始减轻形式化过程中的苦力活，甚至到了可以实时完成的程度。这打开了无数的可能性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;形式化正在改变数学思维 &amp;nbsp;把含混经验转化为可检验的结构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;： 我第一次接触 Kevin Buzzard，是 2017 年他在 MSRI（美国数学科学研究所）教自守形式那门课的时候。几年后我跟他聊天，他说他当时根本没在关注那门课的内容，因为那个夏天他正在自学 Lean&amp;mdash;&amp;mdash; 在 Tom Hales 在第一届大型证明会议上告诉大家 Lean 将是未来之后。&lt;/p&gt;&lt;p&gt;我自己在第一次学习形式化证明的时候，有一个体会是：我慢慢意识到，其实我从来没有真正学会清晰地思考数学论证。高等数学的证明里有一种普遍的，或者说文化性的混乱感。我很好奇，当你越来越深入地去预判如何形式化证明时，你对自己数学思维的认知有什么变化？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;： 确实有一些变化，改变了我写论文的方式。我现在能看到那些「隐形假设」&amp;mdash;&amp;mdash; 那些我们习惯性地默认成立的东西。你会更认真地思考：怎样才是最干净的定义方式？因为在 Lean 里，当你定义一个概念并想使用它时，你必须先建立一堆琐碎的引理，就是所谓的 API，围绕着每个概念。这些东西在论文里往往是「显然这个概念是单调的」「显然它在某种运算下封闭」，但你其实应该证明它们。而且你会发现，如果定义得不够好，形式化这些「琐碎」命题要花两倍甚至五倍的时间。所以这让我学会了如何精简自己的写作。有时候我会对合作者有点不耐烦，因为有些人没有这个视角，还在用老式的非形式化风格写东西。&lt;/p&gt;&lt;p&gt;Heather Macbeth 写过一篇文章，讲形式化和自动化如何催生了一种新的证明写作风格。传统的证明通常是线性的，从 A 到 B，一步一步推，比如一串等式。但有了自动化工具，你可以说：这里有 10 个相关的事实，用一个标准工具来找出这 10 个事实的正确组合就能完成证明。而这个组合往往很无聊，没什么意思 &amp;mdash;&amp;mdash; 你知道某种线性代数之类的东西能从这些事实得出结论。这是一种不同的证明写作风格，某种意义上反而更容易读懂。对人类来说更难验证，但你能更清楚地看到一个证明的输入和输出，而传统写法往往把这些藏起来了。&lt;/p&gt;&lt;p&gt;Jared Duker Lichtman：Peter Scholze 的情况也是这样，他说过，在形式化过程中获得反馈，实际上让他对某个关键引理的细节思考得更清楚了，他觉得这是一个非常有价值的过程。你有一个很棒的框架 &amp;mdash;&amp;mdash; 前严谨阶段、严谨阶段、后严谨阶段。这个框架怎么融入我们现在讨论的话题？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：对，我写过一篇传播很广的文章，讲学习数学的三个阶段。第一个是前严谨阶段，你并不真正知道什么是证明，但对什么行得通、什么行不通有一些模糊的直觉。这通常是小学阶段对数学的理解方式。有时候你的直觉是对的，有时候是错的，但你没有办法分辨哪个是哪个。&lt;/p&gt;&lt;p&gt;然后是严谨阶段，你被迫完全按照规矩来，每一步都要做得准确无误。但在这个阶段，你往往会失去直觉，因为你全部的注意力都在确保每一步都正确。不过这有助于清除你所有错误的直觉，因为你能看到精确的反例，知道论证在哪里失败了。而所有好的直觉 &amp;mdash;&amp;mdash; 那些与严谨推理一致的 &amp;mdash;&amp;mdash; 都会保留下来。&lt;/p&gt;&lt;p&gt;然后是后严谨阶段，你可以在两种模式之间自由切换。你可以非形式化地论证，但现在是安全的，因为你已经清除了所有错误的直觉。你知道如果需要的话，可以把它转换回严谨的形式。反过来，你也可以读一个严谨的论证，然后把它转换成直觉性的语言。&lt;/p&gt;&lt;p&gt;Lean 确实帮我清理了一些思维中低效或错误的习惯。一个很常见的低效问题是：当你在教科书里陈述一个定理时，往往会加入太多假设。你有点过于保守，想确保证明是对的，就加了一堆额外条件 &amp;mdash;&amp;mdash; 这个非空、那个连续、这个为正之类的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：你会想去对这些假设进行压力测试。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：对。但其实还有自动化的 linter 工具，当你在 Lean 里形式化某个东西，证明结束后它会说：「顺便提一下，你从来没用过这个假设。」然后你就会想：「哦，确实，我其实根本不需要正性条件。」文献里确实有过这样的真正突破：人们心里有个思维定式，觉得某个工具只能用在比如正数的情况下，但其实证明在没有正性条件的情况下照样成立，只是没人注意到。形式化能让你自动发现每个工具的自然适用范围。这已经非常有用了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：这个说法很精辟。我们花了很多时间思考一个问题：来自软件工程和计算机科学的深度洞见，如何影响人们对数学认知和数学研究的思考方式。你刚才说的形式化如何让我们更清楚地理解每个定理的假设和输出，这其实就是良好的软件工程实践。Dijkstra 就专门讲过，人们应该更多地去推理前置条件和后置条件。同样的道理，数学家习惯在定理里堆一堆可能用不上的假设，这在软件工程里是典型的反模式 &amp;mdash;&amp;mdash; 一种公认的坏习惯。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;两个顿悟时刻 &amp;nbsp;形式化正在改变数学领域协作方式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：我特别想问你的是：你在形式化过程中的「顿悟时刻」是什么？显然一开始有很高的启动门槛，你得学习所有这些关于这门小众学术编程语言的晦涩知识。但是，在哪个时刻你意识到，把数学变成软件这个过程，不仅仅是翻译，还能加速你的理解，加速数学发现的过程？&lt;/p&gt;&lt;p&gt;对我来说，是在形式化连续统假设的独立性时。有一个时刻我完全迷失了，所有的参考资料都是错的，但我发现可以打开或关闭某些关键假设，然后很快就获得了比任何教科书都深得多的理解。我很好奇你有没有类似的经历。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：有，我有两个印象特别深刻的时刻。&lt;/p&gt;&lt;p&gt;第一个是我在形式化一个和合作者一起证明的定理，叫 PFR 猜想 &amp;mdash;&amp;mdash; 多项式 Freiman-Ruzsa 猜想。结论里有一个指数常数，我们当时证明的是：存在一个常数，使得某个性质成立，而这个常数最后算出来是 12。原因并不神秘，只是把证明中所有零零碎碎的小常数一路累积下来，最后自然就变成了 12。&lt;/p&gt;&lt;p&gt;我们花了大概三周时间，把这个「C 等于 12」的结论完整形式化成 Lean 代码。那是一个完全没有 AI 的年代，整整 20 个人，全靠手工，是一次非常浩大的工程。&lt;/p&gt;&lt;p&gt;后来，有人往 arXiv 上放了一个很短的预印本，说如果你回到原始论文，只要做五个小改动，就可以把这个 12 降到 11。于是大家就开始讨论：那我们要不要把 C 等于 11 也形式化一遍？问题在于，C 等于 12 已经花了我们三周时间，那再来一遍岂不是又是三周？&lt;/p&gt;&lt;p&gt;实际情况并不完全是这样，但直觉上你几乎只是把最终定理里的 12 改成 11。然后你会发现，大概有五行代码变红了，也就是证明不再成立了。但你去看那篇新的预印本，就会发现，哦，这五行我知道该怎么改。结果一改，这五行是好了，又有另外十行变红了。于是你再回去改那十行。就这样来回几次，我们在一天之内就把整个证明更新成了 C 等于 11。&lt;/p&gt;&lt;p&gt;所以，&lt;strong&gt;形式化确实很繁琐，尤其是第一次把一个结果完整写出来的时候。但一旦你想修改一个已有的证明，它就比传统数学方式好得多。这是我第一个非常深刻的体会&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;第二个经历来自一个名为 Equation of Theories 的项目，然后对一项研究进行形式化时，有一次很深的体会。当时有人在把另一位作者写的证明形式化，结果卡在了某一步。我当时也并不了解整个证明的全貌，甚至可以说完全不理解整体结构，但我盯着那一行代码看了一会儿，发现我其实能理解这一行在做什么。&lt;/p&gt;&lt;p&gt;我能够理解足够多的上下文，从而指出：你这里其实只需要复制并稍微修改这一行，让它在类型上匹配，这样就能调用这个工具了。&lt;/p&gt;&lt;p&gt;也就是说，&lt;strong&gt;我只通过检查一千多行代码中的三行，就给出了一个非常原子级（atomic）的诊断，精确地指出了这个证明该如何修复&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;我认为这正是 Lean，乃至形式化验证软件的一大特点：它具有一种&lt;strong&gt;高度模块化的结构&lt;/strong&gt;，这是很多其他软件甚至传统数学中并不具备的。你可以围绕某一行、某一个非常具体的局部问题展开极其精细的讨论，而完全不需要理解系统的其余部分。&lt;/p&gt;&lt;p&gt;而在传统数学中，只有在与你长期合作、彼此已经在思维方式上高度对齐的情况下，才能做到这一点。那种状态下，你们几乎可以在极其细微的层面上互相理解，甚至补全对方的句子。&lt;/p&gt;&lt;p&gt;通常情况下，当你和一个尚未在思维方式上充分同步的人讨论数学问题时，是很难进行这种粒度如此之细的交流的。&lt;/p&gt;&lt;p&gt;所以你确实可以进入那种高度专注、默契协作的状态，那种感觉非常好。但现实是，能让我进入这种状态的合作者其实只有少数。更多时候，合作中充满了翻译成本：你需要反复澄清定义、解释背景，也不可避免地会出现各种误解。&lt;/p&gt;&lt;p&gt;而在 Lean 中，这些问题在很大程度上都会消失。因为你面对的是一个对问题和修复方式都有着精确定义的类型描述。问题是什么、哪里不匹配、该如何修复，都被明确地写进了系统里。Lean 以一种此前从未有过的方式，把数学原子化了 &amp;mdash;&amp;mdash; 这是其他做数学的方法所不具备的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数学进入「工业化」时代 &amp;nbsp;数学家也可以是架构师&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jared Duker Lichtman：顺着这个话题再往前想，其实也很有意思：我们正在用一种全新的方式来使用数学。你经历过互联网的兴起，也算是较早参与并推动了类似 Polymath （博学者项目）这种协作式研究项目的人之一。也许你可以谈谈，你对协作的直觉是如何形成的？在过去大约二十年的时间里，这种协作方式是如何演化的？&lt;/p&gt;&lt;p&gt;以及展望未来，在一种高度模块化的交互模式下，有时甚至是匿名的协作中，数学研究可能会呈现出怎样的新形态？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：我想再补充一点。你在几年前发表于《Notices of the American Mathematical Society》的一篇文章里，提到过一个非常有意思的观点：你如何看待数学家角色的演变。&lt;/p&gt;&lt;p&gt;我也很想听你进一步展开这一点，因为这和我们刚才讨论的内容高度相关，比如，当你开始主导、协调这些形式化项目时，你是否也感受到自己角色的变化？以及你在组织 Polymath 项目过程中积累的经验，又是如何与这种变化发生交汇、相互影响的？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我一直都有一种很强烈的感觉：&lt;strong&gt;我想做的数学，远远超过了一个人所能完成的量。因此，我始终觉得合作极其高效、也极其重要。&lt;/strong&gt;我从合著者身上学到了很多，同样也从互联网上一些看似偶然的交流中学到了很多。&lt;/p&gt;&lt;p&gt;举个例子，我最早开始写博客，其实源于一次非常偶然的经历。有一次，我在自己的网页上随手贴了一个数学问题，并没有期待会有人回应。但当时已经有不少人会浏览我的页面，结果在短短三天之内，就有人给了我一个非常完整的参考说明，直接指出这个问题最早的来源。放在今天，这可能只需要一次简单的 ChatGPT 查询就能得到答案，但在当时，这对我来说是一种颠覆性的体验。&lt;/p&gt;&lt;p&gt;后来，英国数学家 Timothy Gowers 提出了 Polymath 项目，希望通过众包的方式来做数学研究，而我也非常享受参与其中。这种想法和我的直觉高度契合：数学中存在着大量潜在的联系，&lt;strong&gt;参与的人越多，就越有可能产生那些偶然的连接，这些连接往往是任何单一专家、无论多么资深，都很难凭一己之力发现的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;但与此同时，这种协作方式始终存在一个明显的瓶颈。&lt;/p&gt;&lt;p&gt;在 Polymath 项目中，当同时有十几、二十个人参与贡献时，总需要有人来逐条检查这些想法，确保逻辑上一致，并把零散的讨论整理成一个连贯、可读的整体。这个工作通常由我、Timothy Gowers，或者其他少数人来承担，而这件事实际上是非常耗费精力的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman：原本看似去中心化的群体协作，最终还是回到了一个核心人物 + 众多贡献者的老模式。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：对，这种模式虽然很有潜力，但并没有真正实现规模化。不过，它确实促成了一些非常宏大的研究项目：来自数学中完全不同方向的人，会因为偶然的灵感，贡献出大量有价值的线索。很多时候，项目的组织者事先根本不知道这些人彼此之间存在任何关联，但他们提供的想法却是相关且有用的。&lt;/p&gt;&lt;p&gt;问题在于，当时我们并没有完善的组织与验证基础设施。而且那时我们主要是通过博客和 Wiki 来运作项目，而不是像今天这样使用 GitHub 这类更成熟的协作平台。&lt;/p&gt;&lt;p&gt;也正是在这里，形式化工具和 AI 展现出了另一项关键能力：&lt;strong&gt;它们真正实现了不同技能背景人群之间的无缝协作&lt;/strong&gt;。在一个形式化项目中，并不是每个人都需要懂 Lean，也不是每个人都需要精通数学，更不是每个人都要熟悉 GitHub。你只需要一个技能集合彼此有重叠的群体：每个关键环节都有一部分人能够胜任，整体就能顺利推进。&lt;/p&gt;&lt;p&gt;这也使得数学研究第一次真正具备了分工协作的可能性。&lt;/p&gt;&lt;p&gt;在传统数学研究中，无论是单人还是合作，参与者几乎都需要什么都懂：既要理解全部数学内容，又要会写 LaTeX、检查推导、整理论文，每个人都要覆盖所有环节。而在真正意义上的分工体系中，就像工业化生产一样，会有人负责项目管理，有人负责质量验证，有人专注于具体技术细节。&lt;/p&gt;&lt;p&gt;软件工程其实早就完成了这种转变。早期的软件开发也是一个人包办一切，但这种方式无法扩展；一旦进入企业级开发，就必须依赖高度专业化的角色分工。&lt;/p&gt;&lt;p&gt;因此，&lt;strong&gt;我确实预见到一种趋势：在规模化、工业化的条件下生产数学成果，并且伴随着清晰的专业分工&lt;/strong&gt;。当然，传统的、手工式的数学研究依然会存在，也依然会被高度珍视；只是未来会出现一种与之互补的、全新的数学生产方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：那么，这是否意味着你预见到，大多数职业数学家的角色将会演变为这些工业化数学体系的架构师？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我认为，数学家的定义本身会被拓宽。未来会出现一类人，他们擅长运作和管理大型项目，就像大型工程中的项目负责人一样。这些大型项目的管理者会掌握足够多的数学和 Lean 知识，能够在宏观层面理解项目在做什么，但他们未必擅长定位和修复某一条具体的形式化问题。尽管如此，他们能够协调复杂项目的推进，而这本身就是一种非常重要的能力。&lt;/p&gt;&lt;p&gt;同时，也会有一些人，他们可能并不是某个数学领域的专家，但非常擅长形式化工作，或者非常善于使用新的 AI 工具。这些能力本身同样有价值。&lt;/p&gt;&lt;p&gt;在这样的体系中，人们可以更自由地加入或离开项目，协作将变得更加流动。当然，也仍然会存在更传统的研究方式：由一个规模较小的团队组成，所有人都深度参与项目的每一个环节。这种方式依然非常重要，也不会消失。关键在于，我们终于拥有了多种选择。&lt;/p&gt;&lt;p&gt;在当前体系下，许多真正热爱数学的人被挡在数学研究之外，只是因为门槛太高了。如果你想参与前沿研究，就必须掌握博士阶段水平的数学；你还得会用 LaTeX；得知道如何写作、如何避免任何细节错误&amp;hellip;&amp;hellip; 这些要求叠加在一起，对很多人来说极具威慑性，进入门槛过高。&lt;/p&gt;&lt;p&gt;即便成功进入这一体系的人，也常常因为自身技能结构不完整而被忽视或边缘化。但未来并不必然如此，随着工具、形式化和协作方式的变化，这种状况有可能被根本性地改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：在门槛被工具和协作机制降低之后，数学研究不再只属于少数职业数学家，而可以像公民科学一样，吸纳大量具有兴趣和部分技能的普通参与者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：是的，我们其实已经在看到这种趋势了。比如我自己就深度参与过一个数学问题网站。它逐渐发展成了一个社区，聚集了几十位数学背景和受教育程度各不相同的参与者，大家各自贡献一些小而具体的内容。&lt;/p&gt;&lt;p&gt;我们学会了把一个问题模块化拆解：也许你没法完整地解决这个问题，但你可以帮忙查找相关参考文献；或者把问题和某个整数序列联系起来；或者评论、改进他人的证明；又或者做一些数值实验和计算。&lt;/p&gt;&lt;p&gt;正是通过这种方式，很多人都能在自己能力范围内参与进来。&lt;/p&gt;&lt;p&gt;而现实中，确实存在着一个非常庞大的群体，他们渴望参与研究级别的数学工作，只是过去缺乏合适的入口和工具。我希望，也相信，&lt;strong&gt;这些新的工具和协作方式，能够真正释放出这股力量。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 应该先帮数学家「干脏活」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：到目前为止，我们已经谈了很多内容：一方面是你在形式化数学前沿工作的经验，另一方面是你在协调大规模协作项目、加速数学研究方面的实践。而我觉得，正好在这两者的交汇点上，是一个非常合适的时机，来谈谈你目前特别投入、也非常兴奋推动的一个项目，解析数论中数学界限（Bounds）的形式化证明。&lt;/p&gt;&lt;p&gt;或许我们可以从一个简要的介绍开始：面向非专业读者，能否先解释一下 &amp;mdash;&amp;mdash; 为什么这个问题本身如此重要？以及它在某种程度上，如何成为我们刚才讨论过的那些问题（协作、形式化、规模化研究）的一个缩影或体现？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我想先从一个更宏观的角度来讲。我一直认为，自动化本质上是对人类思维的补充工具。&lt;/p&gt;&lt;p&gt;最直观的一种思路是：把人类最想解决、也最困难的数学问题 &amp;mdash;&amp;mdash; 比如像黎曼猜想这样的重大猜想，直接交给计算机，让它们来尝试解决。计算机在这些问题上确实可能取得一定进展，但我认为，在可预见的未来，它们更有可能在另一类完全不同的任务上发挥巨大优势。&lt;/p&gt;&lt;p&gt;这些任务往往与人类真正擅长、或乐于从事的工作是正交的，尤其是那些需要进行大量枯燥的数值计算、枚举海量可能性、反复筛选组合情况的工作。这类任务人类通常并不享受，甚至极易出错，但对 AI 和计算机来说却并不构成障碍。&lt;/p&gt;&lt;p&gt;以我所从事的领域之一解析数论为例，这里就存在一个非常典型的困难：其中有大量极其繁琐、细碎的组合性计算工作，长期以来几乎只能由人类亲自完成，而这正是自动化和 AI 最有潜力介入、并发挥巨大价值的地方。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：对我个人来说，在思考一个解析数论问题时，至少有 70% 的时间，都花在这种繁琐、机械性的工作上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：是的，我认为我们其实已经掌握了很多非常精巧的思想和工具，可以把关于数字的一类陈述，或者关于和的展开、各种算术函数等内容，转化为我们真正关心的另一类陈述。解析数论中正是依靠这些工具在不同表述之间来回转换。&lt;/p&gt;&lt;p&gt;但问题在于，这些工具都有各自的输入和输出条件，而真正做研究时，你需要把它们一环一环地串联起来。相关的工具和结果分散在不同的论文中，每篇论文使用的记号体系都不一样，假设条件也往往和你手头的问题并不完全匹配。于是你不得不重新拆解原有证明，根据自己的需求重写一套版本。&lt;/p&gt;&lt;p&gt;在这个过程中，就会产生大量的重复劳动：反复调整参数、对齐条件、重建推导链条，而且非常容易出错。&lt;/p&gt;&lt;p&gt;为了让事情稍微不那么痛苦，我们发展出了一些权宜之计。其中一个最常见的做法是：不去关心具体常数。比如这里原本是 27，那里是 38，我们干脆都记成一个统一的常数 C，只说明存在某个常数，而不去计算它的具体数值。这样可以显著减少计算量，也能在一定程度上避免错误，即便你在常数上算错了，只要结论仍然成立，通常也不会造成严重后果。&lt;/p&gt;&lt;p&gt;但这种做法是有代价的。它导致解析数论中的很多结果都是非显式的。比如你可能证明了：所有足够大的奇数都可以表示为三个素数之和，但足够大究竟是多大？这个常数 C 到底是多少？我们并没有算出来，说白了，是懒得算。&lt;/p&gt;&lt;p&gt;因此，真正去显式计算所有常数的解析数论研究，只占整个领域中非常小的一部分。这类工作极其繁琐、计算量巨大，做的人很少，论文也往往不太好理解。这并不是作者水平的问题，而是因为研究内容本身就充斥着大量细碎、明确的计算过程，几乎没有那种直观的结构美感可言。&lt;/p&gt;&lt;p&gt;说实话，这种研究并不好理解。但我认为，这恰恰是自动化最理想的应用场景之一。如果我们能够搭建一条流水线，把这些显式型的论文纳入进来，其中的思想和工具本身其实已经相当成熟，真正困难的只是把大量彼此略微不兼容的工具拼接在一起，并把所有参数对齐，那么，用现有的方法就完全有可能在规模化条件下完成这些形式化工作。&lt;/p&gt;&lt;p&gt;在此基础上，我们甚至可以引入 AI 或机器学习，去探索这些工具链的最优组合方式。这将为整个领域打开许多全新的观察视角。&lt;/p&gt;&lt;p&gt;举个具体的例子：如果有人在某个算术函数上证明了一个新的界，我们希望能把这个结果直接丢进一个已经形式化好的、包含上百条定理的系统中，然后像操作 Excel 表格一样自动更新，改动一格，所有依赖它的结果都会自动刷新。&lt;/p&gt;&lt;p&gt;这样一来，我们就可以拥有一个持续演化、动态更新的领域最前沿状态，而不再是那些写死了指数和常数的论文。现在的做法是：每当某个关键结果被改进，研究者往往需要重写整篇论文，重新推导所有相关界限，才能弄清楚最新的最好结果是什么。而这类更新，通常十年才发生一次；但如果工具链足够成熟，这些工作完全可以在几分钟内完成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：所以你的意思是，这本质上是一个软件问题，对吗？就像早期编程时代，人们看待汇编语言时那样，它非常繁琐，到处都是子程序，逻辑隐藏在代码细节里，既不直观，也谈不上可读性。但一旦能够在更高层次上对这些内容进行抽象和推理，情况就会完全不同。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：可以这么理解。而且在现代软件工程中，原则上一切都是可以互操作的。你可以调用别人的子程序，不同工具之间有标准化的接口和格式，它们能够彼此通信，从而构建起极其复杂、庞大的软件生态系统。&lt;/p&gt;&lt;p&gt;当然，这样的系统也会带来一个问题：正是因为系统复杂、组件众多，软件中不可避免会出现各种错误。&lt;/p&gt;&lt;p&gt;但在数学形式化这件事上，像 Lean 这样的工具，至少在理论上，让我们有机会构建一种尽可能无 bug 的协作体系。通过形式化验证，你可以希望、甚至确信这些由大量研究者共同构建的成果是相互兼容、逻辑一致的。而这正是我们目前在数学研究中所缺失的东西：一种真正可靠、可互操作、可规模化扩展的基础设施。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当新工具出现 &amp;nbsp;数学的研究路径会整体改写吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：那么你是否愿意做一个大致的判断或推测：在数论，乃至其他数学领域中，有多大比例的工作其实是由这些相对枯燥、机械性的劳动构成的？如果这种工作负担的比例发生改变，是否可能由此催生一种截然不同的研究工作流程？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：我想在这个问题上再补充一句。事实上，在数学史上，应该已经出现过不少并非基于形式化验证、也不依赖计算机的例子：某些更好的数学技术或方法被发明出来之后，使数学家得以摆脱以往的一些繁琐劳动，从而能够把精力投入到全新的问题和思考方式中。&lt;/p&gt;&lt;p&gt;我也很好奇，在解析数论的发展过程中，是否存在过这样的重要例子？比如，是否有某些关键方法的出现，真正改变了人们理解和研究这一领域的方式？&lt;/p&gt;&lt;p&gt;如果是这样的话，那么我们是否也可以把如今的形式化工具（如 Lean）以及自动形式化技术，视为历史上这一类技术演进的又一个实例，一次新的数学技术革命？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我认为数论其实是最早采用实验性方法的数学分支之一。例如，数论中的一个核心问题，关于素数分布的规律，最早就是由高斯提出的猜想。&lt;/p&gt;&lt;p&gt;高斯当年通过一种极其艰苦的方式来获得直觉：他手工计算了前几十万、甚至上百万个素数，并从这些数据中观察到了某些模式，由此提出了后来影响深远的素数分布猜想。&lt;/p&gt;&lt;p&gt;从今天的角度看，这几乎就是一种早期的计算实验数学：通过大量具体数据的积累，来引导理论判断和猜想的形成。这在当时是非常开创性的做法，也深刻影响了数论此后的发展方向。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：而且当时所依赖的，其实只是规模很小的数据。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：是的。高斯展现出了一种非凡的能力：他能够从规模非常小的数据集中，概括出极其深刻、普遍的规律，这正是高斯天才的体现，也正因为如此，后来很多工具都会以他的名字命名。&lt;/p&gt;&lt;p&gt;而随着计算技术的发展，我们才真正能够系统性地展开这种探索。后来也陆续出现了不少类似的例子：一些重要的猜想最初正是通过数值实验和计算探索被发现的；而在更近的时代，还有一些结果是借助大规模枚举，甚至结合机器学习方法，才逐渐显现出其结构和规律的。&lt;/p&gt;&lt;p&gt;这些进展都说明了一点：新的技术手段不断扩展着数学家可探索的空间，也在持续改变人们理解和研究数论的方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：我想，甚至连图灵当年也在做类似的事情，亲自去计算函数的零点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：像某些算术函数的研究，其实早期就大量依赖数值计算。比如黎曼猜想，在很长一段时间里，正是通过大量数值实验获得了强有力的支持。&lt;/p&gt;&lt;p&gt;因此，历史上早就存在这样的先例：&lt;strong&gt;计算机的引入，催生了一种新的数学研究方式，不再只是依赖纯粹的抽象思考，而是结合数据和实验来推动理论的发展&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;当然，我们现在讨论的这种形式化工作，并不完全等同于数据驱动的数学，但它无疑是一种计算机辅助的研究模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：那么，撇开机器学习领域里那一小部分人，或者少数主动尝试新工具的研究者不谈，对于一位普通的数学家来说，无论是在数论还是其他领域，在日常研究工作中，有多大比例其实是被这种繁琐、机械性的苦工所拖慢、所构成瓶颈的？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：这个问题其实很难给出一个精确的百分比，但我觉得关键并不在于直接统计时间比例，而在于一种间接影响。&lt;/p&gt;&lt;p&gt;正是因为这些繁琐劳动的存在，我们往往会有意识地改变做数学的方式，尽量减少自己要面对的苦工。比如，当我们意识到某一步组合推导开始变得非常凌乱、计算量巨大时，往往会选择刻意绕开，改用另一条思路继续推进。&lt;/p&gt;&lt;p&gt;因此，如果你只看最终论文里呈现出来的内容，会觉得我们似乎做的都是高判断力的工作，真正的苦工并不多。但那是因为我们在研究过程中，已经下意识地避开了道路上的一个个坑，用一个比喻来说，我们是在不断绕开崎岖路段，而不是去填平它们。&lt;/p&gt;&lt;p&gt;而一旦这些工具真正到位，情况可能会发生根本变化。那时，我们会改变做事方式：如果前方出现一个巨大而繁重的计算任务，我们不再选择绕路，而是直接碾过去，动用所有可用的技术手段，借助计算、形式化工具，甚至直接交给计算机，说清楚从这里到那里该怎么走，然后继续前进。&lt;/p&gt;&lt;p&gt;这样一来，我们就可以穿越那些现在几乎是下意识回避的障碍。所以，&lt;strong&gt;从表面上看，当前数学研究中苦工的比例似乎并不高；但如果把那些被我们主动规避掉的工作也算进去，那这个比例其实远比看上去要大得多&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：之前你提到过，一个非常重要的瓶颈在于：寻找合适的合作者本身就很困难，更不用说还要在工作方式、思路层面与他们建立足够的默契。&lt;/p&gt;&lt;p&gt;我想具体问的是：在这种情况下，你觉得在研究过程中，有多大比例的时间，其实是被人与人之间沟通、对齐思路、传递和同步这些界限结果所消耗的？也就是说，为了在人类专家之间完成某种分布式计算，我们究竟付出了多大的沟通成本？&lt;/p&gt;&lt;p&gt;以及，如果你所设想的这一愿景真的实现了形式化、自动化工具能够承担起这些传递与整合工作，你认为这一领域的数学研究整体上有可能被加速多少倍？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：我觉得确实如此。首先，这是一个信任问题。在这类计算密集的研究中，只要某一步出了错，整个推导就可能全部失效。因此，你&lt;strong&gt;必须清楚哪些作者是可靠的、哪些结果是可以放心使用的，而这些信息往往是隐性的，并不会明确写在论文里&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;现实中，我们不会公开列出哪些工作存在严重问题，于是你只能依赖对学术共同体的熟悉程度：你得知道这个圈子，知道该去问谁。很多时候，如果某个结果还没有正式发表，但你认识相关领域的专家，就可以直接去问他：这个地方是不是只需要稍微改一下就行？对方可能就会给你一个可靠的判断。&lt;/p&gt;&lt;p&gt;这就形成了一个明显的瓶颈：你必须身处这个关系网络之中，认识足够多对的人，才能高效地在这个领域工作。&lt;/p&gt;&lt;p&gt;而一旦我们能够通过形式化工具（比如 Lean）提供这种可验证的信任保证，情况就会发生根本改变。那时，&lt;strong&gt;你可以放心使用来自陌生研究者的结果，即便你从未见过他们，因为所有证明都已经由系统严格验证过&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;正是在这一点上，我认为&lt;strong&gt;形式化将会极大地解锁生产力，消除大量由于信任与沟通成本造成的阻塞，从而释放出此前被压抑的大量研究潜力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：是的，我明白你的意思。你刚才提到信任这个概念，其实在数学研究中，信任往往是通过长期积累的学术记录建立起来的。一个研究者在某个领域持续工作、不断产出成果，随着时间推移，其他人自然会越来越信任他的结论。&lt;/p&gt;&lt;p&gt;而真正让我开始对形式化和数学基础问题产生强烈兴趣的一个重要故事，正是关于一位数学家的经历。他曾经建立起极高的学术声誉，证明过许多非常了不起的结果，因此在学界拥有极强的可信度。&lt;/p&gt;&lt;p&gt;但在 20 世纪 90 年代末，他写过一篇论文，后来大约在十年之后，他才意识到其中存在一个关键性的错误。回过头来看，他自己也反思到：当时很多人之所以接受那篇结论，很大程度上是因为大家在相信他这个人，而不是因为证明本身被彻底、逐行地验证过。&lt;/p&gt;&lt;p&gt;而这正揭示了一个核心问题：个人声誉和过往记录，并不等同于真理的保证。这类经历也正是形式化证明与基础工具如此重要的原因之一，它们提供的不是基于人的信任，而是基于可验证结构的信任。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：当然，这种做法在深度上是有极限的。我们能够推动数学前进的程度，终究会受到限制。当前在分析学中，这个问题相对没那么严重，是因为这里逐渐形成了一张不断加密的信任之网，而且我们的工作方式往往更接近从第一性原理出发，比其他一些领域更少依赖远距离的结果。&lt;/p&gt;&lt;p&gt;但即便如此，这种基于信任的结构依然是数学发展的一个限制因素。从长远来看，这是一个无法回避的问题，也是形式化和基础工具之所以重要的又一个原因。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jared Duker Lichtman&lt;/strong&gt;：我想再追问一个相关的问题。随着我们开始系统性地回溯并形式化一些经典论文，以及从 20 世纪 60 年代以来的大量文献，你会如何看待这样一个问题：&lt;/p&gt;&lt;p&gt;第一，在现有的数学文献中，可能还存在多少尚未被发现的错误？&lt;/p&gt;&lt;p&gt;第二，这些错误中，有多少只是可以通过小修小补解决的技术性问题？换句话说，整个数学体系作为一个整体，对这类错误究竟有多强的鲁棒性？&lt;/p&gt;&lt;p&gt;也就是说，即便我们真的通过形式化手段暴露出大量隐藏的问题，它们是否大多不会动摇理论的核心结构，而只是需要局部修正？还是说，其中也可能存在少量但影响深远的根本性漏洞？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陶哲轩&lt;/strong&gt;：说实话，我也很想知道实际的错误率到底是多少。也许结果会让我们惊喜，也可能会让我们不太愉快。等六个月之后再来问我吧。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jesse Han&lt;/strong&gt;：今天这次交流真的非常愉快，真希望能再多聊一会儿。那就希望六个月之后，我们还能再进行一次这样的对话。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Sebastian Raschka万字年终复盘：2025，属于「推理模型」的一年</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:58:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fb81ab4c-43c5-47ad-a6bc-1be0d559462c/1767372891034.png" style="width: 700%;" class="fr-fic fr-dib"&gt;随着2025年的日历翻过最后一页，AI 领域再次证明了预测未来的难度。&lt;/p&gt;&lt;p&gt;在这一年，Scaling Law 并没有失效，但它的战场已经转移：从单纯的参数堆叠转向了推理侧的强化。DeepSeek R1 的横空出世，不仅打破了专有模型的神话，更让 RLVR 和 GRPO 算法成为了年度技术风向标。与此同时，我们在架构上看到了 MoE 与高效注意力机制的收敛，也在行业中目睹了「极限刷榜」带来的评估困境。&lt;/p&gt;&lt;p&gt;著名 AI 教育家与研究员 Sebastian Raschka 在他今年的年度总结中，以其一贯的「硬核工程视角」对 2025 年进行了全面复盘。从 DeepSeek 的成本经济学到推理模型的算法细节，从工具使用的演进到 AI 辅助编程的真实体验，Raschka 不仅梳理了技术脉络，还反思了人与 AI 的协作边界。&lt;/p&gt;&lt;p&gt;以下是 Sebastian Raschka 的博客原文：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LGfm3xFmTvoajA6OCRy19ia47jib2vmJGLicqiaRRGr1IRgqaBkOwWpMeIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4064814814814815" data-type="png" data-w="1080" data-width="1371" data-height="557" data-imgfileid="503526344" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e0dbd922-153f-4099-b22b-f3d7425d3c25/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="0 0 []"&gt;https://magazine.sebastianraschka.com/p/state-of-llms-2025&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;随着 2025 年接近尾声，我想回顾一下大语言模型（LLM）在本年度的一些最重要进展，反思现存的局限性和未解难题，并分享一些关于未来的想法。&lt;/p&gt;&lt;p&gt;正如我每年常说的那样，2025 年对于 LLM 和 AI 来说又是充满变数的一年，而且今年没有迹象表明这种进步正在饱和或放缓。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、推理之年：RLVR 与 GRPO&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想探讨的有趣话题很多，让我们按时间顺序从 2025 年 1 月开始说起。&lt;/p&gt;&lt;p&gt;Scaling 仍然有效，但它并没有真正改变 LLM 在实际应用中的表现或感觉（唯一的例外是 OpenAI 刚发布的 o1，它增加了推理轨迹）。因此，当 DeepSeek 在 2025 年 1 月发布 R1 论文，展示了类似推理的行为可以通过强化学习开发出来时，这意义非凡。（在 LLM 的语境下，推理意味着模型会解释其答案，而这种解释本身通常会带来答案准确性的提升。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lp4e3meiaLExm6gBeViavozaCaMdyRtxbvhKlAnvPY8aWia1lVwoe0gDZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9787037037037037" data-type="png" data-w="1080" data-width="1496" data-height="1464" data-imgfileid="503526345" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c7a7b942-af3e-440c-8ff2-db7d116b57ff/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：一个简短的回答和一个包含中间步骤的更长的回答，后者通常是推理模型生成的。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.1 DeepSeek 时刻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 因各种原因备受关注：&lt;/p&gt;&lt;p&gt;首先，DeepSeek R1 是作为开放权重模型发布的，其表现非常出色，足以媲美当时最好的专有模型（如 ChatGPT, Gemini 等）。&lt;/p&gt;&lt;p&gt;其次，DeepSeek R1 的论文促使许多人（尤其是投资者和记者）重新审视 2024 年 12 月发布的 DeepSeek V3 论文。这导致了一个修正后的结论：虽然训练最先进的模型仍然昂贵，但其成本可能比之前假设的低一个数量级，估计更接近 500 万美元，而不是 5000 万或 5 亿美元。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LhwBls2CmcZBdRcl9SRGiarXvicNvHicuEwnxyzJHwrXZniafNqsS4s6ibLA/640?wx_fmt=jpeg#imgIndex=3" data-ratio="0.18888888888888888" data-type="png" data-w="1080" data-width="1456" data-height="351" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5I76ibsxkINcEUXNtPYWYcXkfVsWMAHu2xS3NHiaqianfPFpUDIHjBCuA/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1456" data-cropy1="42.82352941176471" data-cropy2="317.3979238754326" data-imgfileid="503526346" data-aistatus="1" data-original-style="width: 578px;height: 109px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/35c9c5f4-a0ee-4ae7-971a-925272beec72/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：来自 DeepSeek V3 论文 的表格，估计训练 6710 亿参数 DeepSeek V3 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 的补充材料估计，在 DeepSeek V3 基础上训练 R1 模型的成本仅需额外的 29.4 万美元，这再次远低于所有人的预期。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LypJzibIqWMIibn7jhS6gXUEqMC3mHKJCPlBoN9AK9zJCQBhfGaDdCCFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.21203703703703702" data-type="png" data-w="1080" data-width="1358" data-height="288" data-imgfileid="503526348" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d993acdd-ee64-4cce-ad31-a8b16fac9840/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：来自 DeepSeek R1 论文补充材料的表格，估计在 DeepSeek V3 基础上训练 R1 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;当然，关于 500 万美元的估算有许多注意事项。例如，它仅涵盖了最终模型运行的算力信用成本，并未计入研究人员的薪水以及与超参数调整和实验相关的其他开发成本。&lt;/p&gt;&lt;p&gt;第三，也是最有趣的一点，该论文提出了带有可验证奖励的强化学习 (RLVR) 配合 GRPO 算法，作为一种新的（或至少是改进的）算法方法，用于开发所谓的推理模型并在后训练阶段改进 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LRTPlWqqflKSwPibDODO19NNYk5dmDOxSicQRzVnofHvZhc3C42lQbmcw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.875" data-type="png" data-w="1080" data-width="1456" data-height="1274" data-imgfileid="503526349" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f4f8531a-ed73-4938-8c52-a7ea832864cf/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4：强化学习应用的广泛概述及其时机。在这一概述中，我跳过了许多细节，但有兴趣的读者可以在我的《LLMs 推理的强化学习现状》一文中阅读更多内容。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在此之前，像监督指令微调 (SFT) 和基于人类反馈的强化学习 (RLHF) 这样的后训练方法（它们仍然是训练流程的重要组成部分）一直受限于昂贵的书面回复或偏好标签。（当然，人们也可以用其他 LLM 合成生成这些数据，但这有点像「先有鸡还是先有蛋」的问题。）&lt;/p&gt;&lt;p&gt;DeepSeek R1 和 RLVR 的重要性在于，它们允许我们在大量数据上对 LLM 进行后训练，这使它们成为通过在后训练期间扩展算力来改进和解锁能力的绝佳候选者（假设有可用的算力预算）。&lt;/p&gt;&lt;p&gt;RLVR 中的 V 代表「可验证」，意味着我们可以使用确定性方法来分配正确性标签，而这些标签足以让 LLM 学习复杂的问题解决能力。（典型的类别是数学和代码，但也有可能将此想法扩展到其他领域。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L8qmOyFvp2nZibke3IPXUx629WVtUMFHEbTtFzJNDlcYImjx79XVWA2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5361111111111111" data-type="png" data-w="1080" data-width="1082" data-height="580" data-imgfileid="503526350" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e6db5b0d-853f-4f20-96a2-30fc906a7fa1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图5：可验证奖励的一个简单示例。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我不想在这里过于纠结技术细节，因为我想在这篇年度回顾文章中涵盖其他方面。关于推理 LLM 和 RLVR，完全可以写整篇文章或整本书。例如，如果您有兴趣了解更多，可以查看我之前的文章。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上所述，结论是：今年的 LLM 发展本质上是由使用 RLVR 和 GRPO 的推理模型主导的。 基本上，继 DeepSeek R1 之后，每一个主要的开放权重或专有 LLM 开发商都发布了其模型的推理（通常称为「思考/Thinking」）变体。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.2 LLM 关注重点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我要简洁地总结每一年 LLM 开发的关注重点（除了单纯扩展架构和预训练算力之外），我的列表会是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2022: RLHF + PPO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2023: LoRA SFT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2024: 中期训练 (Mid-Training)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2025: RLVR + GRPO&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;预训练仍然是一切的必要基础。除此之外，RLHF（通过 PPO 算法）当然是早在 2022 年带来最初 ChatGPT 模型的功臣。&lt;/p&gt;&lt;p&gt;在 2023 年，重点大量集中在 LoRA 和类 LoRA 的参数高效微调技术上，用于训练小型自定义 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lb3le591ibg3TBNr3SsxooOTJu42nl8Lc9nulFDXquv80XvRzVskk4rA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.36018518518518516" data-type="png" data-w="1080" data-width="1456" data-height="524" data-imgfileid="503526351" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9488821f-174a-4165-a48f-4b6b461d8c6e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 6：近年来专有和开源权重 LLM 开发的一些关注领域。请注意，这是累积性的，意味着例如 RLHF + PPO 仍然相关且被使用。然而，它已不再是讨论的热点话题。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;接着，在 2024 年，所有主要实验室开始通过关注合成数据、优化数据混合、使用特定领域数据以及增加专门的长上下文训练阶段，使其（预）训练流程更加复杂。我在当时的 2024 年文章中总结了这些不同的方法（当时我将这些技术归类为预训练，因为「中期训练」这个术语当时还没被创造出来）：&lt;/p&gt;&lt;p&gt;当时，我认为这些是预训练技术，因为它们使用相同的预训练算法和目标。今天，这些紧随常规通用数据预训练之后的、稍微更专业化的预训练阶段，通常被称为「中期训练」（作为常规预训练和包括 SFT、RLHF 以及现在的 RLVR 在内的后训练之间的桥梁）。&lt;/p&gt;&lt;p&gt;那么，你可能会问，接下来是什么？&lt;/p&gt;&lt;p&gt;我认为明年我们会看到对 RLVR 的（更多）关注。目前，RLVR 主要应用于数学和代码领域。 下一个合乎逻辑的步骤是，不仅使用最终答案的正确性作为奖励信号，还要在 RLVR 训练期间评判 LLM 的解释。这在过去多年里一直以「过程奖励模型」的研究标签存在。然而，它尚未取得超级成功。例如，引用 DeepSeek R1 论文：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;4.2. 不成功的尝试 [...] 总之，虽然 PRM 展示了良好的能力来对模型生成的前 N 个响应进行重新排序或辅助引导搜索 (Snell et al., 2024)，但在我们的实验中，与其在大规模强化学习过程中引入的额外计算开销相比，其优势是有限的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;然而，看看上个月发布的最新 DeepSeekMath-V2 论文（我在之前的文章《从 DeepSeek V3 到 V3.2：架构、稀疏注意力和 RL 更新》中讨论过），我认为未来我们会看到更多将「解释评分」作为训练信号的做法。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://sebastianraschka.com/blog/2025/technical-deepseek.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前对解释进行评分的方法涉及第二个 LLM。这引出了我看到的 RLVR 的另一个方向：扩展到数学和代码以外的其他领域。&lt;/p&gt;&lt;p&gt;所以，如果你今天问我如果不展望 2026 年和 2027 年会看到什么，我会说：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2026: RLVR 的扩展和更多的推理时扩展&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2027: 持续学习&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了上述的 RLVR 扩展，我认为 2026 年将会有更多关注点放在推理时扩展上。推理时扩展意味着我们在训练后，让 LLM 生成答案时花费更多的时间和金钱，但其效果非常显著。&lt;/p&gt;&lt;p&gt;推理扩展并不是一个新的范式，LLM 平台已经在底层使用了某些技术。这是延迟、成本和响应准确性之间的权衡。然而，在某些应用中，准确性比延迟和成本更重要，极端的推理扩展完全是值得的。例如，正如最近的 DeepSeekV2-Math 论文所示，它将模型在具有挑战性的数学竞赛基准测试中的表现推向了金牌水平。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lgo4kxXoySblp3wm7ZrE6jXu78K1U8iaX6JllOCQctk68Lcw1qNrD0Mw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526352" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/079ab775-78ff-4af5-9402-9ec440e6d46b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 7：两种推理时扩展方法的结合：自一致性与自精炼。额外的自精炼迭代可以提高准确性。该图来自 DeepSeekMath-V2 论文。自一致性与自精炼在《从零构建推理模型》一书的第 4 章和第 5 章中有详细说明。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;今年同事之间也有很多关于持续学习的讨论。简而言之，持续学习是指在不从头开始重新训练的情况下，在数据或知识上训练模型。 这并非新想法，我也好奇为什么今年它被提及这么多次，因为目前在持续学习方面并没有任何新的或实质性的突破。&lt;/p&gt;&lt;p&gt;持续学习的挑战在于灾难性遗忘（正如持续预训练的实验所示，学习新知识意味着 LLM 在某种程度上正在遗忘旧知识）。 不过，既然这看起来是一个如此热门的话题，我确实期望在未来几年在最小化灾难性遗忘和使持续学习方法开发成为重要进展方面取得更多进步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、GRPO：年度研究宠儿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在昂贵的 LLM 时代，学术研究近年来一直颇具挑战性。当然，尽管（或者正因为）预算较少，学术界仍然可以做出重要的发现，并成为主流和 LLM 进步及突破的关键支柱。近年来的流行例子包括 LoRA（2021 年的大型语言模型低秩适应）及其相关的参数高效微调方法。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LA631P3NNEmRQdJYWhaANufgibNMduQNOORWIHjiamrUu4GYZmVMpUBrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8175925925925925" data-type="png" data-w="1080" data-width="1456" data-height="1190" data-imgfileid="503526353" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ae1ea1db-0f96-4f41-a2b2-0df356415252/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8：基于代码的 LoRA 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;另一个是 DPO（直接偏好优化：你的语言模型秘密地是一个奖励模型）及其相关的无奖励模型对齐方法，作为基于人类反馈的强化学习的替代方案。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L49PyWufJKTYcKleM4a242icoKynL9iangpUp1xpeLcthhibChbelZlycQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8518518518518519" data-type="png" data-w="1080" data-width="1456" data-height="1240" data-imgfileid="503526354" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c287f634-ddac-4a31-8834-33b92a91e666/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9：基于代码的 DPO 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在我的圈子里，今年的研究亮点是 GRPO。虽然它是在 DeepSeek R1 论文中介绍的，而非源自学术界，但它仍然让研究人员度过了令人兴奋的一年：RLVR 和 GRPO 在概念上都很有趣，而且根据规模不同，进行实验的成本并不令人望而却步。&lt;/p&gt;&lt;p&gt;因此，今年我在 LLM 研究文献中看到了许多对 GRPO 的数学改进（来自公司和学术研究人员），这些后来被采纳进了最先进 LLM 的训练流程中。例如，其中包括以下改进：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Olmo 3：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;零梯度信号过滤 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;主动采样 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Token 级损失 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无 KL 损失 (DAPO by Yu et al., 2025 和 Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Clip higher (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;截断重要性采样 (Yao et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无标准差归一化 (Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;DeepSeek V3.2：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;带有特定领域 KL 强度的 KL 调优（数学领域为零）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重新加权的 KL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Off-policy 序列掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留 top-p / top-k 的采样掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留原始 GRPO 优势归一化&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我可以确认，这些 GRPO 的技巧或修改在实践中具有巨大的影响。例如，采用了其中一些或多项修改后，糟糕的更新不再破坏我的训练运行，我也不再需要定期重新加载检查点。&lt;/p&gt;&lt;p&gt;即便是非常短的运行，我在采用这些技巧时也观察到了巨大的收益：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LG0z49N20icw8aZmCPlrg38v6b50RXiaia5icw5tZB2aISzTVlLYpY78o3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.28888888888888886" data-type="png" data-w="1080" data-width="1456" data-height="421" data-imgfileid="503526356" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/51928105-7550-4bb2-9271-f9f161b99223/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10：我从零开始的 GRPO 训练代码部分结果，该代码可在 GitHub 上获取&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;无论如何，如果你想尝试一下，我在「从头构建推理模型」的代码库中有一个原生 GRPO 脚本。（我很快会添加更多包含相应修改的消融研究。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、LLM 架构：岔路口？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说到 LLM 架构，最先进的模型仍然使用老式的解码器风格 Transformer。然而，今年，开放权重 LLM 或多或少都收敛于使用混合专家 (MoE) 层，以及至少一种「效率调整」的注意力机制：分组查询注意力 、滑动窗口注意力或多头潜在注意力。&lt;/p&gt;&lt;p&gt;除了这些相当标准的 LLM 架构外，我们还看到了针对注意力机制的更激进的效率调整，旨在随序列长度线性扩展。这方面的例子包括 Qwen3-Next 和 Kimi Linear 中的 Gated DeltaNets，以及 NVIDIA Nemotron 3 中的 Mamba-2 层。&lt;/p&gt;&lt;p&gt;无论如何，我不想在这里深入太多细节，因为如果您想了解更多，我有一篇完整的 1.3 万字且最近更新的文章专门讨论这些架构：大型 LLM 架构比较&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LDjr3AVbCichiclibbibn5UjjYP6EAtjtPmkjo1IF8JyuLxgwS32BhhWolw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="1.3712962962962962" data-type="png" data-w="1080" data-width="1167" data-height="1600" data-imgfileid="503526357" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/a31ab06a-5774-46c5-af13-be1d9b417128/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 11：大型 LLM 架构对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我的预测是，我们将继续基于 Transformer 架构构建至少几年，至少在最先进的建模性能方面是这样。 同时，我确实认为我们会看到越来越多像 Gated DeltaNet 和 Mamba 层这样的效率和工程调整，因为在 LLM 训练、部署和使用的规模下，从财务角度来看，这对那些仍在为服务 LLM 烧钱的公司来说是有意义的。&lt;/p&gt;&lt;p&gt;这并不意味着没有其他替代方案。正如我在《超越标准 LLM》中所写，文本扩散模型是一种有趣的方法。目前，它们属于实验性研究模型类别，但 Google 分享说他们将发布 Gemini Diffusion 模型。它在建模质量上不会与其最先进的产品相抗衡，但对于低延迟要求的任务（如代码补全），它将非常快且具吸引力。&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，两周前，开放权重的 LLaDA 2.0 模型发布了。其中最大的一个拥有 1000 亿参数，是迄今为止最大的文本扩散模型，与 Qwen3 30B 相当。（是的，它并没有推动整体的最先进水平，但在扩散模型领域仍是一个值得注意的版本。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、这也是推理扩展和工具使用的一年&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过扩展训练数据和架构来改进 LLM 是一个既定公式，且（仍然）持续奏效。然而，特别是在今年，这已不再是「唯一」足够的秘诀。 我们在 GPT 4.5（2025 年 2 月）上看到了这一点，据传它比 GPT 4（以及后来发布的 GPT 5）大得多，但单纯的Scaling 通常不是最明智的前进方式。GPT 4.5 的能力可能比 GPT 4 更好，但增加的训练预算被认为是「性价比低」。&lt;/p&gt;&lt;p&gt;相反，更好的训练流程（更加关注中期和后训练）和推理扩展推动了今年的大部分进步。 例如，如前所述，在谈论达到金牌级数学表现的 DeepSeekMath-V2 时，推理扩展是我们可以利用的杠杆之一，让 LLM 按需解决极其复杂的任务（GPT Heavy Thinking or Pro 是其他例子；由于高延迟和成本，将这些用于所有事情是没有意义的，但在某些例子中，如具有挑战性的数学或编码问题，高强度的推理扩展是有意义的。）&lt;/p&gt;&lt;p&gt;另一个重大改进来自以工具使用为核心的 LLM 训练。如您所知，幻觉是 LLM 最大的问题之一。可以说，幻觉率一直在改善，我认为这很大程度上归功于上述的工具使用。例如，当被问及谁赢得了 1998 年 FIFA 世界杯时，LLM 不再尝试死记硬背，而是可以通过工具使用传统的搜索引擎，并从该主题的可信网站（例如本例中的 FIFA 官方网站）选择和抓取此信息。数学问题也是如此，使用计算器 API 等等。&lt;/p&gt;&lt;p&gt;例如，OpenAI 的 gpt-oss 模型是今年发布的早期开放权重模型之一，其开发时就特别考虑了工具使用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LElNRkjgywwZAA1LZxvDhyIvBQw9zicricPN0VYq3nDwEa9ukJe8r91Dg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.7416666666666667" data-type="png" data-w="1080" data-width="1456" data-height="1080" data-imgfileid="503526358" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/35d51828-d87b-490a-8483-b0d8b0178702/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 12：来自 gpt-oss 模型卡片论文的注释表格.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;遗憾的是，开源生态系统尚未完全赶上，许多（如果不是大多数）工具仍然默认在非工具使用模式下运行这些 LLM。一个原因是这是一个较新的、不断发展的范式，工具需要适应。另一个原因也是这是一个更难解决的问题，出于安全考虑（给予 LLM 无限制的工具使用访问权限可能会带来潜在的安全风险或对系统造成其他形式的破坏。我认为应该始终问的一个明智问题是：你会信任一个新实习生拥有这种级别的系统访问权限来做这件事吗？）&lt;/p&gt;&lt;p&gt;我确实认为，在未来几年，当在本地使用 LLM 时，启用和允许工具使用将变得越来越普遍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、年度词汇：Benchmaxxing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我必须选一个词或趋势来描述今年的 LLM 发展，那将是「极限刷榜 (Benchmaxxing)」。 在这里，Benchmaxxing 意味着过度关注推高排行榜的分数，有时甚至到了基准测试表现本身成为目标，而不是作为通用能力的代理指标的地步。&lt;/p&gt;&lt;p&gt;一个突出的例子是 Llama 4，它在许多既定基准测试中得分极高。然而，一旦用户和开发者上手使用，他们就意识到这些分数并不能反映真实世界的能力和实用性。 正如那句流行语所说，如果测试集是公开的，它就不是真正的测试集。而如今的问题是，测试集数据不仅（有意或无意地）是训练语料库的一部分，而且在 LLM 开发过程中经常被直接优化。&lt;/p&gt;&lt;p&gt;过去，即使公共测试集的基准分数虚高，至少模型排名仍然保持不变。例如，参见下方 2019 年论文《ImageNet 分类器能泛化到 ImageNet 吗？》中的注释图。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LQiaIscKgRkvX6XoNzlyy7Buqfp4Im1F3G3Jsibm0y8df3xZD2SxCWsRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6351851851851852" data-type="png" data-w="1080" data-width="1388" data-height="882" data-imgfileid="503526359" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/9fbf55b9-b295-43d6-acc8-069df620e25a/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 13：来自 2019 年论文《Do ImageNet Classifiers Generalize to ImageNet?》的标注图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 LLM 开发中，这已经到了基准数字不再是值得信赖的 LLM 性能指标的地步。 然而，我确实认为基准测试仍然是 LLM 必须跨越的必要门槛。即，如果我看到一个 LLM 在基准 Y 上的得分低于 X，我就已经知道它不是一个好的 LLM。然而，如果它在基准 Y 上的得分高于 X，这并不意味着它比另一个在同一基准上得分高于 X 的 LLM 好多少。&lt;/p&gt;&lt;p&gt;另一个需要考虑的方面是，图像分类器只有一个工作，即分类图像。然而，LLM 用于许多不同的任务：翻译文本、总结文本、编写代码、头脑风暴、解决数学问题等等。评估图像分类器（有明确的指标如分类准确率）比评估 LLM 在确定性和自由形式任务上的表现要简单得多。&lt;/p&gt;&lt;p&gt;除了在实践中尝试 LLM 并不断生成新的基准测试外，遗憾的是，这个问题没有解决方案。 顺便说一句，如果你好奇了解 LLM 评估的主要类别，你可能会喜欢我的文章《从头理解 LLM 评估的 4 种主要方法》。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、AI 用于编码、写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然这个问题经常出现，我想分享一下我对 LLM 取代人类进行某些类型任务（甚至工作）的看法。 从高层次来看，我将 LLM 视为赋予某些职业的人们「超能力」的工具。我的意思是，当 LLM 被用好时，它们可以使个人效率大幅提高，并消除日常工作中的许多摩擦。这范围从相对平凡的任务（如确保章节标题的大小写一致）到在大型代码库中查找复杂的错误。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.1 编码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，我仍然自己编写大部分我关心的代码。「我关心的」是指在那些我理解代码且代码正确性至关重要的上下文中。例如，如果我设置一个 LLM 训练脚本，我会实现并仔细检查训练逻辑。这是为了 a) 确保它在做我认为它应该做的事情，以及 b) 保留我在该任务中的知识和专业技能。然而，我现在使用 LLM 来添加周围更平凡的代码，例如添加命令行 argparse 样板代码，以便我可以更方便地从命令行使用我自己的代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LMWf8Vp5AoXZKpSbGtVlHVVHJNFOg0qFNZDJJSx8PTz0zGAaox7KTHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.6666666666666667" data-type="png" data-w="960" data-width="960" data-height="1600" data-imgfileid="503526360" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/950d2605-f1a7-4ce2-bdcc-feb90ce3cf4b/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 14：使用提示「为 training-script.py 添加 argparse 以支持所有超参数选项」向训练脚本添加命令行参数的例子。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但我也越来越多地依靠 LLM 来发现问题、建议改进或对想法进行健全性检查。同时，我想了解我正在构建什么，作为个人目标，我旨在加深我的知识和技能，并继续增长我的专业知识。&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，LLM 对于我核心专业知识之外的任务非常有价值。它们让我自动化了一些我本来没有时间或精力去处理的事情。一个例子是我最近写的一个工具，用于将我的 Substack 文章提取并备份为 Markdown。（我在 Markdown 中起草所有内容，但我经常直接在 Substack 编辑器中编辑和扩充文章，所以我的本地草稿并不总是最新的）。LLM 还帮助我清理了网站上的 CSS，这些 CSS 积累了多年的重复和不一致。今年有很多类似的案例我使用了 LLM。&amp;nbsp;&lt;/p&gt;&lt;p&gt;简而言之，我认为这里的诀窍是识别何时使用以及何时不使用 LLM。以及如何以一种有助于你增长专业知识同时也令人感到满足的方式使用 LLM。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.2 代码库和代码库&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 在编写代码方面变得更好了，但尽管我听到其他人这么说，我不认为代码是或将变得短暂或过时。LLM 赋予人们超能力来生成某些编码项目，这些项目如果由他们自己创建，将需要大量精力。 然而，纯粹由 LLM 生成的代码库并不能取代专家精心制作的代码库。这些专家代码库甚至可能是由人类编码员自己使用 LLM 创建的。但关键点在于，该领域的专家投入了大量时间和精力来创建、测试和完善它。其他人要复制它需要大量工作，所以如果它存在，为什么不采用它呢？&lt;/p&gt;&lt;p&gt;简而言之，我认为一个学习了良好设计模式和权衡取舍、并在职业生涯中研究、见过并构建了许多平台的专家全栈 Web 开发人员，将能够构建比一个随机提示 LLM 构建平台的人更好的平台。 很棒的是，一个随机的人现在可以构建一个平台，即使它不是最好的。然而，使用和提示 LLM 只能让那个人走这么远，平台的质量可能会停滞不前。因此，如果这个人真的关心改进平台，深入研究这里，学习其他人如何构建平台，并带着更多的知识回来更有效地使用 LLM 来指导和改进平台设计，将是一个好主意。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.3 技术写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与编码类似，我不认为 LLM 会使技术写作过时。写一本好的技术书籍需要数千小时和对主题的深刻熟悉。这个过程可能涉及 LLM 来提高清晰度、检查技术正确性、探索替代方案或运行小型实验，但核心工作仍然取决于人类的判断和专业知识。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lv2KFlI8vykxJPX6QTmGefhUaV8rvib3T4k5Q4vvAoWfjS320znibjf7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="1.499531396438613" data-type="png" data-w="1067" data-width="1067" data-height="1600" data-imgfileid="503526362" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/7b4a580c-7dbf-43cb-aacf-4fd2da543603/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp;图 15：一个非分阶段的例子，其中 LLM 只是帮助我找到并修复了前一篇文章中的错误。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;是的，LLM 可以让技术书籍变得更好。它们可以帮助作者发现错误、扩充参考文献，并通常减少花在平凡任务上的时间。这释放了更多时间用于真正需要创造力和经验的深度工作。&amp;nbsp;&lt;/p&gt;&lt;p&gt;从读者的角度来看，我也不认为 LLM 取代了技术写作。使用 LLM 了解一个主题对于快速提问和初学者级别的解释非常有效。然而，当你想要建立更深层次的理解时，这种方法很快就会变得混乱。&lt;/p&gt;&lt;p&gt;在那一点上，与其可能浪费数小时自己试图过滤 LLM 关于你试图学习但（尚）不是专家的主题的回复，通常遵循专家设计的结构化学习路径更有意义。（专家可能使用了也可能没有使用 LLM。）&lt;/p&gt;&lt;p&gt;当然，在参加课程或从书中学习时，使用 LLM 来澄清问题或探索旁支路径仍然非常有意义。让它设计测验或练习来实践知识也很棒。&lt;/p&gt;&lt;p&gt;总的来说，我认为 LLM 对作者和读者来说都是净收益。 但我也认为这里的诀窍是学会识别何时使用以及何时不使用 LLM。例如，主要的缺点是，当一个话题变得困难时，人们很容易立即使用 LLM，因为先自己努力解决问题通常会带来更强的学习效果。&lt;/p&gt;&lt;p&gt;我看待研究的方式也差不多。LLM 对于查找相关文献、发现数学符号中的问题和建议后续实验非常有用。但让一位人类研究员坐在驾驶座上仍然是有意义的。 也许这里的经验法则是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书完全由人类生成，它可能还有进一步改进的空间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书可以通过仅仅提示 LLM 生成，那么它可能不够新颖和/或不够深刻。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;6.4 LLM 与职业倦怠&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 仍然相当新且在不断发展，我认为过度使用 LLM 也有一个较少讨论的缺点。例如，我认为如果模型做了所有的操作，而人类主要是在监督，工作可能会开始让人感到空虚。&lt;/p&gt;&lt;p&gt;当然，有些人真的喜欢专注于管理系统和编排工作流程，这是一个完全有效的偏好。但对于那些喜欢亲手做事的人来说，我认为这种工作模式可能会加速职业倦怠。（这对于那些期望因为有了 LLM 而能更快获得更多结果的公司来说尤其如此。）&lt;/p&gt;&lt;p&gt;与难题搏斗并最终看到它成功，有一种特别的满足感。当 LLM 一次性搞定解决方案时，我没有同样的感觉。我想这类似于烹饪（这只是我想到的，我不是一个好厨师）。如果你喜欢做披萨，使用预制的面团只加配料可能会消除很多乐趣，烹饪变成了达到目的的手段。这不一定是坏事，但我认为如果你在较长一段时间内（几个月或几年）每天做很多小时这样的工作，我能看到它会让人感到空虚并最终导致倦怠。 所以，一个自私的观点是写代码也比读代码更有趣。你可能会同意，创建 Pull Request 通常比审查它们更有趣（当然，这对每个人来说并不都是真的）。&lt;/p&gt;&lt;p&gt;也许一个很好的、理想化的（但并非完美的）类比，说明我们应该如何以可持续的方式使用 AI，就是国际象棋。&amp;nbsp;&lt;/p&gt;&lt;p&gt;国际象棋引擎在几十年前就超越了人类棋手，但人类进行的职业国际象棋仍然活跃且繁荣。我不是国际象棋专家，但我觉得这项游戏可能甚至变得更加丰富和有趣了。&lt;/p&gt;&lt;p&gt;根据我听到的（例如，基于 Kasparov 的《Deep Thinking》一书和以 Magnus Carlsen 为特色的播客），现代棋手一直在使用 AI 来探索不同的想法，挑战他们的直觉，并以前所未有的深度分析错误。&lt;/p&gt;&lt;p&gt;我认为这是一个有用的模型，可以用来思考智力工作其他形式中的 AI。如果用得好，AI 可以加速学习并扩展一个人可以合理承担的工作。我认为我们应该更多地把它视为合作伙伴而不是替代品。 但我也认为，如果 AI 被用来完全外包思考和编码，它就有可能破坏动力和长期技能发展。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LJmeDUugQnicvCtHxDPr3g1edcTd9R4AXG7qUsaziariaFjqD8mNrUC7Ew/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526363" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/033a26a8-67d5-4a5b-bf2d-7d9b1ba1e8a0/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 16：LLMs 降低了入门门槛，使程序员（无论是初学者还是专家）更加高效。然而，在我们即将结束 2025 年之际，我认为仍然值得投资成为专家，因为这样你将能从 LLMs 中获得更多的价值，并能够交付更出色的结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7、优势：私有数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 的通用编码、知识问答和写作能力在不断提高。这很大程度上是因为由于训练流程和范式（例如 RLVR）以及推理扩展和工具使用的改进，Scaling 仍然提供了正向的投资回报。&lt;/p&gt;&lt;p&gt;然而，这将在某个时刻开始趋于平稳（类似于我们在 GPT 4 到 GPT 4.5 开发中看到的），除非我们继续发明新的训练方法和/或架构（目前，还没有人知道这些可能是什么样子的）。&lt;/p&gt;&lt;p&gt;LLM 目前能够解决许多通用任务和低垂的果实。但要将它们确立在某些行业中，就需要更多的领域专业化。我认为 LLM 提供商会很乐意获得高质量的、特定领域的数据。目前看来，这将是一个挑战。&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，似乎大多数接触过的公司都拒绝了此类交易，恰恰是因为数据是专有的并且是其业务差异化的核心。（我从多个来源听到了这一点，还有一篇关于此主题的 The Information 文章。）&amp;nbsp;&lt;/p&gt;&lt;p&gt;在我看来，这完全说得通。我认为将有价值的专有数据（有一天可能会给公司带来优势）卖给 OpenAI 或 Anthropic 可能有点短视。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LPxp0fnU6IHnWXZEvkMUb3JNsLOvUebib7DibTchs39GH8ylYymtpyLPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.45092592592592595" data-type="png" data-w="1080" data-width="1456" data-height="657" data-imgfileid="503526364" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/31132ae5-d478-424b-9a69-6caa2846fcd2/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 17：可用于训练领域专用 LLMs 的数据领域和类型示例，但在这些情况下将数据出售给外部方可能会引起担忧。(我不是法律专家，这也不构成法律建议，但我可以想象，如果是一个纯本地的 LLM，不会离开公司的安全服务器，那么在患者健康数据上训练模型与开发其他使用该患者健康数据的内部软件并无不同。)&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;目前，LLM 开发在大规模上极其昂贵且具有挑战性，这就是为什么只有少数大公司开发最先进的 LLM。然而，我认为 LLM 开发正变得越来越商品化，因为 LLM 开发者频繁在雇主之间轮换，最终将被更大的金融机构、生物技术公司和其他有预算开发利用其私有数据的具有竞争力的内部 LLM 的公司聘用。&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些 LLM 甚至不必完全从头开始训练；许多最先进的 LLM 如 DeepSeek V3.2、Kimi K2 和 GLM 4.7 正在发布，可以进行调整和进一步的后训练。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8、从头构建 LLM 和推理模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你可能想知道我今年都在忙些什么。我的重心几乎完全放在了 LLM 相关的工作上。去年，我决定成为一名独立人士并创办了自己的公司，主要是为了有更多时间从事我自己的研究、书籍撰写、Substack 写作以及行业合作。&lt;/p&gt;&lt;p&gt;作为一名独立研究员，咨询项目是维持这种工作模式可持续的一部分。这不仅涵盖了日常开销（从食品杂货到健康保险），还包括一些不太显眼的成本，比如用于上述实验的云端算力费用。&lt;/p&gt;&lt;p&gt;随着时间的推移，我的目标是进一步减少咨询工作，将更多时间花在长篇研究和写作上，特别是我在这里分享的技术深度文章。&lt;/p&gt;&lt;p&gt;我很幸运，许多公司都联系我提供全职职位。如果独立这条路走不通，那将是一个可行的选择，但目前，我计划保持独立。&lt;/p&gt;&lt;p&gt;如果你觉得我的工作有用，并且在能力范围内，订阅我的 Substack 或购买我的一本书，确实有助于使这类工作变得可持续，我真心感谢大家的支持。&lt;/p&gt;&lt;p&gt;今年我的个人高光时刻之一是收到了关于我的书《从头构建大语言模型》 (Build A Large Language Model (From Scratch))的积极反馈。我收到了来自世界各地公司和大学读者的许多深思熟虑的留言。&lt;/p&gt;&lt;p&gt;这些反馈涵盖了广泛的用例：从大学教授将其作为主要教科书来教授 LLM 原理，到前学生用它准备面试并获得新职位，再到工程师依靠它作为在生产环境中实施自定义 LLM 的踏板。&lt;/p&gt;&lt;p&gt;得知这本书现在已经被翻译成至少九种语言，我也感到非常兴奋。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LXnVK0ap4icfhKtB43uZFxpWSicSRr3NUjdjAibrrRnu61WdnOFWoXU8LQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.7694444444444445" data-type="png" data-w="1080" data-width="1456" data-height="1120" data-imgfileid="503526365" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/b42684b8-231a-4273-b0d9-702e56a9d75c/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 18：构建一个大型语言模型（从头开始）翻译成不同语言。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;许多读者还问是否会有第二版，涵盖更新、更高级的主题。虽然我也考虑过这一点，但我对降低这本书的易读性持谨慎态度。例如，用更复杂的变体（如一些较新的 DeepSeek 模型中使用的多头潜在注意力）来替换标准的多头注意力，会大大提高准入门槛。&lt;/p&gt;&lt;p&gt;相反，目前我倾向于保持这本书的原样，因为它非常适合那些想入门 LLM 的人。对于对更高级材料感兴趣的读者，作为后续，我在这一年中向该书的 GitHub 代码库添加了大量的补充材料。我计划随着时间的推移继续扩展这些材料。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LHWmph5p8XvASuoIFxeQ3ZGjACkW5KnHMlGX1y4yq4gu2CwC0FiaxSZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="1.3546296296296296" data-type="png" data-w="1080" data-width="1178" data-height="1596" data-imgfileid="503526366" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/c0f2302c-4fda-4dc6-876c-1b2b25f6a5b4/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 19：我今年为《从零构建大型语言模型》（From Scratch）仓库添加的一些附加内容摘录。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，正如你可能知道的，我目前正在撰写续作《从头构建推理模型》。&lt;/p&gt;&lt;p&gt;第一本书《从头构建大语言模型》侧重于核心的大语言模型架构和预训练的基础知识。&lt;/p&gt;&lt;p&gt;[图片]&lt;/p&gt;&lt;p&gt;&lt;sup&gt;图 20：展示这两本从零开始的书籍如何相互关联的示意图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这本关于推理模型的书则紧接第一本书的内容。它从一个预训练好的基础模型开始，探索专门旨在提高推理能力的推理时扩展方法和强化学习技术。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LaNVxIytDmkdu3lwIcibBj66lUeicfHV7x21PyHayGMRhibBUowe1zbbqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.8203703703703704" data-type="png" data-w="1080" data-width="1456" data-height="1194" data-imgfileid="503526369" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/e3300f54-90ce-498d-b483-94878212d1c3/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 21：《从零构建推理模型》（早期访问版）的摘录.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;除了这个 Substack 博客，我正在努力撰写这本关于推理的书。在许多方面，我认为这是我迄今为止构思最周密、打磨最精细的一本书。&lt;/p&gt;&lt;p&gt;目前，我估计每一章大约花费 75-120 小时。如果你好奇的话，我估计具体的时间分配通常如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;3-5 小时： 头脑风暴和修改选题&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 构建内容结构&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;20 小时： 编写初始代码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 运行额外实验并阅读最新文献以获取更多见解&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 制作图表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10 小时： 撰写初稿文本&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 重写和润色章节&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 制作练习题加上运行实验&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2-5 小时： 整合编辑和读者的建议&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前，我已经完成了第 6 章的一半，该章实现了用于训练推理模型的带有可验证奖励的强化学习代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LeiasrFI3kzZxIA9LPtzq8hzI7I8iaInogJ2qEX3icsPDaGFveKgQLjfBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.7101851851851851" data-type="png" data-w="1080" data-width="1456" data-height="1034" data-imgfileid="503526370" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/297e6a06-c7f1-4a4a-b835-2b5e67110876/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 22：第 6 章和第 7 章中关于可验证奖励的强化学习实验的初步结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;《从头构建推理模型》是一项非常艰巨的工作，但我完全乐在其中！我希望你和其他读者会发现它像《从头构建大语言模型》一样有用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9、2025 年的惊喜与 2026 年的预测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想用一些主要的收获来结束这篇文章，重点关注我认为对我来说有点令人惊讶的事情，以及我对 2026 年的预测。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9.1 2025 年值得注意和令人惊讶的事情&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;让我们从 2025 年的惊喜开始。如果你在 2024 年早些时候问我，这些可能是我没想到的发展：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;几个推理模型已经在主要数学竞赛中达到金牌级表现（OpenAI 的一个未命名模型、Gemini Deep Think 和开放权重的 DeepSeekMath-V2）。我对这种事情的发生并不感到惊讶，但我很惊讶这在 2025 年就已经发生了，而不是 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Llama 4（或一般的 Llama）在开放权重社区中几乎完全失宠，Qwen 在受欢迎程度上已经超过了 Llama（根据 Nathan Lambert 的 ATOM 项目报告的下载量和衍生品数量衡量）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Mistral AI 在 2025 年 12 月宣布的最新旗舰 Mistral 3 模型使用了 DeepSeek V3 架构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;除了 Qwen3 和 DeepSeek R1/V3.2 之外，许多额外的竞争者出现在最先进开放权重模型的竞赛中，包括 Kimi、GLM、MiniMax 和 Yi。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更便宜、高效的混合架构已经成为领先实验室的更大优先事项（Qwen3-Next、Kimi Linear、Nemotron 3），而不是由单独的实验室开发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;OpenAI 发布了一个开放权重模型（gpt-oss，我今年早些时候写了一篇关于它的独立文章）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MCP（加入 Linux 基金会）已经成为代理式 LLM 系统中工具和数据访问的标准（目前）；我原本预计生态系统在 2025 年会保持更加碎片化，直到至少 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;9.2 2026 年预测&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们可能会看到一个工业规模、面向消费者的扩散模型，用于廉价、可靠、低延迟的推理，Gemini Diffusion 可能会率先推出。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开放权重社区将缓慢但稳定地采用具有本地工具使用和日益增强的代理能力的 LLM。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;RLVR 将更广泛地扩展到数学和编码以外的其他领域（例如化学、生物学等）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;经典的 RAG 将慢慢淡出作为文档查询的默认解决方案。与其在每个文档相关的查询上使用检索，开发人员将更多地依赖更好的长上下文处理，特别是随着将会有更好的「小型」开放权重模型出现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大量的 LLM 基准测试和性能进步将来自于改进的工具和推理时扩展，而不是来自于训练或核心模型本身。看起来 LLM 正在变得更好，但这主要是因为周围的应用正在改进。同时，开发人员将更多地专注于降低延迟，并使推理模型在不必要时减少推理 Token 的消耗。别误会，2026 年将进一步推动最先进水平，但今年的进步比例将更多地来自推理端，而不仅仅是训练端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后总结，我认为如果说 2025 年有一个元教训，那就是 LLM 的进步不再是关于单一的突破，而是通过多个独立的杠杆在多条战线上进行改进。这包括架构调整、数据质量改进、推理训练、推理扩展、工具调用等等。 同时，评估仍然很困难，基准测试是不完美的，关于何时以及如何使用这些系统的良好判断仍然至关重要。&lt;/p&gt;&lt;p&gt;我希望 2026 年我们继续看到有趣的改进，但也希望我们了解改进来自何处。这既需要更好和更一致的基准测试，当然也需要透明度。&lt;/p&gt;&lt;p&gt;谢谢阅读！&lt;/p&gt;&lt;p&gt;Cheers, Sebastian&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5beSNXduviaPh5O08SOVvMAEOVUiaZqfrDN74M5rqYia6YE0L3ibDeiaSXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1456" data-height="970" data-imgfileid="503526372" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/cfed2d35-1bfa-4b46-add0-e3c5b0e2cefc/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;附赠：LLM 研究论文精选列表（2025 年 7 月至 12 月）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今年 6 月，我曾分享了一篇附赠文章，其中包含了我为付费订阅者（是你们让这个 Substack 博客得以维持）精心挑选并收藏的研究论文列表。&lt;/p&gt;&lt;p&gt;以同样的方式，作为对所有好心支持者的感谢，我在下面准备了一份列表，列出了我在 2025 年 7 月至 12 月期间收藏并归类的所有有趣的研究文章。我略读了这些论文的摘要，但只详细阅读了其中很小的一部分。不过，我仍然喜欢不断收集这些有条理的列表，因为在进行特定项目时，我经常会回过头来查阅其中的某一组论文。&lt;/p&gt;&lt;p&gt;然而，鉴于目前这篇文章的篇幅已经非常巨大，我将这份列表分享在一篇单独的文章中，链接如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>KAN作者刘子鸣：AI还没等到它的「牛顿」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:45:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1c023bee-dd43-4080-8124-a33dfa63ca35/1767372187912.png" style="width: 700%;" class="fr-fic fr-dib"&gt;大家新年快乐！今天和大家分享 KAN 作者刘子鸣最新发布的一篇博客。&lt;/p&gt;&lt;p&gt;过去的一年，我们见证了 Scaling Laws 持续发力，模型能力不断刷新天花板。虽然 AI 社区从未停止对可解释性的探索，但在工程进展如此迅猛的当下，我们对模型内部机制的理解，似乎总是慢了半拍。&lt;/p&gt;&lt;p&gt;刘子鸣在博客中，借用科学史提出了一个发人深省的观点：如果参照物理学的发展史，&lt;strong&gt;今天的 AI 可能还远未在这个时代的「牛顿力学」时刻，而是仍处于「第谷（Tycho）时代」&lt;/strong&gt;，一个拥有大量观测和实验，却尚未来得及系统性总结规律的早期阶段。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526556" data-ratio="1.0787037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVydCiaASeS1zapMI5GD3fd59tlyBCbNQfbbrCiaaw9888j9thmPRNibJJPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3ece9a6d-fcae-45cb-b21a-ced28a27fb4c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们拥有海量的实验数据和强大的模型，却缺乏对底层现象的系统性梳理。他指出，为了追求短期性能指标，AI 领域跳过了「理解」这一关键步骤，这实际上是在背负高昂的「认知债务」。&lt;/p&gt;&lt;p&gt;更为矛盾的是，当前的学术发表机制往往偏爱「完美的故事」或「巨大的性能提升」，导致大量像「第谷的观测记录」那样碎片化但极具价值的「AI 现象学」工作被忽视。&lt;/p&gt;&lt;p&gt;为此，刘子鸣呼吁建立一种「平易近人的现象学」：&lt;strong&gt;不以即时应用为导向，回归到用 Toy Model（玩具模型）进行可控的、多视角的假设驱动探索&lt;/strong&gt;。他宣布将身体力行，通过博客分享「半成品」的实验笔记，并计划在清华大学开设相关课程，邀请社区共同偿还这笔认知债务，推动 AI 从「炼丹」走向真正的物理学。&lt;/p&gt;&lt;p&gt;明星数据科学家 Jeremy Howard 也在评论区表示赞同，长期以来「实验性观察」几乎无法在 AI/ML 期刊和会议上发表，这种现象无疑阻碍了该领域的发展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyfwV2mmL3HK0JibYYJZPjnSVFomHx9k2gDIk8Tasyk1nwxYMDaGR8bng/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526557" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e2b0f798-3a38-431c-aa7a-15f6138ecbef/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 物理学需要思维模式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大家都知道，物理学领域主要沿着「第谷 &amp;mdash; 开普勒 &amp;mdash; 牛顿」这一科研范式发展，而如果借用这一类比来理解 AI 的发展阶段，那么&lt;strong&gt;今天的 AI 研究很大程度上仍然停留在「第谷阶段」，即以「实验与观察」为主的阶段&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;但即便是在「观察」这一层面，业界目前所做的事情也极其原始：大多数人关注的仍然只是少数几个基于性能的指标调优。这背后，源于物理学与 AI 在目标上的根本差异。&lt;/p&gt;&lt;p&gt;物理学的目标是通过「理解世界来改变世界」，其中「理解」本身占据着核心地位。因此，这个领域对那些能够提供洞见即便（暂时）没有实际用途的工作，也具有极高的容忍度。&lt;/p&gt;&lt;p&gt;相比之下，AI 的目标则是「直接改变世界」，近些年 Scaling Laws 的盛行使得整个领域得以跳过「理解」这一阶段，直接进入对 AI 本身进行改造和强化。但这似乎构成了一种&lt;strong&gt;认知债务（cognitive debt）&amp;mdash;&amp;mdash; 这种债务迟早是要偿还的，如果不是现在，那也会是在未来&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，现在就谈论 AI 的「牛顿力学」阶段还为时过早，即使是在基础现象学层面，仍处于非常早期的阶段。AI 的现象学可以是相对宏观的 &amp;mdash;&amp;mdash; 连接不同的模型，例如涌现与 Scaling laws，也可以更微观 &amp;mdash;&amp;mdash; 聚焦于训练动态，例如 Grokking、双下降（double descent）或稳定性边缘（edge of stability）&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;我们首先需要发现更多现象，只有这样，我们才会有动力去建立模型，并发展理论来研究它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么 AI 现象学如此难以发展？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么 AI 现象学的发展如此困难？一个原因是&lt;strong&gt;论文发表文化在其中扮演了重要角色&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;总结来看，当前可发表的工作往往只有两类：在性能上有显著提升的工作（在这种情况下，现象学似乎「没有必要」），或者拥有一个足够吸引人的「故事」。&lt;/p&gt;&lt;p&gt;而所谓「好故事」，通常有两种形式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;普适性（Universality）&lt;/strong&gt;：该现象必须在大量不同设定中都能被验证，稳定性边缘（edge of stability）就是一个例子。但这类工作对投稿的要求极高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;惊奇性（Surprise）&lt;/strong&gt;：现象必须足够反直觉、足够出人意料。这种情况非常罕见，也高度不可预测，grokking 就是代表性案例。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这也解释了为什么 AI 领域中被反复引用的现象学例子如此之少。在「AI 物理学」仍处于如此早期阶段的情况下，却对现象学提出了过高的期望，反而抑制了它的发展。&lt;/p&gt;&lt;p&gt;朱泽园所写的《大语言模型的物理学》是一项非常出色的工作，但从我与朋友们的交流来看，大家普遍的感受是：这很有意思，但不知道如果自己想进入这个领域，该从哪里开始。&lt;/p&gt;&lt;p&gt;同样的情况也出现在我们自己的工作《叠加导致稳健的神经缩放》《 Superposition Leads to Robust Neural Scaling》中。很多人好奇这样的「故事」是如何被构思出来的。&lt;/p&gt;&lt;p&gt;我无法代表整个 AI 物理学领域的整个研究群体，但从个人经验来看，我花费了大量时间去「包装」一个故事 &amp;mdash;&amp;mdash; 这既「浪费」自己的时间，也在无形中拉大了与读者之间的距离。&lt;/p&gt;&lt;p&gt;更重要的是，能够被包装成故事的现象极其稀少。许多我个人觉得非常有趣的现象，因为无法整理成一篇论文，最终只能被随意丢弃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;迈向更易理解的现象学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因此，我倡导一种更易于接近、更具包容性的现象学研究方式。这种方法将比当前的 AI 现象学更宽容，也更接近物理学中现象学的精神。它应当：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不以即时可用性为导向；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不被要求包装成一个完整的「故事」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不限制分析工具，只要它们在描述、预测上是有效的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;同时，它将强调：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可控性&lt;/strong&gt;：使用玩具模型来简化和抽象现实场景，使得结果能够用最少的资源复现（理想情况下，一台笔记本加一个 CPU 就足够了）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多视角刻画&lt;/strong&gt;：从尽可能多的角度和指标来描述研究对象 &amp;mdash;&amp;mdash; 就像「盲人摸象」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;好奇心或假设驱动的探索&lt;/strong&gt;：现象应当能够带来新的洞见，定性结果已经足够，定量结果当然更好。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;这种「可接近的现象学」也许不容易发表在主流 AI 会议上，但它对于社区建设具有极高价值。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;比如，研究者 A 发现了一个现象（关键在于把它公开出来），B 将其与自己此前观察到的现象联系起来，C 将二者统一，D 进行理论分析，E 再将这些洞见转化为算法改进。最终，这五个人可以一起写一篇论文。&lt;/p&gt;&lt;p&gt;但在传统模式下，A 可能只会在一个很小的圈子里合作。就我对 AI 物理学社区的理解，目前这个领域仍然高度碎片化，往往按应用领域分割。例如，做视觉的研究者通常只与其他视觉研究者合作，他们的直觉也主要由视觉任务塑造。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那我们能够做什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就我个人的经验来看，我是先从写博客开始的，开始以博客文章的形式，分享我们自己的「AI 现象学」研究。读者应当抱有这样的预期：这是同事在分享阶段性结果 &amp;mdash;&amp;mdash; 工作可能并不完整，但原始数据和思考过程会被透明地呈现出来。&lt;/p&gt;&lt;p&gt;目标有三点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是迫使自己记录观察结果&lt;/strong&gt;：正如前面所说，无法写成论文的现象往往会被丢弃。这个尝试部分受到苏剑林博客的启发 &amp;mdash;&amp;mdash; 他的博客更偏向数学原理，而我的将更强调实验观察（现象学）、「物理直觉」，以及在必要时提供一些（半）定量分析，为未来的数学研究提供问题和直觉。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;二是吸引志同道合的研究者与学生&lt;/strong&gt;：如果你对这些问题感兴趣，欢迎联系我，一起探索。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;课程准备&lt;/strong&gt;：我计划在清华大学开设一门《Physics of AI》课程。这些博客文章（及配套代码）未来可能会成为课程材料。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么对于你来说，该如何开始：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是找到你真正关心的问题&lt;/strong&gt;：例如，研究扩散模型损失函数的参数化方式，或复现已有现象（如 Grokking）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义一个简单的玩具模型&lt;/strong&gt;：例如，李天宏与何恺明的 JIT 论文使用一个二维螺旋数据集来研究损失参数化。而理解 grokking 的最好方式就是自己亲手训练一个模加任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;致力于彻底理解这个玩具模型&lt;/strong&gt;：这是最困难的一步。由于发表文化的影响，我们往往急于从玩具模型跳到更真实的模型。一旦玩具模型给出了「正向结果」，我们就会立刻离开。这是一种监督式使用玩具模型。而我认为，玩具模型在无监督使用时，才能真正展现其力量。既然是玩具，就应当以孩童般的好奇心去对待它，反复把玩，从所有可能的角度理解它（就像盲人摸象）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，我无法保证这些洞见会立刻转化为性能提升，但我相信：如果整个领域持续积累这样的理解，最终一定会发生一次类似渗流（percolation）的相变。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/ZimingLiu11/status/2006810684546494522&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://kindxiaoming.github.io/blog/2025/physics-of-ai/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
