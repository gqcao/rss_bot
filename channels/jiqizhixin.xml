<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>你的论文有novelty吗？复旦搞了个顶会论文查新系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 12:07:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/382d228d-2bc6-4d38-b9b5-715533fd2a07/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;ICLR 2026 的 Rebuttal 结束了。当 OpenReview 上的喧嚣散去，我们发现，作者与审稿人之间漫长的拉锯战，最终往往只剩下一个核心分歧：「这个想法，以前真的没人做过吗？」&lt;/p&gt;&lt;p data-path-to-node="5"&gt;Novelty（创新性）是学术评审中被高度关注的指标之一， 但其评估在实践中仍高度依赖评审者的经验判断与检索覆盖。随 arXiv 文献数量的快速增长，仅靠人工检索与记忆来追溯相关研究工作，已难以满足高效的评审需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF2lMvtTzQu4zX9HHcsXgFJBo9IibXPXQFTyT5Q90GoxqhTy33C8cys1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5578034682080925" data-s="300,640" data-type="png" data-w="692" type="block" data-imgfileid="503528556" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e0c9c206-8e9e-40f0-bd0a-d2c261709eb2/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="6"&gt;针对这一挑战，复旦大学 NLP 研究团队与其此前孵化的学术搜索平台 WisPaper 展开合作，共同研发了 OpenNovelty&amp;mdash;&amp;mdash;一个基于大语言模型、强调证据与可验证性的自动化新颖性分析系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFYZqk3YVn7xsfHFPxEmgITKeDFb5xOibC0jmrUMQgIvTszWN8O5hv2IQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528555" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4c4b5d53-8c4c-4980-a4fa-07f87d3a35cf/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="8,0,0"&gt;论文标题：OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,0,0"&gt;论文链接：https://arxiv.org/abs/2601.01576&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,1,0"&gt;Github 链接：https://github.com/january-blue/OpenNovelty&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,2,0"&gt;HuggingFace：https://huggingface.co/papers/2601.01576&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,3,0"&gt;官方网站：https://www.opennovelty.org&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="9"&gt;&lt;strong&gt;核心设计&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;OpenNovelty 的根本原则很简单：任何关于「该论文创新性不足」的判断，都必须附带可追溯的真实证据，这些证据必须来自于已发表的文献，并且能精确定位到原文具体段落。若系统未能找到相关证据，则如实说明「未发现支持该判断的证据」。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;与传统查重仅关注文字表层重叠不同，OpenNovelty 试图解决语义层面的重复。 系统会对投稿进行结构化抽取，将作者表述转写为更便于检索与对比的学术概念短句，自动提取出论文的一个核心任务（Core Task）和若干具体贡献（Contributions）。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;此外，系统还采用了「查询扩展（Query Expansion）」机制，针对提取出的每条信息，生成多个语义等价的变体，在 WisPaper 的索引库中进行地毯式检索，防止单一表述带来的检索遗漏。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;&lt;strong&gt;四步分析流程：从论文提交到生成 &amp;nbsp;可验证的新颖性评估报告&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="13"&gt;&lt;strong&gt;第一步：核心信息提取&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="14"&gt;系统从论文的标题、摘要和引言，精准地提取出两类信息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="15,0,0"&gt;&lt;strong&gt;核心任务&lt;/strong&gt;：论文拟解决的核心学术问题（例如：「基于多轮强化学习的 LLM 智能体长周期决策训练」）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="15,1,0"&gt;&lt;strong&gt;贡献声明&lt;/strong&gt;：作者明确宣称的创新点，如新方法、框架、算法或理论形式化（例如：「一个支持多种强化学习算法的统一训练框架」）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFUk4MYTAr5Bq0cEnLRGxVB0HTia5IO5tiblF3n1ASskpDggrR2pKNb9XA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0074074074074073" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528558" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1e750d25-830d-41a1-83aa-2c2f4e558859/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;第二步：相关文献检索与筛选&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;基于提取的信息，系统自动生成一组学术搜索语句（包括同义词及变体表达，避免因措辞差异而遗漏相关文献），然后利用 WisPaper 学术引擎展开地毯式搜索。&lt;/p&gt;&lt;p&gt;初步检索可能召回数百至上千篇潜在相关论文，随后通过去重、时间过滤与筛除弱相关性文献等步骤，最终形成约 60&amp;ndash;80 篇用于后续分析的候选论文集合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFhf9gngGTp3r5UBibBiapbXjmRchKEo55tEIYOlf8Qick5UUVjvbF486Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7796296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528560" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/59a1a707-8492-42ac-9e96-223b9972d2ab/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;第三步：层次化分析与证据比对&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;这是系统的核心分析环节。系统会基于核心任务召回的候选论文构建层次化 taxonomy（树状分类体系），以呈现目标论文在相关研究脉络中的位置。提供目标论文在候选研究脉络中的相对定位，供评审者快速浏览。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;针对每条贡献声明，系统会在贡献召回的候选论文集合中进行逐篇对比，并尝试给出可核验的对应证据片段。比对的结果有如下三种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,0,0"&gt;能反驳（can_refute）：找到已发表的论文具有相似贡献，必须附带双方论文的原文摘录作为证据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFolXicgIaYKq63HtYkg8SJRKMNjHRGicIk9wFtGhCwClOB9PTcHPnEfTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.8268518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528561" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/416499bb-64c6-4b58-b9e9-c34ea6dc3d2b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,1,0"&gt;无法反驳（cannot_refute）：在当前检索范围内，未发现可质疑该创新贡献的文献。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="21,2,0"&gt;存疑（unclear）：信息不足，无法判断。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="22"&gt;关键在于：如果系统做出「能反驳」的判断，但其提供的证据（即摘录段落）无法在原论文中找到或匹配度过低，该判断会自动降级为「无法反驳」。&lt;/p&gt;&lt;p data-path-to-node="23"&gt;&lt;strong&gt;第四步：「新颖性调查报告」生成&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="24"&gt;系统整合前三阶段结果，生成包含以下模块的评估报告：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="25,0,0"&gt;论文的核心任务&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,1,0"&gt;研究领域的分类体系&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,2,0"&gt;每条创新声明的比对结果和证据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,3,0"&gt;综合的「新颖性评估」叙述&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于系统给出的关键判断，报告会尽量提供可追溯的候选文献与可核验的原文证据位置，便于评审者快速定位与人工复查。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFbIpgAb3ianhG9BQvh4ceC11L6ZHKXHcR22tYWhjPmUkG9X2YJvqoLkA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528562" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/ea1c4630-21b0-45ee-9a85-43c031e8b62a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;strong&gt;系统部署与公开验证&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;截止到 1 月 16 日，团队已经在系统上分析了 1360 篇投稿，并且把所有生成的新颖性报告公开发布在其官方网站。任何人都可以查阅系统对某篇投稿的分析结果、检索到的相关文献以及判断依据。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;团队计划进一步将分析规模扩展至 2000+ 篇投稿，此外，还将持续优化系统，计划将其应用于其他 AI 顶级会议，并对所收集的报告和评审证据进行深入分析。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;&lt;strong&gt;OpenNovelty 的影响&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="30,0,0"&gt;&lt;strong&gt;对审稿人而言&lt;/strong&gt;：它是一个辅助工具而非替代。系统可以帮助评审者梳理文献脉络，快速掌握一篇论文在领域中的位置，从而将更多精力集中于更需要人类专业判断的关键环节，如研究意义、方法严谨性等问题。&lt;/p&gt;&lt;p data-path-to-node="30,1,0"&gt;&lt;strong&gt;对论文作者而言&lt;/strong&gt;：它可作为投稿前的自查工具。如果研究具备实质创新性，系统可以提供相关证据；如果漏引了重要文献，系统亦能指出问题。&lt;/p&gt;&lt;p data-path-to-node="30,2,0"&gt;&lt;strong&gt;对学术界而言&lt;/strong&gt;： 该系统提供了一种&amp;ldquo;可验证的新颖性评估&amp;rdquo;工程路径&amp;mdash;&amp;mdash;用检索到的真实文献与贡献级证据对比来约束结论输出，让判断能够被追溯与复核，而不是停留在模型的无证据生成。推动 AI 成为负责人的知识引证者，而非不可靠的内容生成器。&lt;/p&gt;&lt;p data-path-to-node="31"&gt;&lt;strong&gt;仍需人类判断&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;团队在论文里也明确指出了系统的局限性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="33,0,0"&gt;难以理解复杂的数学公式和图表&amp;mdash;&amp;mdash;如果一篇论文的核心创新藏在一个复杂的方程式里，系统可能会错过；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="33,1,0"&gt;只能搜到被索引过的论文，可能错过未被收录的小众期刊或非英语出版物；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="33,2,0"&gt;「无法反驳」仅表示在「检索范围内未找到」，并不等于「确实不存在」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="34"&gt;因此，团队一再强调：&lt;strong&gt;这是辅助工具，而非决策主体&lt;/strong&gt;。最终的学术判断，仍然要由人类审稿人完成。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="36"&gt;OpenNovelty 的出现带有某种实验性的克制。它并非试图取代现有的同行评审体系，而是作为一套第三方审计系统介入。在 Rebuttal 结束后的最终决策阶段，它负责清洗迷雾，向 AC 展示那些被淹没的证据，而将最终的价值判断权留给人类。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;目前，ICLR 2026 的部分论文查新报告已在 OpenNovelty 官网开放查阅。对于即将在明年继续冲击顶会的科研人员来说，这或许是一个审视自己工作的新鲜视角。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让机器人看视频学操作技能，清华等全新发布的CLAP框架做到了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 12:03:52 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8f91d587-4689-4bf2-bce1-879a8a63af5b/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近日，&lt;strong&gt;清华大学与星尘智能、港大、MIT&amp;nbsp;&lt;/strong&gt;联合提出基于对比学习的隐空间动作预训练（Contrastive Latent Action Pretraining, CLAP）框架。这个框架能够将视频中提纯的运动空间与机器人的动作空间进行对齐，也就是说，机器人能够直接从视频中学习技能！&lt;a href="https://mp.weixin.qq.com/s/6qkoPGMbnZXFWOYg-MljlQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e843c007-a49d-4ee4-9d14-26ed5527b6c2/1768795269900.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;论文标题：CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.04061&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址：https://lin-shan.com/CLAP/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;长期以来，机器人学习面临着一个令人头疼的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;数据饥荒」难题：互联网上有着数以亿计的人类行为视频，但专门用于训练机器人的数据却寥寥无几。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;这种数据不对称现象的根源在于，收集机器人操作数据需要昂贵的硬件设备、专业的操作环境，以及大量的人工标注工作，成本高昂且效率低下。相比之下，人类行为视频数据虽然丰富，但由于视觉表征与机器人动作空间之间存在巨大的语义鸿沟，传统方法难以有效利用这些资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;现有的潜在动作模型（Latent Action Models）试图利用视频数据，但往往会遭遇「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;视觉纠缠」（visual entanglement）问题 &amp;mdash;&amp;mdash; 模型学到的更多是与实际操控无关的视觉噪声，而非真实的操控技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLAP 框架的核心创新正是解决了这一长期困扰业界的技术瓶颈。&lt;/strong&gt;该框架能够将视频中提纯的运动空间与机器人的动作空间进行对齐，有效避免了以往潜在动作模型中普遍存在的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;视觉纠缠」问题。通过对比学习，CLAP 将视频中的状态转移映射到一个&lt;strong&gt;量化的、物理上可执行的动作码本&lt;/strong&gt;上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;研究团队基于两种 VLA 建模范式进行训练：其一是 &lt;strong&gt;CLAP-NTP&lt;/strong&gt;，一种自回归模型，在指令跟随与对象泛化方面表现突出；其二是 &lt;strong&gt;CLAP-RF&lt;/strong&gt;，一种基于 &lt;strong&gt;Rectified Flow&lt;/strong&gt; 的策略，面向高频率、精细化的操控。&lt;/p&gt;&lt;p&gt;这一技术突破的实际意义体现在多个层面。首先，从数据利用效率来看，CLAP 框架使得机器人能够从 YouTube、抖音等平台上的海量视频中学习技能，极大扩展了可用训练数据的规模。其次，从成本效益角度分析，这种「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;看视频学技能」的方式显著降低了机器人技能获取的门槛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;此外，该框架还解决了机器人学习中的一个关键技术挑战 &amp;mdash;&amp;mdash; 知识迁移问题。通过&lt;strong&gt;知识匹配（Knowledge Matching, KM）&lt;/strong&gt;正则化策略，CLAP 有效缓解了模型微调过程中的灾难性遗忘现象，确保机器人在学习新技能的同时不会丢失已掌握的能力。&lt;/p&gt;&lt;p&gt;从产业应用前景来看，CLAP 框架的长期价值不仅在于技术创新，更在于其对机器人产业化进程的推动作用。当机器人能够通过观看视频快速掌握新技能时，企业部署机器人的成本和周期将大幅降低，这有望加速机器人在服务业、制造业等领域的规模化应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;详解 CLAP 框架&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDpoiaMxzHjtfdDs495VticjX6hLp5uD2iaUHicbnU34t7as4T9zEibyTCm4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.9" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528522" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/63f662bf-113b-4619-9e67-ec7430526a14/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队构建了一个统一的视觉 - 语言 - 动作（VLA）框架，使其能够同时利用&lt;strong&gt;机器数据的动作精确性与大规模无标注人类视频演示的语义多样性&lt;/strong&gt;。框架分为两个相互衔接的阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通过 CLAP 进行跨模态对齐&lt;/strong&gt;：建立共享的潜在动作空间，弥合无标注人类视频与有标注机器人轨迹之间的监督缺口。该过程基于对比学习进行隐空间动作预训练（CLAP）：它将人类视频中的视觉状态转移「锚定」到一个&lt;strong&gt;量化的、物理上可执行的动作空间&lt;/strong&gt;中。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDyAwt85U69iaUdBIVj3RWd9t9HBTR1K9fEzeibTenpITLbtTfvHNuarJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37962962962962965" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528523" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ce891345-2e02-4d2c-8651-1a0de81aea91/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分层策略训练&lt;/strong&gt;：研究团队通过连续训练两个 VLA 模型，将语义理解与控制动力学有效解耦：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CLAP-NTP&lt;/strong&gt;：采用「下一词元预测」（Next-Token-Prediction）训练的 VLA，擅长指令跟随与任务规划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CLAP-RF&lt;/strong&gt;：包含一个 VLM 模型与一个采用 Rectified Flow 训练的动作专家，以实现高频、精确控制。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为高效适配新的本体形态并防止预训练先验在微调中发生灾难性遗忘，研究团队进一步提出&lt;strong&gt;知识匹配（Knowledge Matching, KM）&lt;/strong&gt;微调策略：一种正则化方法，在微调过程中将策略更新锚定在可信区域内。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgHX6qibG0kurUP2HKTFBCKhFWK7P5iciazbWvfa4ac3MhkdE0Cc5icVsoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528525" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/57593a5e-a8dc-4330-97f9-fb342a0a36b1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;大量实验表明，CLAP 显著优于强基线方法，使得从人类视频中学习到的技能能够有效迁移到机器人执行中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;下表 1 为初始设置下，CLAP 与基线方法在真实世界任务中的性能比较。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDc0pibb9xbg0loFCgtYZiaPiaKfIUAwdQibuny80cINkEh48sXydnI9dGHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.287962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528527" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a5904f01-6636-4312-8f07-10ebc48a38b2/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;下表2 为 CLAP 与基线方法在环境扰动下的鲁棒性评估。&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDbQoTyLSf2FMQhzb07TnYicWy10VOPEa7lhwSfJtp4uZmCkqErbTsicGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.28703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528528" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/01e49ce1-6631-417d-a0a4-93c1da927ea0/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;更多实验结果请参阅原论文。&lt;/span&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CES 2026趋势照进现实：算力引擎RK182X重塑千行百业，瑞芯微AI生态大会共建落地生态</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 10:32:10 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img alt="图片" data-aistatus="1" data-ratio="0.7574074074074074" data-src="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxQpJXzbBGljuPsptbV4I1Y3CScn5pmia6gl5n1eIqyNNIwXYLYNXRQqd8lH8iclt0oCiaiawGrQg30SPg/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=0" data-type="other" data-w="1080" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e0bcff20-b6a1-4b42-8845-21144178ec64/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-font-family="微软雅黑"&gt;一年一度的&amp;ldquo;科技春晚&amp;rdquo;CES2026于上周落下帷幕，从今年的主题&amp;ldquo;定义AI的物理边界（Physical AI）&amp;rdquo;，可以看出全球科技新趋势正在推动AI从虚拟走向现实应用，通过多元化的消费电子、机器人、智能汽车等实体形态让生活智能化变得具象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;瑞芯微作为国内AIoT芯片领域的领军企业，正在这一科技浪潮中扮演着重要角色。全球首颗3D架构协处理器RK182X系列芯片的技术突破，不仅为全球&amp;ldquo;Physical AI&amp;rdquo;的发展提供强大的硬件和算力支撑，更是推进千行百业用AI重做一遍的AIoT2.0时代的落地进程。同时，瑞芯微将举办AI软件生态大会，&lt;span data-pm-slice="0 0 []"&gt;依托在AIoT千行百业、超过5000家全球客户的广大生态，&lt;span data-pm-slice="0 0 []"&gt;搭建起AI软件与市场的桥梁。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;瑞芯微RK182X：AIoT2.0的算力引擎&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在这一轮产业变革中，端侧AI能力将成为关键。&lt;/span&gt;驱动硬件设备从&amp;ldquo;被动执行&amp;rdquo;向&amp;ldquo;主动服务&amp;rdquo;跃迁，瑞芯微RK182X提供关键的&lt;/span&gt;&lt;strong&gt;主动感知与综合决策能力&lt;/strong&gt;。其在视觉语言模型和大语言模型上的卓越性能，构成了新一代&amp;ldquo;环境智能体&amp;rdquo;的双脑核心，使设备能主动预见需求、理解复杂场景并执行综合任务，真正实现&lt;strong&gt;从&amp;ldquo;功能机&amp;rdquo;到&amp;ldquo;智能体&amp;rdquo;的本质进化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;基于实测数据显示，RK182X运行Qwen2.5-3B模型输出速度突破百Token，是市场对标产品的3倍；同时&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;在多模态视觉语言模型任务上，瑞芯微已率先支持Qwen3-VL-2B/4B模型，实测数据业内领先。RK182X运行Qwen3-VL-2B模型输出速度达136.32TPS，运行Qwen3-VL-4B模型输出速度近百Token&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxRXhSj56Jbyw4twZFicb0CgQx4dich9SxQVBiaupzWrZRhU3icx4PeG1cEYduQficOvpRTmPOIma9iaoQFQ/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=1" alt="图片" data-ratio="0.5777777777777777" data-s="300,640" data-type="other" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxRXhSj56Jbyw4twZFicb0CgQx4dich9SxQVBiaupzWrZRhU3icx4PeG1cEYduQficOvpRTmPOIma9iaoQFQ/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="578" data-cropsely2="349" data-imgfileid="503443581" data-aistatus="1" data-original-style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;vertical-align: bottom;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 676.984px !important;height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0e4303ad-5705-4a4d-9f8b-8f2ff02b631b/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;RK182X的技术突破主要体现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;从&amp;ldquo;看清&amp;rdquo;到&amp;ldquo;看懂&amp;rdquo;，处理复杂模型的&amp;ldquo;直觉&amp;rdquo;与&amp;ldquo;认知&amp;rdquo;。&lt;/strong&gt;&lt;/span&gt;新一代硬件需要充分理解用户指令并具备对&amp;ldquo;长尾场景&amp;rdquo;的认知能力。如传统的监控设备，能准确识别人、车、物等目标，&lt;strong&gt;RK182X的强大端侧AI算力，能够让新一代AI设备具备解读事件和行为的能力，实现同时分析四路视频实时预警功能，异常响应仅需 0.5 秒，每路均能输出视频理解后的场景和行为细节描述&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/9oOslerakonH91ROSsZL-A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/633ed16c-5edc-43b7-af35-3bba8bd17ee5/1768789738059.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;从&amp;ldquo;听清&amp;rdquo;到&amp;ldquo;听懂&amp;rdquo;，保障实时&amp;ldquo;交互&amp;rdquo;与隐私安全。&lt;/strong&gt;&lt;span data-font-family="微软雅黑"&gt;RK182X 直接颠覆了端侧 AI 音频的体验逻辑：在拾音端，它凭借强劲算力实现&lt;strong&gt;多人语音 AI 8 轨多音轨分离与精准声源定位&lt;/strong&gt;，彻底告别传统 &amp;ldquo;唤醒词&amp;rdquo;；不管环境多嘈杂，设备都能自主识别有效指令、抓准核心需求，再配合&lt;strong&gt;百 Token/s 级的本地处理速度，连续对话丝滑无卡顿&lt;/strong&gt;，不止 &amp;ldquo;听清&amp;rdquo; 用户的表达，更能 &amp;ldquo;听懂&amp;rdquo; 用户的需求甚至主动串联复杂任务；而这所有的处理都在设备本地完成，敏感数据无需联网，隐私安全直接拉满。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;输出端&lt;/strong&gt;&lt;span data-font-family="微软雅黑"&gt;，针对音乐播放，可通过深度学习模型将&lt;strong&gt;混合音频中的人声、吉他、贝斯、钢琴，鼓点等拆分为高保真，低串音的独立音轨&lt;/strong&gt;，可以根据需要重构声场，打造无与伦比的专属听觉体验。RK182X正是把端侧 AI 音频从 &amp;ldquo;能用&amp;rdquo; 推向 &amp;ldquo;好用、敢用&amp;rdquo; 的关键一步。&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;赋能场景：三大领域迎接硬件智能化浪潮&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;基于CES 2026展示的产品新趋势，RK182X将为三大核心领域提供技术驱动力，推动Physical AI快速落地。&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;消费电子领域&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;，展会上备受关注的智能眼镜、智能电视、智能镜柜等新一代智能硬件，&lt;strong&gt;将AI助手、实时翻译、视觉增强等功能融入其中&lt;/strong&gt;，需要强大的端侧AI能力来处理图像识别、语音理解和实时交互任务，RK182X正好满足这一需求，&lt;strong&gt;让消费电子产品从单一功能工具转向重塑交互，具备更强大的端侧多模态即时处理能力&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;机器人领域，&lt;strong&gt;RK182X为需要自主移动、环境交互的机器人提供核心算力&lt;/strong&gt;。CES上的能够武术表演的人形机器人、能爬楼梯的吸尘机器人、家务多功能机器人，正是这一趋势的缩影。&lt;strong&gt;未来的机器人不再仅仅是执行预设程序的机械装置，而是能够理解环境、适应变化并自主决策的智能伙伴。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;智能座舱领域，多家中国车企在CES 2026展示了最新的辅助驾驶技术以及功能更丰富的车载娱乐系统，端侧AI能力将成为关键支撑。&lt;strong&gt;凭借RK182X强大的本地AI处理能力，未来汽车能够在离线环境下仍做出安全决策，实现更自然的语音、手势等多模态交互。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;生态布局：瑞芯微携手软件伙伴实现场景落地价值变现&lt;/strong&gt;&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;在AIoT2.0时代，瑞芯微不仅提供硬件解决方案，更致力于构建完整的产业生态。瑞芯微将通过开放易用的工具链、深度合作的算法生态以及可快速复用的行业参考设计，构建&amp;ldquo;芯片+算法+行业方案&amp;rdquo;的全栈能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;瑞芯微首届AI软件生态大会，诚邀AI软件公司共聚福州，共同探讨端侧AI在机器人、机器视觉、智能座舱、自动驾驶、 工业应用、智能家居、AI电脑、AI手机、可穿戴设备等千行百业的落地路径与商业模式。共同搭建起AI软件与市场的桥梁，依托瑞芯微在AIoT千行百业、超过5000家全球客户的广大生态，实现AI软件算法的场景落地、价值变现。&amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/549lkW9auxRcrQiaG3hgqJcADfhGrskQibzUndjK1lTIw2Rgea7S1CpDxUQVehXgAgDooku0LPlUN9QxLQ5ze05A/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=2" alt="图片" data-ratio="2.1287037037037035" data-s="300,640" data-type="other" data-w="1080" type="block" data-imgfileid="503443562" data-aistatus="1" data-original-style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;vertical-align: bottom;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 676.992px !important;height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/677dee94-e5a9-43de-8cf4-9d3cd56846d8/640.png" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>效果、性能双突破，快手OneSug端到端生成式框架入选AAAI 2026</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 10:25:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/54f5f759-6533-411a-9d04-fc212ec9c954/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []" data-source-doc-id="eZQB1lHk_VfBdTsNfXXRa7lqw"&gt;当你在电商平台搜索“苹果”，系统会推荐“水果”还是“手机”？或者直接跳到某个品牌旗舰店？短短一个词，背后承载了完全不同的购买意图。而推荐是否精准，直接影响用户的搜索体验，也影响平台的转化效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;查询推荐（Query Suggestion）是现代电商搜索系统中的关键功能，通过在用户输入过程中实时推荐相关查询，帮助用户快速明确意图，提升搜索体验与转化效率。传统方法通常采用多阶段级联架构（MCA），虽然在效率与效果之间取得了一定平衡，但由于各阶段目标不一致、长尾查询召回困难等问题，限制了系统性能的进一步突破。&lt;/p&gt;&lt;p&gt;基于上述问题，快手在业界首次提出端到端的生成式统一查询推荐框架 ——OneSug，成功将召回、粗排、精排等多个阶段统一在一个生成模型中，显著提升了推荐效果与系统效率，在快手电商场景中实现了业务指标与用户体验的双重提升。&lt;/p&gt;&lt;p&gt;本工作相关成果《OneSug: The Unified End-to-End Generative Framework for E-commerce Query Suggestion》已被人工智能顶级会议 AAAI 2026 接收。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFKcKWFJBStrhd53JZQo2Owl2tCBE1dMxiazxUx8PIX3HyLRESSx0oBLQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=1" data-ratio="0.3398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528571" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d23652fb-a3fb-4032-b779-3410e1a49748/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2506.06913&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、研究背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统查询推荐系统通常采用多阶段级联架构，依次进行召回、粗排和精排。尽管该架构在响应时间与转化率之间实现了一定平衡，但也带来了明显的局限性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;级联式框架（召回 -&amp;gt; 粗排 -&amp;gt; 排序），前一链路性能决定下一链路上限；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;召回、排序分离技术迭代范式，全链路统一目标优化难；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;长尾前缀由于缺乏历史行为数据，难以召回高质量 Query。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;近年来，生成式检索（Generative Retrieval）因其强大的语义理解与生成能力，在推荐与搜索领域展现出巨大潜力。然而，现有方法多聚焦于视频推荐，其本质上是一个开集到开集的任务，难以直接应用于输入输出都是开放词表的的查询推荐场景。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFRoLHLL5ibKgL8v7qheyN3otXexv7Y9UFndDZkHOoLUInIGcl4ZRza6Q/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.5120370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528574" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0ee8c588-000e-4ed2-8086-6f1cdc2e6535/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFBCpcmJPPQrKLxr8RaLkBgysdk8JPU2x55Yzz7RBwUbjoMwyPVTHqSg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.24722222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528575" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ed13c183-737c-42df-9684-81ce51e09d8e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;二、方法简介：OneSug 的三大核心模块&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFicPicM7ENLm6ZOqRaklM3MbicVM5hgb5vpfuYiavvaUHDy0QpMMN0stwMw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.5138888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528591" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/31bcea93-87ec-47fd-83dd-93243be517c5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;针对上述问题，快手提出了 OneSug 模型，整体架构如上图所示，主要包括 3 个部分：&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;（1）&lt;/span&gt;Prefix-Query 表征增强模块（Prefix2Query Representation Enhancement）&lt;/p&gt;&lt;p&gt;（2）统一的 Enc-Dec 生成架构（Unified Encoder-Decoder Architecture）&lt;/p&gt;&lt;p&gt;（3）用户行为偏好对齐（User Preference Alignment）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. Prefix-Query 表征增强模块&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Sug 场景下，用户输入的前缀往往较短且意图模糊（如 “苹果” 可指水果或品牌）。为此，快手提出的解决方式分为 2 个部分。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;语义与业务空间对齐：以 BGE 作为 base 模型，同时引入用户真实的 prefix2query、query2query 数据，使用对比学习对 BGE 进行微调，使其语义空间与快手电商的业务特征空间对齐。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;层次化语义 ID 生成：在对齐语义空间的基础上，引入 RQ-VAE，为每个前缀和 Query 生成层次化的语义 ID。RQ-VAE 可将任意文本映射为离散的语义 ID，同时保证语义相近的 query 会被编码到相同的簇中。通过这种方式，对于任何一个用户输入的前缀，可以快速匹配到与其语义 ID 最接近的 top-K 个相关 query，作为增强上下文输入后续生成模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 统一的 Enc-Dec 生成架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OneSug 的生成架构基于 Enc-Dec 结构，并直接通过自回归（Autoregressive）方式生成用户最有可能点击的 Query。&lt;/p&gt;&lt;p&gt;该模型的输入包含四个关键部分：&lt;/p&gt;&lt;p&gt;（1）用户当前输入前缀（如 “智能手机”）&lt;/p&gt;&lt;p&gt;（2）由 PRE 模块增强的相关查询序列（如 “智能手机性价比 2025”）&lt;/p&gt;&lt;p&gt;（3）用户历史行为序列（如过去搜索的 “蓝牙耳机”、“手机壳” 等）&lt;/p&gt;&lt;p&gt;（4）用户画像信息&lt;/p&gt;&lt;p&gt;输出即为模型生成的 Query 列表（如 “智能手机推荐 2025”、“智能手机性价比排行”）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 用户行为偏好对齐（RWR）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;3.1 用户偏好量化&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;首先对用户在搜索场景下的真实行为进行了精细化分级，将其划分为六个明确的层次，并为每个层级赋予一个基础奖励权重 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFiczZ1fE0LorYVJkunvZT8LkmmSDssHBXBT2FlTXAmHfb55xkuz5MMyg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=5" data-ratio="1.2222222222222223" data-s="300,640" data-type="png" data-w="27" type="block" data-imgfileid="503528592" data-aistatus="1" data-original-style="width: 20px;height: 24px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/9126e0ce-06ee-4f98-8dd5-08da0c8c83e4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 3.27%;"&gt;:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFtf1Z22avuibg6SKln6BNkUqmTI2bK43DyHU44IhKRrQpMyGq8icQfoEA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.4211597151576806" data-s="300,640" data-type="png" data-w="983" type="block" data-imgfileid="503528595" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/20e1e396-2fd7-4435-ab1f-ccf578412b89/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Rand 随机负样本 0.0 为了进一步细致的调节样本权重，额外引入了调节因子 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFwXQ4bGchlzOVBpb4BfLpRuGRxW4jmps7up1zIYVm8RRTv1AyFwvCKg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=7" data-ratio="0.1813953488372093" data-s="300,640" data-type="png" data-w="215" type="block" data-imgfileid="503528597" data-aistatus="1" data-original-style="width: 149px;height: 27px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/1f07d416-3aff-4fd1-aac7-f5ec8f96a126/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 20.03%;"&gt;，其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF3zfiafKTCf3tgbA5iaOGKlfWtJ2f7eOMg6kmVhc2zkbO0nKib9BpVPRJw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=8" data-ratio="0.7333333333333333" data-s="300,640" data-type="png" data-w="45" type="block" data-imgfileid="503528599" data-aistatus="1" data-original-style="width: 37px;height: 27px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/29fc4e87-08d6-4d30-8a4f-7bdee4253ece/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 4.74%;"&gt;表示当前前缀下 query 的 ctr。&lt;/p&gt;&lt;p&gt;3.2 混合排序框架奖励加权偏好优化&lt;/p&gt;&lt;p&gt;传统的 DPO 使用 &amp;lt; 正样本，负样本 &amp;gt; 对进行训练，但默认两者同等重要。这在业务场景中是不合理的，因为区分 “点击” 和 “曝光” 的难度远小于区分 “点击” 和 “随机负样本”。&lt;/p&gt;&lt;p&gt;RWR 的核心思想是根据正负样本之间的奖励差距，为不同的样本对赋予不同的学习权重。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;构建了九种类型的样本对（如 &amp;lt;Order, Show&amp;gt;, &amp;lt;Click, Rand&amp;gt;）。对于每一对样本，计算其奖励差异权重 rwΔ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF7rdOMBBQhX2kkiboNicShxhjqnFj7BfEoeOehCEmhtrpGias5dicEWMlNg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=9" data-ratio="0.2125" data-s="300,640" data-type="png" data-w="480" type="block" data-imgfileid="503528601" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/954456c9-9da7-430f-be33-a0de8e407f72/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFOPWlnsiaLzXgtFPxWxZicmsoBANQH538iaE5jwI9icUiapWsHrO3wruy5tQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=10" data-ratio="0.5238095238095238" data-s="300,640" data-type="png" data-w="63" type="block" data-imgfileid="503528604" data-aistatus="1" data-original-style="width: 49px;height: 26px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/e63e6899-11b7-4ca8-b917-330e5595cbf9/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 6.79%;"&gt;值小：说明正负样本奖励差距大（如 &amp;lt; Click, Rand&amp;gt;），是 “容易样本”，模型正常学习即可。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFlWDL8wEg86t6hkcmQQEu0VqoZKuLYGGgS7ZzSJPPG1tDWicUjtvprsA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=11" data-ratio="0.5789473684210527" data-s="300,640" data-type="png" data-w="57" type="block" data-imgfileid="503528605" data-aistatus="1" data-original-style="width: 45px;height: 26px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5833298e-b9d5-44e2-b0a7-237e6d2858f5/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 6.68%;"&gt;值大：说明正负样本奖励差距小（如 &amp;lt; Click, Show&amp;gt;），是 “困难样本”，RWR 会赋予更大的权重，迫使模型更加努力地学习其间微妙的偏好差异。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;3.3 混合排序框架&lt;/p&gt;&lt;p&gt;为了克服传统 Pairwise 范式的 DPO 在全局排序能力上的局限性，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;引入了一种混合排序框架。该框架将 listwise 范式的排序损失和 point-wise 范式的 sft loss 进行混合，使得模型既能获得高效的排序能力，同时避免 reward hacking 造成的生成能力下降。&lt;/p&gt;&lt;p&gt;Pairwise 范式对齐模型，在包含多个负样本的候选中无法学习到 “哪个是最好的”。受 Plackett-Luce 模型启发，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;设计了 Listwise 排序损失，对于正样本，让模型同时拉大它与所有负样本的奖励差距，迫使模型不仅要知道正样本比负样本好，还要学会在负样本越多、越强的情况下，依然将正样本排在前面，从而直接优化列表的整体排序质量。&lt;/p&gt;&lt;p&gt;论文中分别提出了基于 Pairwise 和 ListWise 范式的混合排序框架，同时在理论上证明了 Pairwise 范式的对齐模型是 ListWise 的特殊情况。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFY0xtQGLibaj7o4ALf6GTR3Gy6ysRwAYbkf5bPJCbnztmp1Pq6eHDCIQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=12" data-ratio="0.1037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528608" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/daabf0cc-9a01-495d-8e2d-af0fe2f128c6/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;三、实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;离线效果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在快手电商场景的大规模数据集上，OneSug 在 HR@16 和 MRR@16 指标上均显著优于传统多阶段系统与生成式基线模型。论文中同时提到，OneSug 不仅适用于 Enc-Dec 结构的生成式模型，Decode-only 架构的模型同样适用，且具有更高的离线指标，因为现阶段的推理耗时约束暂时没有进行在线实验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFV8yGnYdRsuHdDquPEiamTSQVB1L77O5n3yiazAMiapF1xsGfWTiaiaYvXlA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=13" data-ratio="0.7287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528610" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/8615898e-d89d-4ffa-b834-eb1e826a5eda/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;在线 A/B&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OneSug 模型目前已在快手电商搜索场景下全量推全。在 AB 实验中，OneSug 大幅度提高了 Ctr、订单和 GMV 等指标，同时人工测评 GSB 指标也有很大幅度的提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFucwZxSdrKpXao5icgXAF18MLMVoq5ZMke7hlCRBZGHowmGIuXSAMRiaQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=14" data-ratio="0.24351851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528611" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/3807bce8-9fd2-4db4-b0ee-98d570684025/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFCBVxBLPianMiamtREaaX4jwMibdbYqQvSJzZX4kWYA7Xl0MDlLe7kQYMw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=15" data-ratio="0.25833333333333336" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528613" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/fda3195c-f995-404e-a063-b2fe3a6d2195/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;在线推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;线上流程完全取代了召回 - 粗排 - 精排，使平均耗时降低了 43.2%，为后续优化提供了充足的空间。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFUdlJYpcibMnwNaz9XibdykPbQmhRfYqJc7FenMsvYO7rI6UJfFQ7lD2A/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=16" data-ratio="0.29907407407407405" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528615" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/2c0b5b8b-7726-40d4-bdb3-63335dccfeb1/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OneSug 是业界首个在电商场景中实现全流量部署的端到端生成式 Query 推荐系统，其统一建模方式显著提升了语义理解与个性化推荐的能力，为生成式模型在搜广推的落地提供了新范式。&lt;/p&gt;&lt;p&gt;未来，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;将进一步探索大语言模型在排序阶段的强化学习优化、实时更新等方向，持续推动端到端生成式系统在推荐、广告等多业务场景中的广泛应用。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>咖啡机变聪明后，我连咖啡都喝不上了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:50:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Sia&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;section&gt;目前还没有人真正解决这个问题：如何让 LLM 知道什么时候该精确、什么时候可以随机。&lt;/section&gt;&lt;/blockquote&gt;&lt;p data-pm-slice="0 0 []"&gt;这真是一个让人当场破防的早晨。&lt;/p&gt;&lt;p&gt;一位 The Verge 的科技记者起床、走进厨房、对着支持 Alexa 的博世咖啡机说了句，煮杯咖啡。&lt;/p&gt;&lt;p&gt;没有即兴发挥，也没提什么复杂要求，她只是希望机器老老实实执行一个早就设好的程序，结果，被拒绝了。&lt;/p&gt;&lt;p&gt;而且不是一次。&lt;/p&gt;&lt;p&gt;自从升级到 Alexa Plus（亚马逊的生成式 AI 语音助手）之后，这种对话几乎成了她的晨间固定项目。&lt;/p&gt;&lt;p&gt;每一次要它煮咖啡，Alexa 都能给出不同理由，以惊人的创造力告诉你，不行。&lt;/p&gt;&lt;p&gt;&lt;img alt="58 个梗图点子| 幽默, 搞笑, 迷因" data-aistatus="1" data-backh="229" data-backw="236" data-imgfileid="503525832" data-ratio="0.9703389830508474" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrOg05AAm5TMAVSnoU8227QfUMeibIdxVNv1mUnAXPxicbicUXMaoZn3ppg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="236" data-original-style="width: 259px;height: 251px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b60d4185-d146-49fb-a0ec-8077d05daa21/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/p&gt;&lt;p&gt;2025 年都快过去了，AI 会写论文、会写代码、会陪人聊天、会教书，却在清晨败给了一句&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;煮杯咖啡&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;在社区讨论中，类似吐槽场面非常壮观，可谓怨声载道。&lt;/p&gt;&lt;p&gt;开灯这个事儿，完全成了重灾区。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="225" data-backw="578" data-imgfileid="503525833" data-ratio="0.3895131086142322" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrtQmxicjhoOZ5ScCqJKGRSwtUVUqxmF6Rn6UCUbLzUR009Mic9sGPwofA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="801" type="block" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9eadcde3-3cbd-4f1d-83ac-8a90576d0ef8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrbsbDFaicYzYamX105u1icGYwSQljM33TNgznZZqM10gT8U1xX5icNDsXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5131086142322098" data-type="png" data-w="801" data-width="801" data-height="411" data-backw="562" data-backh="288" data-imgfileid="503525817" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/efdf8f11-258e-469d-a8dc-6e7a59140f88/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="286" data-backw="562" data-height="453" data-imgfileid="503525820" data-ratio="0.5084175084175084" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrgX6ibqlosK907iaCIgdBbk8ABlc7ib2P2ViakUuu405QfMbrux18fwgCpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="891" data-width="891" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/024e96c0-27c4-491a-b905-98d89f59aefb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr3UG3Argc2sKHNM2DGkhBqe5YLOzgEVkEHr73eWkBBBNPGicfA1tBkkA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.12222222222222222" data-type="png" data-w="1080" data-width="1128" data-height="138" data-backw="562" data-backh="69" data-imgfileid="503525818" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a311f228-643c-4362-8aec-6261d9e92be4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="278" data-backw="562" data-height="510" data-imgfileid="503525823" data-ratio="0.4941860465116279" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrMC3Wq7XKkb7ktz3icnpk6Qyk2d6nkiatTrEBNCgWYyzvCnvGhJCC6qEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1032" data-width="1032" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1cb4b4af-351e-4aec-b55e-07a23756a93b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="70" data-backw="562" data-height="141" data-imgfileid="503525821" data-ratio="0.12407407407407407" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrVPAvQrib9j6gQsxKRjXWwiaw5Adk325d2aTsgXxDRe7INSyD38gqp0tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" data-width="1134" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ec10f489-fafd-4cb0-bd43-53ebb547ddf5/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;播放歌曲也是艰难。&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="127" data-backw="562" data-height="243" data-imgfileid="503525819" data-ratio="0.22562674094707522" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrsGh85LiaQNcl9iaoIeyx2g1TflMFd7LVfoibibclETaY1QCnBN6qB2WkVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1077" data-width="1077" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7ab0151d-d713-475e-8a22-4bb3ea6bce01/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;定个时也这么难了啊。&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="72" data-backw="562" data-height="144" data-imgfileid="503525816" data-ratio="0.1287037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrSuBKq1rbLq1FL3QfwrI6NMpGRa0nbGbfU2tFY1XRTAnc13J2zltdRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="1080" data-width="1116" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/8754d53c-d337-4645-a30e-15b06dca65aa/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;彻底心灰意冷的也有。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-backh="61" data-backw="578" data-imgfileid="503525866" data-ratio="0.10555555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrf7AauzZZCVsjUlRfiayWR8GIWldK6xSnv1mfh5mlU98h4KHmn94u9PA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9e739da4-2121-48bf-950f-cde94939cabe/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;显然，现实与大家对 AI 的直觉预期，构成了鲜明反差。&lt;/p&gt;&lt;p&gt;传统助手虽然笨吧，但高度确定，只要你把（有点傻的）&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;咒语&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;念对，结果总是可以预期的。&lt;/p&gt;&lt;p&gt;现在好了，以 LLM 为核心的生成式AI助手，智商是高了，理解是深了，表达是丰富了，却偏偏在它们原本最擅长的事情上频频翻车：&lt;/p&gt;&lt;p&gt;开灯、设定计时器、播报天气、播放音乐、运行 Routine。&lt;/p&gt;&lt;p&gt;&lt;img alt="港產片｜這些經典對白梗圖你知道出處嗎？ | 影視時尚| 潮遊生活| 當代中國" data-aistatus="1" data-backh="317" data-backw="562" data-imgfileid="503525868" data-ratio="0.5635416666666667" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr06ywibZXIziczXneOAWJnxEIR4n4mom6rhuKBc4Ae4LZzGLkOiav3TYYg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-type="jpeg" data-w="960" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/ad4dd05d-8c58-4b7b-806f-44fe6c80113e/640.png" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;为什么会这样？&lt;/p&gt;&lt;p&gt;因为，LLM 天生引入了大量随机性。它能理解更多含义，也允许更自由的表达，但代价是：解释空间被极大放大了，包括误解的可能性。&lt;/p&gt;&lt;p&gt;你向 ChatGPT 提出同一个问题，今天和明天得到不同答案，这正是它的价值所在。但当这种特性被用于控制一台咖啡机时，就有问题了。&lt;/p&gt;&lt;p&gt;在要求即时、可重复、零容错的控制场景下谈概率，本身就是一个大 bug。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-height="192" data-imgfileid="503525822" data-ratio="0.17037037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrVdUeqfe45qhxAXfZPNwEPViarwVPxp5awMNiaBzZ6NKQJ7W9I858NP8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" data-width="1125" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/657530c7-7b33-4480-b710-dceed29393d9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;相比之下，传统语音助手的本质，其实是模板匹配器。它们并不理解，只是识别关键词，然后填参数。&lt;/p&gt;&lt;p&gt;比如你说&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;播放广播&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;，系统非常清楚，后面只可能跟&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;电台名称&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;为了弥补生成式模型在确定性上的短板，亚马逊和谷歌都尝试将 LLM 与智能家居 API 深度绑定。但这又引入了新的问题。&lt;/p&gt;&lt;p&gt;LLM 确实不擅长在每一次请求中，都生成完全一致、语法严格正确的系统调用。&lt;/p&gt;&lt;p&gt;而当它们被要求直接生成 API 调用、去控制真实设备时&amp;mdash;&amp;mdash;哪怕是一个极小的偏差，都可能导致整个操作失败。&lt;/p&gt;&lt;p&gt;这正是为什么，你的咖啡机有时就是死活不肯给你做咖啡。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="200" data-backw="562" data-height="399" data-imgfileid="503525824" data-ratio="0.35555555555555557" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrJQ4ElmQgLsTjqakGgvMaAXytcC8bUWcQq0aIKfSXcqFDss44aooZcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" data-width="1122" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/35ab64d9-397b-4c44-a6aa-23c5281afd4f/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;理论上，让新助手达到旧助手那样的可靠性，并非不可能，但这需要极其大量的工程投入、约束设计和失败兜底。&lt;/p&gt;&lt;p&gt;而在资源有限、 &lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;做点更刺激、也更赚钱的事情&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;诱惑又足够大的现实里， 最简单的路径就是先把技术推到现实世界中，再让它慢慢自我修正。&lt;/p&gt;&lt;p&gt;换句话说，我们正在集体扮演一个角色：AI 的长期内测用户。&lt;/p&gt;&lt;p&gt;目前还没有人真正解决&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;如何让 LLM 知道什么时候该精确、什么时候可以随机&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;的问题。所以，大家可能要在相当长的一段时间里，不断和它较劲、和血压搏斗。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="204" data-backw="350" data-imgfileid="503525934" data-ratio="0.5828571428571429" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvruvgz6GGT4RpoYZMtJBxK7eEaUGstLxeFVHPLhln9bJh3ib75aStxssA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-type="gif" data-w="350" type="block" data-original-style="width:441px;height:257px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/b2fd925a-05e3-446e-897e-f30323866f0c/640.gif" data-order="0" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;既然如此，为什么还要坚定地抛弃旧技术？&lt;/p&gt;&lt;p&gt;两个字：潜力。&lt;/p&gt;&lt;p&gt;所谓的代理式 AI（Agentic AI），让系统具备服务链式调用的能力：它能够理解复杂任务之间的内在关系，并在此基础上动态生成执行逻辑。&lt;/p&gt;&lt;p&gt;这也是旧技术路线必须被放弃的根本原因。&lt;/p&gt;&lt;p&gt;过去，基于固定规则与关键词匹配的语音系统，在架构层面就被限定为&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31);font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif;font-size: 15px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-align: start;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;display: inline !important;float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「&lt;/span&gt;&lt;/span&gt;单指令执行器&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;，它们无法理解目标、拆解任务，更不可能在运行时生成新的行动路径。&lt;/p&gt;&lt;p&gt;这不是一次简单的技术升级，而是一次能力范式的切换。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="300" data-backw="300" data-imgfileid="503525933" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrWHLXEvlPETpaxh3nHll3vRDJUgibc6ROeLKFfjyVkK2dw4ZzuLZTMTA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=15" data-type="gif" data-w="300" type="block" data-original-style="width:378px;height:378px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/4b615278-c574-4d08-b93e-beef9648b7da/640.gif" data-order="1" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;回到社区舆论，虽然连最基本的指令都出错，但网友们也承认，升级后的语音助手在理解复杂命令这件事上，确实更强了。&lt;/p&gt;&lt;p&gt;比如你说，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;这里调暗一点，温度再高一点。&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt; 它可以同时调灯和调恒温器。&lt;/p&gt;&lt;p&gt;当质问&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;Alexa，你到底在干嘛？为什么不关掉我的音乐？！&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt; 它真的会去查一下发生了什么。&lt;/p&gt;&lt;p&gt;放在过去，这些都是不可想象的。&lt;/p&gt;&lt;p&gt;最为人称道的是是摄像头通知功能的变化。&lt;/p&gt;&lt;p&gt;传统系统往往只有一句高度概括的废话，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;后院检测到运动。&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;于是你不得不：打开 App &amp;rarr; 点开视频 &amp;rarr; 回看 &amp;rarr; 发现是一只猫。&lt;/p&gt;&lt;p&gt;现在，新系统会直接告诉你，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;门口出现了不熟悉的面孔，但没有进入院子。&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;用语音设置复杂 Routine，也确实比在 Alexa App 里一层层点设置来得轻松，哪怕这些 Routine 运行起来并不那么稳定。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="512" data-backw="512" data-imgfileid="503525935" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr1ZRhMQelUklrxZnk6zad4ZsvV160PgTzH9I6ib06lkbnyAdevEEQL1g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=16" data-type="gif" data-w="512" type="block" data-original-style="width:435px;height:435px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/6cddca10-f848-49f4-a9c3-5d789ec1290e/640.gif" data-order="2" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在大量用户讨论中，也逐渐形成了一个相对温和的共识：问题不在于是否引入 AI，而在于&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;边界&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;、是否试图用 AI 替代一切。&lt;/p&gt;&lt;p&gt;一些用户认为，更合理的方向不是&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;去按钮化&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;&amp;mdash;&amp;mdash;取代那些已经被验证过的、确定性的执行机制，而是让 AI 帮助人理解系统。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="148" data-backw="562" data-height="303" data-imgfileid="503525825" data-ratio="0.2638888888888889" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrib6tLj2YEiaj1DIyHRoDgibM80cvKr08BeYDllNbnIPrqrpYnC9nuQWcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-type="png" data-w="1080" data-width="1149" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/05ec9e55-444b-423b-8a36-8c4c8566188c/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当前出现的混乱，或许并不是生成式 AI 的失败，而是其被放置在了一个并不适合它的核心位置。&lt;/p&gt;&lt;p&gt;不过，至少在今天，这条清醒的边界远未被勾勒出来，也不知什么时候能被画出来。&lt;/p&gt;&lt;p data-end="237" data-pm-slice="0 0 []" data-start="205"&gt;那么，你的智能家具还好吗？有没有过类似的抓狂瞬间？欢迎来评论区唠唠。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/tech/845958/ai-smart-home-broken&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/technology/comments/1pvh1c8/how_ai_broke_the_smart_home_in_2025_the_arrival/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026｜相聚新加坡，探讨AI时代最核心难题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:45:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;活动 1&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题：在 AI 重构人类主体性的时代，如何捍卫我们的自主决断权？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在人工智能潜移默化地重构人类能动性 (Human Agency) 的当下，我们该如何保留有意义的人类自主决断权？&lt;/p&gt;&lt;p&gt;诚邀您参加由 AI Singapore 主办的「&lt;strong&gt;工作、学习、拥有与选择的权利&amp;rdquo; (The Right to Work, Learn, Own &amp;amp; Choose)&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;研讨会。本次会议旨在探讨技术型 AI 社区与 AI 治理社区如何深度融合，共同推动尊重人类主体性，并维护我们在工作、学习、所有权及选择权方面权益的 AI 系统发展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFZAFDCG3BZRSTRfD33ovjVzmAoHEDFuIn01qyYJvLP3UIwTFIIAFaicQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.4148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528551" data-aistatus="1" data-original-style="width:523px;height:740px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/dd72b408-a8c8-48b3-a83d-8a0e0515b55a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;本次研讨会邀请了多位重量级嘉宾，包括 Ashok Goel (佐治亚理工学院)、Jungpil Hahn (新加坡国立大学计算机学院)、Luke Zettlemoyer (华盛顿大学 &amp;amp; Meta FAIR) 以及 Djallel Bouneffouf (IBM 研究院)。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF0pJVKg7kn3nbPrG3HaynUdelpa18xX4YYUItLnKM8Ep7Wia8QkWjG3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528552" data-aistatus="1" data-original-style="width:535px;height:757px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5f2f70bd-7228-43ee-b26a-c35b6047497f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;会议详情： &lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;日期： 2026 年 1 月 23 日（星期五）&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;时间： 08:30 - 13:30&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;地点： 新加坡国立大学 COM3 多功能厅 (11 Research Link, Singapore 119391)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现场将提供午餐及茶点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注册链接：&lt;/strong&gt; https://luma.com/xyon5cw4 (截止日期：2026 年 1 月 22 日)&lt;/p&gt;&lt;p&gt;主办方将发送确认邮件以确认您的名额。&lt;/p&gt;&lt;p&gt;注：本次活动是新加坡 AI 研究周 (Singapore AI Research Week) 的一部分，与 AAAI2026 同期举行。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动 2&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题：探索 Agentic AI、自主智能体与多智能体系统的前沿融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;想要了解基于大语言模型 (LLM) 的智能体的前沿进展，以及构建和部署这些系统的经验教训吗？&lt;/p&gt;&lt;p&gt;诚邀您参加由新加坡国立大学人工智能研究所 (NAII)、DSO 国家实验室与亚马逊云科技 (AWS) 联合举办的专题研讨会：「&lt;strong&gt;Agentic AI meets Autonomous Agents and Multiagent Systems。&lt;/strong&gt;」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF8SMH1Pv1IY1ZxficxiaaKz2Dt6VIxwBKq1IXwzWxneQSYyHzInWtROfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.413888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528553" data-aistatus="1" data-original-style="width:498px;height:704px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/59d7d801-f6d3-42d3-aee9-78f3b53480f7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;现代 &amp;quot;Agentic AI&amp;quot; 系统（例如 LLM 驱动的智能体、使用工具的 Copilot 以及自主工作流）正从精心编排的演示 (Demos) 走向实际部署。这一转变要求系统具备长程规划能力、可靠的工具使用能力，以及与人类和环境进行稳健交互的能力。&lt;/p&gt;&lt;p&gt;本次研讨会不仅关注当下的 Agentic AI，更将其作为审视机器人学、具身智能 (Embodied AI) 以及多智能体系统 (Multiagent Systems) 中长期挑战的透镜。通过连接这些视角，我们旨在发掘共同面临的开放性问题，并激发跨领域合作，推动 Agentic AI 向更可靠、安全和高性能的方向发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;特邀演讲嘉宾：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Leslie Kaelbling (麻省理工学院 MIT)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Bo Li (伊利诺伊大学香槟分校 UIUC)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Pang Wei Koh (华盛顿大学 &amp;amp; Ai2)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Frank Dignum (瑞典于默奥大学)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFic38EMfO6tsEZX1EOKGJ1dGnx95FBbUrM9U1lQBpXUPHkCCZe1WqBWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.413888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528554" data-aistatus="1" data-original-style="width:500px;height:707px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4fd8ee4a-d22b-4505-a07e-d2dd2d7f6844/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;活动详情：&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;日期： 2026 年 1 月 21 日（星期三）&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;时间： 13:00 - 18:00&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;地点： 新加坡国立大学 COM3 多功能厅 (11 Research Link, Singapore 119391)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现场将提供茶点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;立即注册&lt;/strong&gt;： https://luma.com/9hz1jyvg&lt;/p&gt;&lt;p&gt;主办方将发送确认邮件以确认您的名额。&lt;/p&gt;&lt;p&gt;注：本次活动是新加坡 AI 研究周 (Singapore AI Research Week) 的一部分，与 AAAI2026 同期举行。&lt;/p&gt;&lt;p&gt;以上邀请是 &amp;ldquo;on behalf of 新国立副校长 Bryan Low &amp;nbsp;,助理教授 刘钿渤 &amp;rdquo;。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谷歌工程师抛出5个残酷问题：未来两年，软件工程还剩下什么？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:42:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;软件行业正站在一个颇为微妙的拐点上。AI 已经从自动补全代码，演进为能够自主执行开发任务的智能体。&lt;/p&gt;&lt;p&gt;在这一变化之下，初级开发者和高级开发者正同时被推入各自不同、却同样棘手的困境之中。&lt;/p&gt;&lt;p&gt;对初级开发者而言，最大的挑战不在于会不会写代码，而在于还没来得及成长，练级空间就被压缩了。企业不再愿意为学习成本买单，初级岗位要么减少，要么被要求一上来就能独立产出。&lt;/p&gt;&lt;p&gt;而对高级开发者来说，处境同样不好过。AI 并没有让他们更轻松，而是让责任进一步集中。当团队规模缩小、初级人手减少，高级工程师往往既要做架构决策，又要兜底 AI 和自动化系统带来的各种隐性风险，代码质量、性能、安全、合规。写代码的比例在下降，但判断、评审和决策的压力却在上升，一旦系统出问题，责任仍然落在人身上。&lt;/p&gt;&lt;p&gt;接下来会发生什么，充满了不确定性。&lt;/p&gt;&lt;p&gt;Addy Osmani，来自谷歌的一名软件工程师，在一篇文章中提出了 5 个可能在 2026 年前重塑软件工程的关键问题，并为每个问题给出两种截然不同的走向。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="399" data-imgfileid="503528238" data-ratio="0.3453703703703704" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiczH3BljB58qB12ATwIAHhVjuyFBWSghCgia6xgZwZlCUXhGXbgg6td0w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1154" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/abc09958-2bd4-4bc7-8c6d-a5ec751cc27d/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;文章链接：https://addyosmani.com/blog/next-two-years/&lt;/p&gt;&lt;p&gt;这五个问题都指向同一件事，软件工程正在从写代码的职业，转变为驾驭复杂系统与 AI 的职业。未来不是单一答案，而是多种路径并存，谁能适应变化，谁就能留下来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;初级开发者之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;结论很直接：随着 AI 开始自动化入门级任务，初级开发者的招聘可能会出现崩塌；也可能随着软件渗透到几乎所有行业而重新反弹。这两种未来都存在，但对应的生存策略完全不同。&lt;/p&gt;&lt;p&gt;像传统路径，学会编程、拿到初级岗位、逐步成长为高级工程师正在动摇。一项覆盖 6200 万名劳动者的哈佛研究发现，当企业采用生成式 AI 后，在六个季度内，初级开发者的就业人数下降了大约 9%&amp;ndash;10%，而高级开发者的就业几乎没有变化。过去三年，大型科技公司招聘的应届毕业生数量减少了 50%。正如一位工程师略带讽刺地说：既然一个 AI 编码智能体的成本更低，为什么还要花 9 万美元去雇一个初级工程师？&lt;/p&gt;&lt;p&gt;这并不只是 AI 的问题。像利率上升等宏观因素，在 2022 年左右就已出现影响，那时 AI 工具还未大规模普及。但 AI 加速了这一趋势。如今，一名配备 AI 辅助的高级工程师，产出已经相当于过去一个小团队的工作量。相比裁员，许多公司更常见的做法是悄悄地不再招聘初级开发者。&lt;/p&gt;&lt;p&gt;反过来的情景是：AI 在所有行业，而不仅仅是科技行业，释放出对开发者的巨大需求。医疗、农业、制造业、金融业都开始大规模嵌入软件和自动化。AI 不是取代开发者，而是成为一种放大器，把开发工作扩展到过去几乎不雇程序员的领域。初级岗位会更多出现，但形式不同：那些能快速为特定细分场景构建自动化和集成方案的 AI 原生开发者。&lt;/p&gt;&lt;p&gt;美国劳工统计局预计，2024 年到 2034 年间，软件相关岗位将增长约 15%。如果企业选择用 AI 来扩大产出，而不是单纯压缩人力规模，它们仍然需要人类去把握 AI 创造的新机会。&lt;/p&gt;&lt;p&gt;但悲观情景的一个长期风险常常被忽视：今天的初级开发者，就是 5 到 10 年后的高级工程师和技术领导者。如果完全切断人才培养管道，最终会造成领导力真空。行业老兵将这种现象称为缓慢衰退，一个停止培养接班人的生态系统。&lt;/p&gt;&lt;p&gt;如何应对？&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要让自己具备 AI 使用能力并保持多面性。证明一名初级开发者 + AI 的组合，能够匹配一个小团队的产出。使用 AI 编码智能体（如 Cursor、Antigravity、Claude Code、Gemini CLI）来构建更大的功能模块，但要理解并能解释其中的每一行代码，至少是大部分代码。把重心放在 AI 不容易替代的能力上：沟通能力、问题拆解能力、领域知识。将相邻岗位（如 QA、开发者关系、数据分析）视为切入口。建立作品集，尤其是包含 AI API 集成的项目。考虑学徒制、实习、合同制工作或参与开源项目。不要成为又一个需要大量培训的应届生，而要成为一个能够立刻产生价值、并且学习速度很快的工程师。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，初级人员减少意味着更多基础性工作会落到自己身上。要用自动化来应对日常事务，但不要什么都自己做。搭建 CI/CD、代码规范检查工具以及 AI 辅助测试，以捕捉基础问题。通过开源项目或辅导其他部门的同事，进行非正式的指导。如果未来初级岗位需求回升，要准备好高效地进行入职引导，并以结合 AI 的方式进行任务分配。你的价值不在于自己写了多少代码，而在于放大整个团队的产出。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528242" data-ratio="0.5895765472312704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicPgNrXjoliaeCr6aXeuCPkDmqD7qWnmSPm7zUSRbl57AQATosCkZmC3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="921" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ef33c45d-7e16-4101-b86a-fd474139c8b0/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;技能之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：当 AI 编写了大部分代码之后，编程基本功要么会逐渐退化，要么会因为人类开发者转向监督与把关而变得比以往任何时候都更重要。接下来的几年，将决定我们究竟是用理解力换速度，还是在效率提升的同时守住理解。&lt;/p&gt;&lt;p&gt;如今，已有 84% 的开发者在日常工作中经常使用 AI 辅助。对许多人来说，面对一个 Bug 或新功能时的第一反应，不再是从零开始写代码，而是先写一个提示词，把 AI 生成的代码片段拼接起来。入门级开发者正在跳过最难的那条路：他们可能从未亲手实现过一棵二叉搜索树，也从未独立排查过一次内存泄漏。&lt;/p&gt;&lt;p&gt;技能结构正在发生迁移：从实现算法，转向知道如何向 AI 提出正确的问题，并验证它的输出。职业阶梯的第一步，不再要求展示纯粹的编码能力，而是能够熟练地提示 AI、校验结果。一些资深工程师担心，这会催生出一代无法独立高质量写代码的开发者，一种事实上的去技能化。而 AI 生成的代码往往会引入隐蔽的 Bug 和安全漏洞，经验不足的开发者很容易忽略这些问题。&lt;/p&gt;&lt;p&gt;另一种对立的情景是：当 AI 处理掉 80% 的常规工作后，人类将专注于最困难的那 20%。架构设计、复杂集成、创造性设计、边界情况 &amp;mdash;&amp;mdash; 这些仍然是机器单独难以解决的问题。AI 的普及并不会让深度知识过时，反而会让人类专家的价值更加凸显。这正是高杠杆工程师：他们把 AI 当作放大器，但必须对系统有深入理解，才能真正驾驭它。&lt;/p&gt;&lt;p&gt;如果每个人都能使用 AI 编码智能体，真正区分优秀开发者的，是能否判断 AI 何时是错误的，或次优的。一位资深工程师曾这样说过：最好的软件工程师，不是写代码最快的人，而是最清楚什么时候不该相信 AI 的人。&lt;/p&gt;&lt;p&gt;编程工作的重心正在转移：更少时间用来敲模板代码，更多时间用来审查 AI 输出是否存在逻辑错误、安全缺陷，或与需求不匹配的问题。关键能力逐渐变成软件架构、系统设计、性能调优和安全分析。AI 可以很快生成一个 Web 应用，但只有经验丰富的工程师，才能确保它遵循了安全最佳实践，没有引入竞态条件。&lt;/p&gt;&lt;p&gt;在 2025 年，开发者社区的讨论明显分裂。一些人坦言自己几乎不再手写代码，认为面试和考核方式也应该随之演进；另一些人则认为，跳过基础训练会导致在 AI 输出失效时陷入更频繁、更痛苦的救火。整个行业开始期待工程师同时具备两种能力：AI 带来的速度，以及支撑质量的基础智慧。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要把 AI 当作学习工具，而不是拐杖。当 AI 编码智能体（如 Cursor、Antigravity、Claude Code、Gemini CLI）给出代码时，主动复盘它为什么能工作、哪里可能存在问题。偶尔关闭 AI 辅助，亲手实现关键算法。优先夯实计算机科学基础：数据结构、算法、复杂度分析、内存管理。一个项目可以做两遍，一遍借助 AI，一遍不借助 AI，对比差异。学习提示词工程和工具使用技巧。同时训练严谨的测试习惯：编写单元测试，在不立刻求助 AI 的情况下阅读堆栈信息，熟练使用调试器。深化 AI 难以复制的互补能力：系统设计、用户体验直觉、并发问题的推理能力。向外界证明，你既能借助 AI 高效产出，也能在它失效时解决棘手问题。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要将自己定位为质量与复杂性的守门人。持续打磨核心专长：架构、安全、可扩展性以及领域知识。练习在系统中引入 AI 组件时的整体建模，并提前思考失败模式。持续关注 AI 生成代码中暴露出的新型漏洞。主动承担导师和评审者的角色，明确哪些场景可以使用 AI，哪些场景必须人工审查（例如支付或安全相关代码）。把精力更多放在创造性和战略性工作上，让初级开发者 + AI 的组合去处理常规的 API 对接，而你来决定应该构建哪些 API。投资软技能和跨领域知识，持续跟进新工具和最佳实践。最终，进一步强化那些让人类开发者不可替代的能力：稳健的判断力、系统级思考，以及培养他人的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528243" data-ratio="0.6175925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicfIzSfXLNBHxg6YrSL2VuNkCFJrdHAuib940tYnYlqiaDYBgmWHic2ILiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cb39a5be-5ca3-4655-9ece-519525cececc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;角色之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：开发者这一角色，可能会收缩为一种有限的审计岗位（主要负责监督 AI 生成的代码），也可能扩展为一个关键性的编排者角色，负责设计和治理由 AI 驱动的系统。无论走向哪一种未来，创造价值都不再只是写代码本身。&lt;/p&gt;&lt;p&gt;这里的两种极端非常鲜明。在其中一种设想中，开发者的创造性职责被明显削弱。他们不再真正构建软件，而是主要负责审计和看护 AI 的输出。AI 系统承担实际生产；人类开发者检查自动生成的代码，查找错误、偏见或安全问题，并批准部署。创造者变成了检查者，写代码的乐趣被风险管理的焦虑所取代。&lt;/p&gt;&lt;p&gt;已经有报道称，一些工程师花在评估 AI 生成的 pull request 和管理自动化流水线上的时间越来越多，而从零开始写代码的时间却越来越少。编程逐渐不像是一种创造性的问题求解，更像是一种合规性工作。一位工程师曾无奈地感叹：我不想最后变成一个代码清洁工，只是收拾 AI 扔过来的烂摊子。&lt;/p&gt;&lt;p&gt;另一种未来则要有意思得多：开发者进化为高层次的编排者，融合技术、战略与伦理责任。随着 AI 工人的出现，人类开发者承担起类似架构师或总承包商的角色，负责设计整体系统，决定哪些任务交给哪一个 AI 或软件组件，并将众多运转中的部件编织成一个完整方案。&lt;/p&gt;&lt;p&gt;一位低代码平台的 CEO 曾这样描述这一愿景：在 Agentic 的开发环境中，工程师会成为作曲家，指挥由多个 AI 智能体和软件服务组成的合奏。他们不会亲自写下每一个音符，但会定义旋律 &amp;mdash;&amp;mdash; 系统架构、接口，以及各个智能体如何交互。这个角色本身具有跨学科和创造性：既是软件工程师，又是系统架构师，同时还是产品战略制定者。&lt;/p&gt;&lt;p&gt;更乐观的看法是：当 AI 接管重复性劳动后，开发者的角色将被迫转向更高价值的活动。工作本身反而可能变得更有意思。总得有人决定 AI 应该构建什么，验证产品是否合理，并不断对其进行改进。&lt;/p&gt;&lt;p&gt;最终走向哪一条路，很大程度上取决于组织如何选择整合 AI。把 AI 视为劳动力替代品的公司，可能会缩减开发团队规模，让留下来的工程师负责维持自动化系统运转；而把 AI 当作团队放大器的公司，则可能保持相近的人员规模，但让每位工程师承担更宏大的项目。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要主动寻找不只是写代码的机会。可以自愿参与测试用例编写、CI 流水线搭建或应用监控等工作，这些能力都与审计者 / 看护者角色高度契合。同时，通过个人项目保持对创造性编码的热情，避免失去构建的乐趣。培养系统思维：学习各个组件如何通信，理解什么样的 API 才算设计良好。多阅读工程博客和系统设计案例。熟悉代码生成之外的 AI 与自动化工具，例如编排框架和 AI API。提升书面和口头沟通能力，写文档时假设读者是另一个人。向资深同事请教时，不只问我的代码能不能跑，而要问我是不是考虑到了该考虑的事情。为自己做好准备，成为验证者、设计者和沟通者，而不仅仅是写代码的人。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要主动拥抱领导力和架构层面的责任。塑造 AI 和初级成员遵循的标准与框架，制定代码质量清单和负责任使用 AI 的规范。持续关注 AI 生成软件在合规与安全方面的新问题。把重心放在系统设计和集成能力上，主动梳理跨服务的数据流并识别潜在失效点。熟练使用各种编排平台，如 Kubernetes、Airflow、无服务器框架以及智能体编排工具。进一步强化技术导师的角色：更多代码评审、设计讨论和技术规范输出。打磨快速评估他人（或 AI）代码并给出高层次反馈的能力。同时培养产品和业务意识，理解为什么要做某个功能，以及用户真正关心什么。可以旁听产品经理的工作，或参与用户反馈会议。通过原型开发、黑客松或前沿技术研究，保护并延续自己的创造热情。从写代码的人，进化为指挥全局的指挥家。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;专才还是通才之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：过于狭窄的专才，面临其细分领域被自动化或淘汰的风险；而在一个快速变化、深度融入 AI 的环境中，更受青睐的是 T 型工程师，既具备广泛的适应能力，又在一两个方向上有深度专长。&lt;/p&gt;&lt;p&gt;在模型、工具和框架不断兴衰更替的背景下，把整个职业生涯押注在单一技术栈上，风险越来越高。某个传统框架的专家，可能会突然发现，当新的 AI 工具几乎不需要人工干预就能处理那套技术时，自己的需求度迅速下降。那些只专注于某一个技术栈、某一个框架或某一个产品领域的开发者，可能一觉醒来就发现，这个领域正在衰退，甚至变得多余。&lt;/p&gt;&lt;p&gt;回想一下 COBOL 开发者、Flash 开发者，或那些在行业转向时未能及时转型的移动游戏引擎专家。不同之处在于，如今变化的速度更快。AI 自动化可以让某些编程任务变得极其简单，从根本上削弱那些围绕这些任务建立起来的岗位。一个只会做一件事的专家（比如精调 SQL 查询，或把 Photoshop 设计稿切成 HTML），可能会发现 AI 已经承担了其中 90% 的工作。&lt;/p&gt;&lt;p&gt;招聘市场总是在追逐最新的细分领域。几年前，云基础设施专家炙手可热；如今，AI/ML 工程师成为焦点。那些只深耕于昨日技术的人，往往会在该领域失去吸引力时陷入停滞。&lt;/p&gt;&lt;p&gt;与此相对的是一种新的专业化形态：多面手式的专才，或者说 T 型开发者。他们在一到两个领域具备深度专长（纵向的一笔），同时对许多其他领域有广泛了解（横向的一笔）。这类工程师往往成为跨学科团队中的胶水，能够与不同方向的专家沟通，在需要时填补空白。&lt;/p&gt;&lt;p&gt;企业不再需要要么过于浅尝辄止、要么过度狭窄的开发者，而是希望工程师既有坚实的核心能力，又能在整个技术栈中协同工作。原因之一是效率：T 型工程师往往可以端到端解决问题，而不必等待频繁的交接；另一个原因是创新：不同领域知识的交叉，往往能催生更好的解决方案。&lt;/p&gt;&lt;p&gt;AI 工具实际上更能放大通才的能力，让一个人同时处理多个组件变得更加容易。后端工程师可以借助 AI 辅助生成可用的 UI；前端工程师也能让 AI 生成服务器端的样板代码。在一个 AI 高度充沛的环境中，人们可以更广泛地工作。相反，深度专才可能会发现自己的细分领域被部分自动化，却很难顺利横向扩展。&lt;/p&gt;&lt;p&gt;如今，接近 45% 的工程岗位都期望候选人具备多领域能力：比如既会编程，又懂云基础设施；或者以前端为主，但对机器学习有一定了解。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要尽早打下宽广的基础。即便是因某个具体角色被录用，也要有意识地走出自己的竖井。如果你做移动端，就去学一些后端基础；如果你做前端，试着写一个简单的服务器。了解部署流程，熟悉 Docker、GitHub Actions 等工具。找出一两个真正让你产生兴趣的方向，持续深入，这将成为你的纵向专长。把自己定位成复合型角色，例如侧重云安全的全栈开发者，或具备 UX 专长的前端工程师。利用 AI 工具快速进入新领域：当你对后端还很陌生时，可以让 ChatGPT 生成入门级 API 代码并加以学习。培养持续再学习的习惯。通过黑客松或跨职能项目，强迫自己进入通才模式。主动告诉你的经理，你希望接触项目的不同部分。在职业早期，适应能力本身就是一种超能力。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要系统性地梳理自己的技能图谱：哪些领域是你的强项，哪些相邻领域只是浅尝辄止。选择一到两个相关方向，投入精力做到能对话、能上手。如果你是后端数据库专家，可以去熟悉一个现代前端框架，或学习机器学习流水线的基础。借助 AI 辅助，在自己薄弱的领域做一个小项目。把你的深度专长放到新的语境中：如果你擅长 Web 性能优化，就去探索这些能力如何应用到 ML 推理优化上。主动推动或设计更具跨职能属性的角色定位，争取成为多领域项目的整合负责人。在指导他人、扩散技能的同时，也从他们身上学习新东西。更新简历，突出你的多面性。利用经验识别可迁移的模式和知识。最终，成为 T 型工程师的榜样：在专长领域足够深入，带来权威和信任；同时不断横向延展自己的能力边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;教育之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：计算机科学（CS）学位是否仍会是进入软件行业的黄金标准，还是会被更快的学习路径（训练营、在线平台、企业培训）所取代？在一个每隔几个月就发生变化的行业面前，大学可能越来越难跟上节奏。&lt;/p&gt;&lt;p&gt;长期以来，四年制计算机科学学位一直是进入软件岗位的主要通行证。但这一传统正在受到质疑。&lt;/p&gt;&lt;p&gt;其中一种未来是：大学仍然重要，但越来越难保持相关性。学位依然是默认的资质门槛，但课程内容落后于飞速变化的行业需求，受限于缓慢的课程更新周期和繁琐的审批流程。学生和雇主都会感觉，学术界与产业脱节，教授的要么是纯理论，要么是已经过时、无法直接转化为工作能力的实践。&lt;/p&gt;&lt;p&gt;许多应届毕业生表示，在整个本科学习期间，他们从未接触过云计算、现代 DevOps 或 AI 工具。如果大学要求学生投入高昂的时间和金钱，却提供低相关度的教育，就有可能被视为昂贵的看门人。但由于惯性，许多公司仍然要求学士学位，于是弥补技能差距的负担被转嫁给学生，他们不得不通过训练营、在线课程和自学项目来补齐短板。&lt;/p&gt;&lt;p&gt;企业每年要花费数十亿美元来培训新员工，因为毕业生并不具备职场所需的技能。大学可能会加一门 AI 伦理课，或开一门云计算选修课，但等到真正落地时，行业工具往往已经更新换代。&lt;/p&gt;&lt;p&gt;更具颠覆性的情景是：传统教育体系被越来越多的新系统所替代，编程训练营、在线认证、自学作品集，以及由雇主主导的培训学院。许多知名企业（如 Google、IBM）已经在部分技术岗位上取消了学历要求。到 2024 年，接近 45% 的公司计划在至少一部分岗位上取消学士学位门槛。&lt;/p&gt;&lt;p&gt;编程训练营本身也在成熟。它们培养出的毕业生，已经可以与科班 CS 毕业生一起进入顶级公司工作。这类项目周期更短（例如 12 周的高强度训练），重点放在实用技能上：当前流行的框架、云服务以及团队协作。招聘中的硬通货正在转向实时作品集、微证书和可验证技能。一份强有力的 GitHub 作品集或被认可的认证，已经可以绕过学位要求。&lt;/p&gt;&lt;p&gt;由雇主驱动的教育模式正在出现：公司建立自己的培训管道，或与训练营合作。一些大型科技公司已经为非传统背景的候选人开设了内部大学。AI 本身也带来了新的学习方式：AI 导师、交互式编程沙盒、个性化教学，使学习不再局限于大学校园。&lt;/p&gt;&lt;p&gt;一个模块化的学习生态，比昂贵的四年制学位更加普惠。一个身处缺乏优质 CS 大学国家的孩子，也可以修同样的 Coursera 课程，构建与硅谷学生同样水平的作品集。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于有志或刚入行的开发者来说，如果你身处传统 CS 项目中，不要完全依赖它。用真实项目来补充课程：做一个 Web 应用，参与开源项目，争取实习或带薪实训。如果课程体系没有覆盖热门方向，就通过在线平台自学。获取行业认可的认证（如 GCP、AWS、Azure），向雇主证明你的实操能力。如果你是自学或来自训练营，重点打造有说服力的作品集，至少要有一个体量不小、文档完善的项目。积极参与开发者社区：贡献开源、撰写技术文章，通过 LinkedIn、线下聚会和开发者活动建立人脉。争取让一位有经验的开发者为你背书。持续学习，因为技术技能的半衰期很短。把 AI 当作你的私人导师，用作品集、认证以及对自己项目的清晰讲述来证明能力，这些都会为你打开机会之门。&lt;/p&gt;&lt;p&gt;对于资深开发者和管理者来说，单靠既有学历不会一直奏效。要持续投入学习：在线课程、研讨会、技术大会和认证。用新的方式验证自己的能力，做好准备应对以真实问题检验当前水平的面试。保持使用新技术的副项目。重新审视招聘要求：你真的需要新员工拥有 CS 学位，还是你真正需要的是某些技能和持续学习的能力？推动以技能为先的招聘方式，扩大人才池。支持内部培训项目或学徒制岗位，为没有传统背景的初级开发者搭建导师网络。积极与高校和替代教育体系互动：参与顾问委员会、做客座分享、反馈课程与行业需求之间的差距。也要在自身职业发展中体现这一点：真实世界的成果和持续学习，比再拿一个学位更重要。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://addyosmani.com/blog/next-two-years/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>红杉合伙人：2026，AGI已经来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:39:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;我们常问：AGI 什么时候到来？你有没有想过，可能它已经来了。&lt;/p&gt;&lt;p&gt;最近，红杉资本合伙人 Pat Grady、Sonya Huang 联合发表了一篇博客，指出 AGI 已经到来，就在此刻。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528672" data-ratio="0.725925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFCb9l5v589m0Y81ebia13JeOtibXibWSjK3aNBPOx3ra84j0nH3ePMEHIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/afd414e8-a6bf-4682-b544-0616b4d22218/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在他们看来，AGI 不需要一个玄乎的技术定义 &amp;mdash;&amp;mdash; 它的本质就是「能把事情搞清楚的能力」。而以 Claude Code 为代表的长周期智能体，正是这种能力的第一批例证。&lt;/p&gt;&lt;p&gt;文中举了一个例子：一位创始人让智能体帮他找一个开发者关系负责人。智能体先在 LinkedIn 上搜索，发现职位头衔说明不了问题；于是转向 YouTube 找技术演讲，筛选出互动数据亮眼的演讲者；再与 Twitter 交叉比对，找出真正有品味、有粉丝的人；然后检查谁最近发帖变少了 &amp;mdash;&amp;mdash; 这往往意味着对现职的倦怠；最后锁定一位刚经历公司裁员、专业方向完全匹配的候选人，起草了一封精准的挖角邮件。&lt;/p&gt;&lt;p&gt;全程 31 分钟。 没有人告诉它该怎么做，它自己形成假设、验证、碰壁、转向，直到找到答案。这就是「把事情搞清楚」。而长周期智能体已经具备了这种能力。&lt;/p&gt;&lt;p&gt;更令人振奋的是，他们给出了一条清晰的指数曲线：长周期智能体的能力每 7 个月翻一番。按此推算，2028 年智能体能完成人类专家一天的工作，2034 年能完成一年的工作。&lt;/p&gt;&lt;p&gt;这意味着什么？&lt;strong&gt;你对 2030 年的梦想，2026 年就能实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个博客得到了一些从业者的认同。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528673" data-ratio="0.3907407407407407" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF9cku6iahJjwuRcIgPfMDia7eOlLYLRLOrIFrgGoicqAI0n0CjtOBMcJ4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/10a8d6ba-6715-4659-84ae-ac10e10a3772/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528674" data-ratio="0.4583333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFAL8kGEiaibBjKzPWdAtJJHDa0bSRZtB2zic07TBfGjNqY5QbYI4DR9hog/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/14c409be-0b2f-4f91-b2d2-f65fbfc0c678/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但也有人认为其中忽略了一些东西，对于未来的预测过于乐观。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528675" data-ratio="1.0462962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFgH1QVx63ZMw8XWpIehXXA07TaB5A59hj0zq04lTjk3icOAZcQ8Lxl5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f319deac-c4f5-4bc7-8f02-c8f257b6e597/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528676" data-ratio="0.9481481481481482" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFs1Crr1oxUCXwUkRBwX2jWIBfDML6RyIYezZAk1SXNqkcCkbOKpJEKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/dc2e73cf-3f1e-4dc0-9bf8-8f7ae39ff805/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;大家可以读完原文自行判断。&lt;/p&gt;&lt;p&gt;以下是博客内容：&lt;/p&gt;&lt;p&gt;几年前，一些顶尖研究者告诉我们，他们的目标是 AGI。我们急切地想听到一个清晰的定义，天真地问道：「你们如何定义 AGI？」他们顿了顿，彼此试探性地对视，然后给出了一个后来成为 AI 领域某种「箴言」的回答：「嗯，&lt;strong&gt;我们每个人都有自己的定义，但我们看到它的时候就会知道&lt;/strong&gt;。」&lt;/p&gt;&lt;p&gt;这段小插曲，正是我们追寻 AGI 具体定义之旅的缩影。这个定义始终难以捉摸。&lt;/p&gt;&lt;p&gt;然而，尽管定义难以捉摸，现实却并非如此。&lt;strong&gt;AGI 已经到来，就在此刻&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;编程智能体是第一个例证。更多案例正在涌现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长周期（long-horizon）智能体在功能上就是 AGI，而 2026 年将是它们的元年。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不受细节拖累&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在继续之前，有必要承认：我们没有资格提出 AGI 的技术定义。&lt;/p&gt;&lt;p&gt;我们是投资人。我们研究市场、创始人，以及两者碰撞的产物：商业。&lt;/p&gt;&lt;p&gt;因此，我们给出的是一个功能性定义，而非技术性定义。新的技术能力引出了 Don Valentine（红杉资本创始人、硅谷风险投资之父）的经典问题：So what？那又怎样？&lt;/p&gt;&lt;p&gt;答案在于现实世界的影响。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI 的功能性定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI 就是能把事情搞清楚的能力。就这么简单。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们深知，如此不精确的定义无法平息任何哲学争论。但从务实的角度来说，当你想完成某件事时，你想要什么？一个能把事情搞清楚的 AI。至于它是如何做到的，远不如它确实做到了来得重要。&lt;/p&gt;&lt;p&gt;一个能把事情搞清楚的人，拥有一定的基础知识、基于这些知识进行推理的能力，以及迭代找到答案的能力。&lt;/p&gt;&lt;p&gt;一个能把事情搞清楚的 AI，拥有一定的基础知识（预训练）、基于这些知识进行推理的能力（推理时计算），以及迭代找到答案的能力（长周期智能体）。&lt;/p&gt;&lt;p&gt;第一个要素（知识 / 预训练）推动了 2022 年 ChatGPT 横空出世的时刻。第二个要素（推理 / 推理时计算）随着 2024 年底 o1 的发布而到来。&lt;strong&gt;第三个要素（迭代 / 长周期智能体）则在过去几周内到来 &amp;mdash;&amp;mdash;Claude Code 和其他编程智能体跨越了一个能力门槛。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具有通用智能的人可以连续自主工作数小时，发现和修正自己的错误，无需被告知下一步该做什么就能自行判断。具有通用智能的智能体也能做到同样的事情。这是全新的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「把事情搞清楚」意味着什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一位创始人给他的智能体发消息：「我需要一个开发者关系负责人。技术能力要强到能赢得资深工程师的尊重，但又真正喜欢玩 Twitter。我们的客户是平台团队。去吧。」&lt;/p&gt;&lt;p&gt;智能体从显而易见的地方入手：在 LinkedIn 上搜索优秀开发者优先公司的「Developer Advocate」和「DevRel（高级开发者关系）」&amp;mdash;&amp;mdash;Datadog、Temporal、Langchain。找到了数百份简历。但职位头衔无法揭示谁真正擅长这份工作。&lt;/p&gt;&lt;p&gt;它转向寻找信号而非资历。它在 YouTube 上搜索技术大会演讲。找到了 50 多位演讲者，然后筛选出演讲互动数据亮眼的那些。&lt;/p&gt;&lt;p&gt;它将这些演讲者与 Twitter 进行交叉比对。一半人的账号不活跃，或者只是转发公司博客。这不是我们要的。但有十几个人拥有真正的粉丝群 &amp;mdash;&amp;mdash; 他们发表真实观点，与人互动，获得开发者的关注。而且他们的帖子很有品味。&lt;/p&gt;&lt;p&gt;智能体进一步缩小范围。它检查谁在过去三个月发帖频率下降。活跃度下降有时意味着对当前工作的倦怠。三个名字浮出水面。&lt;/p&gt;&lt;p&gt;它调研这三个人。一个刚宣布了新职位 &amp;mdash;&amp;mdash; 来晚了。一个是刚刚完成融资的公司创始人 &amp;mdash;&amp;mdash; 不会离开。第三位是一家 D 轮融资公司的 DevRel 人员，该公司刚刚在营销部门进行了裁员。她最近的演讲正好是关于这家创业公司所瞄准的平台工程领域。她有 1.4 万 Twitter 粉丝，发的梗图能让真正的工程师互动。她的 LinkedIn 两个月没更新了。&lt;/p&gt;&lt;p&gt;智能体起草了一封邮件，提到了她最近的演讲、与创业公司理想客户画像的重合度，以及关于小团队能提供的创作自由的具体说明。建议先随便聊聊，不是推销。&lt;/p&gt;&lt;p&gt;总耗时：31 分钟。创始人得到的不是挂在招聘网站上的一份 JD，而是一份只有一个人的候选名单。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这就是「把事情搞清楚」的含义。在模糊中导航以达成目标 &amp;mdash;&amp;mdash; 形成假设，验证假设，走进死胡同，然后转向，直到某些东西奏效。&lt;/strong&gt;智能体没有遵循脚本。它运行的是一位优秀招聘者脑中同样的循环，只不过它不知疲倦，31 分钟就完成了，且无需被告知如何做。&lt;/p&gt;&lt;p&gt;需要说明的是：&lt;strong&gt;智能体仍然会失败。它们会产生幻觉，丢失上下文，有时会信心满满地冲向完全错误的方向。但趋势是明确的，而且这些失败越来越可以被修复。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们是如何走到这一步的？从推理模型到长周期智能体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在去年的文章中，我们将推理模型描述为 AI 最重要的新前沿。长周期智能体将这一范式推进得更远，让模型能够采取行动并随时间迭代。&lt;/p&gt;&lt;p&gt;让模型思考更长时间并非易事。基础推理模型可以思考几秒或几分钟。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;两种不同的技术路径似乎都在奏效并能良好扩展：强化学习和智能体框架。&lt;/strong&gt;前者通过训练过程中的不断调整，从本质上教会模型保持更长时间的专注。后者则围绕模型的已知局限（记忆交接、压缩等）设计特定的脚手架。&lt;/p&gt;&lt;p&gt;扩展强化学习是研究实验室的领域。他们在这方面取得了非凡进展，从多智能体系统到可靠的工具使用。&lt;/p&gt;&lt;p&gt;设计优秀的智能体框架是应用层的领域。当今市场上一些最受欢迎的产品正是以其精心设计的智能体框架而闻名：Manus、Claude Code、Factory 的 Droids 等。&lt;/p&gt;&lt;p&gt;如果要押注一条指数曲线，那就是长周期智能体的性能曲线。METR 一直在细致追踪 AI 完成长周期任务的能力。进步速度呈指数级增长，大约每 7 个月翻一番。&lt;strong&gt;如果我们沿着这条指数曲线推算，到 2028 年，智能体应该能够可靠地完成人类专家需要一整天的任务；到 2034 年完成一整年的任务；到 2037 年完成一个世纪的任务。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那又怎样？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很快你就能「雇佣」一个智能体了。这是 AGI 的一个试金石。&lt;/p&gt;&lt;p&gt;你今天就可以「雇佣」GPT-5.2、Claude、Grok 或 Gemini。更多例子正在涌现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;医疗：OpenEvidence 的 Deep Consult 扮演专科医生&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;法律：Harvey 的智能体扮演律师助理&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;网络安全：XBOW 扮演渗透测试员&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;运维：Traversal 的智能体扮演 SRE&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;销售：Day AI 扮演业务开发代表、售前工程师和收入运营负责人&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;招聘：Juicebox 扮演招聘官&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数学：Harmonic 的 Aristotle 扮演数学家&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;芯片设计：Ricursive 的智能体扮演芯片设计师&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 研究：GPT-5.2 和 Claude 扮演 AI 研究员&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从「说话者」到「行动者」：对创始人的启示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这对创始人有着深远的影响。&lt;/p&gt;&lt;p&gt;2023 和 2024 年的 AI 应用是「说话者」。有些是非常老练的对话者！但它们的影响力是有限的。&lt;/p&gt;&lt;p&gt;2026 和 2027 年的 AI 应用将是「行动者」。它们会给人同事的感觉。使用频率将从每天几次变成全天候、每一天，同时运行多个实例。用户不是这里省几个小时、那里省几个小时 &amp;mdash;&amp;mdash; 而是从作为个人贡献者工作，变成管理一个智能体团队。&lt;/p&gt;&lt;p&gt;还记得那些关于「出售工作成果」的讨论吗？现在这成为可能了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你能完成什么工作？&lt;/strong&gt;&amp;nbsp;长周期智能体的能力与模型的单次前向传播截然不同。在你的领域，长周期智能体能解锁哪些新能力？哪些任务需要持久性，哪些任务的瓶颈是持续的注意力？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你将如何把这些工作产品化？&lt;/strong&gt;&amp;nbsp;当工作的用户界面从聊天机器人演进到智能体委派时，你所在领域的应用界面将如何演变？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你能可靠地完成这些工作吗？ &lt;/strong&gt;你是否在痴迷地改进你的智能体框架？你是否有强大的反馈循环？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你如何销售这些工作？&lt;/strong&gt; 你能否根据价值和成果来定价和打包？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;扬鞭策马！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;是时候驾驭长周期智能体的指数级增长了。&lt;/p&gt;&lt;p&gt;今天，你的智能体大概可以可靠地工作约 30 分钟。但它们很快就能完成一天的工作量 &amp;mdash;&amp;mdash; 最终是一个世纪的工作量。&lt;/p&gt;&lt;p&gt;当你的计划以世纪为单位衡量时，你能实现什么？一个世纪，是 20 万项从未被交叉引用的临床试验。一个世纪，是所有客户支持工单，终于被挖掘出信号。一个世纪，是整部美国税法，被重构得条理清晰。&lt;/p&gt;&lt;p&gt;你路线图上那个雄心勃勃的版本，刚刚变成了现实可行的版本。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;原文链接：https://x.com/HungamaHeadline/status/2011533578279272652&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>VerseCrafter：给视频世界模型装上4D方向盘，精准运镜控物</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:35:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/45e44809-61bc-453c-9ad4-83cc931a3c9d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;视频世界模型领域又迎来了新的突破！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;复旦大学与腾讯 PCG ARC Lab 等机构的研究者们提出了 VerseCrafter&lt;/strong&gt;，这是一个通过显式 4D 几何控制（4D Geometric Control）实现的动态逼真视频世界模型。它不仅能像「导演」一样精准控制运镜，还能同时指挥场景中多个物体的 3D 运动轨迹，为视频生成引入了物理世界维度。&lt;/p&gt;&lt;p&gt;自 Sora 问世以来，视频世界模型（Video World Models）成为了 AI 领域最热门的研究方向之一。我们希望 AI 不仅能生成视频，更能理解和模拟真实的物理世界。然而，现有的视频模型往往面临一个核心困境：&lt;strong&gt;视频是在 2D 平面上播放的，但真实世界是 4D（3D 空间 + 时间）的。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现有的方法（如 Voyager、Yume 等）虽然引入了 3D 几何结构来辅助生成，但往往难以在一个统一的框架下同时实现&lt;strong&gt;精准的相机控制和多物体运动控制&lt;/strong&gt;。要么是控制了镜头但物体不动（静态场景），要么是控制了物体但镜头受限，或者依赖于刚性的 3D 边界框和人的参数化模型（如 SMPL），难以应对复杂的真实世界物体。&lt;/p&gt;&lt;p&gt;为了打破这一僵局，&lt;strong&gt;来自复旦大学、上海创智学院、香港大学和腾讯 PCG ARC Lab 的研究团队提出了 VerseCrafter&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528437" data-ratio="0.20833333333333334" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDBxfibqaW4QRcrzmqyicrFGUVdictaHqhFuV8PQErncOdqkofpWSNgYpLQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9696f006-6cfa-4f2a-8e6e-d4b33470329e/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址： https://arxiv.org/pdf/2601.05138&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页： https://sixiaozheng.github.io/VerseCrafter_page/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库： https://github.com/TencentARC/VerseCrafter&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/33bbe3ce-35f5-423a-bbc7-b843b57789cd/1768739502008.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;VerseCrafter 的核心理念在于：&lt;strong&gt;用一个统一的 4D 几何世界状态（4D Geometric World State）以此驱动视频生成&lt;/strong&gt;。 它利用静态背景点云和每个物体的 3D 高斯轨迹，实现了对相机和物体运动的解耦与协同控制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何构建 4D 可控的世界模型？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VerseCrafter 的魔法源于其独特的&lt;strong&gt;&amp;nbsp;4D 几何控制（4D Geometric Control） 表示和轻量级的 GeoAdapter 架构&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 统一的 4D 几何控制表示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的控制信号通常是 2D 的（如光流、轨迹点、掩码），缺乏 3D 空间的一致性。VerseCrafter 创新性地提出了一种基于 &lt;strong&gt;3D 高斯（3D Gaussians）&lt;/strong&gt; 的表示方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;：&amp;nbsp;使用静态背景点云（Background Point Cloud）来表示环境几何。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物体&lt;/strong&gt;： 使用&lt;strong&gt;每物体 3D 高斯轨迹（Per-object 3D Gaussian Trajectories）&lt;/strong&gt;来编码物体运动。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528441" data-ratio="0.3851851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDMw2FXF6ahH4JLRbA8H1jMQJjicdiatgFcGYVYuEic0ZE9VSJc2PPs9W9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0114b19f-02f3-4a64-9119-0ad6cc59bc51/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;VerseCrafter 的框架图。通过将 4D 几何控制渲染为多通道图，并通过 GeoAdapter 注入到冻结的 Wan2.1 主干网络中。&lt;/p&gt;&lt;p&gt;相比于刚性的 3D 边界框，3D 高斯轨迹提供了一种软性、灵活且类别无关的表示方式。它的均值定义了运动路径，协方差则捕捉了物体随时间变化的形状和方向。这意味着无论是汽车、行人还是动物，VerseCrafter 都能以概率分布的形式描述其在 3D 空间中的占据情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 冻结的 Wan2.1 主干 + GeoAdapter&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了保证视频生成的画质和真实感，VerseCrafter 并没有从头训练一个大模型，而是巧妙地利用了强大的开源视频生成模型 &lt;strong&gt;Wan2.1-T2V-14B&lt;/strong&gt; 作为冻结的视频先验（Frozen Video Prior）。&lt;/p&gt;&lt;p&gt;研究团队设计了一个轻量级的 GeoAdapter：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;首先将 4D 几何控制信息（背景 RGB / 深度、物体高斯轨迹 RGB / 深度、控制掩码）渲染为 2D 序列图；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;利用 GeoAdapter 对这些几何信息进行编码；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;将其作为残差注入到 Wan2.1 的特定 DiT 模块中。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这种设计既保留了 Wan2.1 强大的生成能力，又以极小的代价引入了精确的 4D 控制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据集：VerseControl4D&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练这样一个 4D 世界模型，最大的瓶颈在于数据 &amp;mdash;&amp;mdash; 我们去哪里找大量带有精确 4D 标注（相机参数 + 多物体 3D 轨迹）的真实世界视频？&lt;/p&gt;&lt;p&gt;为了解决这个问题，团队构建了 &lt;strong&gt;VerseControl4D 数据集&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528442" data-ratio="0.687962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDXD9e3OGCopuhHIxXOlKDKicdZCYvYfwq5MFM8FicXoDJxyaiaSudZ6cqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7ba2f96e-6d43-4e72-99ee-311beb2c2c38/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;VerseControl4D 数据集的自动化构建流程&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据源&lt;/strong&gt;：&amp;nbsp;基于 Sekai-Real-HQ 和 SpatialVID-HQ 等高质量视频数据集；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自动化标注引擎&lt;/strong&gt;：&amp;nbsp;结合了 Qwen2.5-VL-72B（生成描述）、Grounded-SAM2（物体分割）、MegaSaM（深度和相机位姿估计）等最先进的工具，自动从视频中提取 4D 几何信息；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;规模&lt;/strong&gt;： 包含&lt;strong&gt;&amp;nbsp;35,000 个&lt;/strong&gt;训练视频片段，涵盖了丰富的动态和静态场景。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一数据集的构建，填补了真实世界 4D 几何控制数据的空白，为模型的训练提供了坚实的基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：SOTA 级的控制力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验表明，VerseCrafter 在各项指标上均超越了现有的 SOTA 方法（如 Perception-as-Control、 Yume、 Uni3C 等）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 动态场景联合控制对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在同时控制相机运镜和物体运动的复杂场景下，VerseCrafter 展现出了惊人的稳定性。&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fbec2e85-1101-4739-a565-6ff283e07011/1768739596595.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;动态场景对比。第一行从左至右：相机轨迹、GT、Perception-as-Control、Yume，第二行从左到右：Uni3C（第 1，2 列）、VerseCrafter（第 3，4 列）。可以看到 VerseCrafter（右下）的物体运动和背景稳定性最好。&lt;/p&gt;&lt;p&gt;从对比视频中可以看出：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Perception-as-Control&amp;nbsp;&lt;/strong&gt;生成的帧质量较低，运镜不准。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Yume&lt;/strong&gt; 虽然能大致遵循文本描述的运动，但缺乏精确的相机控制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Uni3C&amp;nbsp;&lt;/strong&gt;仅限于单人体运动控制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VerseCrafter&amp;nbsp;&lt;/strong&gt;能够精确地让物体沿着预设的 3D 高斯轨迹移动，同时完美执行相机运镜，且背景保持几何一致。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 静态场景运镜对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;即使在没有移动物体的静态场景中，作为单纯的「场景漫游」工具，VerseCrafter 的表现也优于专门的 ViewCrafter 和 Voyager 等模型。&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5d59027c-2b04-43a9-a53a-90ceec1b1891/1768739618300.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;静态场景运镜对比。第一行从左至右：相机轨迹、GT、ViewCrafter，第二行从左到右：Voyager、FlashWorld、VerseCrafter。VerseCrafter 在大幅度运镜下依然保持了建筑结构的笔直和纹理的清晰。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 多视角一致性（Multi-Player View）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;得益于统一的 4D 世界坐标系，VerseCrafter 还支持多玩家视角（Multi-Player View）生成。对于同一个动态事件，可以从完全不同的两个视角分别生成视频，两者在时间、空间和物体动作上保持高度一致。&lt;a href="https://mp.weixin.qq.com/s/P2MBsslV2i1Q9v8N7zm_bQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3a6025d0-faf7-4462-ad22-1b0e924e58f0/1768739632674.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;两者在同一时间轴上展现了完全一致的世界动态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VerseCrafter 的出现，标志着视频生成向&lt;strong&gt;可控 4D 世界模拟&lt;/strong&gt;迈出了重要一步。通过将显式的 3D 几何先验（点云与高斯）与强大的 2D 视频生成模型（Wan2.1）相结合，它不仅解决了复杂场景下的控制难题，也为游戏制作、电影预演和具身智能模拟提供了新的可能性。&lt;/p&gt;&lt;p&gt;目前，项目代码与模型权重均已开源，感兴趣的读者可以前往项目主页体验。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AI 视频生成时代，留给人类的只有演技？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 17 Jan 2026 17:57:16 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-17-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-17-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜泽南、杨文&amp;nbsp;&lt;/p&gt;&lt;p&gt;总有人说直播网红是「换头怪」，全靠滤镜整容，现在 AI 给你直接换个人，你受得了吗？&lt;/p&gt;&lt;p&gt;最近，社交媒体上疯传的一些视频让无数人感到震惊。&lt;/p&gt;&lt;p&gt;有网友做出任意表情、动作，然后无缝替换到《怪奇物语》中的米莉・博比・布朗、芬恩・伍夫哈德等多位演员身上，实现零成本的「无限角色互换」。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a8c6444c-b8e8-4e1b-a52d-aaf905d100fd/1768643679897.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这已经不是普通的 3D 皮套了，很多视频生成 AI 已经实现了实时换脸的能力：只需要找到一张参考的照片，你就可以在视频中直接「扮演」这个人。&lt;/p&gt;&lt;p&gt;现在 AI 可以精准地捕捉像眨眼、张嘴、侧脸等微表情，效果和画面背景之间也没有任何的割裂感，几乎看不出破绽来。&lt;/p&gt;&lt;p&gt;有的人已经把这些技术整合成了 APP。比如这个叫 levelsio 的人就展示了一系列 AI 直播的效果，并表示，虚拟网红的时代已经来临。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2c53409c-a434-499e-8d4f-87483b7b3c2c/1768643691686.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;真实到有一点点可怕。&lt;/p&gt;&lt;p&gt;风险投资机构 a16z 合伙人 Justine Moore 直言：「我们对 AI 如何迅速改变生产流程完全没有准备好。一些最新的视频模型已经对好莱坞产生了直接而重大的影响，角色可以无限替换，成本却几乎可以忽略不计。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OgrOjtvzx4MJ36Q0iaiceFTX4Xflo8wEg3e9zK6VgIjR7JaY11xxhP8kw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3209647495361781" data-type="png" data-w="1078" data-width="1078" data-height="346" data-backw="578" data-backh="186" data-imgfileid="503528744" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/bb4a47e2-e8fe-42b0-a1b6-3c882c5cba60/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在 X 上，这类视频动辄就能获得超百万播放量，评论区也两极分化严重。有人惊讶技术进步的飞速，有人则担心深伪用于诈骗与破坏信任，「连人类身份都难以证明」，有人甚至提到以后或许需要「眼球扫描」来验证真实性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「好莱坞完了」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这波换脸技术的核心突破，主要来自快手推出的 Kling Motion Control，只需上传任意一段视频以及一张目标角色的照片，AI 即可生成一个「角色替换」视频。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26077537-1635-4077-bdbb-44e3289a26f2/1768643706281.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;国外网友已经玩疯了。&lt;/p&gt;&lt;p&gt;电影制作人 Arut 用这个工具复刻了 2023 年奥斯卡热门片《坠落的审判》（Anatomy of a Fall）里的那段标志性单镜头争吵场景。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8ae4f61e-4fc2-401c-b82e-a42df86b1682/1768643716316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这段 25 秒的视频，全靠 Kling 2.6 Motion Control Pro 实现，它能精准控制长达 30 秒的肢体动作和面部表情。这也意味着，以前需要专业团队、摄影棚、灯光道具才能完成的镜头，现在只要一部手机和一个 AI 工具就行。&lt;/p&gt;&lt;p&gt;看来时代真的变了。&lt;/p&gt;&lt;p&gt;AI 电影制作人 Uncanny Harry AI 的演示更夸张，他穿着睡衣，顶着乱糟糟的头发，在家里用 AI 让自己一人分饰两角：一个中年光头男人和一个红发女职员。&lt;/p&gt;&lt;p&gt;两个角色上演了一场气氛紧张的对话，唇部同步完美、微表情和肢体语言均高度一致。&lt;/p&gt;&lt;p&gt;而他本人既不是训练有素的专业演员，视频也未经过专业的音效处理。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8cf588a0-c733-43a4-a583-c0f00f685125/1768643727854.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;还有人用 AI 生成的一个 K-pop 偶像做鬼脸的视频，比如嘟嘴、吐舌、眨眼&amp;hellip;&amp;hellip; 每个动作表情都自然流畅。&lt;a href="https://mp.weixin.qq.com/s/_C2tm-6iUVOZWQuHFkZX3g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1d746823-bdca-4f52-93cd-0dd1daefe5fd/1768643738751.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;有人做了不完全的统计，现在包括 Kling 2.6、Deep-Live-Cam、DeepFaceLive、Swapface、SwapStream、VidMage 和 Video Face Swap AI 在内的一系列工具，都可以根据实时网络摄像头画面生成实时的 AI 换脸视频，或是基于静态的图片，以及人们的文字提示，按照需求生成从几十秒到几分钟的视频。&lt;/p&gt;&lt;p&gt;这些工具的价格也越来越亲民，每月费用在 10 美元到 40 美元之间。&lt;/p&gt;&lt;p&gt;这方面的技术在过去一年里取得了显著进步，唇形同步效果更好，眨眼和表情也更加自然。现在它足以以假乱真，骗过很多人。当然，不同的 AI 也各有自己擅长的方面，比如 Sora 2 能够更好地模拟物理效果，Kling 的运动比较真实等等。&lt;/p&gt;&lt;p&gt;或许过不了多久，建模质量就不再是你的必选项，火不火全都取决于整活了。&lt;/p&gt;&lt;p&gt;可以预见，随着 AI 视频生成内容的不断进步，很多前所未有的创意和想法将会变成现实。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Arutkaran_/status/2010705052374286587&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Uncanny_Harry/status/2008881579095961934?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/IamEmily2050/status/2002968479276937403?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/AIMevzulari/status/2012105893882536266?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>贴广告的ChatGPT，一夜之间让全球网友破了防</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 17 Jan 2026 13:32:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-17-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-17-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南、杨文&lt;/section&gt;&lt;p&gt;这一天终于还是来了。&lt;/p&gt;&lt;p&gt;周六凌晨，OpenAI 的一则公告引起轩然大波：他们计划在 ChatGPT 里加广告了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="684" data-backw="578" data-height="1394" data-imgfileid="503528701" data-ratio="1.1833333333333333" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OrYlwlbcKaQfWJiciaTuGl12ExfYj5UXWXtjTQWgNm842nXuBdQ8WNdmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1178" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/312ae896-b172-4160-ba9d-b04d0635b534/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对此，网友们感到很受伤。有人表示，现在大家用大模型的一个重要原因就是能够避免广告，更好地查询信息，现在 ChatGPT 又把广告加回来是几个意思？&lt;/p&gt;&lt;p&gt;也有人认为，加广告的这件事表明了 OpenAI 目前的营收压力很大。&lt;/p&gt;&lt;p&gt;华盛顿大学教授荣誉退休教授、知名 AI 学者 Pedro Domingos 吐槽道：OpenAI 终于实现了 AGI，不过此 AGI 非彼 AGI，而是 Ad-Generated Income.&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OiczQSsU2sd3CzyZ1myQP1cpOasScMjMuiaibwR2jQvuDwAn2jwuatFwqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.15221579961464354" data-type="png" data-w="1038" data-width="1038" data-height="158" data-backw="578" data-backh="88" data-imgfileid="503528702" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dcd0e81f-e197-4aa3-9097-8ea8a1262683/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;OpenAI 的公告指出，广告测试将在未来几周内率先在美国启动，能看到广告的用户包括免费版，还包括一种新的付费层级 &amp;mdash;&amp;mdash;ChatGPT Go 的用户。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ChatGPT「小会员」，每月 8 美元&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在广告出现之前，OpenAI 官方宣布 ChatGPT Go 已在全球上线，在所有支持 ChatGPT 的国家可用。&lt;/p&gt;&lt;p&gt;ChatGPT Go 是他们的低价订阅计划，每月 8 美元，提供比免费版多 10 倍的消息额度、文件上传和图像生成功能、更大的内存、更长的上下文窗口，以及可以无限使用 GPT 5.2 instant 模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OuzlMiatEXJZuz4PsXUF1xUfjNCPNMmdfAcD4icMkws5xaUrmwjplZcEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.575925925925926" data-type="png" data-w="1080" data-width="1199" data-height="690" data-backw="578" data-backh="333" data-imgfileid="503528704" data-aistatus="1" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/76016e3c-2ca1-4a7c-a191-85e04d140c4d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;需要注意到的是，Go 版用户仍然无法使用 GPT‑5.2 Thinking 模型。&lt;/p&gt;&lt;p&gt;另外，OpenAI 指出，除了免费版和 ChatGPT Go 以外，Plus、Pro、Business 和 Enterprise 版本的付费用户将不会看到广告。所有 ChatGPT 中的回复不会受到广告的影响。&lt;/p&gt;&lt;p&gt;看 OpenAI 的说法，ChatGPT 的广告和 Google 等搜索引擎上的很像。广告不会打断对话流，而是会出现在 AI 生成的回复的底部，并标注好「Sponsor」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OibX7IJmwXoU2g5o0lESibGhdtZ8oiaWs2ECJ70cWrBVzahiaOfqAlC9sGg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.562037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503528717" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3ad8598b-05b1-43ff-a5d3-4fbf5a33f85b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;OpenAI 承诺广告商无法影响 ChatGPT 生成的答案内容，此外，用户的具体对话内容不会被直接发送给广告商，只会用于匹配相关性。&lt;/p&gt;&lt;p&gt;虽然 AI 的回复内容里不会有广告内容，但 ChatGPT 显示的广告将根据你的对话上下文进行匹配，比如你在问食谱的时候会出现相关食材或配送服务的广告。&lt;/p&gt;&lt;p&gt;另外，在涉及健康、心理健康、政治等敏感话题的对话中，不会显示广告。&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;理想与现实的妥协&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 的这一决定，是在公司面临巨大的财务压力和商业化转型的背景做出的。&lt;/p&gt;&lt;p&gt;尽管 OpenAI 的估值即将达到 7500 亿美元，但考虑到其在算力和数据中心上的投入是天文数字（在 2025 年就有高达 1.4 万亿美元的基础设施建设承诺），去年奥特曼预计的 200 亿美元收入显然远远不够。&lt;/p&gt;&lt;p&gt;为了维持运营并继续扩展 AI 大模型能力，加广告可能是唯一的办法。&lt;/p&gt;&lt;p&gt;看起来很合理，但是在这件事情上，山姆・奥特曼仍然食言了。&lt;/p&gt;&lt;p&gt;作为一个致力于解决 AGI 大问题公司的舵手，奥特曼在不久之前还曾在多个场合公开表达过对于加广告的厌恶。在 2024 年与 Lex Fridman 的播客访谈时，他提到自己对广告有一种「精神上的厌恶（spiritual dislike）」。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OcM1nSCWJ7SUo79ria00eSj33VLNe7rV7gXQ7coRvXiblZiahbdKkvZbKw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.6276747503566333" data-type="gif" data-w="701" type="block" data-backw="578" data-backh="363" data-imgfileid="503528705" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/402f4bab-fcbe-4e6d-b474-271a87bd914c/640.gif" data-order="0" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;奥特曼解释说，这主要是针对当时互联网上那些「糟糕的交互界面（crappy interfaces）」，他认为广告往往会干扰用户获取信息，破坏产品的纯粹性。&lt;/p&gt;&lt;p&gt;他当时强调了一个核心逻辑：「我喜欢用户付费使用 ChatGPT，因为这样他们就知道答案没有被广告商影响。」他担心一旦引入广告，AI 的回答可能会为了讨好广告主而出现偏向性。&lt;/p&gt;&lt;p&gt;这也是所有普通用户所担心的问题。在今天 OpenAI 的声明之后，不知大家该作何感想。&lt;/p&gt;&lt;p&gt;在奥特曼介绍 ChatGPT 广告的推文下，有网友还扒出了 2024 年 5 月奥特曼在哈佛大学演讲里的内容，当时他说：广告对我们来说是一种商业模式的最后选择。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OKbueXDpgiaKia086Ghr7a8hEVjkxVUb8ibtib2PHmJayiataxMy2BLQYvBw/640?wx_fmt=jpeg#imgIndex=6" data-ratio="0.13953488372093023" data-s="300,640" data-type="png" data-w="602" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OB9Qjd2kVkCJLHIPnjds8MMBKw0Tj9APgj0vjf6WKV2aH3XgNFlr1nw/640?wx_fmt=png&amp;from=appmsg" data-cropx2="602" data-cropy1="21.423487544483987" data-cropy2="104.97508896797153" data-backw="578" data-backh="101" data-imgfileid="503528718" data-aistatus="1" data-original-style="width:562px;height:78px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/daa182bd-d474-4da1-a385-02377a3a5d02/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;马斯克和奥特曼又在 X 上「升堂」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除了 ChatGPT 要加广告这事，今天最热的新闻之一还得是马斯克和 OpenAI 旷日持久的官司。&lt;/p&gt;&lt;p&gt;近日，加州北部地区法院解封逾百份文件，包括 OpenAI 总裁 Greg Brockman 2017 年的私人日记摘录。&lt;/p&gt;&lt;p&gt;这些记录显示，Brockman 曾在日记中写道：「这是我们摆脱 Elon 的唯一机会&amp;hellip;&amp;hellip; 从财务角度，什么才能让我达到 10 亿美元？」并讨论转向营利结构，以避免马斯克的控制「破坏经济利益」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6O376DfCdL4zj8Y1SPwbMslSvTz5N4HZSIQAVprdR1lIictiauMvrE4ReA/640?wx_fmt=jpeg#imgIndex=7" data-ratio="0.8916666666666667" data-type="png" data-w="1080" data-width="1200" data-height="1200" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6Oz8kqMeCZpJMdKsUpzibpbbzkZhqyhCWdqb0IDencXsZdxUpEYBnhOlw/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1180.782918149466" data-cropy2="1052.6690391459074" data-backw="578" data-backh="578" data-imgfileid="503528706" data-aistatus="1" data-original-style="width:553px;height:493px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b013d60c-8440-4a01-8cbb-d1975387a994/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Brockman 还总结道：「在马斯克不知情或不同意的情况下，把非营利组织从他手里偷走、强行改成营利性公司，这种做法是错误的，那样做会显得相当道德败坏，而且他真的不是傻子。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OJ8eun9gAKHRJebFLczcVKTjgVrLvq5wiaMdzTOyw1t4eBg6vf3picj9Q/640?wx_fmt=jpeg#imgIndex=8" data-ratio="1.0601851851851851" data-type="png" data-w="1080" data-width="1454" data-height="2078" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OOGDiaoJ6YeOSibLSw7TzWVNHia1r0QO6dCwjfNLFSwibZYkhtFkfshSeAQ/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1420.3665480427046" data-cropy2="1505.743772241993" data-backw="578" data-backh="826" data-imgfileid="503528708" data-aistatus="1" data-original-style="width:549px;height:582px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/4d55166e-d9d0-4061-97b7-481459363056/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;马斯克在 X 上直接评论：「他们偷了一个慈善组织，就这么简单。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OPb7l9griaYwFZ9vJzZSNbFcNyfqQibPLr1Yv0NREr8JR8sN5teTtREUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.29887218045112784" data-type="png" data-w="1064" data-width="1064" data-height="318" data-backw="578" data-backh="173" data-imgfileid="503528710" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/886c4eb9-6eb0-43c2-aec8-6687a1b74af1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;奥特曼回应称，马斯克在断章取义地抹黑 Greg Brockman，实际情况的完整版是马斯克自己当时大力推动公司改成新的结构，Greg 和 Ilya 花了大量精力去研究、讨论能不能接受或满足 Elon 提出的那些苛刻条件。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6Otu5u9zUKKD5evYfFojE0MlzZicaA1HDYa0PSYc3XaWZXUfxztDg5qhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.7262357414448669" data-type="png" data-w="1052" data-width="1052" data-height="764" data-backw="578" data-backh="420" data-imgfileid="503528711" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/f312ffd2-c647-4db0-91c7-176aa9f46818/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;「我之前记得很多这些细节，但这个部分我完全忘了：『Elon 说，他需要攒到 800 亿美元来建一个能在火星上自给自足的城市，他认为自己需要、也配得上多数股权。他还说必须有完全的控制权，因为以前没控制权吃过大亏。在聊到公司继任、接班问题时，他突然提到要让他的孩子们来掌控 AGI，这让我们挺震惊的。』我觉得大家直接说清楚自己想要什么挺好的，这样才能真正解决问题或看清没法解决。但 Elon 当时提出这些要求，正是 Greg Brockman 纠结、思考公司未来方向的重要背景。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OaaLwMPaurZ4K65e13rkz8x1G2gYIBWDsBUAHj9JRDWgYgoBe263hwQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4261682242990654" data-type="png" data-w="1070" data-width="1070" data-height="456" data-backw="578" data-backh="246" data-imgfileid="503528712" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/9629e6b6-11bf-4e10-bbca-4a69b5c88cf2/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;关于双方的纠葛，MenloVentures 合伙人 Deedy 的评论一针见血：说到底，这一切都和钱有关。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicOgd00I0lGNmnxC0vibsC6OdqQhXiatR4O71psicbIThz6rf9CEgsFJBohAFNdIMPE4lN7NCbXpZ3Vw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3308270676691729" data-type="png" data-w="1064" data-width="1064" data-height="352" data-backw="578" data-backh="191" data-imgfileid="503528713" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/cd7ad919-9043-4081-925e-0a497602d5f6/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;由于解封出的文件存在「足以让陪审团相信可能存在违约行为」的嫌疑，美国地区法官 Yvonne Gonzalez Rogers 已于 2026 年 1 月正式裁定拒绝 OpenAI 的撤诉请求。该案件将于 2026 年 4 月 27 日进入陪审团审判。&lt;/p&gt;&lt;p&gt;最后，我们再回到ChatGPT加广告这事。你认为，OpenAI 在未来，终究也会走回科技巨头的「老路」吗？&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考信息：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/OpenAI/status/2012223373489614951?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/news/863466/openai-chatgpt-go-global-release&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/deedydas/status/2012074556106924233?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/XFreeze/status/2012209234134409475?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/elonmusk/status/2012173548039622685?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/sama/status/2012272451363709377&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>开源8300小时标注数据，新一代实时通用游戏AI Pixel2Play发布</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 17 Jan 2026 13:29:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-17-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-17-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3a2d7c6d-3d8e-42d8-a13f-278ea4507571/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着人工智能在代码以及图片生成方面日益成熟，越来越多的研究人员也开始关注 AI 模型在游戏领域中的表现。实际上，游戏在 AI 的发展早期就已经是一个重要的研究方向，许多前期研究聚焦在 Atari，星际争霸，Dota 等热门游戏，并成功训练出了表现超越人类玩家的专用模型。然而，这类模型通常只能在单一游戏环境中运行，缺乏跨游戏的泛化能力。&lt;/p&gt;&lt;p&gt;另一方面，虽然 ChatGPT 和 Gemini 这类模型通用模型在众多任务上已经展现出了卓越的能力，它们却难以在游戏环境中取得好的表现，即便是很简单的射击游戏。&lt;/p&gt;&lt;p&gt;为了解决这一问题，来自 Player2 的研究员们提出了 &lt;strong&gt;Pixel2Play（P2P）&lt;/strong&gt;模型，该模型以游戏画面和文本指令作为输入，直接输出对应的键盘与鼠标操作信号。在消费级显卡 RTX 5090 上，P2P 可以实现超过 20Hz 的端到端推理速度，从而能够真正像人类一样和游戏进行实时交互。P2P 作为&lt;strong&gt;通用游戏基座模型&lt;/strong&gt;，在超过 &lt;strong&gt;40&lt;/strong&gt; 款游戏、总计 &lt;strong&gt;8300 +&lt;/strong&gt; 小时的游戏数据上进行了训练，并能够以零样本（zero-shot）的方式直接玩 Roblox 和 Steam 平台上的多款游戏。&lt;/p&gt;&lt;p&gt;为了促进领域的发展，Open-P2P 团队在没有使用许可限制的情况下&lt;strong&gt;开源了全部的训练与推理代码，并公开了所有的训练数据集&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;接下来请看 P2P 模型的人机对战：(在 Roblox Rivals 游戏中)&lt;a href="https://mp.weixin.qq.com/s/QNPkAtbvvTMV-gFtZsdGcg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/29f5b78e-5937-4489-8750-9110907af4db/1768627654314.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文题目：Scaling Behavior Cloning Improves Causal Reasoning: An Open Model for Real-Time Video Game Playing&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://elefant-ai.github.io/open-p2p/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文代码：https://github.com/elefant-ai/open-p2p&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文数据：https://huggingface.co/datasets/elefantai/p2p-full-data&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;训练数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练游戏 AI 模型需要高质量的&lt;strong&gt;游戏画面、文本指令&lt;/strong&gt;以及对应的&lt;strong&gt;操作数据&lt;/strong&gt;。与海量公开的图文数据不同，这类&lt;strong&gt;&amp;nbsp;&amp;ldquo;画面 - 操作&amp;rdquo; 数据&lt;/strong&gt;在互联网上很少见。尽管已有通过游戏视频反推动作的开源数据集，但开源的大规模高质量人工标注操作数据却还是空缺。为了弥补这一空缺，Open-P2P 项目开源了全部的训练数据集。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiciax1NZVI7OqKibNqY9UaVwBlDiciciaQVZzFg5E1dyEiad3K1upN64oeGoEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.34965034965034963" data-s="300,640" data-type="png" data-w="858" type="block" data-imgfileid="503528276" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/06e5a735-43bd-402d-9c04-c98d5aa5e0ac/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如图所示，P2P 所用的训练数据同时包括游戏图像画面与对应的文本指令，并提供了精确的键盘鼠标操作标注&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型设计&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicJRP4akVFNVGKaJOM3xQ8ujc4Tu9MWbbkiarFmYluMJXM56ImGaAH9Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.34558823529411764" data-s="300,640" data-type="png" data-w="680" type="block" data-imgfileid="503528277" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/25a75100-b692-47dd-a6d5-c0368586e3e0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为了保证模型可以做到快速的推理速度&lt;/strong&gt;，P2P 选择了轻量级模型框架并从零开始训练。&lt;/p&gt;&lt;p&gt;模型主体由一个解码器 Transformer 构成（左图所示），并额外接入一个轻量化的 action-decoder 来生成最终的操作信号。该结构使得模型在推理时只需要对主体模型进行一次前向计算，即可生成 action-decoder 所需的表征信号，从而使得整体推理速度提升 5 倍。&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了实现跨游戏通用性，P2P 采用了&lt;strong&gt;自回归的离散 token&amp;nbsp;&lt;/strong&gt;序列作为操作输出空间。具体来说，每个操作由 8 个 token 表示：4 个对应键盘按键，2 个对应鼠标在水平与垂直方向上的离散位移，最后两个对应鼠标按键。这样的设计可以涵盖绝大部分游戏的操作需求。&lt;/p&gt;&lt;p&gt;在输入方面，除了当前帧图像与文本指令 token 外，P2P 还会输入&lt;strong&gt;真实操作 token&lt;/strong&gt;，这使得模型能够根据历史操作来做决策，从而更贴近人类玩家的操作习惯。为了保证模型的因果关系，训练时使用了&lt;strong&gt;特殊的掩码机制&lt;/strong&gt;（右图所示），以确保模型在预测时仅能看见历史真实操作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;P2P 共训练了四个不同规模的模型，参数量分别为 150M，300M，600M 和 1.2B。在实测中，150M 模型可以达到 80Hz 的端到端推理速度，而最大的 1.2B 模型也能达到 40Hz，完全满足与游戏环境实时交互的需求。&lt;/p&gt;&lt;p&gt;模型评估的标准主要是人工评估，评估环境选取自四款游戏&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Steam 平台上的 Quake，DOOM&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Roblox 平台上的 Hypershot，Be a Shark&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;模型行为评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 DOOM 和 Quake 中，每个官卡设置了四个不同的起始位置（Roblox 游戏因联网机制无法固定起点），模型需从指定起点操作至下一个目标点。&lt;/p&gt;&lt;p&gt;人工评估采取了两两比较的方式：将 1.2B 模型生成的游戏录像与另外三个相对较小的模型录像进行人工比对。结果显示，1.2B 模型分别以 80%，83% 与 75% 的偏好度优于 150M，300M 和 600M 模型。下方视频展示了对比片段：&lt;a href="https://mp.weixin.qq.com/s/QNPkAtbvvTMV-gFtZsdGcg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c2752123-ee3b-45cf-936d-2ef2f659271d/1768627724774.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令遵循评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究还测试了 P2P 模型理解并执行文本指令的能力。评估环境选择了 Quake 的一个迷宫关卡，该关卡要求玩家依次点亮三个红色按钮才能开门。&lt;/p&gt;&lt;p&gt;这个任务对于仅凭借视觉信息的模型来说很有挑战，因为 &amp;ldquo;按下按钮&amp;rdquo; 和 &amp;ldquo;不按按钮&amp;rdquo; 在行动轨迹上几乎没有区别。所以，未接受指令的模型通过率只有 20%。而当模型接收到 &amp;ldquo;按下红色按钮&amp;rdquo; 的文本指令后，模型的通过率可大幅提高到 80%，显示出了优秀的文本指令理解和执行能力。&lt;/p&gt;&lt;p&gt;下方视频对比了 1.2B 模型在有指令（左）和无指令（右）的情况下各运行 5 次的表现。&lt;a href="https://mp.weixin.qq.com/s/QNPkAtbvvTMV-gFtZsdGcg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4fd6570a-2385-49ab-92fc-cf9acfbfd5d5/1768627736180.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;因果混淆分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因果混淆是行为克隆中常见的难题，在高频的交互环境中尤其突出。例如，一个简单的策略就是直接复制上一帧的操作，这种模型在训练时，但在真实环境测试时表现就会很差。&lt;/p&gt;&lt;p&gt;论文对此进行了系统的研究，发现扩大模型的规模与增加训练模型的数据量能够有效提升模型对因果关系的理解能力，使其不再依赖着泪虚假关联，从而学到更好的操作策略。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicCeJY6Ce0vVibMyVNGfNYoVcs9iaKpW9nvTIZyFA2c2hNJ574jRicoM0LQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6" data-s="300,640" data-type="png" data-w="1000" type="block" data-imgfileid="503528278" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/e5e42a92-3fbe-4bcd-bd73-8b7bfc333f99/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如图所示，随着训练数据增多与模型参数量增加，P2P 模型在因果推断评估中的表现呈上升趋势。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于作者&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文第一作者岳煜光现任初创公司 Player2 研究员，负责游戏模型的开发和研究。在加入 Player2 之前，他曾先后在 Amazon 和 Twitter 担任研究人员，致力于语言模型与推荐系统的相关研究。&lt;/p&gt;&lt;p&gt;岳煜光博士毕业于德州大学奥斯汀分校（UT-Austin），师从周明远教授，研究方向是强化学习以及贝叶斯统计；此前他于加州大学洛杉矶分校（UCLA）取得硕士学位，本科毕业于复旦大学数学系。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicnaqfc89Gd0h33fAiaFfj4A8Ft4mlYDKOmIeibu1hKJ5guRfRPOQ3cDhg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="1.3324074074074075" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528279" data-aistatus="1" data-original-style="width:412px;height:549px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c625d8cd-0673-42e7-ba08-074b29b1c907/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
