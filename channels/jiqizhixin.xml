<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>揭秘！RLVR/GRPO中那些长期被忽略的关键缺陷</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 17:37:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/4188c4a4-eb59-46a0-9b27-17066f141a3a/640.png" alt="图片" data-report-img-idx="51" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近年来，大模型在数学推理、代码生成等任务上的突破，背后一个关键技术是 &lt;strong&gt;RLVR（Reinforcement Learning with Verifiable Rewards）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;简单来说，RLVR 不是让模型「听人打分」，而是让模型自己尝试多种解法，然后用可验证的规则（如答案是否正确）来反向改进自己。这使得模型能够通过反复试错不断变强，被广泛应用于当前最先进的推理模型中。&lt;/p&gt;&lt;p&gt;在实际训练中，为了让学习过程更稳定、避免引入额外的价值网络，许多 RLVR 方法（如 GRPO）都会对同一个问题生成一组回答，并在组内进行相对比较。模型不是直接看「这个回答好不好」，而是看「它在这一组回答中相对好不好」，这就是所谓的&lt;strong&gt;组内优势估计（group-relative advantage）&lt;/strong&gt;，也是目前几乎所有 group-based 强化学习方法的核心设计。优势估计并不仅仅是一个「评估指标」，而是直接决定策略梯度更新方向的核心信号。&lt;/p&gt;&lt;p&gt;然而，一个长期被忽视的关键问题在于：&lt;strong&gt;组内优势估计并不像人们通常直觉认为的那样是「近似无偏」的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;相反，&lt;strong&gt;北航、北大、UCB、美团&lt;/strong&gt;最新的工作揭示了，这种组内优势估计在统计意义上存在&lt;strong&gt;明确且系统性的方向性偏差：困难题的优势会被持续低估，而简单题的优势则被不断高估&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tSAghRXo2ft0za8WWMtAKXAkU3RSCBNcvZnMgTJsJvLhNbcmqMTjdqw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.26944444444444443" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530526" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1006ee0b-42f6-4e93-a166-655007999a73/640.png" alt="图片" data-report-img-idx="50" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/pdf/2601.08521&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一偏差带来的后果往往十分隐蔽，却极具破坏性。训练过程中，曲线表面上看似「稳定收敛」，但模型实际上正在&lt;strong&gt;逐渐回避困难问题、转而偏好简单样本&lt;/strong&gt;。随着训练的推进，探索与利用之间的平衡被悄然打破，模型的泛化能力与长期训练稳定性也随之下降。&lt;/p&gt;&lt;p&gt;更关键的是，这并非一个可以通过简单调整超参数来缓解的问题，而是组内优势估计这一设计在统计结构层面本身就存在的内在缺陷。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;接下来，我们先引入若干必要的定义，以便于清晰表述后续的核心发现。我们首先给出最常用的组内相对优势估计的数学定义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;组内相对优势估计（Group-relative Advantage） ：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在一个训练回合&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t33tyWOicD1DpBrl49SZfRZzftqY7ud57PvNic5BiaG6qQBRhamiaMvuZgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.391304347826087" data-s="300,640" data-type="png" data-w="46" type="block" data-imgfileid="503530528" data-aistatus="1" data-original-style="width: 20px;height: 28px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9e49e5a4-62e8-4c14-9bc6-2a4d18cef471/640.png" alt="图片" data-report-img-idx="48" data-fail="0" class="fr-fic fr-dii" style="width: 2.86%;"&gt;，对于一个给定的提示（prompt）&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t5jGUCqO6icnOgiciciaWv95uTP3VYcLictjicyS4mwv7QzKxu39Igrx1xLWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8857142857142857" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530529" data-aistatus="1" data-original-style="width: 31px;height: 27px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/208c8848-2780-4315-9657-46f0a7cf5266/640.png" alt="图片" data-report-img-idx="47" data-fail="0" class="fr-fic fr-dii" style="width: 3.7%;"&gt;，算法从当前策略&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCTUr8rlgotGSEibakfpd9YYUtD6Fka1vxPxZ4HkicbzAsx9nW9rRgCPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0277777777777777" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530530" data-aistatus="1" data-original-style="width: 30px;height: 31px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/fed17959-76e3-4c81-bc8e-703ba39ca42a/640.png" alt="图片" data-report-img-idx="45" data-fail="0" class="fr-fic fr-dii" style="width: 3.7%;"&gt; 中独立采样 G 个响应，并获得对应的 G 个奖励&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tvX3PKlNMvjBVwU8ZxOX4A5D9Vw9ObjgV02J01gzk1d1FnSmaEFk6bA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.3181818181818181" data-s="300,640" data-type="png" data-w="44" type="block" data-imgfileid="503530531" data-aistatus="1" data-original-style="width: 20px;height: 26px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3b1b3f64-fc1e-45c9-94b2-8b7ce3b054e4/640.png" alt="图片" data-report-img-idx="49" data-fail="0" class="fr-fic fr-dii" style="width: 2.86%;"&gt;。随后，将组内的平均奖励 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tSyJYC6VxbqO1AjGdO1cTOqUDcCBLwpbwc0jlXXj1HjT0VTIvGP4ic5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.394736842105263" data-s="300,640" data-type="png" data-w="76" type="block" data-imgfileid="503530532" data-aistatus="1" data-original-style="width: 20px;height: 28px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/f2bb8e89-2bc4-40f9-b293-d7ffa7863860/640.png" alt="图片" data-report-img-idx="46" data-fail="0" class="fr-fic fr-dii" style="width: 2.64%;"&gt;作为 baseline ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tZrs8QYkd2ZBeLxoWBaTjc8y7RDQpXsxG9UPt8g2IDOMjAf5RfUk9Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.47435897435897434" data-s="300,640" data-type="png" data-w="312" type="block" data-imgfileid="503530533" data-aistatus="1" data-original-style="width: 162px;height: 77px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/27915dd6-2f31-4352-9b9c-20db4378d76b/640.png" alt="图片" data-report-img-idx="44" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;并据此计算每个响应的组内相对优势估计&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tvMsm32PRdh2apHbdhuQWqgzMahf7AQSAG0zjfW2X3MZkcqXxLDzWUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.0476190476190477" data-s="300,640" data-type="png" data-w="84" type="block" data-imgfileid="503530534" data-aistatus="1" data-original-style="width: 27px;height: 28px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/54461544-32bf-4d62-b408-f0030fa70163/640.png" alt="图片" data-report-img-idx="42" data-fail="0" class="fr-fic fr-dii" style="width: 4.76%;"&gt;：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tPnMop0LFaZPibSONiarpLKV8bmBibh3eUNruzCTtslaib9WaB8yv2onETQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.37373737373737376" data-s="300,640" data-type="png" data-w="396" type="block" data-imgfileid="503530535" data-aistatus="1" data-original-style="width: 161px;height: 60px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/00995323-990e-4915-82dd-717197c3b1c8/640.png" alt="图片" data-report-img-idx="43" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;为便于阐述理论结论，下文中我们忽略标准化项。为了分析组内优势估计的统计性质，我们需要引入策略在给定提示下的真实期望表现和优势，并将其作为后续讨论的参照基准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;期望奖励：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 &lt;strong&gt;RLVR &lt;/strong&gt;设定下，考虑一个给定的提示&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5358fb56-d924-42b8-8635-2a0a41c36974/640.png" alt="图片" data-report-img-idx="39" data-fail="0" class="fr-fic fr-dii" style="width: 3.81%;"&gt;, 在 0&amp;ndash;1 奖励假设下，我们将策略 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCTUr8rlgotGSEibakfpd9YYUtD6Fka1vxPxZ4HkicbzAsx9nW9rRgCPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0277777777777777" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530530" data-aistatus="1" data-original-style="width: 30px;height: 31px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/b8b69657-0341-4887-84cf-2a707e6ab668/640.png" alt="图片" data-report-img-idx="41" data-fail="0" class="fr-fic fr-dii" style="width: 4.55%;"&gt;在该提示上&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/7d90ad0a-74be-470c-b19b-3ffe590164cd/640.png" alt="图片" data-report-img-idx="40" data-fail="0" class="fr-fic fr-dii" style="width: 4.44%;"&gt;的期望奖励定义为&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tAcuhBMGVzxnBaeibibvAvvQhpegY9cjceUIicfWSoX54knV9n6DibibQrEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.10648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530537" data-aistatus="1" data-original-style="width: 365px;height: 39px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/c90aa69e-1b7e-419d-9903-77edf88f1994/640.png" alt="图片" data-report-img-idx="38" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;由此构造的组内平均奖励&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tSyJYC6VxbqO1AjGdO1cTOqUDcCBLwpbwc0jlXXj1HjT0VTIvGP4ic5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.394736842105263" data-s="300,640" data-type="png" data-w="76" type="block" data-imgfileid="503530532" data-aistatus="1" data-original-style="width: 20px;height: 28px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/85efd063-4b32-4b8a-bd7b-b3860b318dae/640.png" alt="图片" data-report-img-idx="36" data-fail="0" class="fr-fic fr-dii" style="width: 3.07%;"&gt;，可被视为&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tLHvlZ0qykWSriaVtQeyq9dj3MTcAx7PsS7yrsLV8goG6J760IGW332A/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.2857142857142858" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530538" data-aistatus="1" data-original-style="width: 20px;height: 26px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/5265935a-8bfa-4aaf-960b-0bc27575dcc8/640.png" alt="图片" data-report-img-idx="37" data-fail="0" class="fr-fic fr-dii" style="width: 3.38%;"&gt;的一个有限样本经验估计。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;期望优势：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于此，对于每一个响应&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tQhV5TnHXN4pGUBOyW6rkM0EH8ibMBoQE6sPOMmjM8LqhhAt1PIxMd1w/640?wx_fmt=jpeg#imgIndex=16" data-ratio="0.8064516129032258" data-s="300,640" data-type="png" data-w="93" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t0Iu9SJ6e0Q8XktyDvXJwKT4BkXxI7tr8wP6LTrmyrc2qAeEBe1hV6w/0?wx_fmt=png&amp;from=appmsg" data-cropx1="10" data-cropx2="104" data-cropy1="3" data-cropy2="78" data-imgfileid="503530539" data-aistatus="1" data-original-style="width: 34px;height: 27px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/2b5e37ad-9f02-4486-8c03-319839ecfd15/640.png" alt="图片" data-report-img-idx="34" data-fail="0" class="fr-fic fr-dii" style="width: 4.97%;"&gt;和其奖励&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t6NCv3NLXiafeF4S5kXnibTc8YvpSzf4DzVgUGSyC3CFTD9QbrDotAdbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6875" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530541" data-aistatus="1" data-original-style="width: 36px;height: 25px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/3c305a8f-13d3-4929-818f-253e660041a6/640.png" alt="图片" data-report-img-idx="35" data-fail="0" class="fr-fic fr-dii" style="width: 5.82%;"&gt;，其&lt;strong&gt;真实（期望）优势&lt;/strong&gt;定义为&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tNcSbKYCjY39N43Ws7W0Q1ewpgoSJlI8p3lNZ53AujIQqDl2EcJicCgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.3090909090909091" data-s="300,640" data-type="png" data-w="550" type="block" data-imgfileid="503530542" data-aistatus="1" data-original-style="width: 185px;height: 57px;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/351a9878-9cb1-418d-b382-e64e523f9d10/640.png" alt="图片" data-report-img-idx="30" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;在 RLVR 中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiabXwGOviau01XNEzfPgEJdtGzJQYTqh26euRhOtgXPupHSPzaLXPzNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.8292682926829268" data-s="300,640" data-type="png" data-w="82" type="block" data-imgfileid="503530543" data-aistatus="1" data-original-style="width: 31px;height: 26px;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/884757d8-bd32-403c-bee4-150bcda4f1e1/640.png" alt="图片" data-report-img-idx="31" data-fail="0" class="fr-fic fr-dii" style="width: 4.87%;"&gt;表示响应&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tQhV5TnHXN4pGUBOyW6rkM0EH8ibMBoQE6sPOMmjM8LqhhAt1PIxMd1w/640?wx_fmt=jpeg#imgIndex=20" data-ratio="0.8064516129032258" data-s="300,640" data-type="png" data-w="93" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t0Iu9SJ6e0Q8XktyDvXJwKT4BkXxI7tr8wP6LTrmyrc2qAeEBe1hV6w/0?wx_fmt=png&amp;from=appmsg" data-cropx1="10" data-cropx2="104" data-cropy1="3" data-cropy2="78" data-imgfileid="503530539" data-aistatus="1" data-original-style="width: 34px;height: 27px;" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/5149b21b-25b5-482b-8ca5-7a03181258af/640.png" alt="图片" data-report-img-idx="32" data-fail="0" class="fr-fic fr-dii" style="width: 4.97%;"&gt;在真实期望意义下的优势，而&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmoPK1ictgFBKFNV9U7qmKBwqWibrj7KdJKavrvdBoU3y9O9jePUkFOvw/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.9166666666666666" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530544" data-aistatus="1" data-original-style="width: 28px;height: 26px;" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/f310dd24-9978-4c58-80af-55a2d87654f8/640.png" alt="图片" data-report-img-idx="33" data-fail="0" class="fr-fic fr-dii" style="width: 4.76%;"&gt;则是通过有限组内采样得到的优势经验估计量。&lt;/p&gt;&lt;p&gt;为了刻画不同提示在训练中所处的难易程度，并分析偏差在不同难度区域的行为差异，我们引入如下基于期望奖励的题目难度定义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;题目难度：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这里，我们首先给出题目难度定义，即给一个&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/ea2d6764-4953-4a49-8325-c92bef7a0319/640.png" alt="图片" data-report-img-idx="27" data-fail="0" class="fr-fic fr-dii" style="width: 3.91%;"&gt;, 如果&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiauznOHt9JiaCjeg6Vu7grWpcghb4NZXZath4GeibZ7fAbnpxsGM0AcIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="1.2758620689655173" data-s="300,640" data-type="png" data-w="58" type="block" data-imgfileid="503530545" data-aistatus="1" data-original-style="width: 23px;height: 29px;" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/42856b64-9759-4c92-b5c8-489f0ee2cd46/640.png" alt="图片" data-report-img-idx="29" data-fail="0" class="fr-fic fr-dii" style="width: 3.81%;"&gt;小于 0.5，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;我们认为他是难题。相反，如果&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiauznOHt9JiaCjeg6Vu7grWpcghb4NZXZath4GeibZ7fAbnpxsGM0AcIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="1.2758620689655173" data-s="300,640" data-type="png" data-w="58" type="block" data-imgfileid="503530545" data-aistatus="1" data-original-style="width: 23px;height: 29px;" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/f41fafa5-c816-45a3-896e-1c665f05d069/640.png" alt="图片" data-report-img-idx="28" data-fail="0" class="fr-fic fr-dii" style="width: 3.91%;"&gt;&amp;nbsp;大于 0.5，&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;我们认为它是一道简单题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;最后，在基于组的策略优化方法中，并非所有采样组都会对参数更新产生有效贡献。为聚焦于真正驱动学习的情形，我们需要显式排除那些导致梯度消失的退化情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;非退化梯度事件：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;R 表示奖励总和:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0trjC74B7iaibp0Iwb6jSgibADYfWOtQNf8wGuqwk9XpUMeMBTGgZDsdamg/640?wx_fmt=png&amp;from=appmsg#imgIndex=25" data-ratio="0.31636363636363635" data-s="300,640" data-type="png" data-w="550" type="block" data-imgfileid="503530546" data-aistatus="1" data-original-style="width: 204px;height: 65px;" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/3fb86117-cd1e-4582-8dc6-c4e088bcfd8a/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;则组内优势估计也可以表示为&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t2Cah3ibCgw8R0oIOeFADTSCd4xHIsjQ1mmrSEVrH3WqP90AicIdlmqJQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.336283185840708" data-s="300,640" data-type="png" data-w="226" type="block" data-imgfileid="503530547" data-aistatus="1" data-original-style="width: 85px;height: 29px;" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/d2e59b0e-1b0e-4565-a61e-e329fdee4bdc/640.png" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dii" style="width: 12.59%;"&gt;。在基于组的策略优化方法中，当某一提示&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=27" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="29" src="https://image.jiqizhixin.com/uploads/editor/d44f6b27-c86a-416e-9d13-d7d74c1fd755/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dii" style="width: 4.23%;"&gt;的 G 个采样响应&lt;strong&gt;全部错误（R=0）或全部正确（R=G）&lt;/strong&gt;时，组内相对优势满足:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tvb7Lh5LIFaNAwzzmZ7WSGaU6z6EObcnnPMB6ntpQoSn3YqzNq7V2mA/640?wx_fmt=png&amp;from=appmsg#imgIndex=28" data-ratio="0.21777777777777776" data-s="300,640" data-type="png" data-w="450" type="block" data-imgfileid="503530548" data-aistatus="1" data-original-style="width: 164px;height: 36px;" data-index="30" src="https://image.jiqizhixin.com/uploads/editor/3d55a307-85e6-4567-bf8e-ad14c068810f/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;从而导致梯度消失，参数不发生更新。实践中，这类&lt;strong&gt;退化组&lt;/strong&gt;不提供有效学习信号，通常被 GRPO 及其变体显式或隐式地忽略。因此，我们将分析聚焦于&lt;strong&gt;实际驱动学习的有效更新区间&lt;/strong&gt;，即至少存在一个非零优势的情形。形式化地，定义&lt;strong&gt;非退化事件&lt;/strong&gt;:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tXfPc3OhgJmjOQaAghZ6LwOnsUEPVzaEI3BMha6bgscEF8KMqgcxQnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=29" data-ratio="0.1891891891891892" data-s="300,640" data-type="png" data-w="518" type="block" data-imgfileid="503530550" data-aistatus="1" data-original-style="width: 235px;height: 44px;" data-index="31" src="https://image.jiqizhixin.com/uploads/editor/ea57387a-f86f-49ad-9de7-85797e61536f/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;对 S 进行条件化并不会改变优化目标或训练轨迹，而仅刻画那些真正参与参数更新的样本子集，使我们能够精确分析组相对优势估计中的系统性偏差。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心发现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重要发现 1：&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0twmKtwDmDpdCXia3yR2Nb9Nvm0FcalePu9TcicXQBlKiaIv0tkMfwuPiaRg/640?wx_fmt=png&amp;from=appmsg#imgIndex=30" data-ratio="0.7022900763358778" data-s="300,640" data-type="png" data-w="786" type="block" data-imgfileid="503530551" data-aistatus="1" data-original-style="width: 295px;height: 207px;" data-index="32" src="https://image.jiqizhixin.com/uploads/editor/2436bef0-1c15-40ee-8209-eec30a7154cc/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;定理 1 揭示了组相对优势估计的一个根本性质。在非退化事件 S 条件下，&lt;strong&gt;基于组的优势估计&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tyuLG4qXylAHiaKsfls2WKFlIEfGdAY4yuiapwPpfQDjicnibeQ5gGicc07A/640?wx_fmt=png&amp;from=appmsg#imgIndex=31" data-ratio="1" data-s="300,640" data-type="png" data-w="74" type="block" data-imgfileid="503530552" data-aistatus="1" data-original-style="width: 23px;height: 23px;" data-index="33" src="https://image.jiqizhixin.com/uploads/editor/d36cb460-7b16-4835-8403-f71e44fc4770/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dii" style="width: 4.23%;"&gt;, 对不同难度的提示表现出&lt;strong&gt;系统性偏差&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;困难提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=32" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="34" src="https://image.jiqizhixin.com/uploads/editor/256b9a23-6848-4ab8-b0b3-3c2ff9546787/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dii" style="width: 3.03%;"&gt;&amp;lt;0.5)，其期望值&lt;strong&gt;系统性低于&lt;/strong&gt;真实优势&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0ttA8QkO3fdnzu8oxPMLUDf7rU4ibhh7my9a4roHssTEaKZPtReSfnUKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=33" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530554" data-aistatus="1" data-original-style="width: 30px;height: 24px;" data-index="35" src="https://image.jiqizhixin.com/uploads/editor/b29352c2-5968-45d7-9eb7-f26ec6363c34/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dii" style="width: 5.4%;"&gt;（即其真实优势被低估）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;简单提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=34" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="36" src="https://image.jiqizhixin.com/uploads/editor/07830a85-727f-4a98-a55c-b4e4068948f3/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 3.24%;"&gt;&amp;gt;0.5$$)，其期望值&lt;strong&gt;系统性高于&lt;/strong&gt;真实优势&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0ttA8QkO3fdnzu8oxPMLUDf7rU4ibhh7my9a4roHssTEaKZPtReSfnUKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=35" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530554" data-aistatus="1" data-original-style="width: 30px;height: 24px;" data-index="37" src="https://image.jiqizhixin.com/uploads/editor/f9a2770a-4c68-4a5e-92de-9eb4af436056/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dii" style="width: 5.4%;"&gt;（即其真实优势被高估）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;仅当&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=36" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="38" src="https://image.jiqizhixin.com/uploads/editor/60337073-f9a2-40be-bfcb-414fdfe0a77c/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dii" style="width: 3.24%;"&gt;=0.5，组相对优势估计才是&lt;strong&gt;无偏&lt;/strong&gt;的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一结论表明，组相对优势的偏差并非由有限采样噪声引起，而是源自其相对优势估计机制本身，且与提示难度密切相关。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tlHLXGKJ2eqgseCMf26CdKBDXOIgicQIM7EEo4zJ8C8zibqLQ9ic6xp3dw/640?wx_fmt=png&amp;from=appmsg#imgIndex=37" data-ratio="0.6648148148148149" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530555" data-aistatus="1" data-original-style="width: 305px;height: 203px;" data-index="39" src="https://image.jiqizhixin.com/uploads/editor/be5e2d3a-0e91-4e71-a3ed-e3e5cb441451/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时，我们对这种优势估计偏差进行了&lt;strong&gt;系统性的可视化分析&lt;/strong&gt;。如图所示，在非退化事件 S 条件下，组相对优势估计的偏差&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiakbtg8uGmk9ElY8DjKhbKq58wbRIxepQIH8gTIxsXZs9V6FJGpw0Dw/640?wx_fmt=png&amp;from=appmsg#imgIndex=38" data-ratio="0.24175824175824176" data-s="300,640" data-type="png" data-w="364" type="block" data-imgfileid="503530556" data-aistatus="1" data-original-style="width: 112px;height: 27px;" data-index="40" src="https://image.jiqizhixin.com/uploads/editor/54ec4e2a-a3dc-4925-80bf-3a81790220dc/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dii" style="width: 17.24%;"&gt;，随提示难度呈现出明显的结构性变化 :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;当&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=39" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="41" src="https://image.jiqizhixin.com/uploads/editor/e4d262a9-1669-4d79-b730-63c8c2dd1be7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 3.35%;"&gt;&amp;nbsp;偏离 0.5 越远（即提示越困难或越简单）时，优势估计的偏差越大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在相同的提示难度下，G 越小，优势估计偏差越大；随着 G 的增加，偏差虽有所缓解，但在有限采样范围内仍然不可忽略。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;举例 1：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;假设一个非常难的问题，模型原本做对的概率只有 1%（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=40" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="42" src="https://image.jiqizhixin.com/uploads/editor/b725a1fc-43bb-479a-b9a2-51bd26fec397/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.49%;"&gt;=0.01）。如果你采样了 8 次，按照 1% 的这个概率来做的话原本模型大概率是全错的，这些数据会被丢弃，不产生梯度。但是一旦这 8 个回答里面至少有 1 个问题做对了，这个时候组内的 Baseline &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tEGfibZMkJ6E9ibrOLUPhvvsmQ4Tm8WXQrxJib1u0GfI7oyFgu8egkEVibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=41" data-ratio="1.2058823529411764" data-s="300,640" data-type="png" data-w="68" type="block" data-imgfileid="503530557" data-aistatus="1" data-original-style="width: 24px;height: 29px;" data-index="43" src="https://image.jiqizhixin.com/uploads/editor/105226c1-9ae6-4060-9126-ac7e9bb55658/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 3.81%;"&gt;就会瞬间被拉高到至少 0.125 参加梯度更新，和原本&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=42" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="44" src="https://image.jiqizhixin.com/uploads/editor/d69f4a9b-9b86-4a99-98a5-6c1bc554e0a2/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.38%;"&gt; =0.01 差距非常大。这导致计算出的优势估计就会变小&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tf3P8cF7rDZAM5c2y4RpdI66LErpYXlo3H3udjEpotsPHkZXIUvUBBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=43" data-ratio="1.02" data-s="300,640" data-type="png" data-w="100" type="block" data-imgfileid="503530559" data-aistatus="1" data-original-style="width: 27px;height: 28px;" data-index="45" src="https://image.jiqizhixin.com/uploads/editor/d9c3292f-27b8-47f1-823f-0b19fd740cd9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 4.02%;"&gt;&amp;le; 0.875，与真实的优势&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t7AlCclxCwCbIZGXRDjQdiaSA2ocwh9jmxgxQyGWmQ0toEXRBEH5h5mw/640?wx_fmt=png&amp;from=appmsg#imgIndex=44" data-ratio="0.7878787878787878" data-s="300,640" data-type="png" data-w="66" type="block" data-imgfileid="503530560" data-aistatus="1" data-original-style="width: 32px;height: 25px;" data-index="46" src="https://image.jiqizhixin.com/uploads/editor/7b35985d-b4b0-4140-b908-e0ce6bffff37/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 4.97%;"&gt;=0.99 产生巨大偏差，即优势被显著低估。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;举例 2：&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t0wqqib7O98rrZtGS3ZFVvfXtEfwYmRTeeMu3R0oO8UlFqZhRvdsnbkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=45" data-ratio="0.6764044943820224" data-s="300,640" data-type="png" data-w="890" type="block" data-imgfileid="503530561" data-aistatus="1" data-original-style="width: 377px;height: 255px;" data-index="47" src="https://image.jiqizhixin.com/uploads/editor/f9a8a113-cb8c-4138-aeb3-a89f912eb5d0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该图展示了在 MATH 数据集上，对于同一道困难题目，组相对优势估计在不同回答采样数量下的表现差异。当采用 8 次采样时，对正确回答所计算得到的优势为 A=2.65；而当采样数量提升至 128 次时，所估计的优势增大至 A=3.64，更接近其真实优势值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重要发现 2：&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tU4JWDcUiauf5mibj9GzObqG7pEPd8yCMBkW9xDQ4bNADTGzGuhLFzvfQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=46" data-ratio="0.7843137254901961" data-s="300,640" data-type="png" data-w="612" type="block" data-imgfileid="503530562" data-aistatus="1" data-original-style="width: 348px;height: 273px;" data-index="48" src="https://image.jiqizhixin.com/uploads/editor/c625565e-5df0-47e8-b7b1-88c9a407e9f9/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为此，进一步给出了优势估计偏差的概率化刻画。如推论 1 所示，在实际常用的组大小范围 G = 8 时，组相对优势估计以&lt;strong&gt;较高概率&lt;/strong&gt;对不同难度的提示产生系统性偏差：对于&lt;strong&gt;困难提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=47" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="49" src="https://image.jiqizhixin.com/uploads/editor/6a0286de-4bb0-4b2f-8c00-93f03b5391be/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 3.38%;"&gt;&amp;lt;0.5），其优势被低估的概率超过 0.63；对于&lt;strong&gt;简单提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=48" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="50" src="https://image.jiqizhixin.com/uploads/editor/94700379-9f1c-44d0-925f-30682a1d2299/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 3.6%;"&gt;&amp;nbsp;&amp;gt;0.5），其优势被高估的概率同样超过 0.63。当提示难度进一步加剧扩大时，这一概率上界进一步提升至 0.78 甚至 100%，表明偏差随难度加深而显著放大。&lt;/p&gt;&lt;p&gt;论文也提供具体偏差量估计：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t2iasLnTnsa8XLn9TUVGZFplSjnEqH2o6QhUTW1xE3DTompEn8BBZJMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=49" data-ratio="1.0496688741721854" data-s="300,640" data-type="png" data-w="604" type="block" data-imgfileid="503530563" data-aistatus="1" data-original-style="width: 334px;height: 351px;" data-index="51" src="https://image.jiqizhixin.com/uploads/editor/3d226803-01c1-46a7-9e38-4dd66f3f4037/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综上所述，组相对优势估计（Group-relative Advantage）在理论上除&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=50" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="52" src="https://image.jiqizhixin.com/uploads/editor/555f22c1-41e8-4fc5-99c6-08b91415fc0b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dii" style="width: 3.17%;"&gt;= 0.5 外均是有偏的。因为 GRPO/Group-based PO 会优势估计机制会强制将样本限制在子集 S 上，相当于对原来的样本全集进行了加权，即加权之后的优势估计是有偏的。&lt;/p&gt;&lt;p&gt;具体而言，该估计方法会对困难提示系统性地低估真实优势，而对简单提示系统性地高估真实优势。进一步地，对于极其困难的提示，优势估计必然被低估；而对于极其简单的提示，则必然被高估。&lt;/p&gt;&lt;p&gt;尽管上述分析主要基于 &lt;strong&gt;0&amp;ndash;1 二值奖励&lt;/strong&gt;的设定，该假设覆盖了大量 RLVR 场景，尤其是依赖硬判别 verifier 的推理任务，但真实应用中的奖励信号往往更加一般。&lt;/p&gt;&lt;p&gt;为此，论文在附录 D.5 中将分析推广至&lt;strong&gt;连续且有界的奖励分布&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;结果表明，组相对优势估计中的核心偏差现象并非 Bernoulli 奖励假设的偶然产物，而是在更广泛的有界奖励模型中同样普遍存在。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这个发现告诉我们什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该发现对 RLVR 训练具有直接而深远的影响。&lt;/p&gt;&lt;p&gt;具体而言，组相对优势估计的系统性偏差会导致不同难度提示在学习过程中受到不平衡的梯度信号：对于困难提示，其真实优势被低估，从而产生较小的梯度更新，导致学习进展缓慢；而对于简单提示，其优势被高估，模型则容易对其过度强化。最终，这种不对称的优势估计会抑制有效探索，使训练过程偏向于反复强化简单样本，而忽视真正具有挑战性的提示。&lt;/p&gt;&lt;p&gt;基于上述分析，我们认为优势估计应当根据提示难度进行自适应调整：&lt;strong&gt;对于困难提示，应适当放大其估计优势以鼓励探索；而对于简单提示，则应抑制其优势以防止过度利用。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为在实践中判定提示难度，论文提出算法 &lt;strong&gt;HA-DW&lt;/strong&gt;，引入&lt;strong&gt;短期历史平均奖励&lt;/strong&gt;作为动态锚点，将新提示与该锚点进行对比，从而判断其相对难度，并据此对优势估计进行自适应重加权。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t87gcI2zwD0riauscOK5GhrbwmeNZeEozSDWRbgBFmGJqOBplPDj5VUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=51" data-ratio="0.9220055710306406" data-s="300,640" data-type="png" data-w="718" type="block" data-imgfileid="503530565" data-aistatus="1" data-original-style="width: 293px;height: 270px;" data-index="53" src="https://image.jiqizhixin.com/uploads/editor/be34ad98-7667-416d-9459-4118e5717aca/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该图展示了在对组相对优势估计进行校正之后，不同难度提示上的性能变化。可以观察到，引入优势校正机制后（GRPO+HA-DW），&lt;strong&gt;模型在困难提示（Hard）上的性能提升最为显著，相比原始 GRPO 提升了 3.4%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GRPO/Group-based PO 的问题不只是 variance，而是 bias&lt;/strong&gt;。这项工作也释放了一个很强的信号：&lt;strong&gt;LLM 强化学习正在从「工程上能跑出效果就行」，回到「估计是不是准确」的根本问题和可解释性。&lt;/strong&gt;以后 RLVR 里，bias analysis /estimator correctness 很可能会成为标配。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>千问C端应用团队一口气四篇论文入选ICLR 2026国际顶会！</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 30 Jan 2026 16:29:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;当AI助手越来越多地参与到学习、工作辅助、医疗咨询等生活场景，能否稳定输出、是否懂得追问关键信息，正成为衡量AI能力的重要标准。&lt;/p&gt;&lt;p&gt;1月30日消息，千问C端应用团队的四篇人工智能领域研究论文入选2026国际学习表征会议（ICLR 2026），论文聚焦扩散模型训练、多轮对话决策、信息验证及模型价值观对齐等关键问题，部分成果已有实际应用，推动AI助手在复杂场景下更加聪明、可靠、实用。&lt;img src="https://image.jiqizhixin.com/uploads/editor/89d73168-232b-40a4-93c3-2af09a6621c5/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;ICLR与NeurIPS、ICML并称为机器学习和人工智能领域三大顶级国际会议。本届会议投稿量接近19000篇，接收率创下近年来新低。&lt;/p&gt;&lt;p&gt;本次四篇论文在多个前沿领域取得创新突破。在扩散语言模型（Diffusion Models）研究方面，千问C端应用团队针对dLLM独特的掩码训练不稳定性，将其系统分解为了三种不同的噪声来源，并相应提出帕累托最优的无偏训练算法。该算法显著降低了dLLM的训练波动、进而提升其图文生成质量。这意味着在内容生成、创作辅助等应用中，AI输出将更加稳定。&lt;/p&gt;&lt;p&gt;围绕医疗多轮对话中的复杂推理任务，团队提出了自适应树策略优化（ATPO）方法，使AI能够根据对话中的不确定性动态调整决策路径。当信息不足时，AI会主动追问关键问题；当线索清晰时，则快速给出判断。这一能力可帮助AI助手在医疗咨询等专业场景学会&amp;ldquo;主动问诊&amp;rdquo;，让AI像经验丰富的医生一样，只问最关键的问题，避免无用的来回对话。&lt;/p&gt;&lt;p&gt;在信息检索与验证方面，研究团队构建了&amp;ldquo;提问&amp;mdash;解答&amp;mdash;验证&amp;rdquo;的自博弈强化学习框架，使AI在无需人工标注的情况下不断自我验证与进化。这一机制有助于提升AI在复杂问题下的检索与核验能力，在学习辅助、研究支持等知识密集型场景中表现更为可靠。&lt;/p&gt;&lt;p&gt;此外，在模型价值观对齐研究中，团队引入信息论偏见消除方法，引导奖励模型关注真正与人类偏好相关的信号，减少冗长、格式化但信息密度不高的输出。这使得AI在训练过程中真正关注能够帮助到用户的核心要点，降低模型输出中出现&amp;ldquo;表面迎合但缺乏实质内容价值&amp;rdquo;的情况。&lt;/p&gt;&lt;p&gt;业内专家指出，当前大模型竞争正从&amp;ldquo;参数规模&amp;rdquo;转向&amp;ldquo;算法深度与工程实效&amp;rdquo;。千问C端应用团队在生成稳定性、多轮对话决策和模型对齐等方向上的系统性探索，体现了其在基础算法与应用导向研究上的持续投入。&lt;/p&gt;&lt;p&gt;值得一提的是，此次千问C端应用团队入选 ICLR 2026 的四篇论文相关代码均已开源。通过开放核心实现细节，将为行业在提升AI可用性、可靠性方面提供有益参考。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>蚂蚁灵波开源具身世界模型LingBot-VA，机器人复杂任务成功率较Pi0.5提升20%</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 30 Jan 2026 15:07:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1 月 30 日，继空间感知模型、具身大模型与世界模型&amp;ldquo;三连发&amp;rdquo;后，蚂蚁灵波科技今日宣布开源具身世界模型LingBot-VA。LingBot-VA首次提出自回归视频-动作世界建模框架，将大规模视频生成模型与机器人控制深度融合，模型在生成&amp;ldquo;下一步世界状态&amp;rdquo;的同时，直接推演并输出对应的动作序列，使机器人能够像人一样&amp;ldquo;边推演、边行动&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在真机评测中，LingBot-VA展现出对复杂物理交互的强适应能力。面对长时序任务（制作早餐、拾取螺丝）、高精度任务（插入试管、拆快递）以及柔性与关节物体操控（叠衣物、叠裤子）这三大类六项高难度挑战，仅需 30~50条真机演示数据即可完成适配，且任务成功率相较业界强基线 Pi0.5平均提升20%。&lt;img src="https://image.jiqizhixin.com/uploads/editor/cb3f5003-ae41-4d63-865b-52ac4b1a0909/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图说：真机评测中，LingBot-VA在多项高难操作任务上性能超越业界标杆 Pi0.5&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在仿真评测中，LingBot-VA在高难度双臂协同操作基准 RoboTwin 2.0 上首次将成功率提升至超过 90%，在长时序终身学习基准 LIBERO上达到 98.5% 平均成功率，均刷新了行业纪录。&lt;img src="https://image.jiqizhixin.com/uploads/editor/cd043118-5a3e-48b9-aa66-18a3ad57514b/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;图说：LingBot-VA在LIBERO与RoboTwin2.0仿真基准测试中刷新现有SOTA&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;据悉，LingBot-VA 采用Mixture-of-Transformers（MoT）架构，让视频处理与动作控制实现跨模态融合。通过独特的闭环推演机制，模型在每一步生成时都会纳入真实世界的实时反馈，确保持续生成的画面与动作不偏离物理现实，从而控制机器人完成高难复杂任务。&lt;/p&gt;&lt;p&gt;为突破大规模视频世界模型在机器人端侧落地的计算瓶颈，LingBot-VA 设计了异步推理管线，将动作预测与电机执行并行化处理；同时引入基于记忆缓存的持久化机制与噪声历史增强策略，让推理时只需更少生成步骤即可输出稳定、精确的动作指令。这一系列优化使得 LingBot-VA既拥有大模型的理解深度，又具备真机低延迟控制的响应速度。&lt;/p&gt;&lt;p&gt;蚂蚁灵波表示，承接前几日开源发布的 LingBot-World（模拟环境）、LingBot-VLA（智能基座）与 LingBot-Depth（空间感知），LingBot-VA 探索出一条&amp;ldquo;世界模型赋能具身操作&amp;rdquo;的全新路径。蚂蚁集团将持续依托 InclusionAI 社区开源开放，与行业共建具身智能基础能力，加速构建深度融合开源开放、且服务于真实产业场景的AGI生态。&lt;/p&gt;&lt;p&gt;目前，LingBot-VA的模型权重、推理代码已全面开源。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>中国科学院等提出的可扩展顺序式多PTM集成平台，处理时间缩短87.5%</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 30 Jan 2026 14:04:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;蛋白质翻译后修饰（post-translational modifications, PTMs）决定了蛋白质在细胞中的真实功能状态，其中以糖基化与磷酸化最具系统调控意义。然而，在实际蛋白组学研究中，由于样本拆分、并行处理、分别富集，再在计算层面勉强拼接，这些信息长期被迫分散在不同实验流程中获取。&lt;/p&gt;&lt;p&gt;这种策略在方法学上并非优雅的选择，而是一种历史妥协&amp;mdash;&amp;mdash;它带来的问题并不隐蔽：样本损耗成倍放大、流程时间冗长、批次效应叠加、定量一致性被结构性削弱。&lt;/p&gt;&lt;p&gt;来自中国科学院、重庆医科大、南昌赣江中药创新中心等研究团队提出并系统验证了一种顺序式多 PTM 蛋白组学平台&amp;nbsp;&lt;strong&gt;MuPPE（Multiplexed PTM Proteomics by Protein Aggregation）&lt;/strong&gt;。其核心思想是在单一样本、单一反应体系中，依次完成蛋白组、糖基化蛋白组与磷酸化蛋白组的捕获与解析，从根本上重构多 PTM 蛋白组学的工程逻辑。&lt;/p&gt;&lt;p&gt;相关研究内容以「A versatile platform for sequential glyco-, phospho-, and proteomics with multi-PTMs integration」为题，于 2026 年 1 月 28 日发布在《Nature Communications》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibtrVUzaeoWiaibGyrh0fjy31lt0jESSics8NtJF7D5VDn61alwV9vvfTpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.29692470837751855" data-type="png" data-w="943" data-width="943" data-height="280" data-imgfileid="100027322" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1af03c48-0b20-4ef2-8c74-b3870ca1358a/640.png" alt="图片" data-before-load-time="1769753031791" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41467-025-68270-7&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;蛋白聚集驱动的顺序式富集&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统多 PTM 蛋白组学流程的核心假设，是不同修饰类型需要彼此独立的富集化学环境与处理条件。因此，研究者通常在样本裂解后即进行拆分，每一份样本对应一种 PTM 富集策略。&lt;/p&gt;&lt;p&gt;这一做法在概念上简单，却在工程上代价高昂。首先，样本拆分会直接降低每一分支的起始物质量，使得低丰度修饰位点更易丢失；其次，不同富集流程之间不可避免地产生处理偏差，最终反映为定量噪声的系统性放大；更关键的是，这种并行流程天然不适用于样本量受限的场景，如临床体液或稀有组织。&lt;/p&gt;&lt;p&gt;研究团队在论文中明确指出，问题并不在于富集材料或质谱灵敏度的不足，而在于&lt;strong&gt;流程结构本身并不为「多层信息一致性」服务&lt;/strong&gt;。MuPPE 正是在这一判断基础上被提出，其目标不是增加某一 PTM 的覆盖率，而是&lt;strong&gt;在同一物理样本轨迹中，最大限度保留不同修饰层之间的真实对应关系&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibibnTD46hPbuZTv8j5pT8IDjCLNdAlgFL3RNzUDf0yAwpIkwiavibZNV2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9124087591240876" data-type="png" data-w="685" data-width="685" data-height="625" data-imgfileid="100027324" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/67dd3c74-3006-4d6b-967c-374a4992e853/640.png" alt="图片" data-before-load-time="1769753031848" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：MuPPE 平台实现了集成的多层次蛋白质组学，提升了效率和覆盖范围。&lt;/p&gt;&lt;p&gt;MuPPE 平台是一个整合蛋白质聚集捕获（PAC）、珠上消化和序列 PTM 富集的统一流程。作为原理验证，该平台使蛋白质组、糖蛋白组和磷蛋白组同时被探测成为可能。它从蛋白质变性、还原和烷基化开始，引入一种经过修改且可扩展的 PAC 方法，实现高效的蛋白质分离。&lt;/p&gt;&lt;p&gt;随后，研究者通过精心设计的顺序洗脱与酶解策略，使不同修饰层在同一载体上被依次释放并分析。整个过程中，样本始终处于单管、单体系中完成，没有发生任何物理拆分。这种顺序式设计的直接结果，是&lt;strong&gt;样本损耗被系统性压缩&lt;/strong&gt;，同时不同修饰层之间的相对定量关系得以最大程度保留。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率、一致性与覆盖度的系统评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在方法学评估中，研究团队首先对 MuPPE 与传统并行富集流程进行了直接对比。在处理时间上，MuPPE 将完整多 PTM 分析流程压缩至约 4 小时，相较传统方法动辄 24&amp;ndash;36 小时的处理周期，时间成本降低约 87.5%。这一压缩并非通过减少步骤实现，而是通过消除并行流程中的冗余处理完成。&lt;/p&gt;&lt;p&gt;在定量一致性方面，MuPPE 在多个生物重复实验中表现出显著更低的变异系数。无论是蛋白组、糖基化蛋白组还是磷酸化蛋白组，变异系数（CV%）均稳定维持在约 12&amp;ndash;15% 区间（平均 CV = 12.3%，而溶液中消化为 17.6%），而传统并行方法在相同条件下普遍超过 20%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibjcnuQPNQuqbwh6PRkSb751ca2T8xEjZ5RD2qFKOibPiafXiauNwYlSBJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0525547445255474" data-type="png" data-w="685" data-width="685" data-height="721" data-imgfileid="100027325" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/11619b8c-0ce8-4f46-874b-18679d4060cd/640.png" alt="图片" data-before-load-time="1769753032182" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：使用 MuPPE 对糖蛋白组、磷酸蛋白组和蛋白质组进行序列化分析。&lt;/p&gt;&lt;p&gt;覆盖度分析显示，MuPPE 在不牺牲深度的前提下，实现了对三类分子层级的稳定检测。数千个蛋白、上万条糖基化与磷酸化位点在单次实验中被同时解析，且不同修饰层之间的对应关系清晰可追溯。这一点在后续的生物学应用中尤为关键。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibz9ujTOa31EzKKzBicJ0kntsecR1XU4Pf2El2MeV7U9FCKCRKsjCXSOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.1167883211678833" data-type="png" data-w="685" data-width="685" data-height="765" data-imgfileid="100027323" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6fdc5e49-c55a-4edc-b718-07c778dbeba7/640.png" alt="图片" data-before-load-time="1769753032216" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 3：小鼠衰老队列的磷蛋白组、糖蛋白组和蛋白质组整合分析。&lt;/p&gt;&lt;p&gt;应用层面，MuPPE 适用于多种复杂生物样本，包括血清、脑组织以及脑脊液等低起始量或高复杂度体系。该平台在样本量受限条件下依然保持稳定的检测能力，且不同 PTM 层的信号强度与定量分布高度一致。&lt;/p&gt;&lt;p&gt;值得注意的是，论文并未刻意放大某一具体生物学发现，而是将重点放在方法本身在真实样本条件下的稳健性验证。这种克制的呈现方式，反而凸显了 MuPPE 作为平台级工具的通用潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;针对流程结构的蛋白组学重构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MuPPE 首次实现了单一样本中糖基化、磷酸化与总蛋白的串联分析，解决了传统方法样本需求量大、修饰间关联性难以捕捉的痛点。其在低样本量、高复杂性样本中表现出优异的富集效率和重现性，拓展了未注释 PTM 位点的发现。&lt;/p&gt;&lt;p&gt;该平台目前对单细胞水平的低蛋白样本仍需进一步优化，但不妨碍它在效率、一致性与样本利用率之间实现了难得的平衡。对于需要在有限样本中同时解析多层蛋白修饰信息的研究场景而言，这种工程层面的改变，可能比单一指标的提升更具长期影响。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>姚顺雨现场颁奖，吉嘉铭、董冠霆等15位青年人才获腾讯「青云奖学金」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 13:05:11 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;刚刚，腾讯「青云奖学金」正式在深圳颁奖。&lt;/section&gt;&lt;p&gt;作为腾讯支持青年人才和科学研究的项目，「青云奖学金」首期评选出 15 位获奖者，并为每位获奖者提供总价值 50 万的激励，包括 20 万现金和价值 30 万的云异构算力资源。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「我们希望青年研究者敢于探索未知、富有创新精神，追逐那些大胆的、前沿的、具有长远影响力的科研方向，共同探索更广阔的科技前沿。」腾讯集团高级副总裁、首席人才官奚丹说。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcI5t5mWTtOMCC0iarvlpGD8Prx9ZlR9NwrlyzrZIEHTfUicmMiavcnrvcg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="385" data-imgfileid="503530953" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9ff02c97-efd1-42c1-9b45-d8878c57cb13/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;不久之前正式入职腾讯出任「CEO / 总裁办公室」首席 AI 科学家的姚顺雨（Vinces Yao），也现身为获奖者颁奖。&lt;/span&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcyMwxFibmvibQDLeDqBiaFdg2WibZkZuyjrkwgMmicYUib5eGVgnicXOgRRicsA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.75" data-type="jpeg" data-w="1080" data-width="1706" data-height="1279" data-backw="578" data-backh="433" data-imgfileid="503530904" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/51941f1e-8211-4554-96e1-db25d062877e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;吉嘉铭、董冠霆、张金涛等多位机器之心熟知的青年 AI 学者获奖，以下为全部获奖者介绍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;白雨石&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcASm9eNKUQQPXt63akwVGntOiasqoI2KyjTLX1eSM3bahhibOLia36yIYg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5074074074074074" data-type="png" data-w="1080" data-width="1084" data-height="550" data-backw="578" data-backh="293" data-imgfileid="503530934" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/464a351a-9337-4ce6-87cd-d9ae97db862b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的白雨石，研究领域涉及长上下文大模型与大模型评测。截至目前，他已在 NeurIPS、ICML、ICLR、ACL 等国际顶会发表 10 篇一作论文，总引用量 4000 + 次，一作论文被引近 2000 + 次。开源的 LongBench、Long-Writer、LongAlign 等工作在 GitHub 共获 3000+ stars 及 300+ forks，在 HuggingFace 上开源的数据集和模型共被下载 200 万+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陈俊松&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc84gEniasZ8WdawBfQicibubFLC9N2w9JJ92ocTk081Yq6tRVj6VQsybqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.49907235621521334" data-type="png" data-w="1078" data-width="1078" data-height="538" data-backw="578" data-backh="288" data-imgfileid="503530936" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f92be927-fa3e-4001-bf0d-8008f8285414/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港大学的陈俊松，研究领域围绕 AIGC 高效视觉生成大模型，专注于扩散模型的高效部署研究，早期贡献了里程碑式的 PixArt 模型，近期主导的 SANA 系列实现效率突破：SANA 原生支持 4K 图像生成，SANA-Sprint 达成 0.1 秒实时成像，SANA-Video 支持分钟级长视频合成。成果累计引用量 2500 + 次及在 GitHub 获得 1 万 + stars，有力推动了高性能生成式 AI 在实时消费级场景的落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;董冠霆&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc9ll4vOLgPcKVOdVGeq2uAaJkdm9QnJLmATyOjuOyuWicp74Z2lCquGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5223880597014925" data-type="png" data-w="1072" data-width="1072" data-height="560" data-backw="578" data-backh="302" data-imgfileid="503530937" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/99a90f60-6e58-4dbd-b0df-771165a2a9e5/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自中国人民大学的董冠霆，主要研究方向为智能信息检索和智能体强化学习，曾获国家奖学金、北京市优秀毕业生等荣誉，并入选国家自然科学基金青年学生基础研究项目 (博士生)、中国科协青年人才托举工程博士生专项计划资助，代表工作包括 ARPO、AUTOIF.DMT、Search-o1、Webthinker、 FlashRAG 等, 受到国内外研究者的广泛关注。其中监督微调数据配比策略 DMT、自动化指令遵循对齐策略 AUTOIF 被落地应用于模型的对齐训练中。以第一 / 共一作身份在 ICLR、NeurlPS 等国际顶会发表论文 10 + 篇，谷歌学术引用量 1 万 + 次，GitHub 获得 8000+ stars。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;邓洋涛&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcKahbEqxL2Wg04DK6HfMTwT5vG3lDE9iaJ46cmACSoD1EZibsYYwBTKiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5046296296296297" data-type="png" data-w="1080" data-width="1082" data-height="546" data-backw="578" data-backh="292" data-imgfileid="503530938" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5b751551-894d-43e5-8371-deba7bee3a65/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港中文大学的邓洋涛，研究领域聚焦 AI 基础设施与系统，致力于攻克大语言模型预训练中的稳定性难题，设计并研发了细粒度、实时的数据依赖追踪与根因分析系统，研究工作已录用或发表于 SOSP、NSDI、NDSS、FSE 等会议，相关系统已在工业级预训练集群中部署，能针对异常进行快速告警。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;吉嘉铭&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcgbX3Kr49hOsm5UvNoXU7A8CSxN8icq7LycicoAbhkceXM35YaFibBSvzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5056179775280899" data-type="png" data-w="1068" data-width="1068" data-height="540" data-backw="578" data-backh="292" data-imgfileid="503530940" data-aistatus="1" data-original-style="width:100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/97b2c048-a63b-4300-aec9-8f00992c3e4d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自北京大学的吉嘉铭，研究领域是大模型安全与强化学习对齐，致力于构建和人类的偏好与意图对齐的人工智能系统，曾获北京大学 2025 年度人物，以第一 / 共一作身份发表人工智能领域顶会论文 14 篇，代表论文被评为 ACL 2025 最佳论文，相关成果谷歌学术总引用量 4600 + 次，GitHub 开源项目获得 3.2 万 + stars，开源模型累积下载量 500 万 + 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;林彬&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcTFxia3ZbKzfJl2D8yBHsFJAK5tds8gs7npPFzxL8nIVOeOk6YOQwpGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.49536178107606677" data-type="png" data-w="1078" data-width="1078" data-height="534" data-backw="578" data-backh="286" data-imgfileid="503530941" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/84d27559-86e4-4f4b-b1c5-fee35586d52c/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同样来自北京大学的林彬，研究方向聚焦于视频生成与多模态大模型，连续一年获评 HuggingFace 社区 Top100 影响力用户，代表作 Open-Sora Plan 与 Video-LLaVA，在 GitHub 累计获得 2 万 + stars，模型开源下载量突破 1300 万+ 次。在 CVPR、ICLR、NeurlPS 等国际顶会期刊发表十余篇论文，多项开源成果获 GitHub 与 Papers With Code 热度榜 Top1，谷歌学术引用量 3200+ 次，单篇一作引用量 1000+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;李磊&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc7wvGGXsvicDGPTxrfsMwDDcA3uhb4kKibOlqqp0pLspSzhOg9EiauhssQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5112359550561798" data-type="png" data-w="1068" data-width="1068" data-height="546" data-backw="578" data-backh="295" data-imgfileid="503530942" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c8fedafd-32d5-493d-a066-acfb5d17bbbd/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港大学的李磊专注于多模态大语言模型与可解释性研究，现任 ACL ARR 领域主席，获评 EMNLP 2025 杰出领域主席，与微信 AI 合作论文获 EMNLP 2023 最佳长文奖，多篇论文入选 CVPR Highlight 及 PaperDigest 最具影响力论文。核心参与开发 MiMo-VL-7B、MiMo-V2-Flash 并获得广泛关注，以第一作者在 ICLR、CVPR、ACL 等国际顶会发表多篇论文，谷歌学术引用量 8700+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;刘松铭&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcrgja38v4Qjr8IpWicwH09x0KMbFJ9TqBpyS86ylyYxtgIALjpUIHebA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5083798882681564" data-type="png" data-w="1074" data-width="1074" data-height="546" data-backw="578" data-backh="294" data-imgfileid="503530944" data-aistatus="1" data-original-style="width:100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/01eaefaa-410f-41eb-919e-015e47259c48/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的刘松铭，致力于具身大模型方向研究，曾获清华本科生特奖，主导研发机器人基础模型 RDT 系列：RDT-1B (ICLR 2025) 获得 1600+stars，RDT-2 作为全球首个 UMI 无本体训练的 7B 大模型，支持任意机械臂零样本部署，实现接箭、打乒乓球等毫秒级动态操控。累计发表 12 篇文章，总引用量 1300+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;刘子君&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcQPFTPAOGvvmo1fBubNkKRIZts2Bn5hJGmSw0DeDH4DvKIeZjkCEcMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5103189493433395" data-type="png" data-w="1066" data-width="1066" data-height="544" data-backw="578" data-backh="295" data-imgfileid="503530945" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5afd6374-5fdf-45af-8269-2f2f2ced4909/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的刘子君，聚焦于大模型群体智能体系与推理时扩展方向研究，曾获国家奖学金、清华大学未来学者等荣誉，主持完成北京市自然科学基金学生项目，提出大模型群体智能体系的动态协同网络 DyLAN 与跨环境迁移算法 CollabUlAgents，实现了推理时高效扩展的通用奖励模型，在 ACL、ICML、COLM 等国际顶会发表多篇论文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;宋立阳&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcFdOfCGTKKU2wDbNr7vH85PP84ZGUB99CZLycmNGuboACby9vaKKuPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5" data-type="png" data-w="1064" data-width="1064" data-height="532" data-backw="578" data-backh="289" data-imgfileid="503530946" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c3fab14f-dfa7-4b36-b0da-52135c2457a1/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自西湖大学的宋立阳主要研究如何利用统计与深度学习算法来理解复杂疾病的遗传机制，围绕遗传数据与多组学数据的整合，开发了 MeDuS (Nature Computational Science,2023) 和 qsMap (Nature,2025) 等方法, 将遗传关联信号解析到具体的细胞状态和组织空间中，实现对疾病相关遗传根源细胞的精准定位。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;胥嘉政&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcjgib6HXcweDrkzhP7FbAzBS39qTAvQoPvZJPXbyIfgINmGCOEuhianTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.515828677839851" data-type="png" data-w="1074" data-width="1074" data-height="554" data-backw="578" data-backh="298" data-imgfileid="503530947" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/abe2b986-e53e-49d9-81a0-3b6cb21133ae/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的胥嘉政，专注于多模态生成模型和强化学习方向研究，代表作包括图像生成模型偏好强化对齐工作 lmageReward 和视频生成偏好框架 VisionReward，其中 lmageReward 是最早将人类偏好引入文生图领域的工作之一，并设计了首个基于梯度对扩散模型直接完成偏好对齐的算法 ReFL。谷歌学术总引用量 4000+ 次，lmageReward 研究引用量 1000+ 次，GitHub 获得 1600+ stars，Python 工具包 PyPi 官方下载量接近百万次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;徐明皓&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcm7Z7a0VauDJTPklJRmwLmXPlqBHlTNZO8LQdvEHG8eWqBK6mtaAclg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.5065913370998116" data-type="png" data-w="1062" data-width="1062" data-height="538" data-backw="578" data-backh="293" data-imgfileid="503530948" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/67d71d28-6fe8-4388-9de4-3f4f8d50ce9b/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自北京大学的徐明皓，研究聚焦于 Al for Science，北京大学和 Mila 魁北克人工智能研究所联培博士，在国际顶会和期刊上发表 20+ 篇论文，论文累计引用量 3000+ 次, 多次受邀在大会上进行报告分享，并组织开展生命科学大语言模型 tutorial。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;杨丽鹤&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rciatuMQvQXQudKKKhhOOkkiaiaxqPsKFibtRuJwVVNyEuutgSerq9AhLQZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.49906542056074765" data-type="png" data-w="1070" data-width="1070" data-height="534" data-backw="578" data-backh="288" data-imgfileid="503530949" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/2a770ac1-cfd4-4a39-bce4-322c97682ca0/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港大学的杨丽鹤研究方向专注于计算机视觉，曾获知名企业奖学金、世界人工智能大会青年优秀论文奖等荣誉，相关工作入选 CVPR 2024、NeurlPS 2024 十大最具影响力论文。在 CVPR、ICCV、NeurlPS、TPAMI 等国际顶会发表若干论文，谷歌学术引用量 5000+ 次，GitHub 获得 1.6 万+ stars。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;张金涛&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rca9eokbiciaPR38NxKkeCe0PlAKEUb9zqcQ8via0fguvuM9J2FkBQwNmJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.5112781954887218" data-type="png" data-w="1064" data-width="1064" data-height="544" data-backw="578" data-backh="296" data-imgfileid="503530951" data-aistatus="1" data-original-style="width:100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/1e43c7cd-a30d-4d07-b8cb-05769ec479a9/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的张金涛，研究聚焦高效机器学习系统，发表一作 A 类国际顶会长文 9 篇，均发表于 ML/DB 的三大顶会，代表作 SageAttention 是首个专注于低比特量化加速注意力计算的研究，相关成果在 GitHub 获得 3000+ stars，被 200+ 家知名企业的真实产品采用，其他一作代表作有 TurboDiffusion、SpargeAttn、Sparse-Linear Attention 等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;赵威霖&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="287" data-backw="578" data-height="530" data-imgfileid="503530952" data-ratio="0.4971857410881801" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcLHsQnCTV9hzxvUh6WxZyC90DyWxLdf4icl6dIEyxB70spquic8Ja6Opg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-type="png" data-w="1066" data-width="1066" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/9ebc0f60-e7d8-4f41-884e-8a57cd9cd62c/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的赵威霖，研究领域是大模型高效架构，针对推理效率与长文本瓶颈进行探索，围绕高频词子空间提出了 FR-Spec，辅助投机采样实现更高效的并行生成，设计 InfLLM-V2 稀疏注意力架构，实现长短文本稀疏稠密的动态切换并获约 4 倍加速，相关成果已整合并开源至 CUDA 框架 CPM.cu。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>LLM-in-Sandbox：给大模型一台电脑，激发通用智能体能力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 13:00:42 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/1d867b8f-290d-4bb5-b8d3-ae59b4c22d38/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大模型的能力正在被不同的范式逐步解锁：In-Context Learning 展示了模型无需微调即可泛化到新任务；Chain-of-Thought 通过引导模型分步推理来提升复杂问题的求解能力；近期，智能体框架则赋予模型调用工具、多轮交互的能力。&lt;/p&gt;&lt;p&gt;沿着这条技术演进路线，下一步是什么？&lt;/p&gt;&lt;p&gt;近日，来自中国人民大学高瓴人工智能学院、微软研究院和清华大学的研究者提出了一个简洁而有效的范式：&lt;strong&gt;LLM-in-Sandbox&lt;/strong&gt;&amp;mdash;&amp;mdash;让大模型在代码沙盒（即虚拟电脑）中自由探索来完成任务。实验表明，这一范式不仅在代码任务上有效，更能显著提升模型在数学、物理、化学、生物医学、长文本理解、指令遵循等多个非代码领域的表现，且无需额外训练，同时显著减少长文本场景下的 token 消耗，并保持相当水平的推理速度。&lt;/p&gt;&lt;p&gt;研究者已将 LLM-in-Sandbox 开源为 Python 包，可与 vLLM、SGLang 等主流推理后端无缝集成。&lt;strong&gt;LLM-in-Sandbox 应当成为大模型的默认部署范式，取代纯 LLM 推理&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tLIkvia1j4VNNIwwnzm6MLAEoiaOL0e4LXNzWtsZnDvmEiaZiaGufJkhdZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.275" data-type="png" data-w="1080" data-width="415" data-height="114" data-imgfileid="503530494" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7b186e64-f7d3-4646-be0c-131662197365/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：LLM-in-Sandbox Elicits General Agentic Intelligence&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.16206&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/llm-in-sandbox/llm-in-sandbox&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://llm-in-sandbox.github.io&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;1. 核心思想：给大模型一台电脑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;电脑可能是人类创造的最通用的工具，几乎任何任务都可以通过电脑完成。这种通用性源于三大&lt;strong&gt;元能力（Meta-Capabilities)&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;外部资源访问：通过网络获取信息和知识&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;文件管理：持久化地读写和组织数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;程序执行：编写并运行任意程序&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;正如人类借助电脑完成各种任务，研究者假设：将大模型与虚拟电脑结合，或许能够解锁其通用智能的潜力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="302" data-imgfileid="503530495" data-ratio="0.7287037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tN06uJUU2icjDRuJOAib9tZv3F5gnCXhc6kzDvdUZmMYOAbjf8XiaFc1qA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="415" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bbf7607e-ed3d-4d7d-8d17-834ae0dcbe9a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. LLM-in-Sandbox：代码沙盒激发通用能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.1 轻量级通用沙盒&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与现有软件工程智能体（SWE-Agent）需要为每个任务配置特定环境不同，LLM-in-Sandbox 采用轻量级、通用化的设计：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于 Docker 的 Ubuntu 环境&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;仅预装 Python 解释器和基础科学计算库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;将领域特定工具的获取交给模型自主完成&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tLQm2iajYFwbbzg05MicibFQKibh58PAw8YDIhTjj9VdWeaAopH1WMbOMvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.20462962962962963" data-type="png" data-w="1080" data-width="415" data-height="85" data-imgfileid="503530496" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/e7999ff4-89a7-4993-837c-44a593f29e31/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种设计带来两个优势：&lt;strong&gt;泛化性&lt;/strong&gt;（同一环境支持多种任务）和&lt;strong&gt;可扩展性&lt;/strong&gt;（无需为每个任务维护独立镜像）。例如，当扩展到数千个任务时，SWE 智能体可能需要高达 6TB 的存储空间用于任务特定镜像，而 LLM-in-Sandbox 仅需约 1.1GB 的共享镜像。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.2 最小化工具集&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究者为模型配备了三个基础工具：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;execute_bash：执行任意终端命令&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;str_replace_editor：文件的创建、查看和编辑&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;submit：标记任务完成&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这三个工具共同实现了电脑的核心能力，足以支撑复杂任务的完成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.3 探索式工作流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM-in-Sandbox 采用多轮交互的工作流：模型在每一轮生成工具调用，接收执行结果作为反馈，然后决定下一步行动，直到调用 submit 或达到最大轮次限制。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tM55rK64GjiawKOLzicnCFTVy4xpAfD3N2EbtiaP3h0W6bIGlPTc71Y8mg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5046296296296297" data-type="png" data-w="1080" data-width="415" data-height="209" data-imgfileid="503530497" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7ca271ab-3173-4c07-914a-9daccafaee29/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2.4 实验结果：无需训练的显著提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究者在六个非代码领域进行了实验：数学、物理、化学、生物医学、长文本理解和指令遵循。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tNmjJTgWnZUuajGibcYmujVgUDiboNuaiaU3Nf5n1vaAp6ENEbcF3qxxcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.687037037037037" data-type="png" data-w="1080" data-width="415" data-height="285" data-imgfileid="503530498" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/40743da3-5355-446b-b973-3ff34c0d1b48/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验结果表明，强大的语言模型在 LLM-in-Sandbox 模式下获得了一致性的提升。值得注意的是，这些提升完全无需额外训练：模型能够自发地利用沙盒环境来增强任务表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.5 涌现的工具使用能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究者通过案例分析揭示了模型如何自主利用沙盒的三大能力。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;外部资源访问&lt;/strong&gt;：在化学任务中，模型被要求根据化合物名称预测分子性质。为此，模型自主安装了 Java 运行环境，并下载了 OPSIN 库来将化学名称转换为分子结构，这些工具并非预装在基础环境中。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tBDBvAryz7nK3DMvcgwxgQsaz0u9VEEqyZEaicH4PjhXGSYyiaDGJgqpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.46111111111111114" data-type="png" data-w="1080" data-width="415" data-height="191" data-imgfileid="503530514" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e352a155-9d75-423f-a5da-84ab6a93a900/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文件管理&lt;/strong&gt;：在长文本理解任务中，面对超过 100K tokens 的行业报告，模型并未尝试在 prompt 中处理整个文档，而是使用 grep、sed 等 shell 工具定位相关段落，然后编写 Python 脚本系统性地提取信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tbmqLPP0KJVP00ibqGYKyUnfB7pOC0tqWQ040vyZyrwNge5bOILZIYng/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.575" data-type="png" data-w="1080" data-width="415" data-height="238" data-imgfileid="503530500" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/81ef982b-a4df-4d5e-ab95-859a569ae039/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;计算执行&lt;/strong&gt;：在指令遵循任务中，模型被要求生成三个满足严格约束的句子：所有句子必须具有相同的字符数，同时使用完全不同的词汇。模型编写了 Python 脚本来统计字符、检测词汇重叠，并迭代优化候选句子。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tbmqLPP0KJVP00ibqGYKyUnfB7pOC0tqWQ040vyZyrwNge5bOILZIYng/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.575" data-type="png" data-w="1080" data-width="415" data-height="238" data-imgfileid="503530501" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/abd3ca33-4a11-48fc-99c4-33f227157df3/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. LLM-in-Sandbox RL：通过强化学习增强泛化能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然强大的智能体模型能够直接受益于 LLM-in-Sandbox，但较弱的模型（如 Qwen3-4B-Instruct）往往难以有效利用沙盒环境，甚至表现不如纯 LLM 模式。&lt;/p&gt;&lt;p&gt;为此，研究者提出了&lt;strong&gt; LLM-in-Sandbox RL&lt;/strong&gt;：使用&lt;strong&gt;非智能体数据&lt;/strong&gt;在沙盒环境中训练模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.1 方法设计&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tqrgs07zDoQicRq5BgFLG0WsoCJa3zPoMrbetM9Gqx6GbUHOChsvJtJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.375" data-type="png" data-w="1080" data-width="415" data-height="155" data-imgfileid="503530502" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/e675e824-ffbd-4368-b115-7e85f5761394/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;核心思想是采用基于上下文的任务（context-based tasks）：每个任务包含背景材料和需要基于这些材料完成的目标。由于完成目标依赖于提供的材料，模型必须主动探索沙盒以找到相关信息，从而自然地学会利用沙盒能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.2 泛化能力&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tQIicSicgDpUhjFU3Fh4cxkoQ9s5CHuDERYc5icOxA6xybVU7JFIl61Ftg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5435185185185185" data-type="png" data-w="1080" data-width="415" data-height="225" data-imgfileid="503530503" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/1ed930ab-c5f9-4ec0-907e-162500d7e79e/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验在 Qwen3-4B-Instruct 和 Qwen3-Coder-30B-A3B 两个模型上进行。关键发现是&lt;strong&gt; LLM-in-Sandbox RL 展现出强大的泛化能力&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨领域泛化&lt;/strong&gt;：&amp;nbsp;训练数据来自通用领域，但模型在数学、物理、化学、长文本、指令遵循等多个下游任务上都获得了一致的提升，甚至在软件工程任务上也有改善。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨推理模式泛化&lt;/strong&gt;：有趣的是，LLM-in-Sandbox RL 不仅提升了沙盒模式的表现，还同时提升了纯 LLM 模式的表现。这说明在沙盒中学到的探索和推理能力可以迁移到非沙盒场景。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨模型能力泛化&lt;/strong&gt;： 无论是较弱的通用模型（Qwen3-4B-Instruct）还是较强的代码专用模型（Qwen3-Coder-30B-A3B），LLM-in-Sandbox RL 都能带来一致的提升，表明这一方法具有良好的模型通用性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;4. 效率分析：LLM-in-Sandbox 的实际部署价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.1 Token 消耗&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tzr7SrHicwGicxwnBVpHSwvPaXjsMPStgrNjdUBdS1GamMnhENaP6ZdDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.462037037037037" data-type="png" data-w="1080" data-width="415" data-height="191" data-imgfileid="503530504" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/eb5034a7-889f-47e8-901d-79044e40db36/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在长文本场景下，LLM-in-Sandbox 将文档存储在沙盒中而非放入 prompt，&lt;strong&gt;可将 token 消耗降低最多 8 倍&lt;/strong&gt;（100K &amp;rarr; 13K tokens）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.2 推理速度&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0thnzO7xoUedyqALMPuC6mg5zqSBSdwGw6eOS2eZfMh4af91dLvrurLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3194444444444444" data-type="png" data-w="1080" data-width="415" data-height="132" data-imgfileid="503530505" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b1474711-d944-49f1-88ad-9bfe8c955a46/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;通过将计算卸载到沙盒，LLM-in-Sandbox 将工作负载从慢速的自回归生成（decode）转移到快速的并行预填充（prefill)，在平均情况下保持有竞争力的吞吐量（QPM）：&lt;strong&gt;MiniMax 可实现 2.2 倍加速。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. LLM-in-Sandbox 超越文本生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前面的实验评估的是 LLM 和 LLM-in-Sandbox 都能完成的任务。然而，LLM-in-Sandbox 还能实现纯&lt;strong&gt; LLM 根本无法完成&lt;/strong&gt;的能力。通过给 LLM 提供虚拟电脑，LLM-in-Sandbox 突破了 text-in-text-out 的范式，解锁了新的可能性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨模态能力&lt;/strong&gt;：LLM 局限于文本输入输出，但 LLM-in-Sandbox 可以通过在沙盒中调用专业软件来处理和生成图像、视频、音频和交互式应用&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文件级操作&lt;/strong&gt;：不再是描述文件应该包含什么，而是直接生成可用的文件 &amp;mdash;&amp;mdash;.png、.mp4、.wav、.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自主工具获取&lt;/strong&gt;：不同于预定义的工具调用，LLM-in-Sandbox 使 LLM 能够自主发现、安装和学习使用任意软件库&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tR9cLVkc5jtHickcYAib7oPNMHTKyicXzZN416QTwzmhJAhHBpsSqicJkWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.7833333333333333" data-type="png" data-w="1080" data-width="415" data-height="325" data-imgfileid="503530506" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/980b8961-452d-4ffa-a7ff-280d4e0cfd97/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这些案例揭示了一个有前景的方向：随着 LLM 能力的增强和沙盒环境的完善，&lt;strong&gt;LLM-in-Sandbox 可能演化为真正的通用数字创作系统。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6. 总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM-in-Sandbox 提出了一个简洁而有效的范式：通过给大模型提供一台虚拟电脑，让其自由探索来完成任务。实验表明，这一范式能够显著提升模型在非代码领域的表现，且无需额外训练。&lt;/p&gt;&lt;p&gt;研究者认为，&lt;strong&gt;LLM-in-Sandbox 应当成为大模型的默认部署范式，取代纯 LLM 推理&lt;/strong&gt;。当沙盒可以带来显著的性能提升，并且部署成本几乎可以忽略不计时，为什么还要用纯 LLM？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Clawdbot接入10000+数据和工具后，7×24小时监听股票，杀疯了！</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 11:44:26 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;Clawdbot（现已更名为 Moltbot）在 AI 圈彻底火了。&lt;/p&gt;&lt;p&gt;这两天，我的朋友圈分裂成了两派人。&lt;/p&gt;&lt;p&gt;一派是还没用上 Clawdbot 的人，在疯狂转发部署教程。&lt;/p&gt;&lt;p&gt;另一派是用上 Clawdbot 的人。&lt;/p&gt;&lt;p&gt;但是，&lt;strong&gt;大部分人玩的，都是「玩具版」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Clawdbot 虽然能跑起来，但是不稳定、不聪明。因为没接专业数据源，只能做些基础对话，真正要干活时就抓瞎。&lt;/p&gt;&lt;p&gt;不过，今天我发掘了一个好东西。&lt;/p&gt;&lt;p&gt;现在，&lt;strong&gt;Teamo 平台竟然把 Clawdbot 接入了金融、商业、社媒等 10000 + 领域数据库和工具 Skills，用户可以一键认领自己的 Clawdbot 了！真正做到了 0 部署 0 配置&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfr8ud56yzYcia3bviaTsaqzqOybteicgHRNXla5J8kA5giaXQdF1MTlEqvA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.42592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530884" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b3e20c66-02cf-4d4d-9a10-3489ec9dc34a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;免费认领链接：https://teamoteam.com/t?a=clawdbot&lt;/p&gt;&lt;p&gt;如果你还不知道 Clawdbot，先来了解一下。&lt;/p&gt;&lt;p&gt;Clawdbot 是一个开源的 AI 助手，可以通过 WhatsApp、Telegram、Discord 等渠道与用户互动，国内可以接入飞书、企业微信。&lt;/p&gt;&lt;p&gt;它可以 7&amp;times;24 小时驻守在你的平台上，能监控市场、能回复消息、能提醒日常、能操作文件、能管理邮件，总之，就是你可以让它 7&amp;times;24 小时替你干活儿。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么说之前是玩具版？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你不对 Clawdbot 做特殊配制，它就只能调用大模型的通用能力，只能和它瞎聊。&lt;/p&gt;&lt;p&gt;因为 Clawdbot 只是提供了一个框架，&lt;strong&gt;没有专业数据源&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;你让它分析股票，它给你「根据公开信息」的模糊总结。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;你让它监控市场，它只能搜新闻。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;你让它做商业分析，它说「我需要更多数据」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;真正让 Clawdbot 有用的，是接入专业数据，比如同花顺、Wind 金融、同花顺，Amazon，arXiv，Pubmed，Alpha Advantage。所以市场上跑的快的团队已经发现这个问题！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Teamo + Clawdbot = YYDS&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，Teamo 平台上线了超级强化版本的 Clawdbot，狠狠的打通了 &lt;strong&gt;10000 +&lt;/strong&gt; 个专业数据库和工具 Skills，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;金融数据源（A 股、美股、港股实时行情）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;加密货币数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;社交媒体数据（Twitter、微博等）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;商业分析工具：企业工商信息，招投标，专利商标，行业报告&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;各类专业 API 接口&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf0YfCNawuq2l3tCn7KEb31PDXiaJCPS5zLU49ib5xHSTxXJuC4M41qyzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5194444444444445" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530885" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/cf1f3fc6-3171-48f1-a69b-53333a42d0d3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这些数据源，单独购买的话，一年成本轻松上万。&lt;/p&gt;&lt;p&gt;最最厉害的是，&lt;strong&gt;现在你可以直接「认领」一个配置好的 Clawdbot。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;0 部署、0 配置、开箱即用&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;你只需要在 Teamo 平台上点击「&lt;strong&gt;免费认领&lt;/strong&gt;」，就能立即获得一个属于自己的 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Clawdbot&lt;/span&gt; 实例。&lt;/p&gt;&lt;p&gt;不需要懂 Docker，不需要买服务器，不需要配任何环境变量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfhwSwCcNK37mjkBD4RQgib7dleU7UgVbhK3xwficNE7KjJPSzUoqgUR1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6046296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530886" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ec5b269b-6722-481b-8ebf-e9545fde904a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;免费认领链接：https://teamoteam.com/t?a=clawdbot&lt;/p&gt;&lt;p&gt;另外，据说 Clawdbot 实例资源有限，手慢无...&lt;/p&gt;&lt;p&gt;剩下的看你们了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真实场景上手：股票分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果自己手速慢了，没抢到，Teamo 官方还开放了一个 &amp;ldquo;公开版&amp;rdquo; 的 Clawdbot 给大家提供服务。&lt;/p&gt;&lt;p&gt;Teamo 官方把这个超级加强版的 Clawdbot 接进了飞书群里，在飞书群里 7&amp;times;24 小时待命，你随时撩拨。&lt;/p&gt;&lt;p&gt;这个 Clawdbot 会实时调用专业数据库，给你专业分析。&lt;/p&gt;&lt;p&gt;比如：「A 股的人工智能 ETF 技术面分析」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfpulMGF8B9WJEVNiaqZurIcLTVQ6ECSZ0tfJnKRveHC2kdZWkiaichezMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.3249027237354085" data-s="300,640" data-type="png" data-w="1028" type="block" data-imgfileid="503530887" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6a9bf3ab-c368-4e57-9e39-676cbe74a8f5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;再比如：「分析一下铜的走势」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfibdvdwl7apGH1icjlGyBciabfqibgljGEsvTaKhUn7bOTkuRK9ibgrNRQGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="2.275186567164179" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503530888" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/347456c9-6b9a-4551-83cf-dd065b3e723f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;再比如：&amp;ldquo;帮我分析一下宝钛股份最近的走势」&amp;rdquo;，&amp;ldquo;提醒我，如果中国平安跌破 50 元就通知我&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfhzx0Eq1tXQGGmMOibTKW8Y6ocRTd7ghrd7w1p8vNDBw2mibPNjrv0Lhg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="2.205761316872428" data-s="300,640" data-type="png" data-w="972" type="block" data-imgfileid="503530889" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4fd6092c-e68d-49b1-b05e-d60e66d77439/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;（以上仅为功能演示，不构成投资建议）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;彩蛋：支持 Skills&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Teamo 版 Clawdbot 不仅是一个专业版的 Clawdbot，还是一个增强版的 Clawdbot。 支持安装各种 Skills。&lt;/p&gt;&lt;p&gt;官方已经支持了几十个 Skills，包括编程场景、金融分析工具等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfouTTkbYbMLcSGrfI3DU8JwomWZbu6nMYMUZ9S1ELdBM8yRhvmzUpicw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530890" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3a2b7f16-406a-4690-8f7c-fbed49b79602/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;上线一个小时，光小红书社媒分析工具都已经有 10 个了...&lt;/p&gt;&lt;p&gt;真的是，用的人越多越强大啊...&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfAwpzGvMibMWvYAWyuY0NyVlRpINsZFt94y0CKoDQ2q0jCBxlWBliaNUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7861873226111636" data-s="300,640" data-type="png" data-w="1057" type="block" data-imgfileid="503530891" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/a17ab734-b2e3-4713-97f1-fad1272de626/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;比如你可以直接让它去搜索达人。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfZ92YeSiaQPejCw9qzSn8BBCBGzN81bLoCq0O2c3xAoKKUCL9IaoFDmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.2080200501253133" data-s="300,640" data-type="png" data-w="798" type="block" data-imgfileid="503530892" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/b470a915-3fc2-4afb-a694-a778dac59a0d/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然你也可以在群里直接告诉它，安装制定的 Skills。&lt;/p&gt;&lt;p&gt;&amp;ldquo;新建一个写作长文的 skills&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfiaoPkvuycib5RWiaeetpRrknnAxjNkmQnZ62b1zMg6TAE5NQVb9raIdwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.29074074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530893" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/84236e2a-280d-4948-9ef0-206c46b847c3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Teamo Clawdbot 可以立即创建技能，并且可以在 10 分钟后提醒你写小红书文案。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfjL8jSlkOyz9rVtIXAniaUtEW8ovKicEZpr7YNpYFyqDiaWTacKVpABxDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.1944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530894" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/4ef6f2fb-b9c0-4ed0-94ca-d6eac216f0a8/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;现在就可以体验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Teamo 版 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Clawdbot&lt;/span&gt; 现已开放认领通道。&lt;/p&gt;&lt;p&gt;无论你是想做金融分析、社交媒体运营、数据监控，还是单纯想体验一下「AI 主动工作」的感觉，都可以来试试。&lt;/p&gt;&lt;p&gt;认领链接：https://teamoteam.com/t?a=clawdbot&lt;/p&gt;&lt;p&gt;没领到的，也可以添加 Teamo 官方的 Clawdbot 飞书体验群，成为朋友圈里第一个用上 Clawdbot 的人。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfzr70v5jVcMBwYToFTVibT67BSCrbRgrO7zib7avWPWzyCPP4NShH0cyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.7142857142857143" data-type="png" data-w="483" data-imgfileid="503530900" data-aistatus="1" data-original-style="width: 419px;height: 299px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/3a61baa3-8ab7-4e79-9dd1-abd3e61443e9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>商汤开源SenseNova-MARS，突破多模态搜索推理天花板</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 30 Jan 2026 10:44:43 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;今日，商汤正式开源多模态自主推理模型 SenseNova-MARS（8B/32B 双版本），其在多模态搜索与推理的核心基准测试中以 69.74 分超越Gemini-3-Pro（69.06 分）、GPT-5.2（67.64 分）。&lt;/p&gt;&lt;p&gt;SenseNova-MARS是&lt;strong&gt;首个支持动态视觉推理和图文搜索深度融合的&amp;nbsp;Agentic&amp;nbsp;VLM&amp;nbsp;模型&lt;/strong&gt;，它能自己规划步骤、调用工具，轻松搞定各种复杂任务，让AI真正具备&amp;ldquo;执行能力&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在MMSearch、HR-MMSearch、FVQA、InfoSeek、SimpleVQA、LiveVQA等基准测试中，SenseNova-MARS取得开源模型中的&lt;strong&gt;&amp;nbsp;SOTA 成绩，&lt;/strong&gt;&lt;strong&gt;还&lt;/strong&gt;&lt;strong&gt;超越Gemini-3&lt;/strong&gt;&lt;strong&gt;.0&lt;/strong&gt;&lt;strong&gt;-Pro&lt;/strong&gt;&lt;strong&gt;、&lt;/strong&gt;&lt;strong&gt;GPT-5&lt;/strong&gt;&lt;strong&gt;.2&lt;/strong&gt;&lt;strong&gt;等顶级闭源模型&lt;/strong&gt;，在搜索推理和视觉理解两大核心领域全面领跑。&lt;strong&gt;更多&lt;/strong&gt;&lt;strong&gt;细节请参见技术报告&lt;/strong&gt;（https://arxiv.org/abs/2512.24330），欢迎开发者、各行业用户测试与体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全能冠军&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;strong&gt;自主&lt;/strong&gt;&lt;strong&gt;解决复杂&lt;/strong&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS在多项多模态搜索评测中展现出明显的领先优势，平均得分达到 69.74 分，成功超过了 Gemini-3-Pro 的 69.06 分与 GPT-5.2 的 67.64 分。&lt;img src="https://image.jiqizhixin.com/uploads/editor/054c9722-7258-4699-b553-6ff4def2a92c/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;在 MMSearch 榜单（图文搜索核心评测）中，模型以 74.27 分登顶，超GPT-5.2（66.08 分）；HR-MMSearch（高清细节搜索评测）中&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;以&lt;/em&gt;&lt;em&gt;54.43 分领先，显著拉开与闭源模型的差距&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/67abeb0c-435f-4bdb-9da5-2bbe2a5a2e89/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;HR-MMSearch&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;的测试&lt;/em&gt;&lt;em&gt;题目堪称&amp;ldquo;AI界的奥林匹克&amp;rdquo;&lt;/em&gt;&lt;em&gt;：采&lt;/em&gt;&lt;em&gt;用305张2025年最新的4K超高清图片，确保AI无法依赖旧知识&amp;ldquo;作弊&amp;rdquo;；所有问题都针对图片中占比不到5%的细节，比如小标志、小字、微小物体，必须用图像裁剪工具才能看清；覆盖体育、娱乐文化、科学技术、商业金融、游戏、学术研究、地理旅行等&lt;/em&gt;&lt;em&gt;八&lt;/em&gt;&lt;em&gt;大领域，&lt;/em&gt;&lt;em&gt;60%的&lt;/em&gt;&lt;em&gt;问题&lt;/em&gt;&lt;em&gt;都&lt;/em&gt;&lt;em&gt;需要至少&lt;/em&gt;&lt;em&gt;使用三&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;种工具才能解答。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;简单说，无论是需要&amp;ldquo;查遍全网&amp;rdquo;的知识密集型任务，还是需要&amp;ldquo;火眼金睛&amp;rdquo;的细粒度视觉分析，它都是当前的&amp;ldquo;全能冠军&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用&lt;/strong&gt;&lt;strong&gt;组合拳&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;strong&gt;解决&lt;/strong&gt;&lt;strong&gt;真实场景&lt;/strong&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS还能实实在在落地到我们生活和工作的场景，解决需要&amp;ldquo;多步骤推理+多工具协作&amp;rdquo;的问题。&lt;/p&gt;&lt;p&gt;普通AI的工具调用，要么只能搜文字，要么只能看图片，遇到需要&amp;ldquo;先放大细节、再识别物体、最后查背景&amp;rdquo;的复杂任务就束手无策。&lt;img src="https://image.jiqizhixin.com/uploads/editor/2ab9ffe0-8e9b-4ac1-9140-15cd4df5d910/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;面对识别赛车服微小&amp;nbsp;&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;L&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;ogo + 查询公司成立年份 + 匹配车手出生年月 + 计算差值&amp;rsquo;的复杂任务，SenseNova-MARS 可自主调用图像裁剪、文本 / 图像搜索工具，无需人工干预完成闭环解答。&lt;img src="https://image.jiqizhixin.com/uploads/editor/4cd36172-20aa-4fad-8de8-b08e96943a79/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;SenseNova-MARS能&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;从&lt;/em&gt;&lt;em&gt;产品和&lt;/em&gt;&lt;em&gt;行业峰会&lt;/em&gt;&lt;em&gt;的&lt;/em&gt;&lt;em&gt;照片中，识别企业的标志，快速搜集&lt;/em&gt;&lt;em&gt;产品、&lt;/em&gt;&lt;em&gt;企业&lt;/em&gt;&lt;em&gt;的信息，以及&lt;/em&gt;&lt;em&gt;时间&lt;/em&gt;&lt;em&gt;、数量、参数等细节要素&lt;/em&gt;&lt;em&gt;，辅助分析行业&lt;/em&gt;&lt;em&gt;情况和&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;格局。&lt;img src="https://image.jiqizhixin.com/uploads/editor/edce7081-8c9a-4776-b485-e42227cb4477/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;SenseNova-MARS能从赛事照片中识别画面中的Logo、人物等信息，追溯比赛或人员背景信息，帮助快速补充重要细节。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1744d5a0-5f2b-4c7e-b64f-9b68ee23f38a/%E5%9B%BE%E7%89%876.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;SenseNova-MARS甚至能够轻松处理，这类超长步骤的多模态推理，和超过三种工具调用，自动裁剪分析细节、搜索相关研究数据，快速验证假设，得出关键判断。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;拥有这种&amp;ldquo;自主思考+多工具协作&amp;rdquo;的能力，SenseNova-MARS能够自动解决&amp;ldquo;细节识别 + 信息检索 + 逻辑推理&amp;rdquo;复杂任务，帮助实现工作效率提升。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;图像裁剪&lt;/strong&gt;：能精准聚焦图片上的微小细节，哪怕是占比不到5%的细节&amp;mdash;&amp;mdash;比如赛车手衣服上的微小Logo、赛事照片里观众席的标语，都可通过裁剪放大清晰分析。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;图像搜索&lt;/strong&gt;：能在看到物体、人物或场景，的瞬间自动匹配相关信息&amp;mdash;&amp;mdash;比如识别出赛车手的身份，或是某款冷门设备的型号。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;文本搜索&lt;/strong&gt;：能快速抓取精准信息&amp;mdash;&amp;mdash;无论是公司成立年份、人物出生年月，还是最新的行业数据，都能秒级获取。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从练中&lt;/strong&gt;&lt;strong&gt;学，&lt;/strong&gt;&lt;strong&gt;形成&amp;quot;直觉&amp;quot;和&amp;quot;经验&amp;quot;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS采用了&amp;ldquo;因材施教&amp;rdquo;的训练方法。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;第一阶段：打基础&lt;/strong&gt;。针对跨模态多跳搜索推理训练数据稀缺的痛点，创新性的提出了基于多模智能体的自动化数据合成引擎，采用细粒度视觉锚点 + 多跳深度关联检索的机制，动态挖掘并关联跨网页实体的逻辑，自动化构建高复杂度的多跳推理链路，同时引入闭环自洽性校验来去除幻觉数据，构造出具备严密逻辑链条与高知识密度的多跳搜索问答数据。用精心筛选的&amp;ldquo;高难度案例&amp;rdquo;做教材，每个案例都标注了&amp;ldquo;该用什么工具、步骤是什么&amp;rdquo;，让AI先学会基本的&amp;ldquo;破案逻辑&amp;rdquo;。这些案例都是从海量数据中挑出的&amp;ldquo;硬骨头&amp;rdquo;，确保AI一开始就接触真实复杂场景。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;第二阶段：练实战&lt;/strong&gt;。采用&amp;ldquo;强化学习&amp;rdquo;&amp;mdash;&amp;mdash;就像侦探在一次次破案中积累经验，AI每做对一次决策（比如选对工具、步骤合理）就会获得奖励，做错了就调整策略。为了避免AI&amp;ldquo;学偏&amp;rdquo;，研究团队还加了个&amp;ldquo;稳定器&amp;rdquo;&amp;mdash;&amp;mdash;BN-GSPO算法，让它在处理简单题和复杂题时都能保持稳定进步，不会出现&amp;ldquo;偏科&amp;rdquo;。这种基于双阶段归一化的优雅机制有效平滑了动态工具调用返回分布多样性带来的优化波动并确保了学习信号分布的一致性，从而成功解决了跨模态多步多工具智能体训练过程中的收敛性难题。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;经过这样的训练，AI不仅学会了用工具，更培养&amp;quot;工具使用直觉&amp;quot;&amp;mdash;&amp;mdash;知道在什么情况下应该使用哪些工具，以及如何将不同工具的结果有机结合起来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型、代码、数据全开源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;商汤日日新SenseNova-MARS模型、代码、数据集全开源，支持 Hugging Face 直接下载。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Github 仓库：&lt;/strong&gt;&lt;a href="https://github.com/OpenSenseNova/SenseNova-MARS"&gt;&lt;u&gt;https://github.com/OpenSenseNova/SenseNova-MARS&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型仓库：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;32B：&lt;a href="https://huggingface.co/sensenova/SenseNova-MARS-32B"&gt;&lt;u&gt;https://huggingface.co/sensenova/SenseNova-MARS-&lt;/u&gt;&lt;u&gt;32&lt;/u&gt;&lt;u&gt;B&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;8B&lt;a href="https://huggingface.co/sensenova/SenseNova-MARS-8B"&gt;&lt;u&gt;https://huggingface.co/sensenova/SenseNova-MARS-8B&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术报告：&lt;/strong&gt;&lt;a href="https://arxiv.org/abs/2512.24330"&gt;&lt;u&gt;https://arxiv.org/abs/2512.24330&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，创智+模思发布开源版Sora2，电影级音视频同步生成，打破闭源技术垄断</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 29 Jan 2026 18:59:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-29-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-29-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南、Panda&lt;/section&gt;&lt;p&gt;今天上午，上海创智学院 OpenMOSS 团队联合初创公司模思智能（MOSI），正式发布了端到端音视频生成模型 &amp;mdash;&amp;mdash; &lt;strong&gt;MOVA（MOSS-Video-and-Audio）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;作为&lt;strong&gt;中国首个高性能开源音视频模型&lt;/strong&gt;，MOVA 实现了真正意义上的「音画同出」。它不仅能生成长达 8 秒、最高 720p 分辨率的视听片段，更在多语言口型同步、环境音效契合度上展现了极高的工业水准。&lt;/p&gt;&lt;p&gt;更具行业意义的是，在 Sora 2 和 Veo 3 等顶尖技术普遍走向闭源的当下，MOVA 选择将模型权重、训练代码、推理代码以及微调方案进行全栈开源。&lt;/p&gt;&lt;p&gt;它生成视频的效果，给人一种身临其境的真实感：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fffa3d0e-3d0e-46ba-add1-5b40144e4393/1769683950741.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;GitHub: https://github.com/OpenMOSS/MOVA&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页: https://mosi.cn/models/mova&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;效果亮眼 &amp;nbsp;可称开源最强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去一年，视频生成模型（Video Generation）经历了爆发式增长。从 Sora 到 Wan，再到 LTX Video，AI 输出的画面越来越逼真，能生成的时间越来越长。但仔细观察 AI 生成的视频你就会发现，这些视频有的是「哑巴」，有的配音出戏。音视频生成（Video-Audio Generation）模型正是通过端到端的模态融合弥补了传统视频模型的音频维度缺陷。&lt;/p&gt;&lt;p&gt;虽然以 Veo3 为代表的音视频端到端模型展示了极高的生成上限，但是其闭源的策略造成了严重的技术垄断，割裂了技术生态的连贯性，也让社区难以通过协作改进模型缺陷（如幻觉、不同步等），导致音视频生成领域缺乏像 LLM 时代那样的「开源爆发式」演进。&lt;/p&gt;&lt;p&gt;为了推倒这堵墙，让音视频生成能力真正回归社区，&lt;strong&gt;MOVA&lt;/strong&gt; 应运而生。它具备高质量的端到端音视频生成能力，完整开源了 360p、720p 两个基础模型，以及包括微调、推理、生成工作流在内的全链路组件，补全了音视频生成基础模型的开源拼图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;电影级别物理智能：音与画的共振&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在物理仿真层面，MOVA 展现了极其出色的「物理直觉」。在这里，声音是具备空间感与质感的环境反馈，而不仅仅是可有可无的音效。&lt;/p&gt;&lt;p&gt;当一辆 SUV 在沙漠中高速掉头时，漫天飞舞的狂沙不仅在视觉上极具冲击力，音轨中同步生成的马达轰鸣声与配乐紧密交织，营造出极强的速度感：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ca13bdd9-785a-408d-abcf-c2387162ccd3/1769683979877.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：一辆 SUV 在沙漠里奔驰，并打方向盘掉头，狂沙飞舞，配上激动人心的音乐，并听到马达轰鸣声。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这种声画逻辑在复杂的巷战模拟中更为突出：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fba636de-0b6d-43f1-8b46-87e779a0ff32/1769684016838.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;360p 模型生成，提示词：在阴天漫射光下的城市巷道中，多名穿沙色迷彩的武装人员保持固定防御队形：左前跪姿射手持续向左侧射击，左中射手掩护，右侧两到三名队员贴墙半蹲警戒，尘土飞扬、电线密集、街道纵深明显，固定稳定中景偏广机位、纪录片式电影写实质感、低饱和灰黄色调与轻微颗粒，短促橙色枪口火光但曝光稳定，音频包含密集近距枪声、子弹掠过与击中声、街区混响、装备摩擦与急促呼吸，人物、站位与构图始终不变。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这种对物理动态的捕捉同样体现在日常生活场景中。比如在下面的例子中，本・斯蒂勒在公路上滑滑板，随着他左右摇摆加速，耳边会传来风掠过路面的呼啸声，可以说相当好地还原了他在《白日梦想家》中的经典场景。&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bd882351-2157-4a8d-aa11-f122b4b5c508/1769684032129.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面是一名穿着红色上衣、灰色裤子的男子在空旷的公路上滑板的场景，公路周边是草地和低山。男子通过左右摇摆的方式不断加速，展开手臂沿着公路不断滑行。背景声音为高速滑行时风吹过的呼啸声。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;电影级别的口型同步能力：精准捕捉叙事灵魂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOVA 另一大突破在于其电影级别的口型同步（Lip-sync）能力。它能够根据中英文指令，生成与语义、情感高度契合的多人物谈话场景。比如下面的公园散步视频中，对话的衔接极其自然：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/669bd1b3-183a-489a-b55f-da3a98b44d8c/1769684049711.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面中是一个男子和孩子在公园中散步的场景。男子转过头疑惑地问孩子说：&amp;ldquo;你长大想要干什么？&amp;rdquo; 男孩一脸自信地回答：&amp;ldquo;债券交易员。唐恩就是做这个的，他带我去过他的办公室&amp;rdquo;。男子笑了笑，回答道：&amp;ldquo;是一个不错的职业。&amp;rdquo;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;MOVA 也能流利地说英语，下面就还原了《王牌特工：特工学院》中「看到西装男人别去惹他，你打不过他的」的经典名场面。这里可以看到，人物的口型、表情与语调的变化严丝合缝，告别了以往 AI 视频中的「对口型感」。&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/91eaf311-1ad6-4a19-9514-45df4093cff6/1769684066040.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面中是在一处英国大街上发生的谈话，背景包含了西欧风格的建筑物、电线杆和一面英国的国旗。画面左边穿着灰色西装、戴着墨镜的男子说道：&amp;ldquo;成为绅士和口音毫无关系，真正的高贵在于超越自我。&amp;rdquo; 右边穿着黄黑色夹克、戴着白色帽子的青年脸色逐渐严肃地回答道：&amp;ldquo;我记住了。&amp;rdquo; 随后陷入了沉思。（原提示词为英文）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;涌现出来的进阶能力：视频文字生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;有意思的是，在提升 MOVA 模型口型精度和语音能力的过程中，OpenMOSS 团队还收获了一个「意外之喜」：文字生成能力&lt;/p&gt;&lt;p&gt;MOVA 能够生成视频中的文字内容。比如下面这个例子，虽在「快」这里还有些瑕疵，但整体效果已超越了很多前沿闭源模型，表现令人相当满意。&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/333e69f1-e22b-4255-8a99-46efdd474627/1769684085198.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面开始于创智学院宽敞而对称的中庭，日光透过透明的玻璃天窗洒落下来。镜头沿着中轴线缓缓向前移动，空间逐渐发生变化，光线化作细小的粒子向上飘散，空中浮现出若隐若现的数据流与抽象的智慧图形。天窗之外的天空逐渐转化为深邃的星空，仿佛整座建筑与宇宙连通。随着镜头推进，玻璃与植物微微发光，整个大厅呈现出安静而充满想象力的未来氛围。画面接近尾声时，所有光芒在中央汇聚，形成闪耀着星光的文字：&amp;ldquo;上海创智学院祝您 2026 年元旦快乐！&amp;rdquo; 神秘而震撼的电子配乐始终伴随画面，在文字出现时略微收束。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;作为对比，Veo 3.1 使用同样提示词的结果是这样的：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8a4e2ec-9825-4f85-8708-1971c12c8698/1769684099268.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;在惊艳的效果背后，更加值得关注的是 MOVA 模型的一体化架构。下面我们就来系统性地看看 MOVA 背后的技术。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;背后的技术 &amp;nbsp;从模态孤岛到端到端共鸣&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;全球音视频生成 AI 模型正处于一个从「纯视频生成」向「音视频端到端生成」（Native Video-Audio Generation）跨越的关键时期，视频生成 AI 模型的优先目标已不再仅仅是更拟真的画面，而是声音与视觉的完美共鸣。&lt;/p&gt;&lt;p&gt;在音视频生成问题上，传统的解决方案是「级联流水线」：先生成无声的视频，再通过 Video-to-Audio 模型配音；或者先有语音，再驱动画面。这种「拼凑」感导致了音画割裂 &amp;mdash;&amp;mdash; 爆炸声可能比火光慢半拍，人物口型由于缺乏底层交互而显得僵硬。&lt;/p&gt;&lt;p&gt;对此，OpenMOSS 团队决定挑战最为困难，但效果更好的音视频端到端生成模式。&lt;/p&gt;&lt;p&gt;他们针对音视频生成任务专门构建了一个基础模型 MOVA（MOSS Video and Audio），其不仅能合成与视频同步的语音，也能精准地合成环境音效。从名字也能看出来，该模型属于模思智能的 MOSS 系列 &amp;mdash;&amp;mdash; 此前已有文本到对话生成模型 MOSS-TTSD、语音到语音生成模型 MOSS-Speech 以及多说话人语音识别模型 MOSS-Transcribe-Diarize。&lt;/p&gt;&lt;p&gt;MOVA 是一个规模约 320 亿参数（MoE 架构，推理时激活 180 亿参数）的模型，支持图像 - 音视频和文本 - 音视频的处理方式。&lt;/p&gt;&lt;p&gt;具体技术上，OpenMOSS 团队进行了模型架构、数据工程、训练策略等多方面的创新，验证了音视频大模型的规模化趋势与性能提升。&lt;/p&gt;&lt;p&gt;下面我们就来看看 MOVA 是如何炼成的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;异构双塔与跨模态时间对齐&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对音频和视频两个模态本身的信息密度，MOVA 巧妙地搭建了一套非对称双塔架构，结合了大尺寸的预训练&lt;strong&gt;视频塔&lt;/strong&gt;和小尺寸的预训练&lt;strong&gt;音频塔&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;具体来说，OpenMOSS 团队采用了 14B 参数的 Wan 2.2 I2V 作为视频骨干网络（用于图像 + 文本条件的 I2VA），并预训练了 1.3B 的文本到音频扩散模型作为音频骨干网络。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5WVSXI0iaRrtPpSIBSNnicBxAaWMibg8IjFsM18tP1zlEIHXsbbUenktA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530872" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ee40cd36-14f8-43e6-8f8b-5cccbb1aa889/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;MoVA 通过一个双向桥接模块将一个 A14B 视频 DiT 主干网络与一个 1.3B 音频 DiT 主干网络耦合在一起，实现模态融合与交互&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在这两座「塔」之间，团队引入了一个&lt;strong&gt;双向桥接模块（Bridge）&lt;/strong&gt;。这个模块的存在，让视频与音频的隐藏状态在每一层都能进行深度的交叉注意力运算。这意味着画面在生成的每一瞬间，图像都在感知声音的节奏，而音频也在捕捉画面的光影。&lt;/p&gt;&lt;p&gt;然而，音视频的物理属性天然互斥。视频通常以每秒 24 帧的频率离散存在，而音频信号的密度则要高出几个量级。为了防止两者在生成过程中产生时间轴上的「漂移」，团队设计了 &lt;strong&gt;Aligned ROPE（对齐旋转位置嵌入）&lt;/strong&gt;机制。通过精确的缩放比例映射，视频与音频的 Token 被巧妙地放置在了同一个物理时间尺度上，避免了音频和视频模态的天然不对齐。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多阶段细粒度数据管线&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;成功的模型根基于架构，更离不开数据。多阶段的高质量音视频数据处理管线是 MOVA 成功规模化的保障。&lt;/p&gt;&lt;p&gt;为了把海量数据真正转化为模型训练真正用得上的知识，OpenMOSS 团队构建了一套涵盖三阶段的精细化管线。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazffzOJbdFnWPRU485TqUUmkDL1Up4FVypVLiaXTxficEsQW94trVEtuIhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5472222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530869" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5771d79c-b664-4cda-9ce5-8c9abfbf7933/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;三阶段的数据处理流程：第一阶段，将原始数据预处理为固定长度的视频片段，分辨率为 720p，帧率为 24fps，时长为 8.05 秒。第二阶段，根据音频质量、视频质量以及音视频同步性对这些片段进行筛选，以获得高质量且同步的视频片段。第三阶段，分别使用音频理解模型和视觉理解模型对视频中的音频和视觉信息进行单模态标注，并最终利用大语言模型将这些单模态描述进行融合，形成细粒度音视频描述。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;相比于传统的视频数据处理管线，MOVA 提出的管线尽可能多地保留了原始音视频数据，减少了裁剪和丢弃，并且通过细粒度的标注避免不同类型和质量的数据之间互相影响，使得模型具备了复杂场景泛化的潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多阶段规模化策略&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;音视频生成的大规模训练是一项计算量非常大的任务，在大规模训练过程中，MOVA 团队展现了敏锐的工程直觉，设计了三阶段由粗到细的训练策略。首先，为了平衡随机初始化的 Bridge 模块与已经具备强大预训练先验的双塔，他们采用了异构学习率的策略。Bridge 模块的学习率被设为两倍于骨干塔，从而加快 Bridge 模块的参数更新效率，取得比较快的初步收敛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf4NgeCfWIibjSMJ5rdMmtynMlqSPSmSIxjQ870No5q58ibVC7pmaL673A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530877" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/782a4d46-d754-4ebb-9aef-65e2312e1687/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 不同训练阶段口型同步指标随着训练步数的持续下降趋势&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了提升训练效率，MOVA 将训练过程分为了三个阶段，&lt;strong&gt;360P 训练、360P 退火训练&lt;/strong&gt;以及&lt;strong&gt; 720P 训练&lt;/strong&gt;，并持续监控口型同步指标随着训练步数增长的变化。更有趣的创新在于 &lt;strong&gt;Dual Sigma Shift（双模态噪声偏移）&lt;/strong&gt;。对于音视频双模态联合去噪的模型，业界并没有明确最优的加噪方案，由于音频和视频模态天生的特性，使用同样的噪声偏移不一定能达到最优的学习效果，可能会导致隐式的模态依赖。基于这个猜测以及先前的研究工作，因此，MOVA 在第一阶段训练中对于音频和视频模态使用了不同的 Sigma Shift 进行加噪，希望避免可能出现的隐式模态依赖。&lt;/p&gt;&lt;p&gt;具体来说，一开始的 Stage 1 用的是 360p 的低分辨率，本质目标不是追求画面细节，而是让模型尽快学会「音频和嘴型应该怎么对齐」。因为 Bridge 是随机初始化的，如果一开始就追求高画质，很容易学不稳或者学偏。所以这里故意让视频端去更激进地去噪，音频端相对平滑，再配合比较高的文本 dropout，让模型不得不依赖音频和视觉之间的桥接关系来建立对齐能力。你可以从曲线看到，虽然一开始误差还有点波动，但整体 LSE-D 很快下降、LSE-C 明显上升，说明模型逐步抓住了嘴型同步的基本规律。&lt;/p&gt;&lt;p&gt;进入 Stage 2 之后，分辨率仍然是 360p，但重点从「学会对齐」转为「把对齐质量拉高、稳定下来」。这里把音频和视频的噪声调度对齐起来，本质是在时间尺度上让两种模态更加同步，这样跨模态注意力会更稳定；同时降低文本 dropout，让文本重新参与细化语义和细节，而不是完全靠音视频对齐硬学；再通过响度归一化避免 CFG 带来的音量失真。你能看到在这一段，LSE-D 继续缓慢下降，LSE-C 有一个明显跃升，说明模型不只是「能对上」，而是「对得更自信、更一致」。&lt;/p&gt;&lt;p&gt;最后的 Stage 3 才真正把分辨率拉到 720p，这一步更像是「高清重制」。此时模型已经具备稳定的跨模态对齐能力，所以可以安全地把算力用在更高分辨率和更细致的空间建模上，而不会破坏之前学到的嘴型同步结构。为了应对高分辨率带来的显存和收敛速度变化，引入了更细粒度的 checkpoint 和更激进的并行优化策略。从曲线看，这一阶段 LSE-D 进一步压低并趋于平台，LSE-C 稳定在较高水平，说明性能已经进入收敛区间，更多是在做质量的精修。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 工作流 &amp;nbsp;让模型更好理解需求&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;拥有了高性能的基模，并不意味着能直接产出完美的视听大片。在 MOVA 的实际部署中，研发团队设计了一套 Agent 工作流，以适应不同粒度和风格的用户输入，最大程度激发模型能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三阶段协同工作流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决视频生成中常见的「描述与视觉不一致」问题 &amp;mdash;&amp;mdash; 即当用户文本与初始帧存在细微偏差时，生成过程容易偏离首图先验并误解用户意图 &amp;mdash;&amp;mdash;MOVA 并未让基模单独承担对齐压力，而是设计了一套三阶段生成流程，将理解、改写与生成分工协作，显著提升首帧一致性与指令遵循能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfSn10YQPcMgqt8tgtpmkdfW80hM6UBj75QGakKjfsLNCNibmtQdP4cUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5425925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530871" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/623a8a1f-2d14-44d8-a86a-0945430c8640/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;三阶段 Agent 工作流，赋予 MOVA 产品级理解能力，更好的处理更加原始、多样的用户需求。&lt;/sup&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉解析&lt;/strong&gt;：系统首先通过 Qwen3-VL 对用户提供的初始图进行结构化解析，将画面的色彩基调、构图信息、核心主体与文字元素抽取为可执行的视觉约束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;提示词重构&lt;/strong&gt;：在视觉约束与用户原始指令共同输入下，借助通用 LLM（如 Gemini）进行上下文示例驱动的提示词重写，将需求转译为更贴近训练分布、具备动态叙事的生成提示词。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;双重条件生成&lt;/strong&gt;：最后，MOVA 结合重写后的提示词和初始帧图像进行「双重条件生成」，使视频在产生运动与变化的同时，最大化保持首帧图的视觉风格与关键元素，并更好地对齐用户意图。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这种多模型协同的思路，让 MOVA 不仅仅是一个基模，更像是一套成熟的视听内容生产系统。&lt;/p&gt;&lt;p&gt;除此之外，MOVA 也展现出扎实的纯文本音视频生成能力：即使不提供真实首帧，用户仅需输入文本，系统会自行传入一张纯色占位图作为初始条件，并生成音画同步、观感统一的高质量视频，从而降低素材门槛，让「零素材创作」成为可能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;双重 CFG：在画质与对齐间寻找平衡&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在推理逻辑的底层，OpenMOSS 团队引入了&lt;strong&gt;双重 Classifier-Free Guidance (Dual CFG)&lt;/strong&gt; 公式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfTw46yeEm5R7BE2oe6MQlhcafWicyXzzS0DlUf5d4xv7icQOLWpNF7wFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.151033386327504" data-s="300,640" data-type="png" data-w="629" type="block" data-imgfileid="503530873" data-aistatus="1" data-original-style="width: 377px;height: 57px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/87c089f8-1e79-4e13-8ae7-e7f5e4b6d11d/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在传统的视频生成中，CFG 往往只服务于「让画面更像描述」。但在音视频联合生成任务中，存在文本指令和模态桥接（Bridge）两个控制源。如果盲目追求提示词契合度，往往会牺牲音画同步率；反之亦然。&lt;/p&gt;&lt;p&gt;MOVA 允许用户根据场景调整这两者的权重：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在一般的生成任务中，侧重文本引导以保证画质和意图实现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在对话、演讲等「口型敏感」场景下，则通过强化模态桥接的引导力，实现毫秒级的对齐精度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对高强度引导可能带来的「音量爆炸」和波形畸变，MOVA 还内置了 LUFS 响度归一化算法，将输出音频强制修正至 -23 dB 的广播级标准，确保了即便在极端推理参数下，声音依然清晰自然。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验表现 &amp;nbsp;打破闭源巨头的技术垄断&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证 MOVA 的视听对齐能力，OpenMOSS 团队将其与目前开源社区最顶尖的两个项目 LTX-2 和 Ovi，以及「WAN 2.1 + MMAudio」这一传统级联方案进行了全方位对比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最佳的口型精度&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf2IvD0GVgUW3vZ7J1Ullkc0Gp29lFhDuZnFXa0L41eWyrVe3FF2aEaw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.3592592592592593" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503530874" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/04952c91-b39c-4406-84f5-2101ab7b7e26/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 Verse-Bench 上的视听生成性能的量化比较。Audio 和 AV-Align 指标是在所有子集上进行评估的；Lip Sync 和 Speech 指标是在 Verse-Bench set3 上进行评估的；ASR Acc 是在团队提出的多说话人子集上进行评估的。加粗和下划线的数值分别表示最佳和第二佳结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在最能拉开差距的口型同步（Lip-sync）任务中，MOVA 展现出了明显的优势。根据 Lip Sync Error 指标，在开启 Dual CFG 模式后，MOVA-720p 的 LSE-D 得分为 7.094，LSE-C 得分为 7.452。其次，在反应语音准确度和说话人切换准确度的 cpCER 指标上，MOVA 也取得了最佳的结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;竞技场真实评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;考虑到当前音视频生成模型的客观评价体系仍不够完善，MOVA 引入了竞技场（Arena）人为主观评测范式，包含了全球最新的开源音视频生成模型，累计获得 5000 次有效投票并对结果进行了系统统计。评测结果显示，MOVA 生成内容在整体偏好上保持领先：其在对战中更频繁获得用户选择，ELO 评分达到了 1113.8（初始分 1000），显著高于各基线模型；并稳定保持超过 50% 的胜率，其中面对 OVI 和级联系统（WAN+MMAudio）的胜率更是超过了 70%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfHAEt0fmSape3DnP7rMiaVqcfGRPYehbOkwprkiaibUiblqibCaPPGZtrcUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7981481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530875" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/aea9d7e9-7b76-4246-a195-24c29ab1a294/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfm1c2JyzYyOpmaJFOGYP1yuBFDJwSJkHzVnLNLJn21cWs7ia1YjdNbFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.38796296296296295" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530876" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/88fd8880-9ddf-49b7-b956-5f1fc452f548/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;开源突围与国产生态 &amp;nbsp;补全多模态拼图&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOVA 的出现对于音视频生成 AI 方向有着重要意义。目前全球范围内，处于第一梯队、被大众或行业认可的模型，如我们耳熟能详的 Sora 2、Veo 3、Kling 2.6、Runway Gen-3 等，绝大多数是闭源的，它们甚至仅向小部分付费用户开放；而在开源的另一边，Wan 2.1、HunyuanVideo 等模型着重于纯视频生成的质量，支持端到端音视频的较少。&lt;/p&gt;&lt;p&gt;MOVA 的出现，改变了「领先技术不开源」的现状。&lt;/p&gt;&lt;p&gt;作为中国首个高性能开源音视频模型，MOVA 通过全栈开源的方式，将训练代码、推理代码、模型权重以及微调代码全部公开。这意味着，开发者不仅可以用 MOVA 生成视频，也能深入底层，理解双塔 Diffusion 架构如何处理多模态数据的交互，甚至在此基础上训练出垂直领域的专用模型。&lt;/p&gt;&lt;p&gt;MOVA 支持了 SGLang 等主流高性能推理框架。其 360p 版本更加面向于较低的硬件门槛，让音视频生成不再是仅限于 GPU 集群的奢侈游戏。在整个音视频生成领域趋向于闭源的大环境下，MOVA 的出现是一次开源社区的突围，它补全了中国音视频生成基模的开源版图，或许能够驱使音视频生成领域走向开源共创。&lt;/p&gt;&lt;p&gt;在 MOVA 音视频大模型的研发进程中，昇腾AI提供了全栈算力支撑，助力MOVA完成了从数据标注到预训练验证的关键环节。目前，MOVA 已成为昇腾首个支持的开源多模态音视频一体生成模型，微调与推理功能已同步上线社区。&lt;/p&gt;&lt;p&gt;MOVA 的发布，距离模思智能上一款引发行业热议的语音识别模型 &amp;mdash;&amp;mdash;MOSS-Transcribe-Diarize 仅仅过去了 20 多天的时间。而 MOSS-Transcribe-Diarize，也在 MOVA 的快速迭代中发挥了关键作用。&lt;/p&gt;&lt;p&gt;如果说上一次发布的语音识别模型让 AI 学会了在嘈杂真实环境中「听懂」人类复杂对话的能力，那么今天发布的 MOVA，则宣告了他们让 AI 具备了「创造」同步音视频的能力。&lt;/p&gt;&lt;p&gt;从感知到生成，从单一模态到端到端多模态，从理解到生成，环环相扣，死磕情境智能（Contextual Intelligence）每一个关键环节的模思智能正在快速构建它的多模态基础模型版图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;研究、创新、与学生培养&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOVA 是上海创智学院与模思智能在&lt;strong&gt;研究、创新和学生培养&lt;/strong&gt;模式上的一次成功实践。上海创智学院「&lt;strong&gt;研创学&lt;/strong&gt;」模式成功融合了学术研究的深度与产业落地的敏锐度，让研究不再拘泥于简单场景，也同时深入到了工业场景，并从中培养一流 AI 人才。&lt;/p&gt;&lt;p&gt;在上海创智学院，学生被视为共同创新创业的合伙人，他们在 MOVA 这种千卡级规模的工业级基模训练中承担核心任务。这种阵地式培养让学生在解决大规模训练 Infra 框架、高性能海量数据分布式处理框架、模型架构从 0 到 1 设计等硬核工程问题的过程中，积累了极具稀缺性的实战经验。&lt;/p&gt;&lt;p&gt;模思智能作为创新的出口，一方面为人才培养提供了验证大规模基模性能的闭环环境，并通过持续的技术迭代，将前沿理论转化为可商用的生产力工具。在这一机制下，技术研发与商业价值形成了互为因果、相互加速的良性循环。&lt;/p&gt;&lt;p&gt;这一模式更深远的意义在于对 AI 顶尖人才培养路径的重塑，让年轻大脑在技术演进最前线接受真火淬炼，为未来的 AGI 竞争储备具备破局能力的澎湃力量。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>昆仑万维开源的SkyReels-V3，把马斯克请来带货了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 29 Jan 2026 18:49:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-29-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-29-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文&lt;/section&gt;&lt;p&gt;AI 网红们在社交平台上混得风生水起。&lt;/p&gt;&lt;p&gt;他们手握品牌合作，还坐拥百万粉丝，但很多人至今不知这些都是 AI 生成的，依然像追真人明星一样互动、点赞、被种草。&lt;a href="https://mp.weixin.qq.com/s/KU61dqc-Ka8i9hRWF5enBg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fce4d605-f339-4210-8055-86627f044255/1769683427510.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频来源：X 博主 @thetripathi58&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这也难怪有博主直呼：虚拟网红时代已经到来。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf6gJtylBPRQiafDWHPhlfMgOScdYmOsHc3ksdVrSEX11UJY4jCibCH5DQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.14661654135338345" data-type="png" data-w="1064" data-width="1064" data-height="156" data-backw="578" data-backh="85" data-imgfileid="503530621" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1b0c23fd-8089-40a0-af48-da1497dc10f6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;现在，昆仑万维也来添了把火，直接把背后的技术开源了。&lt;/p&gt;&lt;p&gt;1 月 29 日，Skywork AI 团队宣布开源 SkyReels-V3 多模态视频生成模型系列。该系列涵盖&lt;strong&gt;参考图像转视频、视频延长和音频驱动虚拟形象&lt;/strong&gt;三大核心能力，在单一建模架构中实现高保真多模态视频生成，达到业界领先水平。&lt;/p&gt;&lt;p&gt;比如，只需一张虚拟主播照片配上音频，就能生成口型精准、表情生动的主播视频：&lt;a href="https://mp.weixin.qq.com/s/KU61dqc-Ka8i9hRWF5enBg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bd54cb15-5299-4e15-b20b-b9ac82ba00f1/1769683467896.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;上传几张素材图，输入文字描述，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;AI 就能自动编排出一条完整的带货短片：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfiblP3cQaxv8NnBgSGG5F3bUibpCUWKYQKPD8QjGr7qCuNnfdXTwKMfHw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.549074074074074" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="562" data-backh="309" data-imgfileid="503530665" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/604bce68-bb02-43f9-b7dc-becbec0d57e0/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;a href="https://mp.weixin.qq.com/s/KU61dqc-Ka8i9hRWF5enBg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7815db0b-ebe6-43ba-b657-5659f256a323/1769683483434.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;还能像专业导演一样，为视频设计切入、切出、正反打等电影级转场效果：&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfxGRgJjkH5ScDsWAiclZbmHuQ108dkCmICBNHSibNx64icQbeceEaRYVHw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.5625" data-type="gif" data-w="640" type="inline" data-imgfileid="503530632" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/eecaf9ac-38c6-4089-8956-91b7592e50d1/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazftXhkpPZIULzMu5ibmdjRTIbg5Fzu2iaibcibnkuk3wJibc8nVK8Z0u3wibFg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.5625" data-type="gif" data-w="640" type="inline" data-imgfileid="503530633" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e2a0db61-5fac-47aa-8f2c-81f1dccde112/640.gif" data-order="1" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;更关键的是，这次是完全开源。任何有想法的创作者，都能用这套工具快速搭建自己的虚拟 IP，甚至批量生产内容矩阵。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;GitHub 链接： https://github.com/SkyworkAI/SkyReels-V3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;API 链接（限时免费）：https://www.apifree.ai/model/skywork-ai/skyreels-v3/standard/single-avatar&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一手实测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SkyReels-V3 的实际表现到底如何？我们第一时间针对三大核心功能进行了全面测试。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参考图像转视频&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个功能允许用户上传 1-4 张参考图像，配合文本提示词，生成时间连贯、语义一致的视频。参考图像可以是人物、物体或场景，模型会精准保留身份特征、空间构图，并按照提示词编排叙事逻辑。&lt;/p&gt;&lt;p&gt;我们首先测试了电商应用场景。&lt;/p&gt;&lt;p&gt;上传马斯克的照片和小象玩偶图，输入提示词：在温馨的客厅里，马斯克坐在沙发上，微笑着拿起身旁的小象玩偶，然后将玩偶举到镜头前展示，阳光从窗户洒进来，气氛温暖。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazff2kvSjDgIq4PBRiafz0404WARGkictsVMalTTCz8qIcRUcibpxXflHqTw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.8185185185185185" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="473" data-imgfileid="503530636" data-aistatus="1" data-original-style="width:100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/774dc2fc-4bbc-488c-847a-bf1c8f917b5f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;生成视频中，即使更换了背景，马斯克面部特征也保持高度一致，未出现扭曲或者「换脸」，动作自然流畅，商品展示角度恰到好处。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfNOKndEUO8lXB0opjuCiaUg5LialtFXbQx1sxN1ugkVB2EROpAAMdCXGg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="1.778" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="889" data-imgfileid="503530637" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c670ecbb-0de1-400a-9e8c-afdd121e4f2e/640.gif" data-order="2" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;我们又上传了手袋商品图和素颜模特照，输入提示词：时尚的都市街头，这个模特拿着 LV 包，展示包的细节和质感。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfFgz2y7y7qDa9OLCZBMmM8fl2wibm4NxKeSWv3pcGoaVsN9sWN2gfSTg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-ratio="0.8712962962962963" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="503" data-imgfileid="503530638" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b74b37dd-5131-4f43-bc5f-995081b45246/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;SkyReels-V3 立马把模特置于车水马龙的都市夜景中，边走边展示产品细节，人物动作优雅，构图也很专业。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfl0M7wmegFhSru11os8TqfPFNwpFhYZqNvBync91cC1sYUBtXdWCEyw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.5625" data-type="gif" data-w="640" type="block" data-backw="578" data-backh="325" data-imgfileid="503530639" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/47e1c155-befb-44b3-86eb-dcc19c1b75a5/640.gif" data-order="3" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们还尝试上传多张参考图像，让不同人物或物体在指定场景下产生互动。&lt;/p&gt;&lt;p&gt;比如把奥特曼的照片丢给它，再来张酷炫智能眼镜和公园图片，然后下指令：男人戴着智能眼镜在公园里散步。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf7wxibz5qC8JibDAP1pfyDGUpqeMZ1CTtQW13N872ptU1wR4OMmBELwxg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=9" data-ratio="0.26944444444444443" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="156" data-imgfileid="503530641" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/5080cb85-a693-477f-9a2d-6711ba921c63/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;模型准确识别人物、物体和背景，并根据提示词编排出合理的交互动作。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfReX1qOODCFwHQgyy7o0N3oGrg8KOrZiaxsSRjcta4jbFN4ItHaglNsw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.5633333333333334" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="326" data-imgfileid="503530642" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/59c6b1c9-cf7d-435d-801b-c36f736d34c1/640.gif" data-order="4" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最近《怪奇物语》热度蹿升，我们上传三名小演员的剧照，外加一张上海外滩图片，输入提示词：这三个人在上海外滩自拍。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf7WOb8TPypACenribgdTr3aUyMRGFrGKzM2Fb5QeLJia1UnbTl5vvtd6Q/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.26481481481481484" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="153" data-imgfileid="503530644" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/754d85a8-cf27-4371-b72d-57ccdaaf52d2/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SkyReels-V3 能同时处理好几张完全不同的参考图，精准还原人物特征，保证整体风格统一，连服饰发型都完美迁移。&lt;/p&gt;&lt;p&gt;生成视频里三个人一起自拍的互动看起来毫不违和，表情特别自然，动作也流畅得很。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfckY11CQEXLHAR5Xcu9OicWFXS892LlnibImIty1uRxDic26AfaRdltsgA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.5633333333333334" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="326" data-imgfileid="503530646" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/9d0b335c-6753-4ac8-819e-ba88b7fe15fb/640.gif" data-order="5" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;视频延长&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视频延长功能则可以将输入的视频片段延伸为更长内容，同时保持运动动态、场景结构和视觉风格的一致性。它支持单镜头延长和镜头切换延长两种模式。&lt;/p&gt;&lt;p&gt;镜头延长模式下，我们提供了一段女生开心面对镜头的视频，输入提示词：女孩笑着笑着突然严肃起来，延长 5 秒钟。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfEOXZqz8x9oqiaaWoBOMlNsxlH5X6HUI8OmmBAbOaVumucTbNEks6s6w/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.565625" data-type="gif" data-w="640" type="block" data-backw="578" data-backh="327" data-imgfileid="503530648" data-aistatus="1" data-original-style="width:100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/94b6b668-05c6-4c66-a43e-6cc321539ce4/640.gif" data-order="6" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这种从开心到严肃的表情过渡需要模型把握好微表情的变化节奏，不能太突兀。SkyReels-V3 对人脸表情动态和情绪演变的理解相当到位，延长过程中女生的面部特征、光影效果和整体视觉风格都没走样。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf4A7ZsLuibk78lMQ9g4WsaOzPtL0zWSDK7Lm2H6kQpWkMgIJia1lnMhhg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-ratio="0.5633333333333334" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="326" data-imgfileid="503530647" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/1c1ad779-e421-4066-9f14-2569d7560248/640.gif" data-order="7" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;镜头切换延长模式则更具创意空间。它支持切入、切出、多角度、正反镜头、切离五种专业转场。&lt;/p&gt;&lt;p&gt;具体而言，切入镜头从广角过渡到特写，切出镜头则相反；正反打镜头指的是在对话场景中，从面向一人的镜头切换到面向另一人的镜头；多角度镜头是切换到不同角度来展示当前场景；切离镜头则是过渡到当前场景中的新区域。&lt;/p&gt;&lt;p&gt;就以切入镜头为例。我们上传女杀手狙击的场面，输入提示词「Close-up on the girl&amp;#39;s face as she aims, sweating」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfukib0R0H3OpDT8H49IZhtcicp4AfgogwKWiboMnInLwodvKR9r5qceq2Q/640?wx_fmt=gif&amp;from=appmsg#imgIndex=15" data-ratio="0.5609375" data-type="gif" data-w="640" type="block" data-backw="578" data-backh="324" data-imgfileid="503530649" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/380ad6e6-28cb-44c8-8a86-0dd9824b21ab/640.gif" data-order="8" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;SkyReels-V3 能够理解 Close-up 这种专业摄影术语，从瞄准动作到面部特写的过渡保持了叙事的连贯性，又通过景别变化增强了画面张力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfCLMYjzE3tT4jD5j61lPEbRth5vh7g3T4uVPJjuUtwicAibsc1Nwy39mw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=16" data-ratio="0.5633333333333334" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="326" data-imgfileid="503530650" data-aistatus="1" data-original-style="width: 100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/2dea168d-5c71-4acc-bfcd-6bc348e8c007/640.gif" data-order="9" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;虚拟形象模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虚拟形象模型则可以从单张肖像图和音频片段生成音视频同步的视频，支持分钟级长度和多角色交互。&lt;/p&gt;&lt;p&gt;我们先测试了最基础的单角色虚拟形象 。上传肖像照，配上音乐片段，SkyReels-V3 快速生成一段唱歌 MV，人物唇形与音频完全同步，并能保持画面稳定。&lt;a href="https://mp.weixin.qq.com/s/KU61dqc-Ka8i9hRWF5enBg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f5b879bb-3e09-484b-b856-58e3de43acc1/1769683614300.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;泛化能力同样出色。我们测试了真实人物、卡通角色等不同风格，模型都能稳定生成高质量结果。&lt;/p&gt;&lt;p&gt;此外，它还支持多人物互动场景。我们上传了朱迪和尼克在咖啡店喝咖啡的参考图，为每个对话片段配置音频。&lt;/p&gt;&lt;p&gt;模型自动识别出图片形象，精准控制每个角色的开口时机，未出现两个角色同时张嘴或者对不上口型的尴尬情况。&lt;a href="https://mp.weixin.qq.com/s/KU61dqc-Ka8i9hRWF5enBg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a6e20b3f-345b-4f7d-8052-4f0fb36d6fbc/1769683628898.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术解读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Skywork AI 团队此次开源，为视频生成领域带来了新的技术选择。&lt;/p&gt;&lt;p&gt;该系列模型在单一建模架构中集成了参考图像转视频、视频延长和音频驱动虚拟形象三大核心模块，在保持高保真度的同时实现了多模态的灵活应用。&lt;/p&gt;&lt;p&gt;先说参考图像转视频功能。这一能力的实现建立在三层技术创新之上。在&lt;strong&gt;数据构建&lt;/strong&gt;层面，团队从海量高质量视频数据中筛选具有显著动态运动的素材，随后通过跨帧配对策略连续视频序列中选择参考帧，以确保时间多样性。&lt;/p&gt;&lt;p&gt;团队还利用图像编辑模型进行主体提取、背景补全和语义重写，有效避免了传统方法中常见的「复制粘贴」伪影问题，并通过多层过滤机制保障参考图像质量。&lt;/p&gt;&lt;p&gt;SkyReels-V3 实现了&lt;strong&gt;统一的多参考条件策略&lt;/strong&gt;，能够联合编码视觉和文本信息，支持最多 4 张参考图像的灵活组合。这意味着开发者无需进行显式的手动组合，即可实现复杂的多主体、多元素视频生成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练策略&lt;/strong&gt;方面，模型采用了图像 - 视频混合训练方案，联合利用大规模图像和视频数据集，并通过多分辨率联合优化提升了对不同空间尺度和宽高比的鲁棒性，原生支持多种输出配置。&lt;/p&gt;&lt;p&gt;在涵盖电影电视、电商、广告等场景的 200 对混合测试集上，&lt;strong&gt;SkyReels-V3 在参考一致性和视觉质量方面均处于国内领先位置&lt;/strong&gt;，验证了其技术方案的有效性。&lt;/p&gt;&lt;p&gt;视频延长模块是 SkyReels-V3 技术实力的另一体现。&lt;/p&gt;&lt;p&gt;其核心创新在于&lt;strong&gt;双模式延长机制&lt;/strong&gt;的设计。单镜头延长模式实现平滑的镜头继续，保持视角和叙事连贯；镜头切换延长模式则支持切入、切出、多角度、正反镜头、切离等五种专业转场类型，为视频创作提供了电影级的叙事工具。&lt;/p&gt;&lt;p&gt;为支撑这一能力，团队开发了专门的&lt;strong&gt;镜头切换检测器&lt;/strong&gt;，能够自动分析长视频中的镜头转场，识别并分类转场类型，同时支持手动选择，有效构建了高质量的训练数据。&lt;/p&gt;&lt;p&gt;技术实现上，SkyReels-V3 采用了&lt;strong&gt;统一的多分段位置编码方案&lt;/strong&gt;，支持复杂多分段视频延伸的精确运动建模，并通过分层混合训练实现平滑的镜头切换。鲁棒时空建模使其能够有效处理快速运动、多主体交互和场景剧变等复杂情况，确保生成内容的物理可信度和时间连贯性。&lt;/p&gt;&lt;p&gt;该模块支持 480p 和 720p 分辨率，单镜头延长可调节 5 至 30 秒长度，并支持 1:1、3:4、4:3、16:9、9:16 等多种宽高比，为不同应用场景提供了灵活的输出选项。&lt;/p&gt;&lt;p&gt;虚拟形象模型的技术方案则聚焦于&lt;strong&gt;音视频精准对齐和关键帧约束生成机制&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;研究团队开发了专用的音视频对齐训练策略，通过区域掩码建模显式的语音单元与面部运动的对应关系，实现了对多语言、多风格、快速语速的鲁棒性能。&lt;/p&gt;&lt;p&gt;关键帧约束生成则通过建立结构重要的关键帧，生成帧间平滑过渡，确保长视频中的角色一致性和自然运动流。&lt;/p&gt;&lt;p&gt;从整体架构来看，SkyReels-V3 的核心优势在于其&lt;strong&gt;模块化设计&lt;/strong&gt;理念。三大功能模块各自经过深度优化，既可以独立使用，也能根据实际需求灵活组合，为不同应用场景提供了充分的适配空间。&lt;/p&gt;&lt;p&gt;企业级的数据处理管线确保了生成质量的稳定性，而在推理端，团队融合了蒸馏、量化及算子优化等多项技术，打造出低延迟、高吞吐的推理引擎，使得模型在实际部署中具备更强的可用性。&lt;/p&gt;&lt;p&gt;在训练效率方面，SkyReels-V3 采用了极致的显存与计算优化方案，支撑起高分辨率长视频的千卡级稳定高效训练。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SkyReels-V3 选择完全开源，某种程度上反映了 AI 视频生成领域的竞争态势。&lt;/p&gt;&lt;p&gt;在 Runway、Pika 等国外产品凭借先发优势占据市场时，国内团队通过开源策略快速建立生态、获取反馈、迭代优化，不失为一种聪明的打法。&lt;/p&gt;&lt;p&gt;而这背后的底气，自然源于昆仑万维在视频生成领域的长期技术积累。&lt;/p&gt;&lt;p&gt;早在 2025 年 2 月，昆仑万维就开源了中国首个面向 AI 短剧创作的视频生成模型 &lt;strong&gt;SkyReels-V1&lt;/strong&gt;，以及中国首个 SOTA 级别基于视频基座模型的表情动作可控算法 &lt;strong&gt;SkyReels-A1&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;4 月，&lt;strong&gt;SkyReels-V2&lt;/strong&gt; 作为全球首个使用扩散强迫（Diffusion-forcing）框架的无限时长电影生成模型正式发布。随后，&lt;strong&gt;SkyReels-A2&lt;/strong&gt; 带来了可控视频生成框架，&lt;strong&gt;SkyReels-A3&lt;/strong&gt; 则实现了任意时长的全模态音频驱动数字人创作。&lt;/p&gt;&lt;p&gt;昆仑万维在视频生成领域的迭代速度和技术深度可见一斑。&lt;/p&gt;&lt;p&gt;除此之外，昆仑天工还自研了包括语言大模型、多模态大模型、SWE 代码大模型、Agent 大模型、视频大模型、3D 大模型、音乐大模型、音频大模型在内的 8 大模型矩阵，并持续开源几十个模型，在多个国际评测中取得开源最优成绩。&lt;/p&gt;&lt;p&gt;视频模型只是这个 AI 矩阵中的一环，却是连接文本、图像、音频等多模态能力的关键节点。&lt;/p&gt;&lt;p&gt;此次 SkyReels-V3 的开源，预示着 AI 视频生成的竞争正在进入更激烈的阶段。技术壁垒逐渐被打破，真正的较量也才刚刚开始。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Karpathy盛赞，啥都没有的创业公司刚融了1.8亿美元，要用小数据造强智能</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 29 Jan 2026 18:41:02 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-29-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-29-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜冷猫&lt;/section&gt;&lt;p&gt;你想象中真正的 AI 是什么样子的？&lt;/p&gt;&lt;p&gt;至少有一点，大多数人会同意：未来的 AI，应该具备像人一样思考的能力。&lt;/p&gt;&lt;p&gt;问题在于，我们现在研究大模型走的这条路，能通向真正的「思考」吗？&lt;/p&gt;&lt;p&gt;当前最先进的大模型系统，几乎是在整个人类可获取的历史数据之上训练出来的：网页、书籍、代码、论文、对话，数万亿 token。训练大模型所需的数据，远超任何一个人类个体一生所能接触的总和。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 需要整个互联网来学习，而人类只需要一个童年。&lt;/strong&gt;人类在成年之前，所接触的语言、文本与符号，顶多只有几十亿 token，相差几个数量级。&lt;/p&gt;&lt;p&gt;正是从这个问题出发，一家几乎&lt;strong&gt;没有产品、没有盈利&lt;/strong&gt;、也不急于商业化的 AI 创业公司，从 GV、Sequoia 和 Index 拿到了 &lt;strong&gt;1.8 亿美元融资&lt;/strong&gt;，并获得了 Andrej Karpathy 的公开力挺。&lt;/p&gt;&lt;p&gt;它的名字，叫 Flapping Airplanes。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="628" data-imgfileid="503530666" data-ratio="0.5453703703703704" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfoliaichNoK0LDPxiapJPkWXaP1LuVz4dphpjWgXZKKts9Q4XJ5AnCgE9g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1152" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ac92b55b-84e5-46e3-8f0e-fb93cae1b6e5/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Flapping Airplanes 是一家基础 AI 研究实验室，专注于解决「数据效率」这一核心问题&lt;/strong&gt;，并正在探索一些看似怪异、但可能至关重要的新思路 &amp;mdash;&amp;mdash; 从重新思考损失函数，到甚至质疑和重构梯度下降本身。该公司的研究团队成员中包括 IMO、IOI、IPhO 奖牌得主等顶尖人才。&lt;/p&gt;&lt;p&gt;Flapping Airplanes 称，其融资用来组建 AI 的新防线：一个想象中的世界，模型可以在不用摄入互联网一半内容的情况下达到人类水平的思考。&lt;/p&gt;&lt;p&gt;他们的估计是：&lt;strong&gt;在人类与现有模型之间，样本效率存在着 10 万倍到 100 万倍的差距&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;要实现如此数量级的跃迁，仅靠渐进式改进是不够的 &amp;mdash;&amp;mdash; 需要真正的 Big ideas。&lt;/p&gt;&lt;p&gt;他们在推文中表示，公司的唯一目标，是做真正优秀、能够改变范式的研究。尽管目前并不急于商业化，但这些工作最终将在企业级应用、机器人、交易系统、科学发现等领域释放出巨大的价值。&lt;/p&gt;&lt;p&gt;「Flapping Airplanes」这个名字，正是公司文化的写照：我们是谁、我们在做什么，本身就是 out-of-distribution 的。非常非典型的活跃性公司文化，从他们的推文中能看出一丝严谨学术之外的跳脱。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="354" data-imgfileid="503530668" data-ratio="0.3" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf2P96uBaQtUCrYB1FX5ibIlN1gyXFTmL2TxU6GJvDT40f1QffzXsg2dw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="1180" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3b497828-b001-418b-a7d4-a084b70662d9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们甚至发现，Flapping Airplanes 官方推特的关注列表里，真的有旧金山机场和两大美国航司&amp;hellip;&amp;hellip;（这是真的要起飞了）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1320" data-imgfileid="503530669" data-ratio="1.125925925925926" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfuLt466PoQJBI2LjSiaR0ibARNYFHD3wKj7wV1cvbuWKBsSQ0rvCQejRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" data-width="1172" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ff243a6d-9a3a-43fe-98bc-f78f2b44c101/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;一家没有产品、没有盈利、也不急于商业化的 AI 创业公司获得融资的事情似乎有些似曾相识。&lt;/p&gt;&lt;p&gt;主流观点是：AI 已经发展到如此阶段，一家新的、以研究为导向的创业公司，几乎不可能在竞争和执行层面上战胜现有巨头。「就你们这么几个人，怎么可能和 Google 竞争？」&lt;/p&gt;&lt;p&gt;但 Andrej Karpathy 毫不留情地指出：这种说法，在 OpenAI 成立时就是错的；后来，又一次被证明是错的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="820" data-imgfileid="503530670" data-ratio="0.6981481481481482" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfuayYbibJCOIpsiaBVYCuPtG0okUGUBZgOQGgrxfNRYibZtLHqjHpT8ichA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" data-width="1174" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/db900caf-da69-4c06-9eba-672640bab134/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然，持续扩大规模、在有效路径上进行局部优化，仍然会带来惊人的进步。但与此同时，我们正以极快的速度解锁大量进展，整个领域被扬起了巨大的「技术尘埃」。&lt;/p&gt;&lt;p&gt;而且，前沿大模型与「一个只消耗 20 瓦功率的人类大脑」这一智慧奇迹之间，依然存在着巨大的鸿沟。正因如此，我认为，能够带来接近 10 倍提升（而非 10% 微增）的研究级突破，其概率依然非常高 &amp;mdash;&amp;mdash; 高到值得持续下注、持续寻找。&lt;/p&gt;&lt;p&gt;真正棘手的问题，当然在于：如何创造出能够孕育这种突破的环境。&lt;/p&gt;&lt;p&gt;Karpathy 认为，这样的环境极为罕见。但他盛赞 Flapping Airplanes，他们具备（罕见的）从上到下的全栈理解能力，并且对人才有极好的判断力。&lt;/p&gt;&lt;p&gt;希望扑翼飞机能够打开人工智能的航空新时代。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>亚马逊裁员16000人，员工竟用AI「算」出了裁员名单？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 29 Jan 2026 16:31:16 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-29-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-29-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;近日，科技巨头亚马逊继去年裁员 14000 名员工后，再次开启新一轮大规模裁员，&lt;strong&gt;预计影响 16000 名员工&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其实这一次裁员属于计划内操作，去年十月的裁员期间，亚马逊就列了个约 3 万个岗位的裁员计划，这一次属于计划的「收尾」阶段，但这并不排除其后续进一步裁员的可能性。&lt;/p&gt;&lt;p&gt;据了解，此次裁员范围波及全球，或将涉及亚马逊网络服务、零售、Prime Video 和人力资源等多个团队，但具体的裁员地点、职位等更多细节尚不清楚。&lt;/p&gt;&lt;p&gt;但「有意思」的是，&lt;strong&gt;一名亚马逊员工使用 AI 工具对内部 Slack 聊天记录进行分析，编制生成了一份可能受到裁员影响的团队和组织名单&lt;/strong&gt;，该名单由一个名为 Pippin 的 AI 工具生成。据了解，当前亚马逊内部员工越来越多地使用该工具来撰写和审核文档。&lt;/p&gt;&lt;p&gt;「我用 Pippin 帮我梳理了今天的对话，」这位员工在公司 Slack 上写道，「请注意，这些信息可能并非 100% 准确。大家保重！」&lt;/p&gt;&lt;p&gt;以下为该员工生成的裁员涉及岗位名单列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AWS 销售组织、AWS Bedrock、AWS Quick Suite、AWS 高级支持 / 支持工程；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AWS ProServe（专业服务）、AWS EC2 网络、AWS 数据库服务、AWS 负载均衡；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AWS Aurora、AWS Redshift、AWS RDS、AWS OpenSearch、AWS EKS；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AWS 安全、AWS 互联网可用性工程、AWS ElastiCache、AWS 数据中心网络；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AWS Virtual、AWS 漏洞管理、AWS IoT、Alexa 组织、Alexa 在 D&amp;amp;S 方面的卓越表现；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Alexa Connections 团队、Alexa Kids 团队、Alexa 购物部门、Alexa 智能属性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Alexa AI 开发工具、Alexa 设备及商店、零售与运营、最后一公里；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SCOT（供应链优化技术）、亚马逊企业购、图书、卖家支持 / 卖家合作伙伴服务 (SPS)；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;亚马逊物流 (FBA)、客户服务 (CS)、Prime Video（直播电视、多普勒）、设备组织；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;PXT（人员体验和技术）、AGS（亚马逊全球服务）、WWSO（全球专家组织）、WWPS（全球公共部门）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最新消息，&lt;strong&gt;目前亚马逊尚未回应核实该名单是否准确的请求&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;据了解，亚马逊几番如此大规模的裁员或与 AI 的广泛应用有关，尤其是在企业和技术职能部门。&lt;/p&gt;&lt;p&gt;其实早在去年 6 月的时候，亚马逊首席执行官 Andy Jassy 就曾表示过，&lt;strong&gt;随着公司越来越多地使用 AI，他预计未来几年公司员工人数将会减少&lt;/strong&gt;。他曾详细地阐述过亚马逊是如何推出更多用于内部运营的生成式 AI 和 Agent 来提升工作效率的，并认为这些工具的应用未来应该会极大「改变我们的工作方式。」&lt;/p&gt;&lt;p&gt;&lt;img alt="图像" data-aistatus="1" data-imgfileid="503530702" data-ratio="0.6666666666666666" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfZ3F2bvLg6bAMIFDLwnNlWF40O5rFfuyomgJGmNsdxJ5XibCib49EeETg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="768" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b09edc9c-6fb3-400b-908f-539e03ee9803/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;「我们将需要更少的人来做现在正在做的一些工作，而更多的人来做其他类型的工作。很难确切知道从长远来看这会产生什么结果，但在未来几年，我们预计随着公司广泛使用人工智能来提高效率，这将减少我们公司的员工总数。」&lt;/p&gt;&lt;p&gt;因此，在他的领导下，&lt;strong&gt;广泛目标中的一部分就是精简机构、剥离业绩不佳的业务&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;据报道，此次裁员背后，亚马逊高管曾在内部备忘录解释，公司裁员 16000 名企业员工是成为「全球最大的创业公司」所必需的。&lt;/p&gt;&lt;p&gt;而裁员消息一经传出，有关「裁员或与 AI 广泛应用有关」的传闻也引起网友热议。&lt;/p&gt;&lt;p&gt;一位网友透露，去年夏天他在露营的时候偶遇一位亚马逊中层经理，彼时该网友已经离开职场大约一年了，所以他询问这个经理，AI 到底对他的工作产生了多大影响？&lt;/p&gt;&lt;p&gt;当时该经理透露，他正在致力于开发一种工具，将有效地取代他所负责的所有中层管理职能：从下属那里收集、提炼信息，然后向上级汇报。&lt;strong&gt;他希望自己能被留下来继续维护他所建立的体系，因为他知道其余所有与他同级别的经理都将被解雇&amp;hellip;&amp;hellip;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如今裁员消息传出，该网友又想起这件事情，让他感觉就像看着一个即将被处决的人亲手打造绞刑架，「他本该非常清楚，自己的工作将是第一个被砍掉的，而他却要负责打造砍掉自己工作的工具。但他还乐观地认为，被砍掉的不会是他。」&lt;/p&gt;&lt;p&gt;「这让我不禁想知道他今天过得怎么样&amp;hellip;&amp;hellip;」&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530699" data-ratio="0.30092592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfl4VPJjfEsbFicd2CsxpIbxqEJ2RH7Urr28pUHtrK2vicHezMtSUV0PUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ab05edb7-a015-4977-a831-a4f823f40ad0/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;也有网友认为，亚马逊的裁员只不过是一个缩影。随着技术的发展，这种情况将越来越常见，过去二三十年的情况也如此，只不过彼时是用计算机取代了其他人的工作，再早之前，人们是用高效的机器和工业机器人取代蓝领工人。&lt;strong&gt;「软件已经吞噬了世界，现在 AI 也将吞噬 &amp;ldquo;软件专业人士&amp;rdquo;&amp;hellip;&amp;hellip;」&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530700" data-ratio="0.23333333333333334" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfsD19AE8r5uVwHickZJFJNRqmcLEtzSjHfv1I2UDJoIOv4zPRtTIlWibg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6cef5419-0e28-4b01-bb85-261706bdd758/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.businessinsider.com/amazon-layoffs-ai-tool-affected-teams-2026-1&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://economictimes.indiatimes.com/tech/technology/amazon-cuts-16000-jobs-globally-in-broader-restructuring/articleshow/127698639.cms?from=mdr&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://news.ycombinator.com/item?id=46796745&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
