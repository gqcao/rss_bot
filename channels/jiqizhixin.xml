<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>2026年，大模型训练的下半场属于「强化学习云」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:24:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3177c979-5de5-4d7c-a344-0b87d712ac1d/1768195078091.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2024 年底，硅谷和北京的茶水间里都在讨论同一个令人不安的话题：&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650942531&amp;idx=1&amp;sn=2fabcd16a94b0966864aaf18c6338faf&amp;scene=21#wechat_redirect" target="_blank"&gt;Scaling Law 似乎正在撞墙&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;那时候，尽管英伟达的股价还在狂飙，但多方信源显示，包括彼时备受期待的 Orion（原计划的 GPT-5）在内，新一代旗舰模型在单纯增加参数规模和训练数据后，并未展现出预期的边际效益提升。另外，也有研究认为预训练所需的数据将会很快耗尽，其甚至还预测了明确的时间节点：2028 年。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALf5AERXPc62A6EIBStJTcQ5GwfUPhS6q03jbbENvaZwc3e4589DtuQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6027777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527888" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/cfad2cd2-a2e7-41a8-9305-9a758923b90f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 来自论文 arXiv:2211.04325v2&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;OpenAI 和 Safe Superintelligence Inc 的联合创始人 Ilya Sutskever 当时还留下了一句意味深长的判词：「2010 年代是规模扩大的时代，现在人们又回到了奇迹和发现的时代。」这句话在当时被许多人解读为悲观的预警，也就是单纯依靠堆砌算力和数据的预训练路线，恐怕已经触到了天花板。&lt;/p&gt;&lt;p&gt;直到 2025 年初，接连的惊喜打破了僵局。&lt;/p&gt;&lt;p&gt;那时候，OpenAI 的 o1 模型已在几个月前率先引入了强化推理，展示了模型在思考时间换取智能深度上的惊人潜力，证明了 test-time scaling（测试时间扩展）是一条通往更高智能的可行路径。然而，o1 的闭源特性让这项技术一度被视为只有巨头才能掌握的「黑科技」。&lt;/p&gt;&lt;p&gt;2025 年 1 月 横空出世的 DeepSeek R1 将 o1 的技术路线成功复现并彻底开源。它的意义不在于从零发明，而是用极低的成本和开放的姿态向全行业证明：&lt;strong&gt;Scaling Law 并没有撞墙，它只是换了引擎&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;DeepSeek R1 等推理模型的成功揭示了一个事实：&lt;strong&gt;深度的推理能力比单纯的参数规模更关键。&lt;/strong&gt;通过强化学习（RL）驱动的思维链（CoT），模型在后训练阶段展现出了类似于人类「慢思考」的推理能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGA9be6iceO5Tmib7aYKia7hW5BiaEvPoK4u9Ox8kZWYhGndfO0v6rvsOFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527887" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9590c21b-25cb-4e7d-95bf-3c11d8659ed9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; DeepSeek-R1 的多阶段训练流程，来自 arXiv:2501.12948v2&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;正如九章云极 DataCanvas AI 首席科学家缪旭在 2025 算力生态大会上回顾的那样：「DeepSeek 的横空出世，让我们第一次感觉到，原来强化学习可以让大模型的进化速度再次提升。」对于更广泛的开发者而言，这种「感觉」正是源于 DeepSeek 拉低了技术门槛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAF8YQML1WXO2RHPPPoKOCq8z5JqlByCdWCGDicibB7anDdqdSeCoJzwfA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.6648148148148149" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527891" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3b1b1126-7de7-4814-8d1f-40276a2d3246/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;看起来，算力的重心正从 &lt;strong&gt;pre-training scaling（预训练扩展）&lt;/strong&gt;走向&lt;strong&gt; post-train scaling（后训练扩展）&lt;/strong&gt;和&lt;strong&gt; test-time scaling（测试时间扩展）&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsXPhyg7G7zEGtK6UCrVon26Rg53DFZz9X0mPhU8UDE5EZ2D5Equusg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527889" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/23487201-98cb-43cf-a471-09928702fb9a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;来自英伟达博客&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 2026 年的今天，我们已经可以确信：&lt;strong&gt;大模型训练的下半场属于强化学习。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这个阶段，模型不再仅仅是基于海量预训练数据的概率涌现，而是能像人类专家一样，通过与环境的交互、试错和自我博弈，进行深度的逻辑推演。&lt;/p&gt;&lt;p&gt;如果说预训练是培养一个通识教育的毕业生，那么基于 RL 的后训练就是将其投入真实世界，进化成一名真正的专家。然而，新的机遇也带来了新的基建危机：当算力的消耗重心从静态的&lt;strong&gt;训练&lt;/strong&gt;转向动态的&lt;strong&gt;探索与推理&lt;/strong&gt;，现有的云计算架构开始显得力不从心。&lt;/p&gt;&lt;p&gt;行业呼唤一种全新的算力形态，去承载这种以「&lt;strong&gt;进化&lt;/strong&gt;」为核心的新智能。而在这一轮基础设施的代际更迭中，谁能率先定义这种形态，谁就能握住下一个时代的入场券。&lt;/p&gt;&lt;p&gt;基于这一观察，缪旭在演讲中抛出了一个定义未来的公式：「&lt;strong&gt;当智能可以并行进化，强化学习云将成为群体智能的放大器。&lt;/strong&gt;」&lt;/p&gt;&lt;p&gt;这里的关键词「&lt;strong&gt;强化学习云&lt;/strong&gt;」，正是九章云极为应对这场范式转移给出的基础设施答案。作为&lt;strong&gt;独立智算云赛道的领军企业&lt;/strong&gt;，九章云极不仅首先提出了这一概念，更通过前瞻性的布局，率先定义了后训练时代的算力标准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首发优势 &amp;nbsp;为什么九章云极能定义「强化学习云」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 OpenAI o1 验证了路径，DeepSeek R1 引爆了热潮，那么九章云极则是在最短时间内率先给出了基础设施答案。&lt;/p&gt;&lt;p&gt;仅仅数月后的 2025 年 6 月，九章云极便正式发布了&lt;strong&gt;业界首个工业级强化学习云平台 Agentic RL&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;而当时，放眼全球，尽管以 Anyscale (Ray) 为代表的硅谷先驱已经在分布式计算框架层面为强化学习提供了底层支持，AWS、谷歌等云巨头也已将 RL 视为通用机器学习平台（如 SageMaker、Vertex AI）下的一个功能组件或工具包，但整体上主流市场的目光仍主要聚焦于如何构建更大的预训练集群或降低传统推理（inference 而非 reasoning）成本，尚未有任何一家企业像九章云极这样，敏锐地洞察到智能体（Agent）时代的算力特征变革，并&lt;strong&gt;将「强化学习」独立定义为一种全新的工业级云服务形态&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种能够迅速捕捉前沿算法趋势，并率先将其转化为标准化、工业级云产品的能力，正是九章云极在独立智算云赛道中确立首发优势与领军地位的基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么我们需要专门的强化学习云？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的云计算架构，本质上是为静态负载设计的。无论是 Web 服务还是传统的深度学习推理（inference），其计算特征相对线性且可预测。但强化学习截然不同，它是一个高频交互、动态探索的过程。智能体需要在模拟环境中进行海量的试错，而这会导致算力需求呈现出剧烈的波峰波谷特征，且对异构资源的调度有着极高的要求。&lt;/p&gt;&lt;p&gt;如果用传统的静态算力去跑 RL 训练，结果要么资源利用率极低，要么在探索高峰期直接卡死。&lt;/p&gt;&lt;p&gt;针对这一痛点，九章云极并没有选择在旧架构上打补丁，而是进行了系统级的重构。其强化学习云 Agentic RL 基于混合专家（MoE）架构与 Serverless 理念，实现了算力的「&lt;strong&gt;按需即取、即用即还&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;数据显示，相比于传统方案，&lt;strong&gt;Agentic RL 可将端到端训练效率提升 500%，综合成本下降 60%&lt;/strong&gt;。更关键的是，它是&lt;strong&gt;全球首个支持万卡级异构算力调度的强化学习基础设施平台&lt;/strong&gt;。这种对大规模异构算力的驾驭能力，标志着九章云极已经率先完成了从「卖资源」到「卖能力」的进化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agentic RL：让通用模型变成专家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;顾名思义，Agentic RL 的核心是 &lt;strong&gt;Agentic（智能体）&lt;/strong&gt;和 &lt;strong&gt;RL（强化学习）&lt;/strong&gt;。但 Agentic RL 并不只是智能体与强化学习的简单叠加，其内涵蕴涵了 AI 能力维度的一次关键跃迁：从单纯的「内容生成」转向复杂的「决策控制」。&lt;/p&gt;&lt;p&gt;在这里，「&lt;strong&gt;控制&lt;/strong&gt;」尤为关键。在九章云极看来，无论是供应链的动态调度，还是工业设计的精密规划，本质上都是一个高难度的&lt;strong&gt;控制问题&lt;/strong&gt;。Agentic RL 的核心目标，正是通过 RL 赋予大模型这种在动态环境中精准感知、规划并执行的能力，使其从单纯的语言专家进化为能解决实际物理世界难题的执行者。&lt;/p&gt;&lt;p&gt;正是为了支撑这种「从生成到控制」的能力跨越，在 2025 算力生态大会上，九章云极 AI 首席科学家缪旭进一步展示了其强化学习云背后的 Agentic RL 技术架构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4JzWZHTaqZEUZf7icMJ3vGj7tJMn2ATibdheat4U5dB6oTxpKwBLlC3Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.40370370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527890" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/61f69a39-03ec-4a65-b8ea-aeab9633e509/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;简单来说，Agentic RL 的使命是将通用模型进化为专家模型，其应具备长时程规划、长/短期记忆、复杂工具调用、检索增强生成优化、角色一致性等多种能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA0OQxPn9zm2AoBOtyq8icict5Iz0HFab93asDT65QCmAzJ0jmZPvmiaBZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527892" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/10c7a0ed-1165-435d-9424-ccbaad3c2e04/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;基于此，缪旭提出了一个更宏大的终局构想：未来的通用人工智能（AGI）可能不会是一个单一的巨型模型，而是由成千上万个垂类专家智能体组成的「&lt;strong&gt;群体智能&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;不同于传统的强化学习，面向群体智能的 Agentic RL 面对的是极度复杂的目标，比如城市规划的长时序约束，或工业设计的精密系统组合。为了支撑这种高难度的进化，九章云极构建了一些核心技术，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致效能的异步系统&lt;/strong&gt;：针对 RL 训练中极不稳定的负载特征，九章云极研发了全异步训练架构，通过 rollout 和 n+1 模型更新机制，成功将 GPU 利用率长期保持在 95% 以上。在算力昂贵的今天，这种工程优化直接等同于巨大的成本优势。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;5 倍速的离线进化&lt;/strong&gt;：针对强化学习样本利用率低的顽疾，九章云极采用了「基于回放的离线强化学习算法」。通过对时间跨度的压缩与样本的高效回放，实现了 5 倍于传统方法的训练速度提升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYBqvX5bPI7Dvfibic45t3XkxHYcMcrUsYmicfYC0mDVsRwAsibQJDBnZWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527893" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/73e8f8c3-bcbf-4603-bbb6-6c655a6982d3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;安全探索的「世界模型」&lt;/strong&gt;：在自动驾驶或医疗等「不能失败」的领域，九章云极与高校合作构建了可控的世界模型。它就像一个高保真的虚拟沙盒，让智能体在其中放手试错，解决现实世界「不敢探索」的难题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAIlXiblmwwjsnib9tbVnOjjEiaQSPqc7P6nkRWSFCgibvYI4yb04LxLzicsg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527894" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/06ccebc1-7e7d-4990-abf5-61cc643e6767/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Alaya NeW Cloud 的全栈重构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;九章云极强化学习云很强，这离不开其精心构建的 Alaya NeW Cloud 智能基础设施。&lt;/p&gt;&lt;p&gt;不同于传统云厂商在通用云上「打补丁」的做法，九章云极从一开始就围绕智能体的运行逻辑，完成了从底层基础设施到上层应用的四层全栈重构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAibwlBHBbVcJXiaAQf3vicicqEl4sxfEVGxQiastD4NtPD9dIjO5a9wSGfSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527895" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/1a4022cb-eb97-48cf-97ea-5a5ac1858993/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了底层技术的突破，九章云极在工程化落地层面也展现出了惊人的敏捷性。为了让最前沿的模型能力即刻触达用户，平台实现了&lt;strong&gt;云容器实例 (CCI)&lt;/strong&gt; 的一键式部署，全流程覆盖，即开即用。以 2025 年终压轴上线的&lt;strong&gt;满血版 DeepSeek-3.2&lt;/strong&gt; 为例，在高端算力卡的加持下，其部署速度更快，运行更高效，完美诠释了平台对最新 SOTA 模型的快速支持能力。&lt;/p&gt;&lt;p&gt;整体看来，在这个智能体时代，九章云极扮演的角色不再仅仅是互联网数据中心（IDC）提供商，更是进化环境提供商。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;开发者&lt;/strong&gt;：只要极少代码即可启动完整的「训练-推理-回传」闭环。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;产业&lt;/strong&gt;：无论是城市规划、工业制造还是自动驾驶，每一个垂直领域的智能体都能在九章智算云上找到专属的进化路径。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;在黄山 &amp;nbsp; 打造城市级智算样板&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;技术领先只是起点，能否在复杂的真实物理世界中落地，才是检验「领军者」成色的试金石。&lt;/p&gt;&lt;p&gt;当大多数智算中心还停留在「建机房、堆显卡」的 1.0 阶段，九章云极已经率先在安徽黄山跑通了「&lt;strong&gt;智算+产业&lt;/strong&gt;」的 2.0 闭环。这里不仅有一座算力中心，更有一个正在运行的、基于强化学习云的城市级实验样本。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;48 天奇迹，这就是九章速度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在黄山，九章云极创造了一个行业纪录：&lt;strong&gt;48 天&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;是的，仅仅 48 天，一座规模达 500 PFLOPS 的&lt;strong&gt;「大位」智算中心&lt;/strong&gt;便拔地而起并投入运营。&lt;/p&gt;&lt;p&gt;这种令人咋舌的交付速度，不仅源于九章云极成熟的工程化能力，更验证了其智算操作系统在异构算力调度上的极致效率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当强化学习走进「全程 AI 伴游」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「大位」智算中心绝非一座冰冷的机房，它是国内首个「&lt;strong&gt;文旅+AI&lt;/strong&gt;」城市级产业应用基础设施。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAtLsGRlTFzvoVqqOAzKjAmlHiaJ1p2sL1yEicGsg6d1tQPsoaZhTeklpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.524074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527896" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/56a97771-17ff-427e-a212-a55be332ea76/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在这里，九章云极的强化学习技术找到了最复杂的演练场：人类社会互动。依托算力底座，黄山实现了国内首个「全程 AI 伴游」景区。成千上万个智能体正在这里学习如何理解游客的意图、规划最优路线、处理突发状况。&lt;/p&gt;&lt;p&gt;这实际上是一场大规模的 Agentic RL 社会实验。每一个游客的反馈，都是一次 Reward（奖励）；每一次路线规划，都是一次 Policy（策略）更新。这种在真实高频场景中打磨出的智能进化能力，远比实验室里的数据更具商业价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智算经济：不仅是投入，更是增长引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于城市管理者而言，智算中心往往面临「建得起、用不起」或「不仅烧电、还烧钱」的质疑。九章云极则用数据打破了这一魔咒。&lt;/p&gt;&lt;p&gt;在本次大会发布的《2026 智算赋能城市产业发展白皮书》中，黄山被定义为「中小城市智算赋能标杆」。易观分析预测，随着「大位」智算中心的全面达产，每年将直接带动黄山市营利性服务业增加值增长不少于 2 亿元。&lt;/p&gt;&lt;p&gt;这一实战成果，正如九章云极董事长方磊在大会现场所下的判断：「&lt;strong&gt;全&lt;/strong&gt;&lt;strong&gt;球 AI 基建正重构生产力底座，算力核心价值在于普惠与落地效能。&lt;/strong&gt;」 黄山模式的成功，正是这一理念的最佳注脚。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAhaS8u56GrNnmozdkpTtGiawEibSUYRelm8ULDUBOnia4uA5ZffMcG2uEg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527897" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/a9fbd7fb-bc5d-427d-898f-ab65fac8cae2/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;通过「智算基建+文旅赋能+场景落地+商业闭环」，九章云极证明了强化学习云不仅能消耗电力，更能生产 GDP。&lt;/p&gt;&lt;p&gt;这种「黄山样板」正在产生强大的磁吸效应。大会现场，中科动力、百鹏互联、歌歌 AI 等 6 家 AI 企业集中签约落地。它们看中的，正是九章云极所构建的这个既有算力底座、又有丰富场景的智算生态。&lt;/p&gt;&lt;p&gt;从技术上的「定义者」到商业上的「破局者」，九章云极用黄山的实践告诉市场：下一代智算云，必须是能直接驱动产业增长的云。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;终局思维 &amp;nbsp;独立智算云赛道的「头号玩家」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 AI 基础设施的牌桌上，玩家虽多，但位置截然不同。有的在做「全能选手」（既做模型又做云），有的在做「卖水人」（只卖裸金属）。而九章云极选择了一条更为艰难、却也更为辽阔的道路：&lt;strong&gt;做独立智算云赛道的领军者。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;独立：真正开放生态的基础&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在「百模大战」向「千行百业」转型的今天，企业的顾虑显而易见：如果我把核心业务数据交给一个同时也做大模型的云厂商，它会不会既是裁判又是运动员？&lt;/p&gt;&lt;p&gt;这就是「独立智算云」存在的根本逻辑：&lt;strong&gt;中立性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;九章云极明确了自己的边界：不与客户争利，不绑定特定模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkATkgSKpvibFCHySBwdXGQm5ypicWMWxVdx7Ge4y5kgKBWeicicpm4ibkmuJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.40370370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527898" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c1cb6a9c-679e-4297-8d75-57fcab310611/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种「独立性」在算力高度集中的当下显得尤为珍贵。针对目前行业内只有不到 10 家巨头公司掌握 10 万卡以上资源的现状，九章云极明确倡导「开源 1000 专家模型」。&lt;/p&gt;&lt;p&gt;他们期望通过动态组合来放大群体智能，为那 10 万家中小企业提供高效的智能化解决方案，让每一个垂直领域的 Agent 都能在九章智算云上找到专属的进化路径 。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkASrmHOTAQrDPNFMQrOIQwmO2dzXjMgBkEEW6EGfwEY39F8MztibBdH8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527899" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/1fa31d6f-cc43-4d53-b362-42a0b7b49970/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种「独立智算云+开源专家模型」的组合拳，彻底区别于那些试图绑定自家闭源大模型的巨头云厂商 ，使其更有可能成功构建起&lt;strong&gt;真正的开放生态&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;正如其发起的 AI-STAR 企业生态联盟，并没有排他性的门户之见，而是连接了上游芯片厂商与下游应用厂商，共同组成了一个自主可控的产业链闭环 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;领军：从卖算力到定标准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;何为领军？不仅是规模最大，更是掌握定义规则的权力。&lt;/p&gt;&lt;p&gt;在算力计费混乱的草莽时代，九章云极率先推出了 「&lt;strong&gt;1 度算力&lt;/strong&gt;」 的普惠化标准，试图让算力像水电一样可度量、可流通。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVqdV8QPlkAtUyL0iaD0C2j3sVq9qpBCicCRyia1ZnyPXIgNJd40Wj5iaJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.18235294117647058" data-s="300,640" data-type="png" data-w="1020" type="block" data-imgfileid="503527900" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/cd0b3d30-03e2-405f-9067-df250bea8dbf/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而在后训练时代，九章云极再次通过强化学习云定义了下一代基础设施的标准架构：&lt;strong&gt;一套包含 Agentic RL 技术架构、Serverless 弹性调度和异构资源管理在内的完整操作系统。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这正是九章云极区别于普通云厂商的核心标志。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;以领军之姿 &amp;nbsp; 为企业打造进化引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年，当我们谈论云计算时，语境已经变了。&lt;/p&gt;&lt;p&gt;如果说过去十年的云计算是「能源时代」，厂商们比拼的是谁的电费更便宜；那么未来的十年，我们将进入「进化时代」，竞争的焦点是谁能让智能体进化得更快、更强。&lt;/p&gt;&lt;p&gt;作为&lt;strong&gt;独立智算云赛道的领军企业&lt;/strong&gt;，九章云极通过首创的强化学习云 Agentic RL，已经率先拿到了通往这个新时代的钥匙。它不仅仅是在提供算力，更是在为在这个星球上即将涌现的无数硅基智能体，提供进化的源动力。&lt;/p&gt;&lt;p&gt;在黄山的数据中心里，成千上万个智能体正在 7x24 小时地自我博弈。对于九章云极而言，这个关于「进化」的故事才刚刚开始。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>顶尖AI竟输给三岁宝宝，BabyVision测试暴露多模态模型硬伤</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:15:13 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/87e98ff5-ace4-4784-93b8-bf34724c7b6a/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;01｜&amp;ldquo;看懂世界&amp;rdquo; 这关，大模型还没上幼儿园&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去一年，大模型在语言与文本推理上突飞猛进：论文能写、难题能解、甚至在顶级学术 / 竞赛类题目上屡屡刷新上限。但一个更关键的问题是：&lt;strong&gt;当问题不再能 &amp;ldquo;用语言说清楚&amp;rdquo; 时，模型还能不能 &amp;ldquo;看懂&amp;rdquo;？&lt;/strong&gt;UniPat AI 携手红杉中国 xbench 团队，并联合多家大模型公司与高校的研究员，发布新的&lt;strong&gt;多模态理解评测集 BabyVision&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;UniPat AI 致力于构建真实场景下 AI 训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。&lt;/p&gt;&lt;p&gt;如果一个视觉问题可以完全用文字描述且不丢信息，它本质上就会 &amp;ldquo;退化成文本题&amp;rdquo;。模型可以靠强大的语言推理能力一路通关，看起来很会看，其实是在走语言捷径。而真正的视觉能力，需要在没有语言扶梯的情况下完成：比较、追踪、空间想象、模式归纳。&lt;strong&gt;而 BabyVision 证明了多模态大模型的这些纯视觉能力还停留在 &amp;ldquo;三岁幼儿&amp;rdquo; 的阶段 ！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Google DeepMind 创始人 Demis Hassabis，在 25 年终播客中也提到类似观点：&amp;ldquo;大模型可以在国际数学奥林匹克拿金牌，却会在小学几何题上出错；它能生成惊艳图像，却不理解杯子为什么不会飘在空中。&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv34HjyBhr0WO3FGBdqmvRrbnDBZzUGDlZVC913FMyxacweOZYiaCc1g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.7685185185185185" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527858" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1bf74415-7494-4213-a76b-5e8975819e9b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAvm6LSBq5NQbzIVJZxPaEc85TcHZeUBCKvhy6h9icha0VRsTs3ziaprUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.39351851851851855" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527936" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/36a2451a-ea9a-486c-8894-635875ec5f22/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;blog：https://unipat.ai/blog/BabyVision&lt;/p&gt;&lt;p&gt;github：https://github.com/UniPat-AI/BabyVision&lt;/p&gt;&lt;p&gt;huggingface：https://huggingface.co/collections/UnipatAI/babyvision&lt;/p&gt;&lt;p&gt;&lt;strong&gt;02｜把顶尖模型和孩子放到同一张 &amp;ldquo;纯视觉试卷&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;BabyVision 先做了一项非常直接的对比实验：把 20 道视觉中心任务（vision-centric）作为 BabyVision-Mini 交给不同年龄段孩子（3/6/10/12 岁）和当下顶尖多模态模型来做。&lt;/p&gt;&lt;p&gt;这份 &amp;ldquo;小试卷&amp;rdquo; 要求严格控制语言依赖：&lt;strong&gt;题目要求很简单，答案必须靠视觉信息本身得出。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;结果非常 &amp;ldquo;扎心&amp;rdquo;（如图 1 所示）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;大多数模型的分数，&lt;strong&gt;聚集在明显低于平均 3 岁儿童的区间；&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini3‑Pro‑Preview 是唯一稳定超过 3 岁基线的模型，但&lt;strong&gt;距离 6 岁儿童仍差约 20 个百分点&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是其中一道题，直观且反直觉，连线垃圾分类，小孩可以轻松做对，但顶尖模型追踪一条线都能追丢。&lt;/p&gt;&lt;p&gt;任务：三件物品沿着线分别连到哪个颜色垃圾桶？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVG7PticNxtFicKCaSwqYHFMQwzpf5ly3xFtmsnO0jDkXO87RumNq8xEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527859" data-aistatus="1" data-original-style="width:411px;height:325px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/892326aa-9ed8-412f-83e1-d377498231b9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkApiaZelZxwcLf36b74z4IyYeywSnTAe5PrZhawtKibnsV9icVHC7vibZUbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8843537414965986" data-s="300,640" data-type="png" data-w="882" type="block" data-imgfileid="503527860" data-aistatus="1" data-original-style="width:439px;height:388px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5f732fb9-9bdc-448d-89b8-9fda9e176a17/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;正确答案：A - 蓝，B - 黄，C - 绿&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型答案（Gemini3-Pro-Preview）：A - 绿，B - 黄，C - 蓝&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;人类的解法几乎是本能，从点出发沿线走到终点（&lt;strong&gt;下面照片是三岁幼儿真实做题痕迹&lt;/strong&gt;）。但模型会写出一大段 &amp;ldquo;逐段追踪&amp;rdquo; 的推理，最后仍把两条路径接反：看起来 &amp;ldquo;很会分析&amp;rdquo;，其实在最基础的视觉追踪上掉线。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;03｜BabyVision‑Full 用 388 题，把视觉能力拆成 4 大类能力 22 个子任务&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队将视觉能力提炼为四大核心类别，每类下细分若干子任务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;精细辨别（Fine-grained Discrimination）&lt;/strong&gt;：分辨细微的视觉差异（8 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉追踪（Visual Tracking）&lt;/strong&gt;：跟随路径、线条与运动轨迹（5 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;空间感知（Spatial Perception）&lt;/strong&gt;：理解三维结构及其关系（5 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉模式识别（Visual Pattern Recognition）&lt;/strong&gt;：识别逻辑与几何规律（4 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这套设计的核心理念很明确：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不是为了 &amp;ldquo;刁难&amp;rdquo; 模型，而是量化那些 &amp;ldquo;人类直觉就会、但构成智能地基&amp;rdquo; 的视觉原子能力。这同样是具身智能（embodied AI）走向现实世界的必修课。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了最大程度确保 &amp;ldquo;纯视觉&amp;rdquo; 考核的有效性，BabyVision 在数据构建上也下足了工夫。&lt;/p&gt;&lt;p&gt;项目团队首先参考了儿童认知教材和视觉发育测验，梳理出了上述 4 大类共 22 种基础视觉子任务。&lt;/p&gt;&lt;p&gt;接着，每个子技能挑选出 2-3 个种子示例（种子图片），作为该类型任务的典型代表。基于这些种子示例，研究者利用逆向图像搜索和关键词搜索，从互联网上爬取了约 4000 张相似的候选图片。&lt;/p&gt;&lt;p&gt;在数据收集过程中，团队严格遵守版权规范，只挑选可用于非商业或学术用途的素材，并过滤掉可能包含大量文字说明或需要文化常识才能理解的图片。由此获得的海量图片进入人工标注环节：多名专业人员逐一检查图片，筛除不适合出题的样本，对保留下来的图片精心设计问题和标准答案。为了确保答案的客观正确，每个问题还附有详细的 &amp;ldquo;解题过程&amp;rdquo; 说明，以证明答案确实可由视觉推理得出。&lt;/p&gt;&lt;p&gt;最终，所有标注完成的问题都经过 &amp;ldquo;双盲质检&amp;rdquo;&amp;mdash;&amp;mdash; 两位独立专家交叉审核，每道题只有在双方都认可其答案无误、推理严谨的情况下才被收录 ；若出现异议则退回修改，反复仍无法达成一致的题目则果断弃用。经过这一系列严苛的筛选，BabyVision 最终产出了 388 道高质量视觉题目，涵盖 22 种子任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAU8NkG6THshd0AU6313qseMxg0Mnr1x6SSGpjpXwFlq4GtaFxLpmQcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.175" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527861" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5a98a82d-5bc1-4e47-98fd-9eb1a6f84113/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;最终评测结果：人类 94.1%，最强闭源 49.7%，最强开源 22.2%&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 BabyVision‑Full 上，研究团队引入了人类基线，16 位至少本科背景的测试者完成全量 388 题，人类准确率达&lt;strong&gt;&amp;nbsp;94.1%&lt;/strong&gt;。&amp;nbsp;&lt;/p&gt;&lt;p&gt;再看模型：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;闭源最强：&lt;strong&gt;Gemini3‑Pro‑Preview 49.7%&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其后：&lt;strong&gt;GPT‑5.2 34.8%、Doubao‑1.8 30.2%&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;开源侧：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;最强模型（&lt;strong&gt;Qwen3VL‑235B‑Thinking&lt;/strong&gt;）整体 &lt;strong&gt;22.2%&lt;/strong&gt;，多数模型在 12&amp;ndash;19% 区间。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;更关键的是：&lt;strong&gt;差距不是集中在某一个类别&lt;/strong&gt;。四大类能力都在下滑，说明这是 &amp;ldquo;系统性缺基础视觉能力&amp;rdquo;，而非某个单点缺陷。 一些子任务甚至几乎 &amp;ldquo;全员翻车&amp;rdquo;，例如 &lt;strong&gt;Count 3D Blocks&lt;/strong&gt; 在多模型中普遍偏低，暴露的是模型结构化场景能力不足。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA6K7ZSNW1fC1k1hB7QuIujMbJhebibHxJr20HWutweCmibbfdk9JFSNzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.9537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527862" data-aistatus="1" data-original-style="width:492px;height:469px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/f6d71de4-dd2d-4a73-9958-a533dc035d5d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;04｜为什么会这样？因为这些视觉推理题目是没法用语言描述的（Unspeakable）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最反直觉的地方在于：&lt;/p&gt;&lt;p&gt;BabyVision 里的很多题，对人类来说不难，甚至孩子会用指一指、圈一圈、沿着线走一遍就搞定。&lt;/p&gt;&lt;p&gt;但模型一旦用文字去 &amp;ldquo;复述&amp;rdquo; 视觉，再用语言推理去算，信息就丢了。&lt;/p&gt;&lt;p&gt;研究团队把这种现象概括为：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;这些视觉题是 &amp;ldquo;unspeakable&amp;rdquo; 的，无法在不损失信息的情况下被完整语言化；模型试图把视觉压缩成 token，细节在压缩中消失。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;并进一步总结了 4 类典型挑战：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战 1：看不见 &amp;ldquo;非语言细节&amp;rdquo;（Observing Non-Verbal Details）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAoHiczERwTu9nBSIV96lxpXLTGNBAUjNVmnuRTL5dK5oEwcYuGAmqMAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9316666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527863" data-aistatus="1" data-original-style="width:442px;height:412px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/71e1c1a5-ea0c-4969-9d75-df10a2bd59fb/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;比如拼图 / 补全题里，选项差别可能只是&lt;strong&gt;一个微小边界、一个局部凸起、一个像素级错位&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;人类凭几何直觉 &amp;ldquo;对齐边界&amp;rdquo; 就能秒选；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型一旦把形状用语言概括成 &amp;ldquo;像钩子、两个腿、差不多七八个六边形&amp;rdquo;，细节就被抹平，选项在 token 空间里变得 &amp;ldquo;几乎一样&amp;rdquo;。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;挑战 2：追线追丢了（Manifold Understanding）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVG7PticNxtFicKCaSwqYHFMQwzpf5ly3xFtmsnO0jDkXO87RumNq8xEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527864" data-aistatus="1" data-original-style="width:399px;height:316px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7c82cac3-ee8c-49fd-9532-63643cf6e84a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;连线 / 绕线 / 轨迹题，答案编码在 &amp;ldquo;连通性&amp;rdquo; 里：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;人类是&lt;strong&gt;锁定一条线&amp;rarr;穿过交叉&amp;rarr;一路追到终点&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型往往把线翻译成 &amp;ldquo;左 / 右 / 上 / 下&amp;rdquo; 的离散步骤，一遇到交叉点就出现分叉爆炸，&lt;strong&gt;容易 &amp;ldquo;换轨&amp;rdquo; 追错线&lt;/strong&gt;。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;挑战 3：缺少真正的空间想象（Spatial Imagination）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4rsCA4xeU6OBqfcgbBE8QJd4x4gOFmyBiciaFnjIKKCJ2L9FsgXT145w/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.97" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527865" data-aistatus="1" data-original-style="width:415px;height:403px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/38f54f76-6739-4440-ae53-5012c6ca8c92/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;三维方块计数、视角投影、遮挡下的结构判断，人类通常不是 &amp;ldquo;用语言一步步描述&amp;rdquo;，而是把结构在脑中 &amp;ldquo;立起来&amp;rdquo;，换个角度看，再数。&lt;/p&gt;&lt;p&gt;模型则容易犯两类错误：&lt;strong&gt;漏掉隐藏块、投影关系搞错&lt;/strong&gt;。这不是逻辑差，而是缺少稳定的 3D 内部表征与变换能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战 4：图形规律归纳难（Visual Pattern Induction）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZdItK1Dbetp1raMxwcRUaicTBNOdBvxgKwE63PwhRbRmGxFjTcV5Wog/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.7536764705882353" data-s="300,640" data-type="png" data-w="816" type="block" data-imgfileid="503527866" data-aistatus="1" data-original-style="width:443px;height:334px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/08ee768c-cff8-470b-b552-6a22e631e03a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这类题要求从少量视觉示例里抽象出规则，再迁移到新图。&lt;/p&gt;&lt;p&gt;人类做的是关系映射，真正决定正确性的是 &amp;ldquo;&lt;strong&gt;发生了什么变化&lt;/strong&gt;&amp;rdquo; 而不是 &amp;ldquo;&lt;strong&gt;那里有什么&lt;/strong&gt;&amp;rdquo;，具体的形状、颜色、绝对位置都可以变，只有它们在变换中的 &amp;ldquo;身份&amp;rdquo; 不变。&lt;/p&gt;&lt;p&gt;模型常常盯着表面属性（颜色、形状），把 &amp;ldquo;结构规则&amp;rdquo; 误读成 &amp;ldquo;外观统计&amp;rdquo;，导致迁移时幻觉规则。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;05｜如果不让它用文字回答，让它 &amp;ldquo;画&amp;rdquo; 呢？BabyVision‑Gen 给出一个新方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当文本推理不够用，一个自然的问题出现了：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;能不能让模型像孩子一样，用画、圈、连线、描轨迹来作答？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;于是有了 BabyVision‑Gen：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从原基准中重新标注出&amp;nbsp;&lt;strong&gt;280 道&lt;/strong&gt;适合 &amp;ldquo;生成式作答&amp;rdquo; 的题&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求模型输出图像 / 视频来表达解题过程或答案&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;并开发了自动评测工具，与人工评测一致性达 &lt;strong&gt;95%&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队在 BabyVision‑Gen 上评测了多种生成模型（包括 Nano‑Banana‑Pro、Qwen‑Image、Veo‑3、Sora‑2）。现阶段得到的结论很克制但重要：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;生成式推理在视觉追踪、精细辨别等 VLM 易翻车任务上出现 &amp;ldquo;更像人类&amp;rdquo; 的行为（会真的去画轨迹、做标注）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但整体仍然缺乏稳定到达完全正确解的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这至少说明：把视觉推理 &amp;ldquo;落地到视觉操作&amp;rdquo; 上，可能是补齐短板的一条路。&lt;/p&gt;&lt;p&gt;下面看一个具体的例子：&lt;/p&gt;&lt;p&gt;任务：用红线沿着从左上角图形延伸出的那条线，完整地描出其全程路径。&lt;/p&gt;&lt;p&gt;Sora2&lt;a href="https://mp.weixin.qq.com/s/-uCVMlIJKaQ80YSBzhRFOw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6f413c5f-44af-4675-8ba7-48e14bf120e2/1768194840251.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAc7uK2NthD9btBqJhXQbybcGxauqWkX6QRniawY9gP9gbXmOBN0mYJicw%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4338405709814808591" data-ratio="1.7777777777777777" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4338405709814808591" data-vh="380.8125" data-vidtype="2" data-vw="677" data-w="1280" height="393" scrolling="no" width="677"&gt;&lt;div data-key="wxv_4338405709814808591"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;NanoBanana-pro&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA3Eg5KqoBEbHcWj6NQnZ9ddl9pa33KXGHBG3SdFCNgxUB8ibhrq3IOKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.9253731343283582" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503527871" data-aistatus="1" data-original-style="width:491px;height:454px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/fa2e6b89-b019-4719-95be-2130bcd1d160/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;06｜为什么 BabyVision 重要？因为现实世界不靠语言提示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;正如研究团队在 Blog（https://unipat.ai/blog/BabyVision）中所写：&lt;/p&gt;&lt;p&gt;很难想象一个视觉能力低于 3 岁孩子的机器人，能够可靠地在真实物理世界里帮助人类。&amp;nbsp;&lt;/p&gt;&lt;p&gt;今天，多模态模型 &amp;ldquo;会说会写&amp;rdquo; 已经很强。&lt;/p&gt;&lt;p&gt;但要走向真正的通用智能与具身智能，视觉地基必须补上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;看得准（细粒度辨别）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;追得住（轨迹 / 连通性）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;想得出（3D 结构想象）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归纳得了（图形规则迁移）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;BabyVision 的价值正在于：把 &amp;ldquo;看懂世界&amp;rdquo; 拆成可测量、可诊断、可迭代的 22 个原子能力，告诉我们差距到底在哪里、下一步该补什么，从而引导多模态大模型发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;UniPat&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;UniPat AI 致力于构建真实场景下 AI 训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。&lt;/p&gt;&lt;p&gt;官网链接：https://unipat.ai&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026 Oral｜快手提出全新「检索数据引擎」CroPS，打破搜索信息茧房</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:07:40 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8810ff32-b049-412f-8061-caa79c22c3ed/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;短视频搜索业务是向量检索在工业界最核心的应用场景之一。然而，当前业界普遍采用的「自强化」训练范式过度依赖历史点击数据，导致系统陷入信息茧房，难以召回潜在相关的新鲜内容。&lt;/p&gt;&lt;p&gt;针对这一问题，&lt;strong&gt;快手搜索团队提出了一套全新的检索数据引擎 CroPS（Cross-Perspective Positive Samples）&lt;/strong&gt;。该方法通过引入用户换 Query 数据、推荐流数据以及大模型生成的世界知识，多视角丰富了正样本信号，并结合层次化标签分配（HLA）策略和 H-InfoNCE 损失函数，实现了对相关性的精细化建模。&lt;/p&gt;&lt;p&gt;目前，CroPS 已在快手搜索业务中实现全量部署，服务亿级用户。实测表明，&lt;strong&gt;该方案在具备极强的架构普适性的同时，显著提升了 CTR 与长播率，并有效降低用户换 Query 率，优化用户搜索体验。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本工作相关成果《CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search》已被人工智能顶级会议 AAAI 2026 Oral 接收。&amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gTjyyR9ATcQ5PfPHZHibaoq1jyTgib0P5vrO3wTXFxCMU4zEI0FjYfAJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.22592592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527340" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8f756158-097c-4449-95cc-40c2baf8aefd/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2511.15443v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前工业界主流的向量检索模型通常采用对比学习范式进行训练，拉近 Query 与正样本在向量空间中的距离，同时推远与负样本的距离，从而学习内容相关性。&lt;/p&gt;&lt;p&gt;然而，在绝大多数工业系统中，&lt;strong&gt;训练数据的正样本高度依赖历史曝光日志中的用户交互行为（如点击），导致「自强化」循环发生&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;具体而言，模型倾向于检索与历史高频点击内容相似的视频，用户受限于展示结果，只能在有限内容中选择和反馈，而这些反馈又再次作为正样本进入下一轮训练，进一步强化了模型原有的偏好。&lt;/p&gt;&lt;p&gt;这种机制不可避免地引发了严重的样本偏差。一方面，大量潜在相关但从未获得曝光机会的优质长尾内容，被系统性地排除在正样本之外，甚至在随机负采样过程中被错误标记为负样本。这种偏差使模型的检索视野逐渐狭窄，搜索结果变得保守且单一。&lt;/p&gt;&lt;p&gt;另一方面，由于缺乏对新颖内容的探索能力，用户的搜索体验逐渐固化，难以在结果中获得惊喜或满足探索性需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gq62JOOOPgCqKE8xKCibiakejibHWoI8VZG4oG5tAicCia83Wd157SwjoUIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527341" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5bfb1380-8ec2-4407-8846-2ec8b7f9420d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;以往的学术研究多致力于改进模型结构（如引入交互更复杂的 Poly-Encoder）或优化负采样策略（如挖掘困难负样本），从而提升检索性能。虽然这些方法在一定程度上增强了对已知内容的判别能力，但始终在历史曝光数据的界限内打转，无法从根本上缓解正样本来源单一所带来的 &amp;ldquo;信息茧房&amp;rdquo; 效应。&lt;/p&gt;&lt;p&gt;针对这一挑战，&lt;strong&gt;快手搜索团队提出了 CroPS 框架，从根源上打破数据闭环。CroPS 首次在业界引入「跨视角」的正样本信号，重塑了检索模型的训练图景。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g7ufbJ6VkJAs6Zib8HB5kgug107N1QastqsJb7ibiahX05YVSE1u1ZUXXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.40925925925925927" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527342" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/531a315e-d13f-42c5-9f7e-27242cd6b4ee/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;多视角正样本增强引擎 CroPS&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了打破数据边界，CroPS 框架构建了一个包含三个维度的正样本增强引擎，分别利用用户换 &amp;nbsp;Query 行为、推荐系统反馈以及大语言模型（LLM）的世界知识，来全方位地丰富语义空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 基于用户换 Query 行为的查询级增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在真实的搜索场景中，用户往往难以一次性精准表达意图。当用户输入查询词 A 却未能找到满意结果时，通常会进行查询重构，输入语义相关但表述不同的查询词 B。如果用户在查询词 B 的结果下产生了深度交互，那么该交互视频在语义上极有可能是查询词 A 的理想正样本，尽管它从未在 A 的结果中获得足够的曝光。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CroPS 敏锐地捕捉到了这种「意图连续性」&lt;/strong&gt;。通过分析用户在短时间窗口内的改写序列，并利用轻量级语义判别器进行过滤，系统能够将改写后获得的成功点击 &amp;ldquo;回流&amp;rdquo; 给原始查询，利用用户的修正行为来纠正模型的语义偏差。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 打破搜推壁垒的系统级增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;推荐系统拥有海量用户消费数据，并且其算法机制天然倾向于发散和探索，因此推荐流中的视频往往具有更丰富的多样性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CroPS 建立了一套跨系统的信号桥接机制&lt;/strong&gt;：对于同一个用户，如果他在推荐信息流中深度消费了某个视频，且该视频在语义上与用户近期的搜索词高度相关，该视频就会被引入作为搜索模型的正样本。&lt;/p&gt;&lt;p&gt;通过这种跨系统的信号融合，搜索模型能够利用推荐系统的探索能力，将用户感兴趣但未主动搜索到的内容纳入召回视野，从而有效缓解单一系统带来的位置偏差和曝光偏差。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 引入大模型的知识级增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当平台现有的内容库或日志无法覆盖某些长尾、复杂查询时，单纯依赖内部数据是无解的。为此，&lt;strong&gt;CroPS 引入了大语言模型（LLM）作为「虚拟检索器」和「内容生成器」，利用 LLM 蕴含的丰富世界知识生成高质量合成样本&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;具体而言，系统采用单样本提示（One-shot Prompting）策略，让 LLM 扮演视频内容专家，针对特定查询生成包含标题、描述和标签的虚拟视频元数据。将这些合成数据作为正样本，训练双塔模型，相当于将外部世界的常识与逻辑 &amp;ldquo;蒸馏&amp;rdquo; 进检索模型中。&lt;/p&gt;&lt;p&gt;这一方法使得模型在面对「冷门」或「从未见过」的搜索 query 时，仍能够凭借语义理解能力找到相关内容，从而彻底突破平台存量数据的限制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g0j3xoTSpJgYTKfp4hvg2TxfNmudjI4sNRMM1eqiaMcV0NNqU3G8l98Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.6684931506849314" data-s="300,640" data-type="png" data-w="730" type="block" data-imgfileid="503527348" data-aistatus="1" data-original-style="width:480px;height:801px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/51ecd71d-5f01-4855-8f45-9baca2bf9d5c/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;层次化标签分配 (HLA)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;HLA 的核心是解决 CroPS 多源正样本的「可靠性差异」问题&lt;/strong&gt;。不同来源的正样本（比如：用户换 Query 后产生互动的视频、推荐流中的视频）与用户真实需求的契合度各不相同。如果一视同仁进行训练，模型可能难以抓住重点。&lt;/p&gt;&lt;p&gt;因此，HLA 为样本分配「分层标签」，让模型能够识别样本的重要程度，从而学习更细粒度的相关性，更好地契合系统优化目标。&lt;/p&gt;&lt;p&gt;具体来说，HLA 将样本划分为「正样本相关层级」和「负样本层级」，为后续训练提供「细粒度监督信号」，不同类型样本对应固定标签，具体如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gm1meuoWKUGo49zsenuKHfdG6NviasicVxDZ3M9cDOib4HDshaz2oicATOA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6240601503759399" data-s="300,640" data-type="png" data-w="1064" type="block" data-imgfileid="503527350" data-aistatus="1" data-original-style="width:496px;height:310px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f4ea35eb-c1a3-4fd8-8315-af8c6100fa0b/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;H-InfoNCE 损失函数&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的语义召回采用的是 InfoNCE 进行优化，默认「样本只有正 / 负两种标签」，会逐个对比「单个正样本」和「对应的负样本」，无法区分 HLA 里「高标签正样本（如上图 Table 1 的标签 5）」和「低标签正样本（如上图 Table 1 的标签 3）」的层次化差异。&lt;/p&gt;&lt;p&gt;而 H-InfoNCE 在训练时，将「当前样本」与「标签严格低于它的所有样本」进行对比。这不仅突显了高优先级样本的重要性，也使学习目标与 HLA 的层级逻辑完全对齐，实现细粒度的语义区分。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;若当前样本是「用户换 Query（标签 5）」&lt;/strong&gt;，H-InfoNCE 会将其与「标签 &amp;le;4 的所有样本（包括推荐正例、曝光未点击样本、负样本等）」 一起对比，强制模型学习「标签 5 样本与查询的相似度，必须高于所有低标签样本」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;若当前样本是「曝光未点击样本（标签 3）」&lt;/strong&gt;，则只需对比「标签 &amp;le;2 的样本」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过这种方式，模型能够逐步掌握「高标签样本更重要」的排序逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gWPibibEia5QV4y3GR6QNeVWo8LyZLy7oUbC3LWmf1Lic1XZLZn41DvtLoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.20925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527351" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/405e3542-6919-40e3-ade4-cbfe18b816a0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; H-InfoNCE 在这里通过样例标签矩阵、样本 mask 矩阵等得到了高效实现。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g2n9X9Ycq80t52lWD9MZVcvHictwXxr1YtXYuZNS6JUnBiarziadwgYibZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.1935185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527352" data-aistatus="1" data-original-style="width:332px;height:64px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fc505d33-3936-451c-a88d-9f2fa6eee5c6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gL5X7e0ElhEI7XD2D1ZFCOPMFfms5D3d0DG8xCSJoRHZLZibKS1S8bmA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527353" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f5fd0547-fb20-4c08-8932-d9468d2482e4/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证这一框架的有效性，团队构建了两类测试集，来衡量模型的召回率 Recall@100：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CT&lt;/strong&gt;：用户点击测试数据集，即用户点击的视频作为正例；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;QR&lt;/strong&gt;：用户换 Query 测试数据集，即用户换 Query 后消费的视频作为正例。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;同时也引入了相关性标注测试数据集，以 NDCG@4 为监测指标，作为模型的相关性表征能力度量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;离线实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文中主要比较了三类主流方法：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;经典方法&lt;/strong&gt;：BM25（概率排序基线）、NCE（传统对比学习）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;神经网络方法&lt;/strong&gt;：DPR（双编码器稠密检索）、ANCE（动态难负样本采样）、ADORE+STAR（NN 模型引入筛选负例）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;负采样策略&lt;/strong&gt;：TriSampler（基于样本的空间位置进行的负例采样）、FS-LR（多级别负标签策略）。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在离线实验测试中，CroPS 相较于最强基线 FS-LR 在 CT 数据集上提升 9.5%，在换 Query 测试集 QR 上提升 7.1%。同时 NDCG@4 和 最强基线相当（67.4%-&amp;gt;67.0%）&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gTudqCG3dEQKmibxxibcApAAFpQMrBot8XBwarvz9d5bFN6tbZ7esIGnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6996047430830039" data-s="300,640" data-type="png" data-w="1012" type="block" data-imgfileid="503527354" data-aistatus="1" data-original-style="width:459px;height:321px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/95c99719-02eb-48bc-9c89-3c1b1a6380ef/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;在线实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在快手搜索的大规模 A/B 测试中，CroPS 带来了全方位的业务增长：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;点击率（CTR）显著提升了 0.869%，长播放率（LPR）提升了 0.483%&lt;/strong&gt;，表明召回的内容不仅相关度高，而且内容质量足以吸引用户长时间驻留。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;用户换 Query 率（RQR）下降了 0.646%&lt;/strong&gt;，意味着用户「一次搜对」的概率大幅增加，不再需要频繁更换搜索词来找到想要的内容，直接反映了用户搜索体验的质变。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g8Qjp9pXtMkkRwbsRWc0htJycocicsCCpAE1SD7icHPJm2ISZvWxNhibAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.4324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527355" data-aistatus="1" data-original-style="width:485px;height:210px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/d003abe1-b43f-407b-a6e2-2155485d6fd8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gkia4x7WvhHricPjwqt1V0eYJUhv7ziaK6ytPEBer85NENZ6PbflHUtheA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.31844660194174756" data-s="300,640" data-type="png" data-w="1030" type="block" data-imgfileid="503527356" data-aistatus="1" data-original-style="width:487px;height:155px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/cd309848-c6d9-422a-a549-1e00a008de69/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CroPS 证明了在工业检索系统中，正样本增强是缓解「信息茧房」问题的有效钥匙，能够提升系统上限。通过跨视角引入多样化信号，并结合精细化优化策略，&lt;strong&gt;CroPS 成功打破了自强化训练的边界&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;未来，快手搜索团队将进一步探索 CroPS 与生成式检索（Generative Retrieval）方法的融合，持续挖掘大规模语言模型在搜索全链路中的潜力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>被Jim Fan点赞！全球第一的千寻智能Spirit v1.5正式开源！</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 10:25:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/63add113-7164-4987-a0a2-3c9161545a00/1768184391206.png" style="width: 700%;" class="fr-fic fr-dib"&gt;提到具身智能，你首先会想到什么？&lt;/p&gt;&lt;p data-path-to-node="6"&gt;是宇树在春晚惊艳亮相的「转手绢」、特斯拉 Optimus 的「金色传说」、真到被怀疑真假的小鹏，还是 2025 年各家竞相上演的「炫技大赏」，空翻、家务、热舞、打拳，无所不能？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagaq2pZsdiaGuwia1qA24doNdnLia2tjW8icRummRjjLhYoFckLLla3QGOiag/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.0574074074074074" data-type="png" data-w="1080" data-width="2731" data-height="2887" data-imgfileid="503527693" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/23a674e8-7332-44f0-9895-229d6cd79063/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="7"&gt;已经过去的 2025 年，无疑是具身智能大爆发的一年。&lt;/p&gt;&lt;p data-path-to-node="8"&gt;热闹属于硬件，但具身智能还有另一个关键赛道：&lt;strong&gt;具身智能与机器人基础模型&lt;/strong&gt;，即具身智能的「大脑」。它们定义了具身智能的智力天花板，也长期主导了行业对「通用性」的解释权。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;在这个赛道，过去两年的叙事主线几乎被 Pi、Google、Figure 等海外团队主导。但在 2026 年伊始，格局发生了变化。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;1 月 12 号，千寻智能（Spirit AI）开源了自研 VLA 基础模型&amp;nbsp;&lt;strong&gt;Spirit v1.5&lt;/strong&gt;，该模型在第三方机器人模型评测组织&amp;nbsp;&lt;strong&gt;RoboChallenge 的 Table30 榜单上位列第一，超过了之前最强模型 Pi0.5&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz2lTewrr9WmOZnw1s0gjGVYzcPc56VXjKcO9TygF7ycWL6feaEzXTlQ/640?wx_fmt=jpeg#imgIndex=2" data-ratio="0.4777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz3seibTdcUYARKbzhptcuhEjBUGUg65ickic0EAib6lucEKWzMQqKCia0x1g/0?wx_fmt=png&amp;from=appmsg" data-cropx2="2940" data-cropy1="172.9411764705882" data-cropy2="1576.8166089965396" data-imgfileid="503527823" data-aistatus="1" data-original-style="width: 578px;height: 276px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/842144eb-116f-4460-acb5-88c4daae8cb6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;千寻开源了Spirit v1.5的基模权重、推理代码以及使用样例，接受公众检验，也方便社区在 Spirit v1.5 的基础上创新。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Code: https://github.com/Spirit-AI-Team/spirit-v1.5&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Model: https://huggingface.co/Spirit-AI-robotics/Spirit-v1.5&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Blog：https://www.spirit-ai.com/en/blog/spirit-v1-5&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="13"&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7a81cc85-59b3-4311-935f-fab796c3c5b6/1768184432544.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/734660a4-01f6-4883-8ed9-7154720bb4c9/1768184448166.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Spirit v1.5 vs Pi0.5 视频对比。上：Spirit v1.5，下：Pi0.5。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="15"&gt;这一手「硬核登顶+开源共享」的组合拳，引发了海外 AI 社区的即时关注，甚至引来了&lt;span data-pm-slice="0 0 []"&gt;英伟达具身智能负责人 Jim Fan（&lt;/span&gt;&lt;span data-type="text"&gt;范麟熙&lt;/span&gt;&lt;span data-type="text"&gt;）的点赞、&lt;/span&gt;Hugging Face 的官方祝贺，以及多位海外大 V 的转发。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzOXDEj1pphPXGQjqW1p18nCwHXCicZRCLBicib6C5czrogxRn0hyiahCgxg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5314814814814814" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527853" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0f9123a8-ae9a-4623-b24d-472df9339db8/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzSqa4ic1CcX6BdjN9vSH0b1a3zB0MguOZmYJF4MCZ2U3jQZrp89ouwnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.298148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527855" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/743a3b40-a0d8-4fbf-bcdb-1459baecb5ce/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzC4neKSzdZV6pqibyoGiadqAu6lmq0XuGYQuAEiatIImIZicDHKibj1Iz0Qg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0083333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527854" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/8a80b8b0-3366-4177-b800-dbeff0824146/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="17"&gt;这不再是一次简单的榜单轮换。它意味着，在具身智能这个未来的核心战场上，中国团队终于结束了「跟随模式」，正式拿到了「全球第一梯队」的入场券。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;Spirit v1.5 为什么能赢 Pi0.5？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;要回答这个问题，我们必须先看一眼「竞技场」。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;RoboChallenge 是由 Dexmal、Hugging Face 和智源研究院等机构发起的全球首个大规模真机评测平台。与常见的仿真环境跑分不同，RoboChallenge 的核心在于&lt;strong&gt;物理世界的真机实测&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="21"&gt;平台建立了一套名为「Table30」的任务集，包含设定在桌面环境中的 30 个多样化操作任务。这些任务不仅涵盖插花、制作三明治、插入网线等日常技能，还被特意设计用来挑战模型能力的各个维度：包括精确的 3D 定位、遮挡处理、时间依赖性以及多阶段长序列任务。&lt;/p&gt;&lt;p data-path-to-node="22"&gt;在该体系下，Spirit v1.5 在多构型机器人（包括 Franka、Arx5、UR5 及双臂 ALOHA 系统）上均进行了评测。截至 2026 年 1 月 12 日的评估显示，Spirit v1.5 在该基准测试上超越了 Pi0.5 等之前的全球领先开源模型，取得了当前最优的性能。&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a72a15c0-542e-4f4c-9e73-bd3adced34cc/1768184491629.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8b77dd1-20f7-4546-9980-a12aa28237b2/1768184508699.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Spirit v1.5 vs Pi0.5 视频对比。上：Spirit v1.5，下：Pi0.5。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="24"&gt;Spirit v1.5 的胜出并非偶然，其核心原因在于对机器人预训练数据范式的根本性重构。&lt;/p&gt;&lt;p data-path-to-node="25"&gt;&lt;strong&gt;摆脱「干净数据」的诅咒，转向「物理常识」的习得&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="26"&gt;传统的具身模型，大多基于如 Open X-Embodiment (OXE)、Agibot 和 RoboCOIN 等数据集进行训练。这些数据集虽然规模庞大，但主要由高度精选的、即所谓的「干净」数据组成。&lt;/p&gt;&lt;p data-path-to-node="27"&gt;在这种模式下，为了最大化采集成功率，研究人员往往像电影导演一样精心设计场景：物体被放置在可预测、易于触及的位置，动作被简化或脚本化。这种「完美」的数据虽然为模型提供了一个稳定的起点，但却产生了一个致命的副作用：经验的零散孤岛。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;如果在训练中，「擦桌子」的数据集永远只包含桌子和标准的擦拭动作，模型就永远学不会如何在抹布打滑后恢复，或者如何处理桌面上意料之外的杂物。这种过度「净化」的数据限制了机器人的泛化能力，一旦面对开放世界的不可预测性，模型极易失效。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;相比之下，Spirit v1.5 采用了「&lt;strong&gt;开放式、目标驱动&lt;/strong&gt;」的数据采集策略。其核心理念是摒弃书面脚本，只给操作员一个模糊的高层目标（如「清理厨房」），允许其即兴发挥。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;在 RoboChallenge 的 Table30 测试中，Spirit v1.5 展现出的跨场景泛化能力主要得益于以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="31,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="31,0,0"&gt;构建连续的技能流形&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="31,0,0"&gt;传统数据制造了任务间的割裂，而 Spirit v1.5 的数据采集员可能会先拿起食物容器，发现碎屑后开始擦拭，接着整理餐具。这种连续的会话将多个微技能自然串联，涵盖了抓取、扭转、插入和复杂的双手协调。&lt;/p&gt;&lt;p data-path-to-node="31,0,0"&gt;这意味着模型不再是机械地重复单一动作，而是学习到了动作与动作之间的过渡与衔接。如同案例所示：无论是给假人模型化妆，还是组装复杂的乐高结构，模型掌握的是一个原子技能谱系，而非孤立的动作片段。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="31,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="31,1,0"&gt;内化的纠错与恢复能力&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="31,1,0"&gt;这是 Spirit v1.5 区别于传统模型的关键。由于训练数据通过「将采集员派往现实环境中的随机地点」获得，包含了海量的物体交互和环境转换，模型见识过各种失败与混乱。因此，Spirit v1.5 习得了类似人类的「物理常识」。&lt;/p&gt;&lt;p data-path-to-node="31,1,0"&gt;当面对复杂操作中的干扰、物体打滑或光线突变时，模型展现出了惊人的韧性，它学会了在动作执行受阻时如何进行动态调整和恢复，而不是像脚本机器那样直接死机。&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d7d0b905-3291-460b-8346-3c3a90ed71e9/1768184549448.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/ZrBDFuugPyuoQp4S6wEBWQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d0550c10-f5ea-4767-96b8-5904c18d9a76/1768184566003.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="31,1,0"&gt;&lt;sup&gt;多样化采集数据示例。上：采集员通过末端执行器操作给假人模型化妆。下：采集员组装复杂的乐高结构。两个案例都展示了多样化原子技能的连续流，包括抓取、扭转、插入和复杂的双手协调。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;模型不是「更大」，而是「更对」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;技术报告中的消融实验进一步证实，Spirit v1.5 的优势源于更高效的数据利用策略，而非盲目的算力扩张。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;实验建立了两组模型进行对比：A 组使用精选演示数据，B 组使用开放式多样化数据，且保持两组的总数据量完全相同。结果揭示了显著的「多样性增益」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="36,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="36,0,0"&gt;收敛速度与迁移效率&lt;/b&gt;：在针对全新任务微调时，使用多样化采集训练的模型（Spirit 策略）达到相同性能基线所需的迭代次数比基线模型少了 40%。这表明，任务的多样性比单任务的演示数量更为关键。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagwSj7Xdgjjt9UCQkWiaEjKtjmd6dcKgUeKGVlVkUsGkreSJdojfb1UWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6" data-type="png" data-w="1080" data-width="1280" data-height="768" data-imgfileid="503527719" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5bd3aa2d-4091-4b4f-804b-60b70f9cc752/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="36,0,1"&gt;&lt;sup&gt;多样化采集预训练的模型比干净数据采集训练的模型具有更快的收敛速度和更好的验证误差。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="36,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="36,1,0"&gt;验证误差的持续下降&lt;/b&gt;：研究还发现，随着多样化数据规模的扩大，模型在新任务上的验证误差呈持续下降趋势。这证明模型正在有效地从现实世界日益增加的内在多样性中汲取养分，形成了一种通用的策略基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagQtQia5TLzd43UnA7OWLH20IeCJ6oPsEnRmEX9bqWKibvB7cSlTfkobvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6" data-type="png" data-w="1080" data-width="1500" data-height="900" data-imgfileid="503527720" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9d7a395b-55c9-4d80-927a-a6b71cf344e7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="36,1,1"&gt;&lt;sup&gt;不同数据规模下的模型效果。扩大多样化采集的数据规模可以持续降低模型的验证误差。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="37"&gt;&lt;strong&gt;既是「榜单杀手」，也是「工程利器」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="38"&gt;除了在学术榜单上领先，Spirit v1.5 在工程落地层面也解决了困扰行业已久的可扩展性的难题。&lt;/p&gt;&lt;p data-path-to-node="39"&gt;传统的「干净数据」采集需要工程师团队设计任务、编写详细指南并严格筛选数据，这种工作流程极大地限制了数据采集的体量和扩展性。&lt;/p&gt;&lt;p data-path-to-node="40"&gt;Spirit v1.5 采用的非结构化采集方式，允许操作员在只设定高层目标（如「清理厨房」）的前提下即兴发挥。这种范式转变带来了巨大的工程效益：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="41,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="41,0,0"&gt;采集效率提升&lt;/b&gt;：数据显示，人均有效采集时长增加了 &lt;strong&gt;200%&lt;/strong&gt;。因为操作员不再是重复数百次枯燥的机械动作，而是像玩游戏一样在物理世界中互动，保持了极高的投入度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="41,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="41,1,0"&gt;专家依赖降低&lt;/b&gt;：这种流程将对算法专家干预的需求削减了 &lt;strong&gt;60%&lt;/strong&gt;。这意味着，大规模扩展数据采集规模不再受限于稀缺的专家资源，管理成本不再线性增加。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="42"&gt;目前，Spirit v1.5 的基模权重、推理代码以及使用样例已全部开源，供研究人员复现和探索。这不仅证明了其作为「实战派」模型的底气，也为通用机器人从实验室走向真实的家庭和产线环境铺平了道路。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;&lt;strong&gt;中国开源力量的突破性进展&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="44"&gt;如果说技术上的超越是 Spirit v1.5 的「硬实力」，那么选择全量开源则是其更具产业价值的决定。&lt;/p&gt;&lt;p data-path-to-node="45"&gt;回顾过去两年，从 Qwen、DeepSeek 到 Kimi、GLM 等，中国的大模型团队已经证明了这一点：&lt;strong&gt;开源模型不仅能追平闭源模型的性能，更能成为推动全球技术平权的重要基础设施。&lt;/strong&gt;这些来自中国的开源力量，实际上已经成为了许多海外开发者构建应用的首选基座。&lt;/p&gt;&lt;p data-path-to-node="46"&gt;不可否认，「开源共建」也已逐渐成为具身智能领域的行业共识，但拼图尚未完整。&lt;/p&gt;&lt;p data-path-to-node="47"&gt;高性能的机器人基础模型（如 Google RT 系列或 Pi）大多处于闭源或半闭源状态。开发者往往面临「两难」：要么使用性能较弱的旧模型，要么依赖大厂的 API，不仅成本高昂，且难以针对特定硬件进行适配。这种「基座缺失」直接制约了具身智能从实验室走向产业落地的速度。&lt;/p&gt;&lt;p data-path-to-node="48"&gt;Spirit v1.5 的开源，标志着&lt;strong&gt;中国团队正在将 LLM 领域的开源繁荣，延续到具身智能领域&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="49,0,0"&gt;&lt;strong&gt;对于科研界&lt;/strong&gt;，它打破了「无 SOTA 可用」的局面，提供了一个与 Pi0.5 同等甚至更强的可复现基线；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="49,1,0"&gt;&lt;strong&gt;对于产业界&lt;/strong&gt;，它为大量试图进入具身智能赛道的中小型厂商，提供了一套经过验证的、可商用的技术底座，避免了行业性的重复造轮子。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="50"&gt;从 Qwen、DeepSeek 到 Spirit，中国团队正在通过高质量的开源贡献，逐渐从全球 AI 生态的「参与者」转变为关键基础设施的「建设者」。&lt;/p&gt;&lt;p data-path-to-node="51"&gt;&lt;strong&gt;结语：从「追随」到「定义」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="52"&gt;RoboChallenge 的榜首位置或许会轮换，数据的记录终将被刷新，但 Spirit v1.5 的出现具有明确的界碑意义：&lt;/p&gt;&lt;p data-path-to-node="53"&gt;它通过实验证明了「&lt;strong&gt;非结构化的多样性是比精选数据更好的老师&lt;/strong&gt;」。在通往通用具身智能的道路上，中国团队已经结束了单纯的「跟随模式」，具备了在核心技术路径（数据范式）与生态建设上与全球顶尖团队「对等对话」甚至「定义规则」的能力。&lt;/p&gt;&lt;p data-path-to-node="54"&gt;随着代码仓库的公开，全球的目光和测试数据将涌向 Spirit v1.5。对于千寻智能而言，登顶榜单只是一个开始，真正的考验才刚刚拉开序幕：如何在真实世界的千万种场景中，经受住全球开发者的验证与打磨。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Sakana让AI互相「猎杀」，而它们开始了趋同进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:59:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3068ed3b-cfe2-4d99-89f8-d577333542b7/1768139698064.png" style="width: 700%;" class="fr-fic fr-dib"&gt;想象一下，一群 AI 程序在一台虚拟计算机里相互猎杀，目标只有一个：&lt;strong&gt;生存&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是 Sakana AI 与 MIT 合作的最新研究：&lt;strong&gt;Digital Red Queen（DRQ）&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagibdw6SsGTU6xk0b1YGDb2wEeZ1J1dzUQBib0icyibw4tkRVPzTrPwQrp4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.25" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527661" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/adfc502c-97d9-40e5-ab6e-194779bd3adf/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他们重拾了 1984 年的经典编程游戏《Core War》，利用大模型驱动了一场跨越维度的「军备竞赛」。&lt;/p&gt;&lt;p&gt;在这里，没有预设的标准答案，只有不断进化的对手。简单来说，他们提出了一种自演化汇编代码的方法。该方法通过在《Core War》中不断战斗来迭代代码演化。与静态优化目标不同，通过训练新「战士」对抗不断变化的对手，可以生成既健壮又通用的「战士」。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7f4932a6-6d4a-4df7-bf4b-b321845c4d76/1768139718803.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种「自博弈」模式产生出的汇编代码，不仅展现出了惊人的复杂性，更揭示了人工生命中一种有趣的现象：&lt;strong&gt;趋同进化&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVaggSsQIxt8ZYZrsggf3MmE4HibalBH8DhgPIGPMhicHk3GCuybXj9QybHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.24351851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527663" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8d7cb0f6-e4ca-496a-b3a4-1eb06759f949/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.03335&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/SakanaAI/drq/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;博客地址：https://sakana.ai/drq/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;《Core War》 是一款诞生于 1984 年的竞技编程游戏，在这款游戏中，被称为「战士」（warriors）的程序在一个虚拟计算机中争夺控制权。参赛者需要使用一种名为 Redcode 的专用汇编语言来编写程序。&lt;/p&gt;&lt;p&gt;在这项研究中，Sakana 探索了一个全新设定：&lt;strong&gt;当 LLM 驱动这个游戏时，会发生什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于静态评测基准，他们构建了一个动态的对抗演化环境，在其中程序不断适应、进化，以击败逐渐累积的对手历史，而非一组固定敌人。然后发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;这一动态对抗过程促使模型产生了越来越通用的策略；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不同的程序实现最终会趋向于相似的高性能行为模式，展现出类似趋同进化（convergent evolution）的现象；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;整体演化过程符合红皇后动态（Red Queen dynamics），即各个智能体不断适应彼此，持续进化但始终处于竞争状态。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终，本研究将《Core War》定位为一个用于研究人工系统中红皇后（Red Queen）动力学的实验沙盒，为分析 AI 智能体在现实世界对抗性环境（例如网络安全）中的演化方式，提供了一个安全且可控的研究环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag3BiazjJ4Z09GrNBUXKwxvJuPhicOOImubykFrMrgxcvvBgf7PyWNQMhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527664" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/36693e3e-a3c6-4a92-90a9-3ebc4d97b6b3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVaglsxiazYcEdB9U8DEcaWf0FArENhaRnqs7ZORWicmYLm4QuUhfJTTT1lA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4981481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527665" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1e534a9f-00f0-4ae8-9d43-fa1a2054bf6d/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;由 DRQ 生成的两个「战士」程序：Ring Warrior Enhanced v9 和 Spiral Bomber Optimized v22。选取这两个示例是为了展示 DRQ 的两个互补特性：其在单个程序中合成质量上截然不同的策略的能力，以及其生成整体表现良好的「战士」程序的能力。请注意，注释部分由大语言模型生成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/db02af18-13a9-4d9b-abcc-946712c2a368/1768139751093.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;在一个隔离的《Core War》沙盒环境中模拟，演化得到的「战士」程序。用户可以交互式地查看鼠标光标所在位置附近的「战士」汇编语言代码（Redcode）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「战士」程序相互竞争 &amp;nbsp;争夺一台虚拟机的控制权&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人类是一场非凡的进化军备竞赛的产物，在与其他生物体持续不断的竞争中被塑造而成。然而，进化并没有停止：竞争仍然在各个层面持续存在，从病毒与细菌，到人类个体、公司之间多方面展开博弈。&lt;/p&gt;&lt;p&gt;随着越来越多的人工智能系统被部署到现实世界中，它们也将不可避免地进入这一竞争格局。这些 AI 系统将以直接或间接的方式相互竞争，从而引发一种全新的演化动态。&lt;/p&gt;&lt;p&gt;为了为这样的未来做好准备，并研究其中演化过程，Sakana 使用 LLM 来演化一组程序，让它们在《Core War》的游戏中相互竞争，这些竞争者的任务是在尽可能长的时间里保持自身进程活跃的同时，尝试使对手程序崩溃，从而取得对一台虚拟计算机的控制权。&lt;/p&gt;&lt;p&gt;整个模拟过程通过交替执行各个程序中的一条指令来运行。一个「战士」可以通过向对手占据的内存位置写入非法指令（如 DAT 命令）来发起攻击，一旦对手程序执行到该位置就会崩溃。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/14b2adbf-7651-4530-a5d9-7aae7db9ff90/1768139769993.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;在《Core War》中相互对战的已发现「战士」示例。在本研究中，Sakana 使用 LLM，通过 Digital Red Queen 的自博弈算法来演化「战士」。这一过程促使出现了多种多样且复杂的策略，包括定向轰炸、自我复制以及大规模多线程。在这里，本文展示了一些被发现的「战士」在《Core War》对战中的表现。图中符号表示指令操作码，颜色表示最后一次修改每个内存地址的「战士」。代码和数据之间没有区分，使得该环境高度动态且不稳定。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，在《Core War》中，代码和数据之间没有界限，因此「战士」程序会在运行过程中频繁地修改自己和对手的代码。&lt;/p&gt;&lt;p&gt;这使得自我修改甚至自我复制成为可能，但也造就了一个极度不稳定的环境，程序必须在这种条件下设法生存下来。&lt;/p&gt;&lt;p&gt;此外，《Core War》是图灵完备的，也就是说，从理论上它可以支持任意复杂的策略。&lt;/p&gt;&lt;p&gt;多年来，人类玩家在《Core War》中设计出了许多巧妙的策略，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;向随机内存位置投放炸弹；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;编写可自我复制的程序；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不断扫描内存，侦测对手位置并发起攻击。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些策略的诞生，实际上是一场由人类主导的元军备竞赛，玩家不断尝试新策略，测试哪些能奏效、哪些不行。&lt;/p&gt;&lt;p&gt;那么，如果我们让 LLM 也参与这样一场军备竞赛，会发生什么？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新提出的方法：数字红皇后（DRQ）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在进化生物学领域，&lt;strong&gt;「红皇后假说（Red Queen Hypothesis）」认为物种必须不断进化，仅仅是为了在千变万化的竞争对手面前生存。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该假说指出，仅仅适应当前环境是不够的。相反，生物必须持续进化 &amp;mdash;&amp;mdash; 不是为了获得优势，而仅仅是为了在这个变幻莫测的世界中维持相对的适应度。&lt;/p&gt;&lt;p&gt;这个概念完美捕捉了对抗性军备竞赛的本质：&lt;strong&gt;即「适应」永远不是一种永久状态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个名字源于《爱丽丝镜中奇遇记》，红皇后对爱丽丝说：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;「在这个国度，你必须拼命奔跑，才能留在原地。」&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4a06ca7a-2459-4b73-8743-41f5e5889139/1768139804308.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;受生物学启发，Sakana 构建了一种名为数字红皇后（DRQ）的简单算法，它在计算环境中体现了这一思想。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DRQ 利用 LLM 来在持续的环境变化中让「战士」进化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体来说：它从一个初始战士开始，然后进化出第二个战士来击败第一个。接着，再进化出第三个战士，使其在对抗前两个战士时表现出色，以此类推。这一过程产生了一个战士世系，其中每个后代都适应于由其所有前代定义的不断变化的环境。&lt;/p&gt;&lt;p&gt;Sakana 表示：「DRQ 本身并非旨在成为一种全新的算法。相反，它是先前多智能体和自博弈方法的最小化实现。它被适配到《Core War》领域，旨在隔离并研究持续协同进化（coevolution）的动态。」&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a72f29f3-6f01-40ce-82c1-715e75ceba91/1768139818850.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究发现，&lt;strong&gt;随着 DRQ 运行轮次的增加，战士们逐渐变得更具通用稳健性&lt;/strong&gt;（这一指标通过与未见过的、由人类设计的战士对抗来衡量）。&lt;/p&gt;&lt;p&gt;这提供了一种稳定且持续生产稳健程序的途径，而无需进行「在测试集上训练」（即直接针对大量人类设计的程序进行优化）。&lt;/p&gt;&lt;p&gt;更令人惊讶的是，实验中还观察到独立运行的多个 DRQ 实验（每个实验都从不同的战士开始初始化）会随时间推移，慢慢趋向于演化出具有相似行为的战士。值得注意的是，这种趋同并没有发生在源代码层面，这表明趋同的是「功能」而非「实现」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagJz8eOMUkAibXvfvYPic4SW09ozOhvUPd9H4APEXAu4EicIPcQlnqZgayw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.32314814814814813" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527667" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e789c70d-7800-47b7-8429-f20edef43d25/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;DRQ 的趋同进化：随着轮次增加，DRQ 产生的战士具有更强的通用稳健性。同时，不同独立运行的 DRQ 实验之间，战士行为的差异在减小，表明出现了趋同。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag7NSRuerZmQWszkoNYq7GqnLE1BFA0frTqG9DF2MWIrFPsf3dK3xsBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.45185185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527668" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/35a870f6-c879-448e-9ff4-adb1fc45d915/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表型趋同（Phenotypic Convergence）：轮次增加带来的趋同仅体现在战士的「表型」（行为）上，而非「基因型」（源代码）。这类似于生物学中功能上的趋同，而非 DNA 的趋同。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一结果让人联想到生物学中的趋同进化 &amp;mdash;&amp;mdash; &lt;strong&gt;即相似的功能特征通过不同的机制独立进化了多次。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;例如，鸟类和蝙蝠各自独立进化出了翅膀；蜘蛛和蛇独立进化出了毒液。&lt;/p&gt;&lt;p&gt;在这些案例中，由于环境变化施加的功能需求倾向于这些解决方案，进化最终达成了相似的通用目的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;讨论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「红皇后（Red Queen）」动态及其引发的趋同进化现象在自然界中普遍存在，这表明 DRQ 算法和 Core War 领域的结合，可能为研究对抗性军备竞赛其他特性提供了一个极具潜力的实验环境。通过模拟得到的宏观洞察，可以帮助我们预测 LLM 在现实世界中的军备竞赛将如何展开与演变。像 DRQ 这样的算法，甚至有助于在系统部署到现实世界之前，实现自动化的红队测试（red-teaming）。&lt;/p&gt;&lt;p&gt;在《Core War》这样的沙盒中进行此类研究的好处是，它完全自成体系：所有程序都在一台使用人造语言的虚拟机器上运行，因此生成的任何内容都无法在沙盒外执行。这提供了一个安全的环境，可以探索那些在现实世界中进行可能具有风险的对抗性动态。&lt;a href="https://mp.weixin.qq.com/s/bf9E9RS7WwsAOKZ-GneDXg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4ebd7700-3793-4f63-a48f-c1e0d0470d35/1768139852297.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;在沙盒化的《Core War》环境中，可以模拟进化出来的「战士」程序，并将它们的行为可视化。用户可以交互式地可视化这些「战士」的汇编语言（Redcode），并通过鼠标光标所在的位置进行查看。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;尽管基础版 DRQ 算法本身较为简单，但它在《Core War》中表现出乎意料得好，这表明：&lt;strong&gt;即便是最简单的自对弈循环，也能揭示出复杂且鲁棒的策略。&lt;/strong&gt;这使得 DRQ 成为探索其他竞争性多智能体仿真（如人工生命、生物学、药物设计、现实世界网络安全或市场生态系统）的有力候选方案。&lt;/p&gt;&lt;p&gt;未来的工作还可以探索更丰富的设置，让多个智能体能够同时共进化，从而更好地模拟现实世界 &amp;mdash;&amp;mdash; 在那里，大规模种群是并行适应的，而不是沿着单一的演化线发展。最终，所获得的洞察将有助于更好地掌握未来，并帮助我们理解这些进化性军备竞赛背后的科学原理。&lt;/p&gt;&lt;p&gt;更多信息，可查看原论文获悉！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>不做人形、不跳舞：他家的具身智能凭什么在100+城市卖出400万杯咖啡？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:53:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a9465250-5bc6-473b-a7f2-37609d609788/1768139402887.png" style="width: 700%;" class="fr-fic fr-dib"&gt;新年刚开局，AI 行业就直接拉满强度。&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;在 CES 这个全球科技风向标上，机器人 &amp;times; AI 成了真正的主角。在拉斯维加斯的霓虹灯下，中国机器人军团走到舞台中央&amp;mdash;&amp;mdash;不靠堆概念，而是带着订单和规模化落地速度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzcBeHwutPYK2ISjAt65dsn2pKWVRBpsS92Jpklw2Mnk3Pc098bBZLow/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6445945945945946" data-s="300,640" data-type="png" data-w="740" type="block" data-imgfileid="503527777" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/cc53e6d8-1897-4033-9997-5c891dd464d1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;CES创新奖评委Chris Pereira 指出，中国厂商正在把新兴技术，快速转化为能量产、能交付、能在全球市场销售的成熟产品。&lt;/p&gt;&lt;p&gt;与此同时，AI 正退到幕后，成为产品底层能力，真正的竞争，落在实用性、设计与可靠执行力上。&lt;/p&gt;&lt;p&gt;在展会现场，最吸睛的依旧是「人形」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzdLzDmFzia9Y7AQxlYH5Tttan1R5WGn3sgTr8n9oSEzxGLs7Wsxp8obw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.734" data-s="300,640" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="367" data-imgfileid="503527802" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dc1b1cc3-e4a3-498b-aa43-56c10d44055a/640.gif" data-order="0" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 波士顿动力（现在已经属于韩国现代集团）的新版Atlas亮相。&amp;nbsp;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但在同一空间内，另一条路线也在同步展开。&lt;/p&gt;&lt;p&gt;在影智 XBOT 的透明橱窗前，人群一层层围拢过来。这是全球首个支持冷热双杯同出的具身机器人，也是目前一众具身智能中最落地的一种呈现。&lt;/p&gt;&lt;p&gt;有人举着手机录像，有人已经在讨论要把什么图案印在咖啡上。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzdYbS4OcbD7yg8xWhrNYPZFyZ4qLvqGwk6WiaQsFJv37QdjgwBAOadsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527784" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1deb982b-b175-4e30-a09b-15fafae87957/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp;影智 XBOT Lite 系列印花咖啡机器人&amp;mdash;&amp;mdash;全球首个支持冷热双杯同出的具身机器人。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;玻璃之后，两只机械臂分工协作，打奶、印花、出杯，动作连贯得像一段被反复打磨过的编舞。110 秒后，一杯冰美式和一杯热拿铁同时完成，杯面上浮现出由 AI 生成的专属印花&amp;mdash;&amp;mdash;每一杯都不重样。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzxkod1MibBBPSSozsX6iaYbfNFBrfibr7dZxIUREibOoibtSs4dFjOSuhGpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.1479028697571745" data-s="300,640" data-type="png" data-w="906" type="block" data-backw="578" data-backh="663" data-imgfileid="503527799" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e0aec6b6-c4c2-479c-bab2-2090ed690f86/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;「这玩意儿太酷了。」队伍里有人忍不住感叹，「能在咖啡上打印照片，绝对是游戏规则改变者。」有人已经等不及拍照发社交平台。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzxicKZT4h4EjHUkPdut5ztPDKBrxiaXOzjzfNaJ3j5ajzibjtLbTGmZXpA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.562962962962963" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527789" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e423c481-29a0-4956-a0f0-7718fdfac865/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;机器人继续出杯，节奏稳定。「你能把公司 logo 印在咖啡上，这杯咖啡一下子就成专属的了，谁会不喜欢？」 有顾客说。「而且不用付小费&amp;mdash;&amp;mdash;对顾客对老板都是好事。」 有人从更现实的角度补了一句。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzeZ13htRHjyf7eX1DPiaia2CgGUuIMV3pMia0t71mjicU38oP7EUfziaoStw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="434" data-imgfileid="503527781" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/871c0b0e-8dcc-431a-92b2-2c3b9cc4cfe4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;喝完咖啡，又尝了旁边影智&amp;nbsp;XBOT&amp;nbsp;冰淇淋机器人做的冰淇淋，人群里笑声不断。「这哪是咖啡机？」有人指着橱窗笑道，「这是个能把人吸过来的娱乐中心。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzic2E9uz3agKogCoApTZiaYOInWd9aeGM8uXpKoKhkRMkwKl83DtmndGQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="562" data-backh="316" data-imgfileid="503527782" data-aistatus="1" data-original-style="width:100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/0e15d811-a619-47a7-9dcf-f48f7976e0c7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;与多数人形机器人仍在努力「看起来很未来」不同，影智XBOT并不追求形似人类，而是成为一台&lt;strong&gt;可以全天候运转的生产工具&lt;/strong&gt;&amp;mdash;&amp;mdash;不跳舞、不表演，直接把一杯口感稳定、好喝的咖啡，端到你面前。&lt;/p&gt;&lt;p&gt;而这套逻辑，已经在真实世界里跑了很久。&lt;/p&gt;&lt;p&gt;从天安门广场、国家图书馆到成都锦里，影智XBOT经历的不是短暂的 show time，而是数百万次的反复出杯。&lt;/p&gt;&lt;p&gt;目前，影智XBOT已在 &lt;strong&gt;15&amp;nbsp;个以上国家、100多个城市&lt;/strong&gt;落地，部署量超过 &lt;strong&gt;600&amp;nbsp;台&lt;/strong&gt;，累计制作咖啡 &lt;strong&gt;400&amp;nbsp;万杯以上&lt;/strong&gt;，在部分核心点位甚至实现了&lt;strong&gt;数月回本&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在具身智能普遍面临商业化难题的当下，影智XBOT用一组明确的数据证明：它是目前行业内&lt;strong&gt;商用落地速度最快的具身智能机器人之一&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzdxpuvfDnarCmJypiaU58ferCP3QF14xqYiczZfEuHUIjqTz9rgoG86icQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-ratio="0.666270783847981" data-type="jpeg" data-w="842" data-backw="421" data-backh="280" data-imgfileid="503527764" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/eec1b48e-219f-4f6c-97f7-c5255547ce0a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 2025年8月影智科技发布年度新品之一：影智XBOT Lite系列印花咖啡机器人。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;回归商业常识：具身智能不等于「人形」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在当下关于具身智能的讨论中，「人形」几乎成了一种默认答案。但在「操刀」影智XBOT的影智科技看来，这条路径更多源于技术想象，而非商业理性。&lt;/p&gt;&lt;p&gt;这一判断，来自公司创始人唐沐长期积累的产品与商业经验。&lt;/p&gt;&lt;p&gt;作为 2022 年福布斯中国十佳设计师，唐沐曾掌舵腾讯用户体验设计中心（CDC），并担任小米生态链副总裁。他既是 QQ 头像、微信表情包等现象级符号的缔造者，也是小米路由器、小爱智能音箱等亿级爆款产品的重要推动者。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzc0yWrNAcQH62eeMXibiax0OFopFqICt0vEbbnSyAMVVtaEGn9d2eQciaA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=9" alt="图片" data-ratio="0.5628539071347678" data-type="jpeg" data-w="883" data-backw="442" data-backh="249" data-imgfileid="503527763" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2e0fdd02-5ff0-44b4-b93a-128ba777a93d/640.png" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;公司创始人唐沐和影智XBOT咖啡机器人。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;长期站在技术、产品与规模化商业的交汇点，也塑造了他极其务实的产品观：一切产品必须从真实场景出发、目标要指向大众市场，并且要经得起规模化、可靠性与成本结构的严格检验。&lt;/p&gt;&lt;p&gt;这也构成了影智科技切入具身智能领域的基本原则&amp;mdash;&amp;mdash;回归商业常识。先解决人的需求，解决人的问题，在一个足够垂直的场景中把事情做到极致，再去讨论所谓的「终极形态」。&lt;/p&gt;&lt;p&gt;在唐沐看来，机器人的进化路径不该从「像人」出发，而应回到「是否真正有用」。具身智能的价值，并不取决于外形是否拟人，而在于是否能够围绕具体问题展开，在真实环境中灵活适应、精准执行。&lt;/p&gt;&lt;p&gt;在大量现实的消费与服务场景中，工程复杂度高、成本更高并伴有不可控风险的人形设计，反而会成为商业化落地的负担。&lt;/p&gt;&lt;p&gt;至于「为什么是精品咖啡」，也是多条现实线索叠加后的选择。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑市场，首先要足够大，其次必须是一个成长型市场&lt;/strong&gt;，咖啡符合这两个前提。它本身是一个高度全球化、已被充分验证的成熟消费市场，而中国市场还在快速增长。&lt;/p&gt;&lt;p&gt;数据显示，2023 年我国人均年咖啡消费量约为 16.74 杯，几乎是 2016 年的两倍；到 2024 年，这一数字已提升至 22.24 杯以上。即便在瑞幸、库迪等品牌快速扩张的背景下，中国咖啡门店的整体密度，依然明显低于日本和韩国等成熟市场，增长空间可观。&lt;/p&gt;&lt;p&gt;需求持续走高的同时，供给侧却长期受制于人力瓶颈。&lt;/p&gt;&lt;p&gt;咖啡师培养周期长、流动性高，岗位留存率普遍偏低；在高度内卷的竞争环境中，咖啡店拼的是出单量与运营效率，对人力的挤压不断加剧，也放大了系统性的运营矛盾。&lt;/p&gt;&lt;p&gt;咖啡消费还呈现出明显的波峰与波谷。高峰期排队几乎成为常态，品质波动难以避免。尤其是在拉花这类对毫米级精度和连续轨迹高度敏感的操作中，人类不可避免的生理性抖动，会直接放大为线条断裂或形变。&lt;/p&gt;&lt;p&gt;而对大多数用户而言，他们关心的不是「谁在做咖啡」，而是出杯是否足够快、品质是否始终稳定。以出杯量为例，每天三百杯以上的稳定输出，对人类咖啡师而言几乎不可持续；而对机器人来说，这只是一个连续、可复制的标准工作负载。&lt;/p&gt;&lt;p&gt;在这样的背景下，大模型的出现，让产品「升维」&amp;mdash;&amp;mdash;从底层重新定义一套面向消费服务场景的具身智能系统&amp;mdash;&amp;mdash;成为可能。&lt;/p&gt;&lt;p&gt;市面上多数咖啡机，本质上仍是工业自动化设备，考虑的是「怎么把咖啡做完」。具身智能除了关心效率，还关心「这杯咖啡是给谁喝的、在什么情境下喝、怎样才算一次好的体验」。咖啡这一日常消费场景，&lt;strong&gt;第一次有机会迈入以用户体验为核心的重构阶段&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;历经两年多研发，影智XBOT问世并成功出圈，唐沐也因此多了一个被媒体反复引用的标签：「具身智能消费机器人第一人」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;具身智能的「三位一体」：&lt;/strong&gt;&lt;strong&gt;为什么能做到万杯如一？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从原料开始，影智XBOT就在为「稳定性」服务。&lt;/p&gt;&lt;p&gt;目前，影智XBOT全部采用阿拉比卡咖啡豆，设备内设置两个豆仓：一个拼配豆，一个单品豆（瑰夏），以覆盖不同用户的口味偏好；牛奶则与蒙牛合作统一供应。无论是在北京、上海，还是成都，下单后端到手里的那杯咖啡，都能保持高度一致的风味。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzZMhfPKzX8ruZvwAn6bc4Uic8E4ezCSKl6QDmHz5g3cpCsib5uPbZXw1g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.5633802816901409" data-s="300,640" data-type="gif" data-w="568" type="block" data-backw="568" data-backh="320" data-imgfileid="503527803" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/680749ac-ca0e-47d3-ad8e-d9959a324826/640.gif" data-order="1" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这种「万杯如一」的表现，并不是靠单一环节实现，而是依赖一套完整的具身智能技术体系：&lt;strong&gt;负责理解与决策的「大脑」、统筹执行的操作系统（OS），以及完成精细物理动作的「小脑」。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;影智XBOT的「大脑」，并不是传统点单系统，而是一套面向真实世界运行的具身智能餐饮大模型，核心目标是更好地理解用户需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzicVz1cKVtiamRKlptoib6bia6VNicQYq4jricZgEbauHM4waukickO9sWtib0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.41505791505791506" data-s="300,640" data-type="png" data-w="1036" type="block" data-backw="578" data-backh="240" data-imgfileid="503527783" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/2e1a0412-b001-41c0-afc8-3a6ac828f93a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当你说出一句模糊需求&amp;mdash;&amp;mdash;比如「我想来一杯热带风情的咖啡」&amp;mdash;&amp;mdash;系统会在毫秒级调取完整的饮品知识体系，覆盖公开菜单、配方逻辑与标准化制作 SOP，并理解「热带风情」意味着椰子、热带水果、冰感与较高甜度。&lt;/p&gt;&lt;p&gt;接下来，大模型会调用口味拼配算法，在现有原料约束下寻找最优解：比例如何控制？先加什么、后加什么，才能在不破坏咖啡骨架的前提下，呈现「热带」风味？&lt;/p&gt;&lt;p&gt;这些原本高度依赖咖啡师经验与手感的判断，被转化为一组可计算、可推演的决策过程。算法甚至「知道」一些已经被反复验证的美味公式，如生椰与拿铁是绝配。&lt;/p&gt;&lt;p&gt;最终，你的抽象需求会被翻译成一连串精确到秒的动作调用：咖啡液多少秒、椰乳多少秒，冰、糖与水如何配合。每一个动作，都是机器人已经掌握的能力模块，可以被反复调用、稳定复现。&lt;/p&gt;&lt;p&gt;在「揽客」上，AI 数字人承担「意图入口」的角色。它具备长记忆能力，能识别老顾客与偏好&amp;mdash;&amp;mdash;「Hi，Thomas，还是要上次的橙 C 冰美式吗？」甚至能在连续对话中保持上下文一致。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOziaYq0Cl4WhaibjErD78J0gvriabvE1uwRKcgW9MqIUXsA2eCVleeFcxJA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="384" type="block" data-backw="384" data-backh="216" data-imgfileid="503527805" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c65bf97c-7e8d-4238-8b37-7869831d58fa/640.gif" data-order="2" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;数字人还能根据状态做出情境化推荐，如夜深时建议一杯 double 浓缩。结合 AIGC，用户「随口一说」的创意，也能被实时「打印」成咖啡印花。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzu3ic4ibpOorZCTThKgUAHbDL73K0aiaoNbKrI3TbsvaByo0BsMayxKwjQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="1.7777777777777777" data-type="gif" data-w="504" type="block" data-backw="504" data-backh="896" data-imgfileid="503527814" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/8c86ba50-843a-4573-aaec-452d4321a96f/640.gif" data-order="3" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 将自拍变成独一无二的咖啡印花。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如果说「大脑」解决的是「逻辑上该怎么做」，那么影智XBOT&lt;strong&gt;操作系统&lt;/strong&gt;（LU BAN OS）要解决的是&lt;strong&gt;在真实世界中能不能这么做&lt;/strong&gt;&amp;mdash;&amp;mdash;这是双臂机器人实现落地的关键一环。&lt;/p&gt;&lt;p&gt;它更像一套神经中枢。当「大脑」给出高层指令后，OS并非简单转发，而是介入执行层，在复杂的真实环境中进行&lt;strong&gt;全局编排：&lt;/strong&gt;统一调度机械臂、咖啡机、奶泡器、糖浆泵、制冰机、印花机等设备，确保每一个步骤、每一个动作，都发生在安全、合理且可控的物理条件之内。&lt;/p&gt;&lt;p&gt;做出一杯咖啡，看似线性的流程，背后其实是一套&lt;strong&gt;高并发的任务调度系统&lt;/strong&gt;。通过底层运动算法，OS实现了双机械臂的&lt;strong&gt;空间解耦与时间同步&lt;/strong&gt;。即便在狭窄的操作空间内，两只手臂也能在毫秒级反馈下实时避障，像人类双手一样默契配合。&lt;/p&gt;&lt;p&gt;OS真正强大的地方，在于赋予了双臂「&lt;strong&gt;柔性作业&lt;/strong&gt;」的能力。在不同调度策略下，双臂可以进行高度非对称的协同，互不干扰地同时制作两款完全不同的饮品。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzBciczibpQIo4ICNU1DGgOicADNkcnkWInqFhU1UXv2tf0b8qP1Hhpib1ow/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527791" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/a7bc3a91-7e27-4973-9841-dc2155952e6d/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;在写字楼早高峰，OS可以同时处理一杯热美式和一杯冰拿铁，将单杯等待时间大幅压缩。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;与此同时，OS还会持续监控设备状态，记录运行数据，提前识别潜在异常，并为下一单完成预准备，等等。正是这套&lt;strong&gt;全局感知与调度能力&lt;/strong&gt;，使影智XBOT即便在无人值守的情况下，也能长期稳定地支撑高并发出杯。&lt;/p&gt;&lt;p&gt;当这套通用底座逐渐成熟，咖啡也就不再是它的唯一应用场景。冰淇淋、奶茶、鸡尾酒、面食，乃至教育、陪伴等更广泛的消费与服务领域，本质上都只是同一套具身智能系统之上的「技能插件」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在此之下，「小脑」承担的是具身智能中最贴近物理世界的一层任务&lt;/strong&gt;：在液体流动、奶泡阻力与原料状态不断变化的真实环境中，依然把口味与视觉表现锁定在同一标准，实现真正意义上的「万杯如一」。&lt;/p&gt;&lt;p&gt;在硬件层面，团队自研双六轴定制工业机械臂，重复定位精度达到&lt;strong&gt;&amp;plusmn;0.03&amp;nbsp;毫米&lt;/strong&gt;；配合高精度运控算法，整体操作精度达到 &lt;strong&gt;0.1毫米&lt;/strong&gt;，远超人类生理极限。&lt;/p&gt;&lt;p&gt;在萃取阶段，粉量误差被压缩至极小范围。糖浆添加与拉花动作被控制在毫米级精度。拉花时，机械臂的移动速度与喷头挤出节奏始终保持同步，一旦感知到液体阻力或流速偏移，系统便即时修正电机输出，确保线条连续、不抖动。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzWJvleF6r0zF1heiaWzgLzaBlh1PSBLibmwSModjXGzOnNWmiaiaSQ1vSBQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=15" data-ratio="0.5134529147982063" data-s="300,640" data-type="gif" data-w="446" type="block" data-backw="446" data-backh="229" data-imgfileid="503527809" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/d7bd9244-a175-4822-8b51-3c76ee607d5b/640.gif" data-order="4" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了教会机器人各种餐饮手艺，比如「审美级」拉花能力，团队搭建了一套顶级红外光学动捕系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz5tXAsIdgocDsKQGGXH8rFEE1twqMr8lIFdmYVWibN2MBxiaMDUHDKVYA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=16" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="320" type="block" data-backw="320" data-backh="180" data-imgfileid="503527808" data-aistatus="1" data-original-style="width: 100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/2f001dea-9b22-48fe-b2da-c37c25f543b0/640.gif" data-order="5" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;75秒内复刻大师级的拉花咖啡技艺。机器人6个小时就能掌握一款新的拉花方式，而人类咖啡师需要6个月。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;通过 11 组高精度摄像头，将顶级咖啡师最细微的手部摆动与力度变化，以毫米级精度完整记录下来，再借助自研算法，将这些大师级技巧翻译为机械臂可执行的控制指令，还实现了跨型号的自动校准。&lt;/p&gt;&lt;p&gt;最终，原本只存在于老师傅经验中的「手感」，被沉淀为可规模复制、稳定复现的工业级能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计美学&amp;nbsp;&amp;times;&amp;nbsp;商业策略：&lt;/strong&gt;&lt;strong&gt;让具身智能真正成为一门生意&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说，技术解决的是「能不能把事做对」，那么工业设计解决的，其实是「这东西能不能被真正用起来」。而后一个问题，才是 2B 商家是否掏出真金白银的分水岭。&lt;/p&gt;&lt;p&gt;商家的目标很简单，用尽可能确定、低摩擦的方式赚钱。因此，影智XBOT是否能够被设计成一台全年无休、稳定运转的生产设备，是否能持续替代人力，把那些琐碎、重复、长期消耗精力的管理问题一并吞掉，远比「看起来有多先进」更重要。&lt;/p&gt;&lt;p&gt;也正因如此，作为少数同时拿下 iF、红点 Best of the Best、IDEA、CMF 等国际设计大奖的团队，影智科技并没有把工业设计当作外观层面的加分项，而是将其视为一套用于降低商业摩擦成本的方法论。&lt;/p&gt;&lt;p&gt;这种思路，最先落到一个极其「现实」的指标上：空间效率。&lt;/p&gt;&lt;p&gt;通过高度紧凑的内部架构，影智XBOT将机械臂、咖啡机、制冰机、印花机等完整模块，压缩进约 1.35㎡&amp;ndash;2.5㎡ 的占地范围内。在寸土寸金的商业环境中，这是直接影响坪效、租金模型，甚至点位是否成立的关键变量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzpSm6nrqtBRSC2Hfj8wSO5l3wjOZh4RJGTrYqyyHjwbkTy9JdFZ2w4A/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527792" data-aistatus="1" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/43343029-3603-4d01-8f93-0686dbfd2f01/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;设计并未止步于「塞得下」，而是与商业运维深度绑定。&lt;/p&gt;&lt;p&gt;通过全模块化架构，将复杂硬件拆解为标准化服务组件，故障模块可在&lt;strong&gt;60&amp;nbsp;分钟内快拆更换&lt;/strong&gt;；配合远程&amp;nbsp;OTA，实现系统、动作路径与配方的一键升级。同时，预留扩展接口，支持未来扩容料仓或接入其他服务设备，让单体机器不被功能锁死，具备持续演进的商业弹性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzWWbiaStOHt2cXoMoT7yLicib6DKwPFQogVaBaz6EsiaW3q5TLklP3eu44g/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="325" data-imgfileid="503527793" data-aistatus="1" data-original-style="width: 100%;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/6c29f053-32dd-44fa-b309-8bd6d1231ebd/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在商业模式上，影智科技并未停留在「卖一台机器」，而是搭建了一套更贴近真实商业世界的三层结构：设备销售、联营模式，以及持续性的增值服务。&lt;/p&gt;&lt;p&gt;其中，「7S」服务体系是一个首创。通过将大量原本由运营者承担的风险前移至平台侧，释放出一个明确信号：咖啡机器人并不是在「与人抢工作」，而是在用技术降低创业门槛，让小生意重新变得可控。它瞄准的，正是那些有创业意愿、却缺乏技术、管理与抗风险能力的中小创业者&amp;mdash;&amp;mdash;过去，这类人往往在高启动成本与不确定风险中迅速出局。&lt;/p&gt;&lt;p&gt;在传统「4S」基础上，「7S」补齐了三项关键能力：用数据运营替代经验判断；通过金融服务，将近 20 万元的初始投入拆解为更轻量的运营方案；通过回购与升级机制，赋予设备流动性与持续迭代空间，明确机器人是一种可持续优化的资产，而非一次性消耗品。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOz3uKvDeT5UiceIHZH0anHeOMiambccVGNobOB7ZwZ9vL0VVur8TrEjYeA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=19" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="434" data-imgfileid="503527794" data-aistatus="1" data-original-style="width: 100%;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/d56eb503-0099-4df3-8ee3-cad6237c36bc/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;把具身智能先安放在当下&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说人形机器人代表的是远方，那么影智科技更像是把具身智能先安放在当下。&lt;/p&gt;&lt;p&gt;它代表了另一类具身智能公司：不沉迷概念叙事，也不等待终极形态，而是用当下可行的技术，在复杂、开放、不可控的真实世界中，反复验证可复制的商业模式。&lt;/p&gt;&lt;p&gt;从底层运控算法、工业设计，到产品形态与商业模式，影智科技在一条全链路上不断打磨同一个问题&amp;mdash;&amp;mdash;当具身智能真正进入现实生活，它如何成为一门成立的生意。至少在咖啡这门生意里，这个问题已经有了被市场验证的答案。&lt;/p&gt;&lt;p&gt;也许正是这些并不「人形」、却能持续运转的「中间态」产品，正在把具身智能从想象中的未来，一步步带进现实世界。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>挑战GRPO，英伟达提出GDPO，专攻多奖励优化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:46:19 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/cfd67a67-0432-42e4-ba90-81a9bbc2a059/1768139025502.png" style="width: 700%;" class="fr-fic fr-dib"&gt;GRPO 是促使 DeepSeek-R1 成功的基础技术之一。最近一两年，GRPO 及其变体因其高效性和简洁性，已成为业内广泛采用的强化学习算法。&lt;/p&gt;&lt;p&gt;但随着语言模型能力的不断提升，用户对它们的期待也在发生变化：不仅要回答正确，还要在各种不同场景下表现出符合多样化人类偏好的行为。为此，&lt;strong&gt;强化学习训练流程开始引入多种奖励信号&lt;/strong&gt;，每一种奖励对应一种不同的偏好，用来共同引导模型走向理想的行为模式。&lt;/p&gt;&lt;p&gt;但英伟达的一篇新论文却指出，在进行多奖励优化时，GRPO 可能不是最佳选择。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgwcrGKTl0WsS2udQZMvenV8eygrt1cLLokwBuBYSJH3tVicfTgT9iadrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.675" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527626" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a88d43fc-f1b5-4760-aee3-88bd2aa1cad3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;具体来说，在多奖励优化场景中，GRPO 会将不同的奖励组合归一化为相同的优势值。这会削弱训练信号，降低奖励水平。&lt;/p&gt;&lt;p&gt;为了解决这一问题，他们提出了一种新的策略优化方法 &amp;mdash;&amp;mdash; 组奖励解耦归一化策略优化（&lt;strong&gt;GDPO&lt;/strong&gt;）。该方法通过对各个奖励信号分别进行归一化，避免了不同奖励之间被混合「抹平」，从而更真实地保留它们的相对差异，使多奖励优化更加准确，同时显著提升了训练过程的稳定性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgicB6ib7yL4erYF4OcT2cSeh4lsicRr2iakWg5ev0639RRAnu7blcOuJ5zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4475374732334048" data-s="300,640" data-type="png" data-w="934" type="block" data-imgfileid="503527611" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/31194a14-4194-44b7-b8fc-c4aeb5452ebe/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2601.05242&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/NVlabs/GDPO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目链接：https://nvlabs.github.io/GDPO/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace 链接：https://huggingface.co/papers/2601.05242&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在工具调用、数学推理和代码推理这三类任务上，论文将 GDPO 与 GRPO 进行了对比评测，既考察了正确性指标（如准确率、缺陷比例），也评估了对约束条件的遵守情况（如格式、长度）。结果显示，在所有设置中，GDPO 都稳定地优于 GRPO，验证了其在多奖励强化学习优化中的有效性和良好泛化能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg3xCXUfIia3WTYxvlWSwwZraZPw3M8txypAMR09uz9gJ5z5xAEDpia3HQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527609" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8b340b41-3f7c-4e9f-9565-313505052ed5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;GRPO 有什么问题？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，GRPO 主要被用于优化单一目标的奖励，通常聚焦于准确率。然而，随着模型能力的持续提升，近期研究越来越倾向于同时优化多个奖励 &amp;mdash;&amp;mdash; 例如在准确率之外，还考虑响应长度限制和格式质量，以更好地与人类偏好保持一致。现有的多奖励强化学习方法通常采用一种直接的策略：将所有奖励分量相加，然后直接应用 GRPO 进行优化。&lt;/p&gt;&lt;p&gt;具体而言，对于给定的问答对，行为策略会为每个问题采样一组响应。假设存在 n 个优化目标，则第 j 个响应的聚合奖励被计算为各目标奖励之和。随后，通过对群组级别的聚合奖励进行归一化，得到第 j 个响应的群组相对优势。&lt;/p&gt;&lt;p&gt;作者首先重新审视了这种将 GRPO 直接应用于多奖励强化学习优化的常见做法，并发现了一个此前被忽视的问题：&lt;strong&gt;GRPO 本质上会压缩奖励信号，导致优势估计中的信息损失。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了说明这一点，他们从一个简单的训练场景开始，然后推广到更一般的情况。假设为每个问题生成两个 rollout 来计算群组相对优势，且任务涉及两个二值奖励（取值为 0 或 1）。因此，每个 rollout 的总奖励可取 {0, 1, 2} 中的值。&lt;/p&gt;&lt;p&gt;如图 2 所示，作者列举了一个群组内所有可能的 rollout 奖励组合。尽管在忽略顺序的情况下存在六种不同的组合，但在应用群组级奖励归一化后，只会产生两个唯一的优势组。具体来说，(0,1)、(0,2) 和 (1,2) 会产生相同的归一化优势值 (-0.7071, 0.7071)，而 (0,0)、(1,1) 和 (2,2) 则全部归一化为 (0, 0)。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgDzffSENdCCPL1aCxqws83ZgGXj8C7mlOiaVW2knA858bibgdTCQ8w7bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6861111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527612" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cd8c6cff-5c7d-4fb3-a063-26c4ff7d0072/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这揭示了 GRPO 优势计算在多奖励优化中的一个根本性局限：它过度压缩了丰富的群组级奖励信号。&lt;/p&gt;&lt;p&gt;从直觉上讲，(0,2) 应该比 (0,1) 产生更强的学习信号，因为总奖励为 2 意味着同时满足了两个奖励条件，而奖励为 1 仅对应达成一个。因此，当另一个 rollout 只获得零奖励时，(0,2) 应该产生比 (0,1) 更大的相对优势。这种局限性还可能因优势估计不准确而引入训练不稳定的风险。如图 5 所示，当使用 GRPO 训练时，正确率奖励分数在约 400 个训练步后开始下降，表明出现了部分训练坍塌。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgDrmib8L0ZzNt3ItJ1YibjsZb07xvDia25OcqaB6EyOL3dVc6ojiawB1IPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.4222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527613" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/381d8ad6-c11d-46ed-8ea6-9d0e127f152f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近期，Dr.GRPO 和 DeepSeek-v3.2 采用了 GRPO 的一个变体，移除了标准差归一化项，使得优势直接等于原始奖励减去均值。尽管这些工作引入此修改是为了缓解问题级别的难度偏差，但乍看之下，这一改变似乎也能解决上述问题。具体而言，移除标准差归一化确实在一定程度上缓解了问题：(0,1) 和 (0,2) 现在分别产生 (-0.5, 0.5) 和 (-1.0, 1.0) 的不同优势值。&lt;/p&gt;&lt;p&gt;然而，当将此设置推广到更多 rollout（保持奖励数量固定）时，如图 3 所示，作者观察到这种修复方法相比标准 GRPO 仅略微增加了不同优势组的数量。在固定 rollout 数量为 4、逐步增加奖励数量的设置下，也观察到类似趋势 &amp;mdash;&amp;mdash; 不同优势组的数量仅有适度改善。作者还在第 4.1.1 节中实证检验了移除标准差归一化项的效果，发现这一修改并未带来更好的收敛性或更优的下游评估表现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKglJ4JwGjPiaSjTT8mOPFeeMpu7hu8fic8JkXcWsefkxxPmmrf5dwvzVlQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527614" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1912da0b-533f-43e5-9a3b-d8ffd2ebb8d4/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;GDPO是怎么做的？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了克服上述挑战，作者提出了群组奖励解耦归一化策略优化（GDPO），这是一种旨在更好地保持不同奖励组合之间区分度、并更准确地在最终优势中捕捉其相对差异的方法。&lt;/p&gt;&lt;p&gt;与 GRPO 直接对聚合奖励和进行群组级归一化不同，GDPO 通过在聚合之前对每个奖励分别进行群组级归一化来解耦这一过程。具体而言，GDPO 不是先将所有 n 个奖励相加再进行群组级归一化得到总优势，而是为第 i 个问题的第 j 个 rollout 的每个奖励分别计算归一化优势，如下所示：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgBSBr2U8IxTKhbaYZ5q4VavIkY4wNhnIAy4elgdeLyqzl9R5MiaX6icSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.10185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527615" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b40c08db-e8df-4aea-b636-b7ff8290c6fa/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;用于策略更新的总体优势通过以下方式获得：首先将所有目标的归一化优势相加，然后对多奖励优势之和应用批次级优势归一化。这确保了最终优势的数值范围保持稳定，不会随着额外奖励的引入而增长。从实证角度，作者还发现这一归一化步骤能够改善训练稳定性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通过分离每个奖励的归一化，GDPO 缓解了 GRPO 优势估计中存在的信息损失问题&lt;/strong&gt;，如图 2 所示。从图中可以看到，当采用 GRPO 时，不同的奖励组合（如 (0,2) 和 (0,1)）会导致相同的归一化优势，从而掩盖了它们之间的细微差异。相比之下，GDPO 通过为每种组合分配不同的优势值来保留这些细粒度差异。&lt;/p&gt;&lt;p&gt;作者通过在两种实验设置下比较 GDPO、GRPO 和「无标准差 GRPO」产生的不同优势组数量，进一步量化了 GDPO 的有效性，如图 3 所示。在两个奖励、rollout 数量变化的场景中，GDPO 始终产生显著更多的不同优势组，且随着 rollout 数量增加，差距不断扩大。另一方面，当固定 rollout 数量为 4 并增加奖励数量时，也呈现出类似的模式 &amp;mdash;&amp;mdash;GDPO 随着目标数量增长表现出逐步增大的优势粒度。这表明论文所提出的解耦归一化方法在所有强化学习设置中都能有效增加不同优势组的数量，从而实现更精确的优势估计。&lt;/p&gt;&lt;p&gt;除了这些理论改进之外，作者还观察到使用 GDPO 能够持续产生更稳定的训练曲线和更好的收敛性。例如，在工具调用任务中，GDPO 在格式奖励和正确率奖励上都实现了更好的收敛，如图 4（见实验部分）所示。GDPO 还消除了 GRPO 在数学推理任务中观察到的训练坍塌问题，如图 5（见实验部分）所示，使用 GDPO 训练的模型在整个训练过程中持续改善正确率奖励分数。实验部分的更多实证结果进一步证实了 GDPO 在广泛的下游任务上实现更强目标偏好对齐的能力。&lt;/p&gt;&lt;p&gt;到目前为止，论文假设所有目标具有同等重要性。然而在实际应用中，这一假设并不总是成立。在论文中，作者系统地概述了如何调整与不同目标相关的奖励权重，或修改奖励函数以强制优先考虑更重要的目标。论文还讨论了当底层奖励在难度上存在显著差异时，这两种设计选择的不同行为表现。具体内容可参见论文第三章。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验部分，作者首先在工具调用任务上评估 GDPO 与 GRPO 的效果，然后在数学推理任务上进行比较，最后将优化奖励数量扩展到三个，在代码推理任务上进行对比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;工具调用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从图 4 的训练曲线可以看到，GDPO 在所有运行中都能在格式奖励和正确率奖励上收敛到更高的值。尽管 GDPO 在格式奖励收敛所需步数上表现出更大的方差，但最终达到的格式合规性优于 GRPO。对于正确率奖励，GDPO 在早期阶段表现出更快的改善，并在后期达到比 GRPO 基线更高的奖励分数。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg1ODCeFd1K9khH1KtlXz1V9KSQskF1ew1CrpmfbtuHDRQ9rAk8992cw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527616" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ae9a14a4-fba6-4211-ba13-5f5b79e0eb8c/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在表 1 的 BFCL-v3 评估中，GDPO 也持续提升了平均工具调用准确率和格式正确率。对于 Qwen2.5-Instruct-1.5B 的训练，GDPO 在 Live/non-Live 任务上分别取得了近 5% 和 3% 的提升，在整体平均准确率上提高了约 2.7%，在正确格式比例上提高了 4% 以上。3B 模型上也观察到类似的改进。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgVC7Rfuu3au6GeRJxwmDEQt2NK0NDLwU8pcf0qJ4MLMm5GzOdIDg78g/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.27870370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527617" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0c42a132-0137-41bd-9311-49cf0e32ffab/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;关于移除标准差归一化项的效果：从图 4 可以观察到，虽然「无标准差 GRPO」收敛到与 GDPO 相似且高于标准 GRPO 的正确率奖励，但它在格式奖励上完全失败。这导致在 BFCL-v3 上的正确格式比例为 0%（见表 2），表明模型未能学习所需的输出结构。这说明简单地移除标准差归一化项以增加优势多样性可能会给训练引入不稳定性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgE9N44nkN0gP8O4wvqOKnHribtqq3EmISlt4XgR82g1R9ibXhHhrDBDNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.2222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527618" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/91e35c43-fc55-41a9-add1-2136498c0fd3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;数学推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从图 5 中 DeepSeek-R1-1.5B 的训练曲线可以看到，模型倾向于最大化更容易的奖励。在本例中，长度奖励更容易优化，GRPO 和 GDPO 都在大约前 100 个训练步内达到满分长度奖励。长度奖励的快速上升伴随着正确率奖励的早期下降，表明这两个奖励存在竞争关系。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgW1B5AZgiaLzsiaSiaREdrTSP3O5FFTQO62M7ia1qySvWer1QpD8xn0eiaibg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527619" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d34ae5e0-1639-4b32-8f35-451d34c37507/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;然而，从正确率奖励轨迹来看，GDPO 比 GRPO 更有效地恢复了正确率奖励。作者还观察到 GRPO 训练在 400 步后开始不稳定，正确率奖励分数逐渐下降，而 GDPO 则继续改善。此外，尽管两者都保持了近乎完美的长度分数，但 GRPO 的最大响应长度在约 400 步后开始急剧增加，而 GDPO 的最大响应长度则持续下降。图 9 和图 10 中 DeepSeek-R1-7B 和 Qwen3-4B-Instruct 的训练曲线也显示出类似的观察结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHc3TPnEmTj8xZXylahFFnI39A328TiabmoQ4KLicq2apibhWlWbCQPTNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527620" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/f3f8f78d-29d5-4fc5-9749-009a2752c25c/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;表 3 的基准测试结果表明，GDPO 训练的模型不仅在推理效率上比原始模型取得显著提升（AIME 上超长比例降低高达 80%），而且在大多数任务上也取得了更高的准确率。对于 DeepSeek-R1-1.5B，GDPO 在所有基准测试上都优于 GRPO，在 MATH、AIME 和 Olympiad 上分别取得了 2.6%/6.7%/2.3% 的准确率提升。DeepSeek-R1-7B 和 Qwen3-4B-Instruct 也呈现类似趋势，GDPO 在更具挑战性的 AIME 基准测试上将准确率提高了近 3%，同时将超长率分别降低至 0.2% 和 0.1%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgLFZOABdEjpLYW6fu01EH525xWHZZcwT6zwmLDTaM8gfaECiala5opvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527621" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/d1ef9794-5d6d-4fa2-878a-9b09df39bd32/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;代码推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者在代码推理任务上检验 GDPO 在优化两个以上奖励时是否仍然优于 GRPO。如表 5 所示，在双奖励设置下，GDPO 在所有任务上都提升了通过率，同时保持相似的超长比例。例如，GDPO 在 Codecontests 上将通过率提高了 2.6%，而超长比例仅增加 0.1%；在 Taco 上取得了 3.3% 的通过率提升，同时将超长违规降低了 1%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgYfn0EBn7lBibBic40Q3ibYdGHzIibvpPXxKHsetk7pbj3WciaFEaZkhueEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527622" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/3c57865f-037b-4def-8e3b-2a1a1047bb24/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在三奖励设置下也呈现类似模式，GDPO 在所有目标上都实现了更有利的平衡，在保持与 GRPO 相似通过率的同时，显著降低了超长比例和 bug 比例。&lt;/p&gt;&lt;p&gt;总体而言，这些结果表明 GDPO 在奖励信号数量增加时仍然有效，在双奖励和三奖励配置中都始终比 GRPO 实现更优的跨目标权衡。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>联邦学习不再安全？港大TPAMI新作：深挖梯度反转攻击的内幕</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:42:06 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/4fe10834-5f13-4fbc-8eac-573aab0b10c4/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;本文第一作者郭鹏鑫，香港大学博士生，研究方向是联邦学习、大模型微调等。本文共同第一作者王润熙，香港大学硕士生，研究方法是联邦学习、隐私保护等。本文通讯作者屈靓琼，香港大学助理教授，研究方向包含 AI for Healthcare、AI for Science、联邦学习等 (个人主页：https://liangqiong.github.io/)。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;联邦学习（Federated Learning, FL）本是隐私保护的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;救星」，却可能因梯度反转攻击（Gradient Inversion Attacks, GIA）而导致防线失守。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;近日，&lt;strong&gt;香港大学、香港科技大学（广州）、南方科技大学、斯坦福大学、加州大学圣塔克鲁兹分校&lt;/strong&gt;的研究团队合作，在人工智能顶级期刊 &lt;strong&gt;IEEE TPAMI&lt;/strong&gt; 上发表重磅工作，对 GIA 进行了全方位的分类、理论分析与实验评测，并提出了切实可行的防御指南。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg7MK4kcIa1ntiauRiadcuEzX19Mica2TQibzDwkj3aPZd4dOUNlqNan5MRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527517" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d2f645f1-94dc-4c87-8ff5-ad982cdfb949/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题： Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址： https://ieeexplore.ieee.org/document/11311346&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页： https://pengxin-guo.github.io/FLPrivacy/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;01 背景：联邦学习真的安全吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;联邦学习（FL）作为一种隐私保护的协同训练范式，允许客户端在不共享原始数据的情况下共同训练模型。然而，近年来的研究表明，&lt;strong&gt;「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;不共享数据」并不等于 「&lt;/span&gt;&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;绝对安全」&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;攻击者可以通过&lt;strong&gt;梯度反转攻击（GIA）&lt;/strong&gt;，仅凭共享的梯度信息就能重建出客户端的私有训练数据（如人脸图像、医疗记录等）。尽管学术界提出了许多 GIA 方法，但一直缺乏对这些方法的系统性分类、深入的理论分析以及在大规模基准上的公平评测。&lt;/p&gt;&lt;p&gt;为了填补这一空白，本研究对 GIA 进行了&lt;strong&gt;抽丝剥茧般的深度剖析&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgdQP8bVgdaOkLHAfmviaXicZDBO9W1UYWcaRcQAIcTEUEW9LsEuPfVwdw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5694444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527518" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dd1bef59-0933-4313-b64d-48a80c4b6216/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;02 方法分类：GIA 的三大门派&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队首先对现有的 GIA 方法进行了系统性梳理，将其归纳为三大类：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 基于优化的攻击 (OP-GIA)：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：通过迭代优化虚拟数据，使其产生的梯度与真实梯度之间的距离最小化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;代表作&lt;/strong&gt;：DLG、Inverting Gradients、GradInversion 等。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 基于生成的攻击 (GEN-GIA)：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：利用预训练的生成模型（GAN 或 Diffusion Model）作为先验，来生成近似的输入数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;细分&lt;/strong&gt;：优化隐向量 z、优化生成器参数 W、或训练逆向生成模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 基于分析的攻击 (ANA-GIA)：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：利用全连接层或卷积层的线性特性，通过解析解（Closed-form）直接恢复输入数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;：通常需要恶意的服务器修改模型架构或参数。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;03 理论突破：误差边界与梯度相似性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于以往的经验性研究，本文在理论层面做出了重要贡献：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Theorem 1（误差边界分析）&lt;/strong&gt;：首次从理论上证明了 OP-GIA 的重建误差与&lt;strong&gt; Batch Size（批量大小）和图像分辨率&lt;/strong&gt;的平方根呈线性关系。这意味着，Batch Size 越大、分辨率越高，攻击难度越大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgPgI4bCn3MruUicmVyMBVXBribcLMicHIpNXG3Alu4ecL0RLMLFDfaicicXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527520" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9311e11a-9e23-4f01-b579-08c3ddd9894c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Proposition 1（梯度相似性命题）&lt;/strong&gt;：揭示了模型训练状态对攻击的影响。如果不同数据的梯度越相似（例如在模型训练后期），攻击恢复数据的难度就越大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgylZpX9tBEXyEk88sFashdFJLFSibf1p8BEwxkE1o4CCqAtLB3cx9Atw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527521" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/42be48fa-b8f8-467b-a54b-f77113452334/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;04 实验发现：谁是真正的威胁？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 CIFAR-10/100、ImageNet、CelebA 等数据集上，针对不同攻击类型进行了广泛的实验（涵盖 ResNet、ViT 以及 LoRA 微调场景）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgKv6WzUg3YTutnINde067VibicO7U7WMzdyic7GDLMkmyxOBDAqqkf7YsQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3194444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527522" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2b91461c-5e83-40ab-92c5-7e13e3413843/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;关键结论（Takeaways）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;OP-GIA 最实用，但受限多&lt;/strong&gt;：它是最实用的攻击设置（无额外依赖），但效果受限于 Batch Size 和分辨率。且在&amp;nbsp;&lt;strong&gt;Practical FedAvg&lt;/strong&gt;（多步本地训练）场景下，其威胁被大幅削弱。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;GEN-GIA 依赖重，威胁小&lt;/strong&gt;：虽然能生成高质量图像，但严重依赖预训练生成器、辅助数据集或特定的激活函数（如 Sigmoid）。如果目标模型不用 Sigmoid，很多 GEN-GIA 方法会直接失效 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;ANA-GIA 效果好，易暴露&lt;/strong&gt;：通过修改模型架构或参数，ANA-GIA 可以实现精准的数据恢复。但这种「做手脚」的行为非常容易被客户端检测到，因此在实际中难以得逞 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;PEFT (LoRA) 场景下的新发现&lt;/strong&gt;：在利用 LoRA 微调大模型时，攻击者可以恢复低分辨率图像，但在高分辨率图像上往往失败。且预训练模型越小，隐私泄露风险越低 。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg4D6OEAjdsnliajkxXqPI5ibfRI7TpBfFbhsbOXTkjnAXdhGJe4L7m3Xg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6111111111111112" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527546" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/fe9aa2a1-1c9c-410e-b4c1-0af944eb538f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;05 防御指南：三步走策略&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于上述深入分析，作者为联邦学习系统的设计者提出了一套「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;三阶段防御流水线」，无需引入复杂的加密手段即可有效提升安全性 ：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 网络设计阶段：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;拒绝 Sigmoid&lt;/strong&gt;：避免使用 Sigmoid 激活函数（易被 GEN-GIA 利用）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;增加复杂度&lt;/strong&gt;：采用更复杂的网络架构，增加优化难度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 训练协议阶段：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;增大 Batch Size&lt;/strong&gt;：根据理论分析，大 Batch 能有效混淆梯度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多步本地训练&lt;/strong&gt;：采用 Practical FedAvg，增加本地训练轮数，破坏梯度的直接对应关系。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 客户端校验阶段：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型检查&lt;/strong&gt;：客户端在接收服务器下发的模型时，应简单校验模型架构和参数，防止被植入恶意模块（防御 ANA-GIA）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;06 总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项发表于 TPAMI 的工作不仅是对现有梯度反转攻击的一次全面体检，更是一份实用的联邦学习安全避坑指南。它告诉我们：虽然隐私泄露的风险真实存在，但通过合理的设计和协议规范，我们完全可以将风险控制在最低水平。&lt;/p&gt;&lt;p&gt;更多细节，欢迎查阅原论文！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>在谷歌深耕14年，华人研究员创立视觉AI公司，计划融资5000万美元</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:37:48 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/616f5b85-a9cf-4ed4-b8ad-700ae60b5143/1768138551245.png" style="width: 700%;" class="fr-fic fr-dib"&gt;最新消息，两名华人前谷歌资深研究员正创立一家全新的视觉 AI 公司，致力于打造能够同时理解和处理文本、图像、视频与音频的前沿 AI 模型。&lt;/p&gt;&lt;p&gt;这两位华人是：在 Google DeepMind 工作 14 年后离职的资深 AI 研究员 &lt;strong&gt;Andrew Dai（戴明博）&lt;/strong&gt;，以及前苹果 AI 研究科学家，曾在谷歌研究部门工作的 &lt;strong&gt;Yinfei Yang （杨寅飞）&lt;/strong&gt;。&lt;/p&gt;&lt;p data-pm-slice="2 2 []"&gt;戴明博表示，这家名为 &lt;strong&gt;Elorian&lt;/strong&gt; 的新公司目前正在与投资人洽谈，计划完成一轮约 &lt;strong&gt;5000 万美元的种子融资&lt;/strong&gt;。知情人士透露，由前 CRV 普通合伙人 Max Gazor 于去年 10 月创立的风投机构 Striker Venture Partners 正在洽谈领投该轮融资。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzxY6hQLUU8rWkKu9b5RsuKMcVMCq7cf4a0fTfibBFF7zVN8wZhA11YLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.562037037037037" data-type="png" data-w="1080" data-width="1800" data-height="1012" data-imgfileid="503527786" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/885220f9-7441-43ed-8ff9-72335808b205/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;戴明博本科毕业于英国剑桥大学计算机科学专业，随后在爱丁堡大学获得机器学习方向博士学位。在攻读博士期间，他曾两次在谷歌进行软件工程实习，博士毕业后&lt;strong&gt;于 2012 年正式加入谷歌，开启了长达 14 年的职业生涯&lt;/strong&gt;，在公司内部从技术研发逐步成长为核心科研管理者。&lt;/p&gt;&lt;p&gt;在 Google DeepMind，他担任&lt;strong&gt;首席研究科学家 / 主任级别研究管理职务&lt;/strong&gt;，负责领导与 Gemini 大型 AI 模型研发相关的数据团队工作，这一项目是 DeepMind 和 Google 在多模态大模型方向的重要战略成果。&lt;/p&gt;&lt;p&gt;作为深度学习与自然语言处理领域的资深研究人员，戴明博不仅在工业级 AI 项目中扮演关键角色，还与业内其他顶尖研究者合作发表过多篇学术论文，积累了丰富的科研和工程融合经验。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzJUcCgsdygsvD3ZOQoibgib2u5bNRia7rNrIiac96EKWzfPnITyAcdXJrNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.3333333333333333" data-type="png" data-w="1080" data-width="1195" data-height="1593" data-imgfileid="503527788" data-aistatus="1" data-original-style="width: 223px;height: 297px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e37fc732-0ac8-49cb-ae16-e00a67521025/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;杨寅飞是一位资深的人工智能研究科学家，曾在&lt;strong&gt;&amp;nbsp;Apple AI/ML 担任研究科学家/多模态负责人&lt;/strong&gt;，主要从事视觉与语言基础模型的研究与开发。&lt;/p&gt;&lt;p&gt;在加入苹果之前，他也&lt;strong&gt;曾在 Google Research 担任研究科学家&lt;/strong&gt;，在自然语言处理、语义检索、多语言表示学习与多模态表示学习等方向有深入的研究与实践。 &amp;nbsp;他还在 Amazon 和 Redfin 担任机器学习与计算机视觉相关的软件工程师/数据科学工程师，积累了丰富的工业研发经验。&lt;/p&gt;&lt;p&gt;他在视觉&amp;ndash;语言联合表示和大规模多模态学习方面具有重要贡献，其代表性研究成果《Scaling up visual and vision-language representation learning with noisy text supervision》推动了多模态表示学习的发展。&lt;/p&gt;&lt;p&gt;值得注意的是，戴明博与杨殷飞目前都已在 LinkedIn 上将公司状态更新为「隐身（stealth）」，其中戴明博的资料显示其担任 CEO。就连戴明博的社交媒体上都标注了「隐身模式」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW90ImRYkyiaALkdAIF1ricnOzjQLUDN8DtlOC2kMSM1iaqJYp58t6qVvOibHH1Ms7kEkMlJDiahGnYJlVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7212962962962963" data-type="png" data-w="1080" data-width="1162" data-height="838" data-imgfileid="503527790" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/170c5e0d-4e80-4cc3-b5bb-a8d0dd5cf192/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在上周六的一次电话采访中，戴明博表示，Elorian 的核心目标是构建能够通过&lt;strong&gt;同时处理图像、视频与音频，对现实世界进行视觉理解与分析的多模态 AI 模型&lt;/strong&gt;。虽然机器人也是其潜在应用方向之一，但公司还设想了更多应用场景，暂未对外披露具体细节。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theinformation.com/articles/former-google-apple-researchers-raising-50-million-new-visual-ai-startup?rc=jn0pp4&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://sites.google.com/site/yinfeiyang/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.linkedin.com/in/andrewdai&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>无需人工标注，轻量级模型运动理解媲美72B模型，英伟达、MIT等联合推出FoundationMotion</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 11 Jan 2026 21:31:48 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8d35ccec-e2f7-470a-941d-38dbe31b5867/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当前的视频大模型发展迅速，但在面对复杂的空间移动和物理规律时，依然 &amp;ldquo;看不懂&amp;rdquo; 物体如何运动。&lt;/p&gt;&lt;p&gt;它们或许能描述视频中发生了什么，但如果你问它：&amp;ldquo;红色的车是在蓝色车转弯之前还是之后通过路口的？&amp;rdquo; 或者 &amp;ldquo;那个皮球的抛物线轨迹最高点在哪里？&amp;rdquo;，很多模型就开始 &amp;ldquo;胡言乱语&amp;rdquo; 了。&lt;/p&gt;&lt;p&gt;究其根本，在于高质量运动数据的极度匮乏。现有的数据集要么规模太小，要么依赖昂贵的人工标注，难以支撑模型去学习真实世界中细粒度的物理运动。&lt;/p&gt;&lt;p&gt;针对这一痛点，来自 &lt;strong&gt;MIT、NVIDIA、UC Berkeley&lt;/strong&gt; 等机构的研究者提出了 &lt;strong&gt;FoundationMotion&lt;/strong&gt;：一套完全不依赖人工标注的自动化数据管线。&lt;/p&gt;&lt;p&gt;令人惊讶的是，仅靠这套管线生成的数据微调后，&lt;strong&gt;15B 参数的视频模型竟在运动理解任务上，超越了 Gemini-2.5 Flash 以及 72B 参数的开源大模型：NVILA-Video-15B: 90.6% on AV-Car benchmark， Gemini-2.5-Flash: 84.1%，Qwen-2.5-VL-72B: 83.3%&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg9FJOic4UUMkkM12d1FdGJjJpOIibe6NzPcUxotsyXraOMoL9ckdM1A9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.26481481481481484" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527509" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8afb5876-6856-4cfb-afab-2f0a67d8ffd8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;项目主页： https://yulugan.com/projects/FoundationMotion.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文： https://arxiv.org/abs/2512.10927&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码： https://github.com/Wolfv0/FoundationMotion&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;视频模型的 &amp;ldquo;物理盲&amp;rdquo; 危机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2024 年至今，被认为是视频生成模型的爆发期。从 OpenAI 的 Sora 到各类国产模型，AI 已经能够生成极其逼真的动态画面。然而，在华丽的像素背后，一个长期被忽视的问题逐渐暴露出来：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这些模型并不真正理解物体的运动。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;例如，在测试中研究人员发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;它们可以生成高速行驶的赛车，却难以判断刹车究竟是发生在碰撞之前还是之后；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;它们能描绘复杂的街景，却常常搞错行人的移动方向与相对位置关系。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;比如我们上传一段一辆汽车在夜间行驶，变道，超过了前方车辆的视频给 Gemini 3 Pro Preview，问 &amp;ldquo;What is the primary driving behavior demonstrated by the ego vehicle in the video?&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgZQ8JJuia79Dnsgc4CGsuq5nzrFRVDCcEwfJlzGakkHIY0ibibcJNz5ibbA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.1875" data-s="300,640" data-type="gif" data-w="960" type="block" data-imgfileid="503527512" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a8ab3d3b-efc4-4d34-b2b3-42ae04948d4c/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgDSuH96icVDwLzq52SVFdwaHYoLh6Ls605H9XfWITMl9GfBFLGzKNWGg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="1.038888888888889" data-s="300,640" data-type="gif" data-w="720" type="block" data-imgfileid="503527513" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a3625f8d-dc72-41a5-b1cf-71b1e55c10ad/640.gif" data-order="1" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Gemini 3 Pro Preview 的回答是这辆车正在它的车道上行驶，完全没有理解这个视频最主要的运动：变道与超车。&lt;/p&gt;&lt;p&gt;正如心理学家 Barbara Tversky 在《Mind in Motion》中所指出的：&lt;strong&gt;空间与运动是人类理解世界的基础&lt;/strong&gt;。 而这一能力，恰恰是当前视频模型最薄弱的部分。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgQtwDuATBrrGtuFhULqX5jZzexicWSAyAntVG7qjcXhhlicmlWwePxHicQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527514" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8831c544-d45b-47b6-948c-0d4a0a969d3f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;问题的根源在于&lt;strong&gt;数据&lt;/strong&gt;。现有视频数据要么只包含静态描述（如 &amp;ldquo;一只狗在草地上&amp;rdquo;），要么高度依赖昂贵、难以扩展的人工标注，使得大规模、细粒度的 &amp;ldquo;运动理解&amp;rdquo; 数据几乎无法获得。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;FoundationMotion &amp;nbsp;一座全自动的 &amp;ldquo;运动数据工厂&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决这一瓶颈，研究团队提出了 FoundationMotion&amp;mdash;&amp;mdash; &lt;strong&gt;一套端到端、无需人工参与的自动化数据生成系统&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;它的工作流程可以被形象地拆解为四步：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgibRYMd86iceZFP2LQX7DN9icib1BE4neJBJiaJfk1T60K9ensZgNewRfyEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.4740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527515" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e95df3aa-8fcb-44d6-9439-9f0b502cb05e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;1 &amp;amp; 2. 预处理 &amp;amp; 先把 &amp;ldquo;运动&amp;rdquo; 精确地抓出来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先，使用成熟的目标检测与跟踪模型，对视频进行逐帧分析，将人、车辆、手部、机械臂等关键物体转化为连续的&lt;strong&gt;时空轨迹（Trajectories）&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;输入： 任何视频。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出： 每个物体在视频中的精确运动坐标。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 把轨迹 &amp;ldquo;讲给&amp;rdquo; 语言模型听&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;仅有数字坐标对语言模型来说过于抽象，FoundationMotion 采用了&lt;strong&gt;多模态融合策略&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;将轨迹转化为结构化的文本描述；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;同时将视频帧与轨迹信息作为 Prompt 输入。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这相当于为模型提供了一份 &amp;ldquo;运动说明书&amp;rdquo;，让它不仅看到画面，还能结合坐标理解物体究竟是如何移动的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 让模型生成标注与问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队利用 GPT-4o-mini，在轨迹与视频的基础上，自动生成两类高质量数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;精细化运动描述：包含速度变化、方向、终止位置等细节；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多维度运动理解问答：覆盖动作识别、时序关系、动作 - 物体关联、空间位置以及重复计数等关键能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终，团队基于 InternVid 构建了约 &lt;strong&gt;50 万&lt;/strong&gt;条高质量运动理解数据，形成了 FoundationMotion 数据集。&lt;/p&gt;&lt;p&gt;数据样例：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg3BJOlObT4JK2d73rzpC6bvD4nomyqW1b0wPrcFoI4BZVBUaP2dqCbw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.573093220338983" data-s="300,640" data-type="gif" data-w="944" type="block" data-imgfileid="503527516" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/79001193-014c-4bee-84d3-b288c234804a/640.gif" data-order="2" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;小模型，击败大模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验环节，研究人员使用 FoundationMotion 生成的数据微调了多个开源视频模型，包括 NVILA-Video-15B 与 Qwen2.5-7B。&lt;/p&gt;&lt;p&gt;结果显示，高质量数据带来的提升是巨大的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;越级挑战： 微调后的 7B/15B 模型在多个运动理解基准上，超越了 Gemini-2.5 Flash 与 Qwen2.5-VL-72B。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;纯数据驱动： 这一提升不依赖额外的模型结构设计或复杂的推理策略，完全归功于数据的质量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;强泛化性： 在自动驾驶、机器人操作、日常活动等不同领域均具备良好表现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无损通用能力： 在增强物理感知的同时，并未损害模型原本的通用视频理解能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;通向 &amp;ldquo;物理 AI&amp;rdquo; 的关键一步&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FoundationMotion 的意义远不止于刷榜。&lt;/p&gt;&lt;p&gt;在自动驾驶与机器人领域，&amp;ldquo;理解物体如何运动&amp;rdquo; 直接关系到系统的安全与决策能力。&lt;/p&gt;&lt;p&gt;FoundationMotion 提供了一条低成本、可扩展的路径，让 AI 能够通过观看海量视频，逐步建立对物理世界的直觉。这套管线未来可广泛用于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;视觉语言模型（VLM）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;视觉 - 语言 - 动作模型（VLA）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;世界模型（World Models）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这被认为是构建真正的具身智能（Embodied AI）的基础设施。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一种基于层级时间标记的 LLM 迁移预测框架，以层级时间标记重构人类移动预测</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Sun, 11 Jan 2026 10:56:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-11-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-11-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynzLibH641j0HXvqNZFQ0hThObFz2s5oXVXG0WrC4jDsC2KsPkfuuMTPg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=1" data-ratio="0.5342592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="309" data-imgfileid="100027111" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/fa9a6db7-71cd-4a11-ba2e-d389cb0f6851/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨%&lt;/p&gt;&lt;p&gt;城市中的人类出行并非连续、均匀的时间序列。通勤、周末出游、周期性活动，构成了一种强烈的「节律结构」。但现有的人类移动预测模型，大多仍将轨迹视作等间隔时间点的线性序列：要么难以捕捉长期依赖，要么在序列拉长后计算成本迅速失控。&lt;/p&gt;&lt;p&gt;来自美国波士顿东北大学（Northeastern University）等的研究团队提出&amp;nbsp;&lt;strong&gt;RHYTHM（Reasoning with Hierarchical Temporal Tokenization for Human Mobility）&lt;/strong&gt;，尝试用一种更接近人类行为组织方式的视角，重构移动预测问题：&lt;strong&gt;先把时间「拆成有意义的单位」，再让大模型进行推理&lt;/strong&gt; 。&lt;/p&gt;&lt;p&gt;相关信息以「RHYTHM: Reasoning with Hierarchical Temporal Tokenization for Human Mobility」为题，发布在 arxiv。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynfiaedtfGDBOEGnhIN3EIgLDXFbJA7nWZFsN7icQKibYMyKYwUwCMzWxXg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.22685185185185186" data-type="png" data-w="1080" data-width="1500" data-height="340" data-backw="546" data-backh="124" data-imgfileid="100027108" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3855a515-bab7-4ebb-8673-924a1b4135de/640.png" alt="图片" data-before-load-time="1768186528570" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2509.23115&lt;/p&gt;&lt;p&gt;&lt;strong&gt;把连续时间，拆成「日」与「周」的层级结构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;历史上，预测人们的移动方式一直是个挑战，原因很简单：人类的移动往往是随机的。然而，仔细观察，你可能会看到人体运动的规律或节奏。掌握这种节奏，也许就能预测人们的移动。&lt;/p&gt;&lt;p&gt;RHYTHM 的第一步不是建模，而是&lt;strong&gt;时间重编码&lt;/strong&gt;。研究者将用户的历史轨迹按固定长度切分为多个片段（，每个片段内部用注意力机制建模短期行为模式，而片段之间再通过更高层级的注意力捕捉跨天、跨周的长期依赖。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynEVjt7C5wmrAWEG6MZxdbK1GlZGlaWm7UNohXiaZKVPbnOzuVfLkTLicg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.4208924949290061" data-type="png" data-w="986" data-width="986" data-height="415" data-imgfileid="100027106" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/fefcd4a2-5e12-419f-8143-480cb32c0285/640.png" alt="图片" data-before-load-time="1768186528594" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：RHYTHM 的开发设想。&lt;/p&gt;&lt;p&gt;这种层级时间标记（hierarchical temporal tokenization）带来两个直接结果：一是显著缩短模型需要处理的有效序列长度，二是显式保留了人类移动中最关键的周期结构，而不是让模型困在冗长序列中自闭式学习。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;冻结的大模型，只负责「理解与推理」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与直接微调大模型不同，RHYTHM 选择将预训练&amp;nbsp;LLM&amp;nbsp;&lt;strong&gt;完全冻结&lt;/strong&gt;，只把它作为一个通用的序列推理引擎。每个时间片段会被配上对应的&lt;strong&gt;语义描述提示&lt;/strong&gt;（例如该时间段的轨迹特征），这些提示先由 LLM 离线编码成语义向量，再与时间标记后的轨迹表示融合。&lt;/p&gt;&lt;p&gt;这样一来，LLM 不需要在训练阶段反复参与前向计算，却仍然为模型提供了高层语义理解与跨片段推理能力，避免了上下文爆炸和算力浪费。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynX9bpsibbgsKM7LvDRTCq5YeXdMicA12q2UkjOibEroOTWdkxvj3NpIAXw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.4497991967871486" data-type="png" data-w="996" data-width="996" data-height="448" data-imgfileid="100027107" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e8c62cc6-eb6c-44fb-9c3e-7f56fcaab6e0/640.png" alt="图片" data-before-load-time="1768186528820" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：RHYTHM 的拟议架构。&lt;/p&gt;&lt;p&gt;研究团队在三个真实世界的人类移动数据集上，将 RHYTHM 与多种主流方法进行对比。结果显示，在总体预测准确率上，RHYTHM 平均提升&amp;nbsp;&lt;strong&gt;2.4%&lt;/strong&gt;；在更具不确定性的&lt;strong&gt;周末场景&lt;/strong&gt;中，提升幅度达到&amp;nbsp;&lt;strong&gt;5.0%&lt;/strong&gt;。与此同时，由于序列被显著压缩、LLM 主干被冻结，模型训练时间减少了&amp;nbsp;&lt;strong&gt;24.6%&lt;/strong&gt; 。&lt;/p&gt;&lt;p&gt;团队还用七天的的运动数据测试了 RHYTHM，发现它能可靠预测接下来一天、接下来几天和接下来一周的运动。理论上，它其实可以预测更远的未来，但误差也会因此而更大。&lt;/p&gt;&lt;p&gt;这些结果表明，性能提升并非来自更大的模型或更长的历史输入，而是来自&lt;strong&gt;更符合行为规律的时间组织方式&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一个关键转向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在遇到极端事件时，人们都想预知未来，以便自己能做出更及时的反应。想要达到这一点，RHYTHM 就不能对预训练 LLM 的质量一直保持高度依赖。在未来的扩展中，团队可能会整合自回归解码，以更接近逐步模拟人类移动决策。&lt;/p&gt;&lt;p&gt;相关报道：https://techxplore.com/news/2026-01-ai.html&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，唐杰、杨强、杨植麟、林俊旸和刚回国的姚顺雨坐一起都聊了啥？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 23:27:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ee8a5b00-e8eb-4362-a1d3-d1eded846c24/1768058508308.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2026 年 AI 的进化，势必会超过我们的想象。&lt;/p&gt;&lt;p&gt;1 月 10 日下午，在由清华大学基础模型北京市重点实验室、智谱 AI 发起的 AGI-Next 前沿峰会上，汇聚了刚刚上市两天的智谱、领跑独角兽月之暗面、全球开源大模型顶流 Qwen 的创始人、CEO 和负责人。&lt;/p&gt;&lt;p&gt;智谱 AI 的唐杰、月之暗面的杨植麟、阿里云通义千问的林俊旸等正处于聚光灯下的中国大模型掌舵者，以及张钹院士、杨强等学界泰斗罕见地同台亮相。&lt;/p&gt;&lt;p&gt;刚刚履新腾讯 AI 首席科学家、曾以「思维树」（Tree of Thoughts）和《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650965529&amp;idx=1&amp;sn=eb553785af462d8fdba2793990754823&amp;scene=21#wechat_redirect" target="_blank"&gt;AI 下半场&lt;/a&gt;》闻名的姚顺雨，也在此迎来了回国后的对外首秀。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagIZwRXaw61XM86tGgFa3kox4yTCH5e3bSG4BgfHIQ3hlhI59UaFwibvA/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="341" data-imgfileid="503527676" data-ratio="0.4546296296296296" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagIZwRXaw61XM86tGgFa3kox4yTCH5e3bSG4BgfHIQ3hlhI59UaFwibvA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5c589d13-5933-48da-ae2c-084b72d7931f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;本周国内 AI 创业公司接连上市，DeepSeek 又刚刚曝出即将发布全新一代大模型，人工智能的热度还在持续升温，但另一方面，AI 技术似乎来到了一个临界点：一边是大规模预训练 (Pre-training)、强化学习对齐（Alignment/RLHF）等范式带来的爆发期即将结束，另一方面，新的提升范式似乎还未启动。&lt;/p&gt;&lt;p&gt;如果说 2025 年的大模型技术以一种近乎「暴力美学」的方式撕开了 AGI 大门的一角，那么 2026 年开年这场峰会，就像是一次冷静后的复盘与再出发。&lt;/p&gt;&lt;p&gt;无论是演讲时的独白，还是圆桌上的激辩，几位掌舵者目及的方向不约而同：从「聊天机器人」进化为「干活的智能体」；从单纯堆砌算力转向追求 AI「自我学习」的新探索；让 AI 从预测下一个词，变为真正理解并改变物理世界的智能生命体。&lt;/p&gt;&lt;p&gt;但与此同时，他们给出的解法却各不相同。&lt;/p&gt;&lt;p&gt;这场峰会传递出一个清晰的信号：单纯的参数竞赛已成过去，前沿公司和团队正在扎堆进入新航路。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;唐杰：让机器像人一样「思考」与「做梦」&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagDzNicIbnzr4IMhZJ1LOrBe2MVOFCNhsF0pY0sAmrGDKLiagVduQic4g3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527677" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/025979a6-a388-4f1d-949a-a267e19c03bd/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为学术界与产业界的双重代表，清华大学计算机系教授、智谱创立发起人兼首席科学家唐杰教授将大模型的进化比作人类认知的成长过程。他回顾了 AI 的发展历程，认为&lt;strong&gt;我们正在从「系统 1」（基于直觉的快思考）向「系统 2」（基于逻辑的慢思考）进化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;唐杰抛出了一个引人深思的观点：「Scaling 可能是一个最轻松的办法，是我们人类偷懒的办法。」他认为，单纯依靠堆砌数据和算力的已知 Scaling 路径虽然有效，但更本质的方法可能是找到新的知识压缩方式，探索未知的 Scaling 范式。&lt;/p&gt;&lt;p&gt;为此，他重点介绍了 &lt;strong&gt;RLVR&lt;/strong&gt;（Reinforcement Learning with Verifiable Rewards，可验证奖励的强化学习）。在数学、编程等「可验证」的场景下，模型可以通过自我探索突飞猛进。智谱 AI 最新的 GLM-4.7 正是这一思路的产物，它在 Coding 和 Agent 任务上展现了惊人的能力。但唐杰也坦承，未来的挑战在于如何将这种能力扩展到「半自动验证」甚至「不可验证」的广阔领域。&lt;/p&gt;&lt;p&gt;在移动端 Agent 方面，唐杰展示了 &lt;strong&gt;AutoGLM&lt;/strong&gt; 的野心。未来的 AI 不应该只是一个聊天框，而应该是一个渗透到设备底层的幽灵。他们采用了一种「API + GUI」的混合模式：对 AI 友好的环节走 API，对人类友好的环节则模拟人手点击 GUI（图形用户界面）。演示中，AutoGLM 可以在手机后台静默执行长达 40 步的复杂操作 &amp;mdash;&amp;mdash; 从查询攻略、打开地图、比价、到最终下单订票，一气呵成。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagYWic0sPPz0Jtyv0NYiayYIyZGWCcIHXeK3ARJoACo7JtzsAPUNLwIy9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527679" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/483a3847-dfd2-464d-ae8e-b6e70c57fb30/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;演讲中一大迷人的部分在于唐杰对「&lt;strong&gt;机器睡眠&lt;/strong&gt;」的构想。他认为人脑之所以聪明，是因为有睡眠机制，在无意识中整理记忆、进行自学习。未来的 AI 也应该具备类似的机制，通过「自反思」和「自学习」来消化数据，而不仅仅是被动地接受训练。他强调，如果没有这种机制，人类的长期记忆可能只是一堆噪音，无法转化为真正的知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagkXcf1DEZbicwIMkvp1B94UUrqialZxfIXvLgQy5pPibrJwFrSU1XjsbxA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527680" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/092f552f-337f-4512-a6c6-668787731901/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管中国开源模型在 2025 年席卷了各大榜单，前五名几乎被中国模型包揽，但唐杰依然保持着清醒。他提醒道，我们是在开源的游乐场里玩得很高兴，但与顶尖闭源模型的实际差距可能并没有想象中那么小。只有去探索那些未知的 Scaling 范式，才能真正缩小这一差距。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;杨植麟：智能是不可替代的 Token，我们在寻找最美的 Loss 曲线&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag3xQ4xkJGCjPh0jgrPiaT8kf1zmpB7BdGn3WJSrx8VG6sk5Wj0bHeFWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527681" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e1ae983b-c817-489b-bfbe-aa6a28e54613/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;一如既往，杨植麟的演讲充满了第一性原理的极客浪漫。这位 90 后创始人没有过多罗列商业数字，而是将大模型的发展回归到最本质的物理规律。他认为从 2019 年至今，&lt;strong&gt;所有大模型的第一性原理依然是 Scaling Law&lt;/strong&gt;，这本质上是一个「将能源转换为智能」的过程。如果拥有更好的芯片、更优的架构，就能以更少的能源置换出更高级的智能。&lt;/p&gt;&lt;p&gt;他特别提到了 Kaplan 早期的经典论文，对比了 Transformer 与 LSTM 在 Scaling Law 下的表现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagPhO551GHvs1XzS0DqtxHISBlEaPR6cDW52b5CuicPJrTLhGomUP9Flw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527682" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5f35752a-ae59-415c-b026-1ea21330702a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在短 Context（上下文）下，两者差异不大；但当 Context 拉长到 1000 甚至更长时，Transformer 的优势才显露无遗。这种「长程优势」，正是 Agent（智能体）时代的胜负手。因为很多 Agent 任务本质上是搜索问题，而更好的预训练模型能提供更强的先验，帮助我们在茫茫的搜索空间中快速剪枝。&lt;/p&gt;&lt;p&gt;为了追求极致的「Token Efficiency」（Token 效率），杨植麟展示了月之暗面在 2025 年的两大杀手锏。首先是&amp;nbsp;&lt;strong&gt;Muon 优化器&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagfwWPuqKuOhG4jRQPaUrkBNlM9pgBdiac9K5zDx1Yb8UehCtKbeBskAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527683" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c6ae9a3c-9a7e-425f-8ecd-ab70146ead74/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;相比于统治了业界十年的 Adam 优化器，这个全新的二阶优化器实现了「两倍的 Token 效率提升」。这意味着，达到同样的智能水平，它只需要一半的数据量。为了解决二阶优化器常见的训练不稳定问题，团队引入了创新的「QK Clip」机制，动态调整梯度。杨植麟指着屏幕上一张完全平稳下降、没有任何毛刺（spike）的 Loss 曲线图，动情地说道：「这张图是我 2025 年见过的最美的东西，它是一个完全平稳下降的 Loss 曲线。当你有一个优雅的方法，就可以得到一个优雅的结果。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagQnlvRUxg3fuCv3NsebGsxReibyhHpoG4LaQvMLK8IEVUc0ufTNWmTbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527684" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/4fe980f1-62bf-43b5-945f-3e106263d3a0/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;另一个突破则是&lt;strong&gt; Key-Value Cross Attention&lt;/strong&gt;。针对长上下文任务，这种新架构不仅克服了传统线性注意力在长距离任务上「掉点」的顽疾，甚至在超长 Context 下的表现超越了全注意力（Full Attention）机制，且速度提升了 6 到 10 倍。&lt;/p&gt;&lt;p&gt;在演讲的最后，杨植麟谈到了 AGI 的「品味」。&lt;/p&gt;&lt;p&gt;他认为&lt;strong&gt;做模型本质上是在创造一种世界观&lt;/strong&gt;。智能与电力不同，电力是同质化的，深圳的一度电和北京的一度电没有区别；但&lt;strong&gt;智能是非同质化的&lt;/strong&gt;，一位音乐家产生的智能与一位程序员产生的智能截然不同。他透露，基于这些理念打造的 &lt;strong&gt;Kimi K2&lt;/strong&gt; 模型，在极高难度的 HLE（Humanity&amp;#39;s Last Exam）基准测试中达到了 45% 的准确率，超越了 OpenAI 等美国前沿公司。&lt;/p&gt;&lt;p&gt;面对 AI 可能带来的风险，他引用了 Kimi 给他的回答：这不仅是工具，更是人类认知的延伸，我们不应因恐惧而停滞不前，放弃人类文明的上限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;林俊旸：通往通用智能体（General Agent）之路&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag08mxhdExURgqJ8qSgMjjibyqndz1brWvr7p5Ijiab19t26ykyQeDRzDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527685" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0a7f71fd-2aa2-4fee-aa8f-23fa7c34c2d8/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;阿里云通义千问（Qwen）的林俊旸则带来了一股浓厚的产品主义气息。作为开源界的「卷王」，他直言「&lt;strong&gt;模型即产品&lt;/strong&gt;」，并分享了 Qwen 如何通过开源社区的反馈完成自我进化的故事。&lt;/p&gt;&lt;p&gt;针对 2026 年的主力模型 &lt;strong&gt;Qwen-3&lt;/strong&gt;，林俊旸透露团队正在全力打磨 &lt;strong&gt;Hybrid Architecture（混合架构）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种架构极有可能是将 Transformer 与 Mamba 或类似的线性注意力机制以 3:1 的比例混合，旨在解决无限长文本（Infinite Long Context）带来的显存和计算瓶颈。他特别自豪地提到了「不降质」的突破 &amp;mdash;&amp;mdash; 在增强视觉和语音能力的同时，模型的文本推理能力不再像过去那样出现倒退，真正实现了多模态与智力的同步提升。&lt;/p&gt;&lt;p&gt;「人有眼睛和耳朵才能更好地理解世界，模型也一样。」林俊旸展示了 Qwen 在 &lt;strong&gt;Omni（全能） 模型&lt;/strong&gt;上的进展。&lt;/p&gt;&lt;p&gt;他放出了两张对比图，一张是 8 月份生成的「AI 味」浓重的图片，另一张是 12 月份生成的「宿舍女生自拍」风格图片，后者逼真程度令人咋舌。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagiaj4zyaZTqnC2RIXcDLAj99bpD4lKxURlAje1ncwbKsOIhibcNb8BUtg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527687" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/fec7b670-e8f1-495d-aa1f-d011fce6aae4/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更重要的是，&lt;strong&gt;Qwen 正在尝试将「生成」与「理解」打通&lt;/strong&gt;。例如在解几何题时，如果模型卡住了，它可以自己画一条辅助线（生成），然后基于这张新图继续推理（理解）。这种「理解-生成一体化」被林俊旸视为通向 AGI 的重要台阶。&lt;/p&gt;&lt;p&gt;林俊旸还分享了一个关于开源社区「反哺」的有趣案例。用户曾反馈图片编辑功能中「手放下来位置歪了」的问题，这让团队意识到即使是微小的像素级偏移，在真实应用中也是不可接受的。这种算法与 Infra（基础设施）的联合优化，让 Qwen 在迭代速度上保持了惊人的优势。&lt;/p&gt;&lt;p&gt;对于 AI 的未来，林俊旸的愿景非常接地气：「如果你的想法不是帮助全人类，那不如不做大模型。」他希望未来的模型不仅仅是通过考试的学霸，更是一个能真正帮助人类的 Agent。他观察到旧金山已经进入了 Vibe Coding（氛围编程）时代，没人再手写代码，而国内尚未普及。他坚信，能够操作电脑、写代码、甚至在物理世界里端茶倒水的 &lt;strong&gt;Embodied AI（具身智能）才是 AI 走向现实世界的终极形态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;圆桌激辩：从硅谷的富人创新到 Agent 的终局&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说演讲环节是各位掌舵者对自家技术版图的宣示，那么随后的圆桌对话则是一场卸下防备的坦白局。&lt;/p&gt;&lt;p&gt;这场对话的阵容堪称豪华：学界泰斗杨强、刚刚履新腾讯 AI 首席科学家的姚顺雨（线上参加，这也是姚顺雨告别 OpenAI 加入腾讯后的首次公开露面）、通义千问负责人林俊旸，以及智谱 AI CEO 唐杰。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagEZBiajb6OHFbDOBV5yXYUrL1ff8L4Odu8v87t5ia6jcx1ticqYpPHS6vQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527686" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/1ee9fd57-642f-4543-aa51-0652f778b18f/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在主持人的追问下，四位嘉宾围绕模型分化、下一代范式、Agent 的商业落地以及中美 AI 差距等敏感话题，展开了一场超过 70 分钟的思想交锋。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ToC 的温吞与 ToB 的激进：姚顺雨的首秀观察&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为横跨中美、经历过 OpenAI 核心研发团队的科学家，姚顺雨的视角显得尤为犀利。对于当前大模型在 ToC（面向消费者）和 ToB（面向企业）市场的表现，他给出了一个极其鲜明的判断：ToC 端的体验正在趋于平缓，而 ToB 端的生产力革命已经发生。&lt;/p&gt;&lt;p&gt;「大家都有一个感觉，今天用 ChatGPT 和去年用 ChatGPT，对大部分人大部分时候其实感受的变化已经没有那么强烈了。」姚顺雨直言不讳。对于普通用户来说，模型在抽象代数或范畴论上的能力提升是「无感」的，它更像是一个搜索引擎的加强版。但 ToB 领域则完全不同，尤其是 Coding 场景，「&lt;strong&gt;Coding 革命已经开始&lt;/strong&gt;，它正在重复整个计算机行业做事的方式 &amp;mdash;&amp;mdash; 不再写代码，而是用英语和电脑交流。」&lt;/p&gt;&lt;p&gt;他用一个生动的例子解释了为什么企业愿意为最强的模型支付溢价：如果一个员工年薪 20 万美元，每天处理 10 个任务。顶级模型（如 OpenAI o1）能做对 9 个，而差一点的模型只能做对 5 个。「问题在于你不知道错的那 5 个是哪 5 个。」在这种情况下，企业宁愿支付高昂的溢价来换取确定性。因此，姚顺雨预判：「在 ToB 市场上，强模型和弱模型的分化会变得越来越明显。」&lt;/p&gt;&lt;p&gt;对于这一观点，阿里云的林俊旸表示认同，他还从「基因」的角度解读一下。对于姚顺雨的「腾讯肯定还是 To C 基因更强的公司」的看法，他半开玩笑地说道：「顺雨到了腾讯，腾讯可能就变成了有顺雨基因的公司。」他认为，无论是 ToB 还是 ToC，最终服务的都是真实的人类，关键在于能否解决长尾问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一个范式：是「间谍」还是「核爆」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当话题转向 2026 年可能出现的技术范式转移时，&lt;strong&gt;自主学习（Self-learning）&lt;/strong&gt;成为了全场共识的关键词。但这个范式将以何种面貌出现？&lt;/p&gt;&lt;p&gt;姚顺雨提供了一个非常独特的视角。他认为自主学习可能不会像 AlphaGo 那样以「平地惊雷」的方式出现，而更像是一个「潜伏的间谍」。&lt;/p&gt;&lt;p&gt;「这个事情其实已经在发生了。」姚顺雨指出，ChatGPT 利用用户数据不断拟合聊天风格，Claude Code 编写了自己项目 95% 的代码，这些都是自主学习的雏形。他将未来的 AI 系统比作两部分：一部分是神经网络（大脑），另一部分是调用这个神经网络的代码库（身体）。当有一天，AI 开始自己编写那部分「调用自己的代码」时，质变就会发生。「这可能更像是一个间谍渗透的过程，而不是一次突发的突破。」&lt;/p&gt;&lt;p&gt;对此，智谱 AI 的唐杰则表现得更加审慎。他坦言自己对 2026 年出现巨大的范式革新持怀疑态度。他提出了&lt;strong&gt;「智能效率」（Intelligence Efficiency）&lt;/strong&gt;的概念，即投入多少资源能获得多少智能增量。目前的 Scaling 虽然有效，但本质上是「最笨的方法」。真正的范式革命，应该是找到一种能用极少投入换取巨大智能增量的新路径。&lt;/p&gt;&lt;p&gt;林俊旸则从安全角度表达了对「主动性 AI」的担忧。「我最担心的不是 AI 学了什么，而是它主动做了一些该做或是不该做的事。」他举例说，如果 AI 主动发现会场有个炸弹，这固然是好事；但如果它产生了其他不可控的主动意图，这将是巨大的安全隐患。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 的终局：从工具到「职场人」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于 2026 年被寄予厚望的 &lt;strong&gt;Agent（智能体）&lt;/strong&gt;，杨强教授提出了一个清晰的四阶段演进论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;目标和规划都由人定义；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;目标由人定义，规划由 AI 辅助；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 观察人的工作流程（Process Data），自动学习规划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;终极阶段：目标和规划都由大模型内生定义。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;目前的 Agent 大多处于第一、二阶段。姚顺雨认为，Agent 要真正产生经济价值，瓶颈往往不在模型本身，而在环境和教育。他在 Scale AI 实习的经历让他意识到，即使模型能力不再提升，仅靠将现有模型部署到各种企业环境中，就能产生巨大的经济效益。&lt;/p&gt;&lt;p&gt;「人和人的差距正在拉大，不是 AI 替代了人的工作，而是会使用工具的人在替代不会使用工具的人。」姚顺雨发出了这样的呼吁。他认为，当下中国最有意义的事情之一，就是教育公众如何更好地使用 AI 工具，填平这道认知鸿沟。&lt;/p&gt;&lt;p&gt;林俊旸则补充了长尾理论。他认为 Agent 的核心价值在于解决那些通用模型无法覆盖的、极其个性化的长尾需求。「如果我寻遍各处都找不到解决方案，但在那一刻，AI 帮我解决了，这就是 AI 最大的魅力。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中美差距的灵魂拷问：胜算如何&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;圆桌的高潮出现在最后一个话题：3 到 5 年后，全球最领先的 AI 公司是一家中国公司的概率有多大？&lt;/p&gt;&lt;p&gt;林俊旸认为比较困难，他给出的理由却发人深省。他将其比作美国的「富人创新」与中国的「穷人创新」。&lt;/p&gt;&lt;p&gt;硅谷拥有顶级的显卡储备，甚至在有些浪费地使用算力探索下一代范式；而中国团队往往是在资源受限的情况下，被逼出了极致的算法优化和工程落地能力。「穷则思变，创新往往也发生在资源受限的地方。」林俊旸认为，软硬结合（如 AI 与 MCU 芯片的结合）或许是中国突围的一个机会。&lt;/p&gt;&lt;p&gt;姚顺雨对此则更为乐观。他认为，硬件（如光刻机）的瓶颈是客观且可解决的，真正的差距在于主观的冒险精神和研究文化。&lt;/p&gt;&lt;p&gt;「在中国，大家还是更喜欢做安全的事情。如果这个事情已经被证明可以做出来，我们几个月就能复现并做到极致。但如果让你去探索一个未知的领域，比如长期记忆，大家就会犹豫。」姚顺雨犀利地指出了中国研究界的痛点：&lt;strong&gt;过分关注榜单和数字，而忽视了什么是正确的事情。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;他回忆起在 OpenAI 的经历，那里的人更在乎「能不能创造出新的东西」，而不是「能不能在榜单上高出一分」。他呼吁中国的研究者走出榜单的束缚，「DeepSeek 做得就很好，他们没有那么关注榜单，而是关注用户体验和什么是正确的技术路径。」&lt;/p&gt;&lt;p&gt;唐杰教授则以「最不幸的一代」自嘲：上有老一辈学者还在工作，下有 00 后天才少年横空出世，夹在中间的 80 后、90 后研究者好像被「无缝跳过了」，世界已经交给下一代了。但他同时指出，中国 00 后一代展现出的&lt;strong&gt;冒险精神&lt;/strong&gt;令人欣慰。&lt;/p&gt;&lt;p&gt;「如果在这个时间点，有一群聪明人真的愿意做特别冒险的事，而且国家能提供更好的容错环境，哪怕概率只有 20%，我们也有机会抓住那个三五年一遇的窗口期。」唐杰最后总结道。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;尾声：未完成的答卷&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这场圆桌对话并没有给出一个确定的答案，却留下了一份沉甸甸的思考。&lt;/p&gt;&lt;p&gt;从姚顺雨对「榜单文化」的批判，到林俊旸对「富人创新」的羡慕与不甘，再到杨强和唐杰对学术界使命的再定义，我们看到的是中国 AI 力量在追赶过程中的焦虑、清醒与韧性。&lt;/p&gt;&lt;p&gt;正如主持人李广密所言：「过去我们是在追赶，是在补课。但当科技能力追上来之后，2026 年，我们期待看到中国不仅有更强的火箭，更要有自己的 Payload（有效载荷）和 Product（产品）。」&lt;/p&gt;&lt;p&gt;在 Scaling Law 依然有效的今天，中国 AI 正在从刷榜走向落地，从复现走向探索。虽然胜算或许充满了不确定性，但正如那条被杨植麟称赞的「最美 Loss 曲线」一样，只要方向正确，下降就是必然的趋势。&lt;/p&gt;&lt;p&gt;同样重要的是，通过把自己最先进的大模型开源出来，国内科技公司正在从全球 AI 技术的跟随者转变为推动者。也同样是随着这个过程，在「六小虎」之后，我们已经可以逐渐看出国内 AI「开源四巨头」正脱颖而出。&lt;/p&gt;&lt;p&gt;除了 DeepSeek 之外，包括智谱、月之暗面和 Qwen，他们今天有三个都在台上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从杨植麟眼中那条「最美的 Loss 曲线」，到唐杰构想中「会做梦的机器」，林俊旸致力打造的「全能智能体」，再到姚顺雨所预言的如「间谍」般潜行的自主学习新范式，这场 AGI-Next 峰会为 2026 年的 AI 战事定下了基调。&lt;/p&gt;&lt;p&gt;过去几年，我们忙于教 AI「读书」，试图将人类文明的知识灌输给它；而接下来的篇章，则是教它「做事」，让它在物理世界的真实反馈中像人一样思考、规划与行动。参数的军备竞赛或许已经降温，但关于智能本质的探索才刚刚开始。&lt;/p&gt;&lt;p&gt;正如几位演讲者在圆桌上的共识：智能的上限远未到达，也是那些愿意「走出榜单、寻找正确之事」的探索者们（像姚顺雨所呼吁的那样）正在努力的方向。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
