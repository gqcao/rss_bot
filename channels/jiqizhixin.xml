<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>京东「再造」京东</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 18:14:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜微胖&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;这，很不京东&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要不是 App Logo 上那只举着魔法棒的小狗先「剧透」，你很难把它和京东联系在一起。&lt;/p&gt;&lt;p&gt;点开「京东AI 购」，反直觉几乎是瞬间发生。没有信息洪流扑面而来，也看不到叠床架屋的功能入口，页面干净到几乎只剩一个对话框。&lt;/p&gt;&lt;p&gt;等等，这不是个聊天 App？这真是用来「买东西」的地方？&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287" style="width: 59.4686%;"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="525" data-backw="266" data-imgfileid="503529354" data-ratio="1.9703703703703703" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKKY3nkSYfwbW0enDkCzficAMUD7iah13UlZsHxxWb85qib2tqXFENtrbEA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="inline" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/50ccab7e-acd1-4a57-a248-f151c3f81cd2/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 56.64%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287" style="width: 40.4469%;"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKZo3wdrvLmCUiaVEyw8TwmYicq7nVeKOMickLlsHKRxpCqbcZunOibz5Qhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="2.175" data-s="300,640" data-type="png" data-w="640" type="inline" data-backw="266" data-backh="579" data-imgfileid="503529386" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/db070d12-fe31-4699-97da-270e026857f3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 主站 VS 新App页面设计，完全是两个世界。&lt;/sup&gt;&lt;/p&gt;&lt;p data-pm-slice="2 2 []"&gt;它不像一个电商 App，更不像那个你已经用了很多的京东，总是强调效率、审美多少有点「直男」的货架工具。&lt;/p&gt;&lt;p&gt;更出人意料的是，它还不是个「闷葫芦」。我还没开口，它先「说话」了。&lt;/p&gt;&lt;p&gt;页面上方弹出一句很有「活人感」的招呼。接着，「橱窗」一样的卡片提醒我，前两天买的丙烯颜料到了，还顺手附上一份使用指南。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="945" data-backw="578" data-imgfileid="503529388" data-ratio="1.6342592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK9sRaj7ibJcuBV3NIvjvFCqeAYB1hWrYDnwnib8aoXBnFDxpsfDpVozhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="width:175px;height:286px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c8a25386-b1f9-4c79-8b89-01126f1ddbdc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;那一刻的感觉，更像是一个已经和你混熟的助理，提前一步意识到：你现在，可能正需要这些。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/54c868f8-33e7-4cc2-aaa5-59cc087a9069/1768990095047.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKSSPWgpWKl1VGQ7MBevBzPRStAria64DWgZwpcO3kdEdYcLND0mmuSVg%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4351647101554900996" data-ratio="0.46272493573264784" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4351647101554900996" data-vh="495.75" data-vidtype="2" data-vw="661" data-w="1080" height="508" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4351647101554900996"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 点开卡片会自动生成一份基础指南，还有同类产品推荐。&lt;/sup&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;直到上手用过几次之后，我才意识到一个更大的变化正在发生。生活服务这件事，正在被压缩成一句话。&lt;/p&gt;&lt;p&gt;比如，「一句话，决策完成」。直接抛出需求：「小学生月底去鄱阳湖观鸟，作为观鸟新手，需要准备哪些装备？」&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7daedf2b-d26a-40fd-841e-dff4fe86d30d/1768990118956.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 过去需要查攻略、抄清单、逐一比对的过程，被压缩成了一次「直接交卷」。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;系统接住的不是关键词，而是一整个场景，装备被拆解、推理、重新组合成一套「省心方案」：双筒望远镜、防风外套、防蚊用品，甚至连折叠椅、观鸟笔记本和铅笔，都被一并考虑进去。&lt;/p&gt;&lt;p data-pm-slice="2 2 []"&gt;后续「PK」，更能助你完成决策前的「临门一脚」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="795" data-backw="477" data-imgfileid="503529397" data-ratio="1.6666666666666667" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKrHibqFOj6aDibHlEnJGNzwrKPXHiamC2bPop7giaxlUkGb9XibQk14eEC1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="477" type="block" data-original-style="width:159px;height:265px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8fc1258c-af6e-4544-a442-b86fea4ee456/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;还有「一句话，信息到位」。对话框被「焊」在商品页底部，不必再耐着性子把图文介绍从头翻到尾，直接发问该买多大的码、总结用户评价，AI&amp;nbsp;会自动去「抓答案」，把结果整理给你。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e19d83ad-835c-4674-a1d5-b19ad06e73f0/1768990148777.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 针对你关心的问题，AI 会自动去「抓答案」，再把结果整理好给你。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;而「找优惠」、「试穿」这些用户期待值最高的能力，甚至被设计成常驻入口，紧挨对话框，一「点」即达。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7488681d-e926-4cb9-9736-0477d5aa5eba/1768990170547.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;每天主站上那么多的优惠，哪些羊毛值得薅？一点即达。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一刻，我终于意识到那种陌生感从何而来。这种极简设计&amp;mdash;&amp;mdash;一个对话框，甚至只是一个 tag、一个浮窗&amp;mdash;&amp;mdash;正在把原本庞大、厚重的电商世界折叠起来。原本需要被反复「逛」的货架体系，变成了一种「呼之则来、挥之则去」的能力，许多曾经耗时费力的事情，就这样被轻描淡写地完成了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;快思考&amp;nbsp;&amp;times;&amp;nbsp;慢思考：&lt;/strong&gt;&lt;strong&gt;生活服务，又被重新想了一遍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很长一段时间里，电商产品几乎都建立在一个默认前提上：用户是理性的。他们知道自己要买什么，打开 App，搜关键词、看参数、比价格，然后尽快完成下单。&lt;/p&gt;&lt;p&gt;但现实生活，很少这么标准和工整。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;更多时候，需求本身是模糊、复杂、说不清楚的，你甚至不知道该从哪一步开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;第一次去婆罗洲热带雨林徒步的人，对该准备哪些装备毫无概念；新手爸妈面对即将到来的生活变化，也说不清楚到底要提前备齐什么；想吃点辣的，预算 20 块左右，别太远，一会儿还要开会，但也说不清吃啥。&lt;/p&gt;&lt;p&gt;当一个人还没想明白「要什么」时，传统电商那套以搜索和筛选为核心的机制，反而会变成一种负担&amp;mdash;&amp;mdash;它在挑战人性，要求一个还没想明白的人，先把逻辑捋顺。&lt;/p&gt;&lt;p&gt;在这种情况下，用户几乎不可能直接在传统平台里完成需求。他们往往会先转战内容平台（比如小红书）查攻略、做功课、记清单，把「该买什么」这件事想清楚；再返回电商或外卖平台，一件件搜索、对比、筛选。平台并不真正参与「思考」，而是把最费力的决策过程，完整地甩给了用户。&lt;/p&gt;&lt;p&gt;而&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「&lt;/span&gt;京东&amp;nbsp;AI&amp;nbsp;购&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;，试图接住的这些「说不清」的时刻。&lt;/p&gt;&lt;p&gt;它不再要求用户先把需求想明白再来下单，而是把原本压在用户身上的决策负荷，转移给&amp;nbsp;AI。这正是产品团队反复提到的&lt;strong&gt;慢思考能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;通过与 AI 「对话」，那段最「烧脑」的过程，不再发生在用户反复滑动、来回跳转的手指之间，也不再只存在于用户的脑中，而是被系统接管。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529345" data-ratio="0.47129629629629627" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKicaotR5CiaO7zSrLD4YKtYC6xia0cYu3VznpNHzzx4oZWUKlibemicHpSEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="width:392px;height:185px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f741231c-e7c5-4b9f-b90d-85f943028384/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;以「新手登山装备」为例。AI 做的第一件事，不是着急推荐买什么，而是弄清楚你到底想干嘛，确保别出错。&lt;/p&gt;&lt;p&gt;一句模糊的人话，会被拆解成一份「可计算的需求说明书」：新手、不懂行、不求专业进阶、预算有限、希望少踩坑。随后，多 Agent 各司其职、协同工作，从不同侧面反复验证：当前这套判断，是否真的贴合「新手登山」的核心意图。&lt;/p&gt;&lt;p&gt;当各个 Agent 给出结果后，系统会进行整合与排序，原则非常明确&amp;mdash;&amp;mdash;需求是否被满足，永远排在第一位。只有「新手可用」前提成立，系统才会进一步引入个人画像，把更符合习惯的商品往前放。&lt;/p&gt;&lt;p&gt;最后，才轮到商品本身「靠不靠谱」的判断。&lt;/p&gt;&lt;p&gt;AI 会结合京东强大的供应链数据（如实时规格、价格、销量），并从海量真实评价中提炼关键信号，把稳定性高、评价一致性强的商品作为重要加权项。&lt;/p&gt;&lt;p&gt;这些信息不仅影响排序，也会被直接写进推荐理由中。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1d753dce-94db-456b-8b43-8e48d71c074b/1768990200748.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 你得到的是一组数量有限、附带推荐说明的商品卡片。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;最终呈现在你面前的，不再是一个需要自己筛选、无限展开的货架，而是一组数量有限、附带推荐说明的商品卡片。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5a6c6c11-a520-4272-b9de-7b94f6d21a5e/1768990220191.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp;外卖生活服务也是如此。推荐理由写得清楚，最终呈现的不再是一份「谁更热门」的商家榜单，而是最适合你当下情境的选择。评分和销量依然存在，但不再是第一优先级，而是用来优化结果。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;与此同时，还有另一种&lt;strong&gt;被极度压缩的慢思考形态&lt;/strong&gt;，出现在复购、常购、定期补货等高确定性场景中，比如卫生纸、猫粮猫砂。&lt;/p&gt;&lt;p&gt;在这些场景里，用户对「买什么」几乎没有任何犹豫。但在传统电商中，他们仍然不得不走完整套流程：从打开 App 到最终支付，七八步下来，没有创造什么新价值。&lt;/p&gt;&lt;p&gt;而通过「对话」，这条链路被直接压缩到近乎「自动驾驶 L4」。无论是「上次那杯咖啡，再来一杯」，还是「之前买的那本书，再来一本」，AI 都会自动完成整套需求映射。&lt;/p&gt;&lt;p&gt;调出历史订单、匹配你的口味或品类偏好、默认配送地址，把一张所有信息都已填好的「确认卡片」，直接递到你面前，几乎没有摩擦。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="450" data-backw="266" data-imgfileid="503529338" data-ratio="1.6879629629629629" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKcy8o445VWzjkTHzyvEYXIltmn0333TwXJBLN0YrrrjNqkEdpZJ62Fw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="inline" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/85a30da5-4e3c-430c-89ad-8dfc79a52fae/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK5PFusDuPVgxicowruU9vhC4yjYqAUibHQgaezA6HtyR12a5MYAR3OTKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.423148148148148" data-s="300,640" data-type="png" data-w="1080" type="inline" data-backw="266" data-backh="379" data-imgfileid="503529339" data-aistatus="1" data-original-style="width:100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fe9ba6ab-00f3-4815-b7bc-2d6eb7a63135/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;上次那杯咖啡，再来一杯；之前买的那本书，再来一本，AI 都会自动完成整套需求映射。&lt;/sup&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="576" data-backw="266" data-imgfileid="503529340" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKe8OgMMqash7icFwV993nA938jttcoYfb1swSn7eTWawaU2DtIrqBsEg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-type="jpeg" data-w="1080" type="inline" data-original-style="width:100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/2f44965f-e50d-4411-8d2d-c63ab7da0ab3/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKc9sXekN8cvoxq5lichs4iciaiavgJv0qNHQIZibG6zsGiawP6t50oZgN3Sdw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.7046296296296297" data-s="300,640" data-type="png" data-w="1080" type="inline" data-backw="266" data-backh="454" data-imgfileid="503529342" data-aistatus="1" data-original-style="width:100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2a9a0c13-2b97-44d6-a49d-9c4bfd037b3a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 还能通过自然语言修改订单。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;但如果只强调慢思考，产品同样会走向另一种极端。&lt;/p&gt;&lt;p&gt;更多时候，用户其实处在&lt;strong&gt;快思考&lt;/strong&gt;&lt;strong&gt;状态&lt;/strong&gt;：目标清楚，只是想逛一逛，通过图片和简单对比，迅速做出判断。比如，想买支口红，但不知道「选哪一款」。这种情况下，关键不在于「把问题想清楚」，而是「如何更快搞定」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「爱购」承担的，正是这一侧的「快思考」需求。&lt;/strong&gt;因此，在产品形态上，它依然沿用了熟悉的双列信息流，但底层逻辑，已经换了一套。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="285" data-backw="578" data-imgfileid="503529343" data-ratio="0.4925925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKUJUZicPlxiaxJU4X4XeENRFibXcNRG0iaoTebSwI1EOa6MTRwasUz60Qicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" type="block" data-original-style="width:381px;height:188px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/e583dc5a-d35c-4335-8962-20e6446e6d45/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;传统电商平台里，当你搜索「口红」， 系统会召回尽可能多的相关商品，再按销量、价格、评分等维度排好队，交给你自己去翻。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="1181" data-backw="578" data-imgfileid="503529346" data-ratio="2.0435185185185185" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKs8kMwxyKC4ugUg4FEbibH0o5UoqJA6jRAeHpWyW3eEBqicDZpHaSzXSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="1080" type="block" data-original-style="width:177px;height:362px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/8676519a-e403-40dc-a8e4-73c01044ac35/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 京东主站搜索结果的呈现。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但「爱购」 不会把海量口红一次性铺开，它更像一位循循善诱的导购。一方面提供必要的「入门指引」，另一方面替你搭起一套清晰的「选购框架」。&lt;/p&gt;&lt;p&gt;例如，口红会被先拆解成几个方向：哑光雾面、滋润镜面、偏修护。当你点进「哑光雾面」，选择再进一步细化到质地、是否易脱色、适合肤质、品牌以及具体色系。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f2d343fb-4f07-43b1-a240-ea3b0ef2b174/1768990288390.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span align="" alt="" border="" data-aiimageid="" data-aiimagesource="" data-aistatus="1" data-asynid="" data-backh="" data-backw="" data-before-oversubscription-url="" data-cacheurl="" data-cardimg="" data-copyright="" data-croporisrc="" data-cropselx1="" data-cropselx2="" data-cropsely1="" data-cropsely2="" data-cropx1="" data-cropx2="" data-cropy1="" data-cropy2="" data-fileid="" data-fromlib="" data-galleryid="" data-gallerysupplier="" data-height="" data-imgfileid="503529379" data-imgid="" data-imgqrcoded="" data-oversubscription-url="" data-positionback="" data-ratio="2.1574074074074074" data-remoteid="" data-retry="" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKdkgkLZ2Y8OScbmaicPHHv06WtUj87jcpIuBaLJTndh90WSDd4VUIJhA/640?wx_fmt=gif&amp;from=appmsg" data-type="gif" data-upload="" data-w="216" data-width="" height="" ismap="" sizes="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKdkgkLZ2Y8OScbmaicPHHv06WtUj87jcpIuBaLJTndh90WSDd4VUIJhA/640?wx_fmt=gif&amp;from=appmsg" title="" type="block" usemap="" width=""&gt;&lt;sup&gt;原本需要用户自己总结的筛选维度，被&lt;/sup&gt;&lt;/span&gt;&lt;em&gt;&lt;sup&gt;AI预先摆在了面前，供你边看边点、边问边筛。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;每一次交互，都会让候选范围再收紧一圈，整个过程像一个不断收口的漏斗，最后「过滤」出最可能被你选中的一小撮。&lt;/p&gt;&lt;p&gt;正是在「一快」、「一慢」无感切换中，「京东 AI 购」最重要的创新渐渐显露&amp;mdash;&amp;mdash;&lt;strong&gt;同一套架构，兼容「快思考」与「慢思考」&lt;/strong&gt;。这并非概念噱头，而是源自对真实购物行为的长期观察，毕竟，没有谁会永远用同一种方式做决定。&lt;/p&gt;&lt;p&gt;通过将京东积累多年的供应链、履约和服务能力，重新组织进一套更贴近人类决策方式的交互逻辑中，「京东 AI 购」试图「兜住」这两种状态。&lt;/p&gt;&lt;p&gt;正是在这里，这个看起来「很不电商」的京东 App，开始真正与旧世界拉开距离。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如影随形的「对话框」：&lt;/strong&gt;&lt;strong&gt;一次低调却关键的交互转向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说，「对快与慢思考的兼容」构成了「京东 AI 购」内核，那么，真正让这种服务「常驻」的，是一个看起来并不起眼的设计：那个始终留在页面底部、几乎和你「形影不离」的对话框。&lt;/p&gt;&lt;p&gt;它的位置甚至有些执拗。无论你是在和 AI 聊天，还是已经点进商品详情页，它都没有消失。它并不提醒你使用，也不主动跳出来打断流程，只是安静地待在那里，等待被召唤。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="731" data-backw="338" data-imgfileid="503529350" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLqNn9ONcmA1YTbLc0GbusHAOR8XLpDE6CwUmkiaU04mQibMQ7RvhGepg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="width:182px;height:394px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c7734e51-3abd-4aa8-ace8-f368f855df56/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 已经点进商品详情页，对话框都没有消失，而是停在页面下方。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这个设计，源于一个被长期忽视的事实：购物中的疑问，并不会在搜索结束的那一刻消失。当用户真正进入商品详情页，决策成本并未降低，甚至可能进一步上升。&lt;/p&gt;&lt;p&gt;传统的商详页，越来越像一幅绵延长卷：营销图片层层堆叠，参数表绵延不绝，用户评论如同瀑布般倾泻而下。信息已足够完备，但当用户搜索关心的卖点时，比如「面料成分」、「羊绒含量」，却如大海捞针。&lt;/p&gt;&lt;p&gt;现在，这个始终留在页面底部的「对话框」，悄然接管了那些「看不完、看不懂、也不想看」的决策成本。&lt;/p&gt;&lt;p&gt;用户不再需要硬着头皮翻阅漫长的图文，随口说出你关心的问题，AI 便会从漫长「卷轴」中定位答案，整理好后，递到面前。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="1251" data-backw="578" data-imgfileid="503529329" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK1CbuBnup4StEgzkMj53B2sXic9JPPwEAXQrdhDj5ZYINxZjzosHQTnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" type="block" data-original-style="width:192px;height:415px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/28f1840f-ae11-413b-9378-0ec820d886bf/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;也正是在这一刻，你能切实感到技术没有被「炫」，而是真正嵌入生活服务的关键节点。&lt;/p&gt;&lt;p&gt;但这个看似轻巧的设计，并非一蹴而就，而是经历了一段不断推翻重来的过程。&lt;/p&gt;&lt;p&gt;最初，「京东 AI 购」的商详页，几乎直接移植了京东手机网页版。结果，用户一进入购买流程，仿佛被瞬间「踢回」十年前的传统电商界面，AI 好不容易营造出的沉浸感立刻被打断。这种强烈的割裂感，很快让团队自己都无法接受。&lt;/p&gt;&lt;p&gt;于是，他们选择彻底重构链路。但与此同时，京东主站最核心的底层能力又必须被完整保留。换句话说，当你点下「立即购买」的那一刻，后台需要瞬间接管。交易、支付、风控、物流，这套沉淀了数十年的系统必须无缝衔接、稳定运行，容不得半点闪失。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="576" data-backw="266" data-imgfileid="503529351" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLqNn9ONcmA1YTbLc0GbusHAOR8XLpDE6CwUmkiaU04mQibMQ7RvhGepg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-type="png" data-w="1080" type="inline" data-original-style="width:100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/11aa1020-70bb-46a2-b030-2eea58f3513f/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK92MSkh4Zsm4awiakhclmvUP9KjehShndlrFnMdJNiaYsLHLjTf9koX7g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=15" data-ratio="2.1638888888888888" data-s="300,640" data-type="jpeg" data-w="1080" type="inline" data-backw="266" data-backh="576" data-imgfileid="503529349" data-aistatus="1" data-original-style="width:100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/eda954fb-4a83-453b-a559-2483dc46af37/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;商品页面也做了减法（左图），还有PK功能，对话框保留在底部。它没有复刻主站那种信息密集的设计（右图）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;真正决定把对话框「焊」在商品页底部的转折点，来自一个被反复观察到的心理事实：用户对 AI 的依赖，并不会在进入商品页时减弱，反而会因为参数复杂、信息密集而变得更强。传统商详页越像层层堆叠的「信息仓库」，用户就越容易陷入搜索与决策泥潭。&lt;/p&gt;&lt;p&gt;于是，「对话框」被赋予新的使命：替你读图、刷评论、抓重点，不再「问完即走」，而是随时待命：只要你还有犹豫，它就在那里。&lt;/p&gt;&lt;p&gt;而这仍然不是终点。产品负责人透露，团队接下来希望把这种理解能力进一步推向「生成式商详」。原本冰冷的参数表和评论区，将被重新组织为「千人千面」的动态答案：你关心优惠，它就把价格逻辑讲清楚；你在意参数，它就直接给出对比结论。&lt;/p&gt;&lt;p&gt;这一过程中，电商的交互逻辑也正在发生根本转向，从过去用户去适应页面，逐渐演进为页面主动适应用户。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;购物里的分寸：一场取与舍的练习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一家以效率、规模著称的电商巨头，却做了一个如此克制、安静的产品，还让它独立出来，怎么看，都是一场激进的尝试。&lt;/p&gt;&lt;p&gt;但放进真实的产品演进过程中，它反而更像一件被有心「按住」的作品：不是 AI 能做什么就一股脑地做什么，而是不断试探什么时候让 AI 大步流星、哪些地方必须保持敬畏。&lt;/p&gt;&lt;p&gt;这种分寸感，让它避开了炫技式的跃进，更像一个被设计为长期存在的产品：接受不完美，拒绝过度承诺，慢慢生长。&lt;/p&gt;&lt;p&gt;「大胆」与「克制」的切换，始终围绕着用户需求。产品团队告诉我们，所有向前一步的决定，都必须回答这个需求是否真实、迫切。&lt;/p&gt;&lt;p&gt;商详页面的设计如此，外卖与酒旅的生态接入也是如此。乍看之下，这些生活服务像是边界外扩，实则顺应了真实生活逻辑。现实生活中，人们并不会严格区分「这是购物 App 的事」、「那是生活服务 App 的事」。他们只关心，现在这个问题，能不能被更聪明地解决。&lt;/p&gt;&lt;p&gt;同样的判断，也体现在低客单价、强复购的场景中。「买不买」不是问题，真正消耗心力的，是那些机械重复却并不产生新价值的步骤。AI 的主动介入，本质上是对低效劳动的「清算」。&lt;/p&gt;&lt;p&gt;将 PK 能力单独「拎出来」，无非是将大多数用户购物时的必经之路显性化，并不是增加复杂度，而是替他消化低效劳动。&lt;/p&gt;&lt;p&gt;AI 大步流星的同时，即便身处对话式 AI 的浪潮，服务流程也并未全盘「 AI 化」。&lt;/p&gt;&lt;p&gt;搜索、咨询、决策阶段，可以是对话式的。一旦进入下单环节，交易体验必须和原生京东 App 保持一致，结算、地址与履约阶段，系统必须切回京东主站底层。&lt;/p&gt;&lt;p&gt;这种对「原生链路」的保留，本质上是对交易确定性的敬畏。产品团队解释说，当用户进入下单环节，他们需要的是熟悉感带来的安全感，而非 AI 创造的「惊喜」。&lt;/p&gt;&lt;p&gt;同样被有意剔除的，还有「内容化」的冲动。长篇种草、新闻播报、数字人展示&amp;mdash;&amp;mdash;这些本可以用来彰显技术能力的功能，最终都被放弃。过载的内容会稀释产品的纯度，也会模糊核心心智。用户来到这里，是为了在信息洪流中快速做出决策，而非陷入另一场需要消化的信息冗余。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「独立」的背后：一次主动「偏航」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果把时间尺度拉长，回看电商二十多年的演进路径，这场貌似主动的「偏航」，其实并不突兀。&lt;/p&gt;&lt;p&gt;京东几乎完整经历了&amp;nbsp;PC&amp;nbsp;时代、移动互联网时代，再到今天的每一个关键阶段。早期，电商解决的是供给问题，有没有货。接着是效率问题，能不能更快、更便宜地把货送到人面前。当供给极大丰富、履约成熟、价格高度透明之后，真正开始变得稀缺的，反而是&lt;strong&gt;决策本身&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;用户不再缺选项，缺的是判断；不再缺信息，缺的是「替我想一想」，「京东AI 购」更像是下一阶段的自然延伸：当平台已经足够擅长「把东西卖出去」，下一步就要回到人的决策上。&lt;/p&gt;&lt;p&gt;而在 2025 年，无论从技术进展还是用户心智变化来看，这件事都具备了现实可行性。&lt;/p&gt;&lt;p&gt;在技术层面，ReAct、多 Agent 等架构逐渐成熟，AI 开始具备被纳入决策、履约链条的条件，而不再局限于聊天。用户心智也在变化。「你帮我选」，不再只是信息过载下的被动妥协，而开始成为一种真实、甚至被主动期待的需求。&lt;/p&gt;&lt;p&gt;但即便如此，另一个问题仍然存在：为什么不直接把这套能力塞进主站 App？为什么要让用户多下一个软件？答案，还是要回到主站本身。&lt;/p&gt;&lt;p&gt;主站也有丰富的 AI 应用，但传统电商 App 天然背负着明确的 GMV 目标，也承载着高度复杂、密集的促销与转化逻辑。在这样的体系中，几乎不可能进行一场彻底的「减法」实验。而独立 App，提供了一块相对纯净的试验空间。&lt;/p&gt;&lt;p&gt;它更像一个先锋验证场，目标并不是短期的转化效率，而是验证一种新的用户心智模型：当电商从「货架」转向「代理人」，产品究竟应该长成什么样？这个问题，很难在主战场上被从容回答。&lt;/p&gt;&lt;p&gt;但是，独立并不意味着另起炉灶，更不是与主站「互搏」。前台交互是新的，但后台能力依然共用。供应链、交易系统、支付、履约、风控，全部来自京东已经成熟运转的基础设施。&lt;/p&gt;&lt;p&gt;如果一定要做一个比喻，主站更像一座稳定运行的「超级超市」，而 AI 购，更接近一间探索未来形态的「概念旗舰店」。它不承担规模化的压力，被允许试错、调整和打磨。&lt;/p&gt;&lt;p&gt;从这个意义上看，「独立」不是目的，而是为下一代电商形态，预留的一条试飞跑道。&lt;/p&gt;&lt;p&gt;在理解人类那些尚未成形的需求、拆解规模庞大而结构复杂的商品世界、以及捕捉不断变化的生活情境方面，这只举着魔法棒的小狗，才刚刚起步。它当然谈不上成熟，也远未完美，但它所指向的方向，却异常笃定，值得手机为它预留一方天地，让未来发生。&lt;/p&gt;&lt;p&gt;此刻，距离大年三十还有 20 多天。也许，你可以从一件再日常不过的小事开始：对它说出你的马年心愿。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>非Transformer架构的新突破，液态神经网络的推理小模型只用900M内存</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 18:02:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜冷猫&lt;/section&gt;&lt;p&gt;谷歌 2017 年提出的 Transformer 架构事实上已经基本垄断了大模型。&lt;/p&gt;&lt;p&gt;不采用 Transformer 架构的大模型已经是少之又少，而采用非 Transformer 架构，还能与主流第一梯队大模型扳手腕的，更是凤毛麟角。&lt;/p&gt;&lt;p&gt;不知道大家是否还有印象，当年有一个尝试&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650936710&amp;idx=1&amp;sn=dbbd17956166684cee4eb73e75e41111&amp;scene=21#wechat_redirect" target="_blank"&gt;给大模型装上「虫脑」&lt;/a&gt;的初创公司，他们的研究人员受到秀丽隐杆线虫的神经结构启发，研发出一种新型的灵活神经网络，也被称为液态神经网络。&lt;/p&gt;&lt;p&gt;这是一个连续时间模型，由多个简单的动态系统组成，这些系统通过非线性门相互调节。这种网络的特点是时间常数可变，输出通过求解微分方程得到。它在稳定性、表达能力和时间序列预测方面都优于传统模型。&lt;/p&gt;&lt;p&gt;除此以外，液态神经网络的另一个特点是规模小得多，在 2024 年该架构就实现了 1.3B 大小的模型部署，但彼时尚未能与主流大模型一拼高下。&lt;/p&gt;&lt;p&gt;提出液态神经网络架构，并且做出 Liquid Foundation Models（LFM）大模型的，是由 MIT 计算机科学和人工智能实验室 CSAIL 孵化，成立于 2023 年 3 月的初创公司 Liquid AI。&lt;/p&gt;&lt;p&gt;就在刚刚，Liquid AI 又一次在 LFM 模型上放大招。他们&lt;strong&gt;正式发布并开源了 LFM2.5-1.2B-Thinking，一款可完全在端侧运行的推理模型&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="530" data-imgfileid="503529358" data-ratio="0.45555555555555555" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKSFMicjhbqKfic9e7qSGbKRnichml5FxAujRzQYPIeMmdJtbt1VpcCYVTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1164" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8624f5ba-fea2-4758-8c9f-54af2bc1b0be/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Liquid AI 声称，该模型专门为简洁推理而训练；在生成最终答案前，会先生成内部思考轨迹；在端侧级别的低延迟条件下，实现系统化的问题求解；在工具使用、数学推理和指令遵循方面表现尤为出色。&lt;/p&gt;&lt;p&gt;该模型在手机上&lt;strong&gt;仅需 900 MB 内存&lt;/strong&gt; 即可运行，同时在同等规模模型中实现了最快的推理速度和最佳的质量表现。两年前还必须依赖数据中心才能完成的能力，如今已经可以在你的口袋里离线运行。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKt16y1f4bm1YVbsf8drCg3gAAlyDSCfQG1DPW5mGibEPKPnd4zg6NCsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.39198218262806234" data-type="png" data-w="898" data-width="898" data-height="352" data-imgfileid="503529359" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a3055c94-f916-4d38-9016-5fe370f21d44/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Leap 开源链接：https://leap.liquid.ai/models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace 链接：https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;优于 Transformer 的性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与 Liquid AI 之前的模型 LFM2.5-1.2B-Instruct 相比，LFM2.5-1.2B-Thinking 在三项能力上实现了显著提升：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数学推理&lt;/strong&gt;：在 MATH-500 上从 63 提升至 88&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;指令遵循&lt;/strong&gt;：在 Multi-IF 上从 61 提升至 69&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工具使用&lt;/strong&gt;：在 BFCLv3 上从 49 提升至 57&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在大多数推理基准测试中，LFM2.5-1.2B-Thinking 的表现已与甚至超过 Qwen3-1.7B，尽管其参数量少了 约 40%。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKYx3MymNrJwkuicibsASD4dDABSRaqoLeiacAibXTZJNzPYic3Xf4BbQjKbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7037037037037037" data-type="png" data-w="1080" data-width="1896" data-height="1334" data-imgfileid="503529360" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d82ef211-575f-41dc-a190-e2d3108fdce2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKvapL2VTsMOUFmQ0qCic5ibazboRMKtWxZlfbRky0Aiaib5Iicr7uHx142FQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5814814814814815" data-type="png" data-w="1080" data-width="1550" data-height="902" data-imgfileid="503529361" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e4bb71c8-b328-4f0b-9d08-2931b73c9b10/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时，该模型在质量与测试时计算效率之间取得了良好平衡：与 Qwen3-1.7B（思考模式） 相比，它在使用更少输出 token 的情况下，依然提供了更高的整体性能。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKy9xY8cBw0SSuVbe6Lu7WMTP3qHUnDR89HNplacMxHULlVt32E4CcGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.42685185185185187" data-type="png" data-w="1080" data-width="2844" data-height="1215" data-imgfileid="503529362" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/bca0075c-60bd-492a-98f6-30d573ec0708/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在推理阶段，这一性能差距进一步拉大：LFM2.5-1.2B-Thinking 在推理速度和内存效率两方面，都&lt;strong&gt;优于纯 Transformer 模型&lt;/strong&gt;（如 Qwen3-1.7B）&lt;strong&gt;和混合架构模型&lt;/strong&gt;（如 Granite-4.0-H-1B）。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK3JKPebJia17Dk4v1Zvlu2OzC5ibgd1Sd6T21ribykLIfwBZ3WhxlbNnSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7037037037037037" data-type="png" data-w="1080" data-width="2844" data-height="2001" data-imgfileid="503529363" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/01f0b7db-24b9-44fe-a420-f83f219ada0b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Liquid AI 表示，LFM2.5-1.2B-Thinking 在 智能体式（agentic）任务和高推理强度任务（例如工具使用、数学、编程）中表现尤为突出。当模型需要规划一系列工具调用、验证中间结果并动态调整解题策略时，其生成的推理轨迹能够发挥实际价值。而在对话交互和创意写作等场景下，则更推荐使用 LFM2.5-1.2B-Instruct。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练细节&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要构建能力强的小型推理模型，关键在于：在知识容量有限的前提下，通过&lt;strong&gt;多步推理&lt;/strong&gt;来弥补能力，同时又要保持答案简洁，以满足端侧低延迟部署的需求。&lt;/p&gt;&lt;p&gt;此前在 LFM-1B-Math 上的实验表明，在中期训练阶段引入推理轨迹，有助于模型内化「先推理，再作答」的模式。随后，基于合成推理轨迹进行的监督微调（SFT），进一步让模型能够稳定地产生思维链，而无需依赖特定格式的奖励设计。&lt;/p&gt;&lt;p&gt;然而，SFT 并不能解决推理模型中的一个常见问题：模型可能陷入重复文本模式，迟迟无法得出结论。这种行为通常被称为 &lt;strong&gt;「doom looping」（死循环式生成）&lt;/strong&gt;。为此，Liquid AI 采用了一种相对直接的缓解方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;在偏好对齐阶段&lt;/strong&gt;，基于 SFT 模型生成了 5 个温度采样候选和 1 个贪婪解码候选；当不存在循环时，选择由 LLM 评判得分最高的作为正样本、得分最低的作为负样本；一旦出现循环生成，则无论评判得分如何，直接将出现循环的候选作为负样本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;在 RLVR 阶段&lt;/strong&gt;，进一步在训练早期引入了基于 n-gram 的重复惩罚，以抑制循环生成行为。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过这些策略，模型在保持推理能力的同时，显著降低了陷入无效循环的风险。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKoH09l6mtb83qxD95HOycNFI7su0fNuPSmYFuWFfCV3ROdJpL2AAEww/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.10740740740740741" data-type="png" data-w="1080" data-width="1588" data-height="170" data-imgfileid="503529364" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/0f2311a0-f539-473c-afe5-557e2ab666b3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这一方法在一个具有代表性提示词的数据集上，将死循环生成的比例从 15.74%（中期训练阶段） 显著降低到了 0.36%（RLVR 阶段），效果非常直接且稳定。&lt;/p&gt;&lt;p&gt;Liquid AI 的 RL 训练流水线核心采用的是无 critic、类 GRPO 方法。整体实现是 reference-free 的，并结合了多项训练技巧，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;非对称比例裁剪（asymmetric ratio clipping）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对零方差提示组的动态过滤&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;超长样本掩码（overlong-sample masking）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不进行优势归一化（no advantage normalization）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;截断的重要性采样（truncated importance sampling）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKah3e3e0GKhUu1sozol7yqOxjEA4ROaD2VlFvkQwTT5SdFMf4am5n2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="2880" data-height="1620" data-imgfileid="503529365" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/124a6906-ca93-41e0-ae80-f5fa6b509ff5/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;RL 方法的简化示意图：最终发布的 checkpoint 是一个合并模型，其「家族树」中包含 25 个不同的子 checkpoint。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Liquid AI 采用了一种高度并行的 &lt;strong&gt;Curriculum RL 训练框架&lt;/strong&gt;，先以指令跟随的 RLVR 作为基础起点，再分叉出面向推理、数学、工具使用等不同领域的专项 checkpoint。&lt;/p&gt;&lt;p&gt;这种并行结构不同于传统的「单模型、多任务同时训练」方式，往往会引发能力相互干扰。&lt;/p&gt;&lt;p&gt;Curriculum RL 提供了更精细的控制粒度：每个领域的模型都可以独立优化，拥有各自的奖励设计、超参数和评估标准。随后，我们在不同阶段进行迭代式模型合并，生成在多种能力之间更均衡的新 checkpoint。&lt;/p&gt;&lt;p&gt;实践表明，模型合并在保留整体性能的同时，能够有效吸收专项能力提升，是一条可行且可扩展的通用 RLVR 训练路径。&lt;/p&gt;&lt;p&gt;此外，&lt;strong&gt;Liquid AI 正在全力拓展 LFM 系列模型的生态系统和合作伙伴&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;LFM2.5-1.2B-Thinking 实现了开箱即用支持，兼容最流行的推理框架，包括 llama.cpp、MLX、vLLM 和 ONNX Runtime。所有框架均支持 CPU 和 GPU 加速，覆盖 Apple、AMD、Qualcomm 和 Nvidia 等硬件。&lt;/p&gt;&lt;p&gt;为了确保 LFM2.5 系列 能够在各种场景下高效运行，Liquid AI 正在快速扩展软硬件生态系统，并欢迎 Qualcomm Technologies, Inc.、Ollama、FastFlowLM 和 Cactus Compute 作为新的合作伙伴加入。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKz8mKzyHt4afV881mEsVLxab8EG2lbnddiahY1ic3NWazu5HpjtpvpkIw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6074074074074074" data-type="png" data-w="1080" data-width="1600" data-height="972" data-imgfileid="503529366" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/dd559534-53e2-4102-a370-6e9038647e98/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; LFM2.5-1.2B-Thinking 在不同硬件设备上的长上下文推理表现。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;LFM2.5-1.2B-Thinking 可能只是个起点，但它已经证明了一件事 &amp;mdash;&amp;mdash;Transformer 并非唯一解，小而强的端侧推理模型或许有更优解。&lt;/p&gt;&lt;p&gt;更重要的是，运行推理模型的门槛越来越低，让更多设备激发 AI 潜能，不论如何，都是一件美事。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://www.liquid.ai/blog/lfm2-5-1-2b-thinking-on-device-reasoning-under-1gb#training-recipe&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AI for Science开年新突破：中科大实现多尺度结构逆向设计128倍加速，登上Nature子刊</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 17:58:19 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/7dd70bb5-d2d3-42b7-b94f-27fa80e1e3a3/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近日，&lt;strong&gt;中国科学技术大学（USTC）联合新疆师范大学、中关村人工智能研究院、香港理工大学&lt;/strong&gt;，在&lt;strong&gt;数据驱动的多功能双连通多尺度结构逆向设计领域&lt;/strong&gt;取得重要突破。相关成果于 2026 年 1 月 8 日以 &lt;strong&gt;&amp;ldquo;Data-driven Inverse Design of Multifunctional Bicontinuous Multiscale Structures&amp;rdquo; &lt;/strong&gt;为题，发表于 Nature 旗下顶级综合期刊 &lt;strong&gt;Nature Communications&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;该研究首次系统性解决了双连通多尺度结构长期存在的&lt;strong&gt; &amp;ldquo;难描述、难设计、难制造&amp;rdquo;&lt;/strong&gt; 核心瓶颈，为&lt;strong&gt;骨植入物、渗透器件、力学隐身结构等复杂工程系统&lt;/strong&gt;的智能化设计提供了全新的数据驱动范式。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529139" data-ratio="0.5916666666666667" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0hFZtuNiaqL4LaV1voZsPT8VGicp9wcUG57XLh9M8vTD00b9s0OpG1G4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/24452c5e-714e-4f14-8870-21396adfaac7/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://www.nature.com/articles/s41467-025-68089-2&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据链接：https://drive.google.com/drive/folders/1VnNVyjxKFQPCH_YchG52gRw1zEXKMr2J&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源链接：https://github.com/llwang91/L-BOM/&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;向自然学习：破解双连通多尺度结构设计的关键难题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在自然界中，双连通多尺度结构并不罕见。以松质骨为例，其内部由固体相与孔隙 / 流体相相互贯通，形成高度互联的三维网络，使结构在保持轻量化的同时兼具优异的力学性能与渗透能力。然而，在工程设计中复现这类 &amp;ldquo;自然结构&amp;rdquo; 并不容易：一方面，缺乏可解析的数学模型，使得传统建模与逆向设计方法难以直接应用；另一方面，多尺度三维结构的联合优化计算量随规模呈指数级增长，连通性难以统一约束，成为制约工程应用的核心难题。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Wau1oOEdoQu1ibvQNJB2S4BNWqyNQb81EK9IoKSibHOcSwoibIkDHK0Hw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4842592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528892" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/35055cf7-b435-492f-b49e-ffb7a2c6d378/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1 数据驱动的多功能双连通多尺度结构设计的动机、挑战与工作流程。a 松质骨；b 双连通开孔结构；c 边界连接性；d 通过拓扑优化（Opt.）与主动学习（AL）构建的 L-BOM 数据集，其边界 / 掩膜为相同的 &amp;ldquo;X&amp;rdquo; 形，右侧为松质骨的多尺度逆向 设计过程。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键突破：一个简单而深刻的结构原理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对上述难题，研究团队提出了一个简单却具有高度普适性的核心原理：只要多尺度结构中每一个微结构单元同时具备双连通性、开孔特征，并共享完全一致的边界条件，无论其如何组合，整体结构都能够天然保持双连通性。基于这一原理，团队首次构建了大规模三维数据集 &lt;strong&gt;L-BOM（Large-range, Boundary-identical, Bicontinuous Open-cell Microstructure）&lt;/strong&gt;。在统一边界条件约束下，L-BOM 数据集不仅实现了双连通微结构的无缝拼接，还覆盖了跨数量级的性能空间，并天然满足制造与结构连接约束，从而从根本上绕开了对解析建模的依赖，为多尺度结构的高效逆向设计奠定了坚实的数据基础。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14SfIRab85ia0DkGaYt5FG2tJcbib4ZPQwCcbzzHgXWALoP9abxAicunTzg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.087037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528894" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/452c10ff-9890-40b5-aa0c-d1dc1ac99ec5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2 在四种不同边界（Mask 1&amp;ndash;4）条件下的 L-BOM 数据集示意图。 a&amp;ndash;c 为第一种边界条件（Mask 1）的构建流程： a 基于 Mask 1 通过优化生成的初始数据集（21,620 个微结构）； b 主动学习（AL）框架； c 经过主动学习后的掩膜 1 最终数据集（106,445 个微结构）。 d&amp;ndash;f 为其余三种边界（Mask 2&amp;ndash;4）的初始与最终 L-BOM 数据集。 蓝色箭头表示多轮主动学习过程。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多尺度逆向设计闭环：效率提升 128 倍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在多尺度逆向设计闭环中，研究团队以股骨植入物为代表性案例，采用 &amp;ldquo;自上而下&amp;rdquo; 的多尺度逆向设计流程，实现了结构性能与生物特征的高度协同匹配。设计结果在多个关键指标上与天然骨组织高度一致：在杨氏模量、孔径和孔隙率等参数上实现精准匹配，并在刚度、渗透性与轻量化之间取得了更优平衡；在结构形态上，自然形成兼具致密骨板状特征与松质骨桁架状特征的多尺度复合结构。&lt;/p&gt;&lt;p&gt;与 IWP、BCC 桁架及旋节线等经典结构设计方法相比，该方法无需后期插值或额外拼接处理，整体计算效率显著提升，且所生成结构在形态与层级特征上更接近真实骨组织，体现出显著的设计优势。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wW05bwrBKljD7aKuoXcGsA3zc86Cr54qWX3raFHiaiajXssciaPSclOLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.362037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528895" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/224875ad-11ee-4e85-ab8c-6a17604a7674/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3 致密骨与松质骨植入物的多尺度设计。a 初始配置及优化结果；b 多尺度结构的匹配、组装与求交过程；c 本研究结果（I）与三种典型结构：IWP（II）、BCC truss（III）以及旋节线结构（IV）的对比；d 展示了本研究的优化结果与 IWP、BCC truss、旋节线结构在松质骨设计中的计算时间（T/s）、杨氏模量（E/MPa）及平均孔径（APS/&amp;mu;m）的比较。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;特别是在力学隐身斗篷等大规模、高复杂度任务中，该多尺度逆向设计闭环将原本 10 小时以上的计算时间压缩至不足 5 分钟，实现了 128 倍的效率提升。更重要的是，随着结构分辨率和问题规模的持续增大，这一效率优势不仅没有衰减，反而进一步放大，展现出优异的可扩展性与规模化潜力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0QRiaWc49Mjcj6pbW4AnmmA7D3ibKoHEIwWbpcdIFPgibWqDCHE5GY9ribg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.36944444444444446" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529140" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/8d2ee133-ff38-4a65-877a-a2589724f2e0/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4 机械斗篷（20 &amp;times; 20 &amp;times; 20 单元）逆向设计结果。右侧展示了优化过程的迭代曲线，以及用于填充隐身体的微结构的性能分布。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;128 倍并非终点，而是多尺度结构设计走向规模化应用的起点。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可调渗透结构：从仿真到实验高度一致&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队还设计并制造了 &lt;strong&gt;4&amp;times;4&amp;times;1 双连通多尺度过滤结构&lt;/strong&gt;，并对其流体性能进行了系统验证。结果表明，基于 L-BOM 数据集构建的结构在渗透率和比表面积（S/V）等关键指标上显著优于传统 TPMS 结构（如 Gyroid、Diamond 和 IWP）。同时，数值计算、仿真分析与实验测量结果高度一致，在高孔隙率样品中，实测流速与数值预测几乎完全重合，验证了该方法在保持整体双连通性的同时，能够实现对流体通道结构的精确调控，显示出在过滤与流体调控器件中的应用潜力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD143tRpKELRwgicORib48YCpWgC7PFysG8h1j9UEibwb0eporLcKUADwUKKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.224074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528897" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/69dae91d-b2cc-434a-9e41-31739e88356e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5 过滤装置的多尺度结构设计。a 过滤装置的初始设置（4&amp;times;4&amp;times;1 个单元）；b 比较了 Mask 2 数据集中的微结构与三种 TPMS 结构（Gyroid、Diamond 和 IWP）在孔隙率 (1&amp;minus;V)、比表面积 (S/V) 和渗透率方面的差异；d 在孔隙率为 0.8 的条件下，对比了所设计结构与 Gyroid、Diamond 和 IWP 结构的性能，并展示了各自的流体仿真结果；e 对六种结构（IWP、Diamond、Gyroid 以及优化后的多尺度设计 M16、M19、M20）进行了渗透率实验验证。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;研究意义：为 AI 设计复杂结构打开新范式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该研究提出了双连通多尺度结构的可组合设计原理，首次构建了覆盖大范围性能空间、具备统一边界条件且可实现无缝拼接的四个&lt;strong&gt;三维双连通开孔结构数据集&lt;/strong&gt;，并将生成式人工智能方法真正引入到具备工程可制造性的结构逆向设计中。同时，研究在力学与流体等多个物理场景下完成了数值计算与实验测量的双重验证。基于上述方法，可广泛应用于定制化骨植入物、力学隐身与超材料、渗透与过滤器件以及多物理场协同结构设计等领域，为多功能结构材料的智能逆向设计奠定了重要的技术基础。&lt;/p&gt;&lt;p&gt;中科大计算几何小组研究团队负责人表示：&amp;ldquo;作为长期深耕计算几何与计算机图形学的研究团队，我们将继续探索基础理论、核心算法与前沿应用的交叉融合，推动几何计算方法在复杂形状建模、仿真分析与智能设计等方向的持续突破。面向未来，团队将持续深入超材料这一前沿探索领域，围绕多尺度结构表征、性能预测与可制造约束下的智能优化等关键问题开展系统研究，形成可复用的设计理论与工具链。与此同时，我们也将积极推动相关成果在先进制造、航空航天、机器人与能源等场景落地，加速从算法创新到工程应用的转化，为产业升级与社会发展创造更大价值。&amp;rdquo;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>告别「手动画框」！Medical SAM3：首个真正「纯文本提示」驱动的医学全能分割模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Wed, 21 Jan 2026 14:19:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;现有的通用医学分割模型往往只是「伪全能」，因为它们在没有人工提示框辅助时几乎寸步难行。&lt;/p&gt;&lt;p&gt;来自中佛罗里达大学（UCF), 宾夕法尼亚大学(UPenn), &amp;nbsp;伦敦大学学院（UCL）等机构的研究团队&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-top: 16px;margin-bottom: 0px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;近日&lt;/span&gt;发布了Medical SAM3，通过全参数微调与创新的分层训练策略，在 33 个医学数据集上实现了革命性突破：它不再需要医生手动画框，仅凭一句分割「肿瘤」的文本指令，即可在 CT、MRI、内镜等 10 种模态中实现专家级分割，将零样本场景下的平均准确率从 11.9% 暴涨至 73.9%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjfjh2wWpQWTMtuctniaqyY76UdojbTkI5YhAG9fUSyia9nyPvia5QkQxAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027204" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8e96ae43-e201-4041-a963-159cc1dfb73b/640.png" alt="图片" data-before-load-time="1768976276624" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接:&amp;nbsp;https://arxiv.org/abs/2601.10880&lt;/p&gt;&lt;p&gt;代码仓库:&amp;nbsp;https://github.com/AIM-Research-Lab/Medical-SAM3&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjN8jt9ic66V7fefK8NSUyAYWDJKdJc202dhN14W6iaewibDh4tjSiaM7qaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027210" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b727a955-0c72-484c-91b4-8cb6552fb4ac/640.png" alt="图片" data-before-load-time="1768976276657" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;核心痛点：以前的「通用模型」真的通用吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Medical SAM3 之前，许多「医学通用分割模型」在实际使用上存在一个关键前提：它们往往高度依赖空间提示（Spatial Prompts）&amp;mdash;&amp;mdash; 需要人工先提供 Bounding Box（边界框）或点击关键点，模型再在提示区域内完成分割。表面上看这只是交互方式的选择，但它也反映出能力边界：当模型必须先由人把目标「圈出来」，其主要贡献更接近于区域内的像素细化与边界优化，而非从整幅图像中完成稳定的语义定位与目标发现。&lt;/p&gt;&lt;p&gt;这种设定在演示场景中可以获得不错的效果，但在真实工作流里会带来明显的推广门槛：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;医生并不总能提前精确圈定病灶，尤其是边界模糊、形态复杂或早期难判的病例；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在筛查、急诊分诊或跨模态阅片等高通量场景下，逐张图像画框 / 点选会显著增加交互成本，难以规模化；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更重要的是，模型性能会对提示质量产生强依赖，系统的核心难题 &amp;mdash;&amp;mdash;「自动语义定位」&amp;mdash;&amp;mdash; 并未被真正解决。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;论文中的诊断性实验进一步量化了这一现象：当移除人工空间提示、仅通过文本询问（更接近「通用」的使用方式）时，原生 SAM3 在医学图像上的表现出现断崖式下降，平均 Dice 降至 11.9%，并在内镜息肉分割等任务中出现 0.0% 的失效案例。这说明模型在很大程度上把空间提示当作了近似「目标索引」；一旦失去该索引，它在复杂背景、低对比度、强噪声或形态多变的医学影像中就难以稳定定位目标。&lt;/p&gt;&lt;p&gt;因此，Medical SAM3 的核心贡献并非把分数再提高一点，而是试图跨过这条关键门槛：将医学分割从「提示驱动的区域细化」，推进到「仅凭文本即可触发的语义驱动分割」，让模型不再依赖人工先验的空间圈定。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjmCqgRUGxLicUcSSEtWCA7rnTyTTbsneQq7yKOKiaARWrompdMHnnUfpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027206" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/828fcd29-a534-4d5c-8627-50e5307eef2c/640.png" alt="图片" data-before-load-time="1768976276882" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;真正的「语义驱动」：不仅是微调，更是重塑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决医学影像「语义难对齐、结构极复杂、模态差异巨大」这一核心难题，Medical SAM3 没有走业界常见的轻量级适配器（Adapter/LoRA）捷径，而是选择了一条更艰难但也更彻底的路线 &amp;mdash;&amp;mdash; 全参数微调（Full Fine-Tuning）。团队的判断很明确：医学影像与自然图像之间不仅是外观风格的变化，更是成像物理、噪声统计、目标形态与语义体系的整体迁移；仅微调少量参数往往只能「学到一点风格」，却难以让模型真正理解医学场景中那些决定分割成败的细粒度概念（例如模糊边界、低对比病灶、细长结构的连通性、器官之间的解剖约束）。因此，Medical SAM3 通过全参数更新，让模型从底层特征到高层语义都能发生充分适配，从而实现更可靠的「语义驱动分割」。&lt;/p&gt;&lt;p&gt;但全参数微调带来的挑战同样显著：一旦训练策略不当，模型可能会遗忘原有的通用视觉能力，或在训练早期出现不稳定震荡。为此，Medical SAM3 引入了分层学习率衰减（Layer-wise Learning Rate Decay, LLRD）策略，以一种「既保守又激进」的方式精细控制迁移过程：浅层网络使用更小的学习率，尽可能保留通用的边缘、纹理与局部对比特征（这些对所有影像都有效）；而深层网络则使用更大的学习率，获得更强的可塑性，专门去学习医学影像中特有的语义与结构规律，例如「毛玻璃影」的弥散分布、内镜息肉与背景黏膜的微妙边界、视网膜血管的树状拓扑与连续走向。最终，这种「浅层稳住通用视觉、深层重塑医学语义」的迁移范式，推动模型完成了根本性跃迁：从过去高度依赖点 / 框等几何提示的交互式分割，转变为仅凭文本语义即可稳定分割的通用能力。&lt;/p&gt;&lt;p&gt;Medical SAM3 的强大并非只来自训练策略，更来自其构建的大规模、多模态训练底座。研究团队整合了覆盖 10 种成像模态的 33 个数据集，并通过统一的数据标准化与接口设计，使模型能够在 76,956 张高分辨率医学图像与 263,705 个精细掩膜上进行系统学习。尤其关键的是，Medical SAM3 采用了统一的 2D 高分辨率视角（Unified 2D Formulation）：无论输入来自 3D CT/MRI 的切片，还是 2D 的眼底、内镜或显微图像，均被统一处理为 1008&amp;times;1008 的高分辨率表示。这一设计带来两点直接收益：其一，它在工程上打通不同设备与模态的输入壁垒，降低跨域部署的不确定性；其二，它让模型获得更强的尺度一致性与细节表达能力 &amp;mdash;&amp;mdash; 从胸片中占据大面积的肺部轮廓，到电子显微镜下仅数十像素的细胞核边界，模型都能在同一框架下捕捉关键结构，形成真正「跨模态、跨尺度、跨任务」的统一分割能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjRhyic7Du3qb3xPSpzDib1IfmzhBTvRrIUPcCF506ibIic4c1waXHdA5naw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3888888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027208" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/db27f8aa-c2b7-434e-bb33-2c9cafb087f0/640.png" alt="图片" data-before-load-time="1768976276972" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;从内部精通到外部泛化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了系统验证模型的可靠性与可迁移性，团队构建了覆盖内部验证（in-domain）与外部测试（out-of-domain）的全面评估体系：前者检验模型在已覆盖医学分布上的稳定性与细节还原能力，后者则以「从未见过的数据集与模态」为压力测试，衡量其真实世界部署最关键的零样本泛化表现。&lt;/p&gt;&lt;p&gt;在内部验证环节，Medical SAM3 展现出对医学结构与边界细节的扎实掌握，平均 Dice 从 54.0% 提升至 77.0%。这一提升不仅意味着「更像」，更代表模型在像素级边界对齐、细小目标召回、低对比度组织分离等方面达到了更可靠的水平。尤其在视网膜血管分割这类典型「高难任务」中，原生模型常见问题是对细长结构缺乏连续性建模，容易出现断裂、漏检与噪点粘连；Medical SAM3 则显著改善了这一失败模式，将 Dice 从 24.8% 提升至 55.8%。更重要的是，提升并非只体现在分数上：模型不仅能「找到血管」，还能够更好地复原血管的连续走向、分叉拓扑与树状结构，这类结构完整性对后续临床分析（如血管密度、分支形态、病变区域关系）尤为关键。&lt;/p&gt;&lt;p&gt;在更为严苛的外部验证环节（测试从未见过的数据集），模型进一步体现出强大的零样本泛化能力。面对 7 个全新的外部数据集，Medical SAM3 将平均 Dice 从 11.9% 提升至 73.9%，IoU 从 8.0% 提升至 64.4%。这组结果的意义在于：外部测试通常伴随显著的分布偏移 &amp;mdash;&amp;mdash; 例如不同医院设备、采集协议、分辨率、噪声形态、病灶外观与标注风格差异 &amp;mdash;&amp;mdash; 许多模型在此类场景下会出现「性能断崖」。而 Medical SAM3 的提升幅度显示，它并非依赖某一类固定模态或固定提示形式，而是学习到了更通用的医学语义与结构先验。&lt;/p&gt;&lt;p&gt;更具说服力的是，在部分极端案例中表现出现了从「无法工作」到「可用级别」的质变：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;内镜息肉分割（CVC-Clinic）：原生模型由于难以从复杂背景中理解「息肉」这一语义目标，Dice 仅 0.0%；Medical SAM3 则达到 87.9%，说明模型能够在反光、粘液、纹理干扰等情况下仍保持对目标语义的稳定聚焦。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;超声胎头测量（HC18）：超声天然存在斑点噪声、边界模糊与组织对比度弱的问题，原生模型 Dice 为 23.9%；Medical SAM3 提升至 92.6%，体现其对低信噪比模态下轮廓结构的鲁棒提取能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ETIS-Larib：同样从 0.0% 跃升至 86.1%，进一步表明模型在外部域中不只是「略有改善」，而是显著降低了原生模型的完全失效概率。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综合内部与外部结果可以得出一个关键结论：Medical SAM3 能够在不依赖人工提示框辅助的情况下，仅通过文本提示驱动分割，在多模态、多数据分布下保持稳定表现。这意味着模型不仅「能分割」，更具备面向真实临床场景的核心能力：当标注成本高、交互提示受限或需要快速批量处理时，它仍能依靠医学语义理解与结构先验，提供一致、可复用、可迁移的分割输出。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl461a77WrUjribOxGDnshEjuq6IVw2KaoMICRkuu6OHG2Xo1iacP2n01IFnToSDJvib9baotwC21CLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.0307328605200945" data-s="300,640" data-type="png" data-w="846" type="block" data-imgfileid="100027209" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/89f216e5-8d16-410b-9e4f-d36d611fba27/640.png" alt="图片" data-before-load-time="1768976277190" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;未来展望：规模化与智能化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管目前的性能已经取得了显著进展，Medical SAM3 团队并未止步。为了进一步提升模型的实用性与智能水平，后续工作将主要集中在以下两个方向：&lt;/p&gt;&lt;p&gt;1. 数据规模与覆盖扩展： 团队计划持续扩充训练语料库，引入更丰富的分割数据，以增强跨域鲁棒性。同时重点补齐临床中的「长尾空白」，例如罕见病灶、小样本亚型、低资源模态以及更复杂的标注形态（多器官、多病灶、细长结构等）。通过更大规模、更多样化的数据「喂养」，进一步降低模型在真实世界场景中遇到分布偏移时的失效概率，让「给一个术语就能稳定分割」更接近可部署的可靠标准。&lt;/p&gt;&lt;p&gt;2. 迈向 Medical SAM3 Agent： 团队的目标不止于做一个分割模型，而是构建面向临床工作流的 Medical SAM3 Agent。通过集成大语言模型（LLMs），系统将具备更强的任务理解、步骤化推理与交互协作能力：例如把医生的自然语言需求拆解为可执行的分割子任务（目标、范围、优先级），在结果不确定时主动发起澄清提问，并把分割结果进一步组织为可读的结构化输出（位置、大小、数量、随访对比等），从而成为医生在阅片、测量与报告生成中的真正智能伙伴。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Medical SAM3 的出现标志着医学 AI 助手从「交互式工具」向「语义智能体」的进化。它不再要求医生充当「画框工」，而是模拟了临床专家的认知过程 &amp;mdash;&amp;mdash; 先理解诊断术语，再主动在图像中搜索病灶。通过建立临床概念与像素级特征之间的直接映射，Medical SAM3 为未来「即插即用」的自动化医疗辅助系统奠定了坚实的基础。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>推翻150年数学直觉：数学家烧坏几台笔记本，解决几何拓扑难题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 13:21:31 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;这是一次数学理论与计算机算力结合的胜利。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKiaWzye7Ly1qrQI4OQWNE85rF3e708FMMWEt9sPuV5hcLZE4IEZgvobQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503529370" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2e7c9054-d778-4b37-bb26-6ab865a9f110/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;设想一下，如果我们的天空总是被一层厚厚的不透明云层所遮蔽，既看不见星星，也无法从上方俯瞰我们的星球，我们还能发现地球是圆的吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答案是肯定的。&lt;/strong&gt;通过测量地面上特定的距离和角度，我们就能确定地球是一个球体，而不是平面或者甜甜圈状。即使没有卫星照片也能做到。&lt;/p&gt;&lt;p&gt;数学家们发现，这种情况在更普遍的二维曲面中也经常成立：&lt;strong&gt;只需要曲面上相对少量的局部信息，就足以推断出其整体形态，也就是由局部唯一确定整体。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;然而在某些例外情况下，这些有限的局部信息可能对应着不止一种曲面。在过去的 150 年里，数学家们一直在致力于整理这些特例：&lt;strong&gt;即那些通常只能定义一种曲面，实际上却描述了多种曲面的局部测量数据。&lt;/strong&gt;但他们能找到的唯一例外并不是像球体或甜甜圈那样规整、封闭的曲面。相反，这些曲面要么向某个方向无限延伸，要么拥有某种「边缘」。&lt;/p&gt;&lt;p&gt;没有人能找到一个打破这一规律的封闭曲面，似乎根本就不存在这样的特例。也许，这类曲面总是可以通过常规的局部信息被唯一确定。&lt;/p&gt;&lt;p&gt;如今，数学家们终于发现了一个寻觅已久的特例。在去年 10 月发表的一篇论文中，三位研究人员，包括柏林工业大学的 Alexander Bobenko、慕尼黑工业大学的 Tim Hoffmann 以及北卡罗来纳州立大学的 Andrew Sageman-Furnas，&lt;strong&gt;描述了一对非常扭曲的封闭曲面，它们虽然拥有相同的局部信息，却具有完全不同的全局结构。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKHkex309GvmZIavCnQiaSv3a2Eh9kV3G4lTxStfRc627qIfj9Je2ia0Zw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5148148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529372" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/dc34ab4c-e982-4fd8-a611-6ddebfd202e3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Compact Bonnet pairs: isometric tori with the same curvatures&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://link.springer.com/article/10.1007/s10240-025-00159-z&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一发现耗费了该团队数年的辛劳、几台因运算过热的笔记本电脑，以及一个来自几何学看似无关领域的意外线索。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;几何学中的异类&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数学家们有各种各样的方法来局部地描述一个曲面，但其中两种尤为有用。&lt;/p&gt;&lt;p&gt;其中&lt;strong&gt;一种方法捕捉的是关于曲面「外在」曲率的信息&lt;/strong&gt;，即在曲面上任选一点，你可以沿着无限多的方向计算曲面在空间中的弯曲程度，也就是所谓的曲率。只关注那些能得到最大和最小曲率值的方向，然后取这两个值的平均数，得到的数值被称为「平均曲率」。你可以计算曲面上任意给定点的平均曲率，从而更好地理解它是如何置于周围空间之中的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;另一种测量方法捕捉的是关于曲面「内蕴」曲率的信息&lt;/strong&gt;，这是一种不依赖于曲面所在外部空间的几何属性。试想一张平整的纸，你可以把它卷成圆柱管而不必拉伸或撕裂它。如果纸上两点之间由一条曲线连接，那么这条曲线在圆柱上的长度将保持不变。这意味着这张纸和圆柱体拥有相同的「度量」，即距离的概念。&lt;/p&gt;&lt;p&gt;但如果你试着把这张纸包在球体上，情况就不再是这样了。你不得不拉伸、剪开或弄皱这张纸，点与点之间的曲线长度也会随之改变。因此，这两个曲面拥有不同的度量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKaj8ib2eGZEEI4eGLKasKbmWxXGDBTkdYlXTV4CXAVcyEt95iaHGKu9Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.1462962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529374" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/04e4a12e-d4fc-4442-afb8-d88afd0c74de/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;1867 年，法国数学家 Pierre Ossian Bonnet 证明，如果你知道一个曲面上每一点的度量和平均曲率，通常就足以确定该曲面的形态。当然，只是「通常」。但「通常」并不代表「总是」，正是这种不确定性让数学家们心痒难耐。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKAUR6RDVicReticUM5qO4PnX5sKsV3KftzmZagztMRWxhlMbKqyHGuXwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.260185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529375" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/11d0e6c9-064f-4575-b356-67c63df2279b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Pierre Ossian Bonnet&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 Bonnet 提出证明后的 150 年间，数学家们发现了各种违背这一规律的曲面。这些曲面拥有相同的度量和平均曲率，却不具备相同的全局结构。&lt;/p&gt;&lt;p&gt;但所有这些曲面都属于数学家口中的「非紧致」曲面。它们不像球体、甜甜圈以及其他「紧致」曲面那样能够完美地闭合。相反，非紧致曲面可能向某个方向无限延伸（如平面或圆柱面），或者拥有突然中断的边缘（如同从一个更大的形状上裁下来的一块）。&lt;/p&gt;&lt;p&gt;紧致曲面受到的限制则更多，它们必须满足各种约束条件，才能自身回转并完美闭合。因此，认为它们或许能被其度量和平均曲率唯一确定，似乎是合乎情理的推测。&lt;/p&gt;&lt;p&gt;1981 年，数学家 Blaine Lawson 和 Renato de Azevedo Tribuzy 证明，对于球体及任何与其拓扑等价的曲面，即任何没有孔洞的紧致曲面。这一推测确实成立。&lt;/p&gt;&lt;p&gt;而当涉及到带有一个孔洞的紧致曲面（即拓扑学上的「环面」，类似于甜甜圈）时，情况多了一点回旋余地。数学家们证明，&lt;strong&gt;给定的度量和平均曲率最多只能对应两个不同的环面&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;然而，从来没有人找到过这种「紧致 Bonnet 对」的实例。因此在几十年间，&lt;strong&gt;学界普遍认为环面与球体一样，给定的度量和平均曲率只能定义唯一的环面&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;「很长一段时间里人们都对此深信不疑，」杜克大学的 Robert Bryant 说道，「因为他们造不出任何反例。」&lt;/p&gt;&lt;p&gt;但是，他们错了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;像素化的世界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去 20 年里，Alexander Bobenko 一直在啃那些「数学甜甜圈」。21 世纪初，他曾试图证明紧致 Bonnet 对确实存在。但当他意识到这个问题绝非几个月就能解决时，便将其暂时搁置，转而专注于他认为能更快取得进展的问题。&lt;/p&gt;&lt;p&gt;他转向了一个看似与 Bonnet 问题毫不相干的数学领域，但这恰恰成了最终解开谜题的关键。&lt;/p&gt;&lt;p&gt;Bobenko 开始思考「离散」曲面，这有点像是光滑曲面经过像素化处理后的低分辨率版本。数学家之所以研究离散曲面，是因为它们不仅本身具有重要的几何性质，而且在计算机科学、物理学、工程学等领域也有着广泛的实际应用。&lt;/p&gt;&lt;p&gt;要构建一个离散曲面，需要选取有限数量的点，并用线段将它们连接起来，形成一个由平面构成的形状。通过选择不同的点，可以用不同的方式来表示同一个光滑曲面。例如，下面就是几种表示球体的方式：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK19xHpLApa7KqPVJUNcJ3FoyrxXNN5FyfiarEI0cNs3Aic6PmRnQOWCbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3527777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529376" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a0185904-1b50-4473-abb4-bcac0f24a07b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;有些离散曲面能比其他的更好地进行表征。近二十年来，Bobenko 和他的长期合作伙伴 Tim Hoffmann 一直致力于建立一套理论，旨在利用离散曲面尽可能保留光滑曲面最显著的几何特征。&lt;/p&gt;&lt;p&gt;2010 年代，当时还是哥廷根大学博士生的 Andrew Sageman-Furnas 加入了这项工作，并将 Bonnet 问题重新带回了讨论之中。&lt;/p&gt;&lt;p&gt;Sageman-Furnas 对渔网等编织材料的力学机制很感兴趣，这些材料本质上就是离散曲面，这也吸引他进入了离散数学领域。在此过程中，他提出了 Bonnet 问题的一个离散版本：&lt;strong&gt;局部信息在什么情况下能唯一确定一个离散曲面，又在什么情况下不能？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过调整一种已知的生成 Bonnet 定理反例的方法，Sageman-Furnas 与他的导师 Max Wardetzky 以及 Hoffmann 一起，&lt;strong&gt;找到了一套在离散情形下构造反例的「配方」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;与光滑情形一样，这些反例也总是非紧致的。但由于离散曲面并不包含无限多个点，因此利用计算机对其进行研究是可行的。Sageman-Furnas 不禁设想，&lt;strong&gt;是否可能利用计算机的「暴力求解」法，在离散几何的世界里找到一对紧致 Bonnet 对？&lt;/strong&gt;如果确实如此，那么离散情形或许也能为解决光滑情形下的问题指明方向。&lt;/p&gt;&lt;p&gt;于是，他作为 Bobenko 研究组的博士后研究员来到柏林，加入了 Bobenko 和 Hoffmann 的行列，并着手开展工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;曲面探寻之旅&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2018 年春，&lt;strong&gt;Sageman-Furnas 开始通过计算机搜寻一种特殊的曲面，这种曲面可以被转化为一个 Bonnet 对&lt;/strong&gt;，就像是用「老面」作为基底能烘焙出各种不同的面包一样。这个作为「引子」的曲面，类似于他读研期间用来构建离散 Bonnet 对的那些曲面。但这一次，他要求它必须是一个环面。也就是说，它必须是紧致的，且带有一个或多个孔洞。&lt;/p&gt;&lt;p&gt;Hoffmann 回忆称，Sageman-Furnas 消失了数周，甚至可能数月。当这位年轻的数学家终于再次现身时，他找到了他一直在寻觅的东西：一个长满尖刺的形状，与其说像环面，倒不如说更像是一只折纸犀牛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKGk2ZuGziagQZzHsR7UJIUvs6rQhcsmCeKRVrCqgFthcUpgVCBauub1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.8099352051835853" data-s="300,640" data-type="png" data-w="926" type="block" data-imgfileid="503529378" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/73f4427d-219c-4a96-a717-ab6a6f06f4a7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 「犀牛」。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但它确实是一个环面。根据 Sageman-Furnas 的计算机程序，它具备生成 Bonnet 对所需的所有其他属性。更重要的是，当 Sageman-Furnas 在计算机上生成这些 Bonnet 对时，它们也都是环面。从犀牛形状到 Bonnet 对的变换似乎并没有将犀牛形状扭曲成非紧致曲面。这些曲面始终保持紧致。&lt;/p&gt;&lt;p&gt;「当你开始进行计算探索和设计时，」Sageman-Furnas 说道，「你可以得到一些远超出你想象的新例子。」&lt;/p&gt;&lt;p&gt;但这会不会好得令人难以置信？计算机程序会产生舍入误差：Sageman-Furnas 的犀牛形状可能看起来符合所需的标准，它生成的 Bonnet 对也可能看起来是环面，但这都可能只是假象，是微小计算误差造成的假象。如果没有严格的证明，数学家们无法确定。&lt;/p&gt;&lt;p&gt;「他来了，给我们展示了一些看起来很奇怪的几何物体，看起来很像是数值计算产生的垃圾，」Bonnet 说。「开玩笑地说，我对整个项目最宝贵的贡献可能就是当时我说了一句：『我见过更糟糕的。』」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKm9ZibXJAJkQMEMwMlulbibT6QywvG7Uj0S0lZNRZq0XC9ABOt0jaqztQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529380" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6a8696bd-fae3-4ce1-867a-0ed58b6b35c0/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;Andrew Sageman-Furnas（左）、Tim Hoffmann（中）和 Alexander Bobenko（右）构建了一对新的形状，从而解决了一个长期存在的猜想。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;虽然花了一些时间，但 Hoffmann 和 Sageman-Furnas 最终确信这个「犀牛」形状值得认真研究。如果能够找到这样一个离散的 Bonnet 对的例子，那么光滑曲面的情况或许也并非毫无希望。Hoffmann 和 Sageman-Furnas 在那个夏天里仔细研究这个犀牛形状，寻找线索，有时一次视频通话就长达八到十二个小时，寻找可能有助于他们缩小光滑 Bonnet 环面搜索范围的特殊性质和几何约束。&lt;/p&gt;&lt;p&gt;到了九月，他们终于找到了一个非常有希望的新线索，这让 Bobenko 重新投入到他几十年前放弃的这个问题中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;闭合环路&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;线索与沿着犀牛边缘环绕的特定线条有关。&lt;/p&gt;&lt;p&gt;这些线条已知可以提供关于犀牛曲率的重要信息 &amp;mdash;&amp;mdash; 描绘出它弯曲和折叠程度最大和最小的方向。由于犀牛是一个存在于三维空间中的二维表面，数学家们原本预计这些线条也会在三维空间中勾勒出路径。但实际上，它们总是位于平面或球面上。这些排列如此巧合的可能性微乎其微。&lt;/p&gt;&lt;p&gt;「这让我们觉得一定有什么特别的事情正在发生，」Sageman-Furnas 说道。这太不可思议了。&lt;/p&gt;&lt;p&gt;与离散表面不同，光滑表面没有边缘。但你仍然可以绘制「曲率线」，描绘出最大和最小弯曲的路径。Sageman-Furnas、Bobenko 和 Hoffmann 决定寻找一个光滑的犀牛类比物，其曲率线同样被限制在平面或球面上。也许一个具有这些特性的初始表面可以产生光滑的 Bonnet 环面。&lt;/p&gt;&lt;p&gt;但这样的表面是否存在尚不清楚。&lt;/p&gt;&lt;p&gt;然后博本科意识到，一个多世纪前，法国数学家让・加斯顿・达布就几乎已经提出了数学家们现在需要的东西。&lt;/p&gt;&lt;p&gt;达布提出了生成具有正确曲率线的表面的公式。问题是，他的公式无法生成闭合的曲率线。相反，它们「看起来像螺旋线，并延伸到无穷远，」Bobenko 说。「不可能让它们闭合。」这意味着虽然曲率线可能位于平面和球面上，但整个表面不会是环面。&lt;/p&gt;&lt;p&gt;经过多年的努力，数学家们 &amp;mdash;&amp;mdash; 结合使用纸笔和计算实验 &amp;mdash;&amp;mdash; 终于找到了如何调整达布的公式，使曲率线闭合。他们终于找到了光滑的犀牛类比物，尽管两者看起来并不太相似。&lt;/p&gt;&lt;p&gt;此外，正如他们所希望的那样，这个光滑的犀牛可以生成一对新的环面，它们具有相同的平均曲率和度量数据，但整体结构不同。该团队最终找到了 Bonnet 问题的答案：某些环面最终无法通过其局部特征唯一确定。但是，当他们弄清楚这对 Bonnet 曲面究竟长什么样时，他们发现这两个环面互为镜像。「从技术上讲，这不成问题，」Sageman-Furnas 说道。「从形式上讲，它解决了问题。」但他补充说，这仍然令人不满意。&lt;/p&gt;&lt;p&gt;因此，在接下来的一年里，他们尝试以各种方式调整他们的光滑犀牛曲面。最终，他们意识到，如果放弃其中一组曲率线必须位于球面上的要求，他们就可以构建一个新的光滑犀牛曲面，从而达到他们的目的。然后，他们利用这个曲面生成了一对新的 Bonnet 曲面 &amp;mdash;&amp;mdash; 这一次，是两个非常扭曲的环面，它们显然是不同的曲面，但仍然具有相同的度量和平均曲率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK2Pj78qBQHgWsMWebrW85GEbG2zPHrgeicaw8VxXgLjLHMW8kFfeMzGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529381" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/2c4764d6-c5e7-4295-b63b-9a1066d34678/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该团队最终找到了紧凑型 Bonnet 曲面的一对实例。&lt;/p&gt;&lt;p&gt;这一结果令 UMass Amherst（马萨诸塞大学阿默斯特分校）的数学家 Rob Kusner 感到惊讶。他表示，这表明即使是环面 &amp;mdash;&amp;mdash; 一些最美观、研究最透彻的曲面 &amp;mdash;&amp;mdash; 也并非总能用其局部特征完美描述。&lt;/p&gt;&lt;p&gt;「这是一个我们的直觉不够用的例子，」杜克大学的数学家 Bryant 说道。&lt;/p&gt;&lt;p&gt;不过，数学家们发现的这两个环面有点奇怪：它们像数字「8」一样自身相交。Bobenko 现在希望证明存在不与自身相交的 Bonnet 环面。&lt;/p&gt;&lt;p&gt;Bonnet 环面的发现是对 Bobenko 和 Hoffmann 数十年来在离散曲面研究方面工作的有力验证。传统上，光滑形状的几何学发展速度更快，而离散几何学的理论发展相对滞后。但在这项工作中，离散理论取得了突破性进展，并最终促成了光滑曲面方面的进展。&lt;/p&gt;&lt;p&gt;Hoffmann 认为，这突出表明：虽然离散曲面看起来像是其光滑对应物的简化模型，但它们拥有自身的数学生命。离散世界可以像光滑世界一样丰富，甚至更加丰富，揭示出一些可能被忽略的额外对称性和联系。&lt;/p&gt;&lt;p&gt;「人们似乎忘记了离散方面的研究，」Hoffmann 说道。「但我们仍然可以从中有所收获。」&lt;/p&gt;&lt;p&gt;&lt;sup&gt;原文链接：https://www.quantamagazine.org/two-twisty-shapes-resolve-a-centuries-old-topology-puzzle-20260120/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AI5芯片搞定，马斯克的纯自研超算Dojo 3又回来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 13:15:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜晓楠、冷猫&lt;/section&gt;&lt;p&gt;刚刚，马斯克丢了个重磅炸弹：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「AI5 芯片设计进展顺利，特斯拉将重启 Dojo3 的工作。」&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="782" data-imgfileid="503528989" data-ratio="0.6648148148148149" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ09CeKw4GwgmJ2kllhKkhibHV4f2AmVKKnp1CIx6SIjGUG3ocKtmCTKeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1176" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7ad01776-b1ef-458e-b8f9-0706d42613e8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;简单两句话，包含了特别大的信息量。&lt;/p&gt;&lt;p&gt;Dojo 项目是在 2021 年特斯拉 AI Day 首次提出，定位是「面向机器学习训练的超级计算机」，目的是处理来自特斯拉汽车的视频录制和其他数据，并利用这些数据来训练公司全自动驾驶软件背后的「神经网络」。&lt;/p&gt;&lt;p&gt;在 2021 年的 CVPR 大会上，时任特斯拉人工智能高级总监的 Andrej Karpathy 曾表示，仅凭视觉技术，计算机必须以与人类相同的速度和敏锐度对新环境做出反应。然而，这需要利用强大的超级计算机，基于海量数据集对人工智能进行训练。而特斯拉就拥有这样一台超级计算机，即 Dojo。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0tFIuH9CiamoB7tYfRtVicPP694WibDyBgNmicY6usM4y4kF47kctQubNcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5148148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528990" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d6b11f2a-aa09-4fdc-b12a-e0de12a4ae08/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2023 年 7 月，Dojo 正式投产。彼时，马斯克对 Dojo 项目充满了期待。&lt;/p&gt;&lt;p&gt;但不知大家还记不记得，去年 8 月，马斯克突然&lt;strong&gt;「全面叫停」Dojo 项目，暂时解散专门的 Dojo 团队&lt;/strong&gt;，项目负责人 Peter Bannon 离职，约 20 名核心成员也跳槽成立新公司 DensityAI。&lt;/p&gt;&lt;p&gt;当时，特斯拉实际上在同时推进两套完全不同的芯片体系：用于车载系统和机器人的芯片，以及用于大规模 AI 训练的芯片。&lt;/p&gt;&lt;p&gt;事实证明，这样的双线推进效率并不高。马斯克必须做些取舍，于是决定暂停 Dojo 项目工作，来将全部资源投入到最具战略意义的 AI5 芯片上。&amp;nbsp;&lt;/p&gt;&lt;p&gt;彼时，外界听到这一消息，很多人都认为 Dojo 项目是一次失败，甚至认为马斯克已经放弃了该项目。但现在看来事实并非如此。&lt;/p&gt;&lt;p&gt;当时马斯克在 X 上发文解释：「对于特斯拉来说，分散资源并扩展两种截然不同的 AI 芯片设计是没有意义的。特斯拉的 AI5、AI6 及后续芯片在推理方面将非常出色，至少在训练方面也会相当不错。所有努力都集中在这一点上。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0wK2N9lXAlUJibWh43d3AyQCr5GEQD6tfGhCYU7qkJdibmocD6Lq6UJ0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6046296296296296" data-type="png" data-w="1080" data-width="1188" data-height="718" data-imgfileid="503528991" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3c8da690-44bf-4799-8750-484fff7ea095/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;AI5 是一颗高度关键的芯片，FSD、Cybercab、Optimus 等核心项目都要依赖它。在 2025 年下半年，马斯克非常明确地表示：&lt;strong&gt;AI5 还远未达到预期&lt;/strong&gt;。如果 AI5 失败，特斯拉未来的自动驾驶和自主系统，很可能都会受到「致命影响」。&lt;/p&gt;&lt;p&gt;马斯克很坦诚地说过：&lt;strong&gt;「解决 AI5 对特斯拉来说是生死攸关的&lt;/strong&gt;，这就是为什么我必须将两个团队都集中在这个芯片上，并且我个人在几个月的时间里每个周六都投入工作。」&lt;/p&gt;&lt;p&gt;特斯拉去年在 X 上表示，AI5 芯片可能比 AI4 芯片有高出 50 倍的提升，目标在 2027 年投入生产。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0ARI6CGmiaTBzgwzkgYkyxJficMWJRwgSj5hXHiazExvtbBVn4lBK05lng/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6611111111111111" data-type="png" data-w="1080" data-width="1170" data-height="774" data-imgfileid="503528993" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a89a1c65-aa4c-4a47-82f6-1410a05ce34b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0F25qpoYd3KVaW4vLrYt3NdicwicekmNiaQc8lBjSMAncibtMxuz7yVYK4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528994" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/af51a90d-d4ae-4749-bec5-60efd93f0839/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其实如果仔细回想，去年马斯克在公开解释 Dojo 项目被「叫停」的原因后，还谈到：「在一套超级计算机集群中，无论是用于推理还是训练，把大量 AI5 / AI6 芯片集成到同一块板卡上都是很合理的做法 &amp;mdash;&amp;mdash; 这样可以将网络布线的复杂度和成本直接降低好几个数量级。某种意义上，这大概就可以被称作 Dojo 3 了。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0VUoqyIQe1vAevftU4EKx19q2XPRm0oiaG5P5zyY0mIwyQ7a2YUQdC4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.49166666666666664" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528995" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5092501f-76ee-48f1-b202-49561e2ad873/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而如今，「Dojo3」项目意在将 512 颗 AI5 或 AI6 芯片密集集成于单块主板，形成超级计算机集群。原来，当时马斯克早已暗示了这一点，由此看来，Dojo 项目从来就没有真正停止，只不过是公司整体在路线优先权上的让步行为。现在，一切进展都在计划中，所以，「Dojo3」又回来了。&lt;/p&gt;&lt;p&gt;马斯克表示，「进展顺利」的 AI5 芯片的单颗 SoC 大致相当于 Hopper 级别，双颗则相当于 Blackwell 级别，但成本极低，功耗更低。&lt;/p&gt;&lt;p&gt;而 Dojo3 摒弃了前两代 Dojo 依赖自研 D1 芯片及晶圆级封装的复杂路径，核心在于架构重构与成本优化，从特斯拉战略规划来看，Dojo 3 采用了基于 AI5 和 AI6 芯片的统一架构，使单颗芯片能够同时处理训练和推理任务。&lt;/p&gt;&lt;p&gt;而这种设计能将网络布线复杂性与硬件成本降低数个数量级，同时保留大规模并行计算能力，这或许是特斯拉想要摆脱对英伟达 GPU 依赖，追求自研芯片垂直整合的战略。&lt;/p&gt;&lt;p&gt;与此同时，Dojo 3 提供的强大也将加速特斯拉 FSD 端到端神经网络模型迭代，同时为 Optimus 人形机器人的运动控制、环境感知模型训练提供算力支撑。&lt;/p&gt;&lt;p&gt;这对特斯拉而言绝对是一大利好，并且特斯拉将利用 AI5 芯片的潜能，不再将车载芯片与大规模 AI 算力芯片分开研究设计，而能够使用同一套芯片解决全部问题，&lt;strong&gt;从训练、推理到车辆和机器人，端到端自建完整算力体系&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这也说明了马斯克称这些芯片将成为「全球出货量最高的芯片」，AI5 或将被装进数百万辆汽车、机器人，并同时成为支撑背后训练系统的芯片。&lt;/p&gt;&lt;p&gt;据了解，目前特斯拉已经与三星电子签署了一项价值 165 亿美元的 AI6 芯片生产协议，这将为 Dojo 3 的规模化提供有力支撑。&lt;/p&gt;&lt;p&gt;当然了，马斯克毕竟是一个经常满嘴跑火车的人。&lt;/p&gt;&lt;p&gt;曾经马斯克表示 Dojo3 将是「基于太空的人工智能计算」，因为他和其他人认为相比地面上越建越大的数据中心，把算力搬到轨道上，反而可能是更优解。其想法是太空更容易获取太阳能，那里的低温可能会大大减少所需的电力等等。但他的说法完全属于推测，甚至有一些幻想色彩，专家们对此表示怀疑。&lt;/p&gt;&lt;p&gt;至于这条路究竟会把特斯拉带向哪里，能否达到马斯克的预期，Dojo 3 才刚刚走到起点，答案还得留给时间。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/news/864164/back-to-the-dojo&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.engadget.com/ai/musk-claims-tesla-will-restart-work-on-its-dojo-supercomputer-173127863.html&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/mubeitech/status/2013304716931768596&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/elonmusk/status/2013034224828215706?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>R1一周年，DeepSeek Model 1悄然现身</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 10:22:55 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜Panda&amp;nbsp;&lt;/p&gt;&lt;p&gt;2025 年 1 月 20 日，DeepSeek（深度求索）正式发布了 DeepSeek-R1 模型，并由此开启了新的开源 LLM 时代。在 Hugging Face 刚刚发布的《「DeepSeek 时刻」一周年记》博客中，DeepSeek-R1 也是该平台上获赞最多的模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKWE4M4nP9fpb6GdMDEh7NacCvvickycjL2S3DcwfOeXu7Toz6ArPibofA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.75" data-s="300,640" data-type="png" data-w="1024" type="block" data-imgfileid="503529284" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/0abd4c2c-0ca8-431e-8ab0-d1fc518c706f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如今，刚过一年时间，DeepSeek 的新模型又在 GitHub 悄然现身。&lt;/p&gt;&lt;p&gt;这些天，DeepSeek 给其 FlashMLA 代码库推送了不少更新，而在这些更新中，一个名为 &lt;strong&gt;Model1&lt;/strong&gt; 的模型引起了广大网友的注意。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKIjPCtboAudnkSK2R9jArS4DsDzNeGtYpOkWykGkDIuhnKNDnle3GZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.47962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529285" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d85a8470-e993-440c-9843-4b03712b99c5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如下截图所示，这个目前还很神秘的 Model1 不仅出现在了代码与注释中，甚至还有与 DeepSeek-V3.2 并驾齐驱的文件。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKjLH3mz4ibNL4kz40LIJK2h6uuMNeDPicF5wib9lNjAib6AicXV7t2j51pHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3490136570561457" data-s="300,640" data-type="png" data-w="659" type="block" data-imgfileid="503529283" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a18b1baa-9d3e-4e82-bece-2aa9eb2bee23/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKbicmibeqltdz3ib8u7iaNZAmyjibC2U5JUqibnPcD6enwwKL80cvfSpzyCng/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.2537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529286" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/42d30602-c7a7-4fcb-80af-e02b0faa45b5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLB9QiarHIJ3dGwV2ribGHrT43LITrfwJIFEe6QJzyugzliayaPibYzDDGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529287" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/12fa4325-a864-4310-baeb-7fac95f29c6e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKo2mNVVmITicCqsOQt0pekVteCfzuTHoGpI6esHf71O87m1auJQvSVOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21574074074074073" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529288" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/7830e8e4-fdd1-4608-a2dd-8f20e284c98f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这也不禁让网友们开始猜测，这个 Model1 很可能就是传闻中 DeepSeek 即将在春节前后发布的新模型的代号。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKbttKGKiaicon7ffMDrjeAALz4MPqISfcP4l6ia3ycvdXbtfbgjjTYkicFg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3496932515337423" data-s="300,640" data-type="png" data-w="489" type="block" data-imgfileid="503529289" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/bdc96e74-da55-4f61-a19e-a6d21f1b1899/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKbyCXxe7rOrlWH6SWLvIPtmKTno9tVf2oKicpd5K30yet7oUP4I89O3g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6599496221662469" data-s="300,640" data-type="png" data-w="794" type="block" data-imgfileid="503529290" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/262c0edb-3aa0-443d-8721-719ee2124360/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKDbnUfdIY866JKibfD3Al4CKYvTfXtrkg1zeHvVaLbkaNBPNY5C3CDYg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.3670076726342711" data-s="300,640" data-type="png" data-w="782" type="block" data-imgfileid="503529291" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/e1b2b95c-8feb-4cea-8294-06dc0e0b79af/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们也让 Gemini 帮忙分析了 DeepSeek 的这些 Commit，让其提取了其中的技术细节，结果如下：&lt;/p&gt;&lt;p&gt;根据 DeepSeek 在 2026 年 1 月提交的 flashmla 库代码变更，可以推断出&lt;strong&gt; Model1 是 DeepSeek 下一代旗舰模型 DeepSeek-V4 的内部开发代号或首个工程版本&lt;/strong&gt;。以下是根据代码 diff 提取的技术细节分析：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 核心架构：回归 512 维标准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 csrc/api/common.h 的 DISPATCH_HEAD_DIM 宏中，可以看到 head_dim 的分支处理：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;V32 (DeepSeek-V3.2)：继续沿用 d_qk = 576 的配置。这是 DeepSeek-V3 引入的非对称 MLA 设计（128 维 RoPE + 448 维 Latent）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Model1：切换到了 512 维。这表明 DeepSeek-V4 在 MLA 架构上进行了「标准化」回归，可能是为了更好地匹配 Blackwell (SM100) 架构的算力对齐，或者优化了 Latent 压缩比例。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 全面支持 Blackwell (SM100) 架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;代码库中出现了大量针对 NVIDIA 下一代 Blackwell GPU 的专门优化：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;SM100 接口：api.cpp 中新增了 FMHACutlassSM100FwdRun。这直接指向了 Blackwell 架构的核心指令集优化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;CUDA 版本要求：README 提到在 B200 上运行需要 CUDA 12.9。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;性能表现：在 B200 上，目前尚未完全优化的 Sparse MLA 算子已能达到 350 TFlops。而在 H800 (SM90a) 上，Dense MLA 的计算吞吐量高达 660 TFlops。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 引入「Token-level Sparse MLA」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是 Model1 相比 V3 系列最显著的算子演进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Sparse &amp;amp; Dense 并行：测试脚本中出现了 test_flash_mla_sparse_decoding.py 和 test_flash_mla_dense_decoding.py。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;FP8 KV Cache 混合精度：Sparse 算子使用 FP8 存储 KV Cache，但在计算矩阵乘法时使用 bfloat16 以保证精度。这说明 &lt;strong&gt;Model1 在极长上下文场景下，会通过「稀疏化推理」来降低显存压力和提升速度。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;4. 新机制：Value Vector Position Awareness (VVPA) 与 Engram&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然 diff 主要是算子层面的，但结合 DISPATCH_MODEL_TYPE 的逻辑和社区披露，Model1 引入了以下新特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;VVPA（数值向量位置感知）：这可能解决了传统 MLA 在长文本下位置信息衰减的问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651011743&amp;idx=1&amp;sn=34e666de69c7ad8166d2d46a4f8938fc&amp;scene=21#wechat_redirect" target="_blank"&gt;Engram 机制&lt;/a&gt;：&lt;strong&gt;这被认为是 DeepSeek 在分布式存储或 KV 压缩上的新突破，用于配合 Model1 的高吞吐需求。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而 Gemini 之所以判断 Model1 是 DeepSeek 下一代旗舰模型 DeepSeek-V4 的内部开发代号或首个工程版本，是因为它认为在下面所示的代码中，MODEL1 的定位是一个与 V32 并列且独立的分支，「&lt;strong&gt;说明它不是 V3 系列的补丁，而是一个采用了不同架构参数的全新模型&lt;/strong&gt;。按照 DeepSeek 的命名惯例，在 V3.2 之后的旗舰级架构跨越，逻辑上即为 V4。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKZc02bvvdfrcLtLLhwy0wHQpsMtruks6Zj1xyA3bUzxFpkyX1nZfvzg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5478036175710594" data-s="300,640" data-type="png" data-w="774" type="block" data-imgfileid="503529292" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c8997455-fae4-4d92-8e2c-26fa1f7d34c7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;对此，你怎么看，你觉得 Model1 就是传说中的 DeepSeek V4 吗？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026 Oral | 告别注意力与热传导！北大清华提出WaveFormer，首创波动方程建模视觉</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 10:17:29 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/f1fa8222-99fa-426e-a9e0-904e033fa1bb/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&amp;ldquo;全局交互&amp;rdquo; 几乎等同于 self-attention：每个 token 都能和所有 token 对话，效果强，但代价也直观 &amp;mdash;&amp;mdash; 复杂度随 token 数平方增长，分辨率一高就吃不消。现有方法大多从 &amp;ldquo;相似度匹配&amp;rdquo; 出发（attention），或从 &amp;ldquo;扩散 / 传导&amp;rdquo; 出发（热方程类方法）。但热方程本质上是一个强低通滤波器：随着传播时间增加，高频细节（边缘、纹理）会迅速消失，导致特征过平滑。&lt;/p&gt;&lt;p&gt;我们是否能找到一种既能实现全局交互，又能精准保留高频细节的物理建模方式？&lt;/p&gt;&lt;p&gt;来自&lt;strong&gt;北京大学和清华大学的研究团队&lt;/strong&gt;给出了答案：&lt;strong&gt;波动方程（Wave Equation）&lt;/strong&gt;：把特征图当作空间信号，让语义在网络深度对应的 &amp;ldquo;传播时间&amp;rdquo; 里，遵循欠阻尼波动方程演化。这样一来，低频的全局结构与高频的边缘纹理不再是 &amp;ldquo;此消彼长&amp;rdquo; 的牺牲关系，而可以在可控的波动传播中共同存在。在 AAAI 2026 Oral 论文《WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation》中，研究者首次将视觉特征图视为在波动传播时间下演化的空间信号，受欠阻尼波动方程支配。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0qfOZyoZKdoRXq76iaiaKQPjIbicia89vsIsrbv3ibFVHKBF8F3D5SIDkTqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529110" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/539b681c-de76-4d14-b42d-c1128afb8da1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.08602&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库：https://github.com/ZishanShu/WaveFormer&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;WaveFormer 首次将波动方程作为视觉主干网络的核心全局建模机制。&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0NiaIoNSHtHfCHiboiav5LwaVIaPPppupuibtuLaW81lZ913OxUE0LzZx0Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5842592592592593" data-type="png" data-w="1080" data-width="1246" data-height="728" data-imgfileid="503529112" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/516ba565-ed23-40c2-a436-b8201e215df5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;方法拆解：把图片当作 &amp;ldquo;波场&amp;rdquo;，特征当作 &amp;ldquo;波&amp;rdquo;，让语义振荡传播&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer 的关键思想可以用一句话概括：&lt;/p&gt;&lt;p&gt;全局交互不一定要靠 &amp;ldquo;相似度匹配&amp;rdquo;（attention），也可以靠 &amp;ldquo;波传播动力学&amp;rdquo;。&lt;/p&gt;&lt;p&gt;WaveFormer 将特征传播写成一个欠阻尼波动方程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;u (x, y, t)：&lt;/strong&gt;语义场（可以理解为特征图随 &amp;ldquo;传播时间&amp;rdquo; 演化）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;v：&lt;/strong&gt;传播速度（控制传播范围）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&amp;alpha;：&lt;/strong&gt;阻尼系数（控制衰减强弱）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它还引入了一个很有意思的设定：除了初始语义场 &lt;strong&gt;u0&lt;/strong&gt;，还允许一个 &amp;ldquo;初始速度场&amp;rdquo;&lt;strong&gt; v0&lt;/strong&gt;，表示不同区域语义被激活 / 抑制的变化趋势。&lt;/p&gt;&lt;p&gt;这个设定带来的最大变化是：&lt;strong&gt;空间频率被显式建模了&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;论文里明确把 &amp;ldquo;频率&amp;rdquo; 对应到 2D 特征图的空间频率：低频是全局布局，高频是边缘与纹理。&lt;/p&gt;&lt;p&gt;WaveFormer 不再把不同频率的信息一股脑丢给网络自己 &amp;ldquo;学着处理&amp;rdquo;，而是把它们写进了传播方程的解里：不同频率以不同方式振荡、衰减，但都参与全局语义的长程运输。&lt;/p&gt;&lt;p&gt;关键在于，团队推导了波动方程在频域下的闭式解：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;热方程常见形式会出现类似&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0e8h4pnBc5JzTBmRtu8iawHhKR6QCXticJYrxCDIIlv2cB5V27QGsPibeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5242718446601942" data-s="300,640" data-type="png" data-w="206" type="block" data-imgfileid="503529114" data-aistatus="1" data-original-style="width: 48px;height: 25px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/889df9b7-4457-4a16-b2a4-5a2062cf068d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 10.56%;"&gt;的项，高频随时间急速衰减&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;WaveFormer 的衰减项更像 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0LV3NtpyaeOicGRSyHgDs7zeDiauoLibmkjABiaNNa5ibyLUicSTiaqHe0iczDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5504587155963303" data-s="300,640" data-type="png" data-w="218" type="block" data-imgfileid="503529116" data-aistatus="1" data-original-style="width: 46px;height: 25px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5f21dc21-abef-42f0-88ca-6107dfe4c704/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 9.8%;"&gt;，对不同频率更 &amp;ldquo;公平&amp;rdquo;，而频率差异主要体现在 cos/sin 的振荡项上，从而实现&lt;strong&gt;频率&amp;ndash;时间解耦&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;热传导方程和扩散方程的闭式解的对比：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0fzVGd8icxCZibwJP68vwmBMzZZdjlVFSibnhBZwibQEhDUrPibgf82JJg7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.33055555555555555" data-type="png" data-w="1080" data-width="1708" data-height="564" data-imgfileid="503529117" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6a968639-67cd-4fe5-bdda-f7211be50015/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;WPO：把闭式解变成一个 O (N log N) 的全局模块&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;更 &amp;ldquo;工程友好&amp;rdquo; 的部分在这里：作者把欠阻尼波动方程的频域解，做成了一个可以直接替换 attention 的算子 WPO。&lt;/p&gt;&lt;p&gt;WPO 的实现流程非常清晰：&lt;/p&gt;&lt;p&gt;1. 把输入特征图变换到频域；&lt;/p&gt;&lt;p&gt;2. 用欠阻尼波动方程的&lt;strong&gt;频率&amp;ndash;时间解耦的闭式解&lt;/strong&gt;，对每个频率分量做 &amp;ldquo;振荡式调制&amp;rdquo;；&lt;/p&gt;&lt;p&gt;3. 再逆变换回空间域，从而完成一次 &amp;ldquo;全局语义传播&amp;rdquo;。&lt;/p&gt;&lt;p&gt;因为核心计算发生在频域（FFT /iFFT），WPO 的全局建模复杂度是 &lt;strong&gt;O (N log N)&lt;/strong&gt;，论文在摘要里明确对比 &amp;ldquo;远低于 attention&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在网络结构上，WaveFormer 走的是层级式骨干：stem + 四个阶段，每个阶段由 WPO Block 组成（WPO + FFN + 下采样），整体可以作为 ViT 或 CNN 的 drop-in backbone。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ04xGqYpUbHDGyP1DdA0L98k3265PhibDXWDzib5C3w8L9SujZeOfXBFJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3824074074074074" data-type="png" data-w="1080" data-width="2456" data-height="940" data-imgfileid="503529119" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/49cd5027-5e1f-4dc3-91f2-68ab13419b62/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为什么 &amp;ldquo;波传播&amp;rdquo; 适合视觉？一个更直观的理解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果把一张图像看成 &amp;ldquo;由低频骨架 + 高频细节叠加&amp;rdquo; 的信号，那么视觉建模很多时候在做两件事：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低频：抓住整体结构、主体布局、长程一致性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高频：保住边缘、纹理、细粒度辨别线索。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;WaveFormer 的 &amp;ldquo;波动方程建模&amp;rdquo; 给了一个很直接的机制：&lt;/p&gt;&lt;p&gt;在频域里，每个频率分量按 &amp;ldquo;阻尼振荡&amp;rdquo; 传播：低频衰减慢、负责全局结构；高频振荡快、在阻尼控制下仍能保留边缘纹理。&lt;/p&gt;&lt;p&gt;论文把这种机制称为一种新的、物理一致的建模偏置（physics-inspired inductive bias），用于同时捕捉全局一致性与高频细节。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：速度、效率与精度的全面超越&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ004eYArZ3RQBBhDl7PUXrCeTmDEQuia20sPgWL2wmsGXCpRLqOn7vXag/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.2916666666666667" data-type="png" data-w="1080" data-width="2958" data-height="862" data-imgfileid="503529130" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/952e0d86-7df8-449a-a447-9af789f66485/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;WaveFormer 在三类核心任务上验证：ImageNet 分类、COCO 检测 / 实例分割、ADE20K 语义分割。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ImageNet-1K 分类：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer-B 在&amp;nbsp;&lt;strong&gt;10.8G FLOPs / 68M 参数&lt;/strong&gt;下达到&amp;nbsp;&lt;strong&gt;84.2% Top-1&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;论文同时给出整体结论：在保持竞争精度的同时，最高可带来 &lt;strong&gt;1.6&amp;times; 吞吐提升、30% FLOPs 降低&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;COCO 检测与实例分割（Mask R-CNN）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer 在 box AP 与 mask AP 上整体优于 Swin/ConvNeXt，并且推理 FPS 更高。例如 &lt;strong&gt;WaveFormer-B 达到 47.9% APb、43.2% APm&lt;/strong&gt;，推理速度 &lt;strong&gt;20.4 img/s&lt;/strong&gt;，比 Swin-B/ConvNeXt-B 分别快 &lt;strong&gt;48%/45%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ADE20K 语义分割（UperNet）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;WaveFormer-B 达到 &lt;strong&gt;50.5% mIoU&lt;/strong&gt;，同时 FLOPs 与 FPS 也具备优势；论文把这种提升与 &amp;ldquo;频率意识的波传播能同时保全局结构与细节边界&amp;rdquo; 直接关联起来。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0TFZ2qVVia8Wlib7ls0Scm18VfL5uVdYvpd4pmzkcxhDmcZoELh91t13Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.708433734939759" data-type="png" data-w="830" data-width="830" data-height="588" data-imgfileid="503529132" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7cb3ee54-b1fd-4d3f-b2ad-9f66f6b55484/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ094e9TJ1stayaaCia3chiaDA5KKJcdf2XMT95KiaclZCdKVsQIBCXLrnTw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529138" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/186cfcf6-612e-476b-82f2-e1cfe54dd051/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;WaveFormer 证明了经典的物理波动规律能够为现代人工智能提供强大的归纳偏置 。这种基于波动方程建模的新范式，不仅为视觉基础模型开辟了频域处理的新路径，也为未来多模态语义传播的研究提供了深刻的启示。&lt;/p&gt;&lt;p&gt;WaveFormer 最值得被记住的，可能不是某个单点指标，而是它把 &amp;ldquo;视觉全局建模&amp;rdquo; 换了一种语言来描述：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从 &amp;ldquo;token 相似度交互&amp;rdquo; 转向 &amp;ldquo;语义场的动力学传播&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;从 &amp;ldquo;隐式处理频率&amp;rdquo; 转向 &amp;ldquo;显式建模低频 / 高频及其随深度演化&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;从 &amp;ldquo;黑盒的全局模块&amp;rdquo; 转向 &amp;ldquo;可解释、可控（v 与 &amp;alpha; 可调）的传播过程&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，MiniMax来承包你的桌面了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 20:53:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-14</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-14</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;如果说 2025 年是 Agent 落地元年，那么刚刚开始的 2026 年势必迎来新一轮爆发。&lt;/p&gt;&lt;p&gt;一开年，Agent 赛道便进入到了白热化的竞争，国外如 Anthropic 发布 Cowork，国内如千问 APP 上线「任务助理」。在这一背景下，市场出现了分化，或专注于工作提效，或聚焦于日常生活体验重塑。&lt;/p&gt;&lt;p&gt;在这个红海市场，10 多天前登陆港股的国产 AI 大模型独角兽 MiniMax 选择的路线是「将释放生产力进行到底」。&lt;/p&gt;&lt;p&gt;1 月 20 日，MiniMax 揭开了其第二代智能体产品 &amp;mdash;&amp;mdash;MiniMax Agent 2.0 的面纱，为这个火热的 AI 赛道添加了又一个生力军。此次的更新被定义为了一个&lt;strong&gt;「AI 原生工作台」（AI-native Workspace）&lt;/strong&gt;，从产品形态和能力分布上进行了深度重构。&lt;/p&gt;&lt;p&gt;这个全新的工作台不再像过去那样依赖简单的 Chat 式对话框，而变身为&lt;strong&gt;能感知本地环境、自主拆解复杂任务且提供专家级专业技能的进阶型智能协作伙伴&lt;/strong&gt;。这些能力实现的背后立着以下三大核心支柱：&lt;/p&gt;&lt;p&gt;首先是&lt;strong&gt;桌面端应用「MiniMax Agent Desktop」&lt;/strong&gt;，它让 Agent 跳出了浏览器网页，而能在操作本地文件和本地环境的同时启动网页自动化任务。这意味着，该 APP 实现了本地与云端之间的无缝连接，通过一个全局视角渗透到各个职能角色的核心工作流中，将人类从「在不同窗口间切换、复制粘贴、点击按钮」的重复劳动中解放出来。&lt;/p&gt;&lt;p&gt;MiniMax 桌面端已经上线了 Windows 和 Mac 双版本。&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;「Expert Agents」 ，打造垂直领域的顶级专家分身&lt;/strong&gt;。Expert Agents 超越了现有预设的 Multi-agent 的 Pro 模式，通过封装私有知识和行业独家 SOP（标准操作流程），用专家级的知识、能力和经验储备来武装用户。&lt;/p&gt;&lt;p&gt;MiniMax 表示，1.0 时代依赖的 Multi-agent 多专家系统只能提供 70 分的通用专家组合，&lt;strong&gt;现在借助 Expert Agents 可以将这一分数拉升到 95 分甚至 100 分&lt;/strong&gt;，可靠性有了质的提升。并且官方还会提供大量开箱即用的 Expert Agents，降低了操作门槛，上手更轻松。&lt;/p&gt;&lt;p&gt;用户现在可以在桌面和网页双端限时免费体验 Expert Agents 功能。&lt;/p&gt;&lt;p&gt;最后&lt;strong&gt;定义自己的 Expert Agents&lt;/strong&gt;，通过更多的上下文信息和更自由的自定义设置，让 Agent 在更懂你的基础上提供个性化的专家服务。&lt;/p&gt;&lt;p&gt;如果说去年发布的 MiniMax Agent 1.0 定义了「靠谱的 AI 伙伴」，如今的 2.0 在同样确保结果的准确性之外，在 AI 原生自动化执行的广度、深度、专业度上来了波全方位加强。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测：这个 Agent 真是能文能武&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;表现如何还得看实战。打开 MiniMax Agent 官网 ，下载最新上线的 MiniMax 桌面端，即可开启 AI 原生工作台体验，重塑工作流。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0E86XbDsWUcibNXx9uyNRrS7XdY1tdfAMw2icdGe8HMbWgUThUVOMDwjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529209" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a6b446cb-f365-407d-a390-74e4c223a102/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;官网地址：https://agent.minimaxi.com/&lt;/p&gt;&lt;p&gt;安装完成后，&lt;strong&gt;在引导界面可以看到 MiniMax 桌面端已经深度打通本地文件&lt;/strong&gt;，我们只需选定一个工作目录，即可让 AI 读取、分析、批量处理该目录下的所有文件。这一设计体现了其打造「AI 原生工作台」的核心思路。&lt;/p&gt;&lt;p&gt;下面就开始测试吧。&lt;/p&gt;&lt;p&gt;作为一家媒体，我们的日常工作中一大很重要的任务是&lt;strong&gt;刷选题&lt;/strong&gt;，直接输入下面的提示词，看看我们能否在 MiniMax 桌面端中让 Agent 自主实现这个定时任务，提升我们刷选题的效率。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;每天 9:00 为我提供过去 24 小时内 AI 领域的重点新闻摘要。每条新闻提炼一个核心要点，并附带网络检索来源，确保清晰易读&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/def72d9d-5c10-401b-9a19-cb8bac986d3b/1768913407226.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 4 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;仅仅 2 分多钟，MiniMax 的 Agent 就成功完成了任务，正确编写了脚本并进行了可行性测试。不仅如此，该 Agent 还给出了后续实现定时任务的教程，让我们只需一些复制粘贴，即可在我们的设备上将这个 AI 任务变成每天上午的日常。下图总结了此次任务的执行结果：&lt;/p&gt;&lt;section data-pm-slice="1 2 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0Dh8MYlxFzb3NuntQ2bmuAFVrB8up6CIFibJrcsePMt56TiaYM7Wd14ZQ/640?wx_fmt=png#imgIndex=2" alt="长图滚动查看" data-ratio="2.986111111111111" data-w="1080" data-aistatus="1" data-original-style="width: 1831.41px;height: auto;display: block;border-radius: 4px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b1f45b69-d733-4b42-95fd-cdb1dea98913/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而作为一家专业的人工智能媒体，&lt;strong&gt;读论文&lt;/strong&gt;也是我们的一个日常，接下来我们试了试让 MiniMax 桌面端分析解读 MiniMax-M1 背后的技术脉络。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;这是 MiniMax-M1 的技术报告 https://arxiv.org/pdf/2506.13585，研究其参考文献，了解其背后的技术，然后制作一个网页，展示 MiniMax-M1 背后的技术进化图谱，务必尽量往前追溯。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;很显然，这个任务会更加复杂一些，耗时大概 6 分钟。&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e0c284f5-4135-4cb6-b2b0-7ca96ead9505/1768913437418.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;4 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在执行过程中，Agent 首先分析了任务需求，然后调用工具下载了指定文档，之后对文档进行了分析解读以及技术追溯。之后，它又按照要求编写了一个网页来进行了展示。&lt;/p&gt;&lt;p&gt;最后，MiniMax 的 Agent 为我们创建了这样一个网页，：&lt;/p&gt;&lt;section data-pm-slice="1 2 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0KiaW4QhV9gYunjA9fpxZlicFDGVd5bMtg4PnFx3aBBckTMlf6xcokG8A/640?wx_fmt=png#imgIndex=3" alt="长图滚动查看" data-ratio="4.937037037037037" data-w="1080" data-aistatus="1" data-original-style="width: 1831.41px;height: auto;display: block;border-radius: 4px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/aaed1756-1a49-4f06-8463-3f0b2a70678d/640.png" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不仅如此，该 Agent 还自动在 MiniMax Space 上部署了这个网页， 让我们可以直接使用和分享这个网页：https://sqwu1jsy96cd.space.minimaxi.com/&lt;/p&gt;&lt;p&gt;这种从研读到交付的闭环能力，展现了其在任务执行上的工程深度。&lt;/p&gt;&lt;p&gt;当然，得益于工作目录的设计，MiniMax 桌面端不仅能处理单篇论文，更能&lt;strong&gt;直接处理一个装满文件的文件夹&lt;/strong&gt;。举个例子，我们的日常工作将会积累很多选题，其中包括一些高质量的技术博客，使用以下提示词，我们可以让 MiniMax 将这些博客从文档中提取出去，并制作成精美的 PPT 进行展示。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;这是我们近几个月的日常选题整理文档，请梳理出其中所有的技术博客，并访问每篇技术博客的内容，给出简短的内容整理。将结果整理成一个 PPT，每一页展示一篇技术博客，其中应包括一些引用自博客的图片或截图、博客标题和链接以及内容简介。使用莫兰迪色系。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这个任务就更加复杂了，而且非常繁琐，也因此我们此前都没去处理。而在 MiniMax 桌面端的帮助下，我们仅用 23 分钟时间就完成了整个任务。&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8096a079-7e72-4303-8f8b-162ae27a5884/1768913466957.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 16 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;可以看到，我们的初始文件是一大堆的 docx 文档，MiniMax 桌面端首先调用工具将所有这些文档转换成了 LLM 最喜欢的 markdown 格式，然后读取详细内容，并提取出了分散在各个文档中的技术博客。之后它继续调用工具，读取了文档中这些技术博客链接的具体内容。之后它继续推进，将这些内容总结成了适合制作 PPT 的文案，接下来，还是调用工具，它使用这些文案生成了图像和演示 PPT。&lt;/p&gt;&lt;p&gt;至于效果，可以说是超乎想象地好。&lt;a href="https://mp.weixin.qq.com/s/I2RgH04J2l5mG1x492T17A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5307f3ac-af37-4744-9098-aebc41e75e51/1768913484215.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;通过以上测试示例，我们看到了 MiniMax 桌面端在日常工作中对我们的强大助益，同时，我们也看到了将 Agent 接入本地计算机的无限可能性。&lt;/p&gt;&lt;p&gt;举个例子，&lt;strong&gt;对以上视频的加速处理，我们也完全是通过 MiniMax 桌面端完成的&lt;/strong&gt;。而我们所做的，不过是输入了这样一段提示词：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;处理一下文件夹中的视频：将 MiniMax-1 和 2 加速 4 倍，将 3 加速 8 倍，将 4 加速 16 倍。我本地已经安装 ffmpeg。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Agent 精准识别了本地环境中的工具路径，并生成了对应的处理指令。无需用户手动输入复杂的命令行参数，视频加速任务便在后台安静、高效地完成了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0tPnhUxo73ViaOqT9OnFVib8ozqZF8cl1FeMdQwgZGvJw1lv8n9CeroBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.37806451612903225" data-s="300,640" data-type="png" data-w="775" type="block" data-imgfileid="503529252" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4d18d72d-1f93-4bc5-84a6-ecea6b9e7ced/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，我们还简单尝试了 &lt;strong&gt;MiniMax 提供的专家 Agent 创建能力&lt;/strong&gt;。据介绍，该功能「允许用户构建在特定领域达到 95 分甚至 100 分的领域的专家 Agent。不仅仅是简单的 Prompt 调整，而是深度的知识与能力注入。」&lt;/p&gt;&lt;p&gt;创建过程非常简单直观。在对话框左下方选择「子代理」&amp;rarr;「管理子代理」，即可创建出可以多次复用的 Agent，比如这里我们简单创建了一些「专家」。而在每个 Agent 的配置中，我们也可以选择启动不同的工具。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0n8sXu3zSIfZZOib7MGnZiaOc520JXCQjI1v9d9v9H83wPQiaZmTeFD87A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="1.002016129032258" data-s="300,640" data-type="gif" data-w="992" type="block" data-imgfileid="503529253" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/7ff4f585-d0ef-4979-a471-019e93a65c5c/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;之后，我们只需在开启任务之前选择我们想要使用的子代理，即可将相应的 Agent 纳入到我们的工作流程中。比如在下面的例子中，我们启用了上面配置的一系列专家，然后让它们围绕「AI 究竟是什么」进行了一系列深度探讨。这时候，MiniMax 本身会化身这场多智能体讨论的主持人，通过在探讨中调用不同配置的子代理，实现对这一话题多视角反复深度讨论。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0f1KbibJqVED0JAeoT76RoLRicv0PATevB1qUBv5e8rKPZnKzSLbLIObw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.6234375" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503529264" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/07754cd7-44f0-40ca-96e7-4ca5b130fa49/640.gif" data-order="1" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这项能力具有巨大的想象空间。它意味着用户可以将行业经验、部门 SOP 甚至复杂的业务逻辑转化为可调用的模块。当用户面对一项复合任务时，不再是与一个通用模型交谈，而是指挥一支由特定领域专家组成的数字团队。这种从「单点能力」向「专家协作」的转变，为大模型在专业垂直场景的落地提供了更具实操性的路径。&lt;/p&gt;&lt;p&gt;整体体验下来，我们看到 MiniMax Agent 能够理解复杂的 SOP 流程，自主调用本地与云端工具，将原本需要多款软件协作的任务浓缩在单一的提示词输入框中。&lt;strong&gt;这种以任务完成率为核心的设计，正是 MiniMax 试图定义的 AI 原生工作范式。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从刷分到会干活：MiniMax 正在重新定义 AI 能力边界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;总结来看，&lt;strong&gt;MiniMax Agent 2.0 并不是在展示它想得有多聪明，而是在证明它能把事做到哪一步&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在 Agent 2.0 的工作方式里，AI 不再等待人类一次次补充上下文，而是主动进入工作环境，理解你的文件、网页、工作流程，持续推进任务本身。你只要给出一个指令，剩下的拆解、执行与跟进，交由 Agent 在 Workspace 中完成。&lt;/p&gt;&lt;p&gt;这也解释了为什么 MiniMax 要把 Agent 2.0 定义为 AI-native Workspace。&lt;/p&gt;&lt;p&gt;这背后，是 &lt;strong&gt;MiniMax 在模型层面的持续升级，以及一套在内部真实运转的工作方式&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;去年 6 月提出的 Lightning Attention 将长序列计算成本从二次方降为线性，让 Agent 不再失忆；10 月发布的 M2 定位为 Agent &amp;amp; Code Native，采用交错思维机制和 MoE 架构（230B 总参数、10B 激活），API 价格仅为 Claude Sonnet 4.5 的 8%；12 月的 M2.1 则向 Rust、Java、C++ 等后端语言深入，使得模型具备全栈工程能力。&lt;/p&gt;&lt;p&gt;而这些能力，首先被 MiniMax 自己用在了内部。模型被直接嵌入研发与办公的核心流程，从写代码、拆需求到跑 Agent 任务。据了解，在过去数周内，MiniMax 内部接近 100% 的同学开始使用 Agent 实习生。&lt;/p&gt;&lt;p&gt;这样一来，模型能力的每一次升级，都会在真实业务中被高频使用和反复打磨，而内部产生的反馈，又返回到下一轮模型和系统设计上来，形成了一条快速自我强化的迭代闭环。&lt;/p&gt;&lt;p&gt;此次 &lt;strong&gt;MiniMax 定义的「AI 原生工作台」将掀起一场对 AI 参与高复杂度工作的价值重构&lt;/strong&gt;。其中一点是交互逻辑发生了变化，从「人要被动适应 Agent」变为「Agent 主动适应人」。另外通过定制化的 Expert Agents，专业壁垒被打破，普通人无需经历漫长的学习就能获得行业顶级的知识与经验。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>马斯克刚刚真把 𝕏 平台推荐算法给开源了，核心也是Transformer</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 20:44:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜冷猫&lt;/section&gt;&lt;p&gt;刚刚，𝕏 平台（原 Twitter 平台）公布了全新的开源消息：&lt;strong&gt;已将全新的推荐算法开源，该算法由与 xAI 的 Grok 模型相同的 Transformer 架构驱动。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该模型预测用户行为（点赞、回复、转发等）来对帖子进行排序，出现在 For You 一栏中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ06fPgwA5OU8Np61Uia0ojwP74icVvpnTcpiavFNT1ZHa3weFVveO6HAsBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.8703703703703703" data-type="png" data-w="1080" data-width="1170" data-height="1018" data-imgfileid="503529153" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a98a260d-f100-43de-a447-bb6827842658/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;众所周知，推荐算法是社交媒体平台的生命线，几乎已经成为了媒体平台获取用户留存，扩大营销收益的核心。在一周多前，马斯克在 𝕏 平台发推声明「将在 7 天后开源𝕏平台推荐算法」的时候几乎令人难以置信。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0cOvia7PJXmBtUqJ9PQicibc8tLjI0PsYkgAbC0HjyXDDaU7ucSo1SPvJQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6620370370370371" data-type="png" data-w="1080" data-width="1178" data-height="780" data-imgfileid="503529154" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f69fb619-6512-4c56-8048-1eaf7dcc732e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而马斯克确实说到做到，虽然比声称的 7 天内略晚，但推荐算法的确已经完全开源。希望之后能够长期遵循每 4 周重复更新的承诺。&lt;/p&gt;&lt;p&gt;在开源信息发布后，马斯克表示：「我们知道这个算法很笨拙，需要大量的改进，但至少你可以看到我们在实时和透明的情况下努力让它变得更好。&lt;strong&gt;没有其他社交媒体公司这样做&lt;/strong&gt;。」&lt;/p&gt;&lt;p&gt;不过，马斯克选择开源 𝕏 平台推荐算法可能另有原因。&lt;/p&gt;&lt;p&gt;据路透社报道，2025 年 7 月，巴黎检察官调查了该社交媒体平台，怀疑其存在算法偏见和欺诈性数据提取，马斯克将其称为「政治动机的刑事调查」，威胁到其用户的言论自由。&lt;/p&gt;&lt;p&gt;12 月，欧盟对 𝕏 处以 1.2 亿欧元罚款，监管机构表示该公司违反了该地区数字服务法案下的透明度义务。罚款与𝕏的「蓝 V」订阅、广告库缺乏透明度以及未能向研究人员提供平台公共数据有关。&lt;/p&gt;&lt;p&gt;既然已经开源，那我们来看一下 𝕏 平台到底公开了些啥？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0g3eaXJ5M85icKvazszEibxz8tvmiaDoZBuG1xOSS5meAliaeGjUAuPlic2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.25833333333333336" data-type="png" data-w="1080" data-width="1688" data-height="436" data-imgfileid="503529155" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/133b2051-3dd0-44c5-affd-3d894ccd5309/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Github 开源链接：https://github.com/xai-org/x-algorithm&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这份代码仓库包含了 &lt;strong&gt;𝕏 平台「For You」信息流背后的核心推荐系统&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;它将站内关系内容（来自你已关注账号的内容）与站外发现内容（通过基于机器学习的召回机制发现的内容）进行融合，并使用基于 Grok 的 Transformer 模型对所有内容进行统一排序。&lt;/p&gt;&lt;p&gt;随后就是一长串的系统架构：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0ho1jbmH2YJ5UwTibwKT0y62XW3nDeRkpjmgkbwo6U1nSxQmlB6JPHng/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="2.053435114503817" data-type="png" data-w="786" data-width="786" data-height="1614" data-imgfileid="503529156" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/85cb1519-3b24-425c-a918-8993fb16a6ee/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;𝕏 推荐算法系统架构&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;新系统彻底抛弃了传统的手工规则，并大幅减少启发式方法，采用完全的神经网络方式。&lt;/p&gt;&lt;p&gt;整个推荐过程的核心几乎全部交给了这个基于 Grok 的 Transformer 模型：它通过理解你的历史互动行为（比如点赞、回复、转发等），来判断哪些内容与你最相关。&lt;/p&gt;&lt;p&gt;整个系统的核心是称为 Thunder 和 Phoenix 的组件。「For You」信息流算法会从两个来源中&lt;strong&gt;召回、排序并过滤&lt;/strong&gt;内容：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;站内关系内容&lt;/strong&gt;（In-Network，Thunder）：来自你已关注账号的帖子&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;站外发现内容&lt;/strong&gt;（Out-of-Network，Phoenix Retrieval）：从全局内容池中通过模型发现的帖子&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;来自这两个来源的内容会被合并在一起，并统一交由 &lt;strong&gt;Phoenix&amp;nbsp;&lt;/strong&gt;进行排序。&lt;strong&gt;Phoenix 是一个基于 Grok 的 Transformer 模型&lt;/strong&gt;，它会为每一条帖子预测不同形式的互动概率。最终排序分数，是这些预测互动概率的加权组合。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Thunder 组件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是一个&lt;strong&gt;基于内存的帖子存储与实时数据摄取系统&lt;/strong&gt;，用于跟踪全体用户的最新发帖情况，主要功能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从 Kafka 中消费帖子创建 / 删除事件&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;为每个用户分别维护原帖、回复 / 转发、以及视频帖的存储&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;向请求用户提供其关注账号的「站内关系内容（in-network）」候选帖&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;自动清理超过保留期限的旧帖子&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持亚毫秒级查询，无需访问外部数据库即可获取站内关系内容&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Thunder 的作用，是让系统能够极高速地获取「你关注的人最近发了什么」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Phoenix 组件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是推荐系统中的 &lt;strong&gt;机器学习核心组件&lt;/strong&gt;，主要包含两个功能模块：&lt;/p&gt;&lt;p&gt;召回（Two-Tower 双塔模型），用于发现相关的站外内容（out-of-network）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;用户塔（User Tower）：将用户特征和历史互动行为编码为向量表示&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;候选内容塔（Candidate Tower）：将所有帖子编码为向量表示&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;相似度检索：通过向量点积相似度，召回最相关的 Top-K 帖子&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;排序（带候选隔离的 Transformer），用于预测每条候选内容的互动概率：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;以用户上下文（历史互动）和候选帖子作为输入&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用特殊的注意力掩码机制，确保候选帖子之间不能相互看到彼此&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出不同互动行为的概率预测（点赞、回复、转发、点击等）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于 Phoenix 的 transformer 模型预测多种参与类型的概率：&lt;/p&gt;&lt;pre data-lang="css"&gt;&lt;code&gt;Predictions:&lt;/code&gt;
&lt;code&gt;├── P(favorite)&lt;/code&gt;
&lt;code&gt;├── P(reply)&lt;/code&gt;
&lt;code&gt;├── P(repost)&lt;/code&gt;
&lt;code&gt;├── P(quote)&lt;/code&gt;
&lt;code&gt;├── P(click)&lt;/code&gt;
&lt;code&gt;├── P(profile_click)&lt;/code&gt;
&lt;code&gt;├── P(video_view)&lt;/code&gt;
&lt;code&gt;├── P(photo_expand)&lt;/code&gt;
&lt;code&gt;├── P(share)&lt;/code&gt;
&lt;code&gt;├── P(dwell)&lt;/code&gt;
&lt;code&gt;├── P(follow_author)&lt;/code&gt;
&lt;code&gt;├── P(not_interested)&lt;/code&gt;
&lt;code&gt;├── P(block_author)&lt;/code&gt;
&lt;code&gt;├── P(mute_author)&lt;/code&gt;
&lt;code&gt;└── P(report)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;加权评分器将这些因素综合成一个最终得分：&lt;/p&gt;&lt;pre&gt;FinalScore= &amp;Sigma; (weight_i &amp;times; P(action_i)) &lt;/pre&gt;&lt;p&gt;&lt;strong&gt;流量密码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个得分就是影响推文推荐水平的量化数据。简单分析，𝕏 平台的推荐逻辑更加关注评估内容与用户的关系质量。&lt;/p&gt;&lt;p&gt;在新的「For You」机制下，每一条帖子都会被独立评估，排序不再主要依赖点赞数量，而是基于系统对深度互动行为的预测与反馈，包括引用评论、私信分享、复制链接、个人主页点击与关注，以及停留时长。相反，「不感兴趣」、静音、拉黑、举报等负面行为会直接被赋予负权重，显著压低内容分发。&lt;/p&gt;&lt;p&gt;此外，情绪化标题、短期刺激型内容的收益正在下降。算法不仅关注互动峰值，也会捕捉后续的负反馈，从而惩罚低质量、不可持续的互动模式。&lt;/p&gt;&lt;p&gt;同时，发布频率越高并不等于覆盖面越广。系统会对同一作者在同一信息流中的多条内容进行递减加权，刷屏式发布反而更容易被压制。更有效的策略，是降低频率、提高单条内容的独立价值。&lt;/p&gt;&lt;p&gt;在分发机制上，关注关系的重要性进一步上升。来自关注者网络的内容保持满权重，而推送给非关注用户的内容则会被系统性折扣，降低「纯病毒式传播」的成功概率。&lt;/p&gt;&lt;p&gt;总体来看，𝕏 的推荐系统正在明确优化长期关系和内容质量，而不是短期热度。谁能建立稳定、正向的互动关系，谁才能获得更可持续的曝光。&lt;/p&gt;&lt;p&gt;规则已经明确地展现在所有人面前，从中每个人都可以发掘自己的流量密码。&lt;/p&gt;&lt;p&gt;或许大家可以去关注一下我们机器之心的 𝕏 ？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>击败GPT、Gemini，复旦×创智孵化创业团队「模思智能」，语音模型上新了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:40:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南、杜伟&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;在语音大模型赛道上，GPT-4o、Gemini 的能力遥遥领先。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;近日，&lt;strong&gt;由复旦邱锡鹏担任首席科学家的模思智能发布了多说话人自动语音识别（ASR）模型 MOSS-Transcribe-Diarize&lt;/strong&gt;，不但可以语音转文字，还可以将音频片段与对话中不同的说话者关联起来，性能超过了 GPT-4o、Gemini、豆包等一众模型。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;多人说话场景的语音转录是语音识别领域的落地痛点问题。以往模型一旦遇到多人抢着说话就可能听不清、记不准。现在 MOSS-Transcribe-Diarize 摸透了多人说话逻辑，能够轻松应对混乱插话、频繁切话或者重叠说话等复杂场景，真正掌握了「说哪记哪、听声辩人」的技能。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;MOSS-Transcribe-Diarize 在语音识别与分析领域具有突破性意义，解决了语音领域最后的落地痛点。MOSS-Transcribe-Diarize 支持 128K 的长上下文窗口，&lt;strong&gt;可以一次性输入并处理长达 90 分钟的音频&lt;/strong&gt;，突出了复杂场景下的抗干扰能力。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;MOSS-Transcribe-Diarize 的跑分成绩同样亮眼。&lt;/strong&gt;在 AISHELL-4、Podcast、Movies 等多个语音基准测试中，模型均取得了业界最优（SOTA）的整体表现。尤其是在影视剧场景下，背景音更杂、多人同时说话、频繁插话、声音重叠，是语音转录里&lt;strong&gt;最乱、也最接近真实应用的情况。&lt;/strong&gt;即便面对这样的复杂语音条件，MOSS-Transcribe-Diarize 依然稳定跑出了当前业界最优的整体成绩：&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0nvS6kWd3rgdOY3rUwjd4x0kjHrsqvy8kyev40ziaK1MuibZT7TM7PAlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529151" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4a6a54d9-4043-4060-bb74-9834e3a8bd1a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="2 2 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 此处 GPT-4o 特指 gpt-4o-transcribe-diarize&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;再更具体一点，该模型实现了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最低的 CER（字错误率）与 cpCER（最优排列字错误率）&lt;/strong&gt;：在多说话人混合与重叠场景下取得业内领先的转录准确率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最佳的 &amp;Delta;cp 指标（说话人分离性能 ）&lt;/strong&gt;：相比于其它因为长音频切片而导致的说话人识别不一致的模型，MOSS-Transcribe-Diarize 保持了最好的说话人标签准确性和一致性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;超长音频处理&lt;/strong&gt;：在面对超长音频时，当前顶尖商业模型（如 GPT-4o Transcribe Diarize、Gemini 3 Pro）受限于输入长度或输出格式的稳定性，而 MOSS-Transcribe-Diarize 能够稳定输出完整的带有说话人以及时间戳的语音转录结果。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实战效果惊艳，经典名场面「华强买瓜」：&lt;a href="https://mp.weixin.qq.com/s/LoP4twE1X5UFSY3G7g42mQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8388af55-0fd3-4eed-a00a-ef4013e49a89/1768905487029.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Mygo 的飞鸟山公园：&lt;a href="https://mp.weixin.qq.com/s/LoP4twE1X5UFSY3G7g42mQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e991c545-34f5-43b7-bdc5-869cb019cc5f/1768905501344.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;看起来 AI 模型可以把说话人和每个人所讲的内容识别地清清楚楚，不论是嘈杂的环境音，人物的方言、俚语，还是因为情感波动表现出的喊叫、哭泣等都不会影响 AI 的判断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首个统一多模态模型，挑战 AI 语音最难题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS-Transcribe-Diarize 的特点不仅在于语音能力，它作为统一的端到端多模态语音转录模型，能够像人类一样，在「听」的过程中同时完成「听懂内容」、「识别是谁说的」以及「记录说话时间」这三件事。&lt;/p&gt;&lt;p&gt;它主要解决的是语音处理中一个经典且极具挑战的问题：SATS，即「带说话人归属和时间戳的转录」。 想象一下，在参加环境嘈杂、一堆人在场的会议时，大家你一言我一语，乱哄哄一片。这种面向多说话人的转录既要求内容准确，也要标明「何人何时发言」。&lt;/p&gt;&lt;p&gt;但是&lt;strong&gt;，传统的模块化组件拼接方案（如自动语音识别 + 说话人日志）、引入 LLM 的半级联方案（使用自动语音识别和说话人日志生成候选内容，然后利用 LLM 修正错误）&lt;/strong&gt;以及&lt;strong&gt;近期将识别与归属统一在多模态框架下的尝试（如 Sortformer、SpeakerLM、JEDIS-LLM 等）&lt;/strong&gt;都不同程度地存在着缺陷，比如级联方案对于说话人重叠的音频表现不鲁棒，其他方案对长时间多说话人对话的转录效果不佳，亟需更优的解决方案。&lt;/p&gt;&lt;p&gt;邱锡鹏团队发布的 MOSS-Transcribe-Diarize 一扫现有 SATS 方案的不足，一举解决了三大核心瓶颈，即长上下文窗口受限、长时记忆脆弱和缺乏原生时间戳。相关技术报告已在几天前发布，同时官方也开放了 &lt;strong&gt;API 接口&lt;/strong&gt;，目前为限时免费期，感兴趣的同学可自行体验：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;技术报告：https://arxiv.org/pdf/2601.01554&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型主页：https://mosi.cn/models/moss-transcribe-diarize&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;API 接入：https://studio.mosi.cn/docs/moss-transcribe-diarize&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中展示了新模型的大量技术特点：其作为一个统一的多模态大语言模型，可以通过端到端的方式同时执行语音识别（ASR）、说话人归属和时间戳预测，消除可能产生的误差传播。&lt;/p&gt;&lt;p&gt;为了达成这些效果，MOSS-Transcribe-Diarize 在模型架构、训练数据组成上形成了一套自己的解法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在架构设计上，它采用了统一的音频 - 文本多模态架构。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;设计者将多说话人的声学表示投影到预训练文本 LLM 的特征空间中，使得该模型在单一的端到端框架内能够联合建模词汇内容、说话人归属和时间戳预测。&lt;/p&gt;&lt;p&gt;模型在一个推理过程中直接输出带有 [S01]、[S02] 标签和精确时间戳的文本。这种机制利用了语义信息来辅助说话人识别（例如，通过说话内容的连贯性来判断是否换人了），极大地提高了识别准确率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在训练数据的组成上，采用「虚实结合」的策略。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS-Transcribe-Diarize 使用大量真实世界的对话音频以及通过概率模拟器生成的合成数据进行训练，增强了对重叠语音、轮替和声学变化等性能指标的鲁棒性。该模型训练使用的真实数据包含了从公共语料库中采样的大量说话人片段，并覆盖了现实中不同类型的多说话人场景。&lt;/p&gt;&lt;p&gt;得益于架构与数据层面的一系列巧思，MOSS-Transcribe-Diarize 才能够一举攻克行业长期以来面临的长对话和多说话人转录难题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长短音频、切话叠音，多场景表现最优&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在与国内外顶级模型的较量中，MOSS-Transcribe-Diarize 在多个基准测试中拿下 SOTA 成绩。它究竟强在哪些方面呢？我们接下来进行了一番深入探究。&lt;/p&gt;&lt;p&gt;1）在&lt;strong&gt;包含近 40 分钟真实世界会议录音的 AISHELL-4 数据集&lt;/strong&gt;上，MOSS-Transcribe-Diarize 在 CER 和 cpCER 两项指标上大幅优于所有基线模型，并表现出了更低的 &amp;Delta;cp 值。这验证了相较于纯粹的 ASR 错误，由说话人归属错误引入的额外性能衰退要少得多，并由此证明了长上下文、端到端建模在长对话中维持说话人一致性方面的有效性。&lt;/p&gt;&lt;p&gt;相比之下，GPT-4o 和 Gemini 3 Pro 均无法可靠地处理 AISHELL-4 等长音频输入，前者受限于音频输入长度，无法完成完整录音转录；后者无法生成符合既定说话人归属格式的有效输出。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ03pW558PqlTxpTYhLdNUEQxMjMLziaLu7hmr4rrFsUGVhY51gayE2MUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529160" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/baa61a3f-8a29-42b6-ad4c-4038ff805a60/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2）在&lt;strong&gt;&amp;nbsp;Podcast 数据集&lt;/strong&gt;（多说话人播客访谈场景）上，MOSS-Transcribe-Diarize 再次取得所有参评模型中最低的 CER 和 cpCER。尽管其他基线模型也达到很高的 ASR 准确率，但在 &amp;Delta;cp 值这点上落败了。这表明，在频繁的话轮转换和长跨度的说话人重现场景下，MOSS-Transcribe-Diarize 能够让说话人归属更加准确。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0wAH5Eq9cd2M4EJwINa9yx0qaO59PZ9CUGqrq87PYzFjMeXZC28xjjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529078" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cc4b02b9-d2c3-4c11-830c-4e72499cac58/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;3）在&lt;strong&gt;&amp;nbsp;Movies 数据集&lt;/strong&gt;（复杂影视剧场景）上，强调短促话语、快速说话人交替以及频繁的语音重叠场景，MOSS-Transcribe-Diarize 面对这种短语音转录任务依然优于所有基线模型。它还在 CER 和 cpCER 两项指标之间保持了相对较小的差距，这意味着不仅能听清说了什么，还能非常精准地判断出是谁说的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0nvS6kWd3rgdOY3rUwjd4x0kjHrsqvy8kyev40ziaK1MuibZT7TM7PAlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529159" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/57239345-b869-41ad-8fb6-f6ed17baeb53/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;目标：情境智能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS 系列大模型的背后，是国内 AI 领域领军人物，复旦大学教授邱锡鹏带领的团队。在中国 AI 版图中，他们显得极具特色。该团队的 MOSS 模型是国内第一个对标 ChatGPT 并开源的对话式大语言模型，并提出了最早的具有内生语音能力的大模型 SpeechGPT 和原生端到端全模态大模型 AnyGPT。团队组建的模思智能（MOSI AI）则由上海创智学院与复旦大学自主孵化，是一家专注面向情境智能的多模态大模型公司。&lt;/p&gt;&lt;p&gt;他们保持了一条清晰且具有战略眼光的技术路径：&lt;strong&gt;让大模型理解复杂的真实世界情境，并以情境多模态实现通用人工智能。&lt;/strong&gt;在这条路线上，他们一直在不断探索，发布了一系列多模态领域的前沿技术成果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;去年 7 月，模思开源了革命性的对话语音合成模型&amp;nbsp;&lt;strong&gt;MOSS-TTSD&lt;/strong&gt;，能够根据完整的多人对话文本，直接生成高质量对话语音。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;去年 11 月，&lt;strong&gt;MOSS-Speech&lt;/strong&gt; 的发布展现了语音 AI 技术的突破，实现了 SOTA 性能。这是一个无文本引导的真端到端语音大模型，可以在保持模型高智商程度的前提下，解决人机低时延交互的挑战。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最近发布的&lt;strong&gt;&amp;nbsp;MOSS-Transcribe-Diarize&lt;/strong&gt;，则攻克了复杂日常多人对话场景的语音识别，对于多模态 AI 的实际落地具有重要意义。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一系列技术成果可覆盖实时对话交互、复杂场景音频生成、高鲁棒性语音理解、多模态交互等核心能力场景，在流畅度、响应速度、理解能力和可控性方面实现了行业领先表现。&lt;/p&gt;&lt;p&gt;面向未来，模思将持续深耕让 AI「理解用户所处的全局情境」的多模态智能，通过规模化物理世界的复杂真实情境，实现真正自然、连贯、可成长、可信赖的智能交互，推动多模态交互与具身智能的产业化落地。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>当黄仁勋将存储定义为「AI运行内存」，基础设施该如何实现物种进化？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:35:39 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜Panda&amp;nbsp;&lt;/p&gt;&lt;p&gt;一根 256 GB 内存条标价 5000 美元？这个价格已经轻松超过了英伟达顶配显卡 RTX 5090 的市场溢价。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JW5fhqyibMtv1Mc4icLwgUldO4SPLvp10W5aeCGEUaN0yg6SSvGwkTPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7512755102040817" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503528866" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8ec2cd31-a8e0-4db6-b13c-ca421e7f76fc/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 此推文引发了广泛讨论，已收获超 200 万浏览，图源：X@Yuchenj_UW&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;由于 AI 算力需求引发了极端的结构性紧缺，全球内存市场正陷入一场前所未有的疯狂。报道称 OpenAI 与三星电子、SK 海力士签署了大规模 DRAM 晶圆供应协议，其预估的 DRAM 晶圆需求可能达到全球 DRAM 晶圆产能的约 40%，这一需求规模在行业内引发了对存储供应紧张的关注。与此同时，微软、谷歌等大型科技公司也派出采购团队在韩国与这些主要存储芯片供应商展开密集谈判，以争取更多 DRAM 和高带宽存储（HBM）供应资源。&lt;/p&gt;&lt;p&gt;而就在 2026 年 1 月的 CES 演讲中，英伟达 CEO 黄仁勋又更进一步为这股趋势给出了极具分量的判断。&lt;/p&gt;&lt;p&gt;他指出，围绕 AI 推理与上下文的数据存储正在形成一个「此前从未真正存在过的市场」，并预测其规模很可能成长为全球最大的存储市场之一，因为它在本质上承载着全球 AI 系统的工作内存（working memory）。黄仁勋强调，AI 的工作负载在访问模式、时延要求和数据生命周期上都与传统数据库和存储系统截然不同，因此现有存储架构难以满足需求，存储技术本身必须经历一次根本性的重构。&lt;a href="https://mp.weixin.qq.com/s/w3GRxO8EsPpZJMlhyTQFKA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3956f995-b6b7-4cd7-a15c-8899686328aa/1768905020049.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种底层架构的变革需求，正是当下 AI 基础设施面临的一大核心挑战。&lt;/p&gt;&lt;p&gt;现在，一家成立已过十周年的公司对这一挑战发起了冲锋。&lt;/p&gt;&lt;p&gt;1 月 15 日， XSKY 星辰天合在北京举办了主题为「&lt;strong&gt;数据常青 智算无界&lt;/strong&gt;」的 AIMesh 产品战略发布会，并宣布战略重心从「&lt;strong&gt;信息技术（IT）&lt;/strong&gt;」全面跨越至「&lt;strong&gt;数据智能（Data Intelligence）&lt;/strong&gt;」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qnx0oTH8RxRKYXCcZwibLWkLEzK3RJbKibDpVDvaMeZj5WZwU0q3NiaPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528868" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/07f63fe5-ffa4-4782-bf66-bdee7a9e2852/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这家成立于 2015 年 5 月的企业，已经在十年多的时间里从初创团队成长为一头独角兽，&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzAwNTc0OTM1NA==&amp;mid=2652426304&amp;idx=1&amp;sn=17daab312c04acd94feb1a5607f6d7f5&amp;scene=21#wechat_redirect" target="_blank"&gt;更是已然成为中国对象存储市场的领跑者&lt;/a&gt;，并肩负起了中国核心产业超过 &lt;strong&gt;5500 PB&lt;/strong&gt; 关键数据的安全重任。不仅如此，该公司的增长势头依然强劲：在近三年实现了超过 &lt;strong&gt;50% &lt;/strong&gt;的逆势高增长；随着业务对性能渴望的加剧，其全闪存占比已翻了三倍，达到了 &lt;strong&gt;35%&lt;/strong&gt;。大规模存储方面，XSKY 已经拥有了 &lt;strong&gt;280&lt;/strong&gt; 个 &lt;strong&gt;10 PB&lt;/strong&gt; 级以上的超级集群，甚至跨越了&lt;strong&gt;单机群百 PB&lt;/strong&gt; 的技术门槛。这每一个数字的增长，都是客户投下的一张张信任票，也构成了 XSKY 应对 AI 大爆发的底层底气。&lt;/p&gt;&lt;p&gt;从这些数字也看得出来，AI 大爆发正在催动数据中心的进化。&lt;/p&gt;&lt;p&gt;过去十年的 IT 时代，数据中心的功能类似于一座严谨的「图书馆」，价值核心在于数据的「存得进、找得到」。但在进入数据智能时代后，数据的价值正在从「被检索」进化为「被计算」，每一份文档和图片都正成为生成未来的燃料。&lt;/p&gt;&lt;p&gt;为了适应这种转变，企业的数据中心必须完成一次物种进化，从安静的图书馆演变为一座日夜轰鸣的「AI 工厂」。&lt;/p&gt;&lt;p&gt;面对大模型时代的算力博弈，XSKY 确立了清晰的战略定位：&lt;strong&gt;通过发布 AIMesh 全栈 AI 数据方案，XSKY 致力于打造开放解耦且绝对中立的数据底座，旨在破解企业私有高价值数据向智慧转化的效率瓶颈。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14EXuibnnVku5egumUibbibX6Z1T1fgCAuU7icnYWyZPCUGrkp0x7icDB4rJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528867" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f48cafe3-edd3-4fd5-8cf8-5ab3cd1d48bb/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为什么「专有数据」是 AI 时代唯一的护城河？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大模型技术快速迭代的当下，业界逐渐达成了一个共识：算法正在走向同质化。&lt;/p&gt;&lt;p&gt;正如 AI 大牛 Andrej Karpathy 指出的那样，大模型（如 Transformer）的算法实现非常简洁，通常只有几百行代码。他提出，在大模型时代，数据不再仅仅是燃料，数据就是「源代码」。因为人类不再通过编写逻辑代码来解决问题，而是通过策划、清洗和标注特定的数据集，让模型通过学习这些数据来获得专家能力。&lt;/p&gt;&lt;p&gt;而对于企业而言，当领先的模型架构和训练方法变得透明且易于获取时，企业真正的差异化竞争优势和护城河，就在于其自身拥有的独特「&lt;strong&gt;专有数据&lt;/strong&gt;」。这些数据是企业长年累月积淀下的独有配方，也是将通用大模型转化为具备垂直领域专家能力的燃料。&lt;/p&gt;&lt;p&gt;出于安全和合规的考虑，这些高价值的核心数据不能外溢到公有云，它们必须牢牢掌握在企业自己手中。因此，构建一个私有化、安全且可控的 AI 数据底座成为了企业的刚需。&lt;/p&gt;&lt;p&gt;XSKY 的角色正是守住数据安全的底线，让企业能将私有数据在内部安全地转化为智慧。&lt;/p&gt;&lt;p&gt;这种对数据价值的深度理解，已经在行业头部的实践中得到了验证。刚刚在 1 月 9 日成功登陆港交所的 MiniMax 便是典型的例子。作为全球 AI 领域从创立到上市最快纪录的最新创造者，MiniMax 的成功证明了在算法日益透明的今天，私有数据资产才是支撑企业估值与竞争力的核心。&lt;/p&gt;&lt;p&gt;目前，MiniMax 有 PB 级的数据存放在 XSKY 的存储平台上，其中包括最核心的训练数据与推理模型数据。对于这类处于商业化爆发期的头部 AI 企业而言，存储底座的稳定性直接决定了研发的连续性。&lt;/p&gt;&lt;p&gt;这种需求的变化也预示着基础设施职能的彻底改变。正如前文所说，过去的数据中心更像是一座安静的「图书馆」，核心任务是确保数据「存得进、找得到」。但在 AI 时代，数据中心必须进化为一座日夜轰鸣的「AI 工厂」，数据不再是静止的档案，而是被不断计算、不断产生价值的动态资产。XSKY 的战略目标，就是帮助企业的专有数据完成这一物种进化，让基础设施能够支撑起从数据准备到模型训练再到推理部署的全生命周期。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AIMesh 如何推倒阻碍 AI 效率的「三堵墙」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大模型训练与推理的实战场景中，传统的存储架构正面临严峻的挑战。这些挑战可以被总结成三堵墙：IO 墙、重力墙和内存墙。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;IO 墙&lt;/strong&gt;：当算力的吞吐速度远远超过存储的读写速度时，计算单元被迫进入空转等待状态，导致 GPU 利用率往往低至 30% 到 50%。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;重力墙&lt;/strong&gt;：随着数据体量的指数级增长，跨地域流动的高昂成本让数据逐渐沦为孤岛，形成了难以逾越的「重力墙」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;内存墙&lt;/strong&gt;：随着 AI 应用向长上下文和复杂智能体（Agent）演进，KVCache 的爆炸式增长让显存（HBM）撞上了物理极限的「内存墙」，导致硬件投入成本急剧攀升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wajnnAKlMk5IpymHrPRIGghcZx3jma1sibB5BtTOgUvS8NfNRJgrZjw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.9825517993456925" data-s="300,640" data-type="jpeg" data-w="917" type="block" data-imgfileid="503528901" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b60556c9-0193-4379-8df8-edddce1aafb1/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;典型的「内存墙」：2018 年至 2025 年期间，Transformer 模型尺寸每 2 年增长约 19 倍，而每个加速器的内存每 2 年仅增长约 1.9 倍。不仅如此，过去 20 年间，峰值计算能力增长了约 6 万倍，但 DRAM 带宽仅增长了约 100 倍，互连带宽也仅增长了约 30 倍。结果就是：处理器闲置等待数据。来源：ayarlabs.com&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;要推倒这些深层物理层面的效率障碍，不仅需要软件架构的创新，更需要与底层芯片性能的深度适配。举个例子，作为这一进程的见证者，芯片巨头英特尔与 XSKY 的合作已经跨越了第一个十年。从早期作为 Intel SPDK 技术最早的一批贡献者共同探索用户态轮询技术，到如今实现对最新硬件的 Day-0 级技术响应，这种长期的技术共创为 AIMesh 全栈 AI 数据方案的发布奠定了基础。&lt;/p&gt;&lt;p&gt;基于这种长期的软硬协同积淀，XSKY 通过 AIMesh 构建了一张面向 AI 工厂的数据与内存网，旨在打破这三堵墙，进而利用架构创新将技术参数转化为真实的业务价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshFS：打破 IO 墙，加速模型训练&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对 AI 训练中严峻的「IO 墙」挑战，XSKY 发布了专为 AI 训练而生的并行文件系统 &lt;strong&gt;MeshFS&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14jHrBMUZadPicpmkFvzL0PnlY95icA61y1zW3OwnDNAv0amkGichz4p4Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528869" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/266606c9-c20a-4462-8091-b8dec6a74916/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该系统将 XGFS 成熟的企业级协议栈与 XSEA 星飞全闪架构的 Shared-Everything 极速底座深度融合，为软件栈注入了强劲的性能心脏。&lt;/p&gt;&lt;p&gt;为了彻底破解算力在等待数据时的损耗，MeshFS 在以下三个维度实现了技术突破：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全协议兼容&lt;/strong&gt;：MeshFS 提供标准的 POSIX 语义，这意味着现有的 Python 或 TensorFlow 训练代码无需修改即可运行。更重要的是其实现了「一份数据，多协议互通」，数据清洗可以通过 HDFS 接口使用 Spark，训练过程通过 POSIX 接口使用 PyTorch，归档则使用 S3。数据在全流程中不需要搬家，原地即可被不同的业务流处理。MeshFS 也完美支持 Kubernetes CSI。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;线性的极致性能&lt;/strong&gt;：通过全分布式架构和元数据分片技术，MeshFS 的性能可以随节点数线性增长。系统引入了 Run To Completion 技术，将元数据处理延迟压低至微秒级。即使面对亿级规模的小文件数据集，依然能保持顺滑的访问体验。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;企业级管理与智能分层&lt;/strong&gt;：在提供目录 QoS、配额以及审计等完善特性的同时，MeshFS 支持智能分层能力。数据可以在全闪存层和低成本层之间透明流动，让用户能够以 Tier-2 的成本存储数据，同时享受 Tier-0 的训练速度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在性能实测中，MeshFS 凭借「一跳读」设计&lt;strong&gt;实现了顺序读带宽 30% 的提升&lt;/strong&gt;，同时&lt;strong&gt;依靠端到端 EC 写技术让顺序写带宽超出同类产品 50%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;此外，MeshFS 还针对英特尔新一代至强处理器的 AVX-512 与 AMX 指令集进行了深度优化。&lt;/p&gt;&lt;p&gt;在刚刚完成 IPO 的大模型企业 MiniMax 的生产环境中，MeshFS 提供了高吞吐、低延迟的 I/O 支持。无论是在大规模数据的 DataLoad 阶段，还是在关键的 Checkpoint 保存环节，MeshFS 都能有效保证训练效率。而在推理端，MeshFS 的高吞吐特性支撑了近万个推理服务在极短时间内上线，确保了海螺 AI 等核心产品在全球市场的竞争力。&lt;/p&gt;&lt;p&gt;在这种顶级 AI 企业的高强度实战中，XSKY 的技术架构经受住了考验，成为了支撑其走向资本市场的坚实底座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshSpace：推倒重力墙，实现全局流动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对「重力墙」，XSKY 给出的解决方案是 &lt;strong&gt;MeshSpace&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ialN0CV0cPjNBBJjwuIkSWFJcOybsiaF2kPUFv3RUyibgtgKcJRxHgWaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528870" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e33e3f1c-292a-497f-bed7-972c2994564b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为面向 EB 级数据的全局非结构化数据平台，MeshSpace 实现了从「单桶千亿」到「单桶 EB」的架构演进。&lt;/p&gt;&lt;p&gt;MeshSpace 通过三大核心能力，重新定义了大规模存储的治理模式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;平滑演进能力&lt;/strong&gt;：MeshSpace 能够直接纳管企业现有的 XEOS 集群。这意味着过去十年积累的数据资产无需经历痛苦的迁移过程，即可原地升级并融入新的 AI 训练流。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全局控制面统一&lt;/strong&gt;：这是架构设计中最具突破性的地方。通过统一的 DNS 接入，MeshSpace 将分散在不同物理机房、甚至是云端的物理集群抽象为一个逻辑整体。对于业务端而言，无论底层物理资源如何离散，都只有一个统一的入口。物理上是离散的，但在逻辑上，它们就是「一套存储」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据治理全局化&lt;/strong&gt;：MeshSpace 支持异构存储平台的统一调度。数据可以在全闪存、HDD 甚至磁带之间，根据数据温度和业务需求自由流动，确保热数据能够快速参与计算，冷数据能够自动沉降以降低成本。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在性能表现上，MeshSpace 带领对象存储正式迈入了「&lt;strong&gt;百万 OPS 单桶时代&lt;/strong&gt;」。单个对象存储桶可以每秒支持高达一百万次对象写入，以及数百万次对象读取，这一规格远超主流公有云产品的单桶性能上限。不仅如此，XSKY 还对 XScale 最底层的分布式 KV 引擎进行了彻底的优化，让 AI 训练中关键的&lt;strong&gt;大块写性能提升了近 50%&lt;/strong&gt;，同时将&lt;strong&gt;延迟降低了 30%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种架构精准击中了 MiniMax 等混合云用户的痛点。由于采用了混合云架构，数据孤岛带来的跨域调度成本曾是其核心挑战。MeshSpace 几乎是为其量身定制的解决方案，通过统一的全局命名空间收敛数据入口，业务端不再需要感知数据的真实物理位置，从而彻底解决了数据迁移带来的低效问题，极大降低了管理成本。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshFusion：击穿内存墙，降低推理成本&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;至于最后的内存墙，XSKY 推出了一种面向 KVCache 的「持久化内存」方案 &lt;strong&gt;MeshFusion&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;MeshFusion 运行在 GPU 服务器内部，通过创新的软件栈将本地 NVMe SSD 资源池化，转化为可供 GPU 直接调用的 L3 级外部内存。&lt;/p&gt;&lt;p&gt;不仅如此，MeshFusion 还拥有三大必杀技：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;零拷贝&lt;/strong&gt;：数据从 SSD 直通 GPU 显存，极大降低延迟。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致并发&lt;/strong&gt;：专为 KVCache 的小 IO、高并发写入优化，支持原子提交。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;协议自适应&lt;/strong&gt;：兼容 vLLM、SGLang 等主流推理框架，代码零修改。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实测数据显示，&lt;strong&gt;该方案能以 1% 的硬件成本实现近乎无限的上下文窗口，且性能与 DRAM 的差距保持在 10% 以内。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;云计算服务商 ZStack 表示，MeshFusion 的 SSD 扩展内存能力将显著降低 AI 服务规模化部署的门槛，并计划将其与自身的 AIOS 智塔平台展开深度集成。同时，XSKY 正在与英特尔联合预研基于 CXL 技术的内存池化方案，旨在彻底打破物理内存边界，为万亿参数模型提供充裕的资源池支持。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据常青与绝对中立的战略定力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在当前「百模大战」的背景下，技术架构与算法模型正处于剧烈的变动期。对于企业决策者而言，在极高的不确定性中做出确定的选择至关重要。XSKY 给出的答案是&lt;strong&gt;坚持开放解耦，做绝对中立的数据底座&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一战略背后蕴含着深刻的时间逻辑。在 XSKY 看来，算力硬件（GPU）的生命周期通常只有&lt;strong&gt; 3 到 5 年&lt;/strong&gt;，属于快速迭代的变量。相比之下，承载着企业智慧的代码、文档与影像等数据资产，其存续周期通常长达 &lt;strong&gt;10 到 20 年&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，XSKY 提出了「&lt;strong&gt;数据常青&lt;/strong&gt;」的理念，主张用一个稳固、长周期的底座去支撑上层快速演进的算力竞争，以不变的底座应对万变的未来。&lt;/p&gt;&lt;p&gt;为了实现这种确定的支撑，&lt;strong&gt;XSKY 始终坚持不绑定任何一种特定的算力平台&lt;/strong&gt;。无论企业选择英伟达，还是昇腾、寒武纪、摩尔线程、沐曦等国产芯片，AIMesh 都能提供统一且标准的数据服务。这种中立立场赋予了客户在算力博弈中的主动权，使其能够根据业务需求自由选择最合适的硬件资源，而不必担心被特定生态锁死。&lt;/p&gt;&lt;p&gt;这种对中立与解耦的坚守，也让 XSKY 在生态构建中获得了深厚的信赖。以 ZStack 为例，双方在云计算时代便是「存算分离」建设的优选组合，彼此被称为「背靠背的战友」。进入 AI 时代，这种默契得到了延续。ZStack 认为 AIMesh 的架构设计与其 AIOS 智塔战略高度契合，双方计划在智算中心建设中继续复制云时代的成功经验，共同成为智能算力基础设施中可靠、高效的算存基石。&lt;/p&gt;&lt;p&gt;从云计算到大模型，技术浪潮几经更迭，但 XSKY 始终致力于解决大规模数据存储与利用的核心需求。正如发布会所强调的，XSKY 的使命是做企业数据资产的守门人，同时也是 AI 之路的加速器。&lt;strong&gt;通过构建高效、可控的 AI 工厂，XSKY 将持续助力企业打破算力与数据的边界，实现智算无界。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;做数据资产的守门人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年 1 月 15 日举行的这场战略发布会，标志着 XSKY 将其十年的技术积累全面导向 AI 场景。AIMesh 全栈方案的发布，是 XSKY 面对智算时代给出的一份阶段性答卷。&lt;/p&gt;&lt;p&gt;回顾这十年的进阶历程，XSKY 对 AI 浪潮的布局早在数年前就已经开始。在 2022 年，公司便预判到了 AI 对于极致性能与数据治理的迫切需求，并投入研发了 &lt;strong&gt;XSEA 全闪底座&lt;/strong&gt;与&lt;strong&gt; EasyData 数据管理平台&lt;/strong&gt;。作为 Shared-Everything 架构的极速底座，XSEA 已经通过了金融核心交易与自动驾驶算力中心等严苛场景的验证，为今天的 MeshFS 提供了澎湃的性能心脏。而 EasyData 则作为数据编排与治理的中枢，面向从采集、清洗到归档的完整链路提供全局管理，确保了 AI 数据全生命周期的有序流动。&lt;/p&gt;&lt;p&gt;正是基于这些关键技术点的长期深耕，XSKY 才能在今天完成从「单点极致」到「全局统领」的架构升维。这一战略升级的核心目标在于破解企业私有高价值数据向智慧转化的效率瓶颈。&lt;/p&gt;&lt;p&gt;在未来的竞争中，算力硬件的生命周期可能只有 3 到 5 年，但承载企业智慧的数据资产却要存续 10 到 20 年。XSKY 将继续坚守「数据常青」的理念，通过提供开放且解耦的基础设施，支撑上层快速迭代的算力竞争。作为数据资产的守门人，XSKY 同时也是企业 AI 之路的加速器。在智算中心需求爆发的未来，XSKY 将持续助力企业打破存储与计算的边界，确保私有数据资产高效转化为智能优势。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
