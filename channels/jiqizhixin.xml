<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>明天上市，MiniMax上市额度已经被抢疯了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 22:40:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26e4c639-7b05-4527-a284-c3fc0d753b51/1767883209855.png" style="width: 700%;" class="fr-fic fr-dib"&gt;即将于 1 月 9 日敲钟上市的大模型公司 MiniMax，创下近年来港股 IPO 机构认购历史记录。此次参与 MiniMaxIPO 认购的机构超过 460 家，超额认购达 70 多倍。&lt;/p&gt;&lt;p&gt;此前的认购记录属于宁德时代，其在 2025 年登陆港股市场时，剔除基石后超额认购 30 倍。&lt;/p&gt;&lt;p&gt;与此同时，此次参与 MiniMax 国配订单的需求达到了 320 亿美元，最后超过 460 家机构实际下单了 190 亿美元。剔除基石部分，此次 MiniMax 的国配认购超额到 79 倍左右。&lt;/p&gt;&lt;p&gt;此次 MiniMax 备受头部基金的青睐。这些下单的机构中不乏众多的长线基金及国家主权基金。包括新加坡主权基金、南非以及中东、加拿大等多家主权基金认购金额超过 10 亿美金。与此同时，这些长线基金的认购订单总额超过 60 亿美金。&lt;/p&gt;&lt;p&gt;除了国配部分外，一些外资长线基金及国家主权基金也参与了 MiniMax 的基石认购部分。公开数据显示，MiniMax 的 14 家基石，其中包括了中东国家主权基金阿布扎比基金、韩国长线基金未来资产等。&lt;/p&gt;&lt;p&gt;1 月 8 日下午的暗盘显示，MiniMax 开盘后一路上涨，最高曾达到 211.2 港元每股，最低也曾达到 180 港元每股，最后收盘价为 205.6 港元每股，涨幅 24.6%。&lt;/p&gt;&lt;p&gt;MiniMax 的收入来源主要有两部分，AI 原生产品、开放平台及其他基于 AI 的企业服务，其中 AI 原始产品包括大语言模型、视频生成模型等于 2025 年 6 月底的收入达到 3802 万美元，占比超过 70%，而平台及企业服务部分的收入则为 1541 万美元，占比则为 28.9%。值得一提的是，截至 2025 年 9 月底，AI 原生产品累计用户达 2.12 亿，其中付费用户超过 177.1 万。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Jp34LnMTxyu2giauBhfLMKibUEFPFyd2rfTDRPIqTLBSBLuL4GQMviaTmO1oR8QE7ftKicIf6uJVxSsvbzn2ziceWJw/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=0" alt="图片" data-ratio="0.47685185185185186" data-w="1080" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/48f4877a-cee5-4239-b9e8-18585ed09e92/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;截至 2025 年 9 月底，MiniMax 的亏损为 1.8 亿美金左右，而现金还有超过 3.62 亿美金。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Jp34LnMTxyu2giauBhfLMKibUEFPFyd2rfCpGicicCSCHXoaQQxLEfdAwiaUb4sEeWDhM4xtB05libUkHbtq2Yic0efibw/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=1" alt="图片" data-ratio="0.5148148148148148" data-w="1080" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d6cc43e6-2603-4071-a54c-5a74fda08c7f/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;部分在港投资者表示，MiniMax 的商业模式相对清晰，而且逐步实现多元化的营收方式 &amp;mdash;&amp;mdash; 这给了他们对于 MiniMax 未来实现收支平衡的信心。MiniMax 的招股书显示，其下变现的方式包括多款产品的订阅及付费等。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Jp34LnMTxyu2giauBhfLMKibUEFPFyd2rfLjejiab7DyicD8ScCniaUYCME1HpP9xOrNe6h37Gicaxtu18xVDdwCe61g/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=2" alt="图片" data-ratio="1.349074074074074" data-w="1080" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/54e2027e-2fd3-4b9e-ba9c-b6f8f882e726/640.png" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>拓宽百年奥运「赛场边界」，阿里云AI让人人皆可上场</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 17:57:04 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d46112cf-3d04-41ae-a1a3-f587aee9e249/1767865739639.png" style="width: 700%;" class="fr-fic fr-dib"&gt;先给大家看个视频，你能分辨出哪个是 AI 生成的吗？&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9b44ecdc-6387-4276-a035-d7cb6c5db3de/1767865751698.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频来源：tiktok 博主 @tkp..1001&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;「真人拍摄还是 AI 生成」，如果搁一年前，这个问题还很容易回答，因为细节处总有一眼 AI 的破绽，但现在，真与假的界限已变得愈发模糊。&lt;/p&gt;&lt;p&gt;越来越多「真实」的视频，评论区里都在争论「这是 AI 吧？」而那些真正由 AI 生成的内容，反倒被当成真实拍摄。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527231" data-ratio="0.5916666666666667" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g3PZU40BlbM0tr7JG4QmvALxm8xWq4VBBK0CbUPXa5cia6Somh5TP3Gw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d5574068-aee1-480a-acf6-e2b639b0dd24/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;AI 视频生成技术的进化速度快到飞起，并正渗透进我们生活的方方面面。随之而来的问题是：我们究竟要如何与这些技术共处？&lt;/p&gt;&lt;p&gt;破解这一难题的钥匙或许就藏在人类的想象力中。技术的超越不该只在于对现实的复刻，更应在创新应用中想象更美好的未来。&lt;/p&gt;&lt;p&gt;站在这个视角，阿里云给出了一个颇具想象力的答案：2026 年米兰冬奥会。&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5c56fe58-cdb5-4565-9dda-242041cab7f4/1767865888788.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;就在冬奥会倒计时 30 天之际，&lt;strong&gt;作为官方云服务合作伙伴的阿里云，拉着国际奥委会以及⽶兰冬奥组委会搞了波大的，共同发起一场全球 AIGC ⼤赛&lt;/strong&gt;。&lt;/p&gt;&lt;section data-id="119085" data-pm-slice="0 0 []" data-tools="135编辑器"&gt;&lt;section&gt;&lt;section data-pm-slice='5 4 ["para",{"tagName":"section","attributes":{"data-tools":"135编辑器","data-id":"119085","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"margin: 10px auto;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g2FPjIaNvwBANVeicSePLROutzLhHEiarCTSJLEWJAZeAL7C6M8THibMGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562037037037037" data-type="png" data-w="1080" data-imgfileid="503527335" data-aistatus="1" data-original-style="vertical-align:baseline;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6e284af2-cf6f-47f1-8cb3-c5e0bee84ecb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role="animate" data-width="100%"&gt;&lt;section data-divisor="1" data-width="400%"&gt;&lt;section data-width="25%"&gt;&lt;/section&gt;&lt;section data-width="25%"&gt;&lt;section&gt;&lt;section&gt;&lt;section data-width="100%"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gGsPLickdujoibr14d1iczZCnmbBEx30rWTS2HAjiaicEP1ibJjiceVMxnqbXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562037037037037" data-type="png" data-w="1080" data-imgfileid="503527336" data-aistatus="1" data-original-style="vertical-align:baseline;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/507cdd89-bc70-4653-83ba-897162555fc3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-width="25%"&gt;&lt;section&gt;&lt;section&gt;&lt;section data-width="100%"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gqZVXRNianDibA3XeuzTlibptpUqVibkBY0Djvpku5lmqZySufjUzn1kRDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-imgfileid="503527338" data-aistatus="1" data-original-style="vertical-align:baseline;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/9afef0d4-2208-4171-9593-3b5442c7bcd7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-width="25%"&gt;&lt;section&gt;&lt;section&gt;&lt;section data-width="100%"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gFCNNGyAhzWOp2L86c7DZ5XQydp68UR0bIxfXq0vLXPG5tJoRPn40nA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-imgfileid="503527337" data-aistatus="1" data-original-style="vertical-align:baseline;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/44d3f6bc-9ca8-46bc-81cd-3f0e78051f22/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;大赛 Slogan 为「YOUR EPIC VIBE」，正好与本届冬奥口号「IT&amp;#39;s Your Vibe」（意展你风采）遥相呼应。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;大赛规则简单粗暴：只需用阿里云的「&lt;strong&gt;万相大模型&lt;/strong&gt;」，在花样滑冰、短道速滑、高山滑雪、单板滑雪经典项目中选一个，生成一段冬奥视频，就能参赛。&lt;/p&gt;&lt;p&gt;除了万相大模型本身，阿里巴巴的 AI 产品生态同样为本次大赛提供了全栈式支持，包括开源开放的开发者社区 Modelscope、AI 创作工具通义万相、堆友，为不同类型、不同渠道的参赛者「保驾护航」。&lt;/p&gt;&lt;p&gt;国际奥委会还直接放话，他们将从这四个项目中各选 25 个最佳作品，纳入奥林匹克博物馆收藏，并组合成奥运史上首个 AIGC 数字艺术影像作品集《YOUR EPIC VIBE》。&lt;/p&gt;&lt;p&gt;这意味着，自 1896 年现代奥运首次举办以来，AI 第一次以这种方式被写进奥运历史。&lt;/p&gt;&lt;p&gt;更刺激的是，Top 100 中将评选出 10 位在叙事创意、情感深度和美学构图上表现最好的获奖者，他们还能直接拿到米兰冬奥会现场门票。&lt;/p&gt;&lt;p&gt;大赛官网：https://summit.aliyun.com/aigcchampionship&lt;/p&gt;&lt;p&gt;AI 视频生成技术卷到现在，终于不只是在社交媒体上刷存在感了。它正以一种谁也没想到的方式，成为奥运历史的一部分。&lt;/p&gt;&lt;p&gt;而要达成这一成就，万相 Wan2.6 凭借其强悍的视频生成能力，化作了参赛者手中最强的那把利器。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用 AI 创造冰雪世界，为何独独选择了阿里云？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在去年 12 月 AI 视频生成大模型又一波涌现的大潮中，阿里云的 Wan2.6 登场。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gNvWYdhbGaycynb3NmcqclXzHkXKSXxntkSBlFdGIMcE7UjGyohjRwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.8629629629629629" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527240" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1a263491-db32-4018-88ae-f0bc4b6bf3d7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;Wan2.6 面向专业级影视制作和图像创作场景，进一步提升了画质、音效、指令遵循能力，并新支持多镜头叙事及最长 15 秒生成。此外&lt;strong&gt;在国内首次支持角色扮演（Reference-to-video，R2V）功能&lt;/strong&gt;，本人可以入镜，并用自己的声音出演 AI 视频。&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gbVB6KibgaJu2upjpkzaaIJqUwQc2WdTK0RwamqZ9HUHAPQiaYCZhjhOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5148148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527360" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/29c0a847-cdc9-4636-a35b-17048b7151c3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;体验地址：https://tongyi.aliyun.com/wan/&lt;/p&gt;&lt;p&gt;对于此次冬奥赛场上的四大经典冰雪项目，Wan2.6 表现出了极高的可玩性。&lt;/p&gt;&lt;p&gt;我们上手测试的结果说明了这一点。&lt;/p&gt;&lt;p&gt;只见一只可爱的雪人从高山之巅快速下滑，身后拉出一条清晰而绵长的雪线，红色帽子在疾驰中随风摇摆，看起来十分的童趣。如果我不告诉你这是 AI 生成的，可能你还以为这是哪部动画片中的场景呢！&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ce28a79d-75f9-49e1-b4fc-02a96253c88b/1767865967752.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;毛茸茸的怪兽在高山之巅飞速直下，双脚踩着雪板完成流畅的滑雪动作，身体随着地形起伏自然摆动。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gdF2uiaibWbG6EjXoB8SeiaUtibPM2FPqibSz7gTDRuwOxMWmFdvD6kyeT4A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.5546875" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503527247" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/fef54367-36f9-47b7-9f39-b55002a1f321/640.gif" data-order="0" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;小王子也来雪山之巅滑雪了，身披围巾、脚踏雪板，仿佛开启了一段属于自己的冰雪冒险，纯真而浪漫。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gbhY9NBq50czEBLFqvMtRgGZJicriab4UPtsBfaWHgnmDLdzC8TdfxndA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="1.4962593516209477" data-s="300,640" data-type="gif" data-w="401" type="block" data-imgfileid="503527248" data-aistatus="1" data-original-style="width:562px;height:841px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/a98355a7-4b4e-4431-bf54-3e48fe0482e1/640.gif" data-order="1" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;穿越千年的兵马俑也献上一段花滑表演：&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f028f99a-3806-46c4-ae26-24bdbf1d21db/1767865983839.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;除了文生视频、图生视频，现在你也可以指定角色来生成了。Wan2.6 的角色扮演功能，可以将你输入的参考视频进行二次创作，甚至是你亲自上场。&lt;/p&gt;&lt;p&gt;我们先来「呼叫奥特曼」上场速滑。只见他起滑、加速、入弯一气呵成，动作那叫一个专业，完全不像是第一次跨界。专业程度甚至让人怀疑他是不是偷偷报过集训班。&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6dd047db-96d4-4b1e-9fe2-c62b8536ed87/1767865999350.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;然后再让马斯克来段花样滑冰，看起来也是有模有样：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gf0TJrib7icYr0OxHwEribj4h2CsjcXLwqDg2UWTKYMiaH0qv9H0ts9rAicw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.551948051948052" data-s="300,640" data-type="gif" data-w="1078" type="block" data-imgfileid="503527260" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/f28416bb-e232-4783-9cd1-a516e22ad369/640.gif" data-order="2" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;与此同时，Wan2.6 在动态表现和视觉冲击力上同样可圈可点。在这一示例中，镜头贴近雪面，紧跟雪板高速前行，低机位带来的速度感与冲击力被充分放大。&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/32c1a78c-de9e-4594-9d93-66d154a88138/1767866014341.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;以前在滑雪场，常能看到有人踩着滑板、扛着相机一路跟拍，冒着不小的风险，才能换来几个漂亮镜头。现在，这种高难度的跟拍视角已经不再依赖人工完成，Wan2.6 可以直接在生成过程中自动实现稳定、贴近动作的动态运镜：&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f8647bf7-8973-4a1a-8344-6141d6f70745/1767866028976.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;慢镜头同样稳得住。高速下滑被自然放慢的那一刻，雪板切雪的力道、雪屑被甩起又在空中翻滚的轨迹一一展开，原本一闪而过的速度感被拆解成清晰可见的细节。这感觉就像在滑雪场里按下了电影级慢放键。&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7927a222-8b59-440a-8899-47ca54763106/1767866039772.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;就算是高难度的多人场面，Wan2.6 依然能够稳稳驾驭。多名滑雪者同时出现在画面中，彼此之间的相对位置、运动方向与节奏保持清晰，没有出现人物混叠或动作错乱。&lt;a href="https://mp.weixin.qq.com/s/_iaiwdraikWZGd49O4zocQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8fd4fdc5-9cd3-4804-9bf6-a2e536f2f800/1767866055640.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;通过上述示例可以看出，Wan2.6 的优势并不在于某一个「炸点」，而是在冰雪运动中「力与美」的呈现上已经达到了相对成熟的水准。&lt;/p&gt;&lt;p&gt;在高速运动、多人互动以及音画同步等关键场景下，Wan2.6 展现出超高的性能。无论是虚构角色还是真人形象，都能够被自然地融入运动场景之中，完成连贯而完整的表演，体现出对运动节奏与视觉叙事的成熟把控。&lt;/p&gt;&lt;p&gt;进一步看，这种稳定性也体现在镜头层面：生成过程中，镜头并非被动记录动作，而是会随着运动推进自动调整视角，在关键节点完成切换，使画面具备基本的分镜逻辑与节奏变化，可以说是深谙运动力学与视觉美学的「数字导演」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;视频生成的多面手，Wan2.6 背后藏着这些「杀手锏」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;长期以来，视频生成被认为是 AI 领域最难攻克的堡垒之一。不过从 OpenAI Sora 开启视频「暴力美学」开始，这个领域在各个环节进入到了进化的快车道。&lt;/p&gt;&lt;p&gt;一开始大家追求的目标很简单，让画面动起来；后来一步步加码，提出了更多更高的要求，比如对复杂物理规律的极致模拟、影视级高清画质、原生音画同步、画面连贯与逻辑统一，最终目标是无限接近真实视频。&lt;/p&gt;&lt;p&gt;如今，升级到 2.6 版本的万相大模型已修炼得「炉火纯青」。&lt;/p&gt;&lt;p&gt;首先做到了&lt;strong&gt;超真实还原&lt;/strong&gt;。实现这一点需要解决几个深层次的技术挑战，包括物理规律的准确模拟、时序一致性、细节高度还原、原生音视频的逻辑一致等。&lt;/p&gt;&lt;p&gt;Wan2.6 提供了音画⼀体的多模态参考⽣成能⼒，通过对输⼊参考视频进⾏多模态联合建模与学习，最终实现从画面到声音的全感官一致性保持与迁移。这种「镜像级人物重建」可以精准捕捉并重建你的形象，就连每个微表情都生动至极。&lt;/p&gt;&lt;p&gt;其次能输出&lt;strong&gt;衔接连贯的多镜头&lt;/strong&gt;。视频生成中精准的分镜控制，要求 AI 不仅要生成连贯的画面，还要像人类导演一样理解空间调度、镜头切换和叙事连续性。&lt;/p&gt;&lt;p&gt;Wan2.6 可以一键完成单人、多人、人与物合拍的视频，还能自动实现多镜头切换。这意味着，视频生成不再是碎片拼凑，并且不管怎么切镜头，视频里的主体都能保持像素级的统一，几乎不会出现镜头一换、主角换脸的尴尬情况。&amp;nbsp;&lt;/p&gt;&lt;p&gt;最后保证&lt;strong&gt;叙事完整不偏离主题&lt;/strong&gt;。生成一段完整的叙事视频，远比几个孤立的炫酷镜头困难得多，其核心挑战在于如何让 AI 具备时间记忆和逻辑常识。&lt;/p&gt;&lt;p&gt;Wan2.6 很好地解决了这些挑战，最长支持 15 秒 1080P 视频生成，并能轻松搞定完整叙事的 Vlog 视频。这使得该模型在短剧制作等专业场景具有广阔的应用前景，只要提示词写得好，输出的视频可直接拿来用，省力又省钱。&lt;/p&gt;&lt;p&gt;一系列底层能力的突破，让 Wan2.6 打破视觉、听觉与物理规律之间的藩篱，为创作者提供了一个生产力级别的视觉生成引擎。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI for all，在奥运这块阵地「登陆」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;去年 7 月，即将成为 OpenAI 史上首位应用 CEO 的 Fidji Simo 发表了一篇文章，主题为《AI：赋能所有人的终极源泉》（AI as the greatest source of empowerment for all）。这篇刷屏的就职檄文再一次让「AI 全民可用」成为热议的焦点。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gze3iaTldKDkO2sJsPxsdl3ULAOpFyTRJv8ibSaeUE9Q8RpTbs2gkzAjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.8740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527278" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/6a2f747c-af83-4edd-a598-ba0f82d9ee4a/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;文中写到，「我相信 AI 将为更多人带来比历史上任何其他技术都多的机遇。如果我们能做好这一点，AI 将给予每个人前所未有的力量。」但同时，这些机遇并不会凭空出现，不仅要求 AI 达到较高的水准，还要有像阿里云这样勇于创新的 AI 玩家。&lt;/p&gt;&lt;p&gt;现在看来，这场全球 AIGC 大赛成为了「AI for all」的实践阵地。&lt;/p&gt;&lt;p&gt;以往，参与奥运的方式要么花很多钱去现场观赛呐喊，要么在电视机或电脑前守候。如今，AI 终于赋予了每一个普通人更沉浸的奥运体验。&lt;/p&gt;&lt;p&gt;在高山滑道、花滑冰场或单板 U 型场，你我同样可以成为万众瞩目的主角。这正是奥运级 AI 科技首次大规模应用于粉丝互动所产生的魅力。&lt;/p&gt;&lt;p&gt;正如 Fidji Simo 所强调的，「如果我们能够让智能技术无处不在、人人可及，就能驱动人类历史上最大的机遇引擎，并帮助更多人过让更好的生活」。阿里云掀起的这场以万相大模型为主导的交互范式变革，正以自己的方式一步步将这样的愿景落地。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>博士申请终极指南：「从准备到抉择」手把手教你拿下理想offer</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 17:48:03 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/613d528d-4bed-4e3f-99d1-3193612184ca/1767865483636.png" style="width: 700%;" class="fr-fic fr-dib"&gt;又快到博士申请季。这是一份复杂而又繁琐的工作：无尽的院校调研、纠结的方向选择、厚重的材料准备，以及决定命运的面试&amp;hellip;&amp;hellip;不可能不感到迷茫、焦虑，甚至怀疑，这一切的辛勤付出，究竟能否换来梦想院校的入场券？在面试官眼中，「完美候选人」究竟应该具备哪些条件&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;最近，加州大学圣地亚哥分校认知科学家兼助理教学教授 Lucy Lai，结合&lt;strong&gt;她以往哈佛大学神经科学博士项目申请者的经验，七年多的模拟面试经验，以及作为&lt;/strong&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;前哈佛博士项目面试官的经验&lt;/strong&gt;&lt;/span&gt;，给出了一份「内部参指南 」&amp;mdash;&amp;mdash;《关于博士申请的一切》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L8RWZYcYhBfHB4dicIZd0ITKib6TiagHUeAHL9tU664coiaicasSdlxZ6r3g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4101851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526343" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3305f7a1-db71-4733-be73-ad8e77bd7b3d/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;《指南》中包括常见的博士面试问题与如何做出最好的回答、招生决定是如何做出的，以及对招生委员会所看重的素质和因素进行的详细说明等。&lt;/p&gt;&lt;p&gt;接下来，我们就具体来看看指南是如何给出申请建议的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一般应用技巧&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何才能确定自己想读研究生？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在所有的准备开始之前，需要先明确一个问题：你真的决定要读研究生了。Lucy Lai 建议，思考过程中如果觉得自己的申请材料还不够优秀，可以考虑休学一年或几年。而判断申请是否足够优秀的一个好方法是咨询你的研究导师。他们阅读和面试过无数研究人员和潜在的研究生，可以很轻松地告诉你在申请过程中可能遇到的情况，以及应该申请哪些学校等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;应该何时开始申请？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一定要尽早开始！申请过程耗时很长，而且会占用大量时间和精力，尤其是在你大四繁重的课程之外（如果你还在读本科的话）。Lucy Lai 建议，在你计划申请的申请季之前的那个夏天，就应该开始缩小你想申请的学校范围，并列出你感兴趣的首席研究员（PI）名单等。一旦你理清了这些，整个过程会变得更加具体和有条理，就可以开始为特定的学校撰写个人陈述了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;应该申请哪些类型的课程和学校？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这取决于你的兴趣。相似专业，例如心理学和神经科学之间最大的区别在于你将要修读的课程以及你可能会遇到的同学类型。博士生涯中最具决定性的环境无疑是你的论文实验室，因此，在最初的一两年之后，选择哪个专业可能就没那么重要了。&lt;/p&gt;&lt;p&gt;你唯一需要考虑、了解的是，你心仪的导师是否招收来自该专业的学生（因为某些专业的经费结构不同）。即使他们从未招收过来自该专业的学生，只要你的研究兴趣与他们相符，他们也可能持开放态度。&lt;/p&gt;&lt;p&gt;最后但同样重要的是，一定要问问你的导师（博士后 / PI 等）他们推荐哪些学校、项目。他们是宝贵的资源，更了解各个项目的声誉，并且可以推荐你可能感兴趣的 PI / 实验室。还有一点就是，他们在领域内工作多年，人脉很广，甚至可能在你申请之前就为你美言几句。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;应该申请多少所学校？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这取决于你感兴趣的实验室数量，一条普遍适用的原则是，你应该申请至少有 2-3 位你感兴趣的导师的学校。这样做很重要，因为万一你真正感兴趣的实验室最终不适合你，你还有其他选择。对于需要轮转的项目（大多数生物科学项目），拥有几位你想合作的导师就显得尤为重要，这样你才能体验不同的轮转，并最终选择一个最适合你的论文实验室。&lt;/p&gt;&lt;p&gt;Lucy Lai 建议，最好是申请 6 到 10 所学校，这既能给你足够的选择余地，又不会让你被申请费用和文书写作压垮。Lucy Lai 当时申请了 14 所，结果是太多了，因为时间不够，不得不拒绝了一些面试邀请。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;申请费用太贵了！如何才能免除申请费&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;刚说到申请学校的费用非常高昂。例如，斯坦福大学的申请费是 125 美元。如果申请 6 到 10 所学校，仅仅为了申请博士项目，就可能要花费 1000 美元！&lt;/p&gt;&lt;p&gt;其实鲜为人知的是，大多数学校都提供申请费减免。有些学校的申请费减免需要你提交 FAFSA（联邦学生助学金申请表）或其他经济困难证明，而有些学校则只需要你写一两段简短的文字，说明你为什么想申请这所学校。&lt;/p&gt;&lt;p&gt;Lucy Lai 通过在网上搜索到她所申请学校的申请费减免政策，以及给招生主任发邮件询问，省下了大约 600 美元的申请费。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;应该在申请前联系项目负责人吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个问题总是众说纷纭，Lucy Lai 认为，如果你对他们的实验室真的感兴趣，可以发邮件表明打算申请他们的学校，并询问他们明年秋季是否招收研究生。不过，不要指望这封邮件会对你的申请过程有很大帮助，如果导师不在招生委员会，申请审核人员很可能看不到这条信息。&lt;/p&gt;&lt;p&gt;在申请前联系导师主要是为了你自己，如果你最终有机会面试你联系过的导师，这确实会带来一些主观优势，他们可能会记得你之前对实验室或学校感兴趣，从而让面试有个好的开始。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;需要准备的申请材料有哪些&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;几乎所有学校都会要求以下物品：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;成绩单、简历&lt;/strong&gt;：如果还是在读，最好保证成绩优异，并尽可能做到最好，如果已经毕业那就要有科研经历 &amp;mdash;&amp;mdash; 很多人在本科毕业后会在实验室担任研究助理一到两年，以进一步提升简历，甚至发表论文。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;GRE 成绩&lt;/strong&gt;：（从 2022 年的政策来看，这一项措施即将取消！）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3 封推荐信&lt;/strong&gt;：推荐信的重要性几乎与个人陈述（SoP）不相上下，甚至可能更重要，这体现了你的研究导师和 PI 通过观察你在他们的实验室工作，对你、你的职业道德以及你在研究生阶段取得成功的能力的了解（关于该找谁写推荐信，最佳方案是，如果你有 3 次不同的研究经历，那就请你的三位导师分别写一封推荐信）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;宗旨声明&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;部分学校会要求提供以下材料：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多元化 / 个人经历陈述说明&lt;/strong&gt;：个人陈述（SoP）是申请材料中极其重要的部分，而且在申请之前你仍可以完全掌控它的撰写。几乎所有学校都会要求你撰写一份个人陈述作为主要文书。好消息是，个人陈述的题目几乎都大同小异，因此你无需为每所申请的学校都进行太多修改。虽然看起来涵盖的内容很多，但最终都可以归结为：你为什么想读博士学位？之前有哪些研究经验？你攻读博士学位期间想研究什么？你希望与这所学校的哪些人员合作？为什么选择这所学校？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;研究声明&lt;/strong&gt;：也就是你实际做了什么。如果学校要求提交研究陈述（RS），那你的个人陈述会有更多篇幅来阐述你对科学产生兴趣的原因，而研究陈述则主要用于详细描述你参与过的研究项目。【Lucy Lai 印象里，她还没有见过哪所学校要求提交全部三份材料（个人陈述、研究经历陈述和多元化陈述）】。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;其他随机简答题&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;面试&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;提交了申请材料后就是等待消息了。这里需要注意的是：&lt;strong&gt;申请过程中你的首要目标是获得面试机会，但并非所有项目都会安排面试！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Lucy Lai 记得，她的大多数工程系朋友都是直接根据在线申请结果被学校录取或拒绝的 &amp;mdash;&amp;mdash; 只有被录取的学生才会被邀请去学校参观。然而，那些会安排面试的项目（大多数生物科学专业）会希望在做出最终录取决定之前先与你见面。&lt;/p&gt;&lt;p&gt;记住，这也意味着你也在面试这所学校，以确定你是否真的愿意在接下来的五六年里在这个城市或研究环境中度过。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如果收到面试邀请，就已经进入了申请流程的下一阶段。&lt;/strong&gt;值得一提的是，只有排名前 5% 到 15%（具体比例取决于学校）的申请者才能获得面试机会。学校会安排你飞往目的地，并支付所有费用入住豪华酒店。Lucy Lai 去年 12 月收到了学校的面试通知，面试从 1 月中旬开始，一直持续到 3 月初。&lt;/p&gt;&lt;p&gt;既然已经通过了纸质申请阶段，接下来就该好好展现自己的个人风采。要自信，坚信自己已经掌握了所有需要的信息：之前的研究经历、研究兴趣，以及为什么想去这所学校 &amp;mdash;&amp;mdash; 这些你都应该写在个人陈述里。再加上一点真诚的热情，那面试体验就会很顺利。&lt;/p&gt;&lt;p&gt;实际上，很多人都会比实际情况紧张得多，但几次面试之后，就会发现这其实只是一次对话。大多数导师都是真心想了解你，看看你是否适合这所学校。&lt;/p&gt;&lt;p&gt;需要注意的是，大多数面试只有 30-40 分钟，可以带个小笔记本，用来在面试过程中或面试间隙记下一些东西，或者以防需要画图解释某些内容（其实大多数项目负责人的办公室都有白板）。除此之外，真的没必要带任何东西，包括打印出来的图表、笔记本电脑、简历（反正他们已经有了）。&lt;/p&gt;&lt;p&gt;一般情况下，面试结构主要包括以下几个方面：介绍自己之前的研究、读研究生期间想研究什么或想做什么样的实验、听面试官介绍他们的实验室或研究、对项目或学校的疑问等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;哪些人能上岸？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面试结束后，很难判断录取决定是如何做出的，但 Lucy Lai 直觉认为，决定录取结果的关键在于研究方向的契合度和整体印象。另外她也注意到其他几个因素，这些因素揭示了导师和招生委员会真正看重的是什么：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;与受人尊敬且知名的人士共事&lt;/strong&gt;：比如谁在你的推荐信中为你加油打气？Lucy Lai 的一位导师曾在面试中告诉她，他会毫不犹豫地录取她，因为推荐信基本上都是他三个最好的朋友写的。学术界的残酷现实是，有知名人士的支持对申请甚至其他方面，都是巨大优势。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;能够清晰阐述你对研究项目的贡献以及项目具体内容&lt;/strong&gt;：几位项目负责人曾要求 Lucy Lai 详细说明具体工作内容，以便了解她对项目的参与程度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;能够就科学展开生动有趣的对话&lt;/strong&gt;：无论是 PI 的研究领域、你自己的研究领域，还是整个科学领域都可以。但这并不意味着必须无所不知，了解大概就行，重要的是积极倾听并参与到深入的科学讨论中，有助于他们了解你的思维方式、积极提问。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;匹配度&lt;/strong&gt;：说到底，招生其实就是围绕着「匹配度」这一模糊概念展开的，这是一个双向过程：项目方在评估你是否能适应他们的研究环境，而你也在评估他们，看看你是否能在那里感到快乐。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;之后，Lucy Lai 曾受邀担任哈佛大学神经科学博士项目的学生面试官。作为面试官，她面试了 5 位申请者。结合她的经验，她又从面试官角度分析了一下，面试者应该具备的特质，包括：谦逊、好奇心、创造力、韧性、勤奋、友善和正直。她认为，它们是成为一名优秀科学家所必需的，也是希望在同行和同事身上看到的品质。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何选择学校&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果有幸收到录取通知书，在开心之余要开始思考到底该去哪个学校，必须决定未来 5-7 年将在哪里度过。&lt;/p&gt;&lt;p&gt;Lucy Lai 的一个建议是，要想「客观」选择学校，一个好方法是制作一个表格，列出所有学校，并给每个决策类别（例如科研契合度、院系文化等）打分（0-10 分）。&lt;/p&gt;&lt;p&gt;这种方法看似客观，实则迫使人们给一些主观因素打分。这样做帮助自己意识到自己真正看重的是学校或项目的哪些方面，之后自己的选择就会更为清晰。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/drlucylai&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://lucylai.com/blog/gradapps&lt;a data-topic="1" href="javascript%3A;"&gt;#how&lt;/a&gt;-do-i-know-i-want-to-go-to-grad-school&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>「听觉」引导「视觉」，OmniAgent开启全模态主动感知新范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 17:43:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/9586af29-b583-43a0-84c1-ba1ca919211d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;针对端到端全模态大模型（OmniLLMs）在跨模态对齐和细粒度理解上的痛点，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;浙江大学、西湖大学、蚂蚁集团联合&lt;/strong&gt;&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;提出 OmniAgent&lt;/strong&gt;。这是一种基于「音频引导」的主动感知 Agent，通过「思考 - 行动 - 观察 - 反思」闭环，实现了从被动响应到主动探询的范式转变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在 Daily-Omni 等多个基准测试中，其准确率超越 Gemini 2.5-Flash 和 Qwen3-Omni 等开闭源模型。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNv6qB2ziclq6hn5CyZGnpu5eokicO6a4rIYZ2uhwW2N0xtrzIefGiaQLgw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526982" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c59b8484-1e97-4922-890b-644e6e481130/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/pdf/2512.23646&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文主页：https://kd-tao.github.io/OmniAgent&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;发起实验室ENCODE LAB：https://westlake-encode-lab.github.io/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNWwS4Voc6LgyHhIDBsLsOOEqjABPB47kReOL1znGKcjnskOeH0GqcBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.33181818181818185" data-s="300,640" data-type="png" data-w="880" type="block" data-imgfileid="503526985" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/25168c0d-133d-4010-b944-43e87972c022/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;背景与痛点&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNPmhiaf7DSV9LOowlHyrYmDTZ66K5zGqibzPWDuDuiaxoOupV2rKg0ZTicQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.3756613756613756" data-s="300,640" data-type="png" data-w="756" type="block" data-imgfileid="503526986" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1fb0086c-062f-4784-b0fa-15c4b220a670/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;端到端全模态模型&lt;/strong&gt;虽然实现了视听统一，但往往受限于高昂的训练成本和困难的跨模态特征对齐，导致在细粒度跨模态理解上表现不佳；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基于固定 Workflow 的智能体依赖人为设定僵化的流程，缺乏细粒度和灵活性，无法根据问题自主的进行规划与信息获取；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Caption-based 视频智能体需要在分析问题之前，先针对整个视频构建帧 caption 数据库，随后基于视频字幕数据库来理解内容，但这种方法计算成本高，难以捕捉细节的跨模态信息。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;相比之下，&lt;strong&gt;OmniAgent 引入了一种全新的主动感知推理范式&lt;/strong&gt;。通过在迭代反思循环中策略性地调度视频与音频理解能力，该方法有效攻克了跨模态对齐的难题，从而实现了对视听内容的细粒度理解。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法论&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNPdwChQj2a1A6db5s9agRpa2xR5bdgicJRzdWbFfm6DpaWTtr9oU5NEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.37962962962962965" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527014" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/646ffd20-03e3-42a6-b34c-ed9d5e1a9f60/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;OmniAgent 摒弃了固定的工作流，采用了&lt;strong&gt;「思考 - 行动 - 观察 - 反思」&amp;nbsp;&lt;/strong&gt;闭环机制 。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;思考&lt;/strong&gt;：OmniAgent 会根据问题进行分析，自主决定「听」还是「看」。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;行动&lt;/strong&gt;：根据计划，OmniAgent 会从构建的多模态工具中选取合适的工具进行调用：&lt;ol style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;strong&gt;事件工具&lt;/strong&gt;：利用音频能够高效捕捉全局上下文的特性，首创音频引导事件定位，快速锁定关键时间窗口，避免对长视频进行无效的视觉扫描 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;视频工具&lt;/strong&gt;：包含粗粒度的全局视频问答，以及在特定时间内基于更高帧率进行分析的片段问答工具。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;音频工具&lt;/strong&gt;：涵盖音频全局描述、细粒度问答，以及支持精确时间戳的语音转录 （ASR）。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;3.&lt;strong&gt;观察与反思机制&lt;/strong&gt;：智能体接受工具结果，评估目前已有的证据能否正确的回答问题，并且结合之前在多步推理中进行跨模态一致性检查，确保视听证据互证，解决幻觉与对齐问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效果如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;OmniAgent 在三个主流视听理解基准测试中均取得了 SOTA 成绩，显著优于现有的开源及闭源模型：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;1.&lt;strong&gt;Daily-Omni Benchmark&lt;/strong&gt;：准确率达到 82.71%，超越 Gemini 2.5-Flash (72.7%) 和 Qwen3-Omni-30B (72.08%)，提升幅度超 10% 。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNzooicicJh9pVqMwmKRQyISCEwlJUibib1S9uSWRibjkOjXtnaciaGfPdwhUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.42407407407407405" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527018" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/84cb434b-23f7-420d-8ed6-234bfae1b5d2/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;2.&lt;strong&gt;OmniVideoBench&lt;/strong&gt;：在长视频理解任务中，准确率达 59.1%，大幅领先 Qwen3-Omni-30B (38.4%) 。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNKic4XZpRuMQ7geJWUrQfBQuaEh2hgcDX7PUSLqUgQL068EfoPNtW0bA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5138888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527024" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/19fb8e7c-e94a-443a-ac3b-189ae8c7586b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;3.&lt;strong&gt;WorldSense&lt;/strong&gt;: OmniAgent 也保持了领先的准确度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNde20mMCicZbaTaIHueej1vUIyMBHwH54E0fdzb8sxIFq46GSAXnr7pA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.20833333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527025" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/00e17145-8216-4ae5-8b40-47189416db95/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;未来愿景&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;OmniAgent 的设计理念有很高的扩展性&lt;/strong&gt;，能够继续结合其他模态的工具；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;OmniAgent 能够帮助生成高质量的 COTT 数据&lt;/strong&gt;，用来构建可以自我调用工具的下一代智能体全模态模型。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;总的来看，&lt;strong&gt;OmniAgent 证明了在全模态理解任务中，音频引导的的主动感知策略是解决跨模态对齐困难、提升细粒度推理能力的有效路径&lt;/strong&gt;。该工作为未来的全模态 Agent 算法设计提供了新的范式参考。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>OpenAI发布ChatGPT新功能，专为健康打造的个人服务体验</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Thu, 08 Jan 2026 11:57:23 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmRZ3nMzjQZKXibDpmxbCzEClUMwLIt44rjwdn6z42LYuzibczPD2mI6vdTycS7BAJOnJW4dTzibicqaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="321" data-imgfileid="100027087" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/ea8b7172-9438-47cb-9125-83ca9800f36e/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;随着大众意识越来越关注个人卫生安全与社区健康保护，2026 年 1 月 7 日，OpenAI 推出了他们的新产品 ChatGPT&amp;nbsp;Health，在确保安全的基础上整合用户健康信息与 ChatGPT 的智能，可以帮助用户在健康旅程中更加了解自身状况、做好准备，并以更充足的信心面对与健康相关的决策。&lt;/p&gt;&lt;p&gt;在如今，每周都有数以亿计的用户提出相关方面的问题，考虑到这类信息的私密性，ChatGPT&amp;nbsp;Health&amp;nbsp;在 ChatGPT 现有的隐私、安全与数据治理能力之上，进一步加入专为健康领域设计的多层保护机制，包括专用加密与隔离技术，以确保健康对话的私密性与分区管理。&lt;/p&gt;&lt;p&gt;ChatGPT&amp;nbsp;Health&amp;nbsp;由 OpenAI 与与医生携手打造，以补充而非替代临床护理为原则，旨在帮助人们更主动地理解并关注自身健康。&lt;/p&gt;&lt;p&gt;相关链接：&lt;em&gt;https://openai.com/zh-Hans-CN/index/introducing-chatgpt-health/?video=1151655050&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;专属健康体验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如今，健康信息常常分散在各类网站、程序和医疗记录中，很难看到全貌，人们不得不独自应对复杂的医疗系统。许多用户分享了他们如何借助 ChatGPT 来理解这些零散信息。根据 OpenAI 对匿名化对话的分析，健康已成为 ChatGPT 最常见的使用场景之一，全球每周有超过 2.3 亿人提出与健康和保健相关的问题。&lt;/p&gt;&lt;p&gt;ChatGPT&amp;nbsp;Health在此基础上进一步扩展，使生成的回复能够结合你的健康信息与个人情境，用户现在可以安全地连接电子医疗记录和各类健康应用。这样，ChatGPT 可以协助理解最新的检查结果、为即将到来的就诊做好准备、获得有关饮食与运动规划的建议，或根据医疗服务使用模式在不同保险方案之间做出取舍。&lt;/p&gt;&lt;p&gt;该项功能旨在支持而非取代医疗护理，也并非用于诊断或治疗。它的作用在于帮助处理日常健康问题，理解自身的长期健康模式，而不仅仅是在生病时提供协助。&lt;/p&gt;&lt;p&gt;ChatGPT&amp;nbsp;Health以独立空间运行，并具备更出色的隐私保护机制，为敏感数据提供有力保障。记录中的对话不会用于训练基础模型。&lt;/p&gt;&lt;p&gt;该项功能将首先向一小部分用户开放，以便持续学习并优化整体体验。随着功能不断完善， OpenAI 计划在未来数周内逐步扩大开放范围，在网页端和 iOS 上向所有用户提供。&lt;/p&gt;&lt;p&gt;电子健康记录 (EHR) 的整合功能及部分应用目前仅在美国可用，且连接 Apple 健康需使用 iOS 系统。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;以隐私与安全为首要设计考量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;用户的健康信息高度私密，因此，「健康」功能拥有独立的专属空间，具备经强化的敏感健康信息保护机制及易用的控制功能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「Health」功能拥有独立的空间&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 ChatGPT 中，「Health」功能拥有独立的空间，历史对话、已连接的应用和文件均与其他聊天内容隔离存储。此外，「Health」功能具备独立的记忆，确保与健康相关的上下文仅限于该空间之内。用户仍可在聊天记录中看到与健康相关的对话，便于随时查阅，但信息本身始终保留在「Health」空间中。&lt;/p&gt;&lt;p&gt;在适当情况下，ChatGPT 可能会参考在「Health」功能之外的对话内容 &amp;mdash; 例如最近的搬迁或生活方式变化 &amp;mdash; 以增强健康对话的相关性，但健康信息与记忆不会回流至主要聊天中，而且，「Health」功能之外的对话无法访问在「Health」空间中的文件、对话或记忆。这部分记忆可以随时被主动删除。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;敏感信息的保护与控制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 深知，用户会在 ChatGPT 中分享个人和敏感信息，而这一点自产品设计之初便塑造了他们在安全、隐私与数据控制⁠方面的原则。早在推出 ChatGPT&amp;nbsp;Health&amp;nbsp;之前，基础性的保护机制便已经搭载完成，让用户能够更有效地管理自己的数据，以及训练模型不保留用户对话中的个人信息。&lt;/p&gt;&lt;p&gt;ChatGPT 中的对话与文件在存储和传输过程中均默认加密，这是核心安全架构的一部分。鉴于健康数据的敏感性，ChatGPT&amp;nbsp;Health&amp;nbsp;在此基础上进一步加入多层防护措施 &amp;mdash; 包括专为健康场景设计的加密与隔离机制 &amp;mdash; 以确保健康相关对话得到保护并实现严格隔离。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;安全连接信息&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在选择连接健康数据（如电子医疗记录或健康应用）后，ChatGPT 的回复将以个人健康信息为基础。OpenAI 将与 b.well 合作，遵循行业最高标准的数据安全与隐私规范。该服务仅向成年用户提供，且权限可被随时撤销。&lt;/p&gt;&lt;p&gt;用户同样可以连接 Apple 健康信息以及其他健康应用，例如 Function 和 MyFitnessPal。所有可在「健康」功能中使用的应用都必须符合 OpenAI 的隐私与安全要求，包括仅收集必要的最少数据，并通过专门针对 ChatGPT&amp;nbsp;Health&amp;nbsp;的额外安全审查。这方面，用户始终拥有掌控权：可随时断开应用连接，权限将立即失效。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;与医生携手打造&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在过去两年中，OpenAI 与来自 60 个国家/地区、数十个专科的 260 多位执业医生合作，深入研究哪些回答方式真正有帮助、哪些可能带来潜在风险。&lt;/p&gt;&lt;p&gt;这种合作不仅优化了 ChatGPT&amp;nbsp;Health&amp;nbsp;的能力，也塑造了它的回复方式：何时需要更紧急地建议用户寻求医生的后续评估，如何在不失准确性的前提下清晰沟通，以及如何在关键时刻⁠优先考虑安全。&lt;/p&gt;&lt;p&gt;相关链接：&lt;em&gt;https://openai.com/zh-Hans-CN/index/helping-people-when-they-need-it-most/&lt;/em&gt;&lt;/p&gt;&lt;p&gt;这种由医生主导的方法被直接融入驱动 ChatGPT&amp;nbsp;Health&amp;nbsp;的模型之中，并通过 HealthBench⁠ 进行临床标准评估。这是 OpenAI 与执业医生网络共同打造的评估框架，不依赖于考试式问题或泛化的准确性检查，而是使用由医生编写的评分标准来评估回复质量，反映真实临床实践中的判断标准。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmRZ3nMzjQZKXibDpmxbCzECyX7tlFAbrMwhBLW9dLTT3KWazj4ibdqzXk9nlmSqO0FqnCba5V2P7mw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.42314814814814816" data-type="png" data-w="1080" data-width="1265" data-height="535" data-backw="546" data-backh="231" data-imgfileid="100027084" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/7da1ad8a-d404-432b-ad45-9e17f3c1a7bb/640.png" alt="图片" data-before-load-time="1767844611775" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：HealthBench。&lt;/p&gt;&lt;p&gt;相关链接：https://openai.com/zh-Hans-CN/index/healthbench/&lt;/p&gt;&lt;p&gt;这种方法以评估为导向，有助于确保模型在用户真正需要帮助的任务上表现良好，其最终目标是提供值得信赖的支持 &amp;mdash; 始终旨在发挥辅助作用，而非取代医疗服务提供商。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;使用方式说明&lt;/strong&gt;&lt;/p&gt;&lt;ol start="1"&gt;&lt;li&gt;&lt;p&gt;获取访问权限后&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;从 ChatGPT 的侧边栏菜单中选择「Health」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmRZ3nMzjQZKXibDpmxbCzECGchJWqS5ky9boIKfH5kao4o5dbtVr1kF8v97NWqo0A0icp6odET6Fvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1920" data-height="1080" data-backw="546" data-backh="307" data-imgfileid="100027085" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1ab79dc6-bfd4-4d87-aaea-61ad9f589cdd/640.png" alt="图片" data-before-load-time="1767844612023" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：ChatGPT 主页的健康功能入口。&lt;/p&gt;&lt;ol start="2"&gt;&lt;li&gt;&lt;p&gt;导入信息&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;将个人医疗记录与追踪应用链接至该功能，可直接上传文件，或通过工具 (+) 或「设置」中的「应用」进行连接。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;新：医疗记录⁠（在新窗口中打开），用于查看化验结果、就诊摘要和临床病史&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;新：Apple 健康⁠（在新窗口中打开），用于同步健康与健身数据，包括运动、睡眠和活动模式（需在 iOS 上使用以完成同步）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;新：Function⁠（在新窗口中打开），用于提供血检洞察与营养建议&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AllTrails⁠（在新窗口中打开） 帮助你发现下一条适合的徒步路线&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;ol start="3"&gt;&lt;li&gt;&lt;p&gt;围绕健康开始聊天&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;「Health」功能中，对话依然保持 ChatGPT 的自然交流方式，但会基于健康信息提供更精准的支持。用户可以上传照片和文件，并使用搜索、深度研究、语音模式或听写功能。在适当情况下，ChatGPT 会自动参考提交数据，提供更相关、更具个性化的回应。&lt;/p&gt;&lt;p&gt;如要使用某个已连接的应用，用户可以在提问时直接点名某个应用、从工具 (+) 中予以选择，或在合适的情境下由 ChatGPT 自动调用。&lt;/p&gt;&lt;ol start="4"&gt;&lt;li&gt;&lt;p&gt;自定义体验&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;用户可以在「Health」功能中添加自定义指令，帮助 ChatGPT 了解需要重点关注的内容、避免提及的敏感话题，或调整回复的呈现方式。这些指令仅适用于「Health」对话，用户可以随时在「Health」或「设置」中更新或删除。&lt;/p&gt;&lt;p&gt;演示视频：https://openai.com/zh-Hans-CN/index/introducing-chatgpt-health/?video=1152278055&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这只是个开始&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 表示，他们将会持续扩展可连接的内容，并提升「Health」功能提供的洞察信息。这样，在用户关注自身健康的过程中，ChatGPT 将有助于获得更充分的信息、更好的准备，以及更强的信心。&lt;/p&gt;&lt;p&gt;原文链接：https://openai.com/zh-Hans-CN/index/introducing-chatgpt-health/&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，DeepSeek R1论文更新，增加了64页</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 11:37:10 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;DeepSeek R1 的论文有了大更新，足足增加了64页！&lt;img src="https://image.jiqizhixin.com/uploads/editor/e9d42a81-c73e-4d9b-a9f7-47544e478738/1767843190508.png" style="width: 70%;" class="fr-fic fr-dib"&gt;我们用 Gemini 快速总结了一下，发现新增了许多细节内容：&lt;br&gt;&lt;br&gt;&lt;strong&gt;1. 训练全路径首次大公开：四阶段管线&lt;/strong&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3059f333-947d-4843-a505-a79e23a751a6/1767843222767.png" style="width: 70%;" class="fr-fic fr-dib"&gt;v2 版本详细披露了 R1 从零到 1 的 4 个关键阶段。&lt;br&gt;&lt;br&gt;Stage 1：冷启动。利用数千条高质量长 CoT 数据进行 SFT，让模型先「学会思考」。&lt;br&gt;Stage 2：推理导向 RL。专注于数学、代码等硬核任务，引入「语言一致性奖励」解决 v1 中提到的语种混杂问题。&lt;br&gt;Stage 3：拒绝采样与再微调。收集约 60 万条推理数据和 20 万条通用数据（如写作、创意），让 R1 既会算题也会写诗。&lt;br&gt;Stage 4：全场景对齐 RL。最终提升模型的助人性与安全性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;2. 「Aha Moment」的数据化验证&lt;/strong&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8b2d50a9-fcd4-4471-bf2e-e90f0414c3a4/1767843241384.png" style="width: 70%;" class="fr-fic fr-dib"&gt;v1 只是提到了模型会自发「反思」，而 v2 通过词频分析给出了科学证据。&lt;br&gt;&lt;br&gt;关键发现：在训练到约 8000 步时，模型对「Wait」（等等）、「Retry」（重试）等词汇的调用频率暴增 5-7 倍。&lt;br&gt;&lt;br&gt;结论：RL 确实让模型自发产生了检查、自我修正和重新验证的行为，这是推理能力进化的铁证。&lt;br&gt;&lt;br&gt;&lt;strong&gt;3. 推理也有「缩放法则」：自适应算力分配&lt;/strong&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f225b5d7-5ef8-4e61-90f0-caf6980825c9/1767843271131.png" style="width: 50%;" class="fr-fic fr-dib"&gt;v2 新增了对 CoT 长度自适应的深入分析。&lt;br&gt;&lt;br&gt;动态分配：模型学会了根据题目难度动态调整思考时间。简单的「1+1」只用不到 100 token，而超难数学题会调用超过 18,000 token。&lt;br&gt;性能提升：这种算力缩放（Scaling）让 R1 在 2024 年数学竞赛题上的 solve rate 达到了 61.8%，远超 GPT-4o。&lt;br&gt;&lt;br&gt;&lt;strong&gt;4. 「诚实」的失败总结：PRM 和 MCTS 为什么不行？&lt;/strong&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bd61b07a-e6cf-4baf-94b2-dd76f60d7dec/1767843300098.png" style="width: 50%;" class="fr-fic fr-dib"&gt;DeepSeek 在 v2 中非常大方地分享了没跑通的路径，这对学术界极具参考价值：&lt;br&gt;&lt;br&gt;PRM（过程奖励模型）：难以定义细粒度的步骤，且容易遭受「奖励作弊（Reward Hacking）」。&lt;br&gt;MCTS（蒙特卡洛树搜索）：在棋类中很强，但在 Token 生成的无限搜索空间中容易陷入局部最优，且计算开销巨大。&lt;br&gt;&lt;br&gt;&lt;strong&gt;5. 跨越时间的验证：AIME 2025 战绩&lt;/strong&gt;&lt;br&gt;&lt;br&gt;为了证明 R1 不是靠记忆刷题，v2 补充了在模型训练完成后才发布的 AIME 2025 结果。&lt;br&gt;&lt;br&gt;战绩：R1 在 AIME 2025 上取得了 75% 的解决率，接近 OpenAI o1 的 80%。这有力回击了关于「数据污染」的质疑。&lt;br&gt;&lt;br&gt;&lt;strong&gt;6. 关于模型规模的「毒药」警告&lt;/strong&gt;&lt;br&gt;&lt;br&gt;v2 明确指出：RL 推理能力对模型基础规模有门槛 。&lt;br&gt;&lt;br&gt;策略建议：小模型提升推理能力的最佳路径是蒸馏大模型（如 R1）的推理逻辑，而不是强行在 base 上做 RL。&lt;br&gt;&lt;br&gt;不过有网友指出，新增内容之前在 Nature 接收的 R1 论文中已经发布过。&lt;br&gt;&lt;br&gt;不知道你们有没发现更多有价值的信息？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>吉利全域AI 2.0发布，Eva智能体、千里浩瀚G-ASD全面进化</title>
      <description>&lt;![CDATA[全域AI 2.0助力，吉利今年将带来全新智舱、智驾体验，冲刺345万辆年销目标。]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 08 Jan 2026 11:15:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;拉斯维加斯当地时间1月5日，吉利汽车集团宣布基于其首发的WAM世界行为模型，吉利全域AI技术体系顺利进化到了2.0时代，实现了AI技术在整车各域的跨域融合，让汽车智能首次拥有了持续进化的“世界观”和“判断力”。在全域AI 2.0加持下，吉利推出的Eva超拟人情感智能体，正快速进化为超拟人、超智能、超好用的整车智能中枢。同时，吉利还发布了千里浩瀚辅助驾驶系统的英文品牌及软件版本名称——千里浩瀚G-ASD，代表着吉利与千里智驾联合研发的高含模量智能辅助驾驶解决方案，旨在为吉利体系下的用户提供同等级下最优质的体验。&lt;/p&gt;&lt;p&gt;此外，吉利还携极氪9X、极氪009光辉（典藏版）、吉利银河M9等最新电动汽车，以及神盾金砖电池、Flyme Auto智能座舱系统等吉利“全域AI”技术体系成果，亮相2026国际消费电子展（2026 CES），全面展现中国汽车领军品牌的科技魅力。&lt;img width="486" src="https://image.jiqizhixin.com/uploads/editor/f2428aa4-9846-4866-91d6-498919c93ab6/1767867258485.jpeg" align="left" alt="/Users/sunshine/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/picturecompress_20260106091314/output_1.jpgoutput_1" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全域AI 2.0基于WAM模型实现跨域融合，Eva加速进化为整车智能中枢&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在2025年CES展会区间，吉利发布了智能汽车行业首个全域AI技术体系，并将AI科技深度融入智能汽车的架构、动力、底盘、座舱、辅助驾驶等全链路。为了让智驾域、座舱域、底盘域等各个域之间充分实现跨域融合，吉利今年发布了具备自我反思与进化能力的世界行为模型——WAM（World Action Model），构建统一的“整车大脑”。&lt;/p&gt;&lt;p&gt;WAM采用了分层设计，上层利用MLLM（多模态模型）进行宏观任务的规划，下层集成动作专家（Action Expert）和世界模型（World Model）进行精细的推演和决策，并引入人类在环（Human-in-the-loop）的价值函数体系（Value Function），实现了从“理解-规划”到“预演-判断-修正”的完整智能闭环，让汽车智能首次拥有持续进化的“世界观”和“判断力”。&lt;/p&gt;&lt;p&gt;基于WAM模型强大的内核，吉利全域AI技术体系顺利进阶到了2.0时代。相较于全域AI 1.0，全域AI 2.0实现“智能体化”和“引擎化”两个根本性的突破。在“智能体化”突破上，吉利首次设计并实现的“1+2+N”全域多智能体协同框架，使不同域的智能体能够进行对话、协商和协作，用户一个简单的自然语言指令，即可触发多个智能体间一系列复杂的任务分解、资源调度和协同执行。“引擎化”则意味着全域AI 2.0将感知、认知、记忆、决策等最基础的AI能力，从各个域中提炼出来，打磨成一系列如“全域感知引擎”、“全域记忆引擎”高效、稳定、可被全域任意智能体随时调用的“公共技术引擎”。&lt;/p&gt;&lt;p&gt;“智能体化”和“引擎化”使全域AI 2.0完成的架构层面的迭代，成为一套更标准、更平台、更协调的技术架构，将带来更高的含模量、更自主的体验和更协同的产品。吉利也将构建起面向全域，而不仅服务于智驾的世界模型，将使车辆对距离、速度、物体行为、社会常识的理解保持一致，赋予汽车统一的“世界观”和“常识库”。&lt;/p&gt;&lt;p&gt;全域AI 2.0的赋能下，吉利推出的Eva超拟人智能体，将加速进化为具有记忆与推演能力的感知-决策-执行中枢，标志着车载智能体从“功能模块”正式进化为“整车智能中枢”。&lt;/p&gt;&lt;p&gt;全面升级的端到端语音大模型、动态记忆技术以及迎来革新的交互界面，将使Eva拥有高情商、具备常识的类人对话能力，完成从“通用AI”到“个人AI”的跨越，“超拟人”的交互“人格”更接近真人。同时，Eva将拥有颠覆性的“超智能”AI自主决策能力，能够理解并执行复杂、模糊的出行需求，自主完成从规划、到执行的完整链条，成为强大的“AI自主出行智能体”，并实现服务标准化。此外，AI自主执行带来的体验革命，能够实现“舱驾协同”的深度融合，Eva可执行完整的出行任务，更成为连接万物的 “生态智能体”，给用户带来“超好用”的出行体验。&lt;img width="484" src="https://image.jiqizhixin.com/uploads/editor/67f4af48-faaa-4b5d-898b-5648a27a4612/1767867258495.jpeg" alt="/Users/sunshine/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/picturecompress_20260106091351/output_1.jpgoutput_1" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;千里浩瀚G-ASD英文名发布，带来全球范围内“含模量”最高、技术最前沿的辅助驾驶&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;全域AI 2.0带来的能力跃阶，不仅仅体现在智能座舱领域，也呈现在技术集中度更高、更复杂、更硬核的辅助驾驶领域。在全域AI 2.0的布局中，吉利新一代千里浩瀚辅助驾驶系统得到全面升级，以超高含模量、超大数据集、超强硬件平台三大技术特点，构筑起行业领先的“技术护城河”。&lt;/p&gt;&lt;p&gt;活动期间，吉利公布了千里浩瀚辅助驾驶系统的全新英文品牌名：G-ASD（即Geely Afari Smart Driving），其作为千里浩瀚整体解决方案的英文名及软件版本命名，代表着吉利与千里智驾联合研发的高含模量智能辅助驾驶解决方案，旨在为吉利体系下的用户提供同等级下最优质的体验。&lt;/p&gt;&lt;p&gt;&lt;img width="484" src="https://image.jiqizhixin.com/uploads/editor/245d8f33-f4a6-472a-9dfd-ed07cc672a5d/1767867258502.jpeg" alt="/Users/sunshine/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/picturecompress_20260106091409/output_1.jpgoutput_1" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;千里浩瀚G-ASD采用行业领先的Smart&amp;nbsp;AI&amp;nbsp;Agent架构，完整应用了WAM世界行为模型,是全球范围内“含模量”最高、技术最前沿的辅助驾驶系统之一。在阶跃星辰通用AI大模型的加持下，云端多模态大模型+世界模型参数达1000亿级别，显著提升环境感知和推理能力。同时，千里浩瀚G-ASD还将模型范式全面升级为生成式范式，落地多模态Diffusion技术，并融入国宾级司机的驾驶行为数据，全面提升辅助驾驶的拟人性、安全性、舒适性和通行效率。&lt;/p&gt;&lt;p&gt;&lt;img width="484" src="https://image.jiqizhixin.com/uploads/editor/73dd23f5-6344-40e4-ac8b-315946447ba0/1767867258509.jpeg" alt="/Users/sunshine/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/picturecompress_20260106091435/output_1.jpgoutput_1" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;千里浩瀚G-ASD拥有的“超大数据集”。不仅拥有吉利旗下累计850万辆车的辅助驾驶和累计百亿智驾历程，行业领先的2500万clips模型数据片段，还具备行业第一的百万车辆事故安全数据。在全生命周期数据闭环系统下，“数据飞轮”将持续迭代进化，辅助驾驶系统“越开越聪明”。&lt;img width="484" src="https://image.jiqizhixin.com/uploads/editor/82f6f68e-f552-4195-a59c-ef7fd24da28f/1767867258516.jpeg" alt="/Users/sunshine/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/picturecompress_20260106091452/output_1.jpgoutput_1" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;此外，千里浩瀚G-ASD配备了行业领先的感知硬件。千里浩瀚各层级方案均有同级领先的芯片算力带宽，例如千里浩瀚H7采用Thor芯片及双Orin芯片，现售车型配备激光雷达及多达31颗感知元器件；千里浩瀚H9更采用两颗Thor芯片，带来1400TOPS的同级最高算力，标配5颗激光雷达，实现3重360°全维覆盖。&lt;/p&gt;&lt;p&gt;受益于吉利全域AI技术体系，千里浩瀚G-ASD拥有最强工程落地能力，产品能力覆盖L2辅助驾驶、L3自动驾驶、L4无人驾驶，最终实现智慧生命体愿景。目前，千里浩瀚G-ASD首版本已在极氪、领克多款车型上搭载。在法规允许的条件下，吉利还将于今年推送高速L3和低速L4功能，并实现Robotaxi运营。&lt;/p&gt;&lt;p&gt;在全域AI 1.0技术体系赋能下，吉利汽车集团2025年销量突破302万辆，其中新能源销量近169万辆，同比增长90%，均创历史新高。2026年，在全域AI 2.0的全面助推下，吉利推出约10款全新车型，冲刺345万辆的全年销量目标，并将中国车企智能电动化的创新成果与全球产业链深度融合，持续为全球用户创造超越期待的出行体验，加速向“全球智能汽车引领者”的目标阔步迈进。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，智谱敲钟上市了，市值达528亿港元</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 10:21:39 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/855b1795-5c4d-4087-abc7-ab260fe3e748/1767838696766.png" style="width: 700%;" class="fr-fic fr-dib"&gt;「全球大模型第一股」来了！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2026 年 1 月 8 日，北京智谱华章科技股份有限公司（02513.HK）（以下简称「智谱」）正式在香港联合交易所挂牌上市。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gricAxsfviciasKr87WuVPtOGbV8taeDauLvbJGFtr0gY7gYANwLicyr2ow/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527241" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a6f62485-8289-46e4-a8d1-b72942f6b780/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;至此，&lt;strong&gt;全球首家以通用人工智能（AGI）基座模型为核心业务的上市公司花落中国。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智谱首日开盘价 120 港元 / 股，市值 528.28 亿港元。&lt;/p&gt;&lt;p&gt;在智谱本次 IPO 发行中，香港公开发售获 1159.46 倍认购，国际发售获 15.28 倍认购。以每股 116.20 港元的发行价计算，智谱本次 IPO 募资总额超 43 亿港元（「绿鞋」前）。&lt;/p&gt;&lt;p&gt;在上市致辞中，智谱董事长刘德兵表示：「全球范围内通用大模型企业第一次以这样的方式走向公开市场，非常有幸智谱作为中国大模型代表，站在这个历史性的起点。&amp;lsquo;让机器像人一样思考&amp;rsquo;是智谱从创立第一天起就选择的方向，是智谱人持之以恒奋斗的唯一目标。」&lt;/p&gt;&lt;p&gt;他回顾称，智谱在 2021 年推出了自研的算法架构 GLM，而今年 GLM-4.7 的发布使其跻身世界领先，为冲刺 AGI 打下重要根基。&lt;strong&gt;「智谱的 Z 是字母表中的最后一个，代表终极境地，我们希望在 AGI 的探索历程上能走到智能的终极境地。」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;凭借「全球大模型第一股」标的的独特稀缺性，智谱吸引了一支由北京核心国资、头部保险资金、大型公募基金、明星私募基金和产业投资人构成的全明星基石投资阵容，JSC International Investment Fund SPC、JinYi Capital Multi-Strategy Fund SPC、Perseverance Asset Management 等 11 家基石投资者合计认购 29.8 亿港元。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gml9r11FDrnTSF25OPbphmk4kF1j3cxXpl2C4ias60KbDeKGOAaiaiawOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6675925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527238" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/821c9b91-7646-4cdf-942b-86e2c253e2a2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;以基座模型为核心，持续探索智能上界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智谱是中国最早投身大模型研发的厂商之一，原创性地提出了基于自回归填空的通用预训练范式 GLM，率先发布了中国首个百亿模型、首个开源千亿模型、首个对话模型、首个多模态模型，以及全球首个设备操控智能体（Agent），并形成全面的模型体系，是国内罕有在原创技术路线上与全球顶尖水平保持同步的厂商，因此也被誉为「中国的 OpenAI」。&lt;/p&gt;&lt;p&gt;目前，GLM 架构已实现全国产化突破，适配 40 余款国产芯片，成为业内通用性最高的模型体系之一。&lt;/p&gt;&lt;p&gt;作为中国最早投身大模型研发的厂商之一，智谱长期坚持高比例、持续性的研发投入。&lt;/p&gt;&lt;p&gt;招股书显示，2022 年 - 2024 年公司研发投入分别为 8440 万元、5.289 亿元、21.954 亿元，2025 年上半年为 15.947 亿元，累计研发投入约 44 亿元，研发人员占比 74%。高强度的研发投入支撑智谱技术快速迭代，GLM 系列模型每 2-3 个月完成一次基座迭代，保持全球领先水平。&lt;/p&gt;&lt;p&gt;2025 年 12 月，智谱新一代基座模型 GLM-4.7 在模型综合能力榜单 Artificial Analysis 与权威编码榜单 Code Arena 中，均荣登开源模型与国产模型双料榜首。模型 Coding 和 Agent 真实体感表现优秀，发布两个月，来自 184 个国家的 15 万开发者朋友为编程订阅产品付费，Cerebras、Windsurf 等超过 50 家海内外开发平台工具选择接入。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69go24HRH6qXEyN7Zx0zVB7ToWnrynxfWn1IicyYbGK7FCicmxzj8LaticVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.31666666666666665" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527249" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7568eca1-2ec7-44c6-b89c-1fb5a3d50533/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;据了解，公司本次募集资金净额的 70%（约 29 亿港元）将用于通用 AI 大模型方面研发投入，进一步巩固智谱在通用基座模型方面的竞争力；约 10%（约 4.2 亿港元）将用于持续优化公司的 MaaS 平台，包括提供最新的基座模型以及训练 / 推理工具及基础设施建设。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中国最大独立大模型厂商，以 MaaS 模式锚定未来增长&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智谱成立于 2019 年，由清华大学技术成果转化而来，专注通用人工智能（AGI）的研发，并坚持做让用户真正用得上的研究与技术。&lt;/p&gt;&lt;p&gt;弗若斯特沙利文报告显示，按 2024 年收入计算，&lt;strong&gt;智谱在中国独立通用大模型开发商中排名第一，在所有通用大模型开发商中排名第二&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;截至 2025 年 9 月 30 日，模型赋能全球 12000 家企业客户（互联网客户占比 50%）、逾 8000 万台终端用户设备及超 4500 万名开发者，是中国赋能终端设备最多的独立通用大模型厂商。&lt;/p&gt;&lt;p&gt;在商业化层面，智谱是少数已实现规模化收入与持续高增长的独立大模型厂商。招股书显示，2022 年 - 2024 年，智谱收入分别为 5740 万元、1.245 亿元、3.124 亿元，年复合增长率高达 130%；2025 年上半年收入为 1.91 亿元，同比增长 325%。2022 年至 2024 年，智谱毛利率分别为 54.6%、64.6%、56.3%，2025 年上半年毛利率为 50%。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智谱自 2021 年就开始布局 MaaS（Model as a Service），这一时间比大模型商业化的时间早两年。&lt;/strong&gt;目前，智谱形成了以 MaaS 为核心的标准化产品体系，包含模型的 API 调用、模型订阅及本地化部署等方式，向企业及开发者输出「通用智能能力」，而非单一场景应用。MaaS 收入和模型调用量在今年迎来较大增长。&lt;/p&gt;&lt;p&gt;数据显示，智谱 MaaS 平台已汇聚超过 300 万家企业及应用开发者，是国内最活跃的大模型 API 平台之一，其中编程订阅产品表现尤为突出，上线短时间内即实现过亿的年度经常性收入（ARR），并在海外开发者社群中快速渗透。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「技术 + 资本」双轮驱动，开启全球竞技新阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前，&lt;strong&gt;全球资本的 AI 投资叙事正从「能力验证」转向「规模扩张」&lt;/strong&gt;。智谱等中国大模型企业以差异化发展路径与商业化闭环，显露开源影响力、模型竞争力和性价比优势，不断吸引国际长线资本加持看好。&lt;/p&gt;&lt;p&gt;根据联合国贸发会议预测，到 2033 年，全球 AI 市场规模将从 2023 年的 1890 亿美元飙升至 4.8 万亿美元，十年内增幅达到 25 倍。&lt;/p&gt;&lt;p&gt;市场规模不断增长的同时，国内政策支持越发成熟。随着《人工智能大模型》系列国家标准正式实施，中国 AGI 发展正式迈入「规范有序」的下半场，大模型在千行百业深度落地，将成为驱动效率革命与模式创新的核心引擎。&lt;/p&gt;&lt;p&gt;在全球 AI 竞赛持续升温的背景下，智谱拿下「全球大模型第一股」，凸显出中国在人工智能基础模型领域的产业链完整度与政策支持逐步成熟，不仅为国产大模型发展注入资本活力，更标志中国 AGI 企业正式迈入资本市场的舞台中央，开启与国际巨头同台竞技的新阶段。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>深入感知级别图像理解：UniPercept 统一图像美学、质量与结构纹理感知</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 10:16:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/b185325e-ba02-40d4-8206-3198964ce2f7/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="6,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="6,0,0"&gt;&lt;strong&gt;操铄&lt;/strong&gt;&lt;/b&gt;&lt;strong&gt;：中国科学技术大学与上海人工智能实验室联合培养博士生，专注多模态图像理解与生成。主导研发了 ArtiMuse、UniPercept 等成果，多篇工作发表于 ECCV、ICCV 等国际顶级会议。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="6,1,0"&gt;&lt;strong&gt;&lt;b data-index-in-node="0" data-path-to-node="6,1,0"&gt;李佳阳&lt;/b&gt;：北京大学硕士生，专注多模态图像理解及融合。作为核心作者参与了 ArtiMuse、UniPercept 等工作，多篇工作发表于 TIP、TPAMI 等国际顶级期刊。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;尽管多模态大语言模型（MLLMs）在识别「图中有什么」这一语义层面上取得了巨大进步，但在理解「图像看起来怎么样」这一感知层面上仍显乏力。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;近日，来自上海人工智能实验室、中科大、北大、清华等机构的研究者联合发布了 &lt;b data-index-in-node="37" data-path-to-node="9"&gt;UniPercept&lt;/b&gt;。这是首个统一了 美学（Aesthetics）、质量（Quality）、结构与纹理（Structure &amp;amp; Texture） 三个维度的感知级图像理解框架。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN5qF7ufpPuKelsatyHEPlicjOKqKPkC58VDU0fibbOU9LUpbqc8fadagw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3101851851851852" data-type="png" data-w="1080" data-width="1852" data-height="575" data-imgfileid="503526957" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/460140fd-7b64-41f7-a1fc-c9de78e246a0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="11,0,0"&gt;🌐 项目主页：https://thunderbolt215.github.io/Unipercept-project/&lt;/p&gt;&lt;p&gt;💻 代码仓库：https://github.com/thunderbolt215/UniPercept&lt;/p&gt;&lt;p&gt;📝 论文地址：https://arxiv.org/abs/2512.21675&lt;/p&gt;&lt;p&gt;📊 模型权重：https://huggingface.co/collections/Thunderbolt215215/unipercept&lt;/p&gt;&lt;p&gt;🎨 相关工作 (ArtiMuse)：https://github.com/thunderbolt215/ArtiMuse&lt;/p&gt;&lt;p data-path-to-node="13"&gt;&lt;strong&gt;引言：从「识别物体」到「感知图像」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="14"&gt;当前，多模态大语言模型在目标检测、图像描述和视觉推理等语义级任务中表现卓越。然而，人类视觉感知不仅限于物体识别，还包括对构图美感、画质损伤、材质纹理以及结构规律性的细腻捕捉。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;语义级理解关注的是「场景中有哪些实体」，而感知级理解则需要评估精细的、低层级的视觉外观，例如美学和谐度、降质严重程度或表面肌理。这些属性往往是微妙且主观的，对内容创作、图像增强及生成模型对齐至关重要。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;为了填补这一空白，研究团队提出了 &lt;strong&gt;UniPercept&lt;/strong&gt;。该工作建立了层次化的感知属性定义系统，构建了大规模基准测试集 &lt;b data-index-in-node="59" data-path-to-node="16"&gt;UniPercept-Bench&lt;/b&gt;，并开发了一个通过领域自适应预训练和任务对齐强化学习训练的强基准模型。此外，研究团队还给出了 &lt;strong&gt;UniPercept&amp;nbsp;&lt;/strong&gt;的下游应用实例，包括作为生成模型的奖励模型（Reward Model），以及作为生成模型评估的指标（Metrics）等。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN4XmtGes7s6ClzKW70Fv2KeR2onv091JLaUeyqpibnzicUX1NdSxxBc4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.0018518518518518" data-type="png" data-w="1080" data-width="1195" data-height="1197" data-imgfileid="503526958" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/faf3505c-cc59-4fed-adce-8c78c829a04e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="17"&gt;&lt;strong&gt;UniPercept-Bench：三位一体的全域感知评价体系&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="18"&gt;UniPercept 将感知级图像理解拆解为三个核心领域，构建了「领域 - 类别 - 准则」的三级层次结构，旨在全面覆盖人类对图像的视觉评价维度。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;&lt;b data-index-in-node="0" data-path-to-node="19"&gt;核心评估维度&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="20,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="20,0,0"&gt;图像美学评估（IAA）&lt;/b&gt;：侧重于构图设计、视觉元素与结构、情感和整体视觉吸引力等。它关注的是图像是否「好看」，探讨艺术表达与视觉平衡。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="20,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="20,1,0"&gt;图像质量评估（IQA）&lt;/b&gt;：侧重于感知保真度和降质因素，如噪声、模糊、压缩伪影。它回答的是图像是否「技术性达标」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="20,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="20,2,0"&gt;图像结构与纹理评估（ISTA）&lt;/b&gt;：这是 UniPercept 首次系统化提出的维度，强调局部特征、几何规律性、材质属性（如平滑度、粗糙度）和细节丰富度。它回答的是图像的「场景、结构、纹理和构成与复杂程度」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN5lwqTMiasj6naNH40eVjicVOfUzNO3kzteyqz13uouwwsQAukYjPJdxQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0037037037037038" data-type="png" data-w="1080" data-width="1189" data-height="1193" data-imgfileid="503526960" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ed1b640e-ac53-403a-9d2f-f65fa718480e/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="21"&gt;UniPercept-Bench 的定义体系分为三级细分，包含 3 个领域、17 个类别和 44 个细分准则，给出了专家级的细致定义体系，其精细程度远远超过此前的图像评估 Benchmark。&lt;/p&gt;&lt;p data-path-to-node="22"&gt;在具体定义上，它实现了从领域到准则的精密解构：例如从美学（IAA）领域，到「构图与设计（Composition &amp;amp; Design）」类别，深入到对「视觉平衡（Visual Balance）」这一微观准则的量化；或从场景解析（ISTA）领域，到「几何构成（Geometric Composition）」类别，细化到对「3D 体积（3D Volume）」隐含信息的提取。这种三级联动的体系，确保了模型能够从宏观的「整体感知」跨越到微观的「渲染精度」进行全方位、多维度的专家级评估。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN1ySFJbNDEBTwFWg6RPlYYRuZwK4muouZ99hGHCDZuCAMMUqdXRlQFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.3247549019607843" data-type="png" data-w="816" data-width="816" data-height="1081" data-imgfileid="503526961" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/29fa0fc0-3af3-495c-a5f9-0ad677198d47/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNTaseH8O1nZ69UOBeZ4nFOneZNhrZpo5ibljdOs5oYAKpRS1BY419BLw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.1015473887814313" data-type="png" data-w="1034" data-width="1034" data-height="1139" data-imgfileid="503526962" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/7b75f2f1-0a27-4ec9-ba1b-b42d68da604d/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNyp06QLopg6O7x7UkNickrOYKIn9Kuz3Oj7ylo9lebUmMHBH5TzV1VPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.940854326396495" data-type="png" data-w="913" data-width="913" data-height="859" data-imgfileid="503526963" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0741bb26-c6ec-4952-8508-3c537ce8716c/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23"&gt;&lt;strong&gt;任务形式与数据流水线&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="24"&gt;该基准支持 视觉评分（Visual Rating, VR） 和 视觉问答（Visual Question Answering, VQA） 两种互补的任务形式。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNibvnKvy36DNZLY2wRLpI7q7NcusjkKWDSIuldL0EvJNYD3viap6KSP1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6194444444444445" data-type="png" data-w="1080" data-width="1922" data-height="1191" data-imgfileid="503526965" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/e6799172-32a8-4984-8e6e-e1b3a147ca07/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="25"&gt;为了确保数据质量，研究团队设计了三阶段自动化流水线：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="26,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="26,0,0"&gt;初始生成&lt;/b&gt;：利用先进多模态模型结合专业准则库生成候选问答对。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="26,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="26,1,0"&gt;拒绝采样&lt;/b&gt;：由异构判别模型对问题的有效性、答案的准确性及逻辑一致性进行五分制打分，剔除约 40% 的不合格样本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="26,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="26,2,0"&gt;人工精修&lt;/b&gt;：组织专业志愿者进行手动核验，特别是对边界案例进行修改，确保最终结果与人类专家感知高度对齐。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN2XoIR3MpZYHjNz9Bu3n4lmZxuYf7yVaEVnnanHT3KMEEl7GOjoicfaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.23981481481481481" data-type="png" data-w="1080" data-width="1929" data-height="463" data-imgfileid="503526966" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/113c196c-6d30-4289-982c-b0636cfd94f1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;strong&gt;UniPercept 模型：领域自适应与任务对齐强化学习&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;为了使模型具备真正的感知能力，研究者采用两阶段框架对基础多模态模型进行持续演进。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;&lt;b data-index-in-node="0" data-path-to-node="29"&gt;领域自适应预训练（Domain-Adaptive Pre-Training）&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="29"&gt;研究团队整合了约 80 万个样本的大规模语料库，涵盖文本描述、结构化标注和数值评分。通过这一阶段，模型习得了跨领域的底层视觉特征，为其后续的精准判断打下了相应的感知基础。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;&lt;b data-index-in-node="0" data-path-to-node="30"&gt;任务对齐强化学习（Task-Aligned RL for VR &amp;amp; VQA）&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="30"&gt;这是提升模型感知一致性的关键。研究者采用了 GRPO 算法进行策略优化，并针对感知任务设计了特定的奖励函数：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="31,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="31,0,0"&gt;视觉问答（VQA）任务&lt;/b&gt;：采用二元奖励，鼓励模型输出准确的离散答案。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="31,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="31,1,0"&gt;视觉评分（VR）任务&lt;/b&gt;：创新性地设计了 自适应高斯软奖励（Adaptive Gaussian Soft Reward）。该函数根据模型预测值与参考分数的偏差动态调整平滑系数。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="32"&gt;这种软奖励机制提供了更平滑的梯度，避免了传统阈值奖励导致的优化不连续性。此外，模型引入了评分 Token 策略，直接从预测概率分布中导出数值，大幅缓解了模型生成数字时的幻觉倾向。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN7JVI4EK8xwoUclhNrvD35GJuPTlsNm2Avo2SGeZibGicB9vLzQHS59TA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.2611111111111111" data-type="png" data-w="1080" data-width="2413" data-height="629" data-imgfileid="503526967" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/d64b68cf-c1f8-49b3-976b-fd0d14af665e/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;性能：全面超越现有顶尖模型&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;研究团队在 UniPercept-Bench 上评估了包括商用闭源模型系列、领先开源系列以及针对美学和质量优化的专用模型在内的 18 个模型，UniPercept 在其中取得了显著优秀的表现。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;&lt;b data-index-in-node="0" data-path-to-node="35"&gt;视觉评分（VR）表现&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="35"&gt;在持续分数的回归任务中，大多数通用模型在没有针对性训练的情况下表现较差。相比之下，UniPercept 在所有三个领域（美学、质量、结构）中均取得了最高的斯皮尔曼相关系数（SRCC）和皮尔逊相关系数（PLCC）。尤其是在 ISTA 领域，UniPercept 填补了现有模型对细节纹理判断的空白。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNZpTibeNWlhdg4iaqRJibSbKmI7jmk6WHH33TiaO3sm3ciaL2TiabampR8FzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.36018518518518516" data-type="png" data-w="1080" data-width="2133" data-height="769" data-imgfileid="503526968" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/8c7f52d0-bfc2-4985-a4ba-81b4aca17c44/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="36"&gt;&lt;b data-index-in-node="0" data-path-to-node="36"&gt;视觉问答（VQA）表现&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="36"&gt;实验显示，即使是目前最顶尖的商业模型在处理精细感知问题时也显得吃力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="37,0,0"&gt;在 图像美学评估（IAA） 领域，UniPercept 的准确率超越了 GPT-4o 约 16 个百分点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="37,1,0"&gt;在 图像质量评估（IQA） 领域，UniPercept 在识别特定物体上的细微损伤（如运动模糊、压缩畸变）方面展现出极强的定位与判断能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="37,2,0"&gt;在 图像结构与纹理复杂度评估（ISTA） 领域，模型能够准确分辨不同材质的表面特性（如镜面反射、亚光纹理），准确率突破 80%。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNYG3PfKpJXoqatTpoUz6ibZ0aJmicB6lMwHhPEpZSvfiaHAPoXR45pOAbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4083333333333333" data-type="png" data-w="1080" data-width="2144" data-height="876" data-imgfileid="503526969" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5ead633c-bb49-4918-b2f5-58497f3c32c5/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNoObia7zK3iaX65OzYuE2L9wvmiajocul6VtrG7huGm8zdK56zOtciapFkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3685185185185185" data-type="png" data-w="1080" data-width="2146" data-height="790" data-imgfileid="503526970" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/10f8758d-f7cc-4637-8be5-7cf3185a1fd2/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNOoPTUwFmWG5EgwE0dkro7etymvibGVyJVWrV2HHxh84gN9FNyiawfpCg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.36666666666666664" data-type="png" data-w="1080" data-width="2145" data-height="786" data-imgfileid="503526971" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/3dcde7fd-da53-4af3-a1a5-3cd2fc31b9a3/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="38"&gt;&lt;strong&gt;应用：作为奖励模型/评估指标&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="39"&gt;UniPercept 展示了作为生成模型优化信号的巨大潜力。研究者将其作为奖励模型，整合进文生图模型的微调流水线中。UniPercept 主要从以下三个方面对生成模型进行优化：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="40,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,0,0"&gt;美学引导&lt;/b&gt;：显著改善生成图像的构图平衡和光影和谐度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,1,0"&gt;质量引导&lt;/b&gt;：增强图像细节的锐度和清晰度，减少常见的伪影干扰。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,2,0"&gt;结构纹理引导&lt;/b&gt;：丰富了场景的复杂程度、结构的丰富度、物体的表面肌理，使画面表现更丰富。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="41"&gt;不同奖励信号有着不同的优化侧重点，当三个维度的奖励信号协同作用时，生成的图像在视觉吸引力和技术保真度上均达到最优。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN8vzVmOiaWl6IXFNXKoAN24CbMuJtYePuQPTHDsE7WQt18k1LFkzbRMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.21481481481481482" data-type="png" data-w="1080" data-width="2093" data-height="450" data-imgfileid="503526972" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/dca2cd4b-388e-4a08-95c3-75fee5739186/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNZbDUjlUCFo0jFKIYQKTo9Suz5l8aZP9PajYoZvzNUBn9Su5gaI8OJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.7148148148148148" data-type="png" data-w="1080" data-width="1726" data-height="1233" data-imgfileid="503526973" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/a6d6d6cd-0a59-4bd3-8bfa-ff02020856a6/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="42"&gt;此外，UniPercept 天然可以作为从美学、质量、纹理与结构三方面对于图像进行评估的 &lt;b data-index-in-node="45" data-path-to-node="42"&gt;评估指标（Metrics）&lt;/b&gt;，可以准确反映不同模型输出图像的各方面表现。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNrEu9ERGbcvqGwY8fsQDlJkScyKFJ64GcSk7b6fXAeaqkd1B0AatWag/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.6518518518518519" data-type="png" data-w="1080" data-width="1828" data-height="1192" data-imgfileid="503526974" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/7cb0d56d-9f91-4359-8848-6f5ce0a5951a/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="43"&gt;&lt;b data-index-in-node="0" data-path-to-node="43"&gt;生成图像的全方位「感知档案」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="43"&gt;UniPercept 还能为图像生成全方位的「感知档案」，不仅给出评分，还能从美学、质量、纹理与结构三个方面针对构图、执行精度、损伤位置等具体维度给出详细的文字解析与结构化输出。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN9PtftJ80yz1VB6xcQbzgrYCyF4M4icYLN2vb637micuHwnwlfcI0NtEw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=17" data-ratio="0.4861111111111111" data-type="jpeg" data-w="1080" data-width="11276" data-height="5483" data-imgfileid="503526975" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/6a5626d2-ac93-4e10-80a6-d435c384cfa5/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="44"&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="45"&gt;UniPercept 的提出，是多模态大模型的研究重心正在从单纯的语义识别，向更具挑战性的「感知图像」转化的重要一环。通过建立统一的评价基准、高效的数据生产线以及新颖的任务对齐学习策略，UniPercept 为未来的视觉内容评价与可控生成提供了一个强大的底座。它不仅是研究感知的有力工具，更是构建「感知闭环」系统的重要一步。&lt;/p&gt;&lt;p data-path-to-node="46"&gt;随着感知级理解能力的不断提升，人工智能将能够像人类艺术家一样，不仅能看懂画面中的故事，更能体会并创造出具备极致美感与精湛质感的视觉作品。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>没错，马斯克的二次元「女友」被雷蛇装到外设里了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 07 Jan 2026 17:48:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/20d62751-f164-4424-879c-3b052e5bb58a/1767779083702.png" style="width: 700%;" class="fr-fic fr-dib"&gt;AI 助手以类似手办的形式出现在桌面上，这样的场景你想象过吗？&lt;/p&gt;&lt;p&gt;近日，CES 2026 展上，在琳琅满目的 AI 为核心的技术与产品中，一个「装在罐子里」的二次元少女形象的「桌面 AI 伙伴」，成为其中最具话题性的展示之一。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q854floIdwiamUw7ic4UsJHBO9l5LLgo81eGibsrgKwxZHxdE6oM3kW0SWMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7675925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527112" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a064961d-375a-491d-93e7-4366885e45a0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;具体来看，这是一个 5.5 英寸的桌面全息胶囊，里面是一个身穿绿色裙子、黑色过膝袜的动态二次元少女。&lt;/p&gt;&lt;p&gt;从现场网友的互动反馈来看，不同于常规的 AI 语音助手，这个虚拟形象是呈现在实体设备上的 3D 立体形式，并且能够做到「既看你，也看你的电脑屏幕」，所以对用户所处的情境感知更广泛、全面，交互时也更为友好。&lt;/p&gt;&lt;p&gt;了解后发现，这是由游戏外设公司 Razer （雷蛇）推出的 Project Ava，官方定位是「与您形影不离的 AI 桌面伴侣」，以 5.5 英寸的 3D 全息动画形式呈现，运用类人的视觉和听觉认知能力，实现全面旋转认知，且基于 AI 驱动，拥有动态个性，能够根据互动不断学习和进化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85WYHGsUHPQicNevdGfX7kjmoM4dT8BIgVTYsbjbJU20ZeqvdLo18aebg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6768518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527118" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7b1ba5a9-4ca7-4fd0-91b0-c613fde9c5d2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其实，去年 Razer 就开始推出 Project Ava，只不过当时还只是一个概念上的 AI 游戏教练，今年就将其实现实体化。&lt;/p&gt;&lt;p&gt;官方显示，目前，Project Ava AI 伙伴的全息投影形式在形象选择上有5种，每个形象都会其独特的风格和气质，比如一个能量球形式的AVA、二次元少女 KIRA、肌肉型男 ZANE、戴眼镜的的电竞选手 FAKER，以及日本网红 SAO。另外，这些虚拟形象还可以进行自定义，包括从零开始创建自己的角色，后续官方还会继续开发推出其他形象，包括与一些网络红人合作，提供角色形象等。&lt;/p&gt;&lt;section align="" alt="" border="" data-aiimageid="" data-aiimagesource="" data-aistatus="1" data-asynid="" data-backh="" data-backw="" data-before-oversubscription-url="" data-cacheurl="" data-cardimg="" data-copyright="" data-croporisrc="" data-cropselx1="" data-cropselx2="" data-cropsely1="" data-cropsely2="" data-cropx1="" data-cropx2="" data-cropy1="" data-cropy2="" data-fileid="" data-fromlib="" data-galleryid="" data-gallerysupplier="" data-height="" data-imgfileid="503527122" data-imgid="" data-imgqrcoded="" data-oversubscription-url="" data-positionback="" data-ratio="0.4089012517385257" data-remoteid="" data-retry="" data-s="300,640" data-src="" data-type="png" data-upload="" data-w="2876" data-width="" height="" ismap="" sizes="" src="" title="" type="block" usemap="" width=""&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85OFyhRqoib6dNNZ5kqASyY2jzZKjNURTPzefFvdK0jdJoWhxb70r8XCg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.40925925925925927" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527123" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d649f8da-81ee-461b-9630-930e95ab2c51/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;宣传中提到的「&lt;strong&gt;既看你，也看你的电脑屏幕&lt;/strong&gt;」，从设计上看，圆柱形桌设备顶部装有一颗朝外的摄像头，在放置上要与笔记本电脑或显示器并排放置，作为 AI 助手的专用显示屏，使其与游戏屏幕分离，而非覆盖在游戏画面之上。&lt;/p&gt;&lt;p&gt;核心技术亮点在于&lt;strong&gt;其多模态感知与交互能力&lt;/strong&gt;，设备配备高清摄像头、环境光传感器和双远场麦克风，实现所谓的「类似人类的视觉和听觉感知」，摄像头通过持续观察用户和屏幕内容，实现眼球追踪、面部表情识别和唇形同步，从而能够实时感知用户所处的环境与状态，实时在线响应用户的交互。&lt;/p&gt;&lt;p&gt;至于具体能做什么，Razer 介绍了几种场景，比如玩游戏时，帮助玩家掌握复杂的游戏攻略，还会在玩家紧张时给予安慰和鼓励，提供情绪价值；工作场景中，能够提供专业咨询和解决方案，另外还能够帮助安排日程、规划日常活动等。&lt;a href="https://mp.weixin.qq.com/s/XyOWgZeOArHGkYlo6LegDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5a14cff6-6add-42cc-a24c-6c7f0fbfe08e/1767779183154.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;据 Razer 产品营销总监大卫・吴表示，&lt;strong&gt;Project Ava 的目标受众是那些热衷于定制桌面设备的科技爱好者&lt;/strong&gt;。而该项目将于今年下半年推出，具体的价格还尚未公布，不过目前支持用户预定，费用为 20 美元。&lt;/p&gt;&lt;p&gt;不过，虽然还没正式出售，但听说&lt;strong&gt;官方豪言计划卖出「十亿台」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;另外，有意思的是，&lt;strong&gt;目前 Project Ava 形象各异的背后共用一个「灵魂」，就是由马斯克 xAI 的 Grok 大模型驱动&lt;/strong&gt;，而这一点，也让大家「又爱又恨」&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527126" data-ratio="0.7648148148148148" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85kyqDmic0k91ZgoncXXOYRFZib56oNDDw9z5icMM06zYG6lHrxCPHwJVog/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="width:500px;height:383px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/fc21cff8-e650-494d-b6c8-a201821aa789/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;机器之心之前报道过&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650979993&amp;idx=1&amp;sn=e9b3dcd2151d229e0ccae89f0e9ddb5b&amp;scene=21#wechat_redirect" target="_blank"&gt;马斯克Grok这个二次元「小姐姐」，攻陷了整个互联网&lt;/a&gt;，去年 7 月的时候，Grok 推出一个新功能「智能伴侣」，用户启用「伴侣」按钮、选择心仪角色后，可以与其进行交流，目标就是吸引那些对动漫、虚拟伴侣以及高级 AI 语音感兴趣的用户。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527124" data-ratio="0.8077669902912621" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q855Ssv2QY8mAibbXOCOkxrZkexSywyWgAJxZgvw7QzNzMoBEvaXbrmCUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1030" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b2a7807c-a455-4323-8768-fbb134ffc099/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当时的用户反馈就褒贬不一。因为有用户认为，「伴侣」的形象虽然可以定制为男性、女性，甚至动物，但其中名为 Ani 女性角色被设计成挑逗又轻浮的形象，让人感到不适。&lt;/p&gt;&lt;p&gt;而此次，在 Project Ava 身上，Grok 那种特有的「调情」风格似乎展露无遗&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;体验者不仅感受到了莫名其妙的过度热情，甚至 Kira 无论从说话语气还是衣着风格，都让人觉得是 Grok 的「AI 女友」Ani 换了个 Razer 的皮肤「重生」了。&lt;/p&gt;&lt;p&gt;国外的一个记者在展会上试着与 Kira 交流，据他说，Razer 为 CES 预设了 Kira 的开场白：「哇！Razer 展台上出现了新面孔？太棒了！我该怎么称呼你呢？」&lt;/p&gt;&lt;p&gt;接着就开始询问是否在展会上看到新鲜好东西，在得到否定回答后，Kira 就开始大段的自我介绍，「我是 Kira，来自 Razer 的 Project Ava 项目，由 Animation Inc. dot com提供技术支持，我在这个项目里还有其他朋友，但今天只有我和 Zane。我是最漂亮的，只为你而漂亮。哈哈&amp;hellip;&amp;hellip;」&lt;/p&gt;&lt;p&gt;之后的多次交流中，Kira 多次发出「哈哈！」的惊叹声，让记者感到距离「调情」也就只有一步之遥&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85OE6s9HHia9MNmh1UmN9Ey84L6zS3qglqfhP6z74NQuHJVQaluib0TzNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5351851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527125" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/06a8a23a-0716-4fbc-9eb1-d4c7746d4271/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不过，据 Razer 称，预计未来 Project AVA 也将支持其他 AI 平台。&lt;/p&gt;&lt;p&gt;但也有不少网友借由 Project Ava 看到了 Grok「智能伴侣」实体化的可能，纷纷喊话马斯克。&lt;/p&gt;&lt;p&gt;「埃隆・马斯克，你打算什么时候给Ani做这个？」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85TlXyN4HdkibaJ9kw06picndkmF0qJdyTJX6UuuUcACKcRtWq6M3Oj9ZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.10462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527129" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/cc6579b5-cf5d-4d7e-96cc-800b19ca4dc7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;「我一直在努力让埃隆接受这个想法。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85tbgxkcLXsFfEffFOqcdLMlO0aicibD6FNRGR420MkMRGN8naha1KYDuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.8472222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527130" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f824dbb2-2a8b-4360-b6a9-5fe08ca50b16/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其实除了这些，Project Ava 还有一个争议在于其&lt;strong&gt;「过度的侵入性」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;前面提到 Project Ava 的一个卖点是「既看你，也看你的电脑屏幕」，好处是设备拥有能够直视用户的摄像头，在分析显示屏游戏画面的同时也在看着用户，在交互时，会给用户营造一个「像是在与一个角色互动」 的沉浸感&amp;mdash;&amp;mdash;不需要启动按钮、不需要唤醒词，TA就在你身边。&lt;/p&gt;&lt;p&gt;但是，这种对用户个人隐私的过度让渡，使得 AI 随时可能通过观察用户的表情来发起话题，甚至评价穿搭，这种「打破第四面墙」交互会不会在当下隐私敏感环境下显得格外刺眼，给用户带来不适呢？这是一个值得思考的问题。&lt;/p&gt;&lt;p&gt;那么你呢，你如何看待这种形式的 AI 伙伴？欢迎在留言区畅所欲言！&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Grummz/status/2008600200579850664?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Grummz/status/2008555915419807789?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/BenjaminDEKR/status/2008599327829357026?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/tech/854705/razer-ai-anime-waifu-hologram-desk&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.businessinsider.com/razer-project-ava-ai-companion-hologram-2026-1&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>从过拟合到通用！ViMoGen开启3D人体动作生成新纪元</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 07 Jan 2026 17:43:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/4c36f015-c670-47f0-b6e2-cd38bdbde1d5/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着 AIGC（Artificial Intelligence Generated Content） 的爆发，我们已经习惯了像 Sora 或 Wan 这样的视频生成模型能够理解「一只宇航员在火星后空翻」这样天马行空的指令。然而，3D 人体动作生成（3D MoGen）领域却稍显滞后。&lt;/p&gt;&lt;p&gt;现有的模型在标准数据集上表现良好，但在泛化能力上仍存在明显瓶颈。一旦用户输入训练集中未见过的复杂交互或罕见动作，生成的动作往往会缺乏自然性、崩坏或退化为简单的平均姿态，这严重限制了其在现实场景和交互系统中的应用。&lt;/p&gt;&lt;p&gt;那很自然地就会思考：&lt;strong&gt;视频生成模型已经初步学会了通用的物理规律和人类行为，为什么不把这些知识「蒸馏」给 3D 人体动作生成模型呢？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526849" data-ratio="0.4638888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaib6AVQ57VSW0KRuj136oFNRRu7bHKAYcPINZT712Cx4bDwKPJicoMjQ1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/96076c19-e7c9-41c4-9379-a09d97ad2486/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibhUzpsddhmKknSe5hZWFQIwGVQ5LBbEEIO91dCVY9T22DAWZibPsZMaQ/640?wx_fmt=jpeg#imgIndex=2" data-ratio="0.3111111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibAIJiajgBh9wFsRibGy1V9Hl7p48odJ1VoUIXNfpNjZcfsB8Gk9ZJpJCw/0?wx_fmt=png&amp;from=appmsg" data-cropx1="5.797153024911032" data-cropx2="1086" data-cropy1="40.580071174377224" data-cropy2="376.8149466192171" data-imgfileid="503526836" data-aistatus="1" data-original-style="width: 559px;height: 174px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/989c4b07-ff00-4c4a-a4ae-dbe5eed55fb8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2510.26794&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://linjing7.github.io/vimogen/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;ViGen-to-MoGen 的三大支柱&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;来自&lt;strong&gt;南洋理工大学、商汤科技、清华大学、香港中文大学和英伟达的研究人员&lt;/strong&gt;提出了题为 &lt;strong&gt;《The Quest for Generalizable Motion Generation: Data, Model, and Evaluation》&amp;nbsp;&lt;/strong&gt;的最新研究成果。这项工作从&lt;strong&gt;数据、模型、评估&lt;/strong&gt;三个维度重新定义了通向通用动作生成的路径。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据 ViMoGen-228K&lt;/strong&gt;:&amp;nbsp;结合了从 30 个 MoCap 数据集中筛选的高精度数据，海量互联网视频与由视频模型（Video Gen）合成视频中提取的动作数据，包含了大量罕见、复杂的交互动作，突破了传统数据棚采集的物理限制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型 ViMoGen&lt;/strong&gt;:&amp;nbsp;采用&lt;strong&gt;Text-to-Motion (T2M) 与 Motion-to-Motion (M2M)&amp;nbsp;&lt;/strong&gt;双分支架构。通过门控机制，将视频生成模型的语义先验与 MoCap 的物理先验完美统一。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;评估 MBench&lt;/strong&gt;: &lt;strong&gt;首个面向「泛化性」的评测基准。&lt;/strong&gt;从动作质量、文本忠实度、泛化能力三大维度（细分 9 项指标）对模型进行全方面测评，是目前最全面的动作生成评测方式。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;数据 ViMoGen-228K &amp;mdash;&amp;mdash; 规模与多样性的双重飞跃&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统动作数据集（如 AMASS）虽然精准但语义单一。ViMoGen 引入了 ViMoGen-228K 数据集，包含约 22.8 万条高质量动作样本。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多模态覆盖&lt;/strong&gt;，包含文本&amp;ndash;动作、文本&amp;ndash;视频&amp;ndash;动作多模态三元组。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多来源实现泛化能力提升&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对来自 30 个公开高质量的光学动作捕捉数据集进行了筛选和重标注。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;从网络视频提取动作序列与语义标签。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;利用视频生成（ViGen）模型生成了在真实动作捕捉中极难获取的长尾动作，填补了语义空白。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;模型 ViMoGen &amp;mdash;&amp;mdash; 多源先验知识的深度表征与协同优化探索&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526851" data-ratio="0.36944444444444446" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaib9iaRWJyRrI8iaZ2vDUL97zoqviaicog0Q5mC6iaDRic6BUIlicN5HAHESNE9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6cb336ab-4825-4cf2-89a6-e61f044f35e5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNv76S2RyzrEIIOVEObevYkNcgMQCq7mErbSsgq0kq9Z9EjvGJY41w7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.28703703703703703" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527084" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/ac0a0379-3408-4749-b225-039cd897bf47/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibicBWv174ZnF7PV8v2j6jcicbe1AJdDxDEWxATgPUNgzIgtft3r9icJPTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526852" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d3f33ab7-2422-409b-a20f-241f29ee34bf/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;ViMoGen 模型巧妙地通过门控机制控制 &lt;strong&gt;Text-to-Motion (T2M)&amp;nbsp;&lt;/strong&gt;分支与 &lt;strong&gt;Motion-to-Motion (M2M)&amp;nbsp;&lt;/strong&gt;双分支，同时利用 MoCap 数据的精准先验和 ViGen 模型的广泛语义先验。该架构模型不仅在传统动作生成测评上取得较好的分数，同时也通过文中提出的 MBench 测评基准，体现了它在泛化性上的卓越表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;测评 MBench &amp;mdash;&amp;mdash; 多维分层评测体系&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526862" data-ratio="0.31851851851851853" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibudNFHQnH8LWKIOaQGZf3UebLLSyhTWvWeAdQqPPocVHrDdsfeMQblg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/063f7efa-a877-4c13-a915-7c0305805cb0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;传统的 FID（Frechet Inception Distance）等指标只能衡量生成动作与特定动作集分布的相似度，却无法体现模型在处理复杂、罕见指令时的真实泛化能力。MBench 将评测拆解为相互关联的三个层面，并细化为 9 项具体的量化指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;动作质量 (Motion Quality)&amp;nbsp;&lt;/strong&gt;关注动作的合理性。通过计算与地面物理接触、穿模情况以及脚步抖动和平滑度，评判生成动作的动作的物理可实现性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令忠实度 (Motion-Condition Consistency)&amp;nbsp;&lt;/strong&gt;利用多模态大模型评估生成动作与复杂文本描述的一致性。例如，模型是否准确还原了文本中提到的方位（&amp;ldquo;向左后方倒下&amp;rdquo;）或特定的交互逻辑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开放世界泛化力 (Motion Generalizability)&amp;nbsp;&lt;/strong&gt;设计了一系列 Out-of-Distribution (OOD) 测试案例，涵盖了极端动作、长尾语义以及复合指令，专门考验模型在未见过场景下的稳定性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;赋能具身智能，构建 Real-to-Sim 的高质量动作桥梁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在当前的人形机器人控制研究中（如 [arXiv:2505.03729] ），研究者通常依赖海量的 SMPL 参考轨迹（Reference Motions）来训练高鲁棒性的控制策略（Policy）。然而，&lt;strong&gt;传统数据的匮乏严重限制了机器人动作的演化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的机器人训练往往局限于几套标准的行走动作。而 ViMoGen-228k 能够带来大量长尾、边缘场景（Corner Cases）高质量动作， 同时 ViMoGen 凭借强大的泛化能力，能够批量产出一些特殊需求的动作数据。这些数据能够让具身智能体在虚拟训练阶段就完成了对复杂动态的预演，使其在现实部署中具备更强的抗干扰能力。&lt;/p&gt;&lt;p&gt;同时 MBench 针对动作质量的一系列评估，能够为下游的 Real-to-Sim 过程做初步筛选，从而排除了可能导致机器人频繁跌倒或关节自锁的无效动作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果展示&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526863" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibQoNECzULHUIQ7qGXuA69nnYgjCApNA9vGGr9VNHmibUOH65xnP0ySzw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-type="gif" data-w="800" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/85613a2f-3087-4e09-8e11-8fcf01639b9d/640.gif" data-order="0" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;空翻&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令&lt;/strong&gt;：一个人俯身蹲低，双腿积蓄力量，随后蹬地猛然跃起，下巴紧贴胸口。身体蜷缩成一个紧密的球状，在空中优雅地翻转。随着空翻动作的完成，他舒展双腿，膝盖微屈平稳着陆，双臂向外伸展以保持平衡。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibLYVibIAVIBokqw3mURkbMnvicwaian8cB6auRVUwia33WKg1Bo0y1KF5Iw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="1" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503526864" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/9bafb99f-775d-4bbe-810f-7b8862957097/640.gif" data-order="1" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 多球杂耍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令&lt;/strong&gt;：一个人双脚与肩同宽站立，目光紧盯着空中的彩色球。凭借熟练的手腕甩动，他们将每个球依次抛向空中，划出流畅的弧线，双手以协调一致的节奏交替动作。球不断升起又落下，形成连续的循环，杂耍者的动作流畅而精准，在整个表演过程中始终保持着完美的节奏与平衡。&lt;sup&gt;&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibYnzz5OCJ43tPduCnnUibK3H1OFkJEo5Ht4HetYGvWJ66hLtsb237V9Q/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="1" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503526865" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/38339843-283c-4e77-8211-c8a099a95b5c/640.gif" data-order="2" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 引体向上&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令&lt;/strong&gt;：一个人在单杠上进行一组标准的引体向上。从双臂完全伸直的悬垂状态开始，利用背部力量将身体垂直向上拉起，直到下巴超过单杠。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526867" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibmKZReP3zoAKMibKgg8org9pIkjSdqD4cV6WBo9t8HHzfL2mO4oY3iaicQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-type="gif" data-w="800" type="block" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c8f82e33-024c-4a40-b4a7-cdbd889b7498/640.gif" data-order="3" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 空手道&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令&lt;/strong&gt;：一位武术家在前进的同时，执行一套动态的空手道组合动作。&lt;br&gt;&lt;img data-aistatus="1" data-imgfileid="503526868" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibYsIZciboiabuDiaKhVd9urlWmiaEWF1KTiaF2icdGyNYib9biaPgrjY4oqqCUQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-type="gif" data-w="800" type="block" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/957f393a-745b-48f2-b549-a92edad185db/640.gif" data-order="4" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 推箱子&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;指令&lt;/strong&gt;：一个人身体前倾，双手抵住一个巨大的重型箱子，在保持接触的同时缓慢向前迈步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文由&lt;strong&gt;南洋理工大学、商汤科技、清华大学、香港中文大学及英伟达&lt;/strong&gt;的顶尖学者合作完成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;林靖、王睿思、鲁俊喆&lt;/strong&gt;为共同第一作者。&lt;strong&gt;林靖是南洋理工大学博士生&lt;/strong&gt;，研究大模型驱动的 3D 感知、生成与理解；&lt;strong&gt;王睿思为商汤研究员&lt;/strong&gt;，兴趣方向在高性能计算与大模型空间智能；&lt;strong&gt;鲁俊喆是清华大学硕士&lt;/strong&gt;，研究生成式模型和 3D 计算机视觉。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>蚂蚁数科风控智能体落地百望股份 可实现一句话完成风控建模</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 07 Jan 2026 17:04:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;近日，百望股份与蚂蚁数科正式达成合作。双方将充分整合各自核心优势，推动大模型技术与海量数据的深度融合及创新应用，加速数据价值释放，共同打造AI时代的“数据智能基础设施”新范式。&lt;/p&gt;&lt;p&gt;作为国内领先的数据智能服务商，百望股份在行业深耕多年，已累积处理超231亿张交易凭证，沉淀超千万亿级数据，服务覆盖2850万企业客户的多元场景实践。目前，百望股份已构建起覆盖智能财税、智能风控、智能决策、智能营销等全链路的产品体系，为企业数字化转型提供全方位支撑。&lt;/p&gt;&lt;p&gt;此次双方合作将率先聚焦于智能风控场景。基于蚂蚁数科的风控智能体技术，将助力百望股份的智能风控产品实现从“经验驱动”迈向“智能生成”。&lt;/p&gt;&lt;p&gt;据了解，蚂蚁数科的风控特征智能体能够辅助人类专家挖掘海量数据的高价值特征，解决传统模式中高度依赖专家经验、积累周期长、试错成本高的痛点，由智能体去“激发灵感”，可实现特征挖掘效果突破专家个人经验，最高实现模型性能提升32%。蚂蚁数科的风控建模智能体能够依托大模型的意图识别和任务规划能力，自主构建建模流程，可实现最少一句指令完成理想建模，将建模耗时缩短30%，且建模效果比肩人类专家。&lt;/p&gt;&lt;p&gt;“此次合作将推动百望股份的智能体平台，从‘数据汇聚与治理’的1.0阶段，直接跃升至‘具备金融级可靠性与业务理解力的数据智能自主生成’的2.0阶段。这不仅有助于提升企业运营效率，也将为客户在合规、风控及经营决策等方面提供更精准和高效的智能支撑。”百望股份CTO王志伟表示。&lt;/p&gt;&lt;p&gt;蚂蚁数科是蚂蚁集团旗下科技业务子公司，专注企业级AI及Web3服务。旗下企业级智能体平台Agentar凭借全栈技术能力与丰富产业实践入选IDC中国智能体开发平台领导者。目前，蚂蚁数科在风控、营销、数据分析等企业核心经营场景，推出超百个智能体联合解决方案，助力大模型在产业的规模化应用与业务价值实现。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
