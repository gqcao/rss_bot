<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>钉钉上线AI差旅：企业免垫资，员工免报销，AI帮比价</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 11:58:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;一趟差旅回来，员工不用再为整理发票头疼，财务无需核对上百张零散票据，而公司却能省下大笔开支&amp;mdash;&amp;mdash;这样的场景正在钉钉上成为现实。钉钉最新推出的&amp;ldquo;AI差旅&amp;rdquo;功能，正试图改变中小企业出差的烦恼。&lt;/p&gt;&lt;p&gt;1月20日，钉钉更新8.2.5版本，由钉钉、高德、支付宝合作的&amp;ldquo;AI差旅&amp;rdquo;产品正式上线，所有企业用户在最新的钉钉内搜索&amp;ldquo;AI差旅&amp;rdquo;、&amp;ldquo;差旅用车&amp;rdquo;、&amp;ldquo;机票&amp;rdquo;、&amp;ldquo;酒店&amp;rdquo;等相关关键词，即可零门槛、免费开通这一服务，无需垫资或支付服务费。在该版本中，AI印、AI听记同声传译等能力也全量上线。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5ce959d0-6837-4852-a315-5118dcb0e12c/1768881390350.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;把中小企业的差旅成本打下来，AI差旅让企业免垫资、员工免报销&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;钉钉AI差旅专为500人以下中小企业打造，整合了高德打车、支付宝企业支付等能力，为用户提供机票、酒店、火车票及用车四大核心场景的差旅服务。与市面上其他商旅平台相比，钉钉AI差旅直连锦江、如家、东呈、亚朵、雅斯特等酒店集团系统，酒店预订更便宜。该产品还提供AI比价功能，为用户在全网自动搜索比价，实时获取多个预订平台的酒店价格，来找到最低价的选项。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f4947085-55c4-4ca0-b594-d106d6c8890d/1768881418508.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;对经常出差的员工来说，AI差旅的差旅助理让出差更简单，实现一句话规划行程，即使是复杂的多城市路线也能在30秒内给出最优方案，并自动生成出差单，无需手动填写。&lt;/p&gt;&lt;p&gt;更让员工感到便利的是，钉钉与高德合作推出的&amp;ldquo;无感报销&amp;rdquo;用车功能。员工提交外出或差旅申请后，可直接在审批单内或通过搜索&amp;ldquo;高德打车&amp;rdquo;叫车；行程结束后，发票和行程单自动关联至对应的审批单，彻底告别了手动翻找票据的繁琐。在支付环节，钉钉携手支付宝企业码提供了企业代付能力，员工出差无需垫付，企业可按需开通。&lt;/p&gt;&lt;p&gt;对企业管理层，AI差旅内置了专业的差旅管理能力，可以自定义差旅标准，设置机票预订时限、酒店价格区间、火车席别等级；产品还可生成按部门、按员工维度的明细和排行榜，让差旅成本真正做到可视、可控。&lt;/p&gt;&lt;p&gt;在杭州一家机器人企业&amp;ldquo;原力无限&amp;rdquo;，HR负责人现场对比了钉钉和其他出行平台的价格后，当场决定启用。&amp;ldquo;钉钉上的酒店资源不仅连锁品牌全覆盖，价格也非常能打。&amp;rdquo;启用一月后，员工从提交申请到完成报销的全流程周期，从过去的10天大幅压缩至3天，公司当月差旅开支直接省下约15万元。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计打印太贵太麻烦？AI印让海报设计印刷像&amp;ldquo;网购&amp;rdquo;一样方便&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;同时上线的钉钉AI印，则将企业的物料设计和印刷流程打包在钉钉里，它能够提供从AI素材设计再到物料打印、物流接收的全流程支持，让用户享受到更有保障、更低成本、更高品质的海报设计及印刷服务。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8236934-07a1-4b8f-ae30-e79230888b3e/1768881433472.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;过去设计靠外包、印刷要货比三家、物流难追踪，如今通过钉钉AI印，没有设计基础的运营、市场人员也能几分钟生成和精修出专业海报，一键下单直连全国六大印刷工厂，易拉宝、彩页、宣传册等主流品类全覆盖，价格远低于打印店等传统渠道，主要城市最快半日送达。&lt;/p&gt;&lt;p&gt;杭州扶一把网络科技有限公司CEO蒋迎安坦言：&amp;ldquo;以前打个易拉宝要多方询价、反复沟通；现在一站搞定，AI设计+平台物流，品质、效率、确定性全都有，我们省去了到处比价的繁琐，也大幅提升品质与效率。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;外语不好没关系，AI听记为跨国开会配了AI翻译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在音视频协同方面，钉钉在8.2.5版本也进一步升级了AI翻译同传能力。在面对面沟通、跨国视频会议时，能及时听到翻译后的对话，就算外语不好，在国外旅游、开会时也不再焦虑。&lt;/p&gt;&lt;p&gt;面对面同声传译的新能力，不仅提供翻译字幕，也支持语音翻译。只要戴上一副普通的蓝牙耳机，即可实现中英日等多语种的实时互译，还可设置左右声道为不同语言，两人一人一只耳机即可顺畅沟通。钉钉视频会议则支持多语种双向同传，参会者只需设置自己的语言，即可在跨国会议中&amp;ldquo;听自己熟悉的母语&amp;rdquo;，会中还会自动生成纪要和待办，显著提升跨国协作效率。&lt;/p&gt;&lt;p&gt;&amp;ldquo;我们在国内和越南都有生产基地，在欧美都有分公司和经销商，每次开会涉及不同部门、国家和语言。AI同传让我们不再依赖专业翻译，也能实现周度月度的无障碍沟通&amp;rdquo;。杭州一家户外家居企业负责人表示。&lt;/p&gt;&lt;p&gt;从AI差旅到AI印，再到AI翻译，钉钉正把原本只有大企业才能享受的专业服务，通过AI下沉给更多中小企业，让出差不再折腾，印刷无需比价，跨国沟通不再焦虑，在降低成本的同时真正释放每一位员工的时间和精力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>零样本&amp;少样本横扫12个工业医疗数据集：西门子×腾讯优图新研究精准定位缺陷，检测精度新SOTA丨AAAI 2026</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 11:49:34 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;在工业质检与医学影像等真实场景中，&lt;strong&gt;异常检测&lt;/strong&gt;始终面临一个核心矛盾：&lt;/p&gt;&lt;p&gt;模型既要跨领域泛化，又要在几乎没有目标域数据的情况下，精确定位细微异常。&lt;/p&gt;&lt;p&gt;现实生产中，产线频繁换型，新产品刚投产，缺陷样本极少，而异常往往表现为局部、稀疏、小尺度的像素级变化。这使得大量依赖监督学习或目标域微调的方法难以真正落地。&lt;/p&gt;&lt;p&gt;近日，西门子与腾讯优图联合研究团队提出&lt;strong&gt;AdaptCLIP&lt;/strong&gt;，一种&lt;strong&gt;通用视觉异常检测框架，&lt;/strong&gt;具有以下亮点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;单一模型&lt;/li&gt;&lt;li&gt;无需目标域微调&lt;/li&gt;&lt;li&gt;同时支持&lt;strong&gt;图像级异常分类&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;像素级异常分割&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;兼容&lt;strong&gt;零样本&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;/&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;少样本&lt;/strong&gt;推理&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、为什么&amp;ldquo;通用异常检测&amp;rdquo;一直做不好？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通用异常检测要求模型在&lt;strong&gt;训练域与测试域分布显著不同&lt;/strong&gt;的前提下，仍能稳定检测异常。这一设定暴露了现有方法的结构性瓶颈：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;传统无监督&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;AD&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;方法&lt;/strong&gt;（如PaDiM、PatchCore、重建式模型）依赖大量正常样本，一旦面对未见类别或新领域，性能迅速退化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;驱动的方法&lt;/strong&gt;虽借助跨模态先验实现零样本检测，但代价并不小：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;WinCLIP 依赖密集窗口扫描，计算与显存开销巨大；&lt;/li&gt;&lt;li&gt;AnomalyCLIP、AdaCLIP 通过修改中间层或引入复杂token，削弱了 CLIP 的原始表征能力；&lt;/li&gt;&lt;li&gt;InCtrl、PromptAD 要么只支持图像级判断，要么仍需目标域重新训练。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;问题归结为一句话：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何在不破坏&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;原有泛化能力的前提下，让它真正学会&amp;ldquo;找异常&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、AdaptCLIP的答案：少即是多&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP&amp;nbsp;将&amp;nbsp;CLIP&amp;nbsp;视为一种&amp;ldquo;&lt;strong&gt;基础服务模型&lt;/strong&gt;&amp;rdquo;，不改动其主干结构，仅在输入与输出端引入&lt;strong&gt;三个轻量适配器&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视觉适配器（VisualAdapter）&lt;/li&gt;&lt;li&gt;文本适配器（TextAdapter）&lt;/li&gt;&lt;li&gt;提示-查询适配器（Prompt-QueryAdapter）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;并由两个关键洞见驱动：&lt;/p&gt;&lt;p&gt;1️⃣ &lt;strong&gt;视觉与文本表征不应联合学习，而应交替学习&lt;/strong&gt;；&lt;br&gt;2️⃣ &lt;strong&gt;少样本对比学习不能只看残差，还必须结合上下文信息&lt;/strong&gt;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/0576e23e-e1ba-451d-b881-32b0cd77a801/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图1 AdaptCLIP架构图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、交替学习：零样本异常检测的核心机制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.1 从 CLIP 的异常判别说起&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;给定查询图像，CLIP视觉编码器输出局部&amp;nbsp;patch token&amp;nbsp;与全局图像token，并与&amp;ldquo;正常&amp;nbsp;/&amp;nbsp;异常&amp;rdquo;文本嵌入进行相似度比对，即可得到图像级异常分数与像素级异常图。&lt;/p&gt;&lt;p&gt;但在工业场景中，&lt;strong&gt;原生&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;的像素级定位能力明显不足&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.2 视觉适配器：只做&amp;ldquo;微调&amp;rdquo;，不做&amp;ldquo;重塑&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视觉适配器分别作用于局部&amp;nbsp;patch token&amp;nbsp;与全局token，均采用&lt;strong&gt;残差&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;MLP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;结构&lt;/strong&gt;，对 CLIP 表征进行轻量自适应调整：&lt;img src="https://image.jiqizhixin.com/uploads/editor/3c2bdec3-e780-4ad1-b811-49bf1f99e3d1/%E5%9B%BE%E7%89%871.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;其中&lt;img src="https://image.jiqizhixin.com/uploads/editor/d854eebe-7d63-4626-950b-cc7292090166/%E5%9B%BE%E7%89%871.png" style="width: 3.58%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/2923abc3-68cd-4fef-bc16-a2e05410c4df/%E5%9B%BE%E7%89%872.png" style="width: 3.69%;" class="fr-fic fr-dii"&gt;分别表示CLIP输出的局部 patch token和全局图像token，&lt;img src="https://image.jiqizhixin.com/uploads/editor/a92f6451-becd-4365-b695-c44879420433/%E5%9B%BE%E7%89%873.png" style="width: 2.74%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/a5f99854-9f2a-45d7-a1e8-291c9f12f9af/%E5%9B%BE%E7%89%874.png" style="width: 2.85%;" class="fr-fic fr-dii"&gt;为适配器可学习参数。&lt;/p&gt;&lt;p&gt;其目标是在&lt;strong&gt;固定文本语义空间&lt;/strong&gt;的前提下，使视觉特征更贴合异常检测任务，从而显著提升像素级定位能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.3 文本适配器：抛弃 prompt 工程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;文本适配器不再依赖人工设计的模板，而是&lt;strong&gt;直接学习&amp;ldquo;正常&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;/&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;异常&amp;rdquo;两类可优化提示嵌入&lt;/strong&gt;，并输入冻结的 CLIP 文本编码器生成语义表示：&lt;img src="https://image.jiqizhixin.com/uploads/editor/db3a3687-774e-4da0-af85-766dc7d60aa6/%E5%9B%BE%E7%89%871.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;其中&lt;img src="https://image.jiqizhixin.com/uploads/editor/512bbc31-3406-4185-ab17-3ecfc668a906/%E5%9B%BE%E7%89%871.png" style="width: 3.69%;" class="fr-fic fr-dii"&gt;表示CLIP文本编码器，&lt;img src="https://image.jiqizhixin.com/uploads/editor/1322ef86-05a3-4e35-b9fd-72884f95c556/%E5%9B%BE%E7%89%872.png" style="width: 4.96%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/898d53af-a6e8-4582-8cd3-5899dfc306ff/%E5%9B%BE%E7%89%873.png" style="width: 4.85%;" class="fr-fic fr-dii"&gt;为最终用于特征比对的异常与正常文本嵌入。&lt;/p&gt;&lt;p&gt;这一设计在保留&amp;nbsp;CLIP&amp;nbsp;原有语义结构的同时，降低了对&amp;nbsp;prompt&amp;nbsp;经验的依赖。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.4为什么交替学习优于联合学习？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文通过消融实验发现，在小规模训练数据下，&lt;strong&gt;联合学习易过拟合&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此&amp;nbsp;AdaptCLIP&amp;nbsp;采用交替优化策略：&lt;/p&gt;&lt;p&gt;固定文本&amp;rarr;&amp;nbsp;优化视觉；固定视觉&amp;rarr;&amp;nbsp;优化文本，循环迭代。&lt;/p&gt;&lt;p&gt;该策略在多个工业与医学数据集上，显著优于联合学习方案，成为零样本异常检测性能提升的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、对比学习：少样本场景下的关键补强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当可获得少量正常样本时，AdaptCLIP启用&lt;strong&gt;提示-查询适配器&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.1 空间对齐：先对齐，再比较&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对查询图像的每个patch，模型在正常样本中搜索&lt;strong&gt;欧氏距离最近的&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;patch&lt;/strong&gt;作为对齐目标，从而消除旋转、平移带来的干扰，并计算对齐残差特征。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.2 残差 + 上下文：避免&amp;ldquo;只见树木，不见森林&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文发现，仅依赖残差特征虽然能突出差异，但容易引入噪声、丢失上下文信息。&lt;/p&gt;&lt;p&gt;因此&amp;nbsp;AdaptCLIP&amp;nbsp;将&lt;strong&gt;原始查询特征与对齐残差逐元素相加&lt;/strong&gt;，形成联合特征：&lt;img src="https://image.jiqizhixin.com/uploads/editor/ca6a354d-1d59-4828-8acd-ba38320b64ae/%E5%9B%BE%E7%89%874.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在 1-shot 设置下，引入上下文后，在 MVTec 数据集上的像素级 AUPR &lt;strong&gt;提升约&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;40%&lt;/strong&gt;，成为少样本性能跃迁的关键因素。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.3 从联合特征到异常预测：极简分割与分类头&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在得到融合了&lt;strong&gt;上下文与对齐残差&lt;/strong&gt;的联合特征后，AdaptCLIP 采用一套&lt;strong&gt;轻量输出头&lt;/strong&gt;完成异常预测。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;像素级分割&lt;/strong&gt;：联合特征经 &lt;strong&gt;1&amp;times;1 卷积&lt;/strong&gt;与若干 &lt;strong&gt;转置卷积模块&lt;/strong&gt;上采样至原分辨率，生成异常图；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;图像级分类&lt;/strong&gt;：对联合特征进行&lt;strong&gt;平均池化与最大池化&lt;/strong&gt;，融合后输入 &lt;strong&gt;MLP&lt;/strong&gt;输出异常分数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推理阶段根据可用信息进行结果融合：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;零样本&lt;/strong&gt;：融合视觉适配器与文本适配器预测；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;少样本&lt;/strong&gt;：在此基础上进一步融合提示-查询适配器结果。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;五、实验结果：跨工业与医疗的一致验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP 在&lt;strong&gt;12 个公开基准数据集&lt;/strong&gt;（8 个工业 + 4 个医疗）上进行了系统评估，覆盖不同成像模态与异常类型。&lt;/p&gt;&lt;p&gt;在零样本异常检测场景下，AdaptCLIP 在 MVTec、VisA、BTAD、Real-IAD 等工业数据集上，图像级 AUROC 平均达到&lt;strong&gt;86.2%&lt;/strong&gt;（SOTA），在多类未见产品与跨类别测试中依然保持稳定优势。&lt;/p&gt;&lt;p&gt;在医学影像任务中，AdaptCLIP在内窥镜数据集Kvasir与Endo的零样本像素级异常分割AUPR平均达到&lt;strong&gt;48.7%&lt;/strong&gt;，并在Br35H（MRI）、COVID-19（X-ray）等数据集的零样本图像级异常检测中取得平均&lt;strong&gt;90.7%&lt;/strong&gt;的AUROC，均显著高于其他现有方法。&lt;/p&gt;&lt;p&gt;在少样本设置下，随着正常样本数量从 1-shot 增加至 4-shot，异常区域的定位逐步细化。提示-查询适配器显著降低了误报区域，使异常边界更加清晰。&lt;/p&gt;&lt;p&gt;从模型规模与效率来看，AdaptCLIP在零样本条件下仅引入约&lt;strong&gt;0.6M&lt;/strong&gt;额外可训练参数（对比方法可高达10.7M）。在 518&amp;times;518 分辨率下，零样本条件单张图像推理时间约&amp;nbsp;&lt;strong&gt;162 ms&lt;/strong&gt;，兼顾检测精度与实际部署需求。&lt;img src="https://image.jiqizhixin.com/uploads/editor/652672e5-67c0-432a-9138-77e0e6d2a54f/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;table border="1" cellspacing="0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan="5" valign="center" width="100%"&gt;&lt;p&gt;&lt;a name="u8650227d"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign="center" width="17.158931082981717%"&gt;&lt;p&gt;&lt;a name="u320fbf43"&gt;待检图像&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="21.940928270042193%"&gt;&lt;p&gt;真实缺陷标注&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="21.09704641350211%"&gt;&lt;p&gt;0-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="20.253164556962027%"&gt;&lt;p&gt;1-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="19.549929676511955%"&gt;&lt;p&gt;4-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图2 &amp;nbsp;AdaptCLIP在工业与医疗数据上检测结果可视化&lt;img src="https://image.jiqizhixin.com/uploads/editor/222f8d35-1fea-4579-b844-df4fdef7140a/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;图3 &amp;nbsp;AdaptCLIP在工业与医疗数据上图像级AUROC分类结果与其他方法对比&lt;img src="https://image.jiqizhixin.com/uploads/editor/39d5826b-98c0-4aa9-b9dc-b77348676ed6/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图4 &amp;nbsp;AdaptCLIP在工业与医疗数据上像素级AUPR分割结果与其他方法对比&lt;img src="https://image.jiqizhixin.com/uploads/editor/7999c22a-1a03-48b1-9ebf-1dbb2e9f2024/%E5%9B%BE%E7%89%873.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图5 &amp;nbsp;AdaptCLIP与其他方法对比模型规模与效率&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP&amp;nbsp;并未试图&amp;ldquo;重造一个更大的模型&amp;rdquo;，而是通过&lt;strong&gt;交替学习&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;轻量适配&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;上下文感知对比&lt;/strong&gt;，在不破坏&amp;nbsp;CLIP&amp;nbsp;原始能力的前提下，实现了真正可迁移的异常检测。&lt;/p&gt;&lt;p&gt;它为工业与医疗等开放场景提供了一条清晰路径：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用最少的结构改动，换取最大的泛化收益。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2505.09926&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>WAIC首次“南下”：沪港握手2026“WAIC UP!全球年终盛会”，共揭AI对话新篇</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻助手</author>
      <pubDate>Tue, 20 Jan 2026 10:40:29 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f064dd62-3632-4097-8448-c4f8c4378c24/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20260116223441_6204_11_min.png" style="width: 700%;" class="fr-fic fr-dib"&gt;香港，2026年1月16日&amp;mdash;&amp;mdash;作为世界人工智能大会（WAIC）的年度重磅收官活动，&amp;ldquo;WAIC UP!全球年终盛会&amp;rdquo;今日在香港科学园举行。全天数千位观众与来自国际、中国大陆和中国香港的AI专家学者、企业家、投资人及香港立法会议员等共聚一堂。&lt;/p&gt;&lt;p&gt;此次盛会意义非凡，核心主题&lt;strong&gt;&amp;ldquo;WAKE UP MORE!&amp;rdquo;&lt;/strong&gt;，象征着一次从认知到行动、从个体到生态的全面唤醒。这不仅是世界人工智能大会（WAIC）首次在港举办年度旗舰活动，更标志着&lt;strong&gt;以上海为代表的内地前沿AI产业实践，与香港的国际枢纽功能完成了一次历史性的战略握手&lt;/strong&gt;，共同激发更广阔的技术前景、更深入的产业融合与更具全球影响力的创新生态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;顶格政商学阵容，筑就国际级思想高地&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大会获得香港各界的高度重视与支持。&lt;strong&gt;香港特别行政区行政长官李家超先生&lt;/strong&gt;特别通过视频为大会揭幕致辞，他表示，今年盛会首次在香港举办，以&amp;ldquo;WAKE UP MORE!&amp;rdquo;为主题，彰显了人工智能的无限可能。要借助AI推动创新，更要用于构建具包容性的经济体系、更具韧性的社区，更可持续创造所有人的未来。并阐明香港在全球AI版图中的战略定位，释放全力支持创新科技产业发展的政策信号。&lt;strong&gt;香港特别行政区创新科技及工业局局长，JP孙东教授&lt;/strong&gt;、&lt;strong&gt;香港科技园公司行政总裁黄秉修先生&lt;/strong&gt;，以及&lt;strong&gt;香港特别行政区立法会议员、香港资讯科技联会会长邱达根先生&lt;/strong&gt;亲临现场发表致辞。引人注目的是，&lt;strong&gt;第十四届全国人民代表大会港区代表，JP，MH冼汉迪先生&lt;/strong&gt;也莅临大会并致辞，与主办方&lt;strong&gt;东浩兰生会展集团股份有限公司副总裁裘皓明女士&lt;/strong&gt;共同启动这一国际AI界年度思想盛会。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a1ac9cb7-1d37-4974-9377-b5b406525f61/%E7%89%B9%E9%A6%96.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这一阵容与会上40余位全球顶尖的AI科技产业巨擘形成&amp;ldquo;政府战略+学界前沿+产业实战&amp;rdquo;的黄金三角，标志着一个连接长三角与大湾区、贯通顶尖技术与全球市场的创新闭环正在WAIC的平台上加速形成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三幕递进式论坛，精准匹配思想价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;议程设计突破传统模式，WAIC旗下五大生态品牌首次在香港并联，以&amp;ldquo;思想觉醒&amp;mdash;拓维跃迁&amp;mdash;灵感迸发&amp;rdquo;为主线，打造差异化体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上午场【WAKE思想觉醒】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;聚焦新锐思想，锚定未来坐标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上午立足全球前沿，&lt;strong&gt;WAIC UP!新锐思想&lt;/strong&gt;为我们打开视野，看见未来真正的轮廓。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;硅谷人工智能研究院创始人、院长皮埃罗&amp;middot;斯加鲁菲（Piero Scaruffi）&lt;/strong&gt;带来开幕主题演讲，以&amp;ldquo;70&amp;middot;40&amp;middot;10&amp;mdash;&amp;mdash;人工智能与硅谷的过去、现在与未来&amp;rdquo;为框架，全面梳理了AI七十年的技术演进、硅谷四十年的创新生态以及未来十年的未知与希望。&lt;img src="https://image.jiqizhixin.com/uploads/editor/303e10ef-422e-4958-8de7-90fa6f7c3514/Piero_Scaruffi.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中国工程院外籍院士、香港科技大学首席副校长郭毅可&lt;/strong&gt;将宏大的AI主权理念具象化为&amp;ldquo;港话通（HKChat）&amp;rdquo;等一系列深度本地化应用，展现AI技术如何扎根香港社会肌理与香港作为东西方AI枢纽的战略价值。&lt;img src="https://image.jiqizhixin.com/uploads/editor/aa41fac3-9f1a-4bf8-b523-139b4d248815/%E9%83%AD%E6%AF%85%E5%8F%AF.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;香港城市大学首席人工智能总监、香港人工智能与科学研究院院长马维英&lt;/strong&gt;阐述了&amp;ldquo;AI科学家&amp;rdquo;愿景，提出FLEX（Forward Learning From Experiences）框架配合分层记忆系统，实现智能与经验的闭环共进化，勾勒出AI重塑科学发现范式与大学研究教育体系的未来图景。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1ae09a9c-3334-41ef-b321-30058a9562e9/%E9%A9%AC%E7%BB%B4%E8%8B%B1.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下午场【UP拓维跃迁】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;WAIC矩阵并联，直击实战与生态&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下午进入高密度、分众化的实战对接环节。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC CONNECT实战案例&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Founders Space董事长兼首席执行官史蒂夫&amp;middot;霍夫曼（Steve Hoffman）&lt;/strong&gt;以&amp;ldquo;AI is Eating Everything（人工智能正在吞噬一切）&amp;rdquo;开场，用&amp;ldquo;吞噬&amp;rdquo;这一生动比喻与直观图示，宏观勾勒出技术爆发的全球图景与中美竞逐态势，最终引发&amp;ldquo;AI是否会取代人类工作&amp;rdquo;的紧迫且深刻思考。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b15f4abc-a96e-4d94-99fb-6b19b07fbb25/Steve_Hoffman.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;来自科研、算力、资本与市场的四方视角汇聚成&lt;strong&gt;&amp;ldquo;商业与产业圆桌&amp;rdquo;&lt;/strong&gt;，完整讨论了从技术研发到商业落地的闭环，尤其关注如何将实验室成果转化为稳定产品、如何突破规模化营收瓶颈、以及如何构建开放协同的AI生态，为AI产业化提供了清晰、务实的发展路径。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c0f89096-b685-465b-b805-d15826872233/%E4%BA%A7%E4%B8%9A%E4%B8%8E%E5%95%86%E4%B8%9A%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC YOUNG科教风向&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;香港大学、香港城市大学、香港理工大学的副校长级科学领袖聚首&lt;strong&gt;&amp;ldquo;校长圆桌&amp;rdquo;&lt;/strong&gt;，不仅剖析了教育评价体系、产学研脱节等瓶颈，更就深化粤港澳大湾区融合、构建&amp;ldquo;研究‑产业&amp;rdquo;并发式合作网络提出具体路径，为AI时代夯实科技根基提供了系统性思考与行动方向。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1d954436-ed50-4de2-a819-5f6729cba3fc/%E6%A0%A1%E9%95%BF%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;聚焦下一代的&lt;strong&gt;&amp;ldquo;青年观察家&amp;rdquo;&lt;/strong&gt;跨界对话中，宇宙学者、艺术家、教育者与生态构建者们从星际尺度、艺术本质、幼儿教育到文明价值等多重维度展开思辨，探讨AI作为&amp;ldquo;新生命形式&amp;rdquo;与人类在演化节奏、创造主体及价值定义上的根本性碰撞。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c4bcc467-c56d-4327-b3a8-22e52521758c/%E9%9D%92%E5%B9%B4%E8%A7%82%E5%AF%9F%E5%AE%B6.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC FUTURE TECH赛道机遇&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;穹彻智能联合创始人，非夕机器人联合创始人，上海交通大学人工智能学院副院长、教授，上海创智学院副院长卢策吾&lt;/strong&gt;聚焦具身智能，提出&amp;ldquo;真实基础-想象拓展-下意识学习&amp;rdquo;，首创群众采集（RoboPocket）范式，构建&amp;ldquo;数字基因&amp;rdquo;世界模型，强调力-位全信息融合，以突破Scaling Law困境。&lt;img src="https://image.jiqizhixin.com/uploads/editor/4d8560db-b30a-49f4-bc1c-6ab6b294123d/%E5%8D%A2%E7%AD%96%E5%90%BE.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;量子圆桌&amp;rdquo;&lt;/strong&gt;邀请&amp;ldquo;祖冲之号&amp;rdquo;量子计算总师朱晓波在内的多位技术路线代表与产业观察者同台交锋，话题涉及量子计算与AI的融合、不同技术路线的竞争与前景，以及量子计算从&amp;ldquo;优越性&amp;rdquo;到&amp;ldquo;实用性&amp;rdquo;的跨越，呈现了一场兼具前瞻性、批判性与建设性的前沿科技对话。&lt;img src="https://image.jiqizhixin.com/uploads/editor/88bad16b-b665-4218-a5cf-eaa010423fc9/%E9%87%8F%E5%AD%90%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AI GRAVITY链接全球&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;猎豹移动董事长兼CEO，猎户星空董事长傅盛&lt;/strong&gt;以自身&amp;ldquo;AI化&amp;rdquo;转型为实证，提出&amp;ldquo;一把手示范、全员革命、工具落地&amp;rdquo;的企业变革三部曲，用生动案例展现了一家老牌公司如何以All in姿态拥抱AI。&lt;img src="https://image.jiqizhixin.com/uploads/editor/102abbab-2880-4a92-8102-6db5a3237d8b/%E5%82%85%E7%9B%9B.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;出海战略圆桌&amp;rdquo;&lt;/strong&gt;汇集了基础模型、汽车金融、工业互联网、智慧物流领域的出海实践者，携同大湾区资源代表香港投推署与生产力促进局，积极探索通过技术赋能、生态合作与平台协同，实现从单点出海到体系化&amp;ldquo;舰队式&amp;rdquo;发展的升级路径。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b50e86b0-bcdd-4a3e-b636-42f509caf483/%E5%87%BA%E6%B5%B7%E6%88%98%E7%95%A5%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;夜晚场【灵感迸发】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;打破圈层，激发&amp;ldquo;灵感迸发&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当维港的灯火亮起，这场持续全天的思想盛宴在夜晚场达到另一种形态的高潮。&lt;/p&gt;&lt;p&gt;WAIC五大生态品牌领衔的&lt;strong&gt;Free Talk Zone&lt;/strong&gt;提供无缝交流局，让最有价值的资源、机会与灵感在非正式对谈中自然流动。&lt;strong&gt;知乎创作者、WAYtoAGI和RTE开发者社区极客、BIM青年科学家、AI头部科技博主&lt;/strong&gt;与白天登台的大咖平等对话。&lt;strong&gt;史蒂夫&amp;middot;霍夫曼（Steve Hoffman）&lt;/strong&gt;带来一场&amp;ldquo;模拟人生：AI缔造的未来&amp;rdquo;特别互动演讲。&lt;strong&gt;加州大学伯克利VIVE增强现实中心创始执行主任杨安（Dr. Allen Yang）&lt;/strong&gt;首次现场揭秘Physical AI的真正野心。&lt;strong&gt;香港立法会议员、港区全国政协委员、优家健康创始人和埔思学院院长&lt;/strong&gt;深入&amp;ldquo;重构生命、财富与记忆&amp;rdquo;等终极议题。&lt;strong&gt;香港城市大学&lt;/strong&gt;的&lt;strong&gt;&amp;ldquo;Tech300&amp;rdquo;菁英汇&lt;/strong&gt;为当晚注入最鲜活的创新动能。创新因子在跨代际碰撞中集中涌现。&lt;img src="https://image.jiqizhixin.com/uploads/editor/0c0ee754-27ba-40a3-939d-428bdb99fbf9/%E5%A4%9C%E5%9C%BA.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从1956年达特茅斯会议到2026&amp;ldquo;WAIC UP!全球年终盛会&amp;rdquo;，AI对话正从纯技术思辨走向&amp;ldquo;技术-产业-人文&amp;rdquo;的融合共创。&lt;/p&gt;&lt;p&gt;香港的意义，远不止资本与技术的枢纽。这座东西方文明交汇的城市，为AI注入了独特的价值维度&amp;mdash;&amp;mdash;在这里，效率与温度并存，创新与传统对话，全球视野与本土智慧交融。WAIC选择香港作为年终思想的收官之地，正是因为这片土地能孕育出不同于硅谷的AI文明形态。&lt;/p&gt;&lt;p&gt;&amp;ldquo;WAIC UP!全球年终盛会&amp;rdquo;既是对过往技术长征的致敬，更是开启&amp;ldquo;人类与机器智能对话&amp;rdquo;的新序章。当思想从彼岸到此岸，当创新从精英走向大众，一个更加多元、包容、可持续的AI未来，正在东方初现曙光。&lt;img src="https://image.jiqizhixin.com/uploads/editor/95133668-965d-4c47-b37b-3cb8b823c84d/_6014826-opq3014263146.jpg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于WAIC和WAIC UP!&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;世界人工智能大会（WAIC）是全球人工智能领域的顶级盛会，已成功举办八届，致力于探索AI技术前沿并推动该领域的创新发展。自创办以来，大会已汇聚了来自全球的8,100多位顶尖科学家、专家、企业家投资者及行业领袖，共同交流思想、分享突破性成果并探索合作机遇。&lt;/p&gt;&lt;p&gt;2024年12月，WAIC首份刊物《WAIC UP!》正式问世，它是AI时代的进化指南，更是WAIC精神的延伸。在数字化的浪潮中，信息的碎片化、同质化、孤岛化，让我们渴望深度与连接。创办《WAIC UP!》的初衷正是为了解决这一时代难题。我们想创建的也正是这样一个多元发声阵地、智慧共鸣窗口和思想启发工具。WAIC UP! WAKE UP MORE! 旨在唤醒更多人，探究关乎技术跃迁自我边界和未来文明的无限可能。&lt;img src="https://image.jiqizhixin.com/uploads/editor/59cf355c-c198-47f7-960c-eab34a5edcbe/WAIC_UP_%E5%85%A8%E7%90%83%E5%B9%B4%E7%BB%88%E7%9B%9B%E4%BC%9A%E5%90%88%E4%BD%9C%E4%BC%99%E4%BC%B4.jpg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>“扣子”官宣2.0品牌升级：AI办公、AI创作全面更新，新增视频创作能力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 10:23:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1月19日，字节跳动旗下AI Agent平台&amp;ldquo;扣子&amp;rdquo;宣布2.0品牌升级。&lt;/p&gt;&lt;p&gt;扣子诞生于2024年2月，最初定位是新一代AI Agent平台。基于服务超1000万真实开发场景的经验，扣子2.0进行了全局重构，定位和使命是帮助更多的职场人。&lt;/p&gt;&lt;p&gt;扣子2.0集成了Agent Skill、Agent Plan、Agent Coding、Agent Office能力，让AI 真正成为用户的&amp;ldquo;工作伙伴&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/04bb453e-9e49-4fdd-b965-1c9138e9ba37/%E5%9B%BE%E7%89%871.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Skills：装上行业技能包，让通用AI变得更专业&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通用Agent已展现出强大的基础任务处理能力，在日常对话、信息整合与简单推理方面有了长足进步，但要应对高度专业化、高精度或高可控要求的复杂场景，仍需特定技能的增强。&lt;/p&gt;&lt;p&gt;通过封装领域知识、标准化操作流程或集成专用工具，&amp;ldquo;技能&amp;rdquo;（Skills）能够将通用AI的认知能力与特定任务需求相结合，更贴合实际应用场景中多元化、高标准的任务要求，保证输出稳定性。&lt;/p&gt;&lt;p&gt;扣子2.0推出的Agent Skills，本质上是「场景最佳实践 + 所需工具」的封装，旨在帮助更多用户调用专业技能，定向增强解决复杂专业问题的能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/3a04368a-21d1-493f-ae3c-13955ab7449e/%E5%9B%BE%E7%89%872.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在全新推出的技能商店中，用户可以浏览、选择并一键安装使用由扣子官方及优质开发者创建的各类专项技能模块，包括但不限于&amp;ldquo;新年绘本&amp;rdquo;&amp;ldquo;互动教学&amp;rdquo;&amp;ldquo;投资知识库&amp;rdquo;&amp;ldquo;法律类案检索&amp;rdquo;等。扣子可根据任务场景，智能调用或组合多个已安装技能，让Agent Skills提供综合性解决方案。技能库会持续更新，确保用户总能获取最前沿、最实用的能力支持。此外，用户可利用扣子提供的工具，为自己量身定制私有技能，还可以将个人经验沉淀封装为可复用的模块。&lt;/p&gt;&lt;p&gt;在Coze Skills生态中，行业专家能够把经验沉淀为&amp;ldquo;可出售的技能&amp;rdquo;，提升专业影响力；特定领域的新人即使没有行业经验，也可以一键使用他人的方法论。对于企业来说，团队能够共享专业标准作业程序（SOP）和最佳实践，新成员也能迅速掌握熟练员工的能力。&lt;/p&gt;&lt;p&gt;此外，扣子官方视频Skill也正式上线，该功能支持自动生成视频脚本、匹配视觉素材，并完成剪辑、转场、配乐等后续流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Plan：从&amp;ldquo;即时问答&amp;rdquo;到&amp;ldquo;长期计划&amp;rdquo;，AI持续执行并主动汇报&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;习惯使用AI产品提效的用户，需要的不只是即时解答问题的工具，更是一个能够理解长期目标、适应个人成长节奏、提供持续支持的智慧伙伴。&lt;/p&gt;&lt;p&gt;扣子2.0推出了Agent Plan，即&amp;ldquo;长期计划&amp;rdquo;，让AI从&amp;ldquo;即时问答工具&amp;rdquo;升级为&amp;ldquo;可持续运作的智能体&amp;rdquo;。用户只需要确定目标，规定好怎么完成、怎么实现，扣子能够持续执行，并向用户主动汇报、最终交付任务。&lt;br&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f5f1a150-e9b0-43ff-a2dd-08b7173af6d2/%E5%9B%BE%E7%89%873.png" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;长期计划实现了复杂目标的闭环管理，Agent将一个需要数小时、数天甚至更长时间才能完成的宏观目标（如&amp;ldquo;一款市场竞品分析报告&amp;rdquo;）分解为多个步骤，并持续追踪进度、管理中间状态，直至最终交付成果。这打破了传统单轮交互的局限。在执行长期任务过程中，Agent可以积累上下文信息、记忆用户偏好、总结历史经验，并动态调整后续策略。例如在长期客户服务场景中，它能基于过往互动提供越来越个性化的支持。&lt;img src="https://image.jiqizhixin.com/uploads/editor/43138986-07b1-4544-ac7b-e2984956c35a/%E5%9B%BE%E7%89%874.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;以自媒体账号运营为例，扣子能够和用户一起讨论账号定位，拆解每个阶段的运营策略，再帮用户创作内容。如果用户想写一本书，只需把写作主题和目标发给扣子，它会自己搜集资料、撰写初稿，再根据反馈自行调整，达成3周内写出10万字初稿的计划。用户还可以用长期计划来完成学习目标，比如考雅思，扣子会设定每日任务并准备学习资料。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Office：深度理解职场场景，AI办公、AI创作能力全新升级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AI通常能够针对用户的提问给到标准答案，但在真实的职场问题中，答案并不是模板化的。AI 只有理解具体场景，才能提供针对性解决方案。&lt;/p&gt;&lt;p&gt;扣子2.0面向职场类任务做了更多优化，写战略报告Word、做分析PPT、梳理数据Excel，都可以交给扣子来处理。&lt;/p&gt;&lt;p&gt;具体来说，扣子2.0增强了深度上下文理解能力，能够为用户提供洞察。用户不需要一次性把所有背景信息塞进去，扣子会通过多轮对话，逐步理解具体情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Coding：扣子编程，全栈式 Vibe Coding 开发平台&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近日，扣子开发平台正式升级为扣子编程。&lt;/p&gt;&lt;p&gt;作为一站式云端 Vibe Coding 开发平台，扣子编程实现了Vibe Agent、Vibe Workflow、Vibe Web、Vibe App几大核心功能开箱即用，用户通过连续对话，即可轻松构建智能体、工作流、网站、移动应用等，并提供 Vibe Infra 基础设施，实现一键部署上线。&lt;/p&gt;&lt;p&gt;在扣子编程平台，Agent能够自己写提示词、装知识库、开发工具，能在多轮对话过程中自我迭代。基于Vibe Workflow功能，用户彻底告别手动拖拽节点，只需要描述清楚需求即可创建工作流，还能够分节点进行调试和修改，让Vibe Coding更可控、更稳定，更好地支撑复杂业务需求。基于Vibe App功能，用户仅需输入自然语言指令即可打造一个跨端的全栈应用，扣子可以生成适配的界面和逻辑，并自动完成多端适配，帮你集成所需的组件，包括AI能力、数据库等等。&lt;/p&gt;&lt;p&gt;结合火山引擎在云计算领域强大的基础设施，扣子编程上线了Vibe Infra的能力，提供众多适合Vibe Coding用户的基础设施服务，包含服务器的资源分配、应用的版本部署，域名备案配置以及iOS和安卓的版本发布。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>最适合科研工作的模型是什么？Anthropic：斯坦福、MIT用Claude加速科研进程</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 19 Jan 2026 18:05:41 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑丨coisini&lt;/span&gt;&lt;/p&gt;&lt;p&gt;去年十月，Anthropic 推出了 Claude 生命科学版 &amp;mdash;&amp;mdash;Claude for Life Sciences，旨在让 Claude 成为生命科学领域工作者更得力的合作伙伴。&lt;/p&gt;&lt;p&gt;之后，Anthropic 投入大量资源，致力于将 Claude 打造为最适合科研工作的模型。最新推出的 Claude Opus 4.5 在图表解析、计算生物学和蛋白质理解等基准测试中均取得显著进步。&lt;/p&gt;&lt;p&gt;Anthropic 与学术界及产业界研究人员密切合作，致力于精准把握科学家如何运用人工智能加速科研进程。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-imgfileid="100027187" data-ratio="0.5472222222222223" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLk52jEyrejv0eC2uJnFTck9e4d4drbBUaSkftRfhNzib9jdLt0a5wk1K7cj7SkqERExpLza6GFLveQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/116b4c43-ad32-4e08-951c-f076e021eaab/640.jpeg" alt="图片" data-before-load-time="1768817038743" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;研究人员已开发出定制化系统，将 Claude 的应用场景拓展到文献综述或代码辅助等基础任务之外。简而言之，Claude 正在重塑科学家的研究模式，推动科研领域迈向全新的科学洞察与发现。&lt;/p&gt;&lt;p&gt;Anthropic 最近列举了一些知名实验室采用 Claude 加速科研进程的例子。&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Biomni：&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;集成数百种工具与数据库的通用生物医学智能体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;生物学研究的一大瓶颈在于工具碎片化：现有数百个数据库、软件包和实验方案，研究人员需要耗费大量时间在不同平台间进行选择和掌握。在理想情况下，这些时间本应用于实验操作、数据解析或探索新课题。&lt;/p&gt;&lt;p&gt;斯坦福大学研发的智能 AI 平台 Biomni，将数百种工具、软件包和数据集整合进统一系统，由 Claude 驱动的智能体可在其中自主调度。研究人员使用自然语言提出需求，Biomni 会自动匹配合适资源。该系统能够提出假设、设计实验方案，并在超过 25 个生物学子领域执行分析任务。&lt;/p&gt;&lt;p&gt;以全基因组关联分析（GWAS）为例，这种研究旨在寻找与特定性状或疾病相关的基因变异。&lt;/p&gt;&lt;p&gt;基因组扫描相对简单，耗时环节在于数据解析与意义解读：基因组数据格式杂乱需要深度清洗；研究人员必须控制混杂因素并处理缺失数据；发现「命中信号」后，还需解析其生物学意义 &amp;mdash;&amp;mdash; 定位邻近基因、确定其表达细胞类型、推测影响的生物通路等。每个步骤都可能涉及不同工具、不同文件格式和大量人工决策。这种繁琐过程使得单次 GWAS 分析常需数月时间，而在 Biomni 的初期试验中，仅需 20 分钟。&lt;/p&gt;&lt;p&gt;Biomni 团队已通过多领域案例验证系统可靠性：在分子克隆实验设计中，盲评显示其方案与拥有五年以上经验的博士后水平相当；处理 30 名受试者超过 450 份可穿戴设备数据仅用 35 分钟，而专家完成相同任务预计需三周；分析 33.6 万个人类胚胎组织单细胞基因活性数据时，系统不仅验证了已知调控关系，更发现了研究人员未曾关联到胚胎发育过程的新转录因子。&lt;/p&gt;&lt;p&gt;Biomni 并非完美系统，因此设置了防护机制以监测 Claude 是否偏离正轨。它也不能解决所有问题，但当其能力不足时，专家可将方法论编码为技能 &amp;mdash;&amp;mdash; 教智能体模仿专家解决问题的思路而非任其自由发挥。&lt;/p&gt;&lt;p&gt;Biomni 代表了一种通用型解决方案，而其他实验室正在构建更专精的系统，以攻克特定研究流程中的瓶颈。&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Cheeseman 实验室：&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;大规模基因敲除实验解读自动化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当科学家需要了解基因功能时，常用方法是将其从细胞或生物体中移除并观察产生的异常。CRISPR 基因编辑技术使大规模精准敲除成为可能，但其应用仍受限制：实验室产生的数据量远超分析处理能力。&lt;/p&gt;&lt;p&gt;这正是麻省理工学院 Whitehead 研究所 Iain Cheeseman 实验室面临的挑战。他们使用 CRISPR 技术对数千万人类细胞进行数千种基因敲除，通过显微成像记录每个细胞的变化。&lt;/p&gt;&lt;p&gt;但解读基因簇的意义 &amp;mdash;&amp;mdash; 探究聚类原因、寻找共同特征、判断属于已知生物学关系还是新发现 &amp;mdash;&amp;mdash; 仍然需要专家逐基因查阅文献。这个过程极其缓慢：单次筛选可能产生数百个基因簇，由于时间、精力和专业知识限制，大多数簇从未被深入探究。&lt;/p&gt;&lt;p&gt;多年来 Cheeseman 亲自承担所有解读工作。他估计自己大约能记住 5000 个基因功能，但有效分析这些数据仍需数百小时。为加速这一进程，博士生 Matteo Di Bernardo 着手构建能自动化 Cheeseman 工作模式的系统。通过深入解析 Cheeseman 的解读方法论 &amp;mdash;&amp;mdash; 数据源选择、模式识别标准、发现价值判断 &amp;mdash;&amp;mdash; 他们最终创建了由 Claude 驱动的 MozzareLLM 系统。&lt;/p&gt;&lt;p&gt;该系统接收基因簇数据后，会执行 Cheeseman 式的专家分析：识别潜在共享生物过程、标注研究充分与欠缺的基因、突出值得跟进的目标。这不仅极大加速了研究进程，还帮助他们获得额外的重要生物学发现。在开发 MozzareLLM 的过程中，Di Bernardo 测试了多种 AI 模型。Claude 的表现始终优于其他模型。&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Lundberg 实验室：&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;测试 AI 主导的基因研究目标假设生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Cheeseman 实验室采用的光学混合筛选技术可在单次实验中敲除数千基因，其瓶颈在于结果解读。但并非所有细胞类型都适用混合筛选方法。斯坦福大学 Lundberg 实验室等研究团队进行的是规模较小、目标集中的筛选实验，他们的瓶颈出现在更前端：如何确定需要靶向的基因。&lt;/p&gt;&lt;p&gt;由于单次聚焦筛选成本可能超过 2 万美元且随规模增加，实验室通常仅选择数百个最可能关联特定条件的基因。传统流程需要研究生和博士后团队逐条添加候选基因并附简要理由或文献链接。这是基于文献调研、专业知识和直觉的「经验猜谜游戏」，受限于人类认知带宽，且依赖已有研究成果和在场人员记忆，难免存在疏漏。&lt;/p&gt;&lt;p&gt;Lundberg 实验室正运用 Claude 颠覆这种方法。他们的系统不再追问「基于已有研究我们能做出哪些推测」，转而探索「基于分子特性应该研究什么」。&lt;/p&gt;&lt;p&gt;团队构建了细胞内所有已知分子（蛋白质、RNA、DNA）的关联图谱，标注蛋白质相互作用、基因编码关系和结构相似性。随后向 Claude 提出目标 &amp;mdash;&amp;mdash; 例如寻找调控特定细胞结构或过程的基因 &amp;mdash;&amp;mdash;Claude 通过遍历分子关系图谱，依据生物学特性与关联度筛选候选基因。&lt;/p&gt;&lt;p&gt;该实验室正在开展验证实验，将对比人类专家与 Claude 的表现。若该方法验证有效，团队预期它将成为聚焦扰动筛选的标准前置步骤。实验室无需再依赖直觉博弈或当代研究中盛行的暴力筛选，而是基于信息做出精准靶向决策。&lt;/p&gt;&lt;p&gt;原文链接：https://www.anthropic.com/news/accelerating-scientific-research&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>租了8张H100，他成功复现了DeepSeek的mHC，结果比官方报告更炸裂</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:28:49 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;元旦期间，DeepSeek 发布的 mHC 震撼了整个 AI 社区。&lt;/p&gt;&lt;p&gt;简单来说，DeepSeek 提出的 mHC 通过将传统 Transformer 的单一残差流扩展为多流并行架构，并利用 Sinkhorn-Knopp 算法将连接矩阵约束在双拟随机矩阵流形上，成功解决了超连接（HC）在大规模训练中因破坏恒等映射属性而导致的数值不稳定和信号爆炸问题。更多详情请参阅《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651010187&amp;idx=1&amp;sn=cc9ae88f676873468dcfc98d54e98aa9&amp;scene=21#wechat_redirect" target="_blank"&gt;刚刚，梁文锋署名，DeepSeek 元旦新论文要开启架构新篇章&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;时至今日，这篇让众多读者大呼看不懂的论文依然是技术社区关注的一大焦点。解读分享这篇论文就好像已成为一种技术时尚。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14VNUWI9adiaSqribkZiavwWb6ylMFfyfib9zLbSr4A4f61P8qnXQ23IJGVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.8574317492416582" data-s="300,640" data-type="png" data-w="989" type="block" data-imgfileid="503528930" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ca024fa7-7692-4ae2-98d6-c4e95d668991/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14P7gbO6qkvHB6GLSKLFoyXgVicLvdV4RUmceGomNTQNQSLibfaQuYR2ug/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.336734693877551" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503528931" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4c2ab415-8c48-418f-abb5-37ebca1f8d2e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但还有更加硬核的，近日 &lt;strong&gt;FlowMode 工程师 Taylor Kolasinski 宣布成功复现了 mHC，并且在测试中还取得了比 DeepSeek 原始论文更好的成绩&lt;/strong&gt;！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148fxf77icFbcLA7DxbN7eIfhTicf2sclr7W6J3Yh7EniaP5UmV4PO63Wsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528932" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/85968fa3-a92d-4e79-801d-416710d17537/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;评论区也是直呼「不明觉厉」：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14iaSBv7DkfgMXeTsyEleE0tDmnzvefpZ7lNibLicF16WSbichWHC520Xl7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528933" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1564350f-b075-4649-a8b6-52572e618ee6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;目前，Kolasinski 正通过一个 mHC 复现系列博客介绍其复现成果，相关博客已经发布了 2 篇。这里我们进行了整理，以飨读者。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Z9dCZ27LYqfS77EtwVlvA79rQR1LuruLB9lUA39EbpHRQ9exEVWibwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6925925925925925" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528934" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ffe49afd-f69a-4c71-a9e5-4126cc73c561/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="2 2 []"&gt;博客 1：https://taylorkolasinski.com/notes/mhc-reproduction/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;博客 2：https://taylorkolasinski.com/notes/mhc-reproduction-part2/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;博客一：DeepSeek 的 mHC：当残差连接发生爆炸&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你使用过的每一个 Transformer 模型都采用了 2016 年以来的同一种残差连接设计。&lt;/p&gt;&lt;p&gt;GPT-5、Claude、Llama、Gemini。在底层，它们做的事情都是一样的：x + F (x)。信息流只有一条，穿过网络，每一层都向其中添加内容。&lt;/p&gt;&lt;p&gt;DeepSeek 提出了一个问题：如果它变得更宽会怎样？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14K67JcIibnb4KQMFVvfVicMYFgKPsFiabVXMTvP6nevicO6D8QWsOjdkUEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528935" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/98ae53d2-b127-4e77-a937-6a617b056476/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;标准残差连接是每一个现代 Transformer 的脊梁。其思路很简单：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ibNUSZVmyqBt9GqhG5AdZsIC6ZYib5pL7NibhiaMLSNpOCMpKWBvold3hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.18181818181818182" data-s="300,640" data-type="png" data-w="209" type="block" data-imgfileid="503528936" data-aistatus="1" data-original-style="width:109px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/24211aba-5f77-4311-a12c-c7087688b798/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;其输入原封不动地流过，加上该层的输出。这是一条单一的信息流。进去是什么，出来的就是什么加上一个学习到的更新量。这就是为什么 Transformer 可以深达数百层：梯度有一条干净的向后路径。简单。稳定。自 2016 年以来未曾改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;超连接（Hyper-Connections）&lt;/strong&gt;采取了不同的方法。它不再是单一流，而是扩展到 n 条并行流，并带有可学习的混合矩阵：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ib303XUokjGaECqsialpZEV9LWOhRFG0M0uOYUGZUiaysdic3uXibAibGSUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.10416666666666667" data-s="300,640" data-type="png" data-w="432" type="block" data-imgfileid="503528937" data-aistatus="1" data-original-style="width:198px;height:21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/02170543-56d9-4c80-ba29-6e3c99b14deb/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;下图对比了标准残差与超连接：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JdzbPqUPZV8m8z7lONBnWBq0aicFXAWxekS3Q8hUvLyX5picxIbUrsYw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.271875" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503528939" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/eba1344d-5cac-4d9f-840a-ec9e95cd2031/640.gif" data-order="0" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;三个矩阵控制着信息的流动方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;H_res：信息流在残差路径中如何混合（红色的交叉部分）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;H_pre：信息流在进入层之前如何组合&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;H_post：层的输出如何分配回各个流中&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;超连接表达能力更强。参数更多，但计算开销几乎可以忽略不计。理论上性能更好。亦可参阅报道《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650941988&amp;idx=2&amp;sn=1b35f2af9982c529a1c9217bfab24a02&amp;scene=21#wechat_redirect" target="_blank"&gt;字节豆包大模型团队突破残差连接局限！预训练收敛最快加速 80%&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;但问题是什么？那些混合矩阵是不受约束的。它们不仅能路由信号，还能放大信号。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;爆炸&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在激进的学习率下，作者的复现实验中超连接（HC）的信号放大达到了 7 倍，随后最终崩溃。Amax（行和列绝对值的最大值）衡量了一个矩阵能将信号放大多少。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14KTGPYOxRc0mIq9po5SS1CabBE40e9zLeqsBbz2rIquTVwKzLutn2RQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.33700137551581844" data-s="300,640" data-type="png" data-w="727" type="block" data-imgfileid="503528940" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5dff3de9-32d7-413b-84c0-6af93530b5ab/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 10M 参数的规模下，这也还行。但 DeepSeek 在 27B 参数下观察到了这种情况：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;「Amax 增益幅度产生了极值，峰值达到 3000」&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;你没有看错：&lt;strong&gt;三千倍&lt;/strong&gt;的放大。在 27B 参数下，不受约束的 HC 不仅仅是漂移，而是爆炸了。这里的 10M 复现中达到的 9.2 倍正是这种指数级故障的早期预警。&lt;/p&gt;&lt;p&gt;也因此，不受约束的混合矩阵在规模化时会崩溃。微小的放大呈指数级复合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14VWxBdN7nxiamNJd85YftJuh72KeQagAibiafxXkCHyGYJe67W4BybGV7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.43333333333333335" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528941" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d2363632-ac09-4089-9477-3b6d7a5e46ff/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;压力测试： 在激进的学习率下，HC 的信号放大在崩溃前达到了 7 倍。mHC 保持平稳，维持在 1.0。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;修复：约束流形&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek 的修复方案很干净：将混合矩阵约束为&lt;strong&gt;双重随机（doubly stochastic）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;一个双重随机矩阵具有以下特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;所有条目非负&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;行之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;列之和为 1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14GH15XHpicXwdEuRIu1Ft45cvA5z2HKhL5xqwibgzKu4ZaGTL2Qu0jwIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5158227848101266" data-s="300,640" data-type="png" data-w="632" type="block" data-imgfileid="503528942" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/8e58bf9b-32b7-4221-9277-1e6c83461eb4/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着混合操作只能对流进行加权平均。它可以路由信息，混洗它，融合它。但它不能放大。&lt;/p&gt;&lt;p&gt;DeepSeek 是如何做到塞？使用 Sinkhorn-Knopp 算法。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD143D4km7Z9CoWuwYU5rm6pTOia8oYH6HtQichr5EEbnlKN8JpNTZO74uMw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.9578163771712159" data-s="300,640" data-type="gif" data-w="403" type="block" data-imgfileid="503528943" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/2ec37ecc-006a-45a6-b4e8-9dd0c98efac3/640.gif" data-order="1" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该算法非常简单：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;从任意矩阵（原始学习到的权重）开始&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;取指数使所有条目变为正数：P = e^H&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归一化行，使每一行之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归一化列，使每一列之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重复 3-4 个步骤，直到收敛&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;就是这样。交替进行行和列的归一化。二十次迭代就足够了。&lt;/p&gt;&lt;p&gt;这个过程是可微分的。梯度可以回传穿过所有二十次迭代。网络学习原始权重 H，而 Sinkhorn 确保实际的混合矩阵始终是双重随机的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14rDcYB40OThxGxcascU0icJHCmTEZicdibrN77EKVoNLbRaPrYmzWejsww/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.12735849056603774" data-s="300,640" data-type="png" data-w="424" type="block" data-imgfileid="503528944" data-aistatus="1" data-original-style="width:210px;height:27px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/d0b60218-ea2f-46a2-bda4-8e081295ee6d/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;当作者第一次看到这个时，感觉像是作弊。你不是在学习稳定性，而是在强制它。但有些属性不应该被学习；它们应该被保证。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;技术说明：严格来说，只有递归矩阵 H_res 需要完整的 Sinkhorn 双重随机处理。它是层层复合误差的那个。输入 / 输出混合器（H_pre，H_post）仅通过 sigmoid 进行有界处理。Sinkhorn 的计算成本只花在最重要的地方。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD146neDNSz6smMWS4LF7bEm1h6Rym6naUn0JzrYIXrIj806DicaSWcfPBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.90744920993228" data-s="300,640" data-type="png" data-w="886" type="block" data-imgfileid="503528945" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/c814eeb5-3376-4ae3-90e3-691de546813c/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不同种子的结果（深度 24，3 个种子）&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14D8MTeOXCHfLaIK0w51V9a5c1nNo4G5vxML4x8A3zOwRbPH704R7nDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.24083769633507854" data-s="300,640" data-type="png" data-w="764" type="block" data-imgfileid="503528946" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/d64f4e03-95c7-4604-8ad7-4abc860b3681/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;HC 在原始性能上获胜：验证损失 0.88 对 1.12。在 10M 参数下，mHC 约束就像是一种稳定性税；你付出的是表达能力。但在 27B 参数下，这种税是防止你的模型爆炸成 NaN 的唯一手段。&lt;/p&gt;&lt;p&gt;但看看方差。HC 的损失在不同种子间的变化是 mHC 的 3 倍（&amp;plusmn;0.033 vs &amp;plusmn;0.012）。至于 Amax？HC 根据种子的不同在 6.1 到 7.6 之间摆动。mHC 是 1.00。每一个种子。每一次运行。零方差。&lt;/p&gt;&lt;p&gt;在 10M 参数下，这种不稳定性是可以存活的。HC 仍然获胜。但在 27B 参数下，那 6-7 倍的放大变成了 3000 倍。在这个规模下你无法赌博。&lt;/p&gt;&lt;p&gt;深度扩展&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14cKz5YI6AVeNYDOBMWaRs93eI1L9jHBrvyFWhLuuQNjKJvAMPo2bhXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.9187643020594966" data-s="300,640" data-type="png" data-w="874" type="block" data-imgfileid="503528947" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/73a9fe86-a9c5-40fc-b6a3-ac3eec3690fb/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作者还扫描了从 6 到 24 层的深度（保持约 11M 的常数参数预算）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;损失随着深度增加而改善，直到不再改善。深度 20 达到了甜蜜点（0.85 验证损失）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;深度 24 略有退步（0.93），这是由于为了将维度缩小到 192 而产生的宽度瓶颈。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Amax 是不可预测的。深度 20 飙升至 9.2 倍。深度 12 达到 6.6 倍。深度 8 保持在 4.3 倍。没有清晰的关系；HC 是混沌的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验细节&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;数据集： TinyShakespeare（约 1M 字符，字符级）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型： GPT-2 架构，约 10M 参数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练： 5000 步，AdamW (&amp;beta;1=0.9, &amp;beta;2=0.95)，权重衰减 0.1，余弦 LR 衰减&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;硬件： Apple M 系列 (MPS)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;深度扫描： 8 种配置（6-24 层），调整宽度以维持约 11M 参数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;种子变异： 3 个种子（42, 123, 456），深度 24&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;为什么这很重要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;残差连接不仅仅是帮助梯度流动的技巧。它们是一种守恒定律。&lt;/p&gt;&lt;p&gt;在物理学中，守恒定律约束了可能发生的事情，但使预测成为可能。你不能制造永动机，但你可以精确计算球会落在哪里。&lt;/p&gt;&lt;p&gt;残差连接中的恒等映射是类似的。它通过防止任意变换来约束网络，但它保证了稳定性。信号幅度被保留。&lt;/p&gt;&lt;p&gt;HC 打破了守恒；mHC 恢复了它，不是通过回归到恒等映射，而是通过找到一个更丰富的、仍然守恒信号的流形。&lt;/p&gt;&lt;p&gt;2016 年，何恺明等人引入 ResNets 来解决梯度消失问题，确保信号不会消亡。十年后，相反的问题出现了：超连接带来的信号爆炸。恒等映射通过被动的方式解决了第一个问题。mHC 通过强制守恒解决了第二个问题。&lt;/p&gt;&lt;p&gt;每一个残差连接都是一种守恒定律。mHC 强制执行了它。&lt;/p&gt;&lt;p&gt;不是黑客手段，不是技巧。这是一个原则性的约束，使架构能在规模化下工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;流持久性 Bug 让人学会谦卑。&lt;/strong&gt;作者的第一个实现看起来是对的。公式与论文相符。代码能跑。但当把输出投影回单一流并在每一层重新扩展它，扼杀了并行架构。「超连接」中的「超」部分实际上没做任何事。三次独立的审计都说「看起来是对的」。Bug 是架构上的，不是数学上的。作者是在问了「等等，层与层之间流动的实际形状是什么？」之后才发现的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;约束不是限制；它们是保证。&lt;/strong&gt;双重随机投影强制了稳定性。你不是在学习好的行为。你是在让坏的行为变得不可能。作者表示自己的第一反应是：「这不优雅。这是束缚。」但其实，HC 达到了 7 倍放大才是重点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无聊的选择能规模化。&lt;/strong&gt;标准残差连接自 2016 年以来一直存活，不是因为它们是最优的，而是因为它们是稳定的。HC 表达能力更强但脆弱。mHC 找到了一个中间地带：比标准残差表达能力更强，且带有稳定性保证。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;博客 2：10,924 倍：17 亿规模下的不稳定炸弹&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下面是 mHC 复现系列的第 2 部分。第 1 部分 展示了 10M 参数量下的不稳定性。现在，要扩大规模了。&lt;/p&gt;&lt;p&gt;在第 1 部分中，作者在 TinyShakespeare 数据集上训练了一个 10M 参数的 Transformer，并目睹了超连接（Hyper-Connections）将信号放大了 9.2 倍。DeepSeek 的论文 报告称在 27B 参数下放大倍数达到了 3000 倍。现在我们也扩大规模看看。&lt;/p&gt;&lt;p&gt;为了这次运行，作者租用了一个 8x H100 的节点。以下是他的发现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规模跃迁&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qRxwTSib2fNm2k7ExD0gK2mnlH1ibeCqFKgAV7bEIcicyeHvdrcqQhPEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.36363636363636365" data-s="300,640" data-type="png" data-w="869" type="block" data-imgfileid="503528948" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/aa27acf1-40f2-4709-845a-d6ccb323100a/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;10924 倍信号放大！这远远超出了 DeepSeek 论文中的 3000 倍。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇博客记录的是作者在三种架构上进行的 18 次实验，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Residual：标准的残差结构，即 x + F (x) 作为基线；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HC：采用无约束混合矩阵的超连接（Hyper-Connections）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;mHC：采用 Sinkhorn 投影的流形超连接（Manifold Hyper-Connections）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每种架构分别在两种网络深度下进行（32 层和 48 层），并使用三个随机种子（42、123、456），因此每种配置运行 3 次。&lt;/p&gt;&lt;p&gt;所有模型均在 C4 数据集上训练 5000 步，采用 bf16 混合精度。其中 32 层模型参数量为 17.3 亿（1.73B）；48 层模型参数量为 25.4 亿（2.54B）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主要结果&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qIudVn1dePL4W3zdUcrJI3JgJhqvEhYg8TFayEBHuMMlcDNicmR3JrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.712037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528949" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/92099748-1230-44ee-aca3-2634116ebb1e/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;首先，在 Loss 表现上：所有方法的收敛表现几乎一致。&lt;/p&gt;&lt;p&gt;三种方法最终都收敛到相近的 loss 区间（约 5.4&amp;ndash;6.0）。整体学习曲线几乎完全重合：HC 并没有学得更快，mHC 也没有变慢。从实验结果来看，引入 Sinkhorn 投影几乎没有额外代价。&lt;/p&gt;&lt;p&gt;其次，Amax 表现出强烈的不稳定性。Amax 是用来衡量混合矩阵对信号的放大程度，Amax = 1.0 表示对信号不放大（中性）；数值越高，表示信号被放大的程度越强。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD143CBnzK5jffKKxibNCgb5LicONnqYD8HaJwHQctPtFg4ibzxfLDEu0oDCw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=20" data-ratio="0.6284722222222222" data-s="300,640" data-type="gif" data-w="576" type="block" data-imgfileid="503528950" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/cac33753-49d5-445c-ae04-fa165554b3f6/640.gif" data-order="2" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验中发现，在深度为 32 时，HC 的 Amax 值飙升至 6500 倍，并伴随着剧烈的波动，而 mHC 值则稳定保持在 1.0。在深度为 48 时，这种模式再次出现：HC 猛增至 3500 倍，而 mHC 值保持不变。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14D4micrXBUEpxjwyjQtjLF8kSJY6wicwExtROYCPmRWTOYiaPVicnhvCQ4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528951" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/03f3c9d8-777a-4ead-a9d7-3aa4e83afe88/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Scaling Laws&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14PrayHRzwlbibf1yNI8eHOSMILT1dwCslXWAKfTkiagiblibId1qSHT2J8g/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528952" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/bc2965d9-9dd6-425c-9fd4-1730a20e6118/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在对 Amax 与模型参数规模进行 log&amp;ndash;log 绘制后，可以观察到明显的放大趋势：当模型规模为 1000 万参数时，Amax 约为 9.2 倍；在 17 亿参数规模下，这一数值跃升至 10924 倍；&lt;/p&gt;&lt;p&gt;而公开数据中，DeepSeek 的 270 亿参数模型对应的 Amax 约为 3000 倍。基于趋势线外推，模型规模达到 100 亿参数时，Amax 可能上升至约 50000 倍，在 1000 亿参数量级下，甚至可能接近 400000 倍。&lt;/p&gt;&lt;p&gt;实验结果并未显示出任何自我修正的迹象，相反，随着模型规模扩大，不稳定性呈现出持续加剧的趋势。值得注意的是，该实验中的 17 亿参数模型所表现出的不稳定性，甚至高于参数规模更大的 DeepSeek 模型。&lt;/p&gt;&lt;p&gt;这种差异可能源于架构设计、训练配方或测量方法的不同；批大小、学习率与网络深度之间的相互作用，也使得尺度效应并非严格单调。&lt;/p&gt;&lt;p&gt;尽管具体数值会受到多种因素影响，但这种不稳定性是客观存在的、可以被量化的，而且规模不容忽视。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可复现性&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Ft0XWaVGSUqCUxpHs8KiaNSQutq3lCBKkA0TAaGQ07bCQdAKcNjjUZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.662962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528954" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/56023cce-775a-471c-817c-796e54dcecbb/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，在三个不同的随机种子下，实验都呈现出完全相同的模式：所有 HC 的训练过程都会发生爆炸，而所有 mHC 的训练过程始终保持平稳。不同随机种子下的 loss 曲线几乎完全重合，两种方法的学习速度也一致。&lt;/p&gt;&lt;p&gt;唯一的差别在于模型内部正在发生的事情：HC 在不断积累不稳定性，这种不稳定性可能在任何时刻被引爆；而 mHC 则始终维持着自身的结构完整性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;逐层分析：不稳定性从哪里开始的&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD144OV30ySHmJNngohQHv5WMXgbTdjS4gVqdSOicAekOx87bzjHYqHZDFA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=24" data-ratio="0.8131487889273357" data-s="300,640" data-type="gif" data-w="578" type="block" data-imgfileid="503528955" data-aistatus="1" data-original-style="null" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/e521e269-94bd-4432-8058-8e09cfb7d8e0/640.gif" data-order="3" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这里有一个令人惊讶的发现：&lt;strong&gt;不稳定性始于输入端，而非输出端&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;HC 的第 0 层（可视化图表中的顶行）率先变红，随后其混合矩阵在训练初期就突破了 Amax 2.0，而更深层的网络则保持相对稳定。看起来问题不在于深度，而在于第 0 层 &amp;mdash;&amp;mdash; 这是唯一一层直接吞吐原始输入的层。&lt;/p&gt;&lt;p&gt;为什么是第 0 层？ 不同于深层网络前面有 LayerNorm 把关，第一个混合矩阵直接面对原始 Embeddings。其他每一层看到的都是经过归一化、变换后的表征，但第 0 层必须硬抗 Embedding 表吐出的任何数值。如果尺度（scale）没有完美匹配，第 0 层就会学习去补偿。&lt;/p&gt;&lt;p&gt;而在 HC 中，「补偿」可能就意味着「放大」。反观 mHC，在所有层级和所有训练步数中都呈现均匀的绿色。Sinkhorn 投影在限制最大值的同时，也完全防止了任何层发生漂移。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信号流：视觉展示&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148HrkPEicLkbMKY9a7yJk04NncECBn5s3SOwX0zx4H40DvwtYVmicv0tQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=25" data-ratio="0.41297935103244837" data-s="300,640" data-type="gif" data-w="678" type="block" data-imgfileid="503528956" data-aistatus="1" data-original-style="null" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/568b2609-5914-4f36-8ee7-3e7dc0cb25ba/640.gif" data-order="4" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在第 3000 步时，一个进入 HC 网络的信号在输出时被放大了 532 倍。而同样的信号经过 mHC 输出时倍率为 1.000003 倍，本质上保持不变。&lt;/p&gt;&lt;p&gt;LayerNorm 和非线性模块似乎「收拾」了大部分烂摊子，但这意味著它们消耗了模型容量，仅仅是为了去抵消上游制造的混乱。&lt;/p&gt;&lt;p&gt;这正是守恒定律的体现，它表明残差连接应当保持信号的幅度：输入了什么，就应当输出什么（再加上学习到的残差）。&lt;/p&gt;&lt;p&gt;HC 打破了这一规则，任由信号失控螺旋上升，而 mHC 则守住了底线。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;压力测试&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14gSaOIAWmiaMM9kuSlNMDvsqRcup1KHcxVicjP8NLXjuyKJZQvNrJgqiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.3509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528958" data-aistatus="1" data-original-style="null" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/87cf0514-a690-4404-ad93-b24701dd4154/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;正常的训练使用了 1e-4 的学习率。如果加大强度会发生什么？作者在 3 倍于正常学习率的条件下进行了压力测试：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14SVdwpjjUCsYuMK9fvtu3RoWcfzBYKp1pWE8CrvhDA1ygzK3ibYg3wuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=27" data-ratio="0.3731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528959" data-aistatus="1" data-original-style="null" data-index="29" src="https://image.jiqizhixin.com/uploads/editor/249935b6-0373-4cbd-a740-a053d055c11f/640.png" alt="图片" data-report-img-idx="27" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;深度 64 的模型在 Amax 达到 14765 倍后，开始在 2000 倍到 10000 倍之间剧烈振荡，同时，混合矩阵彻底失控。&lt;/p&gt;&lt;p&gt;反观 mHC，在所有配置、所有学习率下都表现得平坦、稳定且「无聊」，数值始终保持在 1.0。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;意料之外：HC 模型并未崩溃&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14gPM78lqLq2pMicicvSaG3vZemP982XL1koRM3AxpdVNuVE9Ew4U0QNSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=28" data-ratio="0.4324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528960" data-aistatus="1" data-original-style="null" data-index="30" src="https://image.jiqizhixin.com/uploads/editor/e401403d-fce4-471a-b9ee-4981ff560077/640.png" alt="图片" data-report-img-idx="28" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;有一个作者没想到的结果：所有的 HC（Hyper-Connections）运行实验都没有崩溃。&lt;/p&gt;&lt;p&gt;信号放大了 14765 倍，在深度 32 时放大了 10924 倍。Loss（损失）没有发散，训练也没有出现 NaN。模型仍在继续学习。&lt;/p&gt;&lt;p&gt;这是一种「定时炸弹」般的场景。不稳定性确实存在，但尚未导致灾难性的失败&amp;hellip;&amp;hellip; 至少目前还没有。&lt;/p&gt;&lt;p&gt;为什么没炸？作者列举了以下几种可能性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;梯度裁剪力挽狂澜。&lt;/strong&gt;将范数裁剪在 1.0 防止了最严重的梯度爆炸，这几乎肯定就是拯救了这次运行的关键。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;5000 步还不够。&lt;/strong&gt;如果训练时间再长一点，它可能就会爆发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;这些模型还太小。&lt;/strong&gt;在 100B（千亿）参数规模下，动力学特性可能会有所不同。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;稳妥的解读是：&lt;strong&gt;HC 正在积聚不稳定性，在不同条件下可能会被引爆，而 mHC则完全消除了这种风险&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;重访守恒定律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在第 1 部分中，作者将残差连接定义为了一种守恒定律，即「每一个残差连接都是一条守恒定律，mHC 强制执行了它。」&lt;/p&gt;&lt;p&gt;1.7B 参数规模的结果让这一点变得具体：HC 违反了守恒，信号在训练过程中增长了 10000 多倍。而 mHC 强制守恒，信号保持稳定。具体地，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 10M（一千万）参数时，违反守恒是可以存活的。作者在第 1 部分中看到的 9.2 倍放大虽然烦人，但尚在可控范围内。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 1.7B（十七亿）参数时，这就是个炸弹。10924 倍的放大意味着一个本该是量级 1 的信号，现在变成了 10924。梯度更新在与这种放大对抗，而优化器必须做额外的工作来补偿网络内部的混乱。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这还仅仅是在 5000 步的时候，如果训练更久、推高学习率、或者扩展到 10B 参数，在某个临界点，炸弹就会引爆。&lt;/p&gt;&lt;p&gt;mHC 不仅仅是降低了不稳定性，而是彻底消除了这种故障模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从这次运行中学到了什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一是，GPU 3 挂了。8 张 H100 中的一张在特定实验中不断报错 CUDA 错误。作者浪费了一个小时调试「代码问题」，才意识到是硬件故障。云端 GPU 是会坏的。&lt;/p&gt;&lt;p&gt;二是，Batch size（批次大小）的限制是真实的。2.5B 参数的 d48 模型无法在 batch size 为 8 时塞进显存。作者不得不降到 batch size 4。这意味着不同深度下的「每步 token 数」不同。&lt;/p&gt;&lt;p&gt;虽然同一深度下 HC 与 mHC 的对比依然有效（batch size 相同），但跨深度的对比就不那么完美了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果正在实现超连接：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用 Sinkhorn 投影。这里大概只有 10 行代码，却消除了一种在大规模下感觉真正危险的故障模式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在训练期间监控 Amax。如果你看到它爬升超过 10 倍，则是在积聚不稳定性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第 0 层是「金丝雀」（预警指标）。特别密切关注你的输入混合矩阵。如果你的基础模型有一个不稳定的第 0 层，微调期间的词表变更或 Embedding 漂移可能会导致网络不稳定。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该约束没有性能代价。mHC 的 Loss 与 HC 完全一致。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;代码和数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数据是公开的，代码即将发布。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;主要实验: wandb.ai/taylorkolasinski/mhc-part2&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;压力测试: wandb.ai/taylorkolasinski/mhc-part2-stress&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者表示，包含训练脚本的仓库即将推出。W&amp;amp;B 仪表板拥有每次运行的完整配置、指标和系统日志。实验在一个 Lambda Labs 的 8x H100 SXM5 节点上运行，耗时约 17 小时。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一步计划&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前有两个悬而未决的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;HC 真的会失败吗？ 作者看到了 10924 倍的放大，但训练没有发散。这是一种潜在风险，还是说训练时间更长就会导致失败？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Scaling Law 是什么？ 10M &amp;rarr; 9.2 倍。1.7B &amp;rarr; 10924 倍。到了 10B 会发生什么？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者想探索 Scaling Law 到 10B 参数，趋势线表明那里可能出现 50000 倍的放大。那个实验技术上已经准备好了，但需要计算预算的大幅提升。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>评审用不用AI，作者说了算？ICML 2026全新评审政策出炉</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:13:11 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;开始前，温馨提醒一下各位投稿 ICML 2026 的小伙伴们，投稿已于 1 月 8 日开放，也请大家注意投稿截止时间：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;摘要提交截止日期：2026 年 1 月 23 日。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;全文提交截止日期：2026 年 1 月 28 日。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;两个月前，ICML 2026发布了征稿新规，我们也&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651000328&amp;idx=2&amp;sn=7be350e14dc2b6b044763ad91f745a4a&amp;scene=21#wechat_redirect" target="_blank"&gt;详细做了报道&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;当时，为了应对大量的，超负荷的预期论文投稿量，以及其他顶会超负荷运行的前车之鉴，ICML 提出了互审数量限制和人工智能使用规定。&lt;/p&gt;&lt;p&gt;征稿要求中提到：评审过程中&lt;strong&gt;可能会使用 AI 工具辅助，但不会允许完全由 AI 执行评审&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;已经投稿了论文的小伙伴或许已经发现了，这次 ICML 似乎有了一些新变化，并且是在征稿要求中没有详细说明的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ucegjrN0AxZIeMX3T1mPs5sAd8t7icFiagK0XhSzCzGwwBoDsTVN4sxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5453703703703704" data-type="png" data-w="1080" data-width="1482" data-height="808" data-imgfileid="503528857" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/254144b5-2641-4b13-a22b-892c22aa7251/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;我们简单概括一下，ICML 2026 引入了评审类型选择机制，&lt;strong&gt;论文作者可以决定&lt;/strong&gt;在其论文评审过程中是否允许使用大语言模型。&lt;/p&gt;&lt;p&gt;具体包括两种政策：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;政策 A 是保守型&lt;/strong&gt;，简单直白好理解：&lt;strong&gt;严格禁止&lt;/strong&gt;在论文评审过程中使用任何大语言模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;政策 B 是宽松型，允许使用&lt;/strong&gt;大模型评审，但会议对使用大模型评审的方式做出了限制：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;允许的行为：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用大语言模型辅助理解论文内容及相关工作；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用大语言模型对评审意见进行语言润色；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;可将投稿论文提交给符合隐私合规要求的大语言模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;不允许的行为：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;向大语言模型询问论文的优点或缺点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型总结或建议评审应关注的关键点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型提供评审意见的结构或提纲；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型撰写完整的评审意见。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;隐私合规大语言模型，是指&lt;strong&gt;不会使用日志数据进行训练、且对数据保留期限作出限制&lt;/strong&gt;的模型工具。&lt;/p&gt;&lt;p&gt;这个小变化是比较新颖的。&lt;/p&gt;&lt;p&gt;过去，评审是否使用大模型，更多取决于评审人，或者处在一种默认被接受的灰色状态。这一次，ICML 明确把选择权交给了作者本身。在论文投稿量持续攀升、评审负担越来越重的现实下，ICML 既没有彻底禁止 AI，也没有完全放开 AI 评审，却给出了一个相对折中的方案。&lt;/p&gt;&lt;p&gt;问题在于，关于大模型使用的规定，执行起来一般都很困难。&lt;/p&gt;&lt;p&gt;就像&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651002013&amp;idx=1&amp;sn=c4588ce6e29f6464cda6e84dfded6af5&amp;scene=21#wechat_redirect" target="_blank"&gt;我们之前报道的&lt;/a&gt;，第三方机构对 ICLR 2026 的审稿意见进行系统性统计，其中就发现了大量 AI 审稿的现象。&lt;/p&gt;&lt;p&gt;在对 75800 篇论文的审稿意见统计中，竟然&lt;strong&gt;有 21% 完全由 AI 生成、4% 重度由 AI 编辑、9% 中度由 AI 编辑、22% 轻度由 AI 编辑，完全由人类（审稿人）撰写的仅占 43%&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14logWUV2YVJemybGdKOicgfps3icWfrfZQGibpFHkiaiaYsYgziagz9qvTTWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.32222222222222224" data-type="png" data-w="1080" data-width="1080" data-height="348" data-imgfileid="503528856" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4bb631eb-7238-43ce-86a2-c29d7c00af30/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;网友们也表达了类似的意见。&lt;/span&gt;AI 审稿已经达到了泛滥的程度，这也并不是 ICML 2026 这次的政策 B 能够完全限制的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14LF88DuOD6fVGxZCpxUVKiavQuaScTv2Seswonic0gNQAfzIaz7icJ7KWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.18796296296296297" data-type="png" data-w="1080" data-width="1450" data-height="272" data-imgfileid="503528858" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f9d22172-c902-42e7-8509-5deb8fb72a61/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;虽然说 ICML 明确规定了使用大模型审稿中不允许存在的行为，但谁又能保证审稿人一定遵从了这些限制呢？我们猜测，用大模型审稿的时候，提问大模型的第一句话就很可能是「给出这篇论文的优缺点」，但这明显是违反规定的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14YK49xxnNkW4vDEZEDHvuVDajoO45DIMWlrbdric1MNiaARR7CCRDzzBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1685185185185185" data-type="png" data-w="1080" data-width="1404" data-height="236" data-imgfileid="503528854" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/183ee06d-5c84-421d-bb9b-e800821af73a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;因此，这套规则或许更像是一种明确态度和方向的约定，而不是一套可以严格执行的机制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14zqG7XA1nMvLVZHian7WcQY4VOcDPQa28mgHSj6b5u3KfsYEOxeW7WBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2796296296296296" data-type="png" data-w="1080" data-width="1430" data-height="400" data-imgfileid="503528855" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/db7a43ce-c6bb-4965-b926-13e6d0a97f63/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不过，在大家如此担心大模型引发各种信任危机的情况下，ICML 还可以让作者选择拒绝大模型审稿。&lt;/p&gt;&lt;p&gt;有个「一刀切」的选项交到论文作者手中，也是当下一个不错的选择，不是吗？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>机器人终于「懂」家务了！伯克利MomaGraph让机器人像人一样做家务</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:02:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/03280580-d5bd-4fa7-bee4-757837eadd1f/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;想象这样一个日常画面：你吩咐家用机器人「烧壶开水」，它却当场卡壳&amp;mdash;&amp;mdash;水壶在哪？该接自来水还是过滤水？先插电还是先按开关？水开了又该如何判断？这些对人类而言像呼吸一样自然的家务，对过去的机器人却是大大的难题：要么忘了插电，要么找不到水壶，甚至会把柜门把手错当成开关一通乱按。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;最近，加州伯克利和马里兰大学联手推出的 &lt;strong&gt;MomaGraph 技术&lt;/strong&gt;，就是要让机器人彻底告别这种「做家务的人工智障」时刻。这套算法不仅能让机器人真正理解「做事的先后顺序」，更在星动纪元星动 Q5 上成功完成了开柜子、开微波炉、开电视、关灯等真实家务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFJH7iavGYicQG6ed7A7QR9c2HU2V7309dMkGQDjbOvguicH6FAKibQ5EcnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5722222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528573" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/daa3e230-b3ed-44a5-9547-2828f793c081/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;a href="https://mp.weixin.qq.com/s/H8aS7_QVhS0Who_tJee69Q"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8a03ed7d-0f3e-48c8-adab-7235162ba11b/1768812923781.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gWibFFuSlngZ6TUI2YBIRPjCRiaakUoUJj2dH6brT0QRZus4psqZYOD4vMJ21RTVh2zodjIssA97aTGg%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4347229785035112470" data-ratio="1.7777777777777777" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4347229785035112470" data-vh="371.8125" data-vidtype="2" data-vw="661" data-w="1920" height="384" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4347229785035112470"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;论文名称：MOMAGRAPH: STATE-AWARE UNIFIED SCENE GRAPHS WITH VISION&amp;ndash;LANGUAGE MODEL FOR EMBODIED TASK PLANNING&lt;/li&gt;&lt;li&gt;论文地址：https://arxiv.org/pdf/2512.16909&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="8"&gt;&lt;strong&gt;一、研究背景：家用机器人做不好家务的「三大卡点」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;家用移动操作机器人（比如帮你开窗户、热牛奶的机器人）需要同时「看路」（导航）和「动手」（操作），但过去的技术一直存在三个关键问题卡点，导致机器人「做不好家务」：&lt;/p&gt;&lt;p data-path-to-node="10,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,0,0"&gt;卡点 1：只知「在哪」，不知「咋用」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,0,0"&gt;比如机器人要开窗户，传统技术可能只知道「窗户在书桌右边」（空间关系），但不知道「窗户把手能控制开关」（功能关系）&amp;mdash;&amp;mdash;就像你知道手机在口袋里，却不知道按电源键能开机，自然用不了手机。&lt;/p&gt;&lt;p data-path-to-node="10,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,1,0"&gt;卡点 2：只认「图片」，不认「变化」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,1,0"&gt;传统模型会把场景当成静态图片，比如机器人转了窗户把手后，模型还以为「窗户没动」，不知道状态已经从「锁着」变成「待打开」；就像你关了灯，却还以为灯是亮的，后续行动规划肯定会出错。&lt;/p&gt;&lt;p data-path-to-node="10,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,2,0"&gt;卡点 3：只想「步骤」，不想「前提」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,2,0"&gt;过去的 AI（比如 GPT-5）会直接从图片里「想步骤」，比如让它「烧开水」，可能会说「装水 &amp;rarr; 加热」，却漏掉「插电源」这个关键前提；而人做这件事时，一定会先确认「水壶能通电」，再规划步骤。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFzmGzDCKZogFb1WibUPVEXs37KVQAuJg7uAd4zHUR0icoYzhrmazSnx0w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.49537037037037035" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528606" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9db73485-6f5f-4127-85f3-ca7146bba6cb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;二、突破思路：给机器人画一张「任务说明书」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;研究团队的核心想法很简单：&lt;strong&gt;让机器人先画一张「任务导向的场景图」，再按图规划任务执行步骤&lt;/strong&gt;，这就是「Graph-then-Plan」（先图后规划）思路，而这张图就是「MomaGraph」。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;这张图到底特殊在哪？举个「开窗户」的例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="14,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,0,0"&gt;统一空间 + 功能&lt;/b&gt;：图里会同时写「把手在窗户右侧」（空间）和「把手能控制窗户开关」（功能）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="14,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,1,0"&gt;动态更新状态&lt;/b&gt;：机器人转了把手后，图会从「把手未旋转 &amp;rarr; 窗户锁着」更新为「把手已旋转 &amp;rarr; 窗户待打开」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="14,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,2,0"&gt;紧扣任务需求&lt;/b&gt;：只保留和「开窗户」相关的信息（比如忽略窗户上的贴纸），不做无用功。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="15"&gt;简单说，传统模型是「看到图片直接猜步骤」，而 MomaGraph 是「先搞清楚『有什么、怎么用、状态如何』，再一步步规划」&amp;mdash;&amp;mdash;就像你做饭前会先看「冰箱有鸡蛋、锅能加热」，再想「打鸡蛋 &amp;rarr; 开火 &amp;rarr; 煎蛋」，而不是直接拿锅就烧。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;三、研究方法：从「数据」到「机器人」的全链条方案&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;要让 MomaGraph 落地，研究团队搭建了「数据集 - 模型 - 基准 - 真实机器人」的完整体系，其中星动纪元轮式人形机器人星动 Q5 成为了「把技术从实验室变实用」的核心硬件。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;b data-index-in-node="0" data-path-to-node="18"&gt;第一步：建「训练素材库」&amp;mdash;&amp;mdash;MomaGraph-Scenes 数据集&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="18"&gt;要教机器人「懂家务」，得先给它看足够多的「家务样本」。团队收集了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="19,0,0"&gt;6278 张多视角家庭照片（比如从正面、侧面拍柜子、微波炉）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="19,1,0"&gt;1050 个「任务场景图」（比如「开微波炉」的图里，标注了「微波炉把手在正面」「把手能开门」）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="19,2,0"&gt;覆盖 350+ 家庭场景、93 种任务（开窗户、烧开水、开电视等）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19,2,0"&gt;这些数据就像机器人的「家务课本」，让它知道不同场景下「物体该怎么用」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFeOWabv3DYFk9Haia8NO6bVjOeicwhLpMf3icUaoYQPUbrqvntjACDaJmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528607" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7b4b794f-3e1f-4009-bdae-19869adae1ec/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;&lt;b data-index-in-node="0" data-path-to-node="20"&gt;第二步：训「聪明大脑」&amp;mdash;&amp;mdash;MomaGraph-R1 模型&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;团队用 70 亿参数的视觉语言模型（VL 模型，基于 Qwen-2.5-VL-7B），通过强化学习训练出 MomaGraph-R1：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,0,0"&gt;训练逻辑：模型生成场景图后，系统会按「三个标准」打分（奖励）：步骤对不对？有没有漏物体？空间/功能关系准不准？比如生成「水壶插电才能加热」就加分，漏了「插电」就扣分；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="21,1,0"&gt;核心能力：能根据任务生成「精简有用」的场景图，比如「找遥控器开电视」时，会重点标注「遥控器在沙发上」「遥控器能控制电视」，忽略沙发颜色这类无关信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFRanGficNIfoGfE0QwqalLWfpfJpzQU48p0qw273iclBCL2Ub356mRA2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5342592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528609" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/38800394-6a9d-4c21-87f5-3749bda24dba/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22"&gt;&lt;b data-index-in-node="0" data-path-to-node="22"&gt;第三步：测「能力高低」&amp;mdash;&amp;mdash;MomaGraph-Bench 基准&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;为了判断机器人「学没学会」，团队设计了 6 种能力测试（比如「步骤对不对」「能不能找对物体」「知不知道操作后会发生什么」），覆盖从简单（开柜子）到复杂（烧开水）4 个难度等级，确保测试结果真实可信。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFAKABI3pJcuUKKiaF96LpcGaNwticF22a7fGwVNnxmYgoKecnVmuoCNyw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.587037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528612" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2c2f805b-3c4a-48a9-92ee-d55f87b9532f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23"&gt;&lt;b data-index-in-node="0" data-path-to-node="23"&gt;关键一步：真实机器人落地&amp;mdash;&amp;mdash;星动纪元 Q5 的硬件优势&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="23"&gt;再好的「大脑」也需要「手脚」来执行，研究团队选择星动纪元星动 Q5 轮式人形机器人做真实场景测试，这款硬件的优势直接帮 MomaGraph 发挥出最佳效果：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFdZibOFjYDBquiah9I42jO62Cp1icEkuyrtcfrVXfVdECrIGMGFyibrKc4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528614" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d75eb094-7ec7-408f-a067-b9b0e6bef843/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,0,0"&gt;双臂 + 移动底座&lt;/b&gt;：能「走」到不同房间（比如从客厅到厨房），还能「动手」精准操作&amp;mdash;&amp;mdash;开柜子时，双臂能稳定抓住把手并拉动；开微波炉时，能控制力度避免损坏；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,1,0"&gt;多视角相机（Intel RealSense D455）&lt;/b&gt;：能拍物体的多个角度（比如从上方看水壶、从侧面看插座），帮模型获取准确的空间信息，避免「认错位置」（比如不会把柜子把手当成开关）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,2,0"&gt;适应家庭场景&lt;/b&gt;：硬件尺寸适合家庭环境（不会撞坏家具），双臂力度可控（不会捏碎杯子），完美匹配「家务任务」的需求。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;比如测试「开柜子」时，星动 Q5 的相机先拍柜子和把手的多视角图，MomaGraph-R1 根据图片生成「把手在柜子正面、能开柜子」的场景图，再规划「靠近柜子 &amp;rarr; 抓把手 &amp;rarr; 拉柜子」的步骤，Q5 的双臂精准执行，成功率远超传统机器人。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;&lt;strong&gt;四、研究结论：机器人「做家务」的能力大幅提升&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;从基准测试到真实机器人实验，MomaGraph 交出了亮眼的成绩，核心结论可以总结为三点：&lt;/p&gt;&lt;p data-path-to-node="28,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,0,0"&gt;「先画图再规划」远胜「直接猜步骤」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,0,0"&gt;在 MomaGraph-Bench 基准测试中，MomaGraph-R1 的准确率达到 71.6%，比目前最好的开源模型（比如 LLaVA-OneVision）高 11.4%；而像 GPT-5 这样的闭源大模型，常会漏关键步骤（比如烧开水没提「插电源」），MomaGraph-R1 却能 100% 覆盖前提步骤&amp;mdash;&amp;mdash;因为它先画了「水壶需要插电」的场景图，再规划步骤。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFqPezApsTukQeG2EKkvibZeNIYFU61QJ7lfACET1bx1N1zMtnZpDa5gw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.36574074074074076" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528616" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7d587a6e-d541-486b-ba56-c3de150a0203/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="28,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,1,0"&gt;「空间 + 功能」一起看，比单独看更准&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,1,0"&gt;实验对比了「只看空间关系」、「只看功能关系」、「两者都看」的效果：MomaGraph-R1（统一版）在复杂任务（Tier 4）的准确率是 68.1%，而「只看功能」的版本只有 59.0%，「只看空间」的版本更低只有 45.4%。这说明：机器人既要知道「东西在哪」，也要知道「东西怎么用」，才能做好家务等任务的执行。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFOasOEIibn2p2CY4ZB5bLAmX7gNOl9IFg7K3qyGu0xBchrKob6JiaQJ1g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.18333333333333332" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528621" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/9152084b-020f-4ac7-ad9f-bf2bebc152a1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="28,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,2,0"&gt;在真实机器人上能落地，还能处理复杂任务&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,2,0"&gt;团队用星动纪元星动 Q5 测试了 4 个常见任务：开柜子、开微波炉、开电视、关灯，全部成功；更难的「长任务」（「开灯 &amp;rarr; 找遥控器 &amp;rarr; 开显示器」），10 次测试成功 7 次&amp;mdash;&amp;mdash;而这个任务需要机器人「先解决照明（状态影响可见性），再找遥控器（空间定位），最后开显示器（功能控制）」，传统机器人根本做不到。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFoDZIUibjTYwy749YZLLlTjFvic2lkFjiacEDdRnhCQCe3lBnRnspIKMicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528622" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/5ce92b65-3aa5-44df-bc87-b64667a49993/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="29"&gt;此外，MomaGraph-R1 在视觉对应任务上也表现突出，在 BLINK 基准和 MomaGraph-Bench 的对应任务中，比最好的开源模型分别高出 3.8% 和 4.8%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFGJGPS9xPrib2U2fzN3cRxce8HQFMtbUibG3ibpc19atXYS5eqKN0h81ZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.2324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528623" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/50952003-4af7-4e4c-ac49-5ebb79a842a6/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="30"&gt;&lt;strong&gt;五、行业意义：家用服务机器人离「进家门」又近了一步&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="31"&gt;MomaGraph 的价值，本质是解决了「机器人理解家庭场景」的核心难题：它让机器人从「只会按固定程序做事」（比如只会重复「推窗户」），变成「能根据场景灵活调整」（比如先看有没有把手，再决定转还是推）。&lt;/p&gt;&lt;p data-path-to-node="32"&gt;而星动纪元星动 Q5 这类执行硬件的参与，更证明了这项技术不仅仅适用于实验室&amp;mdash;&amp;mdash;仿人双臂、移动底座、精准相机的组合，让 MomaGraph 的「聪明大脑」有了可靠的「手脚」。未来，随着技术优化，我们可能会看到：机器人能帮老人烧开水、整理柜子，甚至帮上班族准备早餐&amp;mdash;&amp;mdash;家用服务机器人从「概念」走向「实用」，终于有了清晰的技术路径。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>迄今为止最大的细胞级CRISPR基因扰动数据集，AI加速药物发现与多组学整合，布局未来精准医疗</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 19 Jan 2026 14:06:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨%&lt;/p&gt;&lt;p&gt;2026 年 1 月 13 日，基因组学巨头&amp;nbsp;Illumina&amp;nbsp;宣布推出&amp;nbsp;&lt;strong&gt;Billion Cell Atlas&lt;/strong&gt;，这是迄今为止最大的细胞级 CRISPR 基因扰动数据集，包含了&lt;strong&gt;10 亿细胞&lt;/strong&gt;在 200 多种疾病相关细胞系中的响应数据。这一数据集将为 AI 模型提供训练基础，显著提升药物靶点识别、疾病机制理解和新疗法发现的效率。&lt;/p&gt;&lt;p&gt;此次发布标志着 Illumina&amp;nbsp;&lt;strong&gt;BioInsight 业务单元&lt;/strong&gt;首次推出数据产品，与辉瑞、默克等制药巨头展开合作，推动精准医学与 AI 药物发现的深度融合。这一数据集每年预计会生成约&amp;nbsp;&lt;strong&gt;20PB&lt;/strong&gt; 的单细胞转录组数据，并通过云平台加速 AI 模型的训练，推动科研进程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;单细胞资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;据公司新闻稿，Atlas 是 Illumina 新成立的 BioInsight 业务推出的首个数据产品。只有借助 Illumina 单细胞 3' RNA 制备平台才能实现，在单一实验中能够捕获数百万个单个细胞。&lt;/p&gt;&lt;p&gt;通过推出 Illumina 细胞图谱，并开发全面的疾病特异扰动数据集，结合先进的 AI 算法，Illumina 正在推动下一代细胞建模的发展。这本新的细胞图谱是在 Illumina 去年二月宣布的计划基础上，最终打造一个价值 50 亿的单细胞资源。到目前为止，Illumina 已从约 1.5 亿个细胞生成数据，预计年底前将达到 10 亿个。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwMuaA62qrKWS34lJdibrpdc6ojnkMczzXMiczMgibC8LFzohQPEibwdfgKQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.5399408284023669" data-type="png" data-w="676" data-width="676" data-height="365" data-imgfileid="100027178" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/6e0a13ff-be65-4c3f-b147-6a0779cf05ad/640.png" alt="图片" data-before-load-time="1768800471793" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;相关链接：&lt;em&gt;https://www.illumina.com/company/news-center/press-releases/press-release-details.html?newsid=383b9322-6cef-4fdd-8099-05a6f6904872&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Connected Multiomics 平台&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在公布该图谱的不久之前，1 月 6 日 Illumina 推出了&amp;nbsp;&lt;strong&gt;Connected Multiomics&lt;/strong&gt; 软件平台，旨在为研究人员提供跨基因组、转录组、蛋白组及表观组等多组学数据的整合分析与可视化工具。此平台结合了&amp;nbsp;&lt;strong&gt;AI 辅助变异解释&lt;/strong&gt;，支持大规模数据分析，为精准医疗和生物医药研发提供强有力支持。&lt;/p&gt;&lt;p&gt;Connected Multiomics 通过将多组学数据整合到单一平台，降低时间、成本和复杂性，使科学家能够加速发现并推动精准医疗的发展。在科罗拉多大学安舒茨医学院，肿瘤学研究人员利用该技术通过蛋白质组学数据分析，揭示了黑色素瘤的新见解。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwJm74gjicSUlsepF9ibdkuXNicLewxTQHOIjSDTEP7BOe2oyDXibc2Afq6Q/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.3148148148148148" data-type="png" data-w="1080" data-width="1460" data-height="459" data-imgfileid="100027177" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b3dec0f2-8bca-404c-8398-fe13736fdba6/640.png" alt="图片" data-before-load-time="1768800472290" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;相关链接：&lt;em&gt;https://investor.illumina.com/news/press-release-details/2026/Illumina-launches-powerful-software-for-connected-intuitive-and-scalable-multiomic-analysis&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;布局精准医疗与 AI 药物发现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从&lt;strong&gt;Connected Multiomics&amp;nbsp;&lt;/strong&gt;到&amp;nbsp;&lt;strong&gt;Billion Cell Atlas&lt;/strong&gt;，Illumina 正在加速推进&lt;strong&gt;AI 与精准医疗&lt;/strong&gt;的深度结合。随着数据集和多组学平台的不断发布，Illumina 在推动&lt;strong&gt;大数据驱动的药物发现&lt;/strong&gt;、&lt;strong&gt;基因组学进展&lt;/strong&gt;及&lt;strong&gt;AI 应用&lt;/strong&gt;方面，始终处于行业前沿。随着未来更多合作与技术落地，Illumina 的全方位布局可能会重塑精准医疗产业格局。&lt;/p&gt;&lt;p&gt;相关报道：&lt;em&gt;https://www.illumina.com/company/news-center/press-releases/press-release-details.html?newsid=fda84c92-b4b3-4691-a402-35555abe8605&lt;/em&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>你的论文有novelty吗？复旦搞了个顶会论文查新系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 12:07:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/382d228d-2bc6-4d38-b9b5-715533fd2a07/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;ICLR 2026 的 Rebuttal 结束了。当 OpenReview 上的喧嚣散去，我们发现，作者与审稿人之间漫长的拉锯战，最终往往只剩下一个核心分歧：「这个想法，以前真的没人做过吗？」&lt;/p&gt;&lt;p data-path-to-node="5"&gt;Novelty（创新性）是学术评审中被高度关注的指标之一， 但其评估在实践中仍高度依赖评审者的经验判断与检索覆盖。随 arXiv 文献数量的快速增长，仅靠人工检索与记忆来追溯相关研究工作，已难以满足高效的评审需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF2lMvtTzQu4zX9HHcsXgFJBo9IibXPXQFTyT5Q90GoxqhTy33C8cys1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5578034682080925" data-s="300,640" data-type="png" data-w="692" type="block" data-imgfileid="503528556" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e0c9c206-8e9e-40f0-bd0a-d2c261709eb2/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="6"&gt;针对这一挑战，复旦大学 NLP 研究团队与其此前孵化的学术搜索平台 WisPaper 展开合作，共同研发了 OpenNovelty&amp;mdash;&amp;mdash;一个基于大语言模型、强调证据与可验证性的自动化新颖性分析系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFYZqk3YVn7xsfHFPxEmgITKeDFb5xOibC0jmrUMQgIvTszWN8O5hv2IQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528555" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4c4b5d53-8c4c-4980-a4fa-07f87d3a35cf/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="8,0,0"&gt;论文标题：OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,0,0"&gt;论文链接：https://arxiv.org/abs/2601.01576&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,1,0"&gt;Github 链接：https://github.com/january-blue/OpenNovelty&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,2,0"&gt;HuggingFace：https://huggingface.co/papers/2601.01576&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,3,0"&gt;官方网站：https://www.opennovelty.org&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="9"&gt;&lt;strong&gt;核心设计&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;OpenNovelty 的根本原则很简单：任何关于「该论文创新性不足」的判断，都必须附带可追溯的真实证据，这些证据必须来自于已发表的文献，并且能精确定位到原文具体段落。若系统未能找到相关证据，则如实说明「未发现支持该判断的证据」。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;与传统查重仅关注文字表层重叠不同，OpenNovelty 试图解决语义层面的重复。 系统会对投稿进行结构化抽取，将作者表述转写为更便于检索与对比的学术概念短句，自动提取出论文的一个核心任务（Core Task）和若干具体贡献（Contributions）。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;此外，系统还采用了「查询扩展（Query Expansion）」机制，针对提取出的每条信息，生成多个语义等价的变体，在 WisPaper 的索引库中进行地毯式检索，防止单一表述带来的检索遗漏。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;&lt;strong&gt;四步分析流程：从论文提交到生成 &amp;nbsp;可验证的新颖性评估报告&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="13"&gt;&lt;strong&gt;第一步：核心信息提取&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="14"&gt;系统从论文的标题、摘要和引言，精准地提取出两类信息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="15,0,0"&gt;&lt;strong&gt;核心任务&lt;/strong&gt;：论文拟解决的核心学术问题（例如：「基于多轮强化学习的 LLM 智能体长周期决策训练」）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="15,1,0"&gt;&lt;strong&gt;贡献声明&lt;/strong&gt;：作者明确宣称的创新点，如新方法、框架、算法或理论形式化（例如：「一个支持多种强化学习算法的统一训练框架」）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFUk4MYTAr5Bq0cEnLRGxVB0HTia5IO5tiblF3n1ASskpDggrR2pKNb9XA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0074074074074073" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528558" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1e750d25-830d-41a1-83aa-2c2f4e558859/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;第二步：相关文献检索与筛选&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;基于提取的信息，系统自动生成一组学术搜索语句（包括同义词及变体表达，避免因措辞差异而遗漏相关文献），然后利用 WisPaper 学术引擎展开地毯式搜索。&lt;/p&gt;&lt;p&gt;初步检索可能召回数百至上千篇潜在相关论文，随后通过去重、时间过滤与筛除弱相关性文献等步骤，最终形成约 60&amp;ndash;80 篇用于后续分析的候选论文集合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFhf9gngGTp3r5UBibBiapbXjmRchKEo55tEIYOlf8Qick5UUVjvbF486Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7796296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528560" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/59a1a707-8492-42ac-9e96-223b9972d2ab/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;第三步：层次化分析与证据比对&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;这是系统的核心分析环节。系统会基于核心任务召回的候选论文构建层次化 taxonomy（树状分类体系），以呈现目标论文在相关研究脉络中的位置。提供目标论文在候选研究脉络中的相对定位，供评审者快速浏览。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;针对每条贡献声明，系统会在贡献召回的候选论文集合中进行逐篇对比，并尝试给出可核验的对应证据片段。比对的结果有如下三种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,0,0"&gt;能反驳（can_refute）：找到已发表的论文具有相似贡献，必须附带双方论文的原文摘录作为证据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFolXicgIaYKq63HtYkg8SJRKMNjHRGicIk9wFtGhCwClOB9PTcHPnEfTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.8268518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528561" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/416499bb-64c6-4b58-b9e9-c34ea6dc3d2b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,1,0"&gt;无法反驳（cannot_refute）：在当前检索范围内，未发现可质疑该创新贡献的文献。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="21,2,0"&gt;存疑（unclear）：信息不足，无法判断。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="22"&gt;关键在于：如果系统做出「能反驳」的判断，但其提供的证据（即摘录段落）无法在原论文中找到或匹配度过低，该判断会自动降级为「无法反驳」。&lt;/p&gt;&lt;p data-path-to-node="23"&gt;&lt;strong&gt;第四步：「新颖性调查报告」生成&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="24"&gt;系统整合前三阶段结果，生成包含以下模块的评估报告：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="25,0,0"&gt;论文的核心任务&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,1,0"&gt;研究领域的分类体系&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,2,0"&gt;每条创新声明的比对结果和证据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,3,0"&gt;综合的「新颖性评估」叙述&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于系统给出的关键判断，报告会尽量提供可追溯的候选文献与可核验的原文证据位置，便于评审者快速定位与人工复查。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFbIpgAb3ianhG9BQvh4ceC11L6ZHKXHcR22tYWhjPmUkG9X2YJvqoLkA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528562" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/ea1c4630-21b0-45ee-9a85-43c031e8b62a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;strong&gt;系统部署与公开验证&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;截止到 1 月 16 日，团队已经在系统上分析了 1360 篇投稿，并且把所有生成的新颖性报告公开发布在其官方网站。任何人都可以查阅系统对某篇投稿的分析结果、检索到的相关文献以及判断依据。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;团队计划进一步将分析规模扩展至 2000+ 篇投稿，此外，还将持续优化系统，计划将其应用于其他 AI 顶级会议，并对所收集的报告和评审证据进行深入分析。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;&lt;strong&gt;OpenNovelty 的影响&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="30,0,0"&gt;&lt;strong&gt;对审稿人而言&lt;/strong&gt;：它是一个辅助工具而非替代。系统可以帮助评审者梳理文献脉络，快速掌握一篇论文在领域中的位置，从而将更多精力集中于更需要人类专业判断的关键环节，如研究意义、方法严谨性等问题。&lt;/p&gt;&lt;p data-path-to-node="30,1,0"&gt;&lt;strong&gt;对论文作者而言&lt;/strong&gt;：它可作为投稿前的自查工具。如果研究具备实质创新性，系统可以提供相关证据；如果漏引了重要文献，系统亦能指出问题。&lt;/p&gt;&lt;p data-path-to-node="30,2,0"&gt;&lt;strong&gt;对学术界而言&lt;/strong&gt;： 该系统提供了一种&amp;ldquo;可验证的新颖性评估&amp;rdquo;工程路径&amp;mdash;&amp;mdash;用检索到的真实文献与贡献级证据对比来约束结论输出，让判断能够被追溯与复核，而不是停留在模型的无证据生成。推动 AI 成为负责人的知识引证者，而非不可靠的内容生成器。&lt;/p&gt;&lt;p data-path-to-node="31"&gt;&lt;strong&gt;仍需人类判断&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;团队在论文里也明确指出了系统的局限性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="33,0,0"&gt;难以理解复杂的数学公式和图表&amp;mdash;&amp;mdash;如果一篇论文的核心创新藏在一个复杂的方程式里，系统可能会错过；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="33,1,0"&gt;只能搜到被索引过的论文，可能错过未被收录的小众期刊或非英语出版物；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="33,2,0"&gt;「无法反驳」仅表示在「检索范围内未找到」，并不等于「确实不存在」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="34"&gt;因此，团队一再强调：&lt;strong&gt;这是辅助工具，而非决策主体&lt;/strong&gt;。最终的学术判断，仍然要由人类审稿人完成。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="36"&gt;OpenNovelty 的出现带有某种实验性的克制。它并非试图取代现有的同行评审体系，而是作为一套第三方审计系统介入。在 Rebuttal 结束后的最终决策阶段，它负责清洗迷雾，向 AC 展示那些被淹没的证据，而将最终的价值判断权留给人类。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;目前，ICLR 2026 的部分论文查新报告已在 OpenNovelty 官网开放查阅。对于即将在明年继续冲击顶会的科研人员来说，这或许是一个审视自己工作的新鲜视角。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让机器人看视频学操作技能，清华等全新发布的CLAP框架做到了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 12:03:52 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8f91d587-4689-4bf2-bce1-879a8a63af5b/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近日，&lt;strong&gt;清华大学与星尘智能、港大、MIT&amp;nbsp;&lt;/strong&gt;联合提出基于对比学习的隐空间动作预训练（Contrastive Latent Action Pretraining, CLAP）框架。这个框架能够将视频中提纯的运动空间与机器人的动作空间进行对齐，也就是说，机器人能够直接从视频中学习技能！&lt;a href="https://mp.weixin.qq.com/s/6qkoPGMbnZXFWOYg-MljlQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e843c007-a49d-4ee4-9d14-26ed5527b6c2/1768795269900.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;论文标题：CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.04061&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址：https://lin-shan.com/CLAP/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;长期以来，机器人学习面临着一个令人头疼的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;数据饥荒」难题：互联网上有着数以亿计的人类行为视频，但专门用于训练机器人的数据却寥寥无几。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;这种数据不对称现象的根源在于，收集机器人操作数据需要昂贵的硬件设备、专业的操作环境，以及大量的人工标注工作，成本高昂且效率低下。相比之下，人类行为视频数据虽然丰富，但由于视觉表征与机器人动作空间之间存在巨大的语义鸿沟，传统方法难以有效利用这些资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;现有的潜在动作模型（Latent Action Models）试图利用视频数据，但往往会遭遇「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;视觉纠缠」（visual entanglement）问题 &amp;mdash;&amp;mdash; 模型学到的更多是与实际操控无关的视觉噪声，而非真实的操控技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLAP 框架的核心创新正是解决了这一长期困扰业界的技术瓶颈。&lt;/strong&gt;该框架能够将视频中提纯的运动空间与机器人的动作空间进行对齐，有效避免了以往潜在动作模型中普遍存在的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;视觉纠缠」问题。通过对比学习，CLAP 将视频中的状态转移映射到一个&lt;strong&gt;量化的、物理上可执行的动作码本&lt;/strong&gt;上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;研究团队基于两种 VLA 建模范式进行训练：其一是 &lt;strong&gt;CLAP-NTP&lt;/strong&gt;，一种自回归模型，在指令跟随与对象泛化方面表现突出；其二是 &lt;strong&gt;CLAP-RF&lt;/strong&gt;，一种基于 &lt;strong&gt;Rectified Flow&lt;/strong&gt; 的策略，面向高频率、精细化的操控。&lt;/p&gt;&lt;p&gt;这一技术突破的实际意义体现在多个层面。首先，从数据利用效率来看，CLAP 框架使得机器人能够从 YouTube、抖音等平台上的海量视频中学习技能，极大扩展了可用训练数据的规模。其次，从成本效益角度分析，这种「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;看视频学技能」的方式显著降低了机器人技能获取的门槛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;此外，该框架还解决了机器人学习中的一个关键技术挑战 &amp;mdash;&amp;mdash; 知识迁移问题。通过&lt;strong&gt;知识匹配（Knowledge Matching, KM）&lt;/strong&gt;正则化策略，CLAP 有效缓解了模型微调过程中的灾难性遗忘现象，确保机器人在学习新技能的同时不会丢失已掌握的能力。&lt;/p&gt;&lt;p&gt;从产业应用前景来看，CLAP 框架的长期价值不仅在于技术创新，更在于其对机器人产业化进程的推动作用。当机器人能够通过观看视频快速掌握新技能时，企业部署机器人的成本和周期将大幅降低，这有望加速机器人在服务业、制造业等领域的规模化应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;详解 CLAP 框架&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDpoiaMxzHjtfdDs495VticjX6hLp5uD2iaUHicbnU34t7as4T9zEibyTCm4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.9" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528522" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/63f662bf-113b-4619-9e67-ec7430526a14/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队构建了一个统一的视觉 - 语言 - 动作（VLA）框架，使其能够同时利用&lt;strong&gt;机器数据的动作精确性与大规模无标注人类视频演示的语义多样性&lt;/strong&gt;。框架分为两个相互衔接的阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通过 CLAP 进行跨模态对齐&lt;/strong&gt;：建立共享的潜在动作空间，弥合无标注人类视频与有标注机器人轨迹之间的监督缺口。该过程基于对比学习进行隐空间动作预训练（CLAP）：它将人类视频中的视觉状态转移「锚定」到一个&lt;strong&gt;量化的、物理上可执行的动作空间&lt;/strong&gt;中。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDyAwt85U69iaUdBIVj3RWd9t9HBTR1K9fEzeibTenpITLbtTfvHNuarJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37962962962962965" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528523" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ce891345-2e02-4d2c-8651-1a0de81aea91/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分层策略训练&lt;/strong&gt;：研究团队通过连续训练两个 VLA 模型，将语义理解与控制动力学有效解耦：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CLAP-NTP&lt;/strong&gt;：采用「下一词元预测」（Next-Token-Prediction）训练的 VLA，擅长指令跟随与任务规划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CLAP-RF&lt;/strong&gt;：包含一个 VLM 模型与一个采用 Rectified Flow 训练的动作专家，以实现高频、精确控制。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为高效适配新的本体形态并防止预训练先验在微调中发生灾难性遗忘，研究团队进一步提出&lt;strong&gt;知识匹配（Knowledge Matching, KM）&lt;/strong&gt;微调策略：一种正则化方法，在微调过程中将策略更新锚定在可信区域内。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgHX6qibG0kurUP2HKTFBCKhFWK7P5iciazbWvfa4ac3MhkdE0Cc5icVsoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528525" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/57593a5e-a8dc-4330-97f9-fb342a0a36b1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;大量实验表明，CLAP 显著优于强基线方法，使得从人类视频中学习到的技能能够有效迁移到机器人执行中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;下表 1 为初始设置下，CLAP 与基线方法在真实世界任务中的性能比较。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDc0pibb9xbg0loFCgtYZiaPiaKfIUAwdQibuny80cINkEh48sXydnI9dGHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.287962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528527" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a5904f01-6636-4312-8f07-10ebc48a38b2/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;下表2 为 CLAP 与基线方法在环境扰动下的鲁棒性评估。&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDbQoTyLSf2FMQhzb07TnYicWy10VOPEa7lhwSfJtp4uZmCkqErbTsicGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.28703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528528" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/01e49ce1-6631-417d-a0a4-93c1da927ea0/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;更多实验结果请参阅原论文。&lt;/span&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CES 2026趋势照进现实：算力引擎RK182X重塑千行百业，瑞芯微AI生态大会共建落地生态</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 10:32:10 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img alt="图片" data-aistatus="1" data-ratio="0.7574074074074074" data-src="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxQpJXzbBGljuPsptbV4I1Y3CScn5pmia6gl5n1eIqyNNIwXYLYNXRQqd8lH8iclt0oCiaiawGrQg30SPg/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=0" data-type="other" data-w="1080" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e0bcff20-b6a1-4b42-8845-21144178ec64/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-font-family="微软雅黑"&gt;一年一度的&amp;ldquo;科技春晚&amp;rdquo;CES2026于上周落下帷幕，从今年的主题&amp;ldquo;定义AI的物理边界（Physical AI）&amp;rdquo;，可以看出全球科技新趋势正在推动AI从虚拟走向现实应用，通过多元化的消费电子、机器人、智能汽车等实体形态让生活智能化变得具象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;瑞芯微作为国内AIoT芯片领域的领军企业，正在这一科技浪潮中扮演着重要角色。全球首颗3D架构协处理器RK182X系列芯片的技术突破，不仅为全球&amp;ldquo;Physical AI&amp;rdquo;的发展提供强大的硬件和算力支撑，更是推进千行百业用AI重做一遍的AIoT2.0时代的落地进程。同时，瑞芯微将举办AI软件生态大会，&lt;span data-pm-slice="0 0 []"&gt;依托在AIoT千行百业、超过5000家全球客户的广大生态，&lt;span data-pm-slice="0 0 []"&gt;搭建起AI软件与市场的桥梁。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;瑞芯微RK182X：AIoT2.0的算力引擎&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在这一轮产业变革中，端侧AI能力将成为关键。&lt;/span&gt;驱动硬件设备从&amp;ldquo;被动执行&amp;rdquo;向&amp;ldquo;主动服务&amp;rdquo;跃迁，瑞芯微RK182X提供关键的&lt;/span&gt;&lt;strong&gt;主动感知与综合决策能力&lt;/strong&gt;。其在视觉语言模型和大语言模型上的卓越性能，构成了新一代&amp;ldquo;环境智能体&amp;rdquo;的双脑核心，使设备能主动预见需求、理解复杂场景并执行综合任务，真正实现&lt;strong&gt;从&amp;ldquo;功能机&amp;rdquo;到&amp;ldquo;智能体&amp;rdquo;的本质进化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;基于实测数据显示，RK182X运行Qwen2.5-3B模型输出速度突破百Token，是市场对标产品的3倍；同时&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;在多模态视觉语言模型任务上，瑞芯微已率先支持Qwen3-VL-2B/4B模型，实测数据业内领先。RK182X运行Qwen3-VL-2B模型输出速度达136.32TPS，运行Qwen3-VL-4B模型输出速度近百Token&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxRXhSj56Jbyw4twZFicb0CgQx4dich9SxQVBiaupzWrZRhU3icx4PeG1cEYduQficOvpRTmPOIma9iaoQFQ/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=1" alt="图片" data-ratio="0.5777777777777777" data-s="300,640" data-type="other" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxRXhSj56Jbyw4twZFicb0CgQx4dich9SxQVBiaupzWrZRhU3icx4PeG1cEYduQficOvpRTmPOIma9iaoQFQ/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="578" data-cropsely2="349" data-imgfileid="503443581" data-aistatus="1" data-original-style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;vertical-align: bottom;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 676.984px !important;height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0e4303ad-5705-4a4d-9f8b-8f2ff02b631b/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;RK182X的技术突破主要体现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;从&amp;ldquo;看清&amp;rdquo;到&amp;ldquo;看懂&amp;rdquo;，处理复杂模型的&amp;ldquo;直觉&amp;rdquo;与&amp;ldquo;认知&amp;rdquo;。&lt;/strong&gt;&lt;/span&gt;新一代硬件需要充分理解用户指令并具备对&amp;ldquo;长尾场景&amp;rdquo;的认知能力。如传统的监控设备，能准确识别人、车、物等目标，&lt;strong&gt;RK182X的强大端侧AI算力，能够让新一代AI设备具备解读事件和行为的能力，实现同时分析四路视频实时预警功能，异常响应仅需 0.5 秒，每路均能输出视频理解后的场景和行为细节描述&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/9oOslerakonH91ROSsZL-A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/633ed16c-5edc-43b7-af35-3bba8bd17ee5/1768789738059.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;从&amp;ldquo;听清&amp;rdquo;到&amp;ldquo;听懂&amp;rdquo;，保障实时&amp;ldquo;交互&amp;rdquo;与隐私安全。&lt;/strong&gt;&lt;span data-font-family="微软雅黑"&gt;RK182X 直接颠覆了端侧 AI 音频的体验逻辑：在拾音端，它凭借强劲算力实现&lt;strong&gt;多人语音 AI 8 轨多音轨分离与精准声源定位&lt;/strong&gt;，彻底告别传统 &amp;ldquo;唤醒词&amp;rdquo;；不管环境多嘈杂，设备都能自主识别有效指令、抓准核心需求，再配合&lt;strong&gt;百 Token/s 级的本地处理速度，连续对话丝滑无卡顿&lt;/strong&gt;，不止 &amp;ldquo;听清&amp;rdquo; 用户的表达，更能 &amp;ldquo;听懂&amp;rdquo; 用户的需求甚至主动串联复杂任务；而这所有的处理都在设备本地完成，敏感数据无需联网，隐私安全直接拉满。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;输出端&lt;/strong&gt;&lt;span data-font-family="微软雅黑"&gt;，针对音乐播放，可通过深度学习模型将&lt;strong&gt;混合音频中的人声、吉他、贝斯、钢琴，鼓点等拆分为高保真，低串音的独立音轨&lt;/strong&gt;，可以根据需要重构声场，打造无与伦比的专属听觉体验。RK182X正是把端侧 AI 音频从 &amp;ldquo;能用&amp;rdquo; 推向 &amp;ldquo;好用、敢用&amp;rdquo; 的关键一步。&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;赋能场景：三大领域迎接硬件智能化浪潮&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;基于CES 2026展示的产品新趋势，RK182X将为三大核心领域提供技术驱动力，推动Physical AI快速落地。&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;消费电子领域&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;，展会上备受关注的智能眼镜、智能电视、智能镜柜等新一代智能硬件，&lt;strong&gt;将AI助手、实时翻译、视觉增强等功能融入其中&lt;/strong&gt;，需要强大的端侧AI能力来处理图像识别、语音理解和实时交互任务，RK182X正好满足这一需求，&lt;strong&gt;让消费电子产品从单一功能工具转向重塑交互，具备更强大的端侧多模态即时处理能力&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;机器人领域，&lt;strong&gt;RK182X为需要自主移动、环境交互的机器人提供核心算力&lt;/strong&gt;。CES上的能够武术表演的人形机器人、能爬楼梯的吸尘机器人、家务多功能机器人，正是这一趋势的缩影。&lt;strong&gt;未来的机器人不再仅仅是执行预设程序的机械装置，而是能够理解环境、适应变化并自主决策的智能伙伴。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;智能座舱领域，多家中国车企在CES 2026展示了最新的辅助驾驶技术以及功能更丰富的车载娱乐系统，端侧AI能力将成为关键支撑。&lt;strong&gt;凭借RK182X强大的本地AI处理能力，未来汽车能够在离线环境下仍做出安全决策，实现更自然的语音、手势等多模态交互。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;生态布局：瑞芯微携手软件伙伴实现场景落地价值变现&lt;/strong&gt;&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;在AIoT2.0时代，瑞芯微不仅提供硬件解决方案，更致力于构建完整的产业生态。瑞芯微将通过开放易用的工具链、深度合作的算法生态以及可快速复用的行业参考设计，构建&amp;ldquo;芯片+算法+行业方案&amp;rdquo;的全栈能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;瑞芯微首届AI软件生态大会，诚邀AI软件公司共聚福州，共同探讨端侧AI在机器人、机器视觉、智能座舱、自动驾驶、 工业应用、智能家居、AI电脑、AI手机、可穿戴设备等千行百业的落地路径与商业模式。共同搭建起AI软件与市场的桥梁，依托瑞芯微在AIoT千行百业、超过5000家全球客户的广大生态，实现AI软件算法的场景落地、价值变现。&amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/549lkW9auxRcrQiaG3hgqJcADfhGrskQibzUndjK1lTIw2Rgea7S1CpDxUQVehXgAgDooku0LPlUN9QxLQ5ze05A/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=2" alt="图片" data-ratio="2.1287037037037035" data-s="300,640" data-type="other" data-w="1080" type="block" data-imgfileid="503443562" data-aistatus="1" data-original-style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;vertical-align: bottom;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 676.992px !important;height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/677dee94-e5a9-43de-8cf4-9d3cd56846d8/640.png" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
