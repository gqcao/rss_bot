<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>刚刚，唐杰、杨强、杨植麟、林俊旸和刚回国的姚顺雨坐一起都聊了啥？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 23:27:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ee8a5b00-e8eb-4362-a1d3-d1eded846c24/1768058508308.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2026 年 AI 的进化，势必会超过我们的想象。&lt;/p&gt;&lt;p&gt;1 月 10 日下午，在由清华大学基础模型北京市重点实验室、智谱 AI 发起的 AGI-Next 前沿峰会上，汇聚了刚刚上市两天的智谱、领跑独角兽月之暗面、全球开源大模型顶流 Qwen 的创始人、CEO 和负责人。&lt;/p&gt;&lt;p&gt;智谱 AI 的唐杰、月之暗面的杨植麟、阿里云通义千问的林俊旸等正处于聚光灯下的中国大模型掌舵者，以及张钹院士、杨强等学界泰斗罕见地同台亮相。&lt;/p&gt;&lt;p&gt;刚刚履新腾讯 AI 首席科学家、曾以「思维树」（Tree of Thoughts）和《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650965529&amp;idx=1&amp;sn=eb553785af462d8fdba2793990754823&amp;scene=21#wechat_redirect" target="_blank"&gt;AI 下半场&lt;/a&gt;》闻名的姚顺雨，也在此迎来了回国后的对外首秀。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagIZwRXaw61XM86tGgFa3kox4yTCH5e3bSG4BgfHIQ3hlhI59UaFwibvA/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="341" data-imgfileid="503527676" data-ratio="0.4546296296296296" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagIZwRXaw61XM86tGgFa3kox4yTCH5e3bSG4BgfHIQ3hlhI59UaFwibvA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5c589d13-5933-48da-ae2c-084b72d7931f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;本周国内 AI 创业公司接连上市，DeepSeek 又刚刚曝出即将发布全新一代大模型，人工智能的热度还在持续升温，但另一方面，AI 技术似乎来到了一个临界点：一边是大规模预训练 (Pre-training)、强化学习对齐（Alignment/RLHF）等范式带来的爆发期即将结束，另一方面，新的提升范式似乎还未启动。&lt;/p&gt;&lt;p&gt;如果说 2025 年的大模型技术以一种近乎「暴力美学」的方式撕开了 AGI 大门的一角，那么 2026 年开年这场峰会，就像是一次冷静后的复盘与再出发。&lt;/p&gt;&lt;p&gt;无论是演讲时的独白，还是圆桌上的激辩，几位掌舵者目及的方向不约而同：从「聊天机器人」进化为「干活的智能体」；从单纯堆砌算力转向追求 AI「自我学习」的新探索；让 AI 从预测下一个词，变为真正理解并改变物理世界的智能生命体。&lt;/p&gt;&lt;p&gt;但与此同时，他们给出的解法却各不相同。&lt;/p&gt;&lt;p&gt;这场峰会传递出一个清晰的信号：单纯的参数竞赛已成过去，前沿公司和团队正在扎堆进入新航路。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;唐杰：让机器像人一样「思考」与「做梦」&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagDzNicIbnzr4IMhZJ1LOrBe2MVOFCNhsF0pY0sAmrGDKLiagVduQic4g3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527677" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/025979a6-a388-4f1d-949a-a267e19c03bd/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为学术界与产业界的双重代表，清华大学计算机系教授、智谱创立发起人兼首席科学家唐杰教授将大模型的进化比作人类认知的成长过程。他回顾了 AI 的发展历程，认为&lt;strong&gt;我们正在从「系统 1」（基于直觉的快思考）向「系统 2」（基于逻辑的慢思考）进化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;唐杰抛出了一个引人深思的观点：「Scaling 可能是一个最轻松的办法，是我们人类偷懒的办法。」他认为，单纯依靠堆砌数据和算力的已知 Scaling 路径虽然有效，但更本质的方法可能是找到新的知识压缩方式，探索未知的 Scaling 范式。&lt;/p&gt;&lt;p&gt;为此，他重点介绍了 &lt;strong&gt;RLVR&lt;/strong&gt;（Reinforcement Learning with Verifiable Rewards，可验证奖励的强化学习）。在数学、编程等「可验证」的场景下，模型可以通过自我探索突飞猛进。智谱 AI 最新的 GLM-4.7 正是这一思路的产物，它在 Coding 和 Agent 任务上展现了惊人的能力。但唐杰也坦承，未来的挑战在于如何将这种能力扩展到「半自动验证」甚至「不可验证」的广阔领域。&lt;/p&gt;&lt;p&gt;在移动端 Agent 方面，唐杰展示了 &lt;strong&gt;AutoGLM&lt;/strong&gt; 的野心。未来的 AI 不应该只是一个聊天框，而应该是一个渗透到设备底层的幽灵。他们采用了一种「API + GUI」的混合模式：对 AI 友好的环节走 API，对人类友好的环节则模拟人手点击 GUI（图形用户界面）。演示中，AutoGLM 可以在手机后台静默执行长达 40 步的复杂操作 &amp;mdash;&amp;mdash; 从查询攻略、打开地图、比价、到最终下单订票，一气呵成。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagYWic0sPPz0Jtyv0NYiayYIyZGWCcIHXeK3ARJoACo7JtzsAPUNLwIy9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527679" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/483a3847-dfd2-464d-ae8e-b6e70c57fb30/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;演讲中一大迷人的部分在于唐杰对「&lt;strong&gt;机器睡眠&lt;/strong&gt;」的构想。他认为人脑之所以聪明，是因为有睡眠机制，在无意识中整理记忆、进行自学习。未来的 AI 也应该具备类似的机制，通过「自反思」和「自学习」来消化数据，而不仅仅是被动地接受训练。他强调，如果没有这种机制，人类的长期记忆可能只是一堆噪音，无法转化为真正的知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagkXcf1DEZbicwIMkvp1B94UUrqialZxfIXvLgQy5pPibrJwFrSU1XjsbxA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527680" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/092f552f-337f-4512-a6c6-668787731901/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管中国开源模型在 2025 年席卷了各大榜单，前五名几乎被中国模型包揽，但唐杰依然保持着清醒。他提醒道，我们是在开源的游乐场里玩得很高兴，但与顶尖闭源模型的实际差距可能并没有想象中那么小。只有去探索那些未知的 Scaling 范式，才能真正缩小这一差距。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;杨植麟：智能是不可替代的 Token，我们在寻找最美的 Loss 曲线&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag3xQ4xkJGCjPh0jgrPiaT8kf1zmpB7BdGn3WJSrx8VG6sk5Wj0bHeFWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527681" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e1ae983b-c817-489b-bfbe-aa6a28e54613/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;一如既往，杨植麟的演讲充满了第一性原理的极客浪漫。这位 90 后创始人没有过多罗列商业数字，而是将大模型的发展回归到最本质的物理规律。他认为从 2019 年至今，&lt;strong&gt;所有大模型的第一性原理依然是 Scaling Law&lt;/strong&gt;，这本质上是一个「将能源转换为智能」的过程。如果拥有更好的芯片、更优的架构，就能以更少的能源置换出更高级的智能。&lt;/p&gt;&lt;p&gt;他特别提到了 Kaplan 早期的经典论文，对比了 Transformer 与 LSTM 在 Scaling Law 下的表现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagPhO551GHvs1XzS0DqtxHISBlEaPR6cDW52b5CuicPJrTLhGomUP9Flw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527682" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5f35752a-ae59-415c-b026-1ea21330702a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在短 Context（上下文）下，两者差异不大；但当 Context 拉长到 1000 甚至更长时，Transformer 的优势才显露无遗。这种「长程优势」，正是 Agent（智能体）时代的胜负手。因为很多 Agent 任务本质上是搜索问题，而更好的预训练模型能提供更强的先验，帮助我们在茫茫的搜索空间中快速剪枝。&lt;/p&gt;&lt;p&gt;为了追求极致的「Token Efficiency」（Token 效率），杨植麟展示了月之暗面在 2025 年的两大杀手锏。首先是&amp;nbsp;&lt;strong&gt;Muon 优化器&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagfwWPuqKuOhG4jRQPaUrkBNlM9pgBdiac9K5zDx1Yb8UehCtKbeBskAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527683" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c6ae9a3c-9a7e-425f-8ecd-ab70146ead74/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;相比于统治了业界十年的 Adam 优化器，这个全新的二阶优化器实现了「两倍的 Token 效率提升」。这意味着，达到同样的智能水平，它只需要一半的数据量。为了解决二阶优化器常见的训练不稳定问题，团队引入了创新的「QK Clip」机制，动态调整梯度。杨植麟指着屏幕上一张完全平稳下降、没有任何毛刺（spike）的 Loss 曲线图，动情地说道：「这张图是我 2025 年见过的最美的东西，它是一个完全平稳下降的 Loss 曲线。当你有一个优雅的方法，就可以得到一个优雅的结果。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagQnlvRUxg3fuCv3NsebGsxReibyhHpoG4LaQvMLK8IEVUc0ufTNWmTbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527684" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/4fe980f1-62bf-43b5-945f-3e106263d3a0/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;另一个突破则是&lt;strong&gt; Key-Value Cross Attention&lt;/strong&gt;。针对长上下文任务，这种新架构不仅克服了传统线性注意力在长距离任务上「掉点」的顽疾，甚至在超长 Context 下的表现超越了全注意力（Full Attention）机制，且速度提升了 6 到 10 倍。&lt;/p&gt;&lt;p&gt;在演讲的最后，杨植麟谈到了 AGI 的「品味」。&lt;/p&gt;&lt;p&gt;他认为&lt;strong&gt;做模型本质上是在创造一种世界观&lt;/strong&gt;。智能与电力不同，电力是同质化的，深圳的一度电和北京的一度电没有区别；但&lt;strong&gt;智能是非同质化的&lt;/strong&gt;，一位音乐家产生的智能与一位程序员产生的智能截然不同。他透露，基于这些理念打造的 &lt;strong&gt;Kimi K2&lt;/strong&gt; 模型，在极高难度的 HLE（Humanity&amp;#39;s Last Exam）基准测试中达到了 45% 的准确率，超越了 OpenAI 等美国前沿公司。&lt;/p&gt;&lt;p&gt;面对 AI 可能带来的风险，他引用了 Kimi 给他的回答：这不仅是工具，更是人类认知的延伸，我们不应因恐惧而停滞不前，放弃人类文明的上限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;林俊旸：通往通用智能体（General Agent）之路&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVag08mxhdExURgqJ8qSgMjjibyqndz1brWvr7p5Ijiab19t26ykyQeDRzDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527685" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0a7f71fd-2aa2-4fee-aa8f-23fa7c34c2d8/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;阿里云通义千问（Qwen）的林俊旸则带来了一股浓厚的产品主义气息。作为开源界的「卷王」，他直言「&lt;strong&gt;模型即产品&lt;/strong&gt;」，并分享了 Qwen 如何通过开源社区的反馈完成自我进化的故事。&lt;/p&gt;&lt;p&gt;针对 2026 年的主力模型 &lt;strong&gt;Qwen-3&lt;/strong&gt;，林俊旸透露团队正在全力打磨 &lt;strong&gt;Hybrid Architecture（混合架构）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种架构极有可能是将 Transformer 与 Mamba 或类似的线性注意力机制以 3:1 的比例混合，旨在解决无限长文本（Infinite Long Context）带来的显存和计算瓶颈。他特别自豪地提到了「不降质」的突破 &amp;mdash;&amp;mdash; 在增强视觉和语音能力的同时，模型的文本推理能力不再像过去那样出现倒退，真正实现了多模态与智力的同步提升。&lt;/p&gt;&lt;p&gt;「人有眼睛和耳朵才能更好地理解世界，模型也一样。」林俊旸展示了 Qwen 在 &lt;strong&gt;Omni（全能） 模型&lt;/strong&gt;上的进展。&lt;/p&gt;&lt;p&gt;他放出了两张对比图，一张是 8 月份生成的「AI 味」浓重的图片，另一张是 12 月份生成的「宿舍女生自拍」风格图片，后者逼真程度令人咋舌。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagiaj4zyaZTqnC2RIXcDLAj99bpD4lKxURlAje1ncwbKsOIhibcNb8BUtg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527687" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/fec7b670-e8f1-495d-aa1f-d011fce6aae4/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更重要的是，&lt;strong&gt;Qwen 正在尝试将「生成」与「理解」打通&lt;/strong&gt;。例如在解几何题时，如果模型卡住了，它可以自己画一条辅助线（生成），然后基于这张新图继续推理（理解）。这种「理解-生成一体化」被林俊旸视为通向 AGI 的重要台阶。&lt;/p&gt;&lt;p&gt;林俊旸还分享了一个关于开源社区「反哺」的有趣案例。用户曾反馈图片编辑功能中「手放下来位置歪了」的问题，这让团队意识到即使是微小的像素级偏移，在真实应用中也是不可接受的。这种算法与 Infra（基础设施）的联合优化，让 Qwen 在迭代速度上保持了惊人的优势。&lt;/p&gt;&lt;p&gt;对于 AI 的未来，林俊旸的愿景非常接地气：「如果你的想法不是帮助全人类，那不如不做大模型。」他希望未来的模型不仅仅是通过考试的学霸，更是一个能真正帮助人类的 Agent。他观察到旧金山已经进入了 Vibe Coding（氛围编程）时代，没人再手写代码，而国内尚未普及。他坚信，能够操作电脑、写代码、甚至在物理世界里端茶倒水的 &lt;strong&gt;Embodied AI（具身智能）才是 AI 走向现实世界的终极形态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;圆桌激辩：从硅谷的富人创新到 Agent 的终局&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说演讲环节是各位掌舵者对自家技术版图的宣示，那么随后的圆桌对话则是一场卸下防备的坦白局。&lt;/p&gt;&lt;p&gt;这场对话的阵容堪称豪华：学界泰斗杨强、刚刚履新腾讯 AI 首席科学家的姚顺雨（线上参加，这也是姚顺雨告别 OpenAI 加入腾讯后的首次公开露面）、通义千问负责人林俊旸，以及智谱 AI CEO 唐杰。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9Oe5EUkPqribGWQ747NWVagEZBiajb6OHFbDOBV5yXYUrL1ff8L4Odu8v87t5ia6jcx1ticqYpPHS6vQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527686" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/1ee9fd57-642f-4543-aa51-0652f778b18f/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在主持人的追问下，四位嘉宾围绕模型分化、下一代范式、Agent 的商业落地以及中美 AI 差距等敏感话题，展开了一场超过 70 分钟的思想交锋。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ToC 的温吞与 ToB 的激进：姚顺雨的首秀观察&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为横跨中美、经历过 OpenAI 核心研发团队的科学家，姚顺雨的视角显得尤为犀利。对于当前大模型在 ToC（面向消费者）和 ToB（面向企业）市场的表现，他给出了一个极其鲜明的判断：ToC 端的体验正在趋于平缓，而 ToB 端的生产力革命已经发生。&lt;/p&gt;&lt;p&gt;「大家都有一个感觉，今天用 ChatGPT 和去年用 ChatGPT，对大部分人大部分时候其实感受的变化已经没有那么强烈了。」姚顺雨直言不讳。对于普通用户来说，模型在抽象代数或范畴论上的能力提升是「无感」的，它更像是一个搜索引擎的加强版。但 ToB 领域则完全不同，尤其是 Coding 场景，「&lt;strong&gt;Coding 革命已经开始&lt;/strong&gt;，它正在重复整个计算机行业做事的方式 &amp;mdash;&amp;mdash; 不再写代码，而是用英语和电脑交流。」&lt;/p&gt;&lt;p&gt;他用一个生动的例子解释了为什么企业愿意为最强的模型支付溢价：如果一个员工年薪 20 万美元，每天处理 10 个任务。顶级模型（如 OpenAI o1）能做对 9 个，而差一点的模型只能做对 5 个。「问题在于你不知道错的那 5 个是哪 5 个。」在这种情况下，企业宁愿支付高昂的溢价来换取确定性。因此，姚顺雨预判：「在 ToB 市场上，强模型和弱模型的分化会变得越来越明显。」&lt;/p&gt;&lt;p&gt;对于这一观点，阿里云的林俊旸表示认同，他还从「基因」的角度解读一下。对于姚顺雨的「腾讯肯定还是 To C 基因更强的公司」的看法，他半开玩笑地说道：「顺雨到了腾讯，腾讯可能就变成了有顺雨基因的公司。」他认为，无论是 ToB 还是 ToC，最终服务的都是真实的人类，关键在于能否解决长尾问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一个范式：是「间谍」还是「核爆」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当话题转向 2026 年可能出现的技术范式转移时，&lt;strong&gt;自主学习（Self-learning）&lt;/strong&gt;成为了全场共识的关键词。但这个范式将以何种面貌出现？&lt;/p&gt;&lt;p&gt;姚顺雨提供了一个非常独特的视角。他认为自主学习可能不会像 AlphaGo 那样以「平地惊雷」的方式出现，而更像是一个「潜伏的间谍」。&lt;/p&gt;&lt;p&gt;「这个事情其实已经在发生了。」姚顺雨指出，ChatGPT 利用用户数据不断拟合聊天风格，Claude Code 编写了自己项目 95% 的代码，这些都是自主学习的雏形。他将未来的 AI 系统比作两部分：一部分是神经网络（大脑），另一部分是调用这个神经网络的代码库（身体）。当有一天，AI 开始自己编写那部分「调用自己的代码」时，质变就会发生。「这可能更像是一个间谍渗透的过程，而不是一次突发的突破。」&lt;/p&gt;&lt;p&gt;对此，智谱 AI 的唐杰则表现得更加审慎。他坦言自己对 2026 年出现巨大的范式革新持怀疑态度。他提出了&lt;strong&gt;「智能效率」（Intelligence Efficiency）&lt;/strong&gt;的概念，即投入多少资源能获得多少智能增量。目前的 Scaling 虽然有效，但本质上是「最笨的方法」。真正的范式革命，应该是找到一种能用极少投入换取巨大智能增量的新路径。&lt;/p&gt;&lt;p&gt;林俊旸则从安全角度表达了对「主动性 AI」的担忧。「我最担心的不是 AI 学了什么，而是它主动做了一些该做或是不该做的事。」他举例说，如果 AI 主动发现会场有个炸弹，这固然是好事；但如果它产生了其他不可控的主动意图，这将是巨大的安全隐患。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 的终局：从工具到「职场人」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于 2026 年被寄予厚望的 &lt;strong&gt;Agent（智能体）&lt;/strong&gt;，杨强教授提出了一个清晰的四阶段演进论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;目标和规划都由人定义；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;目标由人定义，规划由 AI 辅助；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 观察人的工作流程（Process Data），自动学习规划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;终极阶段：目标和规划都由大模型内生定义。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;目前的 Agent 大多处于第一、二阶段。姚顺雨认为，Agent 要真正产生经济价值，瓶颈往往不在模型本身，而在环境和教育。他在 Scale AI 实习的经历让他意识到，即使模型能力不再提升，仅靠将现有模型部署到各种企业环境中，就能产生巨大的经济效益。&lt;/p&gt;&lt;p&gt;「人和人的差距正在拉大，不是 AI 替代了人的工作，而是会使用工具的人在替代不会使用工具的人。」姚顺雨发出了这样的呼吁。他认为，当下中国最有意义的事情之一，就是教育公众如何更好地使用 AI 工具，填平这道认知鸿沟。&lt;/p&gt;&lt;p&gt;林俊旸则补充了长尾理论。他认为 Agent 的核心价值在于解决那些通用模型无法覆盖的、极其个性化的长尾需求。「如果我寻遍各处都找不到解决方案，但在那一刻，AI 帮我解决了，这就是 AI 最大的魅力。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中美差距的灵魂拷问：胜算如何&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;圆桌的高潮出现在最后一个话题：3 到 5 年后，全球最领先的 AI 公司是一家中国公司的概率有多大？&lt;/p&gt;&lt;p&gt;林俊旸认为比较困难，他给出的理由却发人深省。他将其比作美国的「富人创新」与中国的「穷人创新」。&lt;/p&gt;&lt;p&gt;硅谷拥有顶级的显卡储备，甚至在有些浪费地使用算力探索下一代范式；而中国团队往往是在资源受限的情况下，被逼出了极致的算法优化和工程落地能力。「穷则思变，创新往往也发生在资源受限的地方。」林俊旸认为，软硬结合（如 AI 与 MCU 芯片的结合）或许是中国突围的一个机会。&lt;/p&gt;&lt;p&gt;姚顺雨对此则更为乐观。他认为，硬件（如光刻机）的瓶颈是客观且可解决的，真正的差距在于主观的冒险精神和研究文化。&lt;/p&gt;&lt;p&gt;「在中国，大家还是更喜欢做安全的事情。如果这个事情已经被证明可以做出来，我们几个月就能复现并做到极致。但如果让你去探索一个未知的领域，比如长期记忆，大家就会犹豫。」姚顺雨犀利地指出了中国研究界的痛点：&lt;strong&gt;过分关注榜单和数字，而忽视了什么是正确的事情。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;他回忆起在 OpenAI 的经历，那里的人更在乎「能不能创造出新的东西」，而不是「能不能在榜单上高出一分」。他呼吁中国的研究者走出榜单的束缚，「DeepSeek 做得就很好，他们没有那么关注榜单，而是关注用户体验和什么是正确的技术路径。」&lt;/p&gt;&lt;p&gt;唐杰教授则以「最不幸的一代」自嘲：上有老一辈学者还在工作，下有 00 后天才少年横空出世，夹在中间的 80 后、90 后研究者好像被「无缝跳过了」，世界已经交给下一代了。但他同时指出，中国 00 后一代展现出的&lt;strong&gt;冒险精神&lt;/strong&gt;令人欣慰。&lt;/p&gt;&lt;p&gt;「如果在这个时间点，有一群聪明人真的愿意做特别冒险的事，而且国家能提供更好的容错环境，哪怕概率只有 20%，我们也有机会抓住那个三五年一遇的窗口期。」唐杰最后总结道。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;尾声：未完成的答卷&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这场圆桌对话并没有给出一个确定的答案，却留下了一份沉甸甸的思考。&lt;/p&gt;&lt;p&gt;从姚顺雨对「榜单文化」的批判，到林俊旸对「富人创新」的羡慕与不甘，再到杨强和唐杰对学术界使命的再定义，我们看到的是中国 AI 力量在追赶过程中的焦虑、清醒与韧性。&lt;/p&gt;&lt;p&gt;正如主持人李广密所言：「过去我们是在追赶，是在补课。但当科技能力追上来之后，2026 年，我们期待看到中国不仅有更强的火箭，更要有自己的 Payload（有效载荷）和 Product（产品）。」&lt;/p&gt;&lt;p&gt;在 Scaling Law 依然有效的今天，中国 AI 正在从刷榜走向落地，从复现走向探索。虽然胜算或许充满了不确定性，但正如那条被杨植麟称赞的「最美 Loss 曲线」一样，只要方向正确，下降就是必然的趋势。&lt;/p&gt;&lt;p&gt;同样重要的是，通过把自己最先进的大模型开源出来，国内科技公司正在从全球 AI 技术的跟随者转变为推动者。也同样是随着这个过程，在「六小虎」之后，我们已经可以逐渐看出国内 AI「开源四巨头」正脱颖而出。&lt;/p&gt;&lt;p&gt;除了 DeepSeek 之外，包括智谱、月之暗面和 Qwen，他们今天有三个都在台上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从杨植麟眼中那条「最美的 Loss 曲线」，到唐杰构想中「会做梦的机器」，林俊旸致力打造的「全能智能体」，再到姚顺雨所预言的如「间谍」般潜行的自主学习新范式，这场 AGI-Next 峰会为 2026 年的 AI 战事定下了基调。&lt;/p&gt;&lt;p&gt;过去几年，我们忙于教 AI「读书」，试图将人类文明的知识灌输给它；而接下来的篇章，则是教它「做事」，让它在物理世界的真实反馈中像人一样思考、规划与行动。参数的军备竞赛或许已经降温，但关于智能本质的探索才刚刚开始。&lt;/p&gt;&lt;p&gt;正如几位演讲者在圆桌上的共识：智能的上限远未到达，也是那些愿意「走出榜单、寻找正确之事」的探索者们（像姚顺雨所呼吁的那样）正在努力的方向。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CES 2026「最烂」产品大赏</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:24:07 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/739a206e-e227-42fd-85e5-44a0a94709df/1768051302246.png" style="width: 700%;" class="fr-fic fr-dib"&gt;说实话，现在有些创新我是真看不懂。&lt;/p&gt;&lt;p&gt;在 CES 2026 展会中，各大厂商卖力吆喝着「AI 改变世界」的同时，一群较真的消费者权益倡导者却颁出了一份另类榜单：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最烂产品奖。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;先来说说评审团颁发的&lt;strong&gt;「全场最烂产品奖」&lt;/strong&gt;&amp;mdash;&amp;mdash; 三星的 Bespoke AI Family Hub 冰箱。&lt;/p&gt;&lt;p&gt;有一说一，它能获此「殊荣」，好像也不冤得慌。&lt;/p&gt;&lt;p&gt;这台冰箱的智能卖点是语音控制开门，听起来很赛博朋克，但在 CES 现场，如果周围环境噪声过大，它就直接装聋，无法识别用户的语音指令。&lt;/p&gt;&lt;p&gt;你在那对着冰箱狂吼「Open the door！」它岿然不动。&lt;/p&gt;&lt;p&gt;三星回应称，展会现场与消费者家庭环境很不一样，Bespoke AI 体验旨在简化家居决策，它让生活更便利、更愉快。&lt;/p&gt;&lt;p&gt;俺这个乡巴佬就纳闷了，开冰箱门是多费劲的事吗？为啥要搞这么复杂？&lt;/p&gt;&lt;p&gt;当然，这台冰箱还有其他功能，比如使用计算机视觉追踪食物库存，库存不足，它会推荐替代品。&lt;/p&gt;&lt;p&gt;嗯。。。这也大可不必。&lt;/p&gt;&lt;p&gt;冰箱真的是瞎创新的「重灾区」，有给冰箱装上屏幕，让人仰着脖子在上面刷抖音的：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgQ6lkK84ahCicwjc769CmopeLFWmVsBEdQdvy34icrUFfW3ib4VON11ib4A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="1.778" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="889" data-imgfileid="503527604" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e55dc746-ebbb-4619-bf52-7e925fa417ac/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;有给冰箱连 wifi 的，脱口秀演员都看不下去了，「一个冰箱为什么要连 wifi？是怕苹果在里面信号不好吗？」&lt;a href="https://mp.weixin.qq.com/s/OjhjM7gQ3YghWmWKVShnrQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b31c3040-a6f1-4d9b-aac8-3a7ffa317dd8/1768051329190.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;有带语音交互功能的，但就是死活听不懂不标准的普通话：&lt;a href="https://mp.weixin.qq.com/s/OjhjM7gQ3YghWmWKVShnrQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/33e03a5a-2621-4651-84e9-ca7131fc5329/1768051338713.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;一个原本只需要给食物保鲜的电器，真的需要这么多智能功能吗？当基本功能的可靠性因为堆砌 AI 特性而受到影响时，这种创新的意义何在？哦，价格贵了。&lt;/p&gt;&lt;p&gt;你以为只有冰箱乱搞创新？其他家电也净整些没用的。&lt;/p&gt;&lt;p&gt;比如这款 Wan AIChef 的微波炉。它运行在看起来很像安卓的系统上，配备食谱推荐、烹饪指导，还有内置摄像头让你实时监控加热进度。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHxOnKibfEdcJYFHbX0AS9AHnlg0SMVqOA6B8Uz2eWXGkE6qyl5uicoLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1080" data-height="720" data-backw="578" data-backh="385" data-imgfileid="503527583" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e87c5610-c5c1-41f8-b33c-3fb9723cc3f0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这看起来挺智能的，但其实只是个微波炉。它啥烹饪也帮不上，唯一能做的就是把食物加热到恰到好处的温度，按官方说法是正负 3 摄氏度的精准控制。&lt;/p&gt;&lt;p&gt;它还提供餐食计划、食物追踪和卡路里计算功能，但前提是得保证自己的所有餐食都用这台 AI 微波炉来加热。&lt;/p&gt;&lt;p&gt;如果说智能冰箱、微波炉只是过度设计，那么亚马逊 Ring 门铃摄像头的新功能则触碰到了更敏感的隐私红线。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgVF4kDtxsQUtvgZRLLSjEfLS69QKTMeiaMsWV9PlkUWM6oChBiaYfI69A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1440" data-height="960" data-backw="578" data-backh="385" data-imgfileid="503527585" data-aistatus="1" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/e6d8b94a-c9aa-4478-8d60-89f56a54cc5b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这款产品斩获了&lt;strong&gt;「隐私类最烂产品奖」&lt;/strong&gt;，理由是「加倍入侵隐私，并支持了『更多监控总是更安全』的错误观念」。&lt;/p&gt;&lt;p&gt;评审团列举了 Ring 的一系列「罪状」，比如新增的「AI 异常事件警报」功能号称能检测意外访客或事件，但这背后包含了面部识别；Ring 还推出了一个应用商店，允许第三方开发者为门铃开发更多应用，这意味着，你家门口的摄像头可能会被用于你完全不知情的用途。&lt;/p&gt;&lt;p&gt;AI 时代，人们对隐私问题越发敏感。&lt;/p&gt;&lt;p&gt;Merach 的联网跑步机就因为隐私政策获得了&lt;strong&gt;「安全类最烂产品奖」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这款跑步机号称拥有行业首个由大语言模型驱动的 AI 教练，不仅能与用户对话，还能根据心率变化主动调整速度和坡度。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgOWfr7vOPrJzmW4vFvDlP3KicBBbVXXwmOja85FXwMhQ0OW7lEMExriaw/640?wx_fmt=jpeg#imgIndex=4" data-ratio="0.9088541666666666" data-type="png" data-w="384" data-width="388" data-height="400" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHUf9zZiag3zDPFOysZPhpVA3OuYKImyEibibxfnYjJdrVFVQaW5YEKJ6Q/0?wx_fmt=png&amp;from=appmsg" data-cropx2="385" data-cropy1="13" data-cropy2="362" data-imgfileid="503527586" data-aistatus="1" data-original-style="width:385px;height:349px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f457eb01-6fe6-4e0d-9626-a8421aa860f9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;听起来很不错，但它的隐私政策中写着「我们无法保证您个人信息的安全」，这意味着你的心率数据、运动习惯、身体状况等生物特征信息都在被收集，却得不到安全保障。&lt;/p&gt;&lt;p&gt;还有那款名为 Ami 的 AI 伴侣，也因为隐私问题赢得&lt;strong&gt;「人民选择最烂产品奖」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这款产品以「永远在线的 3D 灵魂伴侣」为卖点，在弧形屏幕上呈现一个女性虚拟形象，专为远程办公者设计，承诺提供私密和共情的互动。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgMd15OTVpN8q1SZPpuYvEFurlufVq2IjrktoScIMTLhFpSPWtAfqibjQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5425" data-type="png" data-w="400" data-width="400" data-height="217" data-imgfileid="503527588" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/cb52c04c-407f-461c-b2a9-daa4fb9f2cf0/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;它会追踪你的眼球运动、分析你的语音语调，试图理解你的情绪状态。但评审团直言不讳地批评「竟敢暗示一台桌面 AI 视频监控设备可以成为任何人的灵魂伴侣」。&lt;/p&gt;&lt;p&gt;虽然这款产品配备了物理摄像头遮挡装置，但「永远在线」的营销话术让人感到不安。&lt;/p&gt;&lt;p&gt;这种陪伴类 AI 产品不在少数，CES2026 中还有个 AI 马斯克（迷你版）吸引不少人关注。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgID6FxvV6Ceu07xZMoaTZZkJDarDwTsvibzmNKKVzAk6z9Vmia9J4y6lw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-type="jpeg" data-w="1080" data-width="2200" data-height="1467" data-backw="578" data-backh="385" data-imgfileid="503527590" data-aistatus="1" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8626f01c-c9a1-480a-a718-8c983da2392c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;迷你马斯克只是 Luka AI 魔方提供的众多虚拟形象之一，还有宫崎骏、《我的世界》里的史蒂夫、哈利・波特等等。&lt;/p&gt;&lt;p&gt;孩子们可以跟这些 AI 聊天，倾诉一天的经历，寻求建议。AI 方块还带摄像头，孩子可以把画面分享给 AI，让虚拟形象知道他们在哪儿、在干什么。Luka 宣称这既是娱乐工具也是教育工具，包含各种教育活动和多语言选项。&lt;/p&gt;&lt;p&gt;不过有人质疑：真的该信任任何一家公司，让他们的 LLM 去接触你的孩子吗？更何况最近 Grok 被指责帮人生成不当图像。&lt;/p&gt;&lt;p&gt;活了三十年，第一次见会唱歌的棒棒糖。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgNmBwUqLezjHJDnFMy5Fic0DicRZVYw3Vw0sDe1Z6CnsUqN1pcwaibxiaGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1248" data-height="702" data-backw="578" data-backh="325" data-imgfileid="503527592" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/284c1fb5-fac4-4cbb-ae65-561f8ca37d52/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Lollipop Star 这款会唱歌的棒棒糖使用骨传导技术，让你在咀嚼时通过后槽牙「听到」音乐。&lt;/p&gt;&lt;p&gt;官方称，他们已与全球流行音乐偶像合作，每个售价 8.99 美元的棒棒糖都有自己独特的节奏、口味。比如桃子味的棒棒糖会播放 Ice Spice 的音乐，蓝莓味的会播放 Akon 的歌。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgJWkgk9yYqia1gZQibKPtXhVpdJicGZr1Zsyc8vibp3iahXpLR5p5dyQGpLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.587037037037037" data-type="png" data-w="1080" data-width="1999" data-height="1173" data-backw="578" data-backh="339" data-imgfileid="503527594" data-aistatus="1" data-original-style="width:100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/09b531b3-a5f9-47c2-9467-4bc4a0422b8e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;创意确实新奇，但问题在于吃完糖后，这根内置电子元件的棒子既不能充电也不能重复使用，只能扔掉。&lt;/p&gt;&lt;p&gt;在全球电子垃圾问题日益严峻的今天，为了几分钟的新奇体验而制造一个无法回收的电子产品，代价未免有点大，正因如此，这款棒棒糖拿下&lt;strong&gt;「环境类最烂产品奖」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;德国科技公司博世一口气拿下了两个「最烂产品奖」。&lt;/p&gt;&lt;p&gt;一个是因为给浓缩咖啡机加入订阅服务和亚马逊 Alexa 语音助手，另一个是因为在电动自行车应用程序上加入防盗和电池锁定功能，让正常维修变得困难重重。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgLO4FuyglXuF8RmnIrnOvpRvkha8aCD8k2T6pRUmtes75NSicpEXpuPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1440" data-height="960" data-backw="578" data-backh="385" data-imgfileid="503527596" data-aistatus="1" data-original-style="width:100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/5c6f9d36-6d1a-4b91-a309-744be0f25d10/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不过博世称这些功能都是可选的，而就浓缩咖啡机而言，这些功能已经很受欢迎。&lt;/p&gt;&lt;p&gt;除此之外，这届 CES 展会上还有各式各样的奇葩发明。&lt;/p&gt;&lt;p&gt;比如这个 Glyde 智能理发器，号称全球首款真正的智能理发器。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgmibILE30UHuWq6wQAHRZWXibgklicDwiccsTP8mz6yHyn9qaS6skBficxicA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.6666666666666666" data-type="jpeg" data-w="1080" data-width="2200" data-height="1467" data-backw="578" data-backh="385" data-imgfileid="503527597" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5008d203-a20e-42f7-b4da-c89c456d2af6/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其核心技术在智能刀片系统，内置传感器会实时追踪你的移动速度、倾斜角度和方向，并自动调整刀片深度，一次避免剪得坑坑洼洼的。&lt;/p&gt;&lt;p&gt;操作仅需三步，打开 App 选发型，App 里有各种流行发型，都是针对不同头型和发质测试过的，可以挑现成的，也能自己定制；戴上渐变带，标记好起始位置；然后开机，从下往上滑就行了。&lt;a href="https://mp.weixin.qq.com/s/OjhjM7gQ3YghWmWKVShnrQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/81acfdad-6eeb-4321-97e4-e47f6b6e8929/1768051390419.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;官方还表示，他们正在开发 AI 语音控制功能，以后连发型都不用自己选了，直接跟理发器说话，它会根据脸型、发质啥的，用 AI 推荐发型。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/tech/858315/most-dubious-ai-tech-ces-2026&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://apnews.com/article/ces-worst-show-ai-0ce7fbc5aff68e8ff6d7b8e6fb7b007d&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/technology/comments/1q7ofw9/worst_in_show_ces_products_include_ai/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>前谷歌研究员发文：算力崇拜时代该结束了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:19:42 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6b8fb529-cfef-4bc2-a6a9-dbf2b80e654c/1768051060339.png" style="width: 700%;" class="fr-fic fr-dib"&gt;过去十年，我们几乎把 AI 领域的创新简化成一条公式：更多参数、更多数据、更多算力。可未来的突破，是否仍然只能从训练算力中产生，其实并不清楚。&lt;/p&gt;&lt;p&gt;这个问题之所以重要，是因为「算力驱动进步」的信念，已经深刻改变了整个领域的研究文化。学术界因缺乏算力逐渐被边缘化，研究参与在地域上高度集中；巨额资本投入也让原本开放的发表传统变得愈发封闭。&lt;/p&gt;&lt;p&gt;在过去的一段时间，前谷歌大脑研究员、Cohere 前 AI 研究负责人 Sara Hooker 一直在呼吁大家重视这个问题。最近，她还把自己之前的演讲内容写成了文章。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527416" data-ratio="1.1578947368421053" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gtzlOub5wa2stBwtBNia4viaKnXI6ZWicj8Dxj83FkkWnhgqO8cn2DHAVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1064" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5798ef54-27fa-4511-bdeb-fd6295380b82/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;文章标题：On the slow death of scaling.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;文章链接：https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5877662&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;文章中提到，对于深度神经网络而言，持续扩展训练计算资源效率极低。我们花费大量资源来学习那些低频特征的长尾部分，而所有迹象都表明，我们正处于收益递减的时期。在模型规模不再逐年翻倍的世界里，模型如何从环境中学习并有效地从新知识中适应，就显得尤为重要。在文章中，她探讨了一些未来有价值的方向。&lt;/p&gt;&lt;p&gt;以下是文章内容节选。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一个不容忽视的趋势：小模型的崛起&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;声称 scaling 正在走向终结，这在许多领域都存在争议。因为过去十年的所有证据都表明，扩展计算能力能够解锁更大的模型规模或数据集。增加计算能力也恰好符合行业季度规划的节奏，相比提出一种替代的优化技术，提议训练更大的模型风险更小。&lt;/p&gt;&lt;p&gt;但仅仅依靠计算资源会忽略规模与性能之间的关系正在发生的一个关键转变。更大的模型并不总能带来更好的性能。最近几年出现了很多大模型被规模小得多的小模型超越的案例。如下图 3b 所示，随着时间推移，这类小模型数量激增。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527418" data-ratio="0.6296296296296297" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gdxsV9Nmk4GQfib912Oyia8F1ZbdftSnEBQQKiayQRyoJwYrmHibPIiaPYyw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/34e5b9dc-f052-4bc6-a31c-ec90cef7e2b2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;要理解为什么会出现这种情况，我们必须弄清楚在过去十年中，哪些关键变量一直在推动性能的提升。在计算资源回报递减的时代，优化和架构上的突破决定了单位计算资源的回报率。而正是这种回报率，对发展速度以及额外计算资源所带来的风险水平最为关键。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527419" data-ratio="1.1398148148148148" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gjCAHkhMJcKic16sxbmt6YuIGysN4WleCmWJqZZVqPfWTxvI7hDt5RVw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3eee99c5-49e6-4200-8c88-08091cb33dbc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;哪些因素会影响算力回报率？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在复杂系统中，孤立地操控一个变量并预见所有影响是极具挑战性的，人们对计算量的推崇也是如此。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增大模型规模正面临收益递减&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去十年，模型参数量从早期 Inception 的 2300 万暴增至 Qwen3-235B 的 2350 亿。尽管更大模型确实带来了性能提升，但额外的参数数量与泛化能力之间的关系仍不清楚。&lt;/p&gt;&lt;p&gt;令人困惑的是：训练结束后，我们可以删除大部分权重而几乎不损失性能；但若一开始就不启用这些权重，则无法达到相同效果。研究发现，仅用一小部分权重就能预测网络中 95% 的权重，说明存在大量冗余。这可能反映的是深度学习技术本身的低效 &amp;mdash;&amp;mdash; 如果有更好的学习方法，我们可能根本不需要这么大的网络。&lt;/p&gt;&lt;p&gt;增大模型规模是学习长尾分布的一种成本极高的方式。深度神经网络的学习效率极低。它们能快速学会常见特征，却需要大量算力和时间来学习罕见特征。这是因为训练基于平均误差最小化，所有样本被同等对待，导致低频特征的信号在批量更新中被稀释。而现实世界中，大多数属性恰恰是低频的 &amp;mdash;&amp;mdash; 人类智能的独特之处正是能高效处理这类长尾数据。深度网络在这方面最为吃力，训练的大部分算力都被消耗在以极高代价记忆长尾数据上，如同「搭梯子登月」般低效。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据质量降低了对计算资源的依赖&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在质量更高的数据上训练的模型不需要那么多计算资源。大量研究表明，改进训练语料库的一些工作，包括去重、数据修剪或数据优先级排序，可以弥补模型规模的不足。这表明，可学习参数的数量并非提升性能的绝对限制因素；对更高数据质量的投入能够减少对更多（计算资源等）的需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新的算法技术弥补了计算量的不足&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去几年的进展，既得益于算法的改进，也得益于计算能力的提升。这包括通过指令微调扩展预训练，以教会模型遵循指令；利用更大、性能更强的「教师」模型生成的合成数据进行模型蒸馏，来训练能力强、规模小的「学生」模型；思维链推理；增加上下文长度；检索增强生成；以及通过偏好训练使模型与人类反馈保持一致等。&lt;/p&gt;&lt;p&gt;所有这些技术都弥补了对大量权重或昂贵的长时间训练的需求。在所有条件相同的情况下，与未使用这些优化技巧且在相同计算量下训练的模型相比，这些技术已被证明能显著提升模型性能。我们正用相同数量的资源做着多得多的事情。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;架构在决定可扩展性方面起着重要作用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;架构在确定单位计算量下的整体性能回报率方面起着巨大作用。它在决定进步上限方面也至关重要。新架构设计的引入可以从根本上改变计算量与性能之间的关系，并使任何现有的 scaling law 变得无关紧要。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Scaling Law 的局限性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;巴菲特曾说过一句话：「别问理发师你需不需要理发。」同样的道理，也别去问计算机科学家或经济学家能不能预测未来。人们往往会被「我能预测」的诱惑牵着走，而忽视了对预测边界应有的谦逊。关于模型规模与性能关系的 scaling law 正是这种自信膨胀的体现。它试图用算力规模去推断预训练损失的变化，或预测下游能力如何随规模出现，但现实远比公式复杂。&lt;/p&gt;&lt;p&gt;Scaling Law 之所以流行，很大程度上源于人们过度相信算力是推动进步的核心变量。它逐渐成了一个万能说法，被用来为巨额投资甚至政策决策背书。其吸引力也不难理解，如果能力真的能随算力精确预测，资本配置就会显得异常清晰。但问题在于，我们几乎从未准确预测过性能究竟会提升多少，这让「算力投入的回报率」在科学上难以站得住脚。&lt;/p&gt;&lt;p&gt;更关键的是，Scaling Law 真正被反复验证的，只是对预训练测试损失的预测，也就是模型补全文本的能力。一旦换成真实的下游任务表现，结果往往混乱且不一致。所谓的「涌现能力」，常被用来解释这种落差，看似是能力突然出现，实际上等于承认 Scaling Law 并不能告诉我们未来会发生什么。即便只预测测试损失，在数据分布假设略有变化时，结果的可复现性也会出现问题。越来越多研究发现，许多能力的提升曲线并不平滑，甚至根本不符合幂律。&lt;/p&gt;&lt;p&gt;对于需要向未来外推的复杂系统来说，小误差会不断累积，而样本数量又极其有限。每一个数据点都是一整个模型，高昂的计算成本意味着很多 scaling 结论建立在不到百个样本之上，统计支撑本身就很脆弱。因此，不同领域中 Scaling Law 的可靠性差异巨大。比如代码生成在极大算力跨度内表现出相对稳定的幂律关系，而其他能力则显得更加不可预测。&lt;/p&gt;&lt;p&gt;在架构、优化方法和数据质量保持不变的短期受控环境下，Scaling Law 对规划训练规模仍有一定价值。但一旦拉长时间尺度，它们就很难经得起检验。Scaling Law 的频繁失效提醒我们，单纯堆算力并不是一条直线式的进步路径。那些过度依赖 Scaling Law 的前沿 AI 公司，可能正在低估其他创新方向的价值，而真正的突破，往往正藏在这些被忽视的地方。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;未来前进方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在计算机科学中，我们长期把算力当成银弹。&lt;/p&gt;&lt;p&gt;但现实正在发生分化。一方面，至少在短期内，人们仍会继续把模型做得更大，试图从逐渐老化的架构中榨取最后的性能；另一方面，算力与性能之间的关系却越来越紧绷，也越来越难以预测。单纯依赖算力，正在变成一条不稳定的道路。&lt;/p&gt;&lt;p&gt;真正有可能引领下一轮创新的前沿实验室，不会把赌注只压在算力上。更有价值的进展，来自对优化空间的根本性重塑，也就是范式层面的转变。与以往不同的是，计算机科学家如今需要同时优化的「工具箱」大幅扩展，这不仅会决定他们把时间花在哪里，也会影响「发现」本身是如何发生的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新的优化空间&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如今，越来越多的计算并不是花在训练阶段，而是花在训练之外、推理之中。过去，模型性能的提升几乎等同于更多数据、更长训练或更大参数规模，而现在，一个明显的转向正在发生：通过在推理时投入更多算力，用搜索、工具调用、多智能体协作或自适应计算来提升表现，而不必改动模型本身。更重要的是，这些方法大多不依赖梯度更新，彻底偏离了过去三十年以训练为中心的进步路径。已有研究表明，仅靠推理阶段的计算放大，就可能带来数倍甚至一个数量级的性能提升，而所需算力远低于重新预训练的成本。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527420" data-ratio="0.5787037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gGNCkGtQbicz5ibqQvSU1cyon3Iibe752icO2c3nyAsKVj5kcTC6Y3KcRnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/729d932a-8bbc-4712-9641-6bf531d33b22/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;与此同时，数据也不再是不可触碰的「静态背景」。长期以来，高质量标注数据稀缺且昂贵，训练集往往被视为对世界的固定快照，从 MNIST、ImageNet 到 SQuAD，AI 的进步建立在这些冻结的数据之上。但现实使用中，模型最擅长的始终是训练分布，而推理时真正重要的场景却常常数据不足，训练与使用之间由此产生结构性错位。随着合成数据成本大幅下降，数据空间本身开始变得可塑，我们可以有意识地生成、引导和放大那些原本稀少却关键的分布区域，这也动摇了机器学习中关于 IID 样本的基础假设。&lt;/p&gt;&lt;p&gt;最后，智能系统的核心正在从「更强的模型」转向「更会与世界互动的系统」。算法本身不再是全部，交互方式、界面设计以及多组件系统的协同，正在成为决定智能上限的重要因素。曾经属于 UX 或人机交互的小众问题，正在走到计算机科学研究的正中央。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;只要还用 Transformer，scaling 就会变得没有意义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在以 Transformer 为核心架构的前提下，只要我们仍局限于 Transformer 这种架构，继续扩大计算规模就没有意义。现有架构已经明显出现边际收益递减，再投入算力也难以换来成比例的进步。深度神经网络主导了过去十年的发展，但越来越多迹象表明，下一次真正的跃迁需要一种全新的架构。随着模型开始持续与世界互动，如何避免灾难性遗忘成为关键挑战，而依赖全局参数更新的深度网络，在持续学习和知识分化上先天受限，很难像大脑那样形成相对独立、可专门化的知识区域。&lt;/p&gt;&lt;p&gt;与此同时，训练算力「scaling 退潮」并不等于 AI 的环境影响会随之减轻。需要区分的是，算力与性能关系的变化，并不等同于整个 AI 系统的计算开销下降。即便模型本身变得更小、更高效，AI 也会被部署到越来越多的场景中。真正的能耗大头，往往不在训练，而在模型上线后的生产化与大规模服务阶段。当数十亿用户同时使用 AI 时，即使单个模型更轻量，总体能耗仍可能持续上升，这依然是一个不容忽视的现实问题。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>因为AI编程，Tailwind CSS差点死了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:16:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dd3916f2-1c34-47c7-af88-4490095c6182/1768050684566.png" style="width: 700%;" class="fr-fic fr-dib"&gt;在生成式 AI 狂飙突进的 2026 年，如果你让一个 AI 编程智能体来写网页应用，它很大概率会用到 &lt;strong&gt;Tailwind CSS&lt;/strong&gt;。要知道，其如今的周下载量已经超过了惊人的&lt;strong&gt; 2600 万&lt;/strong&gt;次。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527523" data-ratio="0.5962962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgKibPoLibZTCYziceiabRKKxHrGMjVl3Xc9o9jZBXoJNVaw55icKQaReiaDiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1a7e49dc-3621-4288-92f6-728198ec355f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;然而，这个备受 AI 智能体欢迎的 CSS 框架背后的团队日子却并不好过。&lt;/p&gt;&lt;p&gt;前两天，Tailwind CSS 创始人 Adam Wathan 在一条 GitHub 评论中揭示了一个辛酸的现实：Tailwind 已经裁掉了 &lt;strong&gt;75%&lt;/strong&gt; 的团队成员。这并非因为产品不再流行，恰恰相反，Tailwind 比以往任何时候都受欢迎。导致这一局面的核心原因在于，AI 带来的巨大流量与商业转化彻底脱钩：&lt;strong&gt;AI 在写代码，就没有人类会去访问文档，也就没人为他们的付费产品买单&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;整体来说：&lt;strong&gt;流量下降 40%，收入损失 80%&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgsPwnAYAwKGeoltsARregZzSG7MIrHy3dAxzrMXmXCrQuWE4jkwViaLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527525" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0f377517-5261-47f5-823a-f7533eeea974/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 注：本截图以及以下多张截图原本是英文，由机器翻译为中文&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一事件撕开了 AI 时代开源软件商业模式最隐秘也最痛楚的一角。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「我们没时间做不能维持生计的事」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;危机的爆发源于一个看似普通的 Pull Request。&lt;/p&gt;&lt;p&gt;2025 年 11 月，一位用户 quantizor 希望新增一个 llms.txt 接口，用于向大模型提供经过优化的项目文档内容，方便 LLM 更好地理解和使用该项目。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgsVabyrqK77qlS5iatIssa7j1wZcM0l0TpEEs9vDRS4cyfdX7DTgUODg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5203703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527524" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/78fa3e3b-c204-454f-baae-3d2387bd65a2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; https://github.com/tailwindlabs/tailwindcss.com/pull/2388&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;然而，该 Pull Request 并未被即时处理，而是被搁置了一个多月，便有用户发起了评论问询。&lt;/p&gt;&lt;p&gt;这时候，Adam Wathan 现身解答了疑惑，并表示 Tailwind 公司已经陷入了财务困境，而让 LLM 更容易阅读文档会让问题更加严重。Tailwind 的商业模式依赖于开发者访问官方文档，进而在页面上接触到他们的付费产品（如 UI 组件库 Tailwind UI）。然而，随着 Cursor 等 AI 编程工具的普及，开发者不再需要查阅文档，AI 可以直接生成代码。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgzuMXguNDIqWZ4t7IZaZM52VIK4thsx9ictou144rrEEW283dUAqXh5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.26296296296296295" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527527" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/de867928-dc59-45fa-bdbf-e07106f91b32/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Wathan 的评论引发了更多讨论，这也让他有机会进一步解释其公司面临的困难：他们&lt;strong&gt;刚刚在前一天裁掉了 75% 的工程团队&lt;/strong&gt;，而原因是「AI 对我们业务造成了极其残酷的冲击」。&lt;/p&gt;&lt;p&gt;Wathan 写道：「尽管 Tailwind 比以往任何时候都更受欢迎，但与 2023 年初相比，我们文档的访问量下降了大约&lt;strong&gt; 40%&lt;/strong&gt;。文档是人们了解我们商业产品的唯一途径，没有客户，我们就无法负担维护这个框架的成本。」更具体而言：「Tailwind 的增长速度比以往任何时候都快，规模也比以往任何时候都大，但我们的收入却下降了将近 &lt;strong&gt;80%&lt;/strong&gt;。」&lt;/p&gt;&lt;p&gt;他还在这条评论中表达了担忧：「这个项目在没有人再受雇来维护它的情况下，最终只会变成一个无人维护、被遗弃的软件。」&lt;/p&gt;&lt;p&gt;最终，为了生存，他拒绝了那个让 AI 更方便「白嫖」知识的请求，关闭了这个 Pull Request。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开源项目的商业模式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这里，我们看到了 AI 编程智能体大爆发时代的另一面。&lt;/p&gt;&lt;p&gt;这一事件自然引发了网友的高度关注和争议。&lt;/p&gt;&lt;p&gt;有开发者直言不讳地在下面评论说 Wathan 拒绝这个 Pull Request 并将其归因于 AI 的做法是错的，他表示：「这件事唯一应该受到指责的人是 Tailwind 的 CEO / 主要维护者。他们做出了错误的决定，雇佣了程序员却不知道如何才能赚到足够的钱来支付他们的工资。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgicmvc40iaiadtXbUACfXLQOxVibtEllkib3rTMlZNpwhjro17tEA9rE4nmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.43148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527528" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/138e6c60-c54d-4032-ac80-f403725b9020/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;甚至还有人恶语相向。最后，Wathan 选择了锁帖。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg20EzmhcdTMiaibffMKSXXuNA18e5MwVpNASROCj0xsv5rGSCOys5NY0Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21420118343195266" data-s="300,640" data-type="png" data-w="845" type="block" data-imgfileid="503527526" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/39de52f8-3097-42cd-87d7-65dc72a80647/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但事件并未就此平息，只是转移了位置，其中很多讨论都围绕着&lt;strong&gt;开源项目的商业模式&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在 X 上，技术作家 Bilgin Ibryam 评论说：「这并非技术失败，而是商业模式的失败。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgbt0LtubL4sgI3iamnAM89JBEB9vuDBbMNIsicj0OicG6iaGqiaAficgbGiboQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.332470892626132" data-s="300,640" data-type="png" data-w="773" type="block" data-imgfileid="503527530" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2212e39d-0d26-45a9-9daf-421c178921b4/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在过去，开源软件通过「免费软件 + 付费服务/托管」的模式生存。而在 Web 开发领域，像 Tailwind 这样的项目，其商业通常闭环是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工具开源&lt;/strong&gt;：吸引海量开发者使用&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文档引流&lt;/strong&gt;：开发者为了查阅用法访问官网&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;转化变现&lt;/strong&gt;：在官网展示高质量的付费模版和组件库&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;但在 2026 年，AI 成了用户。&lt;/p&gt;&lt;p&gt;正如 Ibryam 所言，AI 在不知不觉中使用了开源项目，但 AI 从不访问网站，从不看广告，更不可能掏出信用卡购买一套 UI 组件包。对于 AI 而言，文档只是训练数据，而非消费入口。&lt;/p&gt;&lt;p&gt;当中间的文档引流环节被 AI 截断，后端的商业转化自然归零。Tailwind 实际上变成了一个为 AI 及其背后的巨头免费提供基础设施，却无法从中获取任何价值的「假奶牛」。&lt;/p&gt;&lt;p&gt;下面展示了更多网友讨论：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgpcf0ALjPUIkkQX86PM3HgtTJ2Cib4OFIezJe9sXiasdqIvHU6ibby8O7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2857142857142857" data-s="300,640" data-type="png" data-w="791" type="block" data-imgfileid="503527529" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7bb532bb-efb5-4d9c-a519-7740a4ae0a59/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgMDw4c0nD7W0icWibfkRgOJK0ibGhmwwwibSfx5MT3DtgAz2Cx3OiafD4NMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.30828025477707005" data-s="300,640" data-type="png" data-w="785" type="block" data-imgfileid="503527531" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/3b331d5b-c730-452e-ba1c-1308d2a05956/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgoLLGUM2QGq7ABSCibgS3OkHUaonSIBsGbsERkjqLBdRr1vLVBRBic1Qg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.21546261089987326" data-s="300,640" data-type="png" data-w="789" type="block" data-imgfileid="503527532" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/bb6afca9-6920-4ea5-afe1-325f82520121/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgpCQNJliaqCUWdCic9wXiaX85KtZ7UySfQagiaNh6sQJayxpdVjJzs4YIpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.516497461928934" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527533" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/b8764fd6-e84d-4791-bd0d-c50685c34077/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有一些人分享了自己的点子，试图帮助 Tailwind 渡过难关：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgUwrFU62eCib0SF6YfsaPS24iboXhAXN4XA8llRa9nuxEJx0jUPzBQuFA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5734355044699873" data-s="300,640" data-type="png" data-w="783" type="block" data-imgfileid="503527534" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/565e39b6-0b88-413e-8518-422c2836ccc3/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgotAxavANZKZiaFbP7Jyvkkock8hE94Zt4hw3OgAzmGgMIGibWkwIvXNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.47715736040609136" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527536" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/2072c393-eb27-44b8-92d6-4f1accb046b1/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;也有人觉得 Wathan 的言语过于夸张，说是裁掉了 75% 的人，其实是裁掉了 4 人中的 3 人。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgmeTESDqZo2nnbqP3q5iacTg0akM5X0wia11dN8KnI36zY2ibknqibRaibvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.3729096989966555" data-s="300,640" data-type="png" data-w="598" type="block" data-imgfileid="503527535" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/a9f5f5cf-b3b0-42a1-8889-a65d13eab529/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;但也有网友对 Tailwind 的遭遇表达了同情和关切：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgTx9ckibC7hxaB5OdEY5JnVczcjZOnVd1flFkMxQbZI0dZice38v64Cyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.2987179487179487" data-s="300,640" data-type="png" data-w="780" type="block" data-imgfileid="503527537" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/b2ce2979-39c9-4be0-83c5-c6e4f40e7f7d/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgBcWVOKb9C7E4AynCUzia6Kor8EXtGRaIQQticy1sMYgTlnoyayXc02dQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.4844903988183161" data-s="300,640" data-type="png" data-w="677" type="block" data-imgfileid="503527538" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/ed862744-d773-4be8-8e27-034d40cb36a2/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;多家公司伸出援手&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个故事略显悲伤，但却有一个还算不错的暂时结局：Tailwind 的呼救被听到了，谷歌等多家公司伸出了援手。&lt;/p&gt;&lt;p&gt;前天，Adam Wathan 就已经在 X 上晒出了一份赞助者名单，其中可以看到 Cursor、Shopify、CodeRabbit 等多家知名 AI 和科技公司。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgq7szoQXgkngibdYDX3kxe0PH6V1qONPyz0Lyic3IPOzhceoS89RjqibgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="1.217005076142132" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527539" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/8489a1c7-37ab-49a2-a405-18203aa6f72f/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而各档位的赞助金额如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgOk4NFwnwCcK6c2HunibYG7t2MyQUViayDtVWfFVuRKgkywnpibvXt8iaVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.6203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527540" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/4e4a0631-e8e1-4c60-8117-4e774d8efa02/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;9 号上午，谷歌 AI Studio 产品负责人 Logan Kilpatrick 也宣布了赞助 Tailwind 项目（每年 5000 美元的 Partner 档位）。对于像谷歌和 Cursor 这样直接受益于高质量 AI 编程体验的公司来说，确保 Tailwind 继续维护显然符合他们的利益。毕竟，如果底层框架死了，AI 生成的代码质量也会随之下降。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgeL5YHgrsreBqvPozlRVIJwiahnGTfThWk31aTBmxy8RbyJv6bysMpNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.3059125964010283" data-s="300,640" data-type="png" data-w="778" type="block" data-imgfileid="503527541" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/3bfc0bf8-db24-47d4-8bc2-1231a0fbaabe/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，该公司前些天推出的每年 120 美元的个人订阅服务「Tailwind Insider」也已经收获了更多新客户。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgofCjd9ym87l0FmnDCVXeDGw7ou9aPYaE84UexrgTRwFEJEWKxxWqzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.12222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527542" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/b04ff4ba-d145-4f9c-93d6-b8db950afd1e/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这些赞助和收入应该可以缓解该公司的燃眉之急。至于被裁掉的工程师，也有可能会被重新招募回来。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg8Z5KDoVp8fiatCdUicxorcibsChoZVSTqyMYGo5Kgfggv9H7do6Np0iadA/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.45790816326530615" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503527543" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/17ac231f-fd2c-4620-80c5-ec7240072bbe/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但这也并不是一个十分完美的结局，Tailwind 还是需要自己努力寻找合适的商业模式，正如 Wathan 所言，这些支持让公司感到「很安心」，他们不需要被拯救，而是获得了一些喘息的时间来探索新的方向。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgB5OucGicKL0W5A7JUO2AE8sLFQxgaMjOKv96I1sW9Ko3rH7mZmo8Gkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.7936305732484077" data-s="300,640" data-type="png" data-w="785" type="block" data-imgfileid="503527544" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/b8fae2a8-3ca5-4e7e-8328-08b941b4a008/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;又或者等待被某家大公司收购？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgUasAYaKzzedTJjlKicgiaDqGLuKlcl8SBWDHXVLDiaRFPt7WV6sxaXOEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.9886075949367089" data-s="300,640" data-type="png" data-w="790" type="block" data-imgfileid="503527545" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/8112687e-0b90-4493-bf84-83737233887d/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;警钟为谁而鸣&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tailwind 的故事有了一个暂时温暖的结局，但它留给行业的思考却是有些寒冷的。&lt;/p&gt;&lt;p&gt;当 AI 能够完美地消化信息、生成代码、甚至替代交互时，所有依附于「人类注意力」和「人类访问量」的商业逻辑都面临着重构的风险。&lt;/p&gt;&lt;p&gt;对于开源维护者而言，2026 年的新课题已经摆在桌面上：当你的用户变成不知疲倦且一毛不拔的 AI 时，你该向谁收费？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>打破学科壁垒！400篇参考文献重磅综述，统一调查「人脑×Agent」记忆系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 21:10:06 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ee3d5c61-1547-41a6-b608-a0d0f7ff2db9/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;跨学科突破：神经科学如何让 Agent 拥有「人类式」记忆？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你是否想过 Agent 能像人类一样积累经验、不断成长？如今，这一愿景正加速走向现实。但是，现有研究要么只聚焦 AI 技术本身，要么对人脑记忆机制的借鉴浮于表面，两个学科之间始终缺少真正的灵感碰撞。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;哈工大、鹏城实验室、新加坡国立、复旦、北大&lt;/strong&gt;联合发布了一篇重磅综述&lt;strong&gt;《AI Meets Brain: A Unified Survey on Memory System from Cognitive Neuroscience to Autonomous Agents》&lt;/strong&gt;，首次打破认知神经科学与人工智能之间的学科壁垒，系统性地将人脑记忆机制与 Agents 记忆统一审视，为设计真正「类人」的 Agent 记忆系统奠定理论基石。&lt;/p&gt;&lt;p&gt;全文横跨认知神经科学与人工智能两大领域，涉猎相关文献共 400 篇。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527382" data-ratio="0.3814814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gAQQFXpYlgj1FlY3bzznK6pGHDqwAeKkhZxbRnXbwVpJousAU40QQSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5f6adbb3-e00a-4e24-9790-ebecf1f7ed51/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：http://arxiv.org/abs/2512.23343&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github 链接：https://github.com/AgentMemory/Huaman-Agent-Memory&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;什么是记忆？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综述重新定义了记忆。记忆不仅仅是数据的存储，它也是认知的纽带。综述从认知神经科学到 Agent 对记忆进行了剖析：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.认知神经科学角度：连接过去与未来的桥梁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在人脑中，&lt;strong&gt;记忆不仅仅是回放信息，其本质是大脑存储和管理信息的过程。&lt;/strong&gt;记忆是连接过去经验与未来决策的认知桥梁。它分为两个阶段：在第一阶段，当大脑获得新概念或遇到新事件时，它会快速形成特定的神经表征，同时整合和存储这些信息。在第二阶段，大脑对存储的表征进行操作，要么随着时间的推移巩固它们，要么根据类似的未来情况检索它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.LLM 视角：三种形态的并存&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于大语言模型，记忆并非单一的存储结构，而是表现为三种形式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数记忆（Parametric Memory）&lt;/strong&gt;：内化在神经网络权重中的知识，对应人类的抽象长期记忆。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工作记忆（Working Memory）&lt;/strong&gt;：基于上下文窗口，负责实时推理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;显式外部记忆（Explicit External Memory）&lt;/strong&gt;： RAG 是典型代表，通过解耦计算与存储，使 LLM 从「知识库」变为「知识调度器」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3.Agent 视角：从存储到认知的跃迁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent 的记忆超越了 LLM 的简单存储，它是一个动态的认知架构，该综述选择沿着三个核心维度解构记忆：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;结构化存储&lt;/strong&gt;：旨在将非结构化自然语言交互转换为易于机器索引和理解的有效格式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;动态调度&lt;/strong&gt;：解决了有限的注意力资源和大量记忆存储之间的冲突，模拟了人脑的遗忘与唤醒机制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;认知进化&lt;/strong&gt;：Agent 必须深入反思、抽象和重组记忆内容，从而推动其行为策略的持续更新。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Agent Memory vs RAG&lt;/strong&gt;：传统的 RAG 侧重于将 LLM 连接到静态的知识库进行查询，而 Agent Memory 是嵌入在 Agent 与其环境之间的动态交互过程中，不断地将 Agent 操作和环境反馈生成的信息合并到记忆容器中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;记忆有何用？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在认知神经科学中，记忆构成了大脑编码、存储和检索信息的神经过程，使个体能够保留过去的经验并利用它们来指导正在进行的行为并为未来的决策提供信息。&lt;/p&gt;&lt;p&gt;在 LLM 驱动的 Agent 中，模型原生的无状态性与复杂、长期任务所需的连续性需求之间存在着天然的鸿沟。因此，记忆超越了其作为桥接历史交互的被动存储库的角色，而是充当 Agent 认知架构中的关键主动组件。因此，给 Agent 装上记忆系统，并非只是为了记住，而是为了实现三大核心作用：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527383" data-ratio="0.5555555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g7QFIGjBHHHuia4SicgraNicgjoE9WSa5r3Djb0ErNxweBWLR8HybCcEicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3ef56602-9912-48c7-ba7d-aa9aca19e02b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1. 记忆通过减轻上下文窗口限制、实现长期个性化以及驱动基于经验的推理来扩展 Agent 的能力。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.突破上下文窗口的限制&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;启发式上下文设计&lt;/strong&gt;：通过设计启发式规则来管理记忆。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自主记忆优化&lt;/strong&gt;：让 Agent 把记忆管理提升为可学习的内在能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.构建长期个性化画像：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;画像构建&lt;/strong&gt;：&amp;nbsp;Agent 能从碎片化的历史对话中，提炼出你的核心特质和信息。它不仅会记录发生了什么，还会定期反思，推测你话语背后的潜在动机，从而在脑海中建立一个个性化档案。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;偏好对齐执行&lt;/strong&gt;：当 Agent 替你执行任务时，记忆库会充当隐形指挥棒。不需要反复叮嘱，它会自动调用记忆中的偏好约束决策。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3.驱动基于经验的推理：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;战略指导&lt;/strong&gt;：检索历史上相似的成功案例或从中提炼的高层经验，指导当前的决策，避免重蹈覆辙。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;程序固化&lt;/strong&gt;：将成功的推理过程转化为可复用的技能或可执行的结构。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;记忆的分类学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在谈论 Agent 记忆的分类之前，综述首先梳理了认知神经科学对记忆的经典定义。&lt;strong&gt;人脑的记忆并不是一个单一的黑盒，而是一个分工明确的复杂系统。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.基于认知神经科学的分类：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;记忆的概念最初源于认知神经科学，它被广泛地定义为大脑存储和管理信息的认知过程，允许在原始刺激或事件不再存在后访问和使用这些信息，通常分为短期记忆和长期记忆。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.短期记忆&lt;/strong&gt;&lt;strong&gt;（Short-term Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：大脑的临时工作台。它负责在极短的时间窗口（约 15～20 秒）内维持和处理信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征&lt;/strong&gt;：容量非常有限（通常只能容纳 4～9 个单位的信息）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.长期记忆&lt;/strong&gt;&lt;strong&gt;（Long-term Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：大脑的永久档案馆。它可以存储从几分钟到几十年的信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征&lt;/strong&gt;：没有严格的容量限制，且结构高度组织化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长期记忆可继续分为情景记忆和语义记忆&lt;/strong&gt;：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;情景记忆（Episodic Memory）&lt;/strong&gt;：指对个人亲身经历过的特定事件的记忆。此类记忆通常不仅包括有关事件本身的详细信息，还包括其时间和空间背景，即事件发生的时间和地点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;语义记忆（Semantic Memory）&lt;/strong&gt;：指对所学事实知识、概念和规则的记忆。这些记忆与获取的特定时间和地点无关，并且它们的检索并不伴随着对过去特定事件的生动重新体验。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;2.Agent 的双维度记忆分类&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综述中指出，连贯的记忆分类对于系统地理解和设计 Agent 系统中的记忆机制至关重要。为了适应复杂的自主任务，综述提出了一套双维度的分类法。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527384" data-ratio="0.5824074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gDnyWkmWpicHybMpkNDbmsXSsia0825054RlcM7txMKKgsaRjLGJcE4LA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/45143a0f-847d-4993-9d0c-02627cd95664/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2. (a) 基于性质的分类法，根据编码的信息类型对记忆进行分类。 (b) 基于范围的分类，根据记忆的应用范围来区分。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（1）.基于「性质」的分类（Nature-based）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是直接对齐人脑「情景和语义」的分类方式，决定了 Agent 在推理时使用的是「经验」还是「知识」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.情景记忆（Episodic Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：任务式数据库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：完整的交互轨迹（Trajectory）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：提供过程性知识，即「How to」&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.语义记忆（Semantic Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：存储 Agent 的知识库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：事实、概念、规则和常识&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：提供陈述性知识，即「What-is」&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;（2）.基于「范围」的分类 (Scope-based)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是基于记忆在任务流中的生命周期和适用范围进行的划分。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.轨迹内记忆（Inside-trail Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：临时工作区&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：当前任务的中间步骤、临时变量和即时的观察结果&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;作用域&lt;/strong&gt;：仅在当前任务或会话中有效&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;：用完即走。当情景结束时，该记忆通常会被清除或重置&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.跨轨迹记忆（Cross-trail Memory）&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：永久存储库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储内容&lt;/strong&gt;：可概括的模式、学习的策略、可重用的知识&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;作用域&lt;/strong&gt;：跨越多个任务、多个对话，甚至跨越 Agent 的整个生命周期&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：提供陈述性知识，即「What-is」&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;记忆的存储机制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;记忆存储的关键在于记忆的存储位置和记忆的存储形式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.认知神经科学中的记忆存储&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在人脑中，记忆存储是一个跨脑区的动态协作过程。&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;短期记忆&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储位置&lt;/strong&gt;：分布在感觉皮层和额顶网络（Sensory-frontoparietal network）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机制&lt;/strong&gt;：感觉皮层保留细节，额顶网络支持跨模式表示，允许不同通道信息在共享表示空间中链接和操作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储形式&lt;/strong&gt;：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;持续活动（Persistent activity）&lt;/strong&gt;：保持高水平的放电活动&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;活动 - 沉默突触连接（Synaptic connection weights）&lt;/strong&gt;：仍可能有用的项目可以默默存储并在需要时重新激活&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;长期记忆&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储位置&lt;/strong&gt;：海马体（Hippocampus） + 新皮层（Neocortex）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机制&lt;/strong&gt;：海马体不是仓库，而是索引。新机制先在海马体暂存，通过系统巩固，慢慢转移到新皮层这个永久仓库中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储形式&lt;/strong&gt;：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;事件单元（Event-based unit）&lt;/strong&gt;：把连续的生活切片成一个个独立的事件包。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;认知地图（Cognitive map）&lt;/strong&gt;：人脑把概念和知识也画成了地图，通过认知距离表示关系的远近。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527385" data-ratio="0.6268518518518519" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g3ALiaQM4nySjBpqqHapr2qEWUQZib2lZq2azr0ibUxmS3ApVcGcziaFfTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/255c0ed1-d8ac-446c-a8d8-7e2e699a7606/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 3. 认知神经科学中的记忆存储机制概述，包括短期和长期记忆的存储位置和存储格式。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.Agent 中的记忆存储&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于人脑浑然天成的神经网络，Agent 的记忆系统是显式的工程构建。不仅要解决存在哪的物理限制，还要在怎么存上进行复杂的数据结构选型，以在计算成本和推理能力之间寻找最优解。&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;存储位置&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;上下文窗口（Context Window）&lt;/strong&gt;：对应轨迹内记忆。主要存放当前的对话流。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;记忆库（Memory Bank）&lt;/strong&gt;：对应跨轨迹记忆。外挂的存储库，容量近似无限。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;存储形式&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文本（Text）&lt;/strong&gt;：自然语言形式，比较直观&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;图结构（Graph）&lt;/strong&gt;：实体和关系组成的结构化网络，支持关系提取和模式发现，能够识别节点之间的隐式链接，从而辅助复杂的逻辑信息查询&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数（Parameters）&lt;/strong&gt;：模型权重，通过训练内化记忆&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;隐式表示（Latent Representation）&lt;/strong&gt;：高维向量，检索速度快&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;记忆的管理系统&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;记忆不是一个静态的仓库，而是一条奔流不息的河流&lt;/strong&gt;。在人类大脑中，记忆通过海马体的重播和新皮层的巩固，不断被重写和重构。而在 Agent 中，记忆管理则是提取（Extraction）、更新（Updating）、检索（Retrieval）、应用（Application）的精密闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.认知神经科学：大脑的动态循环&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人脑的记忆管理不是简单的「写入」和「读取」，而是一个充满可塑性的动态过程。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527386" data-ratio="0.6611111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gGdKBIEurjKy7q2PfKGhd4Y0DictJldDUYLrozkExENvuQr4sicEOib4xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/67911d58-4ae8-466b-8347-4e1f1dee62d6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4. 认知神经科学中的记忆管理概述。该框架阐释了信息处理的动态循环，包括记忆形成、更新和检索，通过这个循环，长期记忆支持对外部环境的灵活适应。&lt;/sup&gt;&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;p&gt;记忆形成（Memory Formation）&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;记忆并非一蹴而就，它经历了三个阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;编码（Encoding）&lt;/strong&gt;：海马体将新皮层内分布的感觉特征结合成统一的表征，并选择性地调节其与感觉皮层的相互作用，以放大未来高效用的表征。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;巩固（Consolidation）&lt;/strong&gt;：在清醒休息或睡眠等离线状态下，海马体通过重播，不断与新皮层同步活动，重新组织和调整新信息，使其稳定下来。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;整合（Integration）&lt;/strong&gt;：通过海马体与内侧前额叶皮层的协作，将巩固的记忆痕迹转化为有组织的关联知识，并最终将其重新分配至新皮层以实现持久的抽象存储。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆更新（Memory Updating）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;大脑如何修正错误的记忆？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机制&lt;/strong&gt;：预测误差（Prediction Error）是核心驱动力。当发现现实与记忆不符，大脑就会触发更新机制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;策略&lt;/strong&gt;：分化是为相似的新旧事件建立互斥的神经表征，防止混淆。整合是将新旧知识与预测误差整合为一体。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆检索（Memory Retrieval）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;检索即重构。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;重构性&lt;/strong&gt;：回忆不是回放录像，而是根据线索（Cue）利用海马体进行模式完成（Pattern Completion），重新构建当时的场景。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;再巩固（Reconsolidation）&lt;/strong&gt;：每当回忆一次，这段记忆就会变得不稳定，容易被修改或增强。这也解释了为什么 &amp;ldquo;常回忆&amp;rdquo; 能加深记忆，但也可能会植入虚假细节。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2.Agent 记忆管理：记忆管理的精密闭环&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与在受限窗口内执行瞬态处理的标准大语言模型不同，Agent 通过显式管理机制实现体验的持久调节。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527388" data-ratio="0.4722222222222222" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69ghHCB3acmTU9YiacKtfRjd7RfOn0a7C2yEd7dVhmP0oBq13ng4ibrw7CA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/dac32bed-f2cc-4583-bb59-c893f18a551a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5. Agent 中记忆管理的概述。该框架形成了一个由记忆提取、更新、检索和利用组成的闭环管道，从而实现持久的经验调节和长期推理。&lt;/sup&gt;&lt;/p&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;p&gt;记忆提取（Memory Extraction）&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Agent 不能把所有 Log 都存下来，它需要提炼：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;扁平提取（Flat）&lt;/strong&gt;：直接将原始信息记录到存储中或应用摘要和分段等轻量级预处理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分层提取（Hierarchical）&lt;/strong&gt;：通过多粒度抽象机制将碎片化信息组织成层次结构，旨在模拟人类在宏观背景和微观细节之间灵活切换的认知能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;生成式提取（Generative）&lt;/strong&gt;：旨在在推理过程中动态重建上下文，从而缓解因过大上下文长度带来的计算开销和注意力稀释问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆更新（Memory Updating）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;遗忘是为了更好地记住，更新机制分为两层：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;轨迹内更新（Inside-Trial）&lt;/strong&gt;：针对上下文窗口，像人类选择性注意一样，实时过滤无关噪声，或在窗口快满时触发摘要工具，腾出工具。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨轨迹更新（Cross-Trial）&lt;/strong&gt;：针对外部记忆库，引入遗忘机制，自动剔除低价值或长时间未访问的记忆节点。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆检索（Memory Retrieval）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;不仅仅是 Embedding 的相似度，主要分为两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基于相似度（Similarity-based）&lt;/strong&gt;：计算余弦相似度，找 Top-k，但相当于只懂字面意思，不懂逻辑结构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多因素检索（Multi-factor）&lt;/strong&gt;：根据时间、重要性、相关性，结构效率和预期奖励等因素确定记忆优先级&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol style="list-style-type: lower-greek;"&gt;&lt;li&gt;&lt;strong&gt;记忆应用（Memory Application）&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;记忆怎么用，主要有两种作用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;上下文利用（Context Utilization）&lt;/strong&gt;：将记忆视为被动参考的传统检索增强生成范式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数内化（Parameter Internalization）&lt;/strong&gt;：该范式借鉴终身学习将显性记忆转化为隐性参数。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Agent 记忆系统评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综述将现有的 Benchmark 分为了两类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;面向语义（Semantic-oriented）&lt;/strong&gt;：重点关注 Agent 如何构建、维护和利用其内部记忆中的信息状态。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;面向情景（Episodic-oriented）&lt;/strong&gt;：旨在评估复杂下游应用场景（使用外部工具完成任务）中 Agent 上记忆系统的实际性能增益。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527389" data-ratio="0.7037037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69guJLTCHXeIFOWH7MpRlY7IsphWwc6BhViahK1z7CbAZt8jQmrb9aoc9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/881950d9-e24e-49aa-bef3-f8aa5b8db653/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表 1. 面向语义的基准&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527390" data-ratio="0.3037037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gFuPufDxtdPmLDePiaDVCOMr8ib5UpeDZayGvRCnKMQxrKOWISJJNDe4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/6d8d98d3-f1ea-4660-8ae5-d2a81793c671/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表 2. 面向情景的基准&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 记忆的安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 攻击&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着 Agent 被部署在长期任务中，记忆成为了攻击。其主要的攻击方式分为两类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;窃取攻击（Extraction-based Attack）&lt;/strong&gt;：把隐私「套」出来，攻击者的目标是 &amp;ldquo;偷数据&amp;rdquo;，其手段是利用精心设计的 Prompt 诱导 Agent。例如，黑客可能伪装成系统管理员，套取 Agent 长期记忆中存储的用户敏感信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;投毒攻击（Poisoning-based Attack）&lt;/strong&gt;：把思想「改变」，攻击者的目标是「坏脑子」。首先第一种是后门植入：向记忆库中注入带有「触发器」的恶意数据，平时 Agent 表现正常，一旦遇到特定的指令，就会触发恶意行为。其次是注入大量噪声或偏见数据的认知污染：让 Agent 的判断力退化，变得糊涂或产生严重的价值观偏差。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 防御&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对这些威胁，综述提出了有三道防线，构筑起从源头到输出的闭环防御体系。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;检索防御（Retrieval-based）&lt;/strong&gt;：在 Agent 读取记忆之前进行清洗。例如，通过多路检索验证一致性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;响应防御（Response-based）&lt;/strong&gt;：在 Agent 生成回答时进行监控。通过引入审查机制或利用自我反思机制，在输出前预测潜在后果，拦截包含恶意意图的响应。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;隐私防御（Privacy-based）&lt;/strong&gt;：在底层存储上做文章。将记忆分为「公有」和「私有」区域，对敏感数据进行匿名化处理，确保了 Agent 在协作时只传递必要信息，不泄露核心隐私。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;未来展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.多模态记忆&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;未来的 Agent Memory 需要打破模态的界限。目前的 Agent 在面对视频、音频等非结构化数据时，往往采用「暴力压缩」或「转写为文字」的方式，这会导致大量丰富的视觉细节（如微表情、光影变化）和听觉情感在转换中丢失。未来的记忆系统应该是&lt;strong&gt;全模态 (Omni-modal) &lt;/strong&gt;的，不仅存文本，还存储压缩后的视觉 / 听觉特征向量，其终极目标是使 Agent 不仅能「读」懂，还能「看」见，真正理解物理世界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.Agent Skills&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现在的 Agent memory 往往是孤立。训练好一个专为写代码的 Agent，它的经验（记忆）很难直接传给另一个专为数学的 Agent，这导致了严重的重复造轮子。&lt;/p&gt;&lt;p&gt;这是因为不同的 Agent 之间的异构性，导致记忆接口的不一致，因此记忆很难直接移植重用。论文借用了 Anthropic 提出的「Agent Skills」概念，即 Agent 将指令集、可执行脚本和相关资源封装到结构化目录单元中。这就好比游戏里的「装备」或「技能书」可以在不同玩家间重复使用。&lt;/p&gt;&lt;p&gt;综述提出两个可能的未来研究方向：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多模态信息的统一存储与表示&lt;/strong&gt;：当前的记忆系统主要是为文本形式设计的。如何构建支持多模态信息的统一存储框架，包括文本、图像、音频和视频，同时设计跨模态检索和推理机制，是支持跨模态 skills 迁移的关键。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨 Agent 的 skills 转移和适应机制&lt;/strong&gt;：不同的 Agent 结构，例如那些建立在不同基础模型上的 Agent，表现出差异在能力特征和接口规范方面。设计通用的 skills 描述语言，使 skills 能够无缝地转移并且跨异构代理的重用构成了实现真实代理的关键挑战 skill-sharing 生态系统。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>DeepSeek-OCR是「长文本理解」未来方向？中科院新基准VTCBench给出答案</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 20:56:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ab84ca9b-ce9c-42f0-9e42-757e7fd6dbe7/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;DeepSeek-OCR 的视觉文本压缩（VTC）技术通过将文本编码为视觉 Token，实现高达 10 倍的压缩率，大幅降低大模型处理长文本的成本。但是，视觉语言模型能否理解压缩后的高密度信息？中科院自动化所等推出 VTCBench 基准测试，评估模型在视觉空间中的认知极限，包括信息检索、关联推理和长期记忆三大任务。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;近期，DeepSeek-OCR 凭借其创新的「视觉文本压缩」（Vision-Text Compression, VTC）范式引发了技术圈的高度关注，以极少的视觉 Token 实现高效的文本信息编码，为长文本处理开辟了新路径。&lt;/p&gt;&lt;p&gt;这一突破性进展让大模型处理超长文本的成本大幅降低，但也抛出了一个核心问题：&lt;strong&gt;当长文本被高度压缩为 2D 图像后，视觉语言模型（VLM）真的能理解其中的内容吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解答这一疑问，来自&lt;strong&gt;中科院自动化所、中国科学院香港创新研究院等机构的研究团队推出了首个专门针对视觉 - 文本压缩范式的基准测试 &amp;mdash;&amp;mdash;VTCBench。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gSLXEev4kibGvoBtcNDzn1cfy4GxNAeyTQjMeZL7xVxtuYHk70iaQibChA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527415" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/96c6a5f7-d28c-4bb3-a93d-d6979ab7c73c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2512.15649&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VTCBench 链接: https://github.com/Moenupa/VTCBench&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VLMEvalKit 链接：https://github.com/bjzhb666/VLMEvalKit&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Huggingface 链接: https://huggingface.co/datasets/MLLM-CL/VTCBench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527417" data-ratio="0.3194444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gxV4xsUQM34fZghJkhUV4nO9BrsQEWlYIGP2Xv3C5OcPicwiahy5uyHSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bf625483-9a68-4fbb-9632-2731679aa28a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：视觉 - 文本压缩 (VTC) 流程演示及 VTCBench&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;与传统大模型直接读取成千上万的纯文本 Token 不同，VTC 范式（如 DeepSeek-OCR）先将长文档渲染 （Rendering）为高密度的 2D 图像，再由视觉编码器转化为少量的视觉 Token。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;该技术可实现 2 倍至 10 倍的 Token 压缩率&lt;/strong&gt;，显著降低了长文本处理时的计算与显存开销。&lt;/p&gt;&lt;p&gt;VTCBench 现已在 GitHub 和 Huggingface 全面开源，其衍生版本 VTCBench-Wild 是一个统一的、全方位评估模型在复杂现实场景下视觉文本压缩的鲁棒性，现已集成到 VLMevalkit。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心使命&amp;mdash;&amp;mdash;衡量「看得见」之后的「看得懂」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前的 VLM 也许能出色地完成 OCR 识别，但在处理 VTC 压缩后的高密度信息时，其长文本理解能力仍存疑。&lt;/p&gt;&lt;p&gt;VTCBench 通过三大任务，系统性地评估模型在视觉空间中的认知极限：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Retrieval (信息检索)&lt;/strong&gt;：在视觉「大海」中寻找特定事实的「针」（Needle-in-a-Haystack），测试模型对空间分布信息的捕捉能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Reasoning (关联推理)&lt;/strong&gt;：挑战模型在几乎没有文本重叠的情况下，通过关联推理寻找事实，超越单纯的词汇检索；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Memory (长期记忆)&lt;/strong&gt;：模拟超长对话，评估模型在视觉压缩框架下，抵御时间与结构性信息衰减的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此外，团队同步推出了 VTCBench-Wild，引入 99 种不同的渲染配置（涵盖多种字体、字号、行高及背景），全方位检测模型在复杂现实场景下的鲁棒性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;揭秘视觉压缩背后的认知瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gbqrAOxuCJGZ1Xnwp3zSfibIEjZLFF2Niaiatv1O6308L9nkBA3Riag1BdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.36574074074074076" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527427" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d0a7a926-9533-43de-bd7c-2dca5f7bdc2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：VTCBench 针对模型在长图像中检索信息的热力图。横轴代表上下文长度，纵轴代表关键事实（Needle）在文档中的深度。展现了模型表现的「迷失」与突破。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;测试结果呈现出显著的 「U 型曲线」：与文本模型类似，视觉语言模型（VLM）能够精准捕捉开头和结尾的信息，但对于中间部分的事实，理解能力会随着文档变长而剧烈衰退。&lt;/p&gt;&lt;p&gt;这证明了&lt;strong&gt;即使在视觉空间，模型依然存在严重的「空间注意力偏见」，是未来 VTC 架构优化的关键方向。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行业洞察 &amp;mdash;&amp;mdash; 视觉压缩是长文本的终局吗？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527430" data-ratio="0.7342592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gjbrkawkian3iaRV30iaJceVDLc31ZQckxIB07M1GBIHt3cTqNtv4BZTOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d9770352-f624-427e-bd65-4fe473d74555/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;通过对 GPT、Gemini、Claude、QwenVL、InternVL、Gemma、KimiVL、Seed1.5 等 10 余种尖端模型的深度评测，可以发现：&lt;/p&gt;&lt;p&gt;虽然 VTC 极大提升了效率，但现有 VLM 在复杂推理和记忆任务上的表现仍显著弱于纯文本 LLM；&lt;/p&gt;&lt;p&gt;消融实验证明，&lt;strong&gt;信息密度是决定模型性能的关键因素，直接影响视觉编码器的识别精度；&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini-3-Pro 在 VTCBench-Wild 上表现惊艳，其视觉理解能力已几乎追平其纯文本基准，证明了 VTC 是实现大规模长文本处理的极其可行的路径！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说传统的长文本处理是「逐字阅读」，那么， DeepSeek-OCR 所引领的 VTC 范式就是「过目成诵」的摄影式记忆。&lt;strong&gt;VTCBench 的出现，正是为了确保模型在拥有这种「超能力」的同时，依然能够读懂字里行间的微言大义。&lt;/strong&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026在新加坡滨海湾畔共饮一杯：蚂蚁InTech之夜邀您共话AI未来</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 17:27:40 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgZ4GvEtZBfLYbT7OB1qLUjkQDm4ExPZFyofsicqOzFDWib7dD7oicByqzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="3.2666666666666666" data-s="300,640" data-type="png" data-w="750" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgZ4GvEtZBfLYbT7OB1qLUjkQDm4ExPZFyofsicqOzFDWib7dD7oicByqzQ/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="1836" data-imgfileid="503527455" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/f6b64fcb-5fdd-4a06-8a8c-04adc2aea7ca/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们为每位到现场的小伙伴准备了专属伴手礼，期待与你相聚新加坡滨海湾，共同度过一个难忘的夜晚。&lt;/p&gt;&lt;section&gt;&lt;a href="https://wj.qq.com/s2/25465624/tvxg/"&gt;点击此链接，预约活动席位。&lt;/a&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让两个大模型「在线吵架」，他们跑通了全网95%科研代码｜深势发布Deploy-Master</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 14:29:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;科学计算领域已经积累了数量空前的开源软件工具。从生物信息学、化学模拟，到材料计算、物理仿真与工程设计，几乎每一个学科方向，都形成了自己的生态。在 GitHub 等平台上，成千上万个代码仓库声称可以被用于科研实践。&lt;/p&gt;&lt;p&gt;但一个长期存在、却始终没有被系统性解决的事实是：&lt;strong&gt;绝大多数科学软件，停留在 &amp;ldquo;被发布过&amp;rdquo;，而不是 &amp;ldquo;可以直接运行&amp;rdquo; 的状态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在科研实践中，我们往往需要花费数天甚至数周时间反复解决编译失败、依赖冲突、系统不兼容等问题，才能在本地 &amp;ldquo;勉强跑通&amp;rdquo; 一个工具。这样的运行环境高度依赖个人经验，往往是临时的、不可移植的，也很难被他人复现或复用。每个研究者、每个实验室，都在手工维护自己的运行环境，而不是在一个共享、可复现的执行基础设施之上开展工作。&lt;/p&gt;&lt;p&gt;这种模式带来的问题，并不只是效率低下。更关键的是，它在结构上限制了科学软件的三件事情：&lt;strong&gt;可复现性、大规模评估，以及系统性集成&lt;/strong&gt;。即便容器化、云计算和 HPC 平台已经显著降低了算力门槛，这一 &amp;ldquo;部署瓶颈&amp;rdquo; 依然真实存在，并且长期制约着科学软件的可用性。&lt;/p&gt;&lt;p&gt;随着 &lt;strong&gt;AI for Science（AI4S）&lt;/strong&gt; 的兴起，这一问题被进一步放大。在新的科研范式中，AI 系统不再只是输出预测结果，而是需要与真实的科学工具发生紧密交互：调用求解器、执行模拟程序、运行分析管线、处理真实数据。在这样的背景下，一个工具是否 &amp;ldquo;真的能跑&amp;rdquo;，不再是工程细节，而是第一性问题。&lt;/p&gt;&lt;p&gt;这一问题在 &lt;strong&gt;Agentic Science&lt;/strong&gt; 场景中表现得更加尖锐。如果工具依赖隐含环境、执行高度脆弱，那么智能体的规划将无法真正落地，执行失败也无法被结构化分析，更不可能转化为可学习的执行轨迹。&lt;/p&gt;&lt;p&gt;从这个角度看，工具是否部署就绪，已经成为制约 AI4S 与 Agentic Science 规模化发展的结构性瓶颈。&lt;/p&gt;&lt;p&gt;基于这些观察，我们逐渐形成了一个判断：科学软件的问题，并不在于工具不够多，而在于缺乏一个能够将工具系统性转化为可执行事实的共享基础设施。Deploy-Master，正是在这一背景下被提出的。&lt;/p&gt;&lt;p&gt;在真实世界中，部署并不是一个孤立步骤，而是一条连续链路：工具能否被发现、是否被正确理解、能否构建环境，以及是否真的可以被执行。&lt;strong&gt;Deploy-Master 正是围绕这条链路，被设计为一个以执行为中心的一站式自动化工作流&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgPnPiapjiagvxxfs1BOyNDRyAficeHyNUuMiaYWdcrhicDcH88agszXyyIIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527457" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9586545d-c900-4d87-8145-e9988a0fdf25/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Search Agent &amp;nbsp;搜索科研锚点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大规模场景下，部署的第一个难题并不在构建，而在于发现。如果候选工具集合本身存在系统性偏差，后续所有自动化都会被放大为偏差。&lt;/p&gt;&lt;p&gt;为此，我们从 &lt;strong&gt;91 个科学与工程领域&lt;/strong&gt;出发，构建了一个覆盖 AI4S 实际应用场景的学科空间，并使用语言模型扩展搜索关键词，在 GitHub 与公共网络中进行大规模检索。初始召回得到的仓库，会作为 &amp;ldquo;锚点&amp;rdquo;，通过依赖关系、引用关系、共享贡献者和文档链接等信号进行迭代扩展，从而避免仅依赖关键词搜索带来的盲区。&lt;/p&gt;&lt;p&gt;随后，我们通过结构启发式规则剔除明显不可执行的仓库，并由 Agent 进行语义判断，确认其是否构成一个可执行科学工具。通过这一多阶段漏斗流程，&lt;strong&gt;我们将最初约 50 万个仓库，收敛为 52550 个进入自动部署流程的科学工具候选&lt;/strong&gt;。这一步的意义，不仅在于筛选工具，更在于第一次以结构化方式刻画了真实科学工具世界的规模与边界。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527458" data-ratio="0.5583333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgACicI7TkibbichYkY1mw8sibWmSeNuHGBZqeiaD7TgfMl3qdG7LqHt6brEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/897914ff-e33d-466e-92ab-66b690bc6e02/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;双模型博弈 &amp;nbsp;实现 95% 成功率&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在构建阶段，我们面对的并不是一个 &amp;ldquo;有明确说明书&amp;rdquo; 的世界。大量科学软件仓库的构建信息是零散的、不完整的，甚至相互矛盾的。README 文件可能早已过期，已有 Dockerfile 也未必反映当前代码状态，而关键依赖往往只存在于作者本地环境中。&lt;/p&gt;&lt;p&gt;Build Agent 会系统性地遍历仓库中的构建线索，并在必要时进行补充信息检索，生成初始构建方案。早期实验表明，仅依赖单一模型生成构建规格，成功率只有 50%&amp;ndash;60%，失败主要源于构建信息中大量隐含、未被显式表达的假设。&lt;/p&gt;&lt;p&gt;为此，&lt;strong&gt;Deploy-Master 引入了双模型评审与辩论（debate）机制&lt;/strong&gt;：一个模型提出构建规格，另一个模型独立审查并主动寻找潜在不一致、缺失依赖或环境假设，提出修正建议。两者通过多轮交互，不断修正方案，直到形成稳定、可执行的构建规格。这一机制&lt;strong&gt;将整体成功率提升到了 95% 以上&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;每一个工具最终都会通过一个最小可执行命令进行验证。只有通过执行验证的工具，才会被视为成功部署，并被进一步结构化、注册和发布到玻尔与 SciencePedia 上，使其可以被直接使用，或被其他 Agent（例如 SciMaster）调用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKggicia79U6xIpFUjVqxcz7EWeakLpG9BazHmicwOp0oFfiapplcRh09CeTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527460" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/113d7560-b30f-43f9-bce7-9a0c65f488f0/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从构建时间的分布来看，大规模部署并不是一个 &amp;ldquo;均匀&amp;rdquo; 的过程。尽管大多数工具可以在 7 分钟左右完成构建，但整体分布呈现出明显的长尾特征。一部分工具仅包含轻量级脚本或解释型代码，构建过程相对简单；而另一部分工具则涉及复杂的编译流程、深层依赖以及系统级库配置，其构建时间显著更长。&lt;/p&gt;&lt;p&gt;这种差异并不会阻止整体流程的推进，但它决定了部署在规模化条件下的成本结构。&lt;/p&gt;&lt;p&gt;在成功部署的 50112 个工具中，我们观察到一个高度异构的语言分布。&lt;strong&gt;工具覆盖了 170 多种编程语言&lt;/strong&gt;，其中 Python 占据了最大比例，其次是 C/C++、Notebook 形式的工具、R、Java 等。绝大部分语言部署成功率都稳定维持在较高水平。少数成功率相对较低的语言，主要集中在依赖复杂编译链或系统级库的场景，例如 C/C++、Fortran 以及部分 R 工具。&lt;/p&gt;&lt;p&gt;这并不意味着这些语言 &amp;ldquo;天生更难部署&amp;rdquo;，而是反映了其工具链对底层环境的耦合程度更高，从而放大了构建规格中的不确定性。从部署的角度看，语言本身并不是决定性因素，环境耦合强度才是。在 2438 次失败的构建尝试中，我们对失败原因进行了系统性统计。结果显示，失败并非均匀分布，而是高度集中在少数几类问题上。最主要的失败来源是构建流程错误，包括构建步骤与仓库当前状态不一致、关键依赖缺失、编译器或系统库不匹配等。这类失败远远多于资源不足、网络异常或权限问题。与此同时，资源相关错误在高并发阶段也确实出现过，并直接推动了我们对调度策略和隔离机制的后续改进。&lt;/p&gt;&lt;p&gt;这进一步说明，在规模化部署中，失败不应被视为异常，而应被视为系统暴露问题、进而自我修正的信号。&lt;/p&gt;&lt;p&gt;通过统一的执行基础设施，我们得以系统性地观察科学软件在真实环境中的部署行为：哪些环节最容易失败，哪些隐含假设最常被触发，哪些工具链最容易放大不确定性。这种可观测性本身，正是 Deploy-Master 希望建立的基础之一。它让 &amp;ldquo;科学软件难以部署&amp;rdquo; 从一种经验判断，转化为可以被量化、被分析、被持续改进的工程对象。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为 Agentic Science 构建行动基座&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Deploy-Master 的直接产出，是一个由数万条执行验证工具构成的集合。但更重要的是，&lt;strong&gt;它为社区 Agent 与各类 Master Agent 提供了一个长期缺失的基础前提。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对 Agent 而言，工具调用并不是抽象动作，而是必须在现实环境中成功落地的执行过程。只有当工具被统一构建、验证并注册为可执行能力，Agent 才真正拥有稳定的 action space，规划、执行与学习之间的闭环才得以成立。这也使得不同来源的社区 Agent，可以共享同一批经过执行验证的工具能力，而不再各自维护脆弱、不可复现的运行环境。&lt;/p&gt;&lt;p&gt;这一方法论的意义，并不局限于科学计算。科学工具往往被视为自动化部署中最困难的一类：依赖复杂、系统耦合强、文档不完整、对环境高度敏感。如果在这样一个 &amp;ldquo;最难场景&amp;rdquo; 中，仍然可以通过以执行为中心的设计，在万级规模下稳定地产生可运行工具，那么结论已经非常清晰 &amp;mdash;&amp;mdash; &lt;strong&gt;问题不在工具类型，而在于是否建立了以执行为核心的基础设施&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一判断同样适用于更广泛的软件工具生态：工程工具、数据处理系统、专业软件乃至各类 Agent Tooling。只要工具最终需要被执行，其部署问题就无法绕开 &amp;ldquo;不完美信息&amp;rdquo; 这一现实前提。&lt;/p&gt;&lt;p&gt;Deploy-Master 并未解决所有问题。异构硬件、分布式计算、语义级 I/O 接口以及与物理实验系统的闭环集成，仍然是未来需要面对的挑战。但有一件事情已经足够清楚：&lt;strong&gt;在 Agentic Science 时代，执行不是推理之后的附属步骤，而是所有能力得以成立的前提。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当 &amp;ldquo;工具能不能跑&amp;rdquo; 不再是一个默认假设，而成为一个被系统性验证的事实，科学智能体才真正开始拥有与现实世界交互的基础。而 Deploy-Master，正是迈向这一执行现实的一次尝试。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>OpenAI for Healthcare——面向医疗保健的AI产品</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 09 Jan 2026 14:28:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-backh="309" data-backw="578" data-imgfileid="100027102" data-ratio="0.5351851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynAWZAa9Tj20Yc5ibLHQHONw6lTpjSDsrqtCuJtEhDbkDV0iauwiclnPKWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/52fced35-4237-488e-84ac-569db61a1db4/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;2026 年1 月 9 日，OpenAI 宣布推出 OpenAI for Healthcare，这是一套旨在帮助医疗机构为患者提供更一致、高质量护理的产品，而这其中也包括他们于 1 月 7 日推出的 &lt;strong&gt;ChatGPT for Healthcare&lt;/strong&gt;，它已被推广至如&amp;nbsp;AdventHealth、Baylor Scott &amp;amp; White Health 等领先机构。&lt;/p&gt;&lt;p&gt;在当今社会，关于个人健康的需求正不断上升，医疗行业的压力也随之剧增。在这种条件下，得益于模型的进步，AI 的应对能力有了明显上升。OpenAI for Healthcare 通过为组织提供安全的企业级 AI 基础，帮助缩小这一差距&amp;mdash;&amp;mdash;让团队能够使用相同工具提供更好、更可靠的护理，同时支持 HIPAA 合规。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;医疗领域的 ChatGPT 应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ChatGPT 医疗平台旨在支持真实患者护理中谨慎且基于证据的推理，同时减轻行政负担，使团队能有更多时间陪伴患者。团队可以将临床医生、管理者和研究人员带入一个安全的工作空间，配备他们所需的控制，以安全且大规模地部署 AI。&lt;/p&gt;&lt;p&gt;相关内容大致有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;为医疗工作流程构建的模型：&lt;/strong&gt;为临床、研究和运营工作提供高质量响应&amp;mdash;&amp;mdash;由为医疗领域构建的GPT-5模型驱动，并通过医生主导的测试在基准和实际工作流程中进行评估。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;证据检索并附带透明引用：&lt;/strong&gt;回答基于医学来源&amp;mdash;&amp;mdash;涵盖数百万同行评审研究、公共卫生指导和临床指南&amp;mdash;&amp;mdash;并附有清晰的引用，包括标题、期刊和出版日期，以支持快速核查来源。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynmq6C5QxH6QqREJN6urbheicfoKTib9K0bfmH4kufbJ2E3F0VgSu7VGbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1920" data-height="1080" data-backw="546" data-backh="307" data-imgfileid="100027099" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/005eac71-e443-4915-8f70-e2ae48def856/640.png" alt="图片" data-before-load-time="1767940085793" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：临床检索。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机构政策与护理路径对齐：&lt;/strong&gt;与 Microsoft SharePoint 等企业工具及其他系统集成，响应内容可纳入机构批准的政策、路径文档和运营指导，支持团队间的一致执行，确保患者获得高质量护理。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynlGI6iapvCo1ibIhHKIqicMrXD9fibezSa882YareLSveIljqrIepjSib2cQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1920" data-height="1080" data-backw="546" data-backh="307" data-imgfileid="100027100" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3b463082-d97b-4f62-93c7-48b0196406d6/640.png" alt="图片" data-before-load-time="1767940085807" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：批准的护理路径。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可重复使用的模板以自动化工作流程：&lt;/strong&gt;共享模板，用于常见任务，如出院摘要、患者指示、临床信函和事前授权支持。临床团队花在重写和搜索上的时间更少，患者拥有更清晰的下一步步骤和更顺畅的护理过渡。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;访问管理与治理：&lt;/strong&gt;一个集中式工作区，支持基于角色的访问控制，与通过 SAML SSO 和 SCIM 实现全组织用户管理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;HIPAA 合规的数据控制与支持：&lt;/strong&gt;患者数据和 PHI 仍由组织控制，提供数据驻留、审计日志、客户管理加密密钥及与 OpenAI 的业务合作伙伴协议（BAA）等选项，以支持符合 HIPAA 的使用。与 ChatGPT 分享的内容不用于训练模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在实践中，团队使用医用 ChatGPT 综合医学证据与机构指导，并将其应用于患者的具体情境、起草临床和行政文档，并调整面向患者的教育材料。这不但减少了行政工作的时间，帮助团队遵循共享的护理标准，还支持更好的患者体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;早期医院合作伙伴&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;医疗保健是增长最快的领域之一企业市场采用人工智能，医院和学术医疗中心已经在其团队中推广ChatGPT医疗服务。&lt;/p&gt;&lt;p&gt;相关链接：&lt;em&gt;https://openai.com/zh-Hans-CN/index/the-state-of-enterprise-ai-2025-report/&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;医疗领域的 OpenAI API&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;借助 OpenAI API 平台，开发者可以利用 OpenAI 最新的模型&amp;mdash;&amp;mdash;包括 GPT-5.2&amp;mdash;&amp;mdash;为工具和产品提供动力，并将 AI 直接嵌入医疗系统和工作流程中。&lt;/p&gt;&lt;p&gt;实际上，相关团队正在使用 OpenAI API 构建医疗应用，包括患者病历摘要、护理团队协调和出院工作流程。像Abridge、Ambience 和 EliseAI 这样的公司正在构建环境聆听、自动化临床文档和临床预约安排功能，服务于临床医生和患者。&lt;/p&gt;&lt;p&gt;API 平台：https://openai.com/zh-Hans-CN/api/&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为医疗保健优化的 AI 模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;所有 OpenAI for Healthcare 产品均由 GPT-5.2 模型驱动，这些模型优于早期 OpenAI 模型，并通过持续研究和真实评估开发，反映了临床医生实际使用 AI 的方式。&lt;/p&gt;&lt;p&gt;研发团队还会参考实际部署的证据。与&amp;nbsp;Penda Health&amp;nbsp;合作的一项研究发现，一个由 OpenAI 驱动的临床副驾驶在常规初级保健中使用减少了诊断和治疗错误&amp;mdash;&amp;mdash;早期证据表明，在适当的保障和临床监督下，AI 能够提升护理质量。&lt;/p&gt;&lt;p&gt;基准测试如健康台一项开放的临床医生设计评估，也强化了这一进展。在这些评估中，GPT-5.2 模型在真实临床工作流程中持续优于前几代和对比模型。在现实医疗任务中，GPT-5.2 在 GDPval 衡量的所有角色中表现优于人类基线， 超越了早期的 OpenAI 模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynxH1ZJObP6qfSpncSx9VYjAEodeUq7vgcS7dEVsH62JMeTI9qBgU3wA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5828220858895705" data-type="png" data-w="815" data-width="815" data-height="475" data-backw="546" data-backh="318" data-imgfileid="100027098" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/54a11074-520f-4866-8a07-7fd978ee02ef/640.png" alt="图片" data-before-load-time="1767940086190" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：HealthBench 共识专业人士挑战医疗专业人员工作流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一步发展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 团队表示，该公告建立在 OpenAI 在健康、生物制药和生命科学领域长期开展的工作基础上。这包括像 ChatGPT Health 这样的产品 ;与&amp;nbsp;Retro Biosciences&amp;nbsp;等公司合作，持续研究人工智能如何加速科学发现等。&lt;/p&gt;&lt;p&gt;他们坚信自己的使命是确保 AI 惠及全人类，并相信改善健康将成为 AI 的关键影响之一。相关团队将继续与使用 OpenAI for Healthcare 的医疗机构紧密合作，借鉴实际应用经验，进一步改进医疗产品。&lt;/p&gt;&lt;p&gt;原文链接：&lt;em&gt;https://openai.com/index/openai-for-healthcare/&lt;/em&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>深势科技发布Deploy-Master：一天部署5万个科学计算工具，这可能是Agentic Science真正的起点</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 09 Jan 2026 14:27:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnGculc4Prz33PHGkz398ynXAYmXG7qhEPKsUxDTbtSfia7CqXNR1P3iaz1QHHTc2eUmGvCxwJTxdIg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.5518518518518518" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="546" data-backh="301" data-imgfileid="100027095" data-aistatus="1" data-original-style="width:100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/83cf1206-a185-457d-af2b-dffd06b77bc1/640.jpeg" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;过去几十年里，科学计算领域积累了数量空前的开源软件工具。从生物信息学、化学模拟，到材料计算、物理仿真与工程设计，几乎每一个学科方向，都形成了自己的工具生态。在 GitHub 等平台上，成千上万个代码仓库声称可以被用于科研实践。&lt;/p&gt;&lt;p&gt;但一个长期存在、却始终没有被系统性解决的事实是：绝大多数科学软件，停留在「被发布过」，而不是「可以直接运行」的状态。&lt;/p&gt;&lt;p&gt;在真实科研实践中，我们往往需要花费数天甚至数周时间，反复解决编译失败、依赖冲突、系统不兼容等问题，才能在本地「勉强跑通」 一个工具。这样的运行环境高度依赖个人经验，往往是临时的、不可移植的，也很难被他人复现或复用。每个研究者、每个实验室，都在手工维护自己的运行环境，而不是在一个共享、可复现的执行基础设施之上开展工作。&lt;/p&gt;&lt;p&gt;这种模式带来的问题，并不只是效率低下。更关键的是，它在结构上限制了科学软件的三件事情：可复现性、大规模评估，以及系统性集成。即便容器化、云计算和 HPC 平台已经显著降低了算力门槛，这一「部署瓶颈」依然真实存在，并且长期制约着科学软件的可用性。&lt;/p&gt;&lt;p&gt;随着&amp;nbsp;AI for Science（AI4S）&amp;nbsp;的兴起，这一问题被进一步放大。在新的科研范式中，AI 系统不再只是输出预测结果，而是需要与真实的科学工具发生紧密交互：调用求解器、执行模拟程序、运行分析管线、处理真实数据。在这样的背景下，一个工具是否「真的能跑」，不再是工程细节，而是第一性问题。&lt;/p&gt;&lt;p&gt;这一问题在&amp;nbsp;Agentic Science&amp;nbsp;场景中表现得更加尖锐。如果工具依赖隐含环境、执行高度脆弱，那么智能体的规划将无法真正落地，执行失败也无法被结构化分析，更不可能转化为可学习的执行轨迹。从这个角度看，工具是否部署就绪，已经成为制约 AI4S 与 Agentic Science 规模化发展的结构性瓶颈。&lt;/p&gt;&lt;p&gt;基于这些观察，我们逐渐形成了一个判断：科学软件的问题，并不在于工具不够多，而在于缺乏一个能够将工具系统性转化为可执行事实的共享基础设施。Deploy-Master，正是在这一背景下被提出的。&lt;/p&gt;&lt;p&gt;在真实世界中，部署并不是一个孤立步骤，而是一条连续链路：工具能否被发现、是否被正确理解、能否构建环境，以及是否真的可以被执行。Deploy-Master 正是围绕这条链路，被设计为一个以执行为中心的一站式自动化工作流。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynfs5URBHobkyAhIzHwd8GCiaK5D74WXb4Zcefl8uicNSoOjk4AR9JicymQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5573440643863179" data-s="300,640" data-type="png" data-w="994" type="block" data-backw="546" data-backh="304" data-imgfileid="100027092" data-aistatus="1" data-original-style="width:100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/331c0e6f-ac51-48ef-8b14-4edff0446119/640.png" alt="图片" data-before-load-time="1767939985388" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Search Agent：百万级仓库搜索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大规模场景下，部署的第一个难题并不在构建，而在发现。如果候选工具集合本身存在系统性偏差，后续所有自动化都会被放大为偏差。&lt;/p&gt;&lt;p&gt;为此，我们从&amp;nbsp;91 个科学与工程领域出发，构建了一个覆盖 AI4S 实际应用场景的学科空间，并使用语言模型扩展搜索关键词，在 GitHub 与公共网络中进行大规模检索。初始召回得到的仓库，会作为「锚点」，通过依赖关系、引用关系、共享贡献者和文档链接等信号进行迭代扩展，从而避免仅依赖关键词搜索带来的盲区。&lt;/p&gt;&lt;p&gt;随后，我们通过结构启发式规则剔除明显不可执行的仓库，并由 Agent 进行语义判断，确认其是否构成一个可执行科学工具。通过这一多阶段漏斗流程，我们将最初约&amp;nbsp;50 万个仓库，收敛为&amp;nbsp;52,550 个进入自动部署流程的科学工具候选。这一步的意义，不仅在于筛选工具，更在于第一次以结构化方式刻画了真实科学工具世界的规模与边界。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="304" data-backw="546" data-imgfileid="100027093" data-ratio="0.5573440643863179" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynSrSm7TUcoKUAoqg8Y01IdYO6TARDlY8eP5mqNho1M6DFNR344tCtibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="994" type="block" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/afc7f5f6-58e5-485f-8fe2-5234e1056fd0/640.png" alt="图片" data-before-load-time="1767939985437" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Build Agent：双模型辩论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在构建阶段，我们面对的并不是一个「有明确说明书」的世界。大量科学软件仓库的构建信息是零散的、不完整的，甚至相互矛盾的。README 文件可能早已过期，已有 Dockerfile 也未必反映当前代码状态，而关键依赖往往只存在于作者本地环境中。&lt;/p&gt;&lt;p&gt;Build Agent 会系统性地遍历仓库中的构建线索，并在必要时进行补充信息检索，生成初始构建方案。早期实验表明，仅依赖单一模型生成构建规格，成功率只有&amp;nbsp;50%&amp;ndash;60%，失败主要源于构建信息中大量隐含、未被显式表达的假设。&lt;/p&gt;&lt;p&gt;为此，Deploy-Master 引入了双模型评审与辩论（debate）机制：一个模型提出构建规格，另一个模型独立审查并主动寻找潜在不一致、缺失依赖或环境假设，提出修正建议。两者通过多轮交互，不断修正方案，直到形成稳定、可执行的构建规格。这一机制将整体成功率提升到了&amp;nbsp;95% 以上。&lt;/p&gt;&lt;p&gt;每一个工具最终都会通过一个最小可执行命令进行验证。只有通过执行验证的工具，才会被视为成功部署，并被进一步结构化、注册和发布到玻尔与 SciencePedia 上，使其可以被直接使用，或被其他 Agent（例如 SciMaster）调用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynYETESg0HKySYeW4SBJDmf30dWE0QXh7bvbCTUzwpODoSlG7z6xibIUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5291750503018109" data-s="300,640" data-type="png" data-w="994" type="block" data-backw="546" data-backh="289" data-imgfileid="100027094" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/cd5254a1-d7b1-4b38-980a-c337254bb61c/640.png" alt="图片" data-before-load-time="1767939985487" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从构建时间的分布来看，大规模部署并不是一个「均匀」的过程。尽管大多数工具可以在 7 分钟左右完成构建，但整体分布呈现出明显的长尾特征。一部分工具仅包含轻量级脚本或解释型代码，构建过程相对简单；而另一部分工具则涉及复杂的编译流程、深层依赖以及系统级库配置，其构建时间显著更长。这种差异并不会阻止整体流程的推进，但它决定了部署在规模化条件下的成本结构。&lt;/p&gt;&lt;p&gt;在成功部署的 50,112 个工具中，我们观察到一个高度异构的语言分布。工具覆盖了&amp;nbsp;170 多种编程语言，其中 Python 占据了最大比例，其次是 C/C++、Notebook 形式的工具、R、Java 等。绝大部分语言部署成功率都稳定维持在较高水平。少数成功率相对较低的语言，主要集中在依赖复杂编译链或系统级库的场景，例如 C/C++、Fortran 以及部分 R 工具。这并不意味着这些语言「天生更难部署」，而是反映了其工具链对底层环境的耦合程度更高，从而放大了构建规格中的不确定性。从部署的角度看，语言本身并不是决定性因素，环境耦合强度才是。在 2,438 次失败的构建尝试中，我们对失败原因进行了系统性统计。结果显示，失败并非均匀分布，而是高度集中在少数几类问题上。最主要的失败来源是构建流程错误，包括构建步骤与仓库当前状态不一致、关键依赖缺失、编译器或系统库不匹配等。这类失败远远多于资源不足、网络异常或权限问题。与此同时，资源相关错误在高并发阶段也确实出现过，并直接推动了我们对调度策略和隔离机制的后续改进。这进一步说明，在规模化部署中，失败不应被视为异常，而应被视为系统暴露问题、进而自我修正的信号。&lt;/p&gt;&lt;p&gt;通过统一的执行基础设施，我们得以系统性地观察科学软件在真实环境中的部署行为：哪些环节最容易失败，哪些隐含假设最常被触发，哪些工具链最容易放大不确定性。这种可观测性本身，正是 Deploy-Master 希望建立的基础之一。它让「科学软件难以部署」从一种经验判断，转化为可以被量化、被分析、被持续改进的工程对象。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从可运行工具，到 Agentic Science 的执行地基&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Deploy-Master 的直接产出，是一个由数万条执行验证工具构成的集合。但更重要的是，它为 社区 Agent 与各类 Master Agent 提供了一个长期缺失的基础前提。&lt;/p&gt;&lt;p&gt;对 Agent 而言，工具调用并不是抽象动作，而是必须在现实环境中成功落地的执行过程。只有当工具被统一构建、验证并注册为可执行能力，Agent 才真正拥有稳定的 action space，规划、执行与学习之间的闭环才得以成立。这也使得不同来源的社区 Agent，可以共享同一批经过执行验证的工具能力，而不再各自维护脆弱、不可复现的运行环境。&lt;/p&gt;&lt;p&gt;这一方法论的意义，并不局限于科学计算。科学工具往往被视为自动化部署中最困难的一类：依赖复杂、系统耦合强、文档不完整、对环境高度敏感。如果在这样一个「最难场景」中，仍然可以通过以执行为中心的设计，在万级规模下稳定地产生可运行工具，那么结论已经非常清晰 &amp;mdash;&amp;mdash;&amp;nbsp;问题不在工具类型，而在于是否建立了以执行为核心的基础设施。&lt;/p&gt;&lt;p&gt;这一判断同样适用于更广泛的软件工具生态：工程工具、数据处理系统、专业软件乃至各类 Agent Tooling。只要工具最终需要被执行，其部署问题就无法绕开「不完美信息」这一现实前提。&lt;/p&gt;&lt;p&gt;Deploy-Master 并未解决所有问题。异构硬件、分布式计算、语义级 I/O 接口以及与物理实验系统的闭环集成，仍然是未来需要面对的挑战。但有一件事情已经足够清楚：在 Agentic Science 时代，执行不是推理之后的附属步骤，而是所有能力得以成立的前提。&lt;/p&gt;&lt;p&gt;当「工具能不能跑」不再是一个默认假设，而成为一个被系统性验证的事实，科学智能体才真正开始拥有与现实世界交互的基础。而 Deploy-Master，正是迈向这一执行现实的一次尝试。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一年后，DeepSeek-R1的每token成本降到了原来的1/32</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 14:24:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e939221b-d8bb-48af-a565-0ffeb2e39054/1767939614648.png" style="width: 700%;" class="fr-fic fr-dib"&gt;几天前，DeepSeek 毫无预兆地更新了 R1 论文，将原有的 22 页增加到了现在的 86 页。&lt;/p&gt;&lt;p&gt;新版本充实了更多细节内容，包括首次公开训练全路径，即从冷启动、训练导向 RL、拒绝采样与再微调到全场景对齐 RL 的四阶段 pipeline，以及「Aha Moment」的数据化验证等等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgia4L0oLW0vZibQORT3mweJ5uB4ULjTEVHolXyqhOJl3ADn563hXpEbNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527472" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/519d86c6-5f24-4379-90e3-d0ea6b89fba3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;DeepSeek-R1 是在 2025 年 1 月 20 日发布的开源推理大模型，它拥有 6710 亿参数、单 Token 激活参数为 370 亿，并采用了 MoE 架构，训练效率得到了显著提升。&lt;/p&gt;&lt;p&gt;R1 在去年的推出震动了全球 AI 领域，其高效率的模型架构、训练方法、工程优化和蒸馏方法在之后成为了全行业的趋势。&lt;/p&gt;&lt;p&gt;没想到在不到一年之后的今天，R1 模型的每 token 成本竟已降低了到了 1/32！&lt;/p&gt;&lt;p&gt;今天，英伟达发表了一篇长文博客，展示了其如何在 Blackwell GPU 上通过软硬协同对 DeepSeek-R1 进一步降本增效。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgbNOxKnEtyh6bfBXzbxcQcgg8X87WPoZlyibZLp8cttNd7hj3clZibshA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527473" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ecc8c14c-1198-4944-af78-921531e7c2aa/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着 AI 模型智能程度的不断提升，人们开始依托 AI 处理日益复杂的任务。从普通消费者到大型企业，用户与 AI 交互的频率显著增加，这也意味着需要生成的 Token 数量呈指数级增长。为了以最低成本提供这些 Token，AI 平台必须实现极高的每瓦特 Token 吞吐量。&lt;/p&gt;&lt;p&gt;通过在 GPU、CPU、网络、软件、供电及散热方案上的深度协同设计，英伟达持续提升每瓦特 Token 吞吐量，从而有效降低了每百万 Token 的成本。此外，英伟达不断优化其软件栈，从现有平台中挖掘更强的性能潜力。&lt;/p&gt;&lt;p&gt;那么，英伟达是怎样协同利用运行在 Blackwell 架构上的推理软件栈，以实现 DeepSeek-R1 在多种应用场景中的性能增益呢？我们接着往下看。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最新 NVIDIA TensorRT-LLM 软件大幅提升推理性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA GB200 NVL72 是一个多节点液冷机架级扩展系统，适用于高度密集型的工作负载。该系统通过第五代 NVIDIA NVLink 互连技术和 NVLink Switch 芯片连接了 72 个 NVIDIA Blackwell GPU，为机架内的所有芯片提供高达 1800 GB/s 的双向带宽。&lt;/p&gt;&lt;p&gt;这种大规模的「扩展域」（Scale-up Domain）专为稀疏 MoE 架构优化，此类模型在生成 Token 时需要专家之间频繁的数据交换。&lt;/p&gt;&lt;p&gt;Blackwell 架构还加入了对 NVFP4 数据格式的硬件加速。这是英伟达设计的一种 4 位浮点格式，相比其他 FP4 格式能更好地保持精度。此外，解耦服务（Disaggregated Serving）这类优化技术也充分利用了 NVL72 架构和 NVLink Switch 技术。简单来解释一下解耦服务，即在一组 GPU 上执行 Prefill（预填充）操作，在另一组 GPU 上执行 Decode（解码）操作。&lt;/p&gt;&lt;p&gt;这些架构创新使得 NVIDIA GB200 NVL72 在运行 DeepSeek-R1 时，能够提供行业领先的性能。&lt;/p&gt;&lt;p&gt;得益于最新 NVIDIA TensorRT-LLM 软件和 GB200 NVL72 的协同，DeepSeek-R1 在 8K/1K 输入 / 输出序列长度下的 Token 吞吐量大幅提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgrlKuVthIGlS3m4jI4jrGZ48vUr2FplkaFL2aGuHyiac5Q35Cf2QqbMg/640?wx_fmt=webp&amp;from=appmsg#imgIndex=3" data-ratio="0.5305555555555556" data-s="300,640" data-type="webp" data-w="1080" type="block" data-imgfileid="503527487" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/adc0e098-93c1-40a0-8c15-b1144a0515c4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同样地，得益于最新 NVIDIA TensorRT-LLM 软件与 GB200 NVL72 的协同，在 1K/1K 序列长度下，DeepSeek-R1 Token 吞吐量同样大幅提升。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527488" data-ratio="0.5361111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg8jrvMrADDslsWiaccoqolCCJ7icgBXFazA7ThsEleX99ZySxzuYNzyAw/640?wx_fmt=webp&amp;from=appmsg#imgIndex=4" data-type="webp" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b87cce71-dbd9-4526-b0f8-f2c6eaf92feb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;另外，在 8K/1K、1K/1K 两种输入 / 输出序列长度的吞吐量与交互性曲线上，GB200 NVL72 也展现出了领先的单 GPU 吞吐能力。&lt;/p&gt;&lt;p&gt;而 TensorRT-LLM 开源库（用于优化 LLM 推理）的最新增强功能，在同一平台上再次大幅增强了性能。在过去三个月中，每个 Blackwell GPU 的吞吐量提升高达 2.8 倍（这里指的是在 8k/1k 输入 / 输出序列长度下，去年 10 月到今年 1 月的 Token 吞吐量变化）。&lt;/p&gt;&lt;p&gt;这些优化背后的核心技术包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;扩大 NVIDIA 程序化依赖启动 (PDL) 的应用：降低核函数启动延迟，有助于提升各种交互水平下的吞吐量；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;底层核函数优化：更高效地利用 NVIDIA Blackwell Tensor Core；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;优化的 All-to-all 通信原语：消除了接收端的额外中间缓冲区。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有业内人士对英伟达放出的一系列图表进行了直观的解读，用一组数据来总结就是，「通过软硬件的深度协同，自 2025 年 1 月以来，英伟达已经将 DeepSeek-R1 (671B) 的吞吐量提升了约 36 倍，这意味着单 Token 的推理成本降低到了约 1/32。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg8fdMnzibNTaG1NQpnO0oiaBgC0rqEEwvjvr6nE0nBAWficHwxbicGtOFhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.28703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527489" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/bf3123f9-4fce-4b53-ba25-d8a8df6816fe/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKggk5rm2iaGib6yP6FJibgICaXNvjNbeEIuQeG6I5uhls0lwtLicZFmRvmgw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527490" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5fbb4283-0e6e-493e-9833-cc6c9b59465c/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;利用多 token 预测和 NVFP4 技术加速 NVIDIA HGX B200 性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA HGX B200 平台由八个采用第五代 NVLink 互连和 NVLink Switch 连接的 Blackwell GPU 组成，在风冷环境下也能实现强大的 DeepSeek-R1 推理性能。&lt;/p&gt;&lt;p&gt;两项关键技术使 HGX B200 上的 DeepSeek-R1 推理性能大幅提升。第一项技术是使用多 token 预测 (MTP)，它可以显著提高各种交互级别下的吞吐量。在所有三种测试的输入 / 输出序列组合中都观察到了这一现象。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgM4ONZ4icoALek7iaBE6AnTKbiaJbFktxpLQ0FMLWAtAViaQQh3JRqDbQTw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527491" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/68cc7a08-09a8-461b-9c53-4e72b2577820/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 HGX B200 平台上，使用 1K/1K 序列长度和聚合服务模式下，FP8（不带 MTP）、FP8（带 MTP）和 NVFP4（带 MTP）的吞吐量与交互性曲线对比。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;第二种方法是使用 NVFP4，充分利用 Blackwell GPU 计算能力来提升性能，同时保持精度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg7RSDM94UibGuaicCibyvoiaNINGLqUMPINgFs6TibNG02dibrUEicxYWbefnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.524074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527492" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f3d5dcd5-d69b-4ebc-919c-ec7b07b16c29/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 HGX B200 平台上，使用 8K/1K 序列长度和聚合服务模式下，FP8（不含 MTP）、FP8（含 MTP）和 NVFP4（含 MTP）的吞吐量与交互性曲线对比。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;NVFP4 使用在完整的 NVIDIA 软件栈上（包括 TensorRT-LLM 和 NVIDIA TensorRT 模型优化器），以确保高性能并保持精度。这使得在给定交互级别下能够实现更高的吞吐量，并且在相同的 HGX B200 平台上，可以实现更高的交互级别。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgmCtSeS5liaL4nFbadtrqDWuCNADm1A0esS82FkV0ickzV92ZkibmnmiczQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5268518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527493" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/8ea1569d-fd4b-4c0b-9916-f505321cb4a7/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 HGX B200 平台上，FP8（无 MTP）、FP8（有 MTP）和 NVFP4（有 MTP）的吞吐量与交互性曲线，序列长度分别为 1K 和 8K，并采用聚合服务模式。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;英伟达表示，其正在不断提升整个技术堆栈的性能，可以帮助用户基于现有硬件产品，持续提升大语言模型的工作负载效率，提升各种模型的 token 吞吐量。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;博客地址：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://developer.nvidia.com/blog/delivering-massive-performance-leaps-for-mixture-of-experts-inference-on-nvidia-blackwell/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Agent 2.0时代来了，首批「工业级智能体」正在核心位置上岗</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 13:36:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3053b7b0-a329-498f-a6a3-2e5c73315247/1767936811357.png" style="width: 700%;" class="fr-fic fr-dib"&gt;如果 AI 工具早一点出现，我们的很多工作会不会提前几年完成？&lt;/p&gt;&lt;p&gt;近日，整个科技圈都在感叹 AI 工具带来的效率提升。一些硅谷 AI 大厂工程师现身说法，表示在用了 AI 工具后，项目完成时长被大幅压缩。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gQx8wicEuks4jKu8YxecoePHbLW0Uu8mSOevnicquIpaNN0brXe0XJAicw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4846066134549601" data-s="300,640" data-type="png" data-w="877" type="block" data-imgfileid="503527368" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/778b6332-fea4-45ce-883a-4ad2789a8c4a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;谷歌首席工程师、Gemini API 负责人 Jaana Dogan 分享了她使用智能体的经历。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;有的人甚至认为，如果在读博的时候就有 Claude Code、Gemini 和 ChatGPT 等各类 AI 工具出现，那么也许只要一年就能毕业。&lt;/p&gt;&lt;p&gt;围绕 AI 智能体技术，一套全新的工作范式正在形成。在开发、数据分析等领域，人们的工作流程已经被 AI 彻底改变：把工作直接安排给大模型，只需要提供背景信息、元提示词，AI 就可以进行需求整理，将任务交给智能体去执行。&lt;/p&gt;&lt;p&gt;最近的一场发布，打开了智能体通向更多行业的突破口。&lt;/p&gt;&lt;p&gt;1 月 7 日，在阿里云飞天发布时刻上，阿里云百炼完成了面向智能体开发范式的一次全面升级。阿里云向行业证明：智能体「手工作坊」的时代结束了，「工业化流水线」时代正在开启。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;百炼升级了其提出的「1+2+N」的蓝图&lt;/strong&gt;：其中最底层的 1 是模型与云服务，中间层的 2 是高代码、低代码的开发范式，在最上层的 N 则是面向不同任务的开发组件。这套能力覆盖了生产级智能体构建的全生命周期。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gCiboBBuqOQT3x0pHsO0vQs6zLiaNiad7IqAlpfibI2hdskw526Bc0jV7Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527369" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/55926f9a-f278-49e5-a7ff-af92cfb67bcf/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;围绕这一框架，阿里云提供的能力，针对解决了智能体技术落地面临的一系列核心问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开发组件 &amp;nbsp;解决智能化核心挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前行业对于 AI 应用的焦点正在从验证可用性转向实际价值，为了让人们能够低门槛地快速用上智能体，百炼进行了大量应用组件的升级。&lt;/p&gt;&lt;p&gt;在百炼的应用广场上，目前已出现超过 10 类聚合主题，其中包含 146 个开箱即用模板（如子弹时间特效、会议图文纪要、AI 换装等），它们在原先支持开发者即开即用、二次开发的基础上继续升级，现在支持免登录体验、一键 API 调用，进一步降低了上手门槛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gP47ufkNdBdGZO2uO3Ik1prC5XzvvT0QR6OMRPpazic1gaZT7MaEQ3cQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6898148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527370" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2a22ecc5-ee28-4f31-b294-c0f1a45d6b1f/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大规模部署的智能体应用，必须能够整合利用多模态数据。如何将企业内部大量的多模态数据进行清洗、加工，转换为可复用、可查询的知识，是业务与 AI 结合的关键问题。&lt;/p&gt;&lt;p&gt;为了让智能体能够真正理解企业业务，把数据转化为可利用的知识，&lt;strong&gt;百炼升级了多模态知识库 RAG 能力，支持文档、图片、音频、视频等数十种文件类型的高精度解析与语义检索&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;依托通义向量模型和多模态向量模型，企业现在可以快速构建起专属 RAG 工具和高性能知识检索生成，让智能体实现多模态问答、商品图搜、视频监控检索等场景化应用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gJXcDaiadQzxia8bM3zZLK4tc3TFwPL3Aichgk27lYszshyf6fTcsViaNEQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.5374064837905237" data-s="300,640" data-type="gif" data-w="802" type="block" data-imgfileid="503527371" data-aistatus="1" data-original-style="width: 405px;height: 218px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/527098cc-0579-4ccd-9dbc-8a1c4193b2ed/640.gif" data-order="0" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 在阿里云百炼上构建多模态 RAG-音视频库。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了满足更加灵活的多模态数据处理场景，除了端到端形式的多模态知识库外，多模态处理能力也以节点的形式在工作流中提供了支持。文档、图片、音频、视频在内的全模态智能理解，都可以由用户通过画布来进行更加灵活的编排处理。&lt;/p&gt;&lt;p&gt;通过集成通义的多模态生成模型，人们可以内置包括图像生成、视频生成、音频生成能力，用于商品图制作、营销短视屏生成、智能客服、语音合成等业务场景。&lt;/p&gt;&lt;p&gt;阿里云也在打通不同平台的数据：&lt;strong&gt;百炼提供的 Connector 企业级数据连接器，现在能够一键对接钉钉、飞书、语雀等文档系统，以及 MySQL、OSS 等数据库。&lt;/strong&gt;通过数十种内置工具，智能体可直接、安全地检索并调用企业内部实时数据。&lt;/p&gt;&lt;p&gt;随着时间的推移，来自真实业务数据的不断反馈，基于百炼平台的智能体会逐渐变得懂业务流程、有专业知识、甚至懂话术，成为「企业专属员工」。&lt;/p&gt;&lt;p&gt;另外在真实场景的 AI 应用中，我们会遇到大量数据处理、信息抽取等复杂任务，它们需要长时间的运行和低成本的调用，百炼提供的能力打破了以往时间和成本的限制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69ghW23lB1EnW1O6uhl3UubpKciakCQ2sDfmicsp70XiaAzCM0WOJYTby7tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.48703703703703705" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527372" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2b52d340-ab51-4f6d-9e98-d6008482ece6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;面向大模型推理、长视频生成等耗时任务，阿里云百炼推出了异步调用 API&lt;/strong&gt;，它打破了同步接口调用 5 分钟的超时限制，可以延长到超过 24 小时，支持任务提交后轮询或回调获取结果，可以保障长周期任务稳定执行。&lt;/p&gt;&lt;p&gt;当智能体任务运行在阿里云上时，系统会自动对算力资源进行调度。&lt;strong&gt;结合实时、闲时资源请求动态调度能力，百炼的系统可以实现任务动态启停，满足不同的智能体推理需求。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;据介绍，百炼的闲时调度能让 AI 的推理成本降低 50% 以上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体开发框架 &amp;nbsp;高代码 + 低代码并行&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;应用层面之下，阿里云百炼提供方便的开发工具，可以更好地帮助人们构建智能体。&lt;/p&gt;&lt;p&gt;阿里云百炼构建了一套生产级智能体开发范式，针对真实的业务场景，在规划决策、信息管理、工具调用以及数据、服务连接等关键环节，用智能体的先进能力，重构了整个业务流程。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gcwqw228AbQ429eZO8SNxe5W7Kj3CFA3nShuqibFS1icRZPSOePVX6JvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.42314814814814816" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527374" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0faef883-d0fe-4ad9-b7c0-abd096cd4c0e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在企业内部，AI 的落地往往面临一个矛盾：懂业务的人不会开发，懂代码的人不了解业务。&lt;strong&gt;百炼平台提供的双模式开发能力，首次实现了高代码与低代码的并行。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;高低代码智能体使用了统一的开发框架和运行时，它令专业的开发者可以利用基于高代码框架灵活定制智能体逻辑，一键将代码包提交至云端托管，享受全链路的日志、网关与可观测能力；与此同时，业务人员可通过低代码界面快速配置模型、提示词、知识库与工具，可视化地搭建智能体。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gu2ibHAgGwCSibeUmq54R7zNMLOsNk7F1CVlBwykq6q1iatbNIO6nVnmdQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.5375" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503527375" data-aistatus="1" data-original-style="width: 423px;height: 227px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fb1d2ec1-ef5e-46f4-a00e-2474f6cbb1a6/640.gif" data-order="1" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 低代码构建深度搜索 Agent。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69goHVCZibC0biaBDXuoict9RXkWE5mJHx7a479IM8yOWPV03BEwJhlII2RA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.5366666666666666" data-s="300,640" data-type="gif" data-w="600" type="block" data-imgfileid="503527376" data-aistatus="1" data-original-style="width:429px;height:230px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/de94968e-a727-477c-9146-d88da474c00d/640.gif" data-order="2" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 高代码结合 Agent Identity 控制阿里云资源、钉钉文档。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;同时发布中提到，两种方式构建的智能体未来还将支持双向导出与部署 &amp;mdash;&amp;mdash; 低代码的开发成果可以转换成高代码。这种方式可以说是真正覆盖了企业内不同角色的开发需求。&lt;/p&gt;&lt;p&gt;现在，百炼平台的智能体应用能力已升级至 Agent 2.0 架构，从底层重塑了智能体的开发逻辑，完成了从「简单对话」向「目标导向的自主执行」的升级。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;升级后的「Agent 2.0」不仅具备强大的任务规划能力，更引入了「规划 - 执行 - 反思（Plan-Execute-React）」链路。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单来说，在 Agent 1.0 时代，调试智能体往就像是在「炼丹」，输入一个 Prompt，模型吐出一个结果，开发者难以理解其内部的推理逻辑；到了 Agent 2.0 时代，通过引入完整的跟踪链路，百炼把 AI 从意图理解、任务规划、工具调用、执行反馈再到自我优化的全流程实现了可视化。&lt;/p&gt;&lt;p&gt;为了构建 Agent 2.0，百炼平台的技术底座 &amp;mdash;&amp;mdash; 通义实验室的开源智能体框架 AgentScope 迎来了重大更新。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AgentScope 现在提供模型能力集成、多智能体编排、智能上下文管理和工具管理四大核心功能&lt;/strong&gt;，不仅有开箱即用的智能体，也带来了用于构建、优化、部署智能体的工具，可以真正地做到自发解决任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gnbSiankEXlBoHkjQQWozQVMzaRwbv6IZBVkfwNdPSZx43uaCsImrHyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.47685185185185186" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527377" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/232873d0-6346-4802-9e7f-ecb6f13bbebb/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在模型能力上，AgentScope 目前已经覆盖了主流大模型 API，支持了本地部署模型 API 服务，其全面支持包括文本、语音、视觉等多种模态的大模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AgentScope 支持智能体自主进行工具管理，包括 StreamableHTTP、SSE 和 STDIO 类型的 MCP，以及 Anthropic Agent Skill 的动态工具加载、卸载，让单智能体适用范围更广，能力更强。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在多智能体能力的构建上，AgentScope 采用动态图的应用编排方式，提供 MsgHub、pipeline 等语法糖，可快速实现多智能体间的信息传递、分享。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在长上下文支持方面，AgentScope 支持短期记忆自动压缩，内置 Mem0、ReMe 等长期记忆实现，支持智能体自主存储、检索向量数据库和长期记忆。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对不同行业方向，百炼还新增了通用型智能体平台 Alias，可以构建数字化助手。在 AgentZoo 上，人们可找到有关金融、数据科学、语音、问答等领域的智能体应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型与云服务 &amp;nbsp;面向真实业务&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在模型服务层面上，阿里云百炼进一步强化了企业级能力的可用性。升级后的模型广场支持结构化元数据展示与多模型对比，以及模型在线体验，能够帮助用户快速匹配业务需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g1gfqWeOz0IiaEnv9HZQGuvmcBmlNd0ZlHLBuFYShHoT55mtK6iaWYOZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527378" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/15bb11d3-628f-4abf-a7ec-b921ae659aa9/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在百炼的模型广场上目前已有 130 余款模型，最近新增的包括 Qwen-Image-Max、GLM-4.7、Wan2.6 视频生成系列、Qwen3-ASR-Flash 多语种识别等，人们还可以在其上对模型进行横向对比。&lt;/p&gt;&lt;p&gt;在生产环境中，阿里云百炼提供全链路的可观测体系，可以分别授权调用审计、推理日志，可以对模型实施全周期用量统计，多维度性能与用量指标都会被集成在业务系统中，方便统一运维管理。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于阿里自家的通义全系列模型，阿里云百炼提供了原生的训练微调能力，可以实现一站式的训练与部署&lt;/strong&gt;，帮助人们使用自己的业务数据构建定制化模型。百炼提供通义系列模型的全阶段 Checkpoint、混合数据训练与 GRPO/GSPO 强化学习算法支持，能够实现评测驱动的训练迭代。&lt;/p&gt;&lt;p&gt;值得一提的是，在通义模型和第三方模型的部署上，阿里云百炼新增了模型单元独占部署选项（模型单元），为高并发、低延迟业务提供专属算力，与此同时不需要专门管理底层资源，可以做到一键拉起部署。相比自建集群使用 vLLM、SGLang 等开源推理引擎，使用模型单元部署可以实现超过 1.3 倍的推理能力提升，以及 1.5 倍以上的并发能力提升。&lt;/p&gt;&lt;p&gt;在安全方面，百炼平台提出的机密推理服务基于 CPU/GPU TEE 可信执行环境，提供目前最高安全等级的模型推理能力。&lt;/p&gt;&lt;p&gt;从模型能力到实际的生产力，百炼为企业围绕自身业务构建智能化提供了底层支撑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 平台企业版发布&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最后，&lt;strong&gt;作为本次发布的「彩蛋」，阿里云百炼发布了 Agent 平台企业版，支持智能体在专有云、本地化与 VPC 的开发与部署&lt;/strong&gt;。人们可以基于高代码或低代码的开发方式使用不同模型、工具与数据快速构建符合自身业务需求的智能体，进而实现大模型业务流，并在落地的过程中进行全流程优化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69guqObibynCa1N9G7xOvnbicMyWfPT4s1cQ8sxtqcmEYUib9WwictTAd4fLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527379" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/abb2c724-fc08-46a7-8985-22fe946f1b67/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 91.99%;"&gt;&lt;/section&gt;&lt;p&gt;阿里云百炼的此次升级发布，一方面让智能体的构建变得严谨可靠，能够持续迭代，另一方面也让新技术可以进入更多行业，开发门槛变得更低。&lt;/p&gt;&lt;p&gt;2026 年一开年，OpenAI 的联合创始人、总裁 Greg Brockman 就对今年 AI 领域的主线剧情进行了预测，他认为这是一个「企业智能体与科研加速」年：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gbV8Wd4v0QxIYbVJH1RLYWNQ56rNnRhK8aP7C99LCCaxb9HfuXpWIiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.4151128557409225" data-s="300,640" data-type="png" data-w="1019" type="block" data-imgfileid="503527380" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/90669a93-b871-44fb-a4ca-0c64c021f91f/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;没想到业界对于大佬预测的回应如此之快。&lt;/p&gt;&lt;p&gt;随着阿里云百炼等更多 Agent 平台的发布和能力升级，当 AI 不再只是写文档、生成代码的工具，而是能够自主调用工具、分析数据并辅助决策的称职「数字化员工」时，真正的人机协同时代正在拉开帷幕。&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.aliyun.com/benefit/ai/discount?utm_content=g_1000409173"&gt;点击此链接，限时抢购 AI 焕新券，新客专享满20减10&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
