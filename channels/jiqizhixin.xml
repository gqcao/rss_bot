<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>百川开源全球最强医疗大模型M3，「严肃问诊」定义AI医疗新能力</title>
      <description>&lt;![CDATA[多指标性能更强大、幻觉率更低的医疗大模型]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 09:26:48 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;昨天，百川智能正式开源新一代医疗大模型 Baichuan-M3，其在全球最权威的医疗 AI 评测 HealthBench 中以 65.1 分的综合成绩位列全球第一；在专门考验复杂决策能力的 HealthBench Hard 上，也以 44.4 分的成绩夺冠。&lt;/p&gt;&lt;p&gt;这一成绩，不仅刷新了 HealthBench 的最高分，更首次在医疗领域实现了对 GPT-5.2 的全面超越。在 OpenAI 引以为傲的低幻觉领域，M3 也实现了超越，幻觉率 3.5 全球最低。&lt;/p&gt;&lt;p&gt;此外，M3 还首次具备了原生的 &amp;ldquo;端到端&amp;rdquo; 严肃问诊能力。它能像医生一样主动追问、逐层逼近，把关键病史和风险信号问出来，进而在完整的信息上进行深度医学推理。评测显示，其问诊能力显著高于真人医生的平均水平。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Hugging Face 地址：https://huggingface.co/baichuan-inc/Baichuan-M3-235B&lt;/li&gt;&lt;li&gt;GitHub 地址：https://github.com/baichuan-inc/Baichuan-M3-235B&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;医疗沟通和推理能力超越 GPT-5.2，登顶世界第一&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;2025 年 5 月份，OpenAI 发布 HealthBench，由 262 位来自 60 个国家的医生共同构建，收录了 5000 组高度逼真的多轮医疗对话，构建了全球最权威、也最贴近真实临床场景的医疗评测集。这一事件，被视为 OpenAI 在医疗领域开始 &amp;ldquo;重兵投入&amp;rdquo;，吹响进军医疗的号角。&lt;/p&gt;&lt;p&gt;相当长一段时间里，无论是 HealthBench 总分还是 HealthBench-Hard 子集， GPT 系列模型从未被超越。2025 年 8 月，百川开源医疗增强大模型 M2 在 HealthBench 上力压 gpt-oss-120B、DeepSeek-R1 等同期所有开源模型，并在 HealthBench Hard 上取得 34.7 分的成绩，仅次于 GPT-5，成为全球唯二突破 32 分的模型。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/af4c0af2-6825-42b4-a119-489baef87e5c/1768353665316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2025 年，强化学习无疑是新一代 Scaling Law 的技术中轴。在 M2 发布后的五个月里，百川智能对强化学习系统进行了全面升级，将原本以患者模拟器和静态 Rubric 为主的半动态反馈，升级为随模型能力不断演进的全动态 Verifier System。随着监督信号持续变细、变难，模型得以不断突破能力上限，使 M3 在复杂医学问题上的表现实现跃迁，不仅在 HealthBench 总分上超越 OpenAI 最新模型 GPT-5.2，也在 HealthBench Hard 上登顶，成为当前全球医疗沟通和推理能力最强的医疗大模型。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;重构幻觉抑制的训练范式，刷新医疗幻觉率底线&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;幻觉是这一代大模型技术范式的通病，更是 AI 进入严肃医疗的拦路虎。在大多数场景幻觉只是体验问题，而在严肃医疗场景可导致安全事件。&lt;/p&gt;&lt;p&gt;降低幻觉，一直是 OpenAI 最重视的研究方向之一。几乎每一代 GPT 模型的幻觉率均为行业最低。OpenAI 也是第一个单独评测医疗能力和提供医疗服务的通用模型公司。&lt;/p&gt;&lt;p&gt;国内 DeepSeek 等模型的普及，让越来越多人开始使用 AI 并尝试进行医疗健康咨询。但大多数模型公司并没有把 &amp;ldquo;降幻觉&amp;rdquo; 提升到与推理、代码等相同的高度。用这样的模型获取健康咨询和诊疗建议，对 AI 医疗的普及和医患信任建立带来很大困扰。&lt;/p&gt;&lt;p&gt;百川 M3 将医疗幻觉抑制前移至模型训练阶段，在强化学习过程中将医学事实一致性作为核心训练目标之一，将 &amp;ldquo;知之为知之，不知为不知&amp;rdquo; 直接作用于模型自身能力的形成过程。这一新的训练方法将医学事实可靠性内化为 M3 自身的基础能力，使其在不借助任何外部系统的情况下，依然能够基于自身医学知识进行稳定、可信的作答。&lt;/p&gt;&lt;p&gt;通过将事实一致性约束融入训练流程，M3 重构了幻觉抑制的训练范式，在不依赖工具或检索增强的纯模型设置下，医疗幻觉率 3.5，超越 GPT-5.2，达到全球最低水平。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26310800-527a-4066-a8ff-63241be5aea9/1768353715138.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;h3 style="text-align: center;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;构建「严肃问诊」新能力，端到端问诊超越真人医生&lt;/strong&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;p&gt;除了强推理和低幻觉，端到端的问诊能力是本次 M3 最重要的一项突破。2025 年行业的技术共识是，用户提供更完整的上下文，模型才有更好的表现。可在医疗领域，患者很难完整表达自己的病症，需要模型像医生一样有能力把患者的混乱叙述转变成可做诊疗决策的信息。&lt;/p&gt;&lt;p&gt;HealthBench 代表了 OpenAI 对临床场景的认知高度，然而它本质上是一个切片式的评测，考核的更像是 &amp;ldquo;AI 会不会回答问题&amp;rdquo;，而不是带着诊疗目标，完整的患者信息收集。这也正说明了行业对问诊重要性和建模思路的理解不足。&lt;/p&gt;&lt;p&gt;应用实践中，通过 prompt &amp;ldquo;你是一位经验丰富的医生&amp;rdquo;，激活模型的 &amp;ldquo;角色扮演&amp;rdquo; 是更常见的做法。这种方式得到的是模型的表演行为，而非内生能力，激活的是模型应该提问的行为，而不是必须获取关键信息的思考。例如，临床医生面对患者的第一反应，永远是先排除危急重症，再考虑常规诊疗，这是刻在职业本能里的安全优先级。但常见的 &amp;ldquo;角色扮演&amp;rdquo; 的问诊方式，无法将 &amp;ldquo;红旗征识别与处置&amp;rdquo; 作为核心行动原则。这种不围绕关键风险点展开的信息收集，即便对话看似完整，也难以支撑安全、可靠的临床判断，从根本上偏离了医疗 &amp;ldquo;安全第一&amp;rdquo; 的原则。&lt;/p&gt;&lt;p&gt;针对这一行业困境，百川智能提出了 &amp;ldquo;严肃问诊范式&amp;rdquo; 与 &amp;ldquo;SCAN 原则&amp;rdquo;，通过 Safety Stratification（安全分层）、Clarity Matters（信息澄清）、Association &amp;amp; Inquiry（关联追问）与 Normative Protocol（规范化输出），将临床问诊中高度依赖经验的思维过程，第一次系统性地 &amp;ldquo;白盒化&amp;rdquo;。&lt;/p&gt;&lt;p&gt;围绕 SCAN 原则，百川智能借鉴医学教育里长期使用的 OSCE 方法，联合 150 多位一线医生，搭建了 SCAN-bench 评测体系，该体系以真实临床经验作为 &amp;ldquo;标准答案&amp;rdquo;，将诊疗过程拆解为病史采集、辅助检查、精准诊断三大阶段，通过动态、多轮的方式进行考核，完整模拟医生从接诊到确诊的全过程。相比于 HealthBench，SCAN-bench 是更加全流程端到端的动态评测新范式。&lt;/p&gt;&lt;p&gt;同时，百川智能还使用原生模型训练方法取代角色扮演 prompt，针对 GRPO 无法稳定进行长对话训练的问题，设计了新的 SPAR 算法，使模型能够在有限对话轮次中，把临床真正需要的关键问题问全、问准，把风险兜住，让输出经得起复核。&lt;/p&gt;&lt;p&gt;在实验过程中发现，问诊准确度每增加 2%，诊疗结果准确度就会增加 1%。评测结果显示，M3 在 SCAN 的四个维度均显著高于人类医生基线水平，并大幅领先于国内外顶尖模型，成功构建了从精准的临床问询、深度医学推理到安全可靠决策的闭环。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f0ee5beb-e7ff-4129-87fe-9ea83c3ad5b4/1768353751451.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;从 1 月初 OpenAI 发布医疗产品 ChatGPT Health，到今天 Anthropic 推出 Claude for Healthcare，AI 医疗正在全球范围内提档加速，竞争也正式进入深水区。在这场竞速中，作为国内唯一专注医疗的大模型企业，百川持续突破低幻觉率、端到端问诊和复杂临床推理等核心能力，已从 &amp;ldquo;跟随者&amp;rdquo; 跃迁为行业 &amp;ldquo;引领者&amp;rdquo; 与新范式的 &amp;ldquo;定义者&amp;rdquo;，正以硬核实力扛起中国 AI 医疗发展的旗帜。&lt;/p&gt;&lt;p&gt;百川智能的医疗应用 &amp;ldquo;百小应&amp;rdquo; 已同步接入 M3，面向医生与患者开放相关能力。医生可借助它推演问诊与诊疗思路，患者及家属也可通过该应用更系统地理解诊断、治疗、检查与预后背后的医学逻辑。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>相约AAAI 2026 | 上海AI实验室北极星 X 星启交流会（报名开启）</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 18:16:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-pm-slice="0 0 []"&gt;2026年1月20日至27日，第40届AAAI人工智能会议（AAAI 2026）将在新加坡召开。期间，上海人工智能实验室（上海AI实验室）将举办&amp;ldquo;&lt;strong&gt;北极星X星启交流会暨云帆AI Talent Meetup&lt;/strong&gt;&amp;rdquo;。届时，实验室相关领域专家将亲临现场，与全球同行展开深度交流与研讨。&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;诚邀AAAI论文作者，人工智能、自然科学、工程科学等多学科交叉领域的教授、博士后，以及产学研各界的创新实践者参加，共探探前沿技术。截至目前，&amp;ldquo;北极星&amp;rdquo;交流会已在中国、美国、新加坡、加拿大等地成功举办多场，为数千名AI英才连接全球机遇。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;&lt;span data-mpa-action-id="mgrf9l7z1mku" data-pm-slice="0 0 []"&gt;报名信息&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;strong&gt;交流会为邀约制&lt;/strong&gt;，请扫描下方二维码或点击文末阅读原文，提交报名信息。审核通过后，将收到邀请函邮件。席位有限，请即报名。&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp58IHScqCRlbkticruibeWyibCCrRYkKiafheZSia6wlVSibPqib57Inyiaf0WrA/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=1" alt="图片" data-ratio="1.3175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100079745" data-aistatus="1" data-original-style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;vertical-align: bottom;height: auto !important;width: 244px !important;visibility: visible !important;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/77b14239-14ff-47a3-8596-e273d2375209/640.png" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;截止时间：&lt;/strong&gt;1月19日12:00p.m.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;咨询邮箱&lt;/strong&gt;：&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"font-size: 16px;color: rgb(62, 62, 62);margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-bottom: 10px;width: 100%;align-self: flex-start;padding: 12px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: center;justify-content: center;display: flex;flex-flow: row;width: 100%;align-self: flex-start;background-color: rgb(255, 255, 255);padding: 14px 17px;box-shadow: rgb(225, 233, 246) 0px 0px 8px 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: justify;line-height: 2;letter-spacing: 1px;font-size: 15px;color: rgb(80, 100, 115);width: 100%;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"data-pm-slice":"0 0 []","style":"margin-bottom: 24px;text-align: left;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;luochen&lt;/span&gt;@pjlab.org.cn&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mpa-action-id="mgrf9haq1qc4" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;活动信息&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp50C1ufP8PWyBS5nSXFcc1fsB48dInzRQmMmK6k0dw9SJnibW7kRMcWQA/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=2" alt="图片" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp50C1ufP8PWyBS5nSXFcc1fsB48dInzRQmMmK6k0dw9SJnibW7kRMcWQA/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="316" data-backw="562" data-backh="316" data-imgfileid="100079737" data-aistatus="1" data-original-style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;vertical-align: bottom;height: auto !important;width: 661px !important;pointer-events: initial;visibility: visible !important;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/33f758d5-800b-4123-83be-7bda2c86070d/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;活动亮点：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖学术分享&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;上海AI实验科学家创新成果分享、前沿技术主题演讲，激发科研灵感。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;实验室直通车：&lt;/strong&gt;与上海AI实验室团队负责人零距离交流，直通核心科研、工程岗位。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;产学资源直通：&lt;/strong&gt;上海AI实验室特邀合作科研机构、高校及企业神秘嘉宾分享，解锁前沿技术洞察。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;活动时间&lt;/strong&gt;：1月22日17:30-20:30(新加坡时间)&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"font-size: 16px;color: rgb(62, 62, 62);margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: flex;width: 100%;flex-flow: column;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"z-index: 1;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: inline-block;width: auto;vertical-align: top;align-self: flex-start;flex: 0 0 auto;border-left: 1px solid rgb(0, 79, 132);border-bottom-left-radius: 0px;padding-left: 13px;min-width: 5%;height: auto;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: justify;font-size: 15px;color: rgb(0, 79, 132);line-height: 2;letter-spacing: 1px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"font-family: \"mp-quote\", -apple-system-font, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Hiragino Sans GB\", \"Microsoft YaHei UI\", \"Microsoft YaHei\", Arial, sans-serif;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;活动地点&lt;/strong&gt;：&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"font-size: 16px;color: rgb(62, 62, 62);margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: flex;width: 100%;flex-flow: column;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"z-index: 1;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: inline-block;width: auto;vertical-align: top;align-self: flex-start;flex: 0 0 auto;border-left: 1px solid rgb(0, 79, 132);border-bottom-left-radius: 0px;padding-left: 13px;min-width: 5%;height: auto;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: justify;font-size: 15px;color: rgb(0, 79, 132);line-height: 2;letter-spacing: 1px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"font-family: \"mp-quote\", -apple-system-font, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Hiragino Sans GB\", \"Microsoft YaHei UI\", \"Microsoft YaHei\", Arial, sans-serif;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;新加坡中心城区&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;议程速览&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp5CsOSBubByBo6SBWjKczwKsZ5OSQ6mSdumklvtwmy2s67oiaazcibjx9A/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=3" alt="图片" data-ratio="0.7929515418502202" data-s="300,640" data-type="png" data-w="681" type="block" data-imgfileid="100079744" data-aistatus="1" data-original-style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;vertical-align: bottom;height: auto !important;visibility: visible !important;width: 603px !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3120497a-c92e-407c-b387-9bd1da5c25ec/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; *（以现场实际议程为准）&lt;/sup&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;We Want You！&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;上海人工智能实验室是国际级人工智能新型科研机构，采取有组织科研与原创探索深度融合的研究范式，开展前瞻性、基础性重大科学问题研究和关键核心技术攻关，凝聚和培养高水平人才，打造&amp;ldquo;突破型、引领型、平台型&amp;rdquo;一体化的大型综合性研究基地，目标建成世界一流的人工智能实验室，成为享誉全球的人工智能原创理论和技术的策源地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在这里，你将获得：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶级科研平台与资源&lt;/strong&gt;：超大规模算力集群和数据支持，投身具备规模化潜力、强泛化能力、长期价值的研究。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全球化创新团队协作&lt;/strong&gt;：参与跨团队、跨领域的重大项目，实现研究能力的指数级跃升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;清晰的职业发展通道&lt;/strong&gt;：由实验室出题，链接顶尖高校、科研机构和行业企业，助力承担重大项目，持续做有影响力的研究，获得在产业中验证价值的机会。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>视觉模型既懂语义，又能还原细节，南洋理工&amp;商汤提出棱镜假说</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 18:12:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/e660baee-2056-466c-a3f6-be1f3af836e1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作者来自 Nanyang Technological University（MMLab） 与 SenseTime Research，提出 Prism Hypothesis（棱镜假说） 与 Unified Autoencoding（UAE），尝试用 &amp;ldquo;频率谱&amp;rdquo; 的统一视角，把语义编码器与像素编码器的表示冲突真正 &amp;ldquo;合并解决&amp;rdquo;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAlyWBy1KknQm5lsFTk7N8U9xgTQCejxkVg5aGn1Q5U4mluIakaGTbiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527982" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/db9d9c4e-202c-4bc5-b35f-1ba97c6b3873/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; line-height: 1.75em; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库：https://github.com/WeichenFan/UAE&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/pdf/2512.19693&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;背景：为什么 &amp;ldquo;懂语义&amp;rdquo; 和 &amp;ldquo;还原细节&amp;rdquo; 总是很难兼得？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在视觉基础模型里，我们经常同时依赖两类能力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;语义理解：像 DINOv2 / CLIP 这类 &amp;ldquo;语义编码器&amp;rdquo; 更擅长类别、属性、关系等抽象信息；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;像素保真：像 SD 系列 VAE 这类 &amp;ldquo;像素编码器&amp;rdquo; 更擅长纹理、边缘、小字等细节重建。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但现实问题是：很多系统被迫把两套表示 &amp;ldquo;拼在一起用&amp;rdquo;：语义一套、像素一套，训练效率下降、表示互相干扰、而且很难得到一个既 &amp;ldquo;语义强&amp;rdquo; 又 &amp;ldquo;细节强&amp;rdquo; 的统一潜空间。&lt;/p&gt;&lt;p&gt;论文把这种矛盾归结为一个更本质的问题：世界的信息到底如何被表示，才能既共享语义，又保留各自模态的细粒度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心洞察：Prism Hypothesis（棱镜假说）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAWqF4P42Toh1Q6FPhR2FSfjUOSp0O2qT8swiaQvznZpYJericuJGS3G2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.35833333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527983" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a4a342d3-1f58-491d-a30a-8d15a8d090e1/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文给出了一个非常直观的统一解释：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;可以把真实世界的输入看成投影到同一条 &amp;ldquo;特征频谱&amp;rdquo; 上的不同切片；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;低频更像 &amp;ldquo;全局结构 / 语义&amp;rdquo;（类别、布局、关系）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高频更像 &amp;ldquo;局部细节 / 质感&amp;rdquo;（纹理、边缘、微小文字）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkASABicp8ERgu38QzfV9hjiagSHrh9w8NwniclLlnyB2ZbY2S5n2IUx83vA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8926380368098159" data-s="300,640" data-type="png" data-w="652" type="block" data-imgfileid="503527984" data-aistatus="1" data-original-style="width:437px;height:390px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1240001c-b582-47c1-90d6-6ecf03a00aa1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQibNibnpfUFQwicrDn4fG7l8VJekgNibicZtrLOjI7IutTvdia6as4ibkt8bQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9079754601226994" data-s="300,640" data-type="png" data-w="652" type="block" data-imgfileid="503527985" data-aistatus="1" data-original-style="width:453px;height:411px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1fd75430-ac2c-43c9-ac4a-fe639d0243e3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了验证，作者做了两类证据：&lt;/p&gt;&lt;p&gt;1. 能量谱分析：语义编码器（如 DINOv2、CLIP）能量更集中在低频，而像素型编码器（如 SD-VAE）保留更多中高频细节。&lt;/p&gt;&lt;p&gt;2. 频率过滤下的检索鲁棒性：文本 - 图像检索的 R@5 在低通情况下较稳定，但在高通 / 去掉低频基座后会明显崩塌、趋近随机，说明跨模态语义对齐主要来自共享低频基座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法：Unified Autoencoding（UAE）怎么把两种表示 &amp;ldquo;合成一套&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYIlvy9UO0cVsUxC2sYDuT2wbP3Zz6G2uItz94tJNyfhP8TCz0libcicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.43796296296296294" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527994" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/30d4043c-d040-4f3b-b097-b2ed3ee09930/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;围绕 &amp;ldquo;低频语义基座 + 高频细节残差&amp;rdquo; 的思路，UAE 的核心是把一个统一编码器学成多频段潜变量，并把 &amp;ldquo;语义该管什么、细节该放哪里&amp;rdquo; 结构化地拆开。&lt;/p&gt;&lt;p&gt;1) Unified Encoder：从语义编码器初始化，走向统一潜空间&lt;/p&gt;&lt;p&gt;以 DINOv2 为例，UAE 的统一编码器从预训练语义模型初始化，进入后续频域处理。&lt;/p&gt;&lt;p&gt;2) Residual Split Flow：在频域做 &amp;ldquo;可控的分带分解&amp;rdquo;&lt;/p&gt;&lt;p&gt;UAE 用 FFT 做频段投影（平滑径向 mask），并采用迭代残差拆分，把潜变量拆成多个频带：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低频带（低频）承载语义 / 全局结构&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更高 band（高频）逐步承载边缘、纹理等细节残差&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;同时强调分解的可逆性与空间一致性。&lt;/p&gt;&lt;p&gt;3) Frequency Band Modulator：只 &amp;ldquo;扰动细节&amp;rdquo;，再做频带融合给解码器&lt;/p&gt;&lt;p&gt;训练时对高频带进行噪声扰动以增强鲁棒性；然后把各频带在通道维拼接，融合后作为解码器唯一输入。&lt;/p&gt;&lt;p&gt;4) Semantic-wise Loss：语义只约束低频，细节放开学像素&lt;/p&gt;&lt;p&gt;为了既继承语义先验、又扩展到高频细节，UAE 的语义对齐损失只施加在最低频的前 K 个 band 上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低频对齐 ；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高频不强行对齐；&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;论文也明确把 UAE 定位为 tokenizer，并强调其 &amp;ldquo;能与现有 diffusion transformers 无缝对齐&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：一个潜空间，同时要 &amp;ldquo;语义&amp;rdquo; 也要 &amp;ldquo;细节&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重建质量（ImageNet / MS-COCO）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 256&amp;times;256 重建任务上，UAE（DINOv2-L）在 ImageNet 上达到 PSNR=33.08、SSIM=0.94、rFID=0.16，在 MS-COCO 上达到 PSNR=32.84、SSIM=0.94、rFID=0.17。&lt;/p&gt;&lt;p&gt;同时，论文指出在相同 DINOv2 编码器设置下，UAE 相比 RAE 基线在 PSNR/SSIM 更高，并且 rFID 下降超过 90%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQbfSGFIzcNxvJaQhpNgbwj4CCVp24LicXwN9LBb2d5umseVdBjj9VicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527993" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3b472157-8e1a-4925-be2a-45af2e416de9/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8gsIlkgTIQBb5b7xtkeBcFo0y75tyZcqhm06TZj4o54RQOvViczs6LA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6981481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527992" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/75698afb-c8f5-4548-8d4f-816599178f88/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;生成能力（ImageNet 类条件生成）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 ImageNet 256&amp;times;256 类条件生成上，UAE 达到 gFID=1.68、IS=301.6。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语义理解（Linear Probing）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 ImageNet-1K 上，UAE 在 ViT-B 骨干下达到 Top-1=83.0%，与 RAE 持平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMjYwA7DgZzEPRzxaeqr6nDLCwFHw0JroeNt66abjhWOlyOARSYicojA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6720257234726688" data-s="300,640" data-type="png" data-w="933" type="block" data-imgfileid="503527989" data-aistatus="1" data-original-style="width:451px;height:303px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/53fda450-4656-4265-b4a4-b9bf39e9c759/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQf2MWEa8VMj8URg64icooqF6dfzibkcuEvsNrLBwx5QrpOIGhzMSQichQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.7563291139240507" data-s="300,640" data-type="png" data-w="948" type="block" data-imgfileid="503527990" data-aistatus="1" data-original-style="width:475px;height:359px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/93db05ef-c2e0-4b8a-be82-8db8edb6aadf/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>无需重新训练，即可学习新任务，Arc研究所开源单细胞基础模型Stack及细胞反应全景图谱</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Tue, 13 Jan 2026 16:25:14 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027134" data-ratio="0.5194444444444445" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLm0558h8aSPtXwRembmSujZkmIkIc0YaYsWD7WTXmXnPF6icxBKmg1nMRyZ29LDfibb3xJILGMb4IiaA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/2a33a020-7f98-4bb0-9f6c-9669402a2bd8/640.jpeg" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑丨coisini&lt;/span&gt;&lt;/p&gt;&lt;p&gt;单细胞转录组学技术为测量跨物种、跨疾病及各类生物条件下的细胞表型多样性提供了可能。去年，Arc 研究所发布了一个名为「State」的虚拟细胞模型，证明了使用细胞集合进行分析能提升扰动响应的预测能力。&lt;/p&gt;&lt;p&gt;然而，最核心的挑战依然存在：能否构建一个通用模型，无需特定环境的扰动数据即可预测细胞在全新环境中的反应？&lt;/p&gt;&lt;p&gt;现在，Arc 研究所宣布推出开源基础模型 Stack&amp;mdash;&amp;mdash; 该模型通过两项关键创新延伸了「细胞集合」理念，并在上述问题上取得突破性进展。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027129" data-ratio="0.21944444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLm0558h8aSPtXwRembmSujZLMlnLoticUrVjyxN4pzAWvfzzUibsvmEzOWYao8BhdmZQicdqfghjzCZA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/0814fc62-5253-44ad-8544-8a281fecdb32/640.jpeg" alt="图片" data-before-load-time="1768292670330" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文地址：https://www.biorxiv.org/content/10.64898/2026.01.09.698608v1&lt;/p&gt;&lt;p&gt;开源地址：https://github.com/ArcInstitute/stack&lt;/p&gt;&lt;p&gt;Stack 基础模型在 1.49 亿个标准化预处理的人类单细胞数据上进行训练，通过表格注意力机制生成基于上下文细胞信息的细胞表征。与基线模型相比，Stack 在零样本场景的下游任务中实现了显著性能提升。&lt;/p&gt;&lt;p&gt;开源基础模型 Stack&lt;/p&gt;&lt;p&gt;Stack 能够从代表任意条件的未标记细胞中进行上下文学习，并预测这些条件对目标细胞群的影响，而无需针对特定数据进行微调。通过两项关键创新，Stack 拓展了「细胞集合」理念：&lt;/p&gt;&lt;p&gt;首先是架构创新。Stack 采用表格化 Transformer 模块，将单细胞数据处理为包含细胞与基因的二维表格，使信息既能在单个细胞内流动（基因间关联），也能在细胞间传递（细胞间关联）。这种设计使模型能更好地捕捉生物学背景：炎症组织中的 T 细胞行为差异不仅源于自身基因，更受细胞环境影响。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027130" data-ratio="0.7222857142857143" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm0558h8aSPtXwRembmSujZXvc5Fdpz9m9tfLjDhGEEGpH92m9aDu27csIX0lbdho8T1BBwibxFpIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="875" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/fcf1d118-32ab-4441-b774-a5683d240725/640.png" alt="图片" data-before-load-time="1768292670355" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Stack 还创新性地引入可训练的「基因模块表征符」，通过多基因衍生的生物组件描述细胞状态，而非独立建模每个基因，使模型兼具更强可解释性与更高训练效率。&lt;/p&gt;&lt;p&gt;其次是训练策略创新。Stack 基于 scBaseCount 数据库中 1.49 亿个细胞（涵盖数百种组织、疾病、供体及状态）进行预训练，使其内化决定细胞环境的生物学关联。随后通过对公共数据库 CellxGene 和 Parse PBMC 中 5500 万个细胞进行后训练，Stack 学会了将一组细胞作为「提示指令」，指导其对另一组细胞的预测。&lt;/p&gt;&lt;p&gt;正如文本提示能引导语言模型生成回应，对 Stack 来说，细胞就是 prompt，界定着影响预测的生物学条件。例如，Stack 可观察经药物处理的免疫细胞，进而预测上皮细胞对同一药物的反应。&lt;/p&gt;&lt;p&gt;Stack 是首个能够在推理时无需重新训练即可学习新任务的单细胞基础模型。这种能力使其在标准测试中表现卓越。&lt;/p&gt;&lt;p&gt;研究团队采用严谨的扰动预测评估框架 cell-eval，结合疾病分类与细胞类型整合等标准任务对 Stack 进行评估。在各项测试中，Stack 的表现始终优于其他方法。在扰动预测指标上，Stack 更是全面超越现有方案，证明了零样本基础模型足以与专业定制方法相媲美。&lt;/p&gt;&lt;p&gt;Perturb Sapiens：&lt;/p&gt;&lt;p&gt;预测性细胞反应全景图谱&lt;/p&gt;&lt;p&gt;为了展现 Stack 模型的能力并为该领域创建新资源，研究团队开发了 Perturb Sapiens&amp;mdash;&amp;mdash; 一个基于 Tabula Sapiens 数据预测细胞反应的图谱。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027133" data-ratio="0.5055555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm0558h8aSPtXwRembmSujZbd6AXfAQY6hv7b7kUcOnJttFGs7cmlPggcZ6gj1cCWCPlKFSXPXVTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/15605f64-3074-44bb-b046-7d0c81750fdd/640.png" alt="图片" data-before-load-time="1768292670588" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Perturb Sapiens 解决了基础实验的空白：绝大多数「细胞类型 - 组织 - 扰动」组合从未被测量过。即便仅全面测试其中一小部分组合，也需要耗费数百万美元和数年实验工作。&lt;/p&gt;&lt;p&gt;为创建该图谱，该研究利用模型的上下文学习能力，将免疫细胞反应「翻译」至整个人体系统。针对每种扰动，Stack 模型通过观察免疫细胞反应，预测 Tabula Sapiens 中每种组织内所有细胞类型的反应，最终生成了约 20000 个预测的「细胞类型 - 组织 - 扰动」组合。&lt;/p&gt;&lt;p&gt;Perturb Sapiens 有何用途？某种对免疫细胞作用强烈的药物，可能对同组织的上皮细胞或基质细胞几乎无影响。干扰素信号在肺上皮与肠上皮中会产生不同的转录组特征。某些药物和细胞因子能在差异显著的细胞类型中激活相似的反应程序，暗示其存在共同的易感性机制。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027131" data-ratio="0.5574074074074075" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLm0558h8aSPtXwRembmSujZLSun4uu0BXDBLQ9WssAYKkeTDmaaKj34O6zvYzYGnWEtCs3wpI59pg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/56a49f5a-acbb-4d91-9a59-c68b442eb502/640.jpeg" alt="图片" data-before-load-time="1768292670628" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Perturb Sapiens 开源地址：https://huggingface.co/datasets/arcinstitute/Perturb-Sapiens&lt;/p&gt;&lt;p&gt;感兴趣的读者可以阅读论文原文，了解更多研究内容。&lt;/p&gt;&lt;p&gt;参考内容：https://arcinstitute.org/news/foundation-model-stack&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>不上云、不租卡，如何优雅地在本地微调Qwen-VL-30B？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:39:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9e5b9119-5d5e-4841-87c6-b36c5b804f42/1768278956181.png" style="width: 700%;" class="fr-fic fr-dib"&gt;假如你是一个致力于将 AI 引入传统行业的工程团队。现在，你有一个问题：训练一个能看懂复杂机械图纸、设备维护手册或金融研报图表的多模态助手。这个助手不仅要能专业陪聊，更要能精准地识别图纸上的零件标注，或者从密密麻麻的财报截图中提取关键数据。&lt;/p&gt;&lt;p&gt;首先，你需要选择一个合适的模型。&lt;/p&gt;&lt;p&gt;7B 参数的小模型虽然跑得快，但「脑容量」太小，面对复杂的图文逻辑经常一本正经地胡说八道；而 70B 甚至更大的模型虽然聪明，但部署和推理成本直接劝退了客户。最后，你可能发现 30B 参数级的开源多模态模型（例如 Qwen-VL-30B）是个不错的选择。&lt;/p&gt;&lt;p&gt;30B 被称为大模型的黄金尺寸：它在理解能力上远超小模型，又比巨型模型轻量，是企业私有化部署的完美平衡点。&lt;/p&gt;&lt;p&gt;不过呢，你可能也会发现，「30B 参数」也是一个极具欺骗性的数字。&lt;/p&gt;&lt;p&gt;在纯文本时代，一张前沿的消费级显卡或许还能勉强塞下 30B 的推理。但在多模态（Vision-Language）场景下，事情完全变了。当模型需要处理高分辨率图像时，视觉编码器会产生大量的视觉 Token；而为了让模型真正懂行业 Know-how，必须用数千张有标注图像进行 LoRA 微调。&lt;/p&gt;&lt;p&gt;这就意味着，除了模型本身的权重，我们还需要在显存里塞进梯度、优化器状态以及训练过程中的激活值。&lt;/p&gt;&lt;p&gt;原本以为只是「稍微大一点」的任务，瞬间撞上了物理学的墙。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这些方案不太行&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你的开发环境是顶级消费级旗舰，拥有 24 GB 的超大显存，但在这次的任务面前，它显得如此无力。&lt;/p&gt;&lt;p&gt;当你尝试启动微调脚本时，终端里那行熟悉的红色报错如期而至：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="cs"&gt;&lt;code&gt;RuntimeError: CUDA out of memory. &lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;对于 30B 多模态模型的微调来说，24 GB 的显存就是不够。为了让程序跑起来，你可能会选择牺牲性能，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Batch Size 降到 1&lt;/strong&gt;： 哪怕训练速度慢到像蜗牛爬。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;开启梯度检查点&lt;/strong&gt;： 这是一个典型的「时间换空间」策略，通过不缓存中间激活值而是在反向传播时重算，来节省显存。但这让训练时间直接翻倍。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极限量化&lt;/strong&gt;： 将模型量化到 4-bit 甚至更低。但这也会带来新的问题：对于精密图纸的识别，量化后的模型精度下降明显，连零件号都经常认错。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;即使做了所有这些妥协，只要稍微喂进去一张分辨率高一点的图表，显存还是瞬间溢出，程序直接崩溃。那种「只差一点点就能跑通」的挫败感，最是折磨人。&lt;/p&gt;&lt;p&gt;「要不试试隔壁美术组那台 Mac Studio？」你可能会这样想。那台机器拥有 128 GB 统一内存（Unified Memory）。从硬件上看，这简直是完美的救星 &amp;mdash;&amp;mdash; 别说 30B，就是 70B 也能塞得下。&lt;/p&gt;&lt;p&gt;但当你兴冲冲地把代码拷过去，才发现这是另一个深坑。&lt;/p&gt;&lt;p&gt;首先是环境配置的噩梦。开源社区的主流多模态模型（尤其是涉及底层 CUDA 优化的视觉算子）在苹果芯片上的适配往往慢半拍。你可能会花不少时间解决各种编译报错，好不容易跑通了推理，却发现训练速度受限于优化，效率远不及预期。&lt;/p&gt;&lt;p&gt;更致命的是「生态隔离」。在 Mac 上微调出的模型检查点，想要部署回公司的 Linux 服务器（基于 NVIDIA GPU）上，需要进行繁琐的格式转换和精度对齐。这种开发环境与生产环境的割裂，对于追求快速迭代的工程团队来说，是不可接受的风险。&lt;/p&gt;&lt;p&gt;那么，你到底需要什么？&lt;/p&gt;&lt;p&gt;难道为了跑通这个 30B 模型，你真的要走漫长的合规流程去申请昂贵的 A100 云实例，时刻防范私密数据出域的风险？又或者，仅仅为了这一个开发项目，就专门配置一个高成本的工作站，甚至去采购一台必须安置在专业机房、且维护成本高昂的机架式服务器？&lt;/p&gt;&lt;p&gt;你需要这样一台机器：它要有 Mac Studio 那样海量的统一内存，让你不再为显存精打细算；它同时又必须流淌着纯正的 NVIDIA 血液，拥有原生的 CUDA 生态，让代码无缝迁移。&lt;/p&gt;&lt;p&gt;这个「既要又要」的幻想，直到一台 1 升体积的小盒子的出现，才变成了现实。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;桌面上的一升解决方案&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个盒子就是&lt;strong&gt;联想 ThinkStation PGX&lt;/strong&gt;。&lt;a href="https://mp.weixin.qq.com/s/qeWJwnchS2qNFAKFaHu-TA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e0ee0cbe-e5a4-49d1-b2ae-69eef17029c6/1768278994471.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;如果你关注过英伟达之前的动作，可能会觉得眼熟。没错，联想 ThinkStation PGX 在核心配置上与 NVIDIA DGX Spark 完全一致。&lt;/p&gt;&lt;p&gt;准确地说，ThinkStation PGX 正是英伟达 DGX Spark 的 OEM 量产版本。英伟达已将这一参考设计授权给了联想等厂商，由它们负责具体的工程化制造与差异化定制。&lt;/p&gt;&lt;p&gt;这台机器最直观的冲击力来自于它的尺寸：&lt;strong&gt;仅有 1 升（1L）&lt;/strong&gt;。它小到可以轻松塞进通勤背包，放在办公桌的一角几乎没有存在感。但就在这方寸之间，联想塞进了一颗基于 NVIDIA Grace Blackwell 架构的 GB10 超级芯片。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA0426a2g3EeEUicsZGqIv62q93ypn8Cb5mfygcewWia1x2gpFMriabrZmQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.5879629629629629" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527947" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3d5b0310-6e10-44e9-bf0b-d35d5cd48d29/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而对于被显存折磨得死去活来的开发者来说，它最性感参数是：&lt;strong&gt;128 GB 统一内存（Unified Memory）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这不仅仅是数字的胜利，更是架构的胜利。ThinkStation PGX 的统一内存架构允许 CPU 和 GPU 共享这 128 GB 的海量空间，且可通过 NVLink-C2C 技术实现高速互联。这意味着，开发者终于可以在桌面上拥有接近甚至超越专业级计算卡（如 H100 80GB）的显存容量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACFNGwzs9rpqowOxffYOwVbpj3FJAnicr7KqyibdVUZ0bZ88LezicK2a5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.612037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527945" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e50bbc83-c24e-43e6-8b33-f70c73e6c8c2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了核心算力，在数据存储方面，联想贴心地提供了 1TB 和 4TB 两个存储版本。对于大部分只是想快速验证模型原型的开发者，1TB 版本足矣；而对于需要本地存放海量训练数据（如医疗影像、自动驾驶点云或数万张高清图纸）的团队来说，4TB 版本显然是更具安全感的选择。&lt;/p&gt;&lt;p&gt;更关键的是，它是一台「原生」的 AI 机器。预装了 &lt;strong&gt;NVIDIA AI &lt;/strong&gt;软件栈，底层运行的是开发者熟悉的 Linux 系统，跑的是最纯正的 CUDA 环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAUWHEEOH6UdalyZXJTUsVxoGCiaUvXbNpiaHGwkxEXLqH9fXqSdYe1yCQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527946" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/aa108d5a-a934-41f7-8cec-6fc7012a79b4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，就让我们亲手试一试这样显存巨大的性能小猛兽吧。&lt;/p&gt;&lt;p&gt;首先，掂一掂重量，着实非常小巧，甚至比 Mac mini M1 还小一些。同时，它的设计也非常精致，采用了标志性的蜂窝状散热设计，不仅看起来科技感十足，更是为了保证进风效率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAcqWFAJQD2rJNtPAWdVTPOeRib2zUu4WyXCF9Zy4wFzu3PXLuHiceg06Q/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527949" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/50317fdf-a6ba-4a5e-8474-0f85cd01bc2a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，把 ThinkStation PGX 连上显示器，通电开机，先来看看基本信息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkARuyPPVnt2obHricibVh9F3MZ9k2h0oDn84JcrKjPsJaDg0kRBa2yiao5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6724324324324324" data-s="300,640" data-type="png" data-w="925" type="block" data-imgfileid="503527948" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1b73c55f-9f80-453c-87ba-c3e779f185e6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在终端输入 nvidia-smi，可以看到显卡型号是 NVIDIA GB10，CUDA 版本为 13.0。但这里有一个有趣的细节：在 Memory-Usage 一栏，它显示的是 Not Supported。&lt;/p&gt;&lt;p&gt;为什么不支持？其实，这反而是最大的利好。&lt;/p&gt;&lt;p&gt;在传统的独立显卡（如 RTX 4090）上，显存是独立的，所以会显示具体 MiB 数值。这里的「Not Supported」以及下面进程列表里能显示显存占用（如 Firefox 用了 230MiB），直接证明了它是&lt;strong&gt;统一内存（Unified Memory）&lt;/strong&gt;架构。&lt;/p&gt;&lt;p&gt;是的，PGX 的 GPU 没有自己封闭的小显存墙，而是直接访问系统的大内存池。&lt;/p&gt;&lt;p&gt;接下来我们将通过一个真实的微调场景来检验这台机器的能力。&lt;/p&gt;&lt;p&gt;首先，我们选择的模型是完整版的 Qwen3-VL-30B-A3B-Instruct。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZw2oLxQjhQBY9V4afmSdMhnRnTyL9hiajLib3lUiciapxBlVv7N0ia1PUcQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.3203342618384401" data-type="gif" data-w="1077" type="block" data-imgfileid="503527952" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0ca3647f-8db1-4be5-ba05-5b72a7f66464/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;糟糕的网速下等待 1 个多小时，下载完成。而为了微调模型，我们还需要一个数据集，这里我们选择是的 lyan62 发布的 FoodieQA 数据集。据介绍，FoodieQA 是一个用于细粒度理解中国饮食文化的多模态数据集，其中包含多图像、单图像视觉问答（VQA）以及关于中国地方美食的文本问答问题。该数据集基于 350 种独特美食条目对应的 389 张独特美食图像构建而成。它要求模型不仅能看图，还要懂中国味。&lt;/p&gt;&lt;p&gt;接下来，我们先是自己尝试了编写微调脚本，但效果并不佳。于是我们决定直接让 AI 全程接管，来一次 vibe fine-tuning（氛围微调）！&lt;/p&gt;&lt;p&gt;给 PGX 装上 Claude Code，并配置好 MiniMax-M2.1。然后下达一小段指令：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;你是一位出色的 AI 模型微调专家，你现在需要在一台拥有 128GB 统一内存的联想 ThinkStation PGX 上微调一个 30B 大小的 MoE 模型。在这里，models/Qwen3-VL-30B 文件夹中是已下载的 Qwen3-VL-30B-A3B-Instruct 模型，FoodieQA 文件夹中是 lyan62/FoodieQA 数据集。请使用 FoodieQA 数据集完成对 Qwen3-VL-30B-A3B-Instruct 模型的进一步微调。&lt;/p&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAFYjISNZko35y7raGCbw1fIsRRp3few9KAJqJAWSrdu4iaIB8JiawuEPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.2092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527950" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/a49db964-d77f-41cb-8882-b2cb919662ab/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来就是等待。两三个小时后，训练方案终于确定下来。以下是训练稳定后 nvtop 监视画面。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAghCNzPibFDCthLo8ibG6aiczoG71fKbOHnhjo0ianR1GaYqzeicN3oSvjVQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.41929499072356213" data-type="gif" data-w="1078" type="block" data-imgfileid="503527957" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b1f9e8cb-9d44-44b2-bab6-7ad167c929de/640.gif" data-order="1" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可以看到，对于该任务，GPU 使用率大体在 23% 左右，显存（统一内存）的占用接近 60GB。&lt;/p&gt;&lt;p&gt;要知道，这 60GB 的显存占用，如果是消费级显卡早就炸了三次了，但在 ThinkStation PGX 上，显存条只吃了一半，它甚至游刃有余。更令人印象深刻的是温控。得益于出色的散热设计，在开了暖气的房间里，ThinkStation PGX 的 GPU 最高温度也仅达到了 40℃。&lt;/p&gt;&lt;p&gt;一夜之后，微调完成。在验证集上的损失从 4.03 成功降到了 1.06，下降了 74%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAJ2vv6xib7VCgKp2WUafTr4jID89da3mg14KLc3Qf2hB3uMnwo3n44mA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6832971800433839" data-s="300,640" data-type="png" data-w="461" type="block" data-imgfileid="503527951" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ce51367e-2baf-4cb2-bd34-40a9e33f39c4/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;来一张我们自己拍摄的食物照片来简单试试。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAArTTIicsI9ibKml8oWcpbx2mQpsHPzAACeSPJXqQXHia50Ht30zTichV9g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.5185185185185185" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527953" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/023683cd-22ad-43e9-a28d-7152e1ef0118/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAdkB1DbJFFB0s7v5mX0FLXiaibD2t6HGUevLA0UlSibRvpQeRmJZF9RrDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.550761421319797" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527954" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/4920ef56-3021-49ef-9645-d19b976df625/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;结果大体正确，这个微调过的 Qwen3-VL-30B-A3B-Instruct 正确识别了中间的阳春面，并正确地指出了其属于淮扬菜，不过它也忽略了旁边的蟹黄（确实有点难以辨认）。&lt;/p&gt;&lt;p&gt;整体体验下来，联想 ThinkStation PGX 展现出了几个让开发者无法拒绝的优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;从容加载&lt;/strong&gt;：128GB 内存意味着我们可以不需要任何量化，甚至可以直接加载 FP16/BF16 精度的原始模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;大胆训练&lt;/strong&gt;：可以直接开启较大的 Batch Size，不用担心 OOM，训练效率成倍提升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;英伟达原生体验&lt;/strong&gt;：基于 Linux+CUDA，可以直接 clone 官方的微调代码库，配置好环境，一行命令 bash finetune.sh 直接开跑，没有适配的痛苦。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;结论很明显：&lt;strong&gt;联想 ThinkStation PGX 是目前桌面上唯一能让 30B 多模态模型「跑得舒服」的设备&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;事实上，微调模型绝非 PGX 的唯一用途。打开想象力，我们能发现很多适合它的大显存 AI 场景，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;算法工程师的本地沙盒&lt;/strong&gt;：用于金融或医疗等数据敏感行业。工程师可以在本地完整加载 70B+ 模型验证想法，无需申请云端资源，数据绝不出域。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;野外科研的离线算力站&lt;/strong&gt;：对于珍稀动物监测或地质勘探，野外往往没有高速网络。PGX 可塞进背包，离线处理海量红外监控影像。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长视频生成的无限画布&lt;/strong&gt;：视频生成模型对显存需求随时间线性增长。PGX 的大内存能支持生成更长时间的连贯视频素材。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;具身智能的数字孪生&lt;/strong&gt;：在桌面运行高保真的 Isaac Sim 仿真环境，训练完成后直接部署到架构同源的 Jetson 模块，零迁移成本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数字艺术家的私有风格库&lt;/strong&gt;：长期累积创作者自己的 Style Checkpoint，本地运行风格迁移，不用担心独家画风泄露。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;为什么选择联想 ThinkStation PGX？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然核心芯片和架构与英伟达的参考设计（DGX Spark）一致，为什么我们更推荐联想的 PGX？&lt;/p&gt;&lt;p&gt;答案在于两个词：&lt;strong&gt;工程&lt;/strong&gt;与&lt;strong&gt;服务&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;驯服 240W 功耗的蜂窝美学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GB10 是一颗性能强悍的超级芯片，但其满载功耗高达 170W，整机功耗更达到 240W。在一个 1 升的极小空间内压制这种热量，如果设计不当，很容易导致积热降频，甚至变成桌面烫手宝。&lt;/p&gt;&lt;p&gt;联想没有简单照搬公版设计，而是沿用了 ThinkStation 家族标志性的「蜂窝状」散热设计。这种源自空气动力学的设计理念（灵感源于阿斯顿・马丁的进气格栅），最大化了机箱前后的进出风效率。&lt;/p&gt;&lt;p&gt;实测表明，相比于初期公版参考设计可能存在的积热问题，PGX 表现得更加「冷静」。对于需要连续跑几天几夜微调任务的开发者来说，这种基于 Top 1 工作站大厂的工程稳定性，意味着你不用半夜起来担心训练因过热而中断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据保险&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于购买 PGX 的企业和科研用户来说，最值钱的往往不是机器本身，而是硬盘里的数据：那些私有的行业数据集、微调后的模型权重、以及核心算法代码。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAw4gLEVCNd27YsBd72iae12KfRFnYCY4ahGrDJDvv5HA7ibTmMJfmJic1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527955" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/0cc2b8b1-d652-4d44-a03c-732d515db106/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为中国市场份额第一的专业工作站品牌，联想给 PGX 配备了中国区独享的顶格服务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3 年上门保修&lt;/strong&gt;：相比于海淘水货或部分竞品可能仅提供的 1 年质保，这是面向生产力用户更合理、也更负责任的保障方案。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;硬盘数据恢复服务&lt;/strong&gt;：这是最打动企业用户的痛点。万一硬盘发生物理损坏，联想提供专业的数据恢复服务。对于科研实验室等数据至关重要的机构来说，这项服务的价值远超机器价格本身。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;售后技术支持&lt;/strong&gt;：联想工作站在全国拥有超过 1 万名认证工程师，2300 多个专业服务站，100% 覆盖 1-6 线城市，能保证 7x24 小时在线支持。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;升级空间：双机 NVLink&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你觉得 128 GB 依然不够用，PGX 还预留了升级空间。&lt;/p&gt;&lt;p&gt;借助内置的 NVIDIA ConnectX-7 网络技术，你可以将两台 ThinkStation PGX 通过高速互联。在 NVLink 的加持下，两台机器瞬间化身为一个拥有&lt;strong&gt; 256 GB 统一内存&lt;/strong&gt;的超级怪兽。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAhwCw3k69fCAP2A9CcZuN3P3c4Bpn1gLCbWKhow073SzSF26Id5PC3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6416666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527956" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/cddb1bde-5c2d-4d97-8f49-baf256a666b8/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这时，你的桌面算力上限将被进一步打破：你甚至可以尝试挑战上千亿参数量级别的超大模型推理。从 1 升小盒子到双机并行，这给了开发者极大的灵活性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算力普及的「最后一公里」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回顾这几天的体验，联想 ThinkStation PGX 给我们留下的最深印象，并不是某个具体的跑分数字，而是它带来的「&lt;strong&gt;确定性&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;在过去，想要在本地搞定 30B 级别以上的多模态模型微调，总是充满了不确定性：显存会不会爆？量化会不会掉点？算子能不能跑通？&lt;/p&gt;&lt;p&gt;而 ThinkStation PGX 用 128 GB 的海量内存和原生的 CUDA 生态，把这些不确定性变成了一条平滑的直线。它填补了消费级显卡（显存太小）和工业级服务器（动静太大）之间那个巨大的真空地带。&lt;/p&gt;&lt;p&gt;至于大家都关心的价格，在拥有 128GB 统一内存和原生 CUDA 生态的前提下，&lt;strong&gt;ThinkStation PGX 1TB 版本售价为 31999 元，4TB 版本售价为 36999 元&lt;/strong&gt;。这仅仅相当于一块高端专业显卡的价格，却可以换来一台完整的、开箱即用的桌面 AI 超算。&lt;/p&gt;&lt;p&gt;如果要我以编辑的身份给一个购买建议，我的答案是：对于深陷显存焦虑的专业开发者而言，&lt;strong&gt;联想 ThinkStation PGX 不仅值得买，甚至可能是目前 4 万元以内唯一的最优解&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;不妨算一笔账：在市面上，要获得同等规模（128GB）的显存容量，你通常需要购买昂贵的专业级计算卡，或者租用按小时计费且数据需上传云端的 A100 实例。而 ThinkStation PGX 以不到 3.7 万元的顶配价格，提供了一个拥有海量统一内存、原生 CUDA 生态且数据完全私有的桌面级方案。&lt;/p&gt;&lt;p&gt;如果你只是偶尔跑跑 7B 小模型，它或许略显奢侈；但对于那些受够了环境配置错误的算法工程师、对数据安全有极高要求的科研团队，以及希望快速验证 idea 的初创公司来说，PGX 买到的不仅仅是硬件，更是「不折腾」的权利：让你不必再为显存溢出修改代码，也不必再为跨平台移植浪费时间。这种&lt;strong&gt;让开发者回归创造力&lt;/strong&gt;本身的价值，远超机器售价本身。&lt;/p&gt;&lt;p&gt;这或许才是 AI 基础设施普及过程中，最动人的「最后一公里」。&lt;/p&gt;&lt;p&gt;如果你也受够了在 OOM 的边缘试探，ThinkStation PGX 值得成为你桌面上的下一台设备。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>OpenAI的首款硬件：是AI耳机，今年销量要冲5000万</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:33:40 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/11e3dc79-d6e5-4b72-88d1-4e44558abb1a/1768278719983.png" style="width: 700%;" class="fr-fic fr-dib"&gt;以人工智能技术闻名的 OpenAI，终于也要搞硬件了，而且一上来就是和苹果正面对标。&lt;/p&gt;&lt;p&gt;最近，有关 OpenAI 硬件的消息越来越多。&lt;/p&gt;&lt;p&gt;今天一早，数码博主 @智慧皮卡丘透露了关于 OpenAI「To-go」硬件项目的最新细节。&lt;/p&gt;&lt;p&gt;该硬件已被确认是&lt;strong&gt;一款取代 AirPods 的特殊音频产品，内部代号为「Sweetpea」（香豌豆）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;据他所说，在制造端，富士康已接到通知，要求在 2028 年第四季度前为五款设备做好量产准备。目前这些设备尚未全部揭晓，但一款家居设备和一款手写笔仍在研发考量中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaev2XJQyC8Ga5Z85b4dNlWJCbOibXLQB2P5s0JWPVcGiaGarmEmyP8wRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528105" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5bc7eabe-54e4-4829-ae19-de07265a308f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 部分截图。原文链接：https://x.com/zhihuipikachu/status/2010745618734759946&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;多方消息来源反复确认了同一个信息：由于苹果前首席设计官 Jony Ive 团队的全力投入，&lt;strong&gt;「Sweetpea」目前处于最高优先级。该产品预计于 9 月左右发布，OpenAI 给它的第一年预估出货量高达 4000-5000 万部&lt;/strong&gt;（作为对比，苹果 AirPods 系列的年出货量约在 6000-7000 万支左右）。目前已知的具体细节如下，如下参考图所示。&lt;/p&gt;&lt;p&gt;在工业设计上，据称设计「独一无二、前所未见」，主机采用金属材质，外形酷似卵石（eggstone）。&lt;/p&gt;&lt;p&gt;在佩戴方式上，在「卵石」内部装有两个胶囊状单元，取出后可佩戴在耳后。&lt;/p&gt;&lt;p&gt;在核心性能上，主处理器目标锁定为 2nm 制程的智能手机级芯片（目前最看好三星 Exynos），因此可以让大部分 AI 推理任务在本地运行。此外，项目还开发了一款定制芯片，允许用户通过指令控制 Siri 来「替代 iPhone 的操作」。&lt;/p&gt;&lt;p&gt;在成本与定位上：由于选材和组件规格更接近手机，外界担心其 BOM（物料清单）成本极高，但据称该设备的功能将比现有产品更强大。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsac3fv7bvWn2TvfWOsRXdsukB93hFaiaNAhru6s5iaib7fKGatosE4MBMog/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8379629629629629" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528107" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9272e968-6864-4ab5-a0f3-60beee9a043b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在评论区，这位博主回答了更多关于这款设备的信息，比如「它的发声是通过骨传导，还是内置了扬声器？」，答案是「目前没有采用骨传导的计划。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsa6MTyV8rkh0BDkR4LibVpVZdoTZkzMNGoxxA50NeL5icEzRrvnuVDrpNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528109" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2a4b3109-8cba-49a5-8970-e5efcb03b4c7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;多位网友认为这款设备很酷，如果真的可以取代 Airpods，绝对是跨时代的产品。毕竟是苹果传奇设计师 Jony Ive 操刀的产品，期待可以拉高一些。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaSEQbdsJ9HopWTXJdwibnWp6w15kyKRX3jiaCHxQK2rY2QniabOCLThflg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528111" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e443b922-3b26-4c41-835b-6e06aba01b10/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;「这看起来是 OpenAI 进军可穿戴 AI 市场的一次大胆尝试。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYRT36XIOhUzM8GXaaxaict7YJXjTrK6kRxDQODqIXs2GpOXjlUQav7g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.16203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528113" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d32dc35b-3f59-4d9d-99af-334698ad3749/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;去年 5 月，OpenAI 宣布以 65 亿美元的价格收购了由苹果前首席设计官 Jony Ive 创办的秘密硬件初创公司 io，这是 OpenAI 自成立以来规模最大的收购案。双方在 2025 年 7 月正式完成了团队整合。&lt;/p&gt;&lt;p&gt;io 原来的目标是开发一种「为 AI 时代而生」的新型计算设备，旨在打破目前以智能手机屏幕为核心的交互逻辑，寻找一种更自然、更具直觉的 AI 交互形态。至少在 OpenAI 耳机上，我们能看到这种思路的延续。&lt;/p&gt;&lt;p&gt;目前，虽然 OpenAI 的智能硬件仍然处于保密状态，但通过越来越多的爆料，我们已经可以逐渐勾画出它的大致样貌了。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考内容：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theinformation.com/articles/openai-ramps-audio-ai-efforts-ahead-device&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/kimmonismus/status/2010804115543114099&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为推出软工代码智能体SWE-Lego，解锁SFT训练极致性能</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:30:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ed362392-6d9c-4a7e-b1b5-1043314720f5/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&amp;ldquo;软工任务要改多文件、多轮工具调用，模型怎么学透？高质量训练数据稀缺，又怕轨迹含噪声作弊？复杂 RL 训练成本高，中小团队望而却步？&amp;rdquo;&lt;/p&gt;&lt;p&gt;华为研究团队推出 &lt;strong&gt;SWE-Lego&lt;/strong&gt;， 仅基于监督微调（SFT）的软件工程代码智能体，无需复杂 RL 流程，在 SWE-bench Verified 基准中斩获同等规模开源模型 SOTA，甚至超越部分更大规模闭源模型！项目已开源，代码、模型和全部数据一键获取！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;arXiv 地址：https://arxiv.org/abs/2601.01426&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub 地址：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://github.com/SWE-Lego&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace 地址：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://huggingface.co/SWE-Lego&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;SWE-Lego 具有三大创新，包括数据、训练和测试时扩展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 混合数据集构建：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;双数据管道互补&lt;/strong&gt;：GitHub 真实 PR 数据 + 注入真实场景 Bug 的合成数据，产出 32k 高质量任务实例 + 18k 专家轨迹；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;严格轨迹筛选&lt;/strong&gt;：过滤 Git 历史泄露、工具错误等噪声，重用部分解决的优质轨迹，提升 SFT 训练有效性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 改进的监督微调：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;两大亮点&lt;/strong&gt;：① 步骤级错误掩码，让模型从长轨迹中学习有效子轨迹；② 课程学习，按交互轮次分级提升任务难度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能提升&lt;/strong&gt;：比传统 SFT 在不同模型上提升 2~4%，筑牢 SOTA 基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 测试时扩展策略（TTS）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;扩展优先级&lt;/strong&gt;：先串行扩展（增大轨迹最大交互轮数）至饱和，再分配资源给并行扩展（多备选答案选最优）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;打分器优选&lt;/strong&gt;：生成式打分器在并行扩展中，全程优于回归式打分器，适配不同模型规模与测试预算。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在软件工程领域，Code Agent 需要处理复杂的任务：修复 bug、重构代码、理解大型代码库。这些任务要求 Code Agent 具备&lt;strong&gt;长序列推理、多文件操作和工具使用&lt;/strong&gt;等能力。现有的训练方法通常需要复杂的训练范式，比如强化学习（RL）或者 RL 和 SFT 的迭代组合。&lt;/p&gt;&lt;p&gt;这些方法虽然有效，但计算成本高，训练过程复杂。能否用更简单的方法达到同样的效果？&lt;/p&gt;&lt;p&gt;华为的研究团队提出了 &lt;strong&gt;SWE-Lego，一个仅基于监督微调（SFT）的软工代码模型的解决方案&lt;/strong&gt;。在 SWE-bench Verified 基准测试上基于 Qwen3 系列模型作为起始模型，经过 SFT 之后得到 SWE-Lego-Qwen3-8B 和 32B 分别达到 42.2% 和 52.6%，&lt;strong&gt;达到了开源模型的 SOTA 水平，并超越了一些更大规模的闭源模型&lt;/strong&gt;。基于测试时扩展策略（TTS）可以进一步把性能提高 6~7%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85vGYcMUqPLFJw5FDvLG6p4n105QiajNXViboAhGic0no60zl9Xaib3vg7NA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527131" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/303b5186-1e49-430a-9d96-d89fcdfed42f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1：SWE-Lego 系列模型在 SWE-bench Verified 上的性能对比，在同等规模模型中表现达到 SOTA&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、挑战与动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;软件工程任务与传统的单文件编程任务有着明显区别&lt;/strong&gt;：一个 bug 修复可能涉及代码项目里多个文件的修改，需要多轮工具调用（读取文件、执行测试、编辑代码等），必须在真实的代码库环境中验证修复效果，还需要理解代码逻辑、定位问题、设计修复方案等复杂推理能力。&lt;/p&gt;&lt;p&gt;为了训练具备软件工程项目级代码编写能力的代码模型，研究者们尝试了多种方法。强化学习（RL）虽然不需要预定义的轨迹，但训练成本极高。复杂组合方法将多种训练范式结合，比如 SFT 和 RL 的迭代训练，进一步增加了训练复杂度。更重要的是，高质量的训练数据稀缺。现有的数据集要么规模有限，要么缺乏可执行环境，要么难以扩展到足够大的规模。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、SWE-Lego 的三大核心组件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 包含三个核心组件：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85lBhxibD6hKhdgRupdPUsiaJafSV05zaEu0LtFFFbNibyjCAScYiajtRqgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.438423645320197" data-s="300,640" data-type="png" data-w="1015" type="block" data-imgfileid="503527133" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9d19b42c-8640-441e-90c4-3117c8152d85/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：SWE-Lego-Qwen3-32B 的性能提升分解，混合数据集贡献最大（+25.6%），改进的 SFT 贡献 + 3.8%，TTS 贡献 + 6.2%&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从图 2 可以看到每个组件的贡献：混合数据集贡献 + 25.6%（最大贡献），改进的 SFT 贡献 + 3.8%，测试时扩展贡献 + 6.2%。总计从基线 23.2% 提升到 58.8%，提升了 35.6 个百分点。这些结果清楚地表明，好的数据集是性能提升的最大驱动力，而改进的 SFT 和测试时扩展提供了不错的增量收益。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件一：混合数据集构建&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 数据集包含 32,119 个高质量任务实例，18,110 个验证轨迹（其中 14,110 个完全解决，4,000 个半解决），覆盖 3,251 个代码仓库。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SWE-Lego 采用混合数据构建策略&lt;/strong&gt;，结合真实世界数据和合成数据。真实世界数据来自严格筛选的 GitHub Pull Requests （PRs），这里的 PRs 中非测试文件作为 Golden Patch, 也就是这个任务的解决方案。真实 PR 数据具有贴近生产环境的优势，能够提供真实的 bug 的复杂性，真实的任务参考 SWE-rebench [1]。但是&lt;strong&gt;真实数据数量有限，且每个任务需要独立的沙箱环境，成本较高&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;参考 SWE-smith [2] 的通过故意引入 Bug 来合成软工任务的方式，SWE-Lego 通过 AST 转换和 LLM 重写，基于真实代码仓得到相应的合成软工数据，对可以通过测试的代码库故意引入一些 Bug。具体地，AST 转换提取抽象语法树（AST）并应用随机变换，如移除条件 / 循环、修改运算符或依赖关系，而 LLM 重写则提示模型使用函数头和文档字符串等信息重写代码。引入 Bug 的补丁进行反转就可以得到解决这个任务的 Golden Patch。&lt;strong&gt;合成数据具有可扩展、成本低、多个任务可共享沙箱的优势，但复杂度相对较低&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在下一步，&lt;strong&gt;团队对真实和合成数据采用测试驱动的方式去得到验证后的软工数据实例&lt;/strong&gt;，筛选出合格的软工任务。具体地，在应用 Golden Patch 前可以通过的测试在应用 Golden Patch 之后仍然可以通过， 而应用 Golden Patch 前不通过的测试在应用 Golden Patch 之后也需要通过。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85bXdevAiaQDibeoMc08U2L0pYDoLIrWuoibBsj9icicNPSeg3DSYxQRMWdeg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.44814814814814813" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527134" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2dc7c643-6445-414d-a104-0b9830e869c5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：SWE-Lego 数据管道，结合真实 PR 和合成的软工任务实例，基于专家模型去生成可执行的轨迹用于 SFT 训练&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真实数据提供深度（复杂性和真实性），合成数据提供广度（数量和覆盖范围）&lt;/strong&gt;。两者互补：真实数据提供主要收益但难以扩展，合成数据通过进一步扩展提供额外收益。实验证明，增加合成数据可以显著提升有效轨迹数量和下游性能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85xia36DysWTXYFxLWibXjz24g5VNhpAldaYBJVyC9aK2klkm8R5o6HKag/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527135" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c75ce22d-38c6-425e-943a-570d855069d5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 4：随着合成实例的增加，有效轨迹数量显著增长&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85XibhMDqGBpCxvjE0NXFQrKk54rn4qOQ3qZy0fH9Doy7icibemNQNwF4YA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527136" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/be29d2b9-3f37-471a-8685-a2bf1f18f7e4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 5：随着混合数据的增加，模型的性能逐步提升&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;轨迹质量优化&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了确保训练数据的质量，SWE-Lego 实施了严格的轨迹生成和验证流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;防止解决方案泄露&lt;/strong&gt;：最近 SWE-Bench 社区 [3] 发现，LLM 可能通过查看 Git 历史来 &amp;quot;作弊&amp;quot;，直接找到正确答案。为了防止这种解决方案泄露，对于真实实例，SWE-Lego 移除问题创建日期之后的所有提交和日志消息，使未来的修复不可见；对于合成实例，由于有 bug 的版本在无 bug 的版本之前（由于故意的 bug 注入），完全移除整个 Git 历史和所有日志，只暴露 buggy 代码库的单个快照。这迫使模型真正推理代码和测试，而不是从版本控制中读取答案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;处理工具调用错误&lt;/strong&gt;：在使用 Qwen3-Coder-480B-A35B-Instruct 作为教师模型时，观察到对 str_replace_editor 工具的频繁格式错误调用，例如将字符串传递给 view_range 或指定超出范围的行范围，导致工具失败并浪费交互预算。为了缓解这些错误，SWE-Lego 应用轻量级后处理：如果 view_range 是字符串，则在执行工具之前将其转换为整数；如果请求的行范围超过文件长度，则返回有效行的子集而不是引发错误，使得模型能够更可靠地检查代码。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;精简工具集&lt;/strong&gt;：虽然任务管理工具（如 task_tracker）已被一些最近的专有模型采用，但发现 Qwen3-Coder-480B-A35B-Instruct 无法有效使用它们，经常导致执行错误。因此，SWE-Lego 丢弃此工具，将工具集限制为四个基本操作：execute_bash、str_replace_editor、think 和 finish，以保持轨迹精简。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;轨迹过滤策略&lt;/strong&gt;：SWE-Lego 通过应用预测补丁并运行测试集来验证轨迹。如果轨迹通过所有测试，则分类为已解决，否则为未解决。然后，过滤低质量的已解决轨迹（例如，通过修改测试文件来 &amp;quot;作弊&amp;quot; 的轨迹），并重用部分解决轨迹（那些正确识别了所有相关文件但未能修复的轨迹）。这些部分解决轨迹提供了有价值的故障定位监督，我们发现加入此类数据会适当提升模型的性能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85aqgAJhnEwht3BZ4QicS0TLKlJalnticUCI1A4VSt0UnWpXLnYib523xIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527141" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8b929db2-f5ae-4e82-9abd-7278171bc345/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 6：轨迹生成中的关键实践，包括防止 Git 泄露、处理工具错误、精简工具集&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85ElzKdAowjXhPXIqeOYlbdA8tcY8V3vTuwzNBqP81icCcxcnNG4Vxasw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527143" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/cf49ae17-ef08-48e6-8360-5a458b005b1a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 1：SWE-Lego 的可验证的任务实例和有效训练轨迹的统计以及和其他 SWE 相关工作的数据对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;具体的数据统计和对比见表 1，可以看出 SWE-Lego 的混合数据管道提供了数量充足的、代码仓多样的、环境可验证的 SWE 任务实例和轨迹。&lt;/p&gt;&lt;p&gt;总结：混合数据集是性能提升的最大驱动力。真实数据与合成数据互补确保了数据数量，严格的轨迹验证确保了轨迹的质量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件二：改进的监督微调&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通常的监督微调将通过测试验证的整条轨迹拿去训练，但实际上在软工的场景，专家轨迹需要多轮在沙箱中交互得到最后的预测补丁，即使&lt;strong&gt;最终成功解决的轨迹也可能包含中间错误步骤&lt;/strong&gt;，盲目学习这些错误可能强化不良行为。另外，不同数据的难度不同，&lt;strong&gt;在训练初期让模型学习难题可能比较吃力&lt;/strong&gt;。针对这些情况，SWE-Lego 提出了两个改进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;改进 1：步骤级错误掩码&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：保持完整轨迹上下文，但只对正确的步骤计算损失。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Nk2uT6COC4ZqEwyUPAfWKLkHNkMa1MzicUoaynibNWMqBp0Msor8oQQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527144" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/56d1eb5f-7d82-44dd-99f2-f12669881376/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 7：步骤级错误掩码示例，错误步骤被掩码，模型只学习正确的操作&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实现方法：使用正则表达式识别终端环境提供的错误消息，对相应的模型响应应用错误掩码。关键是要排除因复现 bug 或执行测试文件而产生的错误。&lt;strong&gt;这种方法保持完整的轨迹上下文，但只对正确的步骤计算损失&lt;/strong&gt;，使模型能够学习正确的操作和恢复策略，而不会强化错误。通过强调学习正确操作，直接减少了核心推理失败，如 &amp;quot;错误实现&amp;quot; 和 &amp;quot;定位错误&amp;quot;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;改进 2：基于难度的课程学习&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：从简单任务开始，逐步增加难度。&lt;/p&gt;&lt;p&gt;SWE-Lego 探索了两种难度分类方法：&lt;strong&gt;基于模型的评分和基于轨迹轮数的启发式&lt;/strong&gt;。研究发现，轨迹轮数与解决率之间存在强负相关（相关系数 - 0.95）。基于这一发现，&lt;strong&gt;SWE-Lego 采用可以直接获取的指标，轨迹轮数，作为轨迹的难度指标&lt;/strong&gt;，将数据分为三个难度等级：简单（0-50 轮）、中等（50-70 轮）、困难（70-100 轮）。训练策略采用三阶段课程：先训练简单任务，再逐步加入中等和困难任务。这种课程学习与训练动态一致：首先让模型在 &amp;quot;简单&amp;quot; 任务上克服基本的 &amp;quot;无法复现&amp;quot; 错误，然后引入 &amp;quot;困难&amp;quot; 任务以发展避免 &amp;quot;超出最大轮次&amp;quot; 失败所需的战略规划。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85X4dibbQLI0oiaS2Y95fY3B09vmGgztwKMOBed6NfZVZRGCTqEJ9tsVkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527147" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0577f126-d803-4eae-bf87-f3b605984a57/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8：轨迹轮次与平均解决率之间的强负相关关系&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;训练过程分析&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过分析训练过程中的错误类型演变，可以清楚地看到模型的学习轨迹：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Ey25EvOiahC5oibIUnAYmHoJE0gy0ib0l1C4dPibduUfAqkiaR9WwAUicl9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527148" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/57b0e284-aa3d-465f-bf90-89ffdb951c6f/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9：训练过程中解决率的提升趋势&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Ogmgib5lx8xXCEVLr16s50IGrLjiaHXicvia442GORicv820pBZJoYAMic3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527149" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/84f31828-103e-4cbb-8fe8-d246ea1d44c6/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10：训练过程中错误类型的演变，从早期的 &amp;quot;无法复现&amp;quot; 到后期的 &amp;quot;错误实现&amp;quot;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;错误类型的变化：训练初期时 &amp;quot;无法复现&amp;quot; 错误占主导，表明模型此时缺乏对软工任务基本的理解能力；训练中期时 &amp;quot;无法复现&amp;quot; 比例大幅减少，但 &amp;quot;定位错误&amp;quot; 比例仍有较多，表明缺乏战略规划；训练后期 &amp;quot;错误实现&amp;quot; 成为瓶颈，表明从过程失败转向推理失败。&lt;/p&gt;&lt;p&gt;改进的 SFT（错误掩码 + 课程学习）带来 3.8% 的性能提升。在 SWE-bench Verified 上，SWE-Lego-Qwen3-8B 达到 42.2%，SWE-Lego-Qwen3-32B 达到 52.6%。通过渐进式训练和选择性学习，模型能够更有效地掌握复杂任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件三：测试时扩展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;测试时扩展（TTS）可以在不重新训练的情况下，通过在测试阶段分配额外的计算资源来提升性能。SWE-Lego 系统研究了两个正交维度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;维度 1：串行扩展 vs 并行扩展&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;SWE-Lego 研究了串行扩展和并行扩展之间的资源分配。串行扩展通过增加最大交互轮次实现，在低测试预算的区域非常高效。额外轮次都能获得环境反馈，使模型能够纠正错误并迭代改进解决方案。这使得串行扩展在预算有限时成为首选策略。然而，模型性能在约 100-140 轮后开始饱和，此时相比于串行扩展，更加需要并行扩展来提升性能。&lt;/p&gt;&lt;p&gt;并行扩展生成多个候选轨迹，用打分器选择最佳的轨迹。&lt;strong&gt;在串行扩展饱和后，并行扩展变得更加有效，因为每个独立轨迹探索解决方案空间的不同路径。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85k1QHfdWvBNrJB9nhG1mLtXMw1QBcL34Wvk1os5XtNveuaanvjaPFAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5268518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527150" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b5bb352e-b62d-4fef-8885-7fea41384c79/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 11：串行扩展和并行扩展的权衡，等延迟曲线显示了最优资源分配策略&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;有限的测试阶段计算预算下，应优先进行串行扩展；在串行扩展饱和后，将剩余计算资源分配给并行扩展&lt;/strong&gt;。图 11 中的等延迟等高线说明了这种权衡：在等效延迟下，最优分配随着总延迟预算的增加从顺序主导转向并行主导。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;维度 2：生成式 vs 回归式打分器&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;打分器用于从多个候选轨迹中选择最佳方案。SWE-Lego 比较了两种范式：回归式打分器和生成式打分器。&lt;/p&gt;&lt;p&gt;回归式打分器在模型上添加一个头输出，使用二元交叉熵损失训练，对整个轨迹转化为单个标量去打分。生成式打分器将验证表述为文本生成任务，预测 &amp;quot;是&amp;quot; 或 &amp;quot;否&amp;quot;，从输出 &amp;quot;是&amp;quot; 或 &amp;quot;否的&amp;quot;token 概率计算分数。生成式打分器的训练目标与预训练的下一个 token 预测目标对齐，可能更好地利用模型的固有知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85edYQZtPKoaUMyNLjU1nk8oCzflosCwaOaruCZug5Wxiaplkl2VsmZTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527151" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/eb87310c-d0e8-48c4-b96c-ae00c543d0f4/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 12：生成式打分器与回归式打分器的对比，生成式打分器在 K 值较大时持续改进&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 rollout 的个数（K 值）比较小时，生成式打分器与回归式打分器两者的性能相近；&lt;strong&gt;随着 rollout 的次数（K）的增加，回归式打分器趋于饱和，而生成式打分器持续改进&lt;/strong&gt;。对于 SWE-Lego-Qwen3-8B，在 K=16 时差距达到 2.8%（49.6% vs 46.8%）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85r2NrjLgQMcTTFGTTKUVPYicCcjJicXRVV6G1UsRErhx3eBTMr0DiagEdQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527152" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/ed9437fe-3f12-44e2-b6ba-e50f4c5b7cab/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 13：SWE-Lego 打分器与现有公开打分器的对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego-Verifier-8B 在 TTS@16 上达到 49.6%，超越了 OpenHands-Critic-32B（44.0%）和 R2E-Gym-Verifier-14B（47.0%）。除了绝对性能外，还观察到不同打分器范式的定性不同缩放行为。OpenHands-Critic-32B 采用回归式范式，在更高的 K 值下表现出性能下降，这是一个反直觉的结果，表明更大的候选池压倒了其判别能力。相比之下，生成式打分器（SWE-Lego 和 R2E-Gym）保持单调改进，趋向于 Pass@K 上限，进一步确认生成式表述提供了更稳健的缩放属性。&lt;/p&gt;&lt;p&gt;总结：测试时扩展可以在测试阶段带来额外提升。在测试的计算预算比较低的时候，串行扩展优先于并行扩展。生成式打分器在并行扩展中表现更优。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、结语与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 证明了&lt;strong&gt;轻量级方法也能达到 SOTA&lt;/strong&gt;，不一定需要复杂的 RL 或 SFT 和 RL 的迭代训练，SFT 也可以取得软工任务的 SOTA 性能。数据质量至关重要，&lt;strong&gt;混合数据集和严格验证是性能提升的关键。训练技巧的价值也不容忽视&lt;/strong&gt;，错误掩码和课程学习等看似简单的改进也带来了性能提升。&lt;/p&gt;&lt;p&gt;未来将探索更大模型和更多数据的组合，&lt;strong&gt;扩展到 Python 之外的其他编程语言和其他类型的代码任务，处理企业级的长序列、多文件任务&lt;/strong&gt;，并将 SWE-Lego 应用到真实的软件开发流程中。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考文献&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[1] Badertdinov, I., Golubev, A., Nekrashevich, M., Shevtsov, A., Karasik, S., Andriushchenko, A., ... &amp;amp; Yangel, B. (2025). SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents. arXiv preprint arXiv:2505.20411.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[2] Yang, J., Lieret, K., Jimenez, C. E., Wettig, A., Khandpur, K., Zhang, Y., ... &amp;amp; Yang, D. (2025). Swe-smith: Scaling data for software engineering agents. arXiv preprint arXiv:2504.21798.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[3] https://github.com/SWE-bench/SWE-bench/issues/465&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型中标TOP10里的黑马：中关村科金的应用攻坚之道</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:46:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ac803b5a-ebae-4bb1-9db4-8ce61e88d0d6/1768271983190.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;一份大模型中标数据报告，揭示了产业重心转移的清晰轨迹：应用类项目占比近六成，市场用真金白银为 &amp;ldquo;落地&amp;rdquo; 投票。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;2025 年，中国大模型产业在招投标市场上演了一场令人瞠目的 &amp;ldquo;狂飙&amp;rdquo;。智能超参数的监测数据显示，全年大模型相关中标项目数量达到 &lt;strong&gt;7539 个&lt;/strong&gt;，披露金额 &lt;strong&gt;295.2 亿元&lt;/strong&gt;，较 2024 年分别激增 &lt;strong&gt;396%&lt;/strong&gt; 与 &lt;strong&gt;356%&lt;/strong&gt;。市场正以前所未有的速度，将技术潜力兑换为商业订单。&lt;/p&gt;&lt;p&gt;更关键的结构性变化在于项目类型：&lt;strong&gt;应用类项目占比高达 58%&lt;/strong&gt;，在 2025 年 11 月甚至达到 63% 的峰值。这明确宣告，产业的焦点已从实验室的参数竞赛，彻底转向商业场景的价值验证。市场用最直接的预算分配，为大模型的发展路径投下了决定性的一票。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;市场转向：从 &amp;ldquo;技术占位&amp;rdquo; 到 &amp;ldquo;价值锚地&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的大模型中标市场，描绘出一条陡峭的指数增长曲线。这不仅意味着市场规模在膨胀，更揭示了价值重心在迁移。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuYVeYtzyMbImVLgNf2uVeQ1BHP8BC9Sqzw9hn09RBly0qdy9CFJxibA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7046296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527965" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b58f84a2-87a3-47bb-9bbe-c3a83e20add0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;根据智能超参数的分类，大模型项目被划分为算力、数据、大模型（基座 / 平台）和应用（智能体 / 场景解决方案）四大类。2025 年的数据清晰地显示，&lt;strong&gt;应用类项目以 58% 的数量占比一骑绝尘&lt;/strong&gt;，成为绝对主流。从季度趋势看，其占比从第一季度的 44% 一路攀升至第三季度的 61%，并在第四季度稳定在 60.5%。&lt;/p&gt;&lt;p&gt;与此同时，&lt;strong&gt;算力类项目金额占比最高（52.9%）&lt;/strong&gt;，但数量占比（27%）远低于应用类。这背后是一个关键的市场信号：随着 DeepSeek、通义千问 Qwen 等高性能开源模型的成熟，更多企业选择直接采购算力，调用或微调现有成熟模型，以快速构建自己的应用。大模型（基座 / 平台）类项目占比为 10%，其中智能体开发平台的采购成为重要组成部分。&lt;/p&gt;&lt;p&gt;行业分布同样耐人寻味。教科、政务、通信、能源、金融是项目数量排名前五的行业。其中，&lt;strong&gt;政务行业以金额占比约 40% 位居榜首&lt;/strong&gt;，这与各地政府将智算中心升级为与大模型强绑定的产业赋能中心密切相关。金融行业则在下半年展现出从算力投资向应用部署的明显转向。&lt;/p&gt;&lt;p&gt;从厂商格局看，通用大模型厂商（如科大讯飞、百度、火山引擎、阿里云等）和拥有广泛渠道的三大运营商是中标主力。然而，一个值得注意的现象是，像&lt;strong&gt;中关村科金、蚂蚁数科这样的垂类大模型厂商，凭借在金融等细分赛道的深耕，同样在中标市场占据了一席之地&lt;/strong&gt;。这印证了一个产业判断：当通用模型的能力差距趋于收敛，&lt;strong&gt;生态构建能力与场景掌控力&lt;/strong&gt;，正取代单纯的模型性能，成为新的竞争壁垒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;攻坚样本：中关村科金的 &amp;ldquo;行业深潜&amp;rdquo; 与 &amp;ldquo;场景破局&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在通用大模型厂商凭借全栈能力横扫市场的同时，另一条深耕垂直领域的路径同样结出了硕果。中关村科金，这家并非以通用模型见长的企业，正是这条路径上的一个典型攻坚者，其在中标市场的表现，精准映射了 &amp;ldquo;应用为王&amp;rdquo; 时代的核心逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkArLp0HCauialpszTDMEvkN5GU1LqqF7UVA7Gd09GiblBmFyooR7S7t9vw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="1.8583333333333334" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527966" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6bcf4175-1285-4af1-b161-ccc93e228e7f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;智能超参数发布的《中国大模型中标项目监测与洞察报告 (2025)》显示，&lt;strong&gt;中关村科金以 23 个中标项目入围 2025 年应用类大模型项目中标厂商 TOP10 榜单，是榜单中少数聚焦垂类场景的大模型厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其战略自始就锚定 &amp;ldquo;应用&amp;rdquo; 与 &amp;ldquo;落地&amp;rdquo;。中关村科金自 2023 年起便战略布局大模型平台，并沿着&lt;strong&gt; &amp;ldquo;平台 + 应用 + 服务&amp;rdquo; 的三级引擎战略&lt;/strong&gt;，推动垂类大模型在垂直行业和场景的应用落地，为 &amp;ldquo;应用为王&amp;rdquo; 提供了多个维度的注脚，其在金融、政务、工业、汽车、零售等多个赛道的全面落地，展现了垂类大模型厂商的独特竞争力。&lt;/p&gt;&lt;p&gt;在工业制造这一复杂且专业壁垒极高的领域，中关村科金展现出将前沿 AI 技术与传统产业深度融合的深厚功力。其助力中国船舶集团经济研究中心打造的&lt;strong&gt;船舶行业大模型 &amp;ldquo;百舸&amp;rdquo;&lt;/strong&gt;，融合了船舶领域百万级专业知识库与长文本推理能力，构建了智能问答、研报写作、文档解读、情报分析等行业智能体，有效推动了船舶行业 &amp;ldquo;数智大脑&amp;rdquo; 的建设。&lt;/p&gt;&lt;p&gt;针对有色金属冶炼等高能耗场景，中关村科金与南方有色金属公司合作，打造了&lt;strong&gt;广西首个有色金属行业大模型&lt;/strong&gt;，通过落地冶炼工艺优化、能源管理、设备智能运维等核心场景智能体，取得了关键生产环节的量化突破：将主操手操作频率降低 90%，温度控制偏差由 &amp;plusmn;15℃收窄至 &amp;plusmn;5℃，并助力综合能耗下降 8%。这标志着垂类大模型已能深入高能耗流程的核心环节，为工业绿色智能化转型提供了关键技术支撑。&lt;/p&gt;&lt;p&gt;在交通基建这类传统上被认为与 AI 技术距离较远的行业，中关村科金也成功开辟了智能化新路径。其与宁夏交建联合打造的&lt;strong&gt;交通基建垂类大模型 &amp;ldquo;灵筑智工&amp;rdquo;&lt;/strong&gt;，基于上万份行业规范、工程技术文档等高质量数据训练，使模型在专业问题上的回答准确率较通用大模型提升 40%。基于该模型构建的专业智能体，在实际应用中平均提效超 60%，不仅解决了工程师撰写施工方案、核算工程量等耗时费力的痛点，更通过智能成本预警等功能，推动了整个行业从 &amp;ldquo;经验驱动&amp;rdquo; 向 &amp;ldquo;数据 + AI 驱动&amp;rdquo; 的转型。&lt;/p&gt;&lt;p&gt;如果说在工业等传统领域的突破证明了其技术下沉的能力，那么在数字化程度最高、要求最严苛的金融行业，中关村科金的深耕则更凸显了其 &amp;ldquo;行业 Know-how&amp;rdquo; 的价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依据智能超参数报告，中关村科金在金融行业大模型项目中标厂商中位列第四&lt;/strong&gt;，仅次于百度云、科大讯飞、火山引擎等大厂，成为垂类厂商深耕金融赛道的标杆代表。其中标项目广泛覆盖智能客服升级、远程视频银行、智能风控合规、智能运营提效等核心业务场景。&lt;/p&gt;&lt;p&gt;中关村科金深耕金融领域多年，已服务 500 多家头部金融机构，包括 50% 以上百强银行及 70% 的信托机构，沉淀了深厚的行业 Know-how。依托其 &amp;ldquo;得助大模型平台 + 金融行业智能体平台&amp;rdquo; 的核心产品组合，中关村科金打造了覆盖 &amp;ldquo;营销 - 风控 - 运营 - 企业服务&amp;rdquo; 全链路的金融智能体矩阵，这并非简单的工具叠加，而是将大模型能力深度融入金融机构从获客、服务到风险管理的核心业务流程。&lt;/p&gt;&lt;p&gt;例如，中关村科金与&lt;strong&gt;中信券商&lt;/strong&gt;合作打造大模型财富助手，能够实时洞察市场动态与数据，精准匹配理财产品与投资组合，并自动生成专业营销话术，助力展业效率提升 3 倍；为&lt;strong&gt;某国有大型商业银行&lt;/strong&gt;提供全栈音视频服务，实现视频银行、合规双录、视频客服、视频会议等全场景统一接入管理；与&lt;strong&gt;中国电建财务公司&lt;/strong&gt;联合打造 &amp;ldquo;财神大模型&amp;rdquo; 及办公智能体，实现员工业务知识获取效率提升 70%；为&lt;strong&gt;百年人寿&lt;/strong&gt;打造的保险知识库问答智能体，问答准确率稳定在 90% 以上，知识获取效率提升 50%，赋能内部 17 个部门；为&lt;strong&gt;申万宏源证券&lt;/strong&gt;打造合规垂直领域专有大模型，赋能员工高效查询制度文件，筑牢业务合规防线。&lt;/p&gt;&lt;p&gt;在智能客服与数字人这一大模型落地最火热的赛道，中关村科金的表现尤为突出，已成为该领域的核心参与者。IDC《中国智能客服市场份额，2024》报告显示，中关村科金位居中国智能客服市场第四，位列垂类大模型厂商第一。根据智能超参数的中标报告，&lt;strong&gt;在 &amp;ldquo;智能客服 &amp;amp; 数字人&amp;rdquo; 应用场景，科大讯飞、百度、中关村科金是中标项目数量排名前三的厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;中关村科金的核心支撑源于自研的得助智能客户平台 5.0，这一覆盖营销服全场景的新一代人机协作智能平台，以 &amp;ldquo;人类员工 + 数字员工&amp;rdquo; 协同为核心，通过多智能体深度联动，让数字员工成为人类员工的专业伙伴与高效延伸。其解决方案已成功赋能金融、汽车、零售、跨境出海、政务民生等多个行业领域，形成了兼具广度与深度的行业实践图谱。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;汽车行业&lt;/strong&gt;，中关村科金的解决方案已深度融入客户运营全链路。例如，其与&lt;strong&gt;丰田&lt;/strong&gt;合作，通过大模型语音智能体进行老客精准营销外呼，在实现超 60% 高接通率，激活沉睡客户；为&lt;strong&gt;岚图汽车&lt;/strong&gt;构建的销售洞察质检平台，则将销售流程合规性提升 70%。这些实践表明，中关村科金正将智能客服从传统的服务支持角色，升级为驱动销售增长与客户体验升级的核心引擎。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;零售与消费领域&lt;/strong&gt;，面对海量、高频的客户咨询与严苛的服务体验要求，中关村科金为&lt;strong&gt;瑞幸咖啡、添可、老板电器&lt;/strong&gt;等知名品牌提供了从智能应答、全渠道服务到全量质检的一体化方案。这些方案不仅有效应对了大促期间的咨询洪峰，更通过智能化工具将客服中心从成本部门转变为提升客户满意度、挖掘服务价值的关键环节。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;全球化服务&lt;/strong&gt;方面，通过构建支持多语种实时互译、全渠道智能路由的 Instadesk 全球客户联络中心解决方案，中关村科金帮助&lt;strong&gt; Imou 乐橙、阿里巴巴国际站&lt;/strong&gt;等出海企业攻克了跨时区、跨文化的服务难题，实现了服务效率与全球用户满意度的双重提升；也为 &lt;strong&gt;UniUni &lt;/strong&gt;这样的北美本地物流平台，以及&lt;strong&gt;泰国大都会水务局&lt;/strong&gt;这样的海外公共服务机构，提供了稳定、高效的多语言智能客服支持，成功将服务能力从企业出海延伸至本地化公共服务领域。&lt;/p&gt;&lt;p&gt;这些遍布多行业的落地案例共同表明，中关村科金的智能客服解决方案不再是简单的问答工具，而是深度嵌入客户旅程、与业务流程紧密耦合的 &amp;ldquo;价值挖掘引擎&amp;rdquo;。这正契合了当前大模型应用从 &amp;ldquo;功能实现&amp;rdquo; 向 &amp;ldquo;业务赋能&amp;rdquo; 演进的核心趋势。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;未来展望：2026，价值交付的深水区与垂类厂商的护城河&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标数据，已经为 2026 年乃至更远未来的发展轨迹画下了清晰的延长线。市场增长的 &amp;ldquo;陡峭曲线&amp;rdquo; 或许会逐渐平缓，但竞争的 &amp;ldquo;深度曲线&amp;rdquo; 将陡然加剧。行业将全面驶入&lt;strong&gt;价值的 &amp;ldquo;深水区&amp;rdquo;&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一，ROI 成为硬指标：从 &amp;ldquo;成本中心&amp;rdquo; 到 &amp;ldquo;利润引擎&amp;rdquo; 的证明之战。&lt;/strong&gt; 随着大模型技术本身日趋成熟和开源化，获取先进 AI 能力的门槛正在迅速降低。2026 年，企业客户将不再满足于 &amp;ldquo;拥有大模型&amp;rdquo; 的演示效果，而是会苛刻地追问每一个 AI 项目的投资回报率（ROI）。这意味着，大模型必须从 &amp;ldquo;成本中心&amp;rdquo; 证明自己作为 &amp;ldquo;利润中心&amp;rdquo; 或 &amp;ldquo;效率引擎&amp;rdquo; 的价值。峰瑞资本创始合伙人李丰的判断正在成为行业共识：AI 投资将进入 &amp;ldquo;第三阶段&amp;rdquo;，即投资真正落地、能挣到钱的应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二，行业 Know-how 与高质量私有数据，将构筑起最坚固的护城河。 &lt;/strong&gt;当通用模型的底层能力可以通过 API 便捷获取时，决定应用效果的将不再是模型的通用性能，而是对特定行业业务流程、专业术语、合规红线的深度理解，以及基于私有数据训练出的 &amp;ldquo;领域专家&amp;rdquo; 能力。中关村科金为中国电建财务公司打造的 &amp;ldquo;财神大模型&amp;rdquo;，与宁夏交建用上万份规范训练的 &amp;ldquo;灵筑智工&amp;rdquo; 大模型，其价值核心正在于此。这些基于海量、高价值、非公开行业数据构建的垂类模型，不仅效果远超通用模型，更因其数据资产的独特性和专业性，形成了竞争对手难以短时间复制的壁垒。未来，&amp;ldquo;数据资产化&amp;rdquo; 与 &amp;ldquo;知识工程化&amp;rdquo; 的能力，将比单纯的算法创新更为关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三，应用形态将从 &amp;ldquo;单点智能工具&amp;rdquo; 演进为 &amp;ldquo;全链路业务智能体&amp;rdquo;。&lt;/strong&gt; 当前的应用大多集中于客服、问答、内容生成等单点环节。下一步，大模型将更深入地与业务流程融合，进化为能够自主完成复杂任务的 &amp;ldquo;业务智能体&amp;rdquo;（Agent）。未来的智能客服将不再是孤立的问答机器人，而是融入客户旅程，能够主动进行销售外呼、完成复杂业务办理、甚至进行客户情绪安抚与挽留的 &amp;ldquo;全能型数字员工&amp;rdquo;。这要求供应商提供的不是单点产品，而是一整套能够与企业现有 IT 系统深度集成、随业务需求灵活编排的智能体生态系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGib2wScIJJRS3gBdbXdGaNic1ooYib28CmErmYgno8QrjDaoRE2YwKYWw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527998" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cfd2e9ac-9259-41e0-b7e5-1f31db85a9b2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;第四，生态协同将成为主流，垂类厂商与通用平台的关系从 &amp;ldquo;替代&amp;rdquo; 转向 &amp;ldquo;共生&amp;rdquo;。&lt;/strong&gt; 未来的市场格局很可能不是 &amp;ldquo;你死我活&amp;rdquo; 的替代关系，而是分层协作的共生生态。像中关村科金这样的垂类应用厂商，将更专注于在特定行业深挖场景，打造开箱即用的行业智能体解决方案；而通用大模型厂商和云厂商，则提供稳定、高效、低成本的算力与模型基座。&lt;strong&gt;中关村科金携手华为云、阿里云、百度智能云、火山引擎、亚马逊云科技、超聚变等企业共同发布的 &amp;ldquo;超级连接&amp;rdquo; 全球生态伙伴计划，正体现了这种开放协作的趋势。&lt;/strong&gt;2026 年，能否融入主流生态、能否与上下游高效协同，将决定一家厂商的市场边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标狂飙，是中国大模型产业从技术狂热走向商业理性的成人礼。市场用近 300 亿的订单，宣告了 &amp;ldquo;应用落地&amp;rdquo; 时代的正式开启。&lt;/p&gt;&lt;p&gt;2026 年的 &amp;ldquo;价值深水区&amp;rdquo;，将是检验真功夫的战场。大厂之外，像中关村科金这样，凭借对行业的深刻理解与扎实的产品和价值交付能力，已然为企业级大模型和智能体厂商如何穿越周期、赢得市场，提供了一个清晰的范本。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，梁文锋署名开源「记忆」模块，DeepSeek V4更细节了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:18:05 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/30c33348-2e2f-4927-8387-a39e06b425ed/1768270430059.png" style="width: 700%;" class="fr-fic fr-dib"&gt;就在十几个小时前，DeepSeek 发布了一篇新论文，主题为《Conditional Memory via Scalable Lookup:A New Axis of Sparsity for Large Language Models》，与北京大学合作完成，作者中同样有梁文锋署名。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALWDibzfe0HzEE5mIybPwTIAI5uGiaI0QA1ZZqyzr79hq8C0bwgj2SOiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528058" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8300495e-2055-4ff9-abf8-9873f1500199/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;简单总结一波&lt;strong&gt;这项新研究要解决的问题&lt;/strong&gt;：目前大语言模型主要通过混合专家（MoE）来实现稀疏化，这被称为「条件计算」。但是，现有的 Transformer 缺少原生的知识查找机制，只能被迫通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;针对这一现状，&lt;strong&gt;DeepSeek 提出了条件记忆（conditional memory），从而与 MoE 的条件计算互补，并通过引入一个新模块 Engram 来实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，模块「Engram」相关的实现已经上传到了 GitHub。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA86NTkhF1jNYqnOSG9OAujyOVQa3cUGicFmAPEXKXroicohumgL38XGqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528060" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c16a6833-4c22-46d2-a7f8-a93402bade79/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;项目地址：https://github.com/deepseek-ai/Engram&lt;/p&gt;&lt;p&gt;这让网友们感慨：「DeepSeek is back！」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALjBOxiceaogbXLPCibElgW4JDeWTo2491OtK0YJTS7emWDCWWCPJh3WA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9717514124293786" data-s="300,640" data-type="png" data-w="1062" type="block" data-imgfileid="503528062" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0a406ecb-aa43-4a96-923a-1b2ebd0b28f6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，结合元旦期间公布的研究《mHC:Manifold-ConstrainedHyper-Connections》，我们可以明确的是 DeepSeek v4 的模样愈发清晰，就等上新了！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;除了条件计算（MoE），LLM 还需要一个独立的条件记忆 Engram&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MoE 模型通过条件计算实现了模型容量的扩展，但现有的 Transformer 架构缺乏原生的知识查找原语，只能通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;为了解决这一问题，DeepSeek 提出了条件记忆（conditional memory）这一与条件计算互补的稀疏化维度，并通过 Engram 模块加以实现。Engram 在经典 𝑁-gram 嵌入的基础上进行了现代化改造，使其能够以 O (1) 时间复杂度完成知识查找。&lt;/p&gt;&lt;p&gt;通过形式化提出稀疏性分配问题，DeepSeek 还发现了一条&lt;strong&gt;呈 U 型的扩展规律&lt;/strong&gt;，用以刻画神经计算（MoE）与静态记忆（Engram）之间的最优权衡关系。&lt;/p&gt;&lt;p&gt;在这一规律的指导下，&lt;strong&gt;DeepSeek 将 Engram 扩展至 270 亿参数规模，并在严格等参数量、等 FLOPs 的条件下，其整体性能显著优于纯 MoE 基线模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;尤为值得注意的是，尽管记忆模块本身主要被用于提升知识检索能力（如 MMLU 提升 +3.4、CMMLU 提升 +4.0），但 DeepSeek 观察到其在通用推理能力（如 BBH 提升 +5.0、ARC-Challenge 提升 +3.7）以及代码与数学推理任务（HumanEval 提升 +3.0、MATH 提升 +2.4）上带来了更为显著的增益。&lt;/p&gt;&lt;p&gt;进一步的分析表明，&lt;strong&gt;Engram 能够将静态知识的重建负担从模型的浅层中剥离出来，从而有效加深网络用于复杂推理的有效深度&lt;/strong&gt;。此外，通过将局部依赖关系交由查表机制处理，Engram 释放了注意力机制的容量，使其能够更专注于全局上下文建模，从而显著提升了长上下文检索能力（例如 Multi-Query NIAH 的准确率从 84.2 提升至 97.0）。&lt;/p&gt;&lt;p&gt;最后，Engram 在系统层面同样展现出基础设施感知的高效性：其确定性的寻址方式支持在运行时从主机内存进行预取，几乎不会带来额外的性能开销。&lt;/p&gt;&lt;p&gt;DeepSeek 认为，&lt;strong&gt;条件记忆将成为下一代稀疏大模型中不可或缺的核心建模原语&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Engram 架构如下，其设计目标是在结构上将静态模式存储与动态计算过程从 Transformer 主干网络中分离出来，从而对其进行增强。该模块对序列中每一个位置依次执行两个功能阶段：检索与融合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAFKoRVttBOmQoIev9VHCpaVOlLtibYm336AibGdPxlqx2d1wa5kr1OEMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528063" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d9aef974-d08b-4723-be55-ed8ac921b9a5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在运行过程中，DeepSeek 首先对当前位置的后缀 N-gram 进行提取与压缩，并通过哈希机制以确定性的方式检索对应的静态嵌入向量。随后，这些被检索到的嵌入会在当前隐藏状态的调制下进行动态调整，并进一步通过一个轻量级卷积操作加以精炼。最后，Engram 与多分支架构进行集成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于哈希 𝑁-gram 的稀疏检索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一阶段的目标是将局部上下文映射到静态记忆条目，这一过程主要包括分词器压缩以及通过确定性哈希机制来检索对应的嵌入表示。&lt;/p&gt;&lt;p&gt;分词器压缩：为了最大化记忆单元的语义密度，DeepSeek 引入了一层词表投影（vocabulary projection）。为此，他们预先设计了一个映射函数&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAgSxiccS8q33sCb3TGn941oX3R7gPxTBPYUwhOuHPGQkUic5Y3KsYOmkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2389558232931727" data-s="300,640" data-type="png" data-w="996" type="block" data-imgfileid="503528064" data-aistatus="1" data-original-style="width:58px;height:20px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4b3f0322-af0a-4995-a5d2-f385e590fefe/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 12.44%;"&gt;，其将原始 token ID 映射为基于文本规范化等价关系（例如使用 NFKC 规范化、统一大小写等）得到的规范化标识符（canonical identifiers）。在实际应用中，对于一个规模为 128k 的分词器，该过程能够将有效词表规模缩减约 23%（详见附录 C）。&lt;/p&gt;&lt;p&gt;多头哈希：直接对所有可能的 N-gram 组合空间进行参数化在计算和存储上都是不可行的。借鉴 Tito Svenstrup 等（2017）的工作，DeepSeek 采用了一种基于哈希的近似方法。为了降低哈希冲突的影响，对于每一种 N-gram 阶数 n，引入 K 个相互独立的哈希头。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上下文感知门控&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前一阶段通过哈希 𝑁-gram 从条件记忆中检索得到的嵌入向量，本质上提供的是一种与具体语境无关的静态先验信息。然而，正因为其静态属性，这些嵌入缺乏对当前上下文的自适应能力，并且在实际应用中可能受到哈希冲突或词项多义性带来的噪声干扰。&lt;/p&gt;&lt;p&gt;为此，DeepSeek 在检索之后引入了一种上下文感知的门控机制，其设计灵感来源于注意力机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;系统效率：计算与存储的解耦&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在带有记忆机制的模型中，规模扩展往往受到 GPU 高带宽显存（HBM）容量有限的制约。然而，Engram 所采用的确定性检索机制天然支持将参数存储与计算资源进行解耦。不同于 MoE 依赖运行时隐藏状态进行动态路由，Engram 的检索索引完全由输入 token 序列决定。这种可预测性使得针对训练与推理阶段的专门优化策略成为可能，如图 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAD4Hibb8SMweeACleRMlsD8LmqQlMl1llDq9iciaO6Egveyo8RsPSLNpNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.725" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528065" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4fe509c8-9e8d-412b-9529-666695d72011/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在训练阶段，为容纳大规模嵌入表，DeepSeek 采用标准的模型并行方案，将嵌入表分片分布在多张 GPU 上。在前向传播过程中，通过 All-to-All 通信原语收集被激活的嵌入行；在反向传播阶段，则将对应梯度分发回各个分片，从而使总可用记忆容量能够随加速器数量线性扩展。&lt;/p&gt;&lt;p&gt;在推理阶段，这种确定性特性进一步支持一种预取&amp;ndash;重叠（prefetch-and-overlap）策略。由于在前向计算开始之前即可确定所需访问的记忆索引，系统能够通过 PCIe 从容量充足的主机内存中异步地预取嵌入向量。为有效掩蔽通信带来的延迟，Engram 模块被放置在主干网络中的特定层级，利用其前序 Transformer 层的计算作为缓冲，从而避免 GPU 计算停顿。&lt;/p&gt;&lt;p&gt;这也要求一种硬件 &amp;mdash; 算法协同设计（hardware&amp;ndash;algorithm co-design）：一方面，将 Engram 放置得更深可以拉长用于隐藏通信延迟的计算窗口；另一方面，从建模效果来看，较早地介入以卸载局部模式的重建更为有利。因此，Engram 的最优插入位置必须同时满足建模性能与系统时延两方面的约束。&lt;/p&gt;&lt;p&gt;此外，自然语言中的 𝑁-gram 天然遵循 Zipfian 分布，即少量高频模式贡献了绝大多数的记忆访问。这一统计特性启发研究者可以构建一种多级缓存层次结构（Multi-Level Cache Hierarchy）：将高频访问的嵌入缓存于更快的存储介质中（如 GPU HBM 或主机 DRAM），而将大量低频的长尾模式存放在容量更大但速度较慢的存储介质中（如 NVMe SSD）。这种分层设计使 Engram 能够扩展到极大规模的记忆容量，同时对有效访问延迟的影响保持在最低水平。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;U 型扩展规律与稀疏性分配&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为「条件记忆」的一种具体实现，Engram 在结构上与 MoE 专家提供的「条件计算」形成了互补。本节旨在探究这种二元特性（Duality）的扩展属性，以及如何最优地分配稀疏容量。&lt;/p&gt;&lt;p&gt;具体而言，本项研究由两个核心问题驱动：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;有限约束下的分配&lt;/strong&gt;：在总参数量和训练计算量固定（即等参数、等 FLOPs）的情况下，应该如何在 MoE 专家与 Engram 嵌入之间划分稀疏容量？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无限记忆范式&lt;/strong&gt;：考虑到 Engram 具有不随规模增长（Non-scaling）的&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAHcWDB842FnjQ5Q4PhGicvSibickXHW66FibPGUah3vTkP1UyWSE1iblunJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5721925133689839" data-s="300,640" data-type="png" data-w="374" type="block" data-imgfileid="503528067" data-aistatus="1" data-original-style="width:28px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6388a81a-17e5-41f7-ab56-1a51aee7b2c7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 5.39%;"&gt;查找开销，如果放宽记忆预算或进行激进扩展，Engram 自身会表现出怎样的扩展行为？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首先来看 &lt;strong&gt;MoE 与 Engram 之间的最优分配比例&lt;/strong&gt;。在计算匹配公式时，DeepSeek 使用以下三个参数度量来分析这个权衡：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;P_tot：总的可训练参数，不包括词汇嵌入和语言模型头。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;P_act：每个 token 激活的参数。这一量度决定了训练成本（FLOPs）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMRupgtg13d22OV6JrKF6CiaUEO14Bnv7XCTEib2lv2Mc1fnm8WZlfWMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.15789473684210525" data-s="300,640" data-type="png" data-w="836" type="block" data-imgfileid="503528069" data-aistatus="1" data-original-style="width:132px;height:21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/a97cfbce-f1f9-4dc5-87d8-5998968c4163/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 24.99%;"&gt;：不激活的参数，表示可用于扩大模型大小而不增加计算成本的「自由」参数预算（例如未选择的专家或未检索的嵌入）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DeepSeek 在每个 FLOPs 预算内保持 P_tot 和 P_act 固定，这样模型具有相同数量的参数和相同的每 token FLOPs。对于 MoE，P_act 由选定的 top-k 专家决定，而未选择的专家的参数贡献给 P_sparse。对于 Engram，每个 token 只检索固定数量的槽（slots），因此增加嵌入槽的数量会增加 P_tot，但不会增加每 token 的 FLOPs。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAH43shOXT1A8Alp089KGPz1kC74mepCkHpMicXaflpbr2icTfyas8NeXA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.08055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528070" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6544befb-5aa2-44cb-96da-70dd742d8244/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;「在无限内存模式下的 Engram」&lt;/strong&gt;。在固定参数预算下优化分配之外，DeepSeek 探索了互补的设置：激进的内存扩展。这个研究的动机来自于 Engram 独特的能力，能够将存储与计算解耦。&lt;/p&gt;&lt;p&gt;DeepSeek 使用一个固定的 MoE 主干，具有 P_tot &amp;asymp; 3B 和 P_act = 568M，并训练了 100B 个 token 以确保收敛。在此基础上附加了一个 Engram 表，并调整了槽的数量 M 从 2.58 &amp;times; 10⁵ 到 1.0 &amp;times; 10⁷（增加最多约 13 亿参数）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下图 3（左）揭示了验证损失与分配比例 𝜌 之间一致的 U 形关系&lt;/strong&gt;。值得注意的是，即使 MoE 分配减少到仅 𝜌 &amp;asymp; 40%（即 5.7B 模型为 46 个专家，9.9B 模型为 43 个专家），Engram 模型仍然达到了与纯 MoE 基准（𝜌 = 100%）相当的性能。&lt;/p&gt;&lt;p&gt;此外，纯 MoE 基准证明是次优的：将大约 20%-25% 的稀疏参数预算重新分配给 Engram 获得最佳性能。定量分析中，在 10B 范围内（𝐶 = 6 &amp;times; 10&amp;sup2;⁰），验证损失从 1.7248（𝜌 = 100%）改善到 1.7109，接近 𝜌 &amp;asymp; 80% 时的最优值（&amp;Delta; = 0.0139）。值得注意的是，这一最优点的位置在不同的范围内稳定（𝜌 &amp;asymp; 75%-80%），表明在固定稀疏性下，各个规模之间有一个稳健的分配偏好。这一观察到的 U 形确认了两种模块之间的结构互补性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;图 3（右）展示了增加内存槽数量会显著改善验证损失，并且这一改进在整个范围内持续稳定&lt;/strong&gt;。该曲线遵循严格的幂律（在对数空间中线性），这表明 Engram 提供了一个可预测的扩展旋钮：更大的内存在不需要额外计算的情况下继续带来收益。&lt;/p&gt;&lt;p&gt;关键一点是，在扩展效率方面：虽然 OverEncoding 通过更大的内存表受益，但 Engram 在相同的内存预算下释放了更大的扩展潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结合分配规律来看，这些结果验证了条件记忆作为稀疏容量的独立、可扩展轴的作用，它补充了 MoE 的条件计算。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYI9OhrrdFotHP42En2iajz85DmEC2doZWnOoJYLwSXO3e1sdqaCImJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.4925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528081" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/543c6639-1b21-4309-840f-f78637bb6ca7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过提出的 Engram 架构以及经验推导出的分配法则，DeepSeek 将 Engram 扩展至数十亿参数规模，以验证其在真实语言模型预训练中的有效性。&lt;/p&gt;&lt;p&gt;总共训练了以下四种模型：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Dense-4B（总参数量 41 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MoE-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Engram-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以及 Engram-40B（总参数量 395 亿）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所有模型均采用完全相同的数据训练流程（相同的 token 预算及顺序），且在激活参数量上严格匹配。&lt;/p&gt;&lt;p&gt;关于实验设置，所有模型均在包含 2620 亿 token 的语料库上进行预训练，并采用了 DeepSeek-v3 的分词器，其词表大小为 128k。DeepSeek 在涵盖语言建模、知识、推理、阅读理解以及代码 / 数学的多样化基准测试集上对模型进行评估。对于每项基准测试，均遵循标准的提示词协议和评估指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;先来看大规模预训练的实验结果，如下表 1 所示，稀疏架构展示了比密集模型更优的扩展规律。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在相同的训练计算预算下，所有三种稀疏变体（MoE-27B，Engram-27B/40B）在所有基准测试中显著超越了 iso-FLOPs 的 Dense-4B 基准。&lt;/p&gt;&lt;p&gt;更重要的是，&lt;strong&gt;Engram-27B 在 iso - 参数和 iso-FLOPs 的 MoE-27B 基准上持续取得改进&lt;/strong&gt;。有趣的是，这些提升并不限于知识密集型任务（例如，MMLU: +3.0，MMLU-Pro: +1.8，CMMLU: +4.0），在这些任务中，内存容量直观上是有益的。此外还观察到，在一般推理领域（例如，BBH: +5.0，ARC-Challenge: +3.7，DROP: +3.3）以及代码和数学推理任务（例如，HumanEval: +3.0，MBPP: +1.6，GSM8K: +2.2，MATH: +2.4）中，改进更加显著。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;扩展到 Engram-40B 进一步减少了预训练损失，并提高了大多数基准测试的性能&lt;/strong&gt;。尽管它尚未在每个任务上严格超越 Engram-27B，但这可能是由于训练不足的结果。此外，Engram-40B 与基准模型之间的训练损失差距在训练结束时继续扩大，表明扩展的内存容量尚未在当前的 token 预算内完全饱和。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACCBl08YcAEt8TJGEtgr6co2ElHKhympbpN6GoEMgJUSpFhSAichtaQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.1018518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528082" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3989c993-b2fb-4a25-b836-10319eb4d81b/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来是&lt;strong&gt;长上下文训练&lt;/strong&gt;。通过将局部依赖建模卸载至静态查找，Engram 架构为处理全局上下文保留了宝贵的注意力容量。DeepSeek 通过进行长文本扩展训练，对这一结构性优势进行了实验验证。通过采用严密的评估协议，将架构设计带来的贡献与基础模型本身的能力剥离开来，证明了 Engram 在长程检索和推理任务中带来了显著的性能增益。&lt;/p&gt;&lt;p&gt;DeepSeek 首先解耦基础模型能力与架构设计之间的影响，其次进行受控对照分析，结果如下表 2 所示，主要得出了以下两个结论：&lt;/p&gt;&lt;p&gt;一是&lt;strong&gt;超越注意力机制的长文本能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;虽然注意力机制和位置编码为上下文处理提供了结构基础，但实验结果表明，长文本性能并非仅由架构先验决定。通过观察 Engram 的演进轨迹（从 41k 步到 50k 步），即使在控制相同模型架构和固定长文本扩展阶段计算预算的前提下，长文本性能仍随预训练进程单调提升。这表明长文本性能与基础模型的通用建模能力存在内在耦合。因此，严谨的架构对比必须通过对齐「基础模型损失（Loss）」而非仅仅对齐「训练步数」来控制这一混淆变量。&lt;/p&gt;&lt;p&gt;二是&lt;strong&gt;受控设置下的架构优越性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;基于上述原则，DeepSeek 将 Engram 与 MoE 基准模型进行了对比测试。在控制基础能力的前提下，Engram 模块的效率增益变得十分显著：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等损耗设置（Iso-Loss Setting，41k 步 vs. 基准）&lt;/strong&gt;：该设置严格分离了架构效率的影响。当对比 Engram-27B（46k 步）与完整训练的 MoE-27B（50k 步），即预训练损失完全对齐的两个模型时，Engram 表现出显著增益。具体而言，它在复杂检索任务中大幅超越基准模型（例如，多查询「大海捞针」 NIAH：97.0 vs. 84.2；变量跟踪 VT：87.2 vs. 77.0）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等计算量设置（Iso-FLOPs Setting，50k 步 vs. 基准）&lt;/strong&gt;：在标准的等计算预算下，Engram-27B（50k 步）进一步拉大了差距，在所有指标上均实现了顶尖性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极端设置（约 82% 计算量）&lt;/strong&gt;：即使是提前停止训练的 Engram-27B（41k 步），在面对完整训练的 MoE-27B（50k 步）时依然极具竞争力。它在 LongPPL 指标上与基准持平，并在 RULER 测试中实现超越，这充分证明了 Engram 架构的内在优越性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528083" data-ratio="0.45555555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAfwbCxbtEKFLia4VL5J1662B4LxwO0Paq8m6Heic6ia4E5OCA0R09tvB4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/62e24474-5ef0-4253-8ddc-2de57dec69c3/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，下图 4 是&lt;strong&gt;对表示对齐与收敛速度的分析&lt;/strong&gt;。(a) 基于 LogitLens 的逐层 KL 散度分析。在模型浅层，KL 散度持续保持在较低水平，这表明 Engram 加速了预测的收敛。(b-c) 为基于 CKA 计算的相似度热力图。高相似度对角线显著的向上偏移表明，Engram 的浅层在功能上等效于 MoE 模型的深层，从而有效地增加了模型的深度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZIWf0cDNkZhTrlYbpiaicpZlRyIRuflwhEsYTJR8Cziatupd9FzHzJ6kg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528084" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/547b3877-47dc-45a6-9614-011ee6e43a5b/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更多细节请参考原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一个模型统一4D世界生成与重建，港科大One4D框架来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:10:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/9100d25b-1d5e-4994-8380-46ec7215d836/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;本文第一作者密振兴，香港科技大学计算机科学与技术学院人工智能方向博士生，研究方向是多模态理解与生成，视频生成和世界模型，目前正在寻找工业界全职职位。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，视频扩散模型在 &amp;ldquo;真实感、动态性、可控性&amp;rdquo; 上进展飞快，但它们大多仍停留在纯 RGB 空间。模型能生成好看的视频，却缺少对三维几何的显式建模。这让许多世界模型（world model）导向的应用（空间推理、具身智能、机器人、自动驾驶仿真等）难以落地，因为这些任务不仅需要像素，还需要完整地模拟 4D 世界。&lt;/p&gt;&lt;p&gt;来自香港科技大学（HKUST）的研究团队提出 One4D，一个统一的 4D 生成与 4D 重建框架。One4D 构造了一个同步输出多模态的视频扩散模型，能够用一个模型同步输出 RGB 视频与 Pointmap（XYZ）几何视频，并支持从单张图像到 4D 生成、从稀疏帧到 4D 生成 + 重建、以及从完整视频到 4D 重建等多种任务形态。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAy5FibWXueDFAwrB8GuU8D5SeXcCfHSlScdE5NGdFUNwMiawiaZfkFgTVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527905" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/aee20b91-4ff5-448e-bc7f-1b9d0cf75fca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2511.18922&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github：https://github.com/MiZhenxing/One4D&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;二、One4D 算法设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 的核心目标是用强大的视频生成模型（比如Wan Video）统一 4D 生成与 4D 重建，输出对齐的 RGB 和几何多模态结果。论文亮点有：&lt;/p&gt;&lt;p&gt;1. 多模态输出：RGB + Pointmap；&lt;/p&gt;&lt;p&gt;2. DLC：解耦 LoRA 控制，稳住 RGB 同时学几何对齐；&lt;/p&gt;&lt;p&gt;3. UMC：统一掩码条件，一套模型覆盖生成和重建任务。&lt;/p&gt;&lt;p&gt;具体来说，One4D 将动态 4D 场景表示为两种同步的输出模态。(1) RGB frames（外观）；(2) Pointmaps（XYZ），即与 RGB 视频对齐的 3 通道几何视频，每个像素存 XYZ 值，可进一步导出 Depth 并结合后处理估计相机轨迹，最终可视化为 4D 点云和相机。&lt;/p&gt;&lt;p&gt;并且，One4D 在一个框架内支持三种输入：单张图到 4D 生成，稀疏视频帧到 4D 生成 + 重建，完整视频到 4D 重建。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. DLC：解耦 LoRA 控制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在基于视频扩散模型的 &amp;ldquo;RGB + 几何&amp;rdquo; 多模态联合建模里，一个常见做法是把模态在通道维拼接。但在低资源微调时，这会导致严重的跨模态干扰，几何学不好，基础模型的 RGB 质量也容易被拖垮。而将两个模态在长宽维度拼接，共享参数，也会导致跨模态干扰，几何精度不高，而且与 RGB 无法保持对齐。&lt;/p&gt;&lt;p&gt;One4D 提出 Decoupled LoRA Control（DLC） 来专门解决这个问题，设计目标包括：&lt;/p&gt;&lt;p&gt;(1) 低资源微调也尽量保住底座视频模型的强先验；(2) 解耦 RGB 与几何生成，减少互相干扰；(3) 仍要保留必要的跨模态通信，确保像素级对齐一致。&lt;/p&gt;&lt;p&gt;具体做法是：&lt;/p&gt;&lt;p&gt;1. 为 RGB 与 Pointmap 分别挂载模态专属 LoRA，并且形成两条解耦计算分支，共享冻结的 base 参数，但 forward 分开跑。确保两个模态能够相对独立。&lt;/p&gt;&lt;p&gt;2. 再用少量 zero-init 的 control links 连接对应层，让两个模态从 0 开始逐步学会互相控制，从而实现精确的像素级对齐。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQTZaZkW0GIAP9IuIHY8oIRqgkYpEs9mgSJVMfMjkiaqlRdevibVTZbHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3425925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527877" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b7804e0d-830e-4922-a9f5-72aa7875997f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从直观上理解 DLC 的设计， RGB 分支努力保持视频美学与运动先验，几何分支专心拟合几何视频的分布，少量控制连接负责对齐同步。这也正是 One4D 强调的多模态输出同步生成的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. UMC：统一掩码条件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了使用同一个视频模型统一 4D 的生成和重建，One4D 基于Wan Video的多任务框架，提出了 Unified Masked Conditioning（UMC），把不同类型的条件如单帧、稀疏帧、全视频，统一打包成一个条件视频，缺失帧用 0 填充，并使用一个 mask 张量指定哪些帧需要生成。单张图对应纯生成，稀疏帧对应混合生成 + 重建，全视频对应纯重建。在UMC的具体实现上，RGB 分支的条件视频通过 VAE 编码之后，连接到 RGB 的 latent states 上。而 XYZ 分支不直接使用这个条件视频，控制信号是通过 DLC 从 RGB 传递给 XYZ，这保证了 XYZ 分支能够更好地去适应新模态。UMC 的设计让 One4D 具备一个非常实用的能力，同一个扩散骨干，同时做 4D 生成和 4D 重建。One4D 模型不需要为不同任务改结构，只需改变输入帧的稀疏度，就可以在不同生成与重建任务之间平滑切换。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAnGBjSE74EJmJvQPuSGjUhwJE32v1YhP5XGCOibkzACIONCmbiaVSbsHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527906" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2844cf21-3eb5-49ac-91f4-7b3309ea4dbe/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 训练数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练 One4D，需要获得大规模 &amp;ldquo;外观 - 几何&amp;rdquo; 配对数据。One4D 的数据构建遵循两个原则：几何要准、分布要真实。因此我们采用合成数据 + 真实数据混合策略。&lt;/p&gt;&lt;p&gt;合成数据通过游戏引擎渲染动态场景，天然提供每帧的几何真值，用于为 Pointmap（XYZ）提供稳定监督，帮助模型学到可靠的时序几何一致性。&lt;/p&gt;&lt;p&gt;真实数据，收集自公开视频数据的真实场景视频，以覆盖复杂光照、材质、运动模式。由于真实视频通常缺少几何真值，我们使用现有的 4D 重建方法 Geo4D 生成几何标注，从而把真实世界外观分布引入训练。&lt;/p&gt;&lt;p&gt;这套数据策略带来的直接收益是，合成数据提供几何精度与稳定性，真实数据提供视觉多样性与真实分布，从而让 One4D 在保持视频质感的同时，也能输出可用、对齐、时序一致的 4D 几何结果。One4D 使用 34K 条视频在 8 张 NVIDIA H800 GPU 上训练 5500 步，就得到了很好的效果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 单图到 4D 生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文将 One4D 与 4DNeX 做了单图到 4D 的对比，评价指标有：&lt;/p&gt;&lt;p&gt;用户偏好（User study）：在一致性、动态性、美学、深度质量、整体 4D 连贯性等维度上，One4D 全面领先。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAWSiayo3LXZanO22cpWzGmfMu0fC3gibktSb7X851adcRyxS3EiaTxbu2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527879" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c6c11557-ff3c-46c6-9e87-2ce280279238/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;VBench：动态性（Dynamic）显著提升（55.7 vs 25.6），同时 I2V consistency 仍保持可比水平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAOKXBMNEWoX3XJu21mtsJlVXs9mUgWSw8PUyAXhyQl9OnGWzX1xDGDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3296296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527880" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a987755f-c7a5-4872-8efc-7e49f3a9eada/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些结果支持了 One4D 的优势，输出的多模态结果有更真实的 RGB 动态、更干净的深度、更完整连贯的 4D 点云与相机轨迹。在不牺牲 RGB 视频质量的前提下，仍然能学到准确、细粒度的 4D 几何结构。更多对比视频请移步项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAbRXDSNibZtWxzuqTDrHCQStJ0aKz3mTkIRhz45XE1voWQx4orUR7ndw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5592592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527881" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/fd5af25d-4b44-48f2-a7a6-cc569a261c16/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. 完整视频到 4D 重建&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 并不只在 4D 生成任务上优势显著，它还是一个重建模型，在完整视频 4D 重建上也保持了不错的性能。在深度重建评测数据集 Sintel 和 Bonn 上，One4D 的表现明显超过一些只做重建的方法如 MonST3R 和 CUT3R。即使我们的方法使用 Geo4D 构造了训练数据，它也取得了与只做重建的 Geo4D 相近的效果。更多对比视频请移步项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkANTdicLL9p38qtQ0fHwTX40IjPbZicqYHB7Sy8sXOYRYk5UZbMqsxEicbA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527883" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5b2e704c-5ffa-4106-bb34-074d79ac472e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsB03GfkiaTfwRp5l4yymUSDEMia5ZFPIGH79jQMgibXDEINrZ7jH3Yyhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.9259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527884" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/97cf48e9-d4db-4a82-b270-cf479ba392f6/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在相机轨迹评估数据集 Sintel 和 TUM 上，One4D 的相机估计能力也保持了可用精度，充分证明了 One4D 统一重建与生成的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQpRJNibhjhzibxogWwy7nd92WczNVIjMia9lcFusFFYmG5PAIiaBNChwsQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527902" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/7d7d6c39-71c5-402b-8808-2fbb97ccc0ca/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 稀疏视频帧到 4D 生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在稀疏视频帧设置下，One4D 的输入仅是首尾帧以及少量中间帧，此时模型需要生成缺失 RGB 帧并补全完整几何序列。实验证明，即使在极稀疏条件下，One4D 仍能得到合理的 4D 结构。这意味着 One4D 不止能做重建，而是真正具备生成动态 4D 场景的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA9jhZuT98kJib0EibMzADYDm8W0vfZtPCvFcPMvVHdMW05mGboDse9vJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527901" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/94de583a-c911-4c5d-a94b-f7e55b25dcd5/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 让视频扩散模型不再只会生成 RGB，而是能够同步生成外观（RGB）与几何（Pointmap / 深度 / 相机轨迹），在同一套框架中统一了 4D 生成和重建任务。它通过 UMC 与 DLC 解决了多任务切换与多模态联合训练中最关键的稳定性与对齐问题。One4D 推动视频生成走向生成可用于理解与交互的 4D 世界，为下一代世界模型与多模态内容创作提供了更实用的基础能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>端到端智驾的算力困局，九章智算云这样破局</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Mon, 12 Jan 2026 17:08:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;前言：智驾的&amp;ldquo;iPhone时刻&amp;rdquo;，正在被算力重新定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026年1月7日至8日， 中国汽车大数据融合与创新应用大会 在上海隆重举行。作为汽车产业数字化转型的重要风向标，本次大会汇聚了来自整车厂、零部件企业、高校科研机构及AI技术平台的300+行业精英，聚焦&amp;ldquo;数据驱动创新&amp;rdquo;的核心命题。&lt;img src="https://image.jiqizhixin.com/uploads/editor/63f8c2ab-1beb-432d-966b-48b61e9914de/%E5%9B%BE%E7%89%87000.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在这场高规格的技术盛宴中， 九章智算云（Alaya NeW）技术总监胡宗星 受邀发表主题演讲《 跨越&amp;ldquo;算力墙&amp;rdquo;&amp;mdash;&amp;mdash;超大规模集群如何加速端到端智驾 》，深入剖析当前智能驾驶从模块化向端到端演进过程中面临的三大基础设施挑战，并系统性地展示了九章智算云在解决这些问题方面的方案与价值。&lt;img src="https://image.jiqizhixin.com/uploads/editor/18cb4a63-2fb9-48e0-aecc-8eb36afa7a72/%E5%9B%BE%E7%89%8700.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端到端智驾：一场从&amp;ldquo;规则驱动&amp;rdquo;到&amp;ldquo;感知决策一体化&amp;rdquo;的革命&lt;/strong&gt;&lt;br&gt;&lt;br&gt;这是九章智算云技术总监胡宗星指出，过去，大家做模块化智驾，是将感知、预测、规划拆开，告诉车见到红灯停、见到行人让。那时候，几十台服务器就够用了。而如今，行业正迈向端到端（End-to-End）架构 &amp;mdash;&amp;mdash;直接输入原始摄像头视频流，输出车辆控制指令。这不仅意味着模型参数量跃升至百亿级别，更带来了对算力、数据吞吐和系统稳定性的全新要求。&amp;ldquo;这不是简单的硬件升级，而是一场关于 超大规模计算集群 的战役。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三座大山：算力墙、存储墙、通信墙&lt;/strong&gt;&lt;br&gt;&lt;br&gt;智驾每升一级，算力需求增长10倍。这不是买几台服务器就能解决的问题，这是一场关于超大规模集群（Hyperscale Cluster）的战役。面对这场变革，传统IT架构迅速暴露出三大瓶颈：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;计算墙 ：单卡算力有限，无法支撑千亿级参数模型训练；&lt;/li&gt;&lt;li&gt;&amp;middot;存储墙 ：海量视频数据读取速度跟不上GPU计算速度，导致GPU空转；&lt;/li&gt;&lt;li&gt;通信墙 ：多卡间通信延迟高、拥塞严重，使得&amp;ldquo;1+1&amp;lt;2&amp;rdquo;的现象频发。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些痛点共同构成了所谓的&amp;ldquo; 基础设施危机 &amp;rdquo;&amp;mdash;&amp;mdash;即使你拥有最先进的GPU，也无法发挥其全部潜力。&amp;ldquo;如果把GPU比作大脑，那么网络就是血管，存储是食物供给。任何一个环节卡住，整个系统都会瘫痪。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;九章智算云的破局之道：专为AI而生的基础设施&lt;/strong&gt;&lt;br&gt;&lt;br&gt;针对上述挑战，九章智算云提出了一套完整的解决方案&amp;mdash;&amp;mdash; 构建面向AI原生的超大规模集群架构 ，具体体现在三个核心技术方向：&lt;img src="https://image.jiqizhixin.com/uploads/editor/b4a69cf9-d83d-4208-82ec-6c519457150f/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;strong&gt;&amp;nbsp;推倒&amp;ldquo;通信墙&amp;rdquo;：构建微秒级低时延无损网络&lt;/strong&gt;在千卡级集群中，网络是决定效率的关键。九章智算云采用 RoCE v2无损网络 + Fat-Tree结构 ，实现全链路微秒级延迟，确保数据高速流动，避免因网络拥塞造成训练中断。哪怕几千张卡同时吼叫，网络也能从容应对。&amp;ldquo;就像给数据修了一条永不堵车的高速公路。&amp;rdquo;&lt;br&gt;&lt;br&gt;打通&amp;ldquo;存储墙&amp;rdquo;：三级存储加速策略端到端训练最怕什么？怕GPU算得太快，数据读写跟不上。为解决数据供给瓶颈，九章智算云设计了&amp;ldquo; 热-温-冷 &amp;rdquo;三级存储架构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;热数据 ：通过全闪存阵列与分布式缓存，实现毫秒级响应；&lt;/li&gt;&lt;li&gt;温/冷数据 ：按访问频率分层存储，兼顾性能与成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一机制确保GPU始终处于&amp;ldquo;满负荷运行&amp;rdquo;状态，大幅提升资源利用率。搞定&amp;ldquo;稳定性&amp;rdquo;：故障自愈保障持续训练不管你的单卡多强，在千卡集群面前，硬件故障不是&amp;ldquo;会不会发生&amp;rdquo;，而是&amp;ldquo;什么时候发生&amp;rdquo;。 GPU掉卡、ECC报错、网络抖动，这是常态。试想一下，如果你跑了一个月的模型，因为最后一天一张卡坏了而前功尽弃，那是灾难。九章智算云有一个绝活是 &amp;ldquo;故障自愈&amp;rdquo;机制，通过实时监测，一旦发现某张卡有&amp;ldquo;罢工&amp;rdquo;的苗头，系统将自动隔离故障节点，并从最近的断点（Checkpoint）自动拉起训练任务，&lt;strong&gt;全程无需人工干预&lt;/strong&gt;。&amp;ldquo;我们将有效训练时间占比提升至95%以上，让一个月的训练不再因为一张卡掉线而功亏一篑。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语：专注模型，剩下的交给我们&lt;/strong&gt;&lt;br&gt;&lt;br&gt;在演讲最后，九章智算云技术总监胡宗星强调：&amp;ldquo;在端到端智驾的赛道上，算法专家应该专注于让模型更聪明，而不是去修服务器、调网络、处理崩溃。&amp;rdquo;九章智算云的存在意义，正是为了 将底层复杂的算力管理、网络优化、容错机制等&amp;lsquo;脏活累活&amp;rsquo;彻底解放出来 ，让客户能够以更低的成本、更高的效率，专注于模型创新与业务落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;展望未来：助力中国智驾走向世界&lt;/strong&gt;&lt;br&gt;&lt;br&gt;此次在 2026中国汽车大数据融合与创新应用大会 上的精彩分享，不仅是九章智算云技术实力的一次集中展示，也标志着国产AI基础设施正在从&amp;ldquo;跟随者&amp;rdquo;向&amp;ldquo;引领者&amp;rdquo;转变。随着智能驾驶进入规模化落地阶段， 高性能、高稳定、高性价比的算力平台将成为产业竞争的新高地 。九章智算云将继续深耕AI原生基础设施，携手车企、研究院与开发者，共同推动中国智能汽车产业迈向新纪元。九章智算云（Alaya NeW） &amp;mdash;&amp;mdash; 用最强的网络、最快的存储、最稳的集群，加速智驾未来的到来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;后记&lt;/strong&gt;&lt;br&gt;&lt;br&gt;本次活动由ATC汽车技术平台主办，复旦大学大数据研究院协办。九章智算云作为受邀的AI算力基础设施服务商，展现了中国企业在智能驾驶底层技术领域的深厚积累与创新能力。&lt;br&gt;未来，我们将持续参与行业交流，推动技术开放与生态共建，为中国汽车产业的智能化转型注入强劲动力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>真香！刚骂完AI，Linux之父的首个Vibe Coding项目上线</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 15:06:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/14c32ba6-4250-4978-8901-f45ca54c0d89/1768201395481.png" style="width: 700%;" class="fr-fic fr-dib"&gt;时代变了，就连 Linus Torvalds 现在也氛围编程（Vibe Coding）了。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527915" data-ratio="0.7001953125" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZ8fslDia3gtGZxsdFmyB0UQOK8V0hKNAQ6gyRcd07Mjibv09ZPyptSiaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1024" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/62a6f83c-0c3a-49c5-ac24-e4ccfb080e0c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;上周末，最著名程序员、Linux 作者 Linus Torvalds 发布 Vibe Coding 项目的消息让不少人始料未及。&lt;/p&gt;&lt;p&gt;大神在 GitHub 上发布了一个名叫 AudioNoise 的新项目，和 Linux 并列。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAy427dp7ocWbBPNN82LZn2OYG7xRvgibMcWbE3Wc32vesxwic1NyWR4fA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.4203703703703704" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527916" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7a3b288d-86cd-43e2-8d63-0508e9960f59/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在自述文件中，Torvalds 说这是一个和吉他效果器相关的代码库，「这些效果器在利用 AI 技术『模拟箱体』&amp;hellip;&amp;hellip; 另外需要注意的是，这个 Python 可视化工具基本上是用 Vibe Coding 的方式编写的。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMiaAuGU6qeytHyicEiaEKtS3sPV48ZwCxXtQZPwjsnFAficqAumzpt7DoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8274725274725274" data-s="300,640" data-type="png" data-w="910" type="block" data-imgfileid="503527917" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a64dbb4a-3fa8-4ab3-ae2b-10a7d6028837/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Torvalds 表示，他对模拟滤波器的了解要比对 Python 的了解要多得多。一开始写这个项目时，他就像平时那样通过谷歌搜索然后照搬照抄的方式进行编程，但后来他决定省略中间环节 &amp;mdash;&amp;mdash; 也就是他自己 &amp;mdash;&amp;mdash; 直接使用 Google Antigravity 来实现音频样本的可视化。&lt;/p&gt;&lt;p&gt;看起来在新年假期里，Torvalds 也没有闲着，他也在顺应最近科技界最大的 AI 潮流。&lt;/p&gt;&lt;p&gt;对此，人们的反应既有欢迎的，也有谨慎的。首先当然是普大喜奔：「官宣了，Vibe Coding 是合法的。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8x6cUozDujmh2rWeTU3xcRkDxCjOsgncActwr0VSgVPykjFfUXmg2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.30886075949367087" data-s="300,640" data-type="jpeg" data-w="395" type="block" data-imgfileid="503527919" data-aistatus="1" data-original-style="width: 332px;height: 103px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/ee470b50-5d4f-47e0-83ab-d2df3b4876c7/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Torvalds 首个 AI 项目，生成了什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个名为「AudioNoise」的项目在 5 天前上传到了 GitHub，目前已经收获了 1.4k 的 Stars。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAqbDaPZiaWMYwbgDU6eoqpmDXTIEQotctFyIjicoZZVjnG8NicIuXXhRDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.40555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527921" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d6071f6d-92b2-4a74-9967-6629c1135407/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;GitHub 地址：https://github.com/torvalds/AudioNoise&lt;/p&gt;&lt;p&gt;根据主页介绍，&lt;strong&gt;AudioNoise 项目源自 Torvalds 几个月前做的一个「随机吉他效果器板设计」（GuitarPedal），包括电路原理图和代码&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这是他在 Linux 内核之外的一个兴趣尝试，目的不是打造成品设备，而是探索运算放大器（op-amp）等电路设计原理，详情可参考以下项目。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAmaKTsw8FXKyGukLEnfmeQPy1y8SNNicICZNMaICREjx29FlCxEBibgHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.40185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527922" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8022af40-8e5c-490c-a1ce-ce7c4cbcb24f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;GitHub 地址：https://github.com/torvalds/GuitarPedal&lt;/p&gt;&lt;p&gt;从上个项目的结果来看，虽然 Torvalds 制作的基于树莓派 RP2354A 开发板和 TAC5112 音频编解码器的数字吉他单块效果器确实可以正常运行。但是 Torvalds 对一些模拟接口的选择并不太满意，尤其是那些电位器。此外他越来越讨厌那个会发出咔嗒声的脚踏开关，即使它能兼做编程时的引导选择开关。&lt;/p&gt;&lt;p&gt;因此，Torvalds 暂时没有去管硬件设计，而是认真琢磨了物理交互界面以及数字音效。他的想法很简单，「既然全都是数字化的，那就先搞模拟，别太纠结硬件。」&lt;/p&gt;&lt;p&gt;这就像 Torvalds 最开始做模拟电路一样，只是玩玩而已，不必太当真。&lt;strong&gt;本项目主要的设计目标是学习数字音频处理相关的基础知识，这和他此前做吉他单块项目来学习硬件的初衷完全一致。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;项目中并没有什么基于 FFT（快速傅里叶变换）的声码器，有的只是 IIR（无限冲激响应）滤波器和基础的延迟循环。&lt;/p&gt;&lt;p&gt;一切都是「单采样输入，单采样输出，并且零延迟」。采样可能会存储在延迟循环中，以便在后续调用时实现回声效果），但也没有进行任何复杂的实时处理。&lt;/p&gt;&lt;p&gt;Torvalds 对 TAC5112 在 ADC（模数转换器） 到 DAC（数模转换器） 链路中低于毫秒级的延迟表现很满意，因此现在也打算延续这种设计思路。再加上他以前没做过这些，所以单从新手这个角度来看，一切都显得非常基础和简单。&lt;/p&gt;&lt;p&gt;换句话说：这些 IIR 滤波器并不是现代单块或吉他音箱里那种高端的 AI「箱体模拟」。虽然它们确实能模拟移相器等模拟电路，但只是通过数字全通滤波器来模拟 RC（电阻器和电容器）网络的效果，并没有用到什么真正高深的技术。&lt;/p&gt;&lt;p&gt;Torvalds 特别强调了，&lt;strong&gt;项目中的 Python 可视化工具基本上是靠「氛围编程（Vibe-Coding）」写出来的&lt;/strong&gt;。他起初只是采用典型的「搜索并照猫画虎」式编程，但后来省去了中间人（他自己），&lt;strong&gt;直接让 Google Antigravity 来写这个音频采样可视化工具&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;对于 AI 编程工具的加入，Torvalds 自己的心得是：&lt;strong&gt;过程基本顺利&lt;/strong&gt;，虽然他有时需要琢磨一下使用「内置矩形选择」功能时到底出了什么状况。在告诉 Antigravity 直接写一个自定义的 RectangleSelector 之后，情况就好了很多。&lt;/p&gt;&lt;p&gt;如果要问&lt;strong&gt;氛围编程是不是要比他自己动手写出来的效果好呢？他的回答是肯定的&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACA5B0s3ACOgNb4gVEh33pzz8btQaUzZlhVVEPTOVzZfqsF6m5lsRIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.8101851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527923" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/a7797ce0-f68e-4b45-9c27-c93f48c24dc8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Torvalds 使用的 AI 软件开发平台 Antigravity，是去年 11 月谷歌刚刚发布的智能体式开发平台，直接对标 Cursor。&lt;/p&gt;&lt;p&gt;它将传统的 AI 驱动的集成开发环境 (IDE) 发展为「智能体优先」的形态。背靠谷歌自家的最新大模型 Gemini 3，可以驱动编程智能体自主规划和执行复杂的、端到端的软件任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkADgk2tVxxfYxaA9QbDUHHmCgiaWzbic511MGK8iapfu84USNKdTtpWbkDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.48055555555555557" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527924" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/40082d06-25ad-43fc-866b-55748c77779e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然，更重要的是，这个工具目前在招揽用户时期是免费使用的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;圈内热评：AI 大势下的「顺流而下」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Linux 之父开始使用 AI 编程工具这一「罕见的盛况」，在圈内引发了现象级的讨论，简直是「活久见」系列。&lt;/p&gt;&lt;p&gt;有人感叹，「我认识的最厉害程序员，包括那些构建编译器、CUDA 内核和操作系统等最核心功能的程序员，他们以前对「所有 AI 代码都是垃圾」的呼声最高。但如今，他们的想法正在迅速改变，并对 AI 的强大感到震惊。没有时间去否认这一点了。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAkD0vtkPPqN9FunMmSZwo34rxMN0wiaQ2MSvXG31fibOyicpqyLqVYbKhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5657407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527926" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c6722554-db52-4540-999f-4e766b47034a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Antigravity 创建者、谷歌 DeepMind 工程师 Varun Mohan 视 Torvalds 为自己的编程偶像之一，此次对其能够在最新的项目中使用该 AI 编程工具感到莫大的荣幸。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAKViaBtvqvJVt1eq5h7RFglF1icYj5PdqOyBaz8bVRa5VTw5PemKMOMTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527927" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/21148314-de6f-493e-a9fd-dacf7e4b00d1/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;云开发平台 Vercel CEO Guillermo Rauch 列举了 2026 开年发生的几件大事，其中 Torvalds 在其非内核项目中使用氛围编程与陶哲轩宣布 GPT 和 Aristotle 自主解决 Erdős 问题、编程大神 DHH 收回在 Lex 播客中发表的「AI 不会编程」的言论等并列。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAJAIUUn5msB7M0DficqTq61lSlgZ2gjNgSb2bpcdsjOHOuTZy55XXhJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0212962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527928" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d1049b86-28ea-400d-83c7-6de787b63a2a/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;几天前，Linus 还在骂 AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为曾经引领时代的程序员大神，Linus Torvalds 对于 AI 写代码这件事的态度还是相对保守的。至少直到去年底，他在几次采访中还是把编程分为「入门」与「生产」两个维度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv5lu1S4vnMM4s4xdIzso9Mw5l5pCiaxB6VPWMqs77azddWfLsL3AfLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527929" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/88bdfdcb-f8c4-4a05-8610-55c8940f4f52/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他认为对于非专业人士来说 Vibe Coding 是一项降低门槛的伟大技术，但对于生产环境和内核开发，Linus 明确表示 Vibe Coding「是一个非常，非常糟糕的主意 &amp;mdash;&amp;mdash; 如果你自己都不理解代码的逻辑，当它在生产环境中崩溃时，你根本无法修复。」&lt;/p&gt;&lt;p&gt;Torvalds 认为目前的 AI 辅助编程主要是「90% 的营销加 10% 的现实」，极其反感那些利用 AI 生成「垃圾代码」并提交给内核维护者的行为。&lt;/p&gt;&lt;p&gt;1 月 7 日，在 Linux 内核开发人员讨论如何规范 AI 生成的 Linux 内核时，Torvalds 忍不住插话进来：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAEGcdqpgTBeibuWylF7K64Uf71j4f83XBh7WjdAHCkwWDH7A3yQ9pDAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.9453703703703704" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527931" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/b93e1aa8-c963-4704-9893-e5b5f4ad73c2/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;他表示：「讨论 AI 生成的垃圾毫无意义，简直愚蠢至极。那些生成垃圾内容的人根本不会在他们的补丁中注明这一点。所以，停止这种愚蠢的行为。我不希望任何内核开发文档包含任何关于人工智能的声明。」&lt;/p&gt;&lt;p&gt;这样厌恶的态度，让人想起当年他对老黄竖起的中指。&lt;/p&gt;&lt;p&gt;不知为何在骂完之后，Torvalds 就放出了自己用 AI 写好的代码。&lt;/p&gt;&lt;p&gt;AudioNoise 这个小项目，会成为 Linus Torvalds 的「真香时刻」吗？&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/theprimeagen/comments/1q9q2kd/linus_torvalds_is_a_vibecoder_now/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/AiBattle_/status/2010105477166969307?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://github.com/torvalds/AudioNoise&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://news.ycombinator.com/item?id=46569587&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/kimmonismus/status/2010445425694867753?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2010215226978042218?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/_mohansolo/status/2010023056778137699?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
