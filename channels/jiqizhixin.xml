<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>OpenAI：以后大家用AI赚的钱，我可能要抽成</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 16:46:07 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杜伟、泽南&lt;/section&gt;&lt;p&gt;今天一早，OpenAI CEO 奥特曼就发推晒收入，「仅我们的 API 业务而言，上个月就增加了超过 10 亿美元的 ARR（年度经常性收入）。」&lt;/p&gt;&lt;p&gt;他继续说到，大多数人只看到了 ChatGPT 的成绩，但 API 团队的工作表现同样令人惊叹。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDGyEELjkG3kLh4qGI1qHqExUgeKy0vFfUlVbGS5bn6JQZmG1UvEeWPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529918" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6a55da28-2746-4e8d-ab95-c512e7ccb2fb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;奥特曼此举或许是为了提振投资者的信心。这几天，OpenAI 被曝正计划寻求融资 500 亿美元，新的估值预计在 7500 亿美元到 8300 亿美元之间。&lt;/p&gt;&lt;p&gt;与此同时，在外媒 The Information CEO Jessica Lessin 主持的一场达沃斯论坛上，OpenAI CFO Sarah Friar 讨论了另一种商业机会 &amp;mdash;&amp;mdash;「价值共享」（value sharing）。&lt;/p&gt;&lt;p&gt;她提出，在药物研发领域，其他公司可以使用 OpenAI 的技术来发现药物。但一旦新药研发成功，OpenAI 将从自己的 AI 技术为客户创造的收益中分取一部分利润。&lt;/p&gt;&lt;p&gt;这意味着，OpenAI 可能正在考虑从「卖工具」转向「分利润」的商业模式。OpenAI 似乎不满足于只收「软件使用费」，而是想在客户发财时「抽成」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDbCa69SrqrmaUG5ASPDQ0RYyEOtEhuILMMCm0d5oqDEazriajLuDrfiaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529920" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6de88620-ccb4-4546-8a51-2a4cbb20ae3a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; OpenAI CFO Sarah Friar 在达沃斯论坛上。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;最近大家都在讨论 OpenAI 的收入压力，预测他们今年会改变策略想办法盈利。没想到改变商业模式，是这么个改变法？&lt;/p&gt;&lt;p&gt;此番报道一出，真可谓一石激起千层浪，OpenAI 又被推上了风口浪尖。&lt;/p&gt;&lt;p&gt;有人认为，这可能是对 AI 工具化认知的一次巨大颠覆。想象一下，如果你在使用 Photoshop，而 Adobe 却要求对你创作的每一件设计作品抽成。&lt;/p&gt;&lt;p&gt;如果这种做法成为行业标准，对于那些基于 AI API 构建业务的初创公司来说，整个商业模式的成本计算逻辑都将被彻底改变。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDXnL0H7rPEpDM90yOGBcg6PIZp5pcDIibwWWE2dW08G67TPDoiaTUes2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.40925925925925927" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529921" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4cdb1852-6be0-4200-a133-7e8fbe8556da/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;也有人分析道，「这听起来可能像是异想天开，但科学家们确实已经对大语言模型作为「想法合成器」和「研究助手」的潜力感到痴迷，并且 OpenAI 也确实在积极寻求获取生物、制药等领域的私有数据授权，用于模型训练。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDb0I6Na5FQ6N0kXTPr3F72goSsKWIUp4XuexaFQ83slebnI4jq1ybCw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.26944444444444443" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529922" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a0d96427-dac5-4005-bc38-44a7107f800b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不过，更有业内人士感叹道，「一家以非营利性质起家的公司竟然走到了这一步，真是令人尴尬，简直是一种耻辱。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDXGduIuCicym6p4Sbia7DPG2pyT5oObmmicLp0ulq66s97mOmiaXqUS90kA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0453703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529923" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/990e46f8-9850-4529-88f2-6178e4fe34dc/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;「所以，OpenAI 打算从用户使用其软件开发的知识产权（IP）中抽取分成，而他们自己的软件，却又是通过侵犯他人的知识产权构建出来的。」&lt;/p&gt;&lt;p&gt;一直以来，OpenAI 面临着 AI 训练数据的来源争议，其模型使用的训练数据中包括受版权保护的文章、书籍、代码和艺术作品。此前，《纽约时报》以及包括多位作家在内的个人就曾对 OpenAI 未经授权使用其数据来训练模型提起过诉讼。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDqjACB7iavOe4ac7nXNyRgibN11jF1VZicPwyXCaTerEuzhUPOBFPA1nnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.25092592592592594" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529924" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e026a181-51f5-4d8d-b7ee-7205412f7ca5/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对于企业来说，OpenAI 的这种模式是可接受的吗？答案或许是肯定的。并且，这可能会令 OpenAI 损失更多商业客户。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD6Xl5dzySmuK3bNAd1ibDKNX5IO4mVicOgaNR3y0uZ0vxzWxfP3W5Ojqw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.21481481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529925" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/8cceab91-bf49-49c4-89db-4191dd8edecf/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDMdec3u0iarAXqkv2lDUoVs0cMWbQYJ02jP6PnZyBII5RTTYvd8BFv7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.21203703703703702" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529926" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d446b6e3-6efb-4803-ae8a-5f656bd12aa8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;OpenAI 转变思路的背后，AI 正在加速药物研发&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 抛出收入分成论的原因，一部分看到是如今 AI 作为科研工具已经已经开始起效了。&lt;/p&gt;&lt;p&gt;最近，制药和生物技术公司纷纷开始使用各种形式的 AI 进行药物研发。已有多家大型医药公司宣布了与 OpenAI 的深度合作，尝试使用 OpenAI 的模型来分析大量数据并提出假设或测试方法。去年 10 月，为制药公司提供服务和设备的企业 Thermo Fisher Scientific 表示，它将使用 OpenAI 模型来加速药物开发，并识别哪些疗法不太可能成功。&lt;/p&gt;&lt;p&gt;OpenAI 似乎也在开发越来越复杂、专门用于生物学和药物方向的 AI 模型，以推动 AI 在药物发现过程中更直接地协助制药公司。&lt;/p&gt;&lt;p&gt;例如，OpenAI 最近与生命科学诊断供应商 Revvity、Xero 以及其他生物技术公司进行了洽谈，想要获得授权以使用它们更专业的数据来训练自家 AI 模型。&lt;/p&gt;&lt;p&gt;在 AI + 医药研发方向，OpenAI 并不是唯一的一家，Anthropic 以及谷歌 DeepMind 等也与一些早期生物技术初创公司就数据许可或合作事宜展开了讨论。&lt;/p&gt;&lt;p&gt;Sarah Friar 无疑熟悉像 Recursion 这样较早期的 AI 药物研发公司，这些公司曾与制药企业达成交易，若其技术成功识别出药物，将获得巨额奖金。不过，目前这样的成功案例即使有，也寥寥无几。&lt;/p&gt;&lt;p&gt;竞争虽然才起步，但已非常激烈：OpenAI 的对手 Anthropic、Google DeepMind 以及 Alphabet 旗下专注于利用 AI 进行药物研发的子公司 Isomorphic Labs，也都已与早期生物技术初创公司就数据许可或合作关系进行了讨论。&lt;/p&gt;&lt;p&gt;上周末，Sarah Friar 在一篇博客文章中做了某些暗示，OpenAI 也可以在能源和金融领域达成这种价值共享类型的安排。「基于知识产权（IP）的许可协议和基于结果的定价，将分享所创造的价值，」Sarah Friar 这样写道。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDRggS2jBriaAasibCo0peJWAluZ0vUjUtlHGyNzt1WfCB0DiboZ3SBAibTw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529928" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/d4432112-f81a-4e34-8de4-ad7a318b9096/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 博客地址：https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;大语言模型已经很擅长发现人类可能错过的架构和形态。OpenAI 的模型有时可以将不同领域的概念联系起来，提出新型实验建议，涉及从核聚变到病原体检测的各个方面。尽管这些模型存在许多局限和错误，但科学家们似乎仍对它们充满热情。&lt;/p&gt;&lt;p&gt;虽然这听起来可能有些天马行空，想象 OpenAI 通过 IP 许可或版税获得的收入比广告还多，但 Sarah Friar 的言论极其清晰地释放了他们想要做什么的信号。&lt;/p&gt;&lt;p&gt;问题在于，在 OpenAI 完成目前正向投资者寻求的数百亿美元融资之后，她是否还会继续谈论这一点。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theinformation.com/newsletters/applied-ai/openai-plans-take-cut-customers-ai-aided-discoveries?rc=jn0pp4&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.tipranks.com/news/the-fly/openai-spoke-to-revvity-about-licensing-data-the-information-reports-thefly&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>陈天奇、贾扬清点赞：Vibe Coding版PyTorch，连论文都是AI写的</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 16:42:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda、泽南&lt;/section&gt;&lt;p&gt;前两天，Node.js 之父 Ryan Dahl 在 X 上断言：「&lt;strong&gt;人类编写代码的时代已经结束了&lt;/strong&gt;。」该帖引发广泛讨论，浏览量更是已经超过了 700 万。而现在，我们迎来了一个对这一判断的有力证明。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529847" data-ratio="0.5400254129606099" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDlXAsWZTBI8zJJfHILDY7ia26riaiciaoYQwLvicSXKH9UwqHDB5EpnJiaWMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="787" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9b890084-f026-4076-b1ba-eabc571b9f08/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;刚刚，英伟达杰出工程师许冰（Bing Xu）在 GitHub 上开源了一个新项目 &lt;strong&gt;VibeTensor&lt;/strong&gt;，让我们看到了 AI 在编程方面的强大实力。&lt;/p&gt;&lt;p&gt;从名字也能看出来，这是 Vibe Coding 的成果。事实也确实如此，这位谷歌学术引用量超 20 万的工程师在 X 上表示：「&lt;strong&gt;这是第一个完全由 AI 智能体生成的深度学习系统，没有一行人类编写的代码。&lt;/strong&gt;」&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529848" data-ratio="0.6615776081424937" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDQHenXRVBYTSyc96xBiaeiczVqJM5kJVxvEYJwqWzKNyaOGia75l0oKibIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="786" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5ee5114b-9eeb-45e7-8161-418c7bed53be/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;更具体来说，VibeTensor 是一个可运行的深度学习系统，配备了 RCU 风格的调度器、缓存分配器和反向模式自动微分器。该智能体还发明了一种&amp;nbsp;&lt;strong&gt;Fabric 张量系统&amp;nbsp;&lt;/strong&gt;&amp;mdash;&amp;mdash; 这是目前任何框架中都不存在的新东西。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529857" data-ratio="0.5342592592592592" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDRibMfOBHBgcm2V2edLU1lmicXFP6bugkHoWjTM8RTMPJ6lgGOx34nrfQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/32951d9c-aed9-4d82-98ad-482cb81871ab/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 很明显，许冰分享的这张项目架构图也是 AI 生成的&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;其 Vibe Kernel 包含 13 种不同类型、总计约 4.7 万行代码的自动生成内核，这些内核使用 Triton 和 CuteDSL 编写，并且具有很强的性能表现。&lt;/p&gt;&lt;p&gt;许冰表示，VibeTensor 由&lt;strong&gt;英伟达的第四代智能体&lt;/strong&gt;生成。但它也呈现出了一种「&lt;strong&gt;弗兰肯斯坦效应（Frankenstein Effect）&lt;/strong&gt;」：系统本身是正确的，但某些关键路径的设计效率低下。因此，其性能无法与 PyTorch 相媲美。&lt;/p&gt;&lt;p&gt;更重要的是，许冰强调：「自 2025 年夏天以来，我一行代码都没写过。」他说这项工作是他看过 Andrej Kaparthy 的播客之后开始的。「我当时并不认同他的观点，所以我和 Terry Chen（英伟达首席工程师）开始用它来测试我们的智能体的能力。弗兰肯斯坦效应最终暴露了我们智能体的一些局限性 &amp;mdash;&amp;mdash; 但方向很明确。」&lt;/p&gt;&lt;p&gt;该项目在 X 上引起了不少关注，许冰的几位著名英伟达同事（也被列为参与者）也有分享点评。&lt;/p&gt;&lt;p&gt;比如陈天奇表示：VibeTensor 很有意思，它表明 AI 智能体能够构建深度学习框架这样复杂的东西。「生成的代码还有一些需要改进的地方，但它能够做到这一点本身就非常有趣。」&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529850" data-ratio="0.42857142857142855" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDCm86TUxoMTTOJfMvDQ2XzCfF30zqKBOGibUGXF04ibaYACiaBwqzMUfCg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="784" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cbdc2ac9-07b3-464a-8f2a-31a911296563/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;贾扬清的评价则更高，他表示该项目的出现罕见地验证了一个根本性问题：AI 能否编写复杂的系统代码？而该项目给出的答案是「能，但是&amp;hellip;&amp;hellip;（仍有问题）」。他说 AI 正以惊人的速度前进，「如果我们能掌握更多正确的原则，AI 终将完全超越人类程序员。这就像 2015 年 1 月的 AlphaGo。」&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529851" data-ratio="0.45616264294790343" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD0tic1X17bGibywfTYwRVHYVETws69QgvVA44XLdc2Hib2mQWvgBCQ78gw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="787" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f58825f7-8071-49cb-a890-d59a6a89ae8a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;目前，许冰已经在 GitHub 上 NVlabs 帐号下发布了 VibeTensor 的相关内容，其中也包含一篇论文。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529853" data-ratio="0.375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDT6e4kVu6Zm18kd0qSx1icAF9b7vmKHdTBR4uuq6B5hgkVTC8snSbiazA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/01e0ce16-3512-490d-996f-b7721fa7cc7b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：VibeTensor: System Software for Deep Learning, Fully Generated by AI Agents&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://github.com/NVlabs/vibetensor/blob/main/docs/vibetensor-paper.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目链接：https://github.com/NVlabs/vibetensor&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有意思的是，当我们初看这篇论文时，我们发现论文中有一些 AI 生成的内容。于是我们询问了许冰本人，而他给出的答案让我们非常震惊：&lt;strong&gt;这篇论文竟也是 100% 由 AI 撰写的！&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529852" data-ratio="0.5421940928270043" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD6Ig1zmToY5kuMapM8gNfZcDQCiasXZWt94cBic5J9qcbiaBmu2icC4kUOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="474" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/bdfae72e-a737-4190-a4c3-5760743c3741/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 许冰的回复&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;下面我们就来详细看看这个 AI 编写的项目究竟是什么。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;VibeTensor：全球首个完全由 AI 智能体生成的全栈系统&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VibeTensor 可不仅仅是又一个深度学习库。它是全球首个完全由 AI 智能体生成的全栈系统。从 Python/Node.js 的上层绑定，到 C++ 核心调度器，再到最底层的 CUDA 内存管理，每一行代码的增删改查、每一次 Bug 的修复、每一轮构建验证，全部由英伟达第四代智能体（Agent）独立完成。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529855" data-ratio="0.6657407407407407" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDxlLjJapWbvJV5jpIzN8yjcibherFa4raO4WPmibffut79wJOawatCo3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/721be502-d9ec-4f4d-91b9-1754bd6e1345/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而人类的作用是提供了高层级的需求指导，然后像监工一样看着 AI 智能体在两个月内疯狂输出。下面就来拆解一下这个氛围编程版的 PyTorch：VibeTensor。&lt;/p&gt;&lt;p&gt;首先，性能上虽然 VibeTensor 目前还无法与 PyTorch 这种经过多年磨砺的框架抗衡（根据论文测试，部分场景慢了约 1.7 到 6.2 倍），但作为一个功能完整的技术原型，其设计的完整度令人吃惊。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529854" data-ratio="0.6194444444444445" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDBUibket7lkeiaUh6WJY0QEDnXc9IJzJ8liaMB0KF3Swrwm5oMmmOoticBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/a21361c3-9555-4331-9a43-f01c72d29434/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529856" data-ratio="0.3888888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDYn5NAxWPSeiaPlc6RiaHTnecdzGVUXXZib6gQcrzEjaFDDru3oG5k78Kg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/53f2b295-c5db-4ea6-9fa1-87b6fa0693b7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;根据论文描述，VibeTensor 并不是一个简单的包装库，它拥有极其硬核的底层架构。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心运行时的「暴力美学」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VibeTensor 的 C++20 核心并非简单的库调用。它实现了一个完整的 TensorImpl 架构，作为参考计数的 Storage 之上的视图。令人惊讶的是，AI 赋予了它支持非连续视图（Non-contiguous views）和 as_strided 语义的能力，并引入了原子版本计数器来确保原地（In-place）操作的安全性。&lt;/p&gt;&lt;p&gt;在算子调度层面，AI 构建了一个 schema-lite 调度器，能够将 vt::add 这样的操作名精准映射到 CPU 或 CUDA 的内核实现上。这种设计支持锁定（Boxed）和非锁定（Unboxed）调用路径，并通过不可变的快照状态（Snapshot states）实现了稳态下的无锁调用，极大地压低了调度开销。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;独创的 Fabric 张量系统：不属于任何现有框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 VibeTensor 的所有组件中，最令人振奋的莫过于名为 Fabric 的实验性子系统。这是目前市面上任何主流深度学习框架（如 PyTorch 或 TensorFlow）中都不曾以这种形式存在的概念。&lt;/p&gt;&lt;p&gt;Fabric 本质上是一个显式的多设备抽象层。它的核心使命是打破单卡运行时的限制，直接接管硬件拓扑的自动发现过程。根据论文描述，Fabric 能够主动识别 CUDA P2P（点对点）和 UVA（统一虚拟地址）支持情况。&lt;/p&gt;&lt;p&gt;不同于传统框架将多卡通信隐藏在复杂的分布式 API 后，Fabric 提供了一套透明的可观测原语，允许研究者直接控制内存的放置与同步策略。&lt;/p&gt;&lt;p&gt;在 VibeTensor 的 Blackwell 评估中，AI 甚至基于 Fabric 构建了一个可选的环形全归约（Ring-allreduce）插件。这种插件直接绑定了 CUTLASS 的实验性内核，完全绕过了 NCCL。这意味着 AI 已经开始尝试从底层通信协议层面，去重构大规模分布式训练的逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529861" data-ratio="0.649074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDZCNa38fcNSE3ReKofxUwaemBXuiaIGVJXZxPsoFktlBnhMM0n0TErsQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/52236822-b80d-4daa-9c61-0b500832105a/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;异步优先的「Node.js + Python」双前端&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在用户界面上，AI 并没有止步于复刻一个 PyTorch。它不仅利用 nanobind 打造了一个高度兼容的 Python 覆盖层（vibetensor.torch），还开创性地引入了一个基于 Node-API 的 Node.js 插件。&lt;/p&gt;&lt;p&gt;这个 JavaScript/TypeScript 界面采用了纯粹的「异步优先」设计。所有的重负载任务都被调度至 napi_async_work 以避免阻塞 Node 事件循环，并通过一个全局在途任务上限（VBT_NODE_MAX_INFLIGHT_OPS）来精细控制排队压力。这种横跨数据科学（Python）与后端工程（Node.js）的选型，体现了 AI 智能体在处理异构开发环境时的灵活性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 内核套件：从算子到显存的全自动进化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在最底层的算子实现上，VibeTensor 附带了一个由 AI 生成的庞大内核套件。这里包含了 200 多个源文件，涵盖了从基础的 LayerNorm 到复杂的 Fused Attention 等各类算子。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529858" data-ratio="0.32407407407407407" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD62IBsoMhR0GQRrgnhCzic5YqHMf67jPficCme5FnaHskpLUp7QOYUrXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/9c9d81a6-4aa1-44b6-badb-23341dc445b5/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这些内核利用了 Triton 和英伟达自家的 CuTeDSL 编写。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529859" data-ratio="0.6268518518518519" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDK8GfgPXbEJcLKDTFnSVz6xbEJjmMIVwgxMkvuqA5Y9TXEmjc8lhezQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/761e26ad-62e0-4b46-bef8-9684a8d54fa6/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;值得注意的是，AI 生成的内核并非只是「能用」，在 H100 的实测中，其生成的 Fused Attention 内核在特定形状下，前向计算比 PyTorch 的原生 FlashAttention 快了 1.54 倍，后向计算快了 1.26 倍。尽管这只是孤立算子的表现，但它证明了 AI 在掌握硬件特性（如 Hopper 架构的 TMA 或 Tensor Cores）方面的巨大潜力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529860" data-ratio="0.3638888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDRiazbbbAchmg6mawTT0LEZ7iaYChcecU6gG34CicpH4vmicxjY1ibic5ltLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/e0b428cf-feb5-4541-a071-9e04cba18f85/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;弗兰肯斯坦效应：AI 编程的隐形墙&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管 VibeTensor 能够跑通复杂的神经网络模型，但许冰和团队在论文中诚实地提出了一个引人深思的概念：「&lt;strong&gt;弗兰肯斯坦效应（Frankenstein Effect）&lt;/strong&gt;」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529862" data-ratio="0.6268518518518519" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDf31SRicMvoPv0qrSuHBM2qe036VQzOgHzMh1mq3wWXKlLRZfibbjCAuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/09bf0e52-c6a8-4683-90ba-20f38c49ff53/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这是 AI 智能体在构建复杂系统时暴露出的核心局限性。简单来说，AI 能够确保每一个局部子系统（如调度器、分配器、算子）在逻辑上是正确的，且能通过单元测试。但当这些局部组件拼凑成一个庞大的全局系统时，它们之间会产生意想不到的「摩擦」，形成性能瓶颈。&lt;/p&gt;&lt;p&gt;例如，AI 为了确保多线程环境下的安全性，在 Autograd 引擎中设计了一个非重入的全局互斥锁。这个设计从局部看非常稳健、安全，但在全局运行时却成了「扼杀」并行性能的元凶，导致原本高效的显卡内核因数据等待而频繁空转。这种「正确但低效」的代码，正是目前智能体在系统级架构设计上的天花板。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 辅助的开发方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VibeTensor 的诞生并非源于一次简单的提示词工程，而是一场长达两个月的、由高层级人类指令驱动的 Agent 自主演化过程。许冰也让 AI 在论文中用一个章节专门总结了「AI 辅助的开发方法」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 彻底的「黑盒」工作流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这场实验中，人类的角色从「程序员」彻底转变为「监工」与「策略制定者」。许冰及其团队并没有进行任何代码层面的 Diff Review（差异审查），也没有手动运行过任何验证命令。&lt;/p&gt;&lt;p&gt;相反，开发流程被简化为一个持续循环的闭环：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;目标设定&lt;/strong&gt;： 人类指定一个作用域明确的目标和必须遵守的约束条件。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;代码生成&lt;/strong&gt;： AI 智能体自主提议代码更改，并以 Diff 的形式应用到仓库中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工具校验&lt;/strong&gt;： Agent 会自动调用编译器、测试框架和差异检查工具。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多智能体评审&lt;/strong&gt;： 为了弥补单体 AI 可能存在的盲点，团队引入了多 Agent 协作评审机制，用于捕捉缺失的边界情况、冗余的抽象或是潜在的安全隐患。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 测试驱动的「硬核」规范&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Agent 驱动的开发中，&lt;strong&gt;测试不再是锦上添花，而是唯一的「真理来源」&lt;/strong&gt;。VibeTensor 的每一行代码都必须经过 C++（CTest）和 Python（pytest）双重测试套件的洗礼。&lt;/p&gt;&lt;p&gt;更具创新性的是，AI 智能体还利用 PyTorch 作为一个「参考原件」，建立了一套自动化的 API 对齐检查器。当 AI 编写的算子出现数值偏差或内存泄漏时，Agent 会自主分析报错日志，添加一个最小化的回归测试用例，并重新进入修复循环。这种「测试即规格说明」的模式，确保了即使在缺乏人工干预的情况下，生成的 16 万行代码依然保持了极高的逻辑一致性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 跨层级调试的挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文揭示了一个有趣的现象：&lt;strong&gt;AI 在处理「单次正确」的任务时表现卓越，但在处理系统的「组合稳定性」时却面临巨大挑战&lt;/strong&gt;。例如，在 Fused Attention 算子的移植过程中，Agent 经历了多次挫败：从最初的参数超限、显存对齐错误，到运行数千次后才暴露出的缓冲区初始化隐患。&lt;/p&gt;&lt;p&gt;这种跨越 C++ 运行时、CUDA 驱动程序和 Python 封装层的多级调试能力，正是此次英伟达第四代智能体展示出的最核心竞争力。它证明了 Agent 已经能够理解复杂的内存语义和硬件约束，而不仅仅是模仿代码片段。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 工程师的「AlphaGo 时刻」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;VibeTensor 的出现并非为了取代 PyTorch，而是一场关于「生成式软件工程」的宏大实验。&lt;/p&gt;&lt;p&gt;正如前文所述，许冰提到这项工作的灵感源于 Andrej Karpathy 的播客。当时他并不完全认同 Karpathy 关于「AI 编程」的某些激进观点，于是决定和首席工程师 Terry Chen 一起，用最硬核的系统开发来测试智能体的极限。&lt;/p&gt;&lt;p&gt;现在，方向已经明确。虽然「弗兰肯斯坦效应」依然存在，但 VibeTensor 的诞生标志着一个新时代的开启：未来的系统软件可能不再是工程师逐行敲出来的，而是由人类定义需求、由 AI 在「氛围」中生成出来的。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/bingxu_/status/2014354974986408138&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/tqchenml/status/2014360719534227561&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/jiayq/status/2014373196934590593&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/rough__sea/status/2013280952370573666&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>思维链太长拖慢推理？把它「画」进隐空间！新框架RoT探索大模型隐空间推理新范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 16:37:03 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/a039cb52-11c0-414a-a597-8978d41c0203/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="2" data-pm-slice="0 0 []"&gt;在 LLM 时代，思维链（ CoT）已成为解锁模型复杂推理能力的关键钥匙。然而，CoT 的冗长问题一直困扰着研究者&amp;mdash;&amp;mdash;中间推理步骤和解码操作带来了巨大的计算开销和显存占用，严重制约了模型的推理效率。&lt;/p&gt;&lt;p data-path-to-node="3"&gt;为了解决这个问题，研究界近期尝试了「隐式 CoT」（Implicit CoT），即让模型在内部隐状态中完成推理，而不输出具体的文本。这种方法虽然快，但却是个「黑盒」：我们无法知道模型到底想了什么，也难以进行监督。&lt;/p&gt;&lt;p data-path-to-node="4"&gt;&lt;strong&gt;有什么方案既保证推理速度快，又使得过程可分析，还无需昂贵的预训练？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="5"&gt;针对这一挑战，腾讯内容服务部 BAC 联合清华大学与北京大学，提出了一种名为 &lt;b data-index-in-node="39" data-path-to-node="5"&gt;Render-of-Thought (RoT)&lt;/b&gt; 的新框架。RoT 的核心思想非常巧妙：&lt;strong&gt;利用多模态模型（VLM）已有的视觉编码器作为「语义锚点」，将文本推理步骤「渲染」为图像的视觉嵌入（Visual Embeddings）。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="6"&gt;这种方法不仅将推理过程压缩到了致密的视觉潜空间中，还通过视觉渲染让隐式推理过程变得可分析且可追踪。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDu68qibiaSoWEIOLO1oIjB0prvjZ6AdUibZDyr6BmdWgZWNLoKc2k8kZZg/640?wx_fmt=jpeg#imgIndex=1" data-ratio="0.5083333333333333" data-type="png" data-w="1080" data-width="1706" data-height="812" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDkypVhEUPwLvO0TQn2rv2Adc0icF8AQysF6yUDm65ic3MpXKO7a5wUWhg/0?wx_fmt=png&amp;from=appmsg" data-cropx1="91.49826989619378" data-cropx2="1599.7439446366782" data-cropy2="767.4048442906574" data-imgfileid="503529781" data-aistatus="1" data-original-style="width: 511px;height: 260px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/dcbb546b-c11d-4a10-b296-3e7ddc8b3be3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.14750&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github 地址：https://github.com/TencentBAC/RoT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Huggingface地址：https://huggingface.co/collections/TencentBAC/rot&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="7,1,0"&gt;&lt;strong&gt;显式太慢，隐式太黑盒？RoT 走出第三条路&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="10,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,0,0"&gt;显式 CoT (Explicit CoT)：&lt;/b&gt; 让模型把每一步推理都写出来，就像学生做数学题写步骤一样。生成几百个 Token 的中间步骤不仅费时，还极其消耗显存。&lt;/p&gt;&lt;p data-path-to-node="10,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,1,0"&gt;隐式 CoT (Implicit CoT)：&lt;/b&gt; 模型直接在内部隐状态中进行推理，不输出具体文本。这种方式就像把思考过程扔进了一个「黑箱」，缺乏中间过程的监督。&lt;/p&gt;&lt;p data-path-to-node="10,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,2,0"&gt;Render-of-Thought (RoT)：&lt;/b&gt; 另辟蹊径，&lt;strong&gt;把「思考」变成了「作画」&lt;/strong&gt;。利用视觉信息的高密度特性，将冗长的文本压缩成紧凑的视觉向量。这不仅有迹可循，还大幅提升了推理速度。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadYGQvTdaHZMdJriamtG2rMLpMRwOGNWtk69uz9OMYw7bb6jSEq14dP9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.785929648241206" data-type="png" data-w="995" data-width="995" data-height="782" data-imgfileid="503529627" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e1a0b74e-6bb2-4b2d-9fa9-fbd0986bde60/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;拒绝「黑盒」：让隐式推理「看得见、摸得着」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;RoT 是一种将文本思维链通过光学渲染（Optical Rendering）和视觉知识蒸馏转化为紧凑视觉表征的新范式。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;与以往需要从头学习「推理 Token」的隐式方法不同，RoT 直接利用了现有 VLM（如 Qwen-VL, LLaVA）中冻结的视觉编码器。通过将 LLM 的隐状态与渲染文本的视觉嵌入对齐，RoT 实现了&lt;strong&gt;即插即用（Plug-and-Play）&lt;/strong&gt;，无需额外的预训练开销。渲染方案将文本推理步骤转化为单行图像，隐空间推理方法通过投影头将 LLM 生成的隐状态与视觉特征对齐。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;为了适应自回归思维链的序列化建模，研究团队摒弃了固定尺寸的图像渲染方案，采用了&lt;strong&gt;单行图像&lt;/strong&gt;渲染。该策略可以根据文本长度动态修改所需的图像宽度。此外，单行的渲染方式确保图像的 Patch 严格按照从左到右的方式提取，自然地将视觉序列与文本顺序对齐。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadGiaYE8CKNNC49CxsGg8gIUSzXxFE8pY74kxnYPoa9uricibOn0OcIQsDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5370370370370371" data-type="png" data-w="1080" data-width="1093" data-height="587" data-imgfileid="503529628" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ab332645-f31d-4464-be5f-afd2f0676707/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="15"&gt;&lt;strong&gt;移花接木的艺术：两步训练实现「降维打击」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="16"&gt;RoT 的实现过程主要分为两个阶段，旨在逐步将 LLM 的离散推理能力转化为连续的视觉隐空间推理能力。&lt;/p&gt;&lt;p data-path-to-node="17"&gt;&lt;b data-index-in-node="0" data-path-to-node="17"&gt;阶段一：视觉对齐 (Visual Alignment)&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="18"&gt;这一阶段冻结了 LLM 和视觉编码器，仅训练一个轻量级的「视觉投影头」（Visual Projection Head）。目标是将 LLM 的文本隐状态映射到由视觉编码器提取的「渲染 CoT 图像」的特征空间上。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;在推理步骤 &lt;span data-index-in-node="6" data-math="t"&gt;t&lt;/span&gt; 时，生成的 latent embedding 可以记为&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadyhJ6qNsmGWdhjichy46z1GCml4N7vBIv2EeQJv6JPRylZIOv4FmsVug/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.09814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529633" data-aistatus="1" data-original-style="width: 175px;height: 20px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/84d7489e-3fec-4b38-baec-f9c91cc7085e/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 36.02%;"&gt;，target vision embedding 记为 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadXPXco9ZicicKeiaicZhNh8oTjdph5qHEQveYw76dmRAZSrGtVicfEKFrZUw/640?wx_fmt=jpeg#imgIndex=5" data-ratio="0.8571428571428571" data-s="300,640" data-type="png" data-w="105" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadgibg7iaP7yZfM8lQW54W2K2VoMUL90D8NSsPrvktXXrG0A5EicNlOibRTg/0?wx_fmt=png&amp;from=appmsg" data-cropx2="105" data-cropy2="89.55882352941175" data-imgfileid="503529634" data-aistatus="1" data-original-style="width: 21px;height: 20px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e1265094-e96a-4d0e-9800-db24469042cb/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 3.21%;"&gt;。此时 vision embedding 的对齐损失可以记为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadf9AwazQkfyLCzIQzqseNXSqfYibAJNvb5SdFqSKA72IqklJDFHZloNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3114942528735632" data-s="300,640" data-type="png" data-w="870" type="block" data-imgfileid="503529636" data-aistatus="1" data-original-style="width: 207px;height: 64px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/549be7e6-a41c-4791-b805-237f794a64b9/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="21"&gt;此外，在第一阶段中，为了使模型与所提出的推理模式保持一致，同时对 &lt;code data-index-in-node="33" data-path-to-node="21"&gt;&amp;lt;|img_end|&amp;gt;&lt;/code&gt; 这一 special token 和答案的交叉熵损失进行了建模：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadBarAZlo3no8O8UL8BhLqIUTpXt2EdbmzrSX2NRj33jOTtYUaTI6m9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.11574074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529637" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2c555f39-41f5-4191-8465-2b52638e2431/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23"&gt;其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadqoD8FuWNAGgHlTgL9CufmomvDAq4KnXCjOadd5pickrwqibvtHnbDVKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.0305343511450382" data-s="300,640" data-type="png" data-w="131" type="block" data-imgfileid="503529638" data-aistatus="1" data-original-style="width: 20px;height: 21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/bb0ef910-e116-428b-b39b-960677afc775/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 2.57%;"&gt;是生成的 latent visual tokens，&lt;span data-index-in-node="46" data-math="y"&gt;y&lt;/span&gt; 为问题 &lt;span data-index-in-node="52" data-math="x"&gt;x&lt;/span&gt; 的 ground truth 答案。阶段一的整体损失函数为上述两者加权：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadL98zUED0Qbn7qLqBz74GmucDqDOoooTsqqJE0gbsJjq7goRTDGaoDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.20588235294117646" data-s="300,640" data-type="png" data-w="850" type="block" data-imgfileid="503529639" data-aistatus="1" data-original-style="width: 192px;height: 40px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/e4260102-339b-43a9-939e-14de13d44f9b/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="25"&gt;&lt;b data-index-in-node="0" data-path-to-node="25"&gt;阶段二：潜在监督微调 (Latent Supervised Fine-Tuning)&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="26"&gt;在对齐之后，第二阶段通过 LoRA 微调 LLM，并且冻结已经训练对齐的投影头。此时，模型不再生成文本 Token，而是自回归地生成一串连续的「潜在视觉 Token」（Latent Visual Tokens）。这些 Token 在隐空间中模拟了视觉编码器的输出，最终引导模型解码出正确的文本答案。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadg2WZOSgzBhphMMh7cL9vxlGAhJuREiaVyia5b4CZfiaOWcBJ9drOp9CYA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.16203703703703703" data-type="png" data-w="1080" data-width="1094" data-height="177" data-imgfileid="503529641" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5b161342-5664-464c-a99e-3e0776f41c9f/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;strong&gt;推理与解码策略&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;推理过程要求模型自主地从连续的潜在推理空间导航到离散的文本解空间。研究团队探索了两种方案：&lt;strong&gt;基于 Special Token 的动态终止策略以及固定 Token 预算的静态终止策略。&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="29"&gt;基于 Special Token 的动态终止策略&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="30"&gt;推理阶段在第一个时间步长 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadUmh0N9fka7qlFdMztTjBwDznkqiby6UViay5JnAvgxRRiab89J5NnbQLw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.6043478260869565" data-s="300,640" data-type="png" data-w="230" type="block" data-imgfileid="503529644" data-aistatus="1" data-original-style="width: 40px;height: 24px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/f5138232-4cb8-43e7-adc1-c9bf587bdc45/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 4.31%;"&gt;&amp;nbsp;结束，此时终止标记的概率达到最大值：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad8tjseC36YIAI9tvNY28x2YnxDrHoFiaBCq7JBn5FAmSjib9p8cZpibkXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.10277777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529645" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/fba7ae8d-55f6-410d-8c31-68c26f6c7a83/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="32"&gt;其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadfuql4lPbKzxu3wia2B7gZpq4cRCfAv0EqtjL8fJoA0pJIiceaWR4MKNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="1.0810810810810811" data-s="300,640" data-type="png" data-w="111" type="block" data-imgfileid="503529646" data-aistatus="1" data-original-style="width: 20px;height: 22px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/d57c2e09-d8fb-4ec1-bff3-c0d210971133/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 2.57%;"&gt; 表示 Token 集，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadNhCnmcpt0qfKmQ36nPibSj34fHrbSkHSOfSSl0Svr5lM7gZrMt3Vgmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.238938053097345" data-s="300,640" data-type="png" data-w="113" type="block" data-imgfileid="503529647" data-aistatus="1" data-original-style="width: 20px;height: 25px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/c17fb0ab-c7b7-41b6-b61e-1493dfc80599/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 2.75%;"&gt; 表示在时间步长 t 时的隐藏状态。模型从后续状态&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadOHqGuJZWJ7yNmReWGyrNPibUAQRyzWwJIwXOHs89qGSv3sjFDsa6q8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5015197568389058" data-s="300,640" data-type="png" data-w="329" type="block" data-imgfileid="503529648" data-aistatus="1" data-original-style="width: 55px;height: 28px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/3349a054-f3d2-4944-8b89-380caa4dbefa/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 5.96%;"&gt;开始对文本答案进行解码。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="33"&gt;固定 Token 预算的静态终止策略&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="34"&gt;该策略将潜在思维链的长度限制为一个固定的超参数。达到这个阈值时，会手动添加 &lt;code data-index-in-node="38" data-path-to-node="34"&gt;&amp;lt;|img_end|&amp;gt;&lt;/code&gt; 这一 special token，以触发从潜在推理到文本生成的转换。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;研究团队在实验中发现，动态终止策略的性能明显低于固定 Token 预算策略。这种性能差距可能源于连续潜空间中自我调节停止机制的&lt;strong&gt;内在不稳定性&lt;/strong&gt;。在生成潜空间推理嵌入时，隐藏状态可能无法始终如一地为终止标记生成高置信度的预测，从而导致过早或延迟的转换，破坏推理流程。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;此外，采用固定 Token 预算策略时，每个数据集的最优 Token 预算各不相同。在 GSM8k-Aug 数据集上，32 个 Token 能实现最佳性能，而 MATH 数据集则需要 64 个 Token 才能达到峰值准确率。研究者推测这种差异的出现是因为 MATH 数据集更具挑战性，需要更长的推理链。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadCC0XZfdcXJQqZZxNzVwkx66xBFicvBFLiahfJIs04bdMBSMYbmW8Eh2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.6639784946236559" data-type="png" data-w="372" data-width="372" data-height="247" data-imgfileid="503529649" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/12fa8b7a-90a8-49eb-93d1-4247980375c6/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="37"&gt;&lt;strong&gt;实测数据说话：推理速度「狂飙」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="38"&gt;研究团队在 GSM8k、MATH、SVAMP 等多个数学和逻辑推理基准上对 RoT 进行了广泛测试。实验基于 Qwen3-VL 和 LLaVA-V1.6 等主流架构。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="39,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="39,0,0"&gt;显著的压缩与加速：&lt;/b&gt; 相比于显式 CoT，&lt;strong&gt;RoT 实现了 3-4 倍的 Token 压缩率&lt;/strong&gt;。在推理速度上，RoT 展现出了巨大的优势。例如在 Qwen3-VL-4B 模型上，Pass@1/&lt;a data-topic="1" href="javascript%3A;"&gt;#L&lt;/a&gt;（准确率与长度比）指标显著优于基线。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="39,0,0"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad0fDWHp3P8KmZlOFpHJjXicibTHMgWzRVVjN5r1tkbcvQYjkkqlDHOlrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.35833333333333334" data-type="png" data-w="1080" data-width="1094" data-height="392" data-imgfileid="503529651" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/d77688dc-3c72-4d3b-a7cc-d1b2b58eaa7e/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="39,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="39,1,0"&gt;优于现有的隐式推理方法：&lt;/b&gt; 与 Coconut、CoLaR 等最新的隐式推理方法相比，RoT 在准确率上表现出色。特别是在 MultiArith 数据集上，RoT (Qwen3-VL-4B) 达到了 97.2% 的准确率，显著优于同等规模下其他隐空间推理方案。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="39,1,0"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadTPBREseibFicPia8JK372yaYK294wRk4nEdqcRVQ7cgpch8mAxxiaJWQWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.3490740740740741" data-type="png" data-w="1080" data-width="1094" data-height="382" data-imgfileid="503529650" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/37113efa-9a50-4ee0-8dd7-eabcc4e10c3c/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadpqAPrud2evia53J4l5c9EqxDicr4UQ2lArIhVxjYuf1YdMrH0ZKIWfVw/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.398876404494382" data-type="png" data-w="1068" data-width="1068" data-height="426" data-imgfileid="503529652" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/ae1c1458-3c7b-4e02-ac8e-e8d27e006d5c/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="39,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="39,2,0"&gt;隐空间推理的可分析性：&lt;/b&gt; RoT 的一大亮点在于其&lt;strong&gt;可分析性&lt;/strong&gt;。由于隐状态被对齐到了视觉空间，可以通过热力图（Heatmap）等来观察模型的「思考过程」。研究团队展示了 MATH 数据集的一个案例。可以看到，生成的潜在 Token 呈现出明显的结构化模式，Token 相似度矩阵显示了推理的阶段性。这证明模型并非在随机生成向量，而是在进行有逻辑的隐式推理。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadNx89qV8oKvyaBNJ1sg6RyVDEKWDH3m7swCnSpfiaovAxlv1NufgIEVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.5351851851851852" data-type="png" data-w="1080" data-width="1791" data-height="958" data-imgfileid="503529653" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/fc8440e1-874a-4db8-a0ce-d2e9c35bcfeb/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="40"&gt;&lt;strong&gt;单行渲染 vs. 多行渲染&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="41"&gt;在 RoT 中，传统的固定尺寸的多行渲染会导致文本在图像中频繁换行。对于模型来说，这种换行在视觉空间中引入了不必要的「空间跳跃」，打断了语义的连续性。&lt;/p&gt;&lt;p data-path-to-node="42"&gt;为了验证这一点，研究团队对比了「固定尺寸的多行渲染图像」与 RoT 文中使用的「单行动态宽度图像」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadRnRZNGFW9p8Gicz4TJUCgMRd3raCnPacwsL3fGspdDofpvMo44fJlzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.5859106529209622" data-type="png" data-w="582" data-width="582" data-height="341" data-imgfileid="503529654" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/98bb8e5d-1297-4f56-9235-94e59665b9b4/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="42"&gt;如上图所示，单行渲染相比多行渲染收敛更快，同时能够更好地契合语言模型从左到右的序列生成特性。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;&lt;strong&gt;两阶段训练缺一不可&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="44"&gt;为了评估渐进式训练策略的效果，研究团队分别对每个阶段进行独立消融实验。&lt;/p&gt;&lt;p data-path-to-node="45"&gt;去除第一阶段会导致 MATH 的准确率从 33.2% 降至 22.2%，表明视觉对齐对于构建潜在空间结构以及在复杂任务中防止表示坍缩至关重要。同样，排除第二阶段也会导致性能显著下降，这会导致模型难以从连续的潜在空间中推导出最终答案。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadK1ibDPev5jJibQNt99ZPqlmLGggm5ibIqvspmiafFT3AzUWLX48vD1boibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.2594142259414226" data-type="png" data-w="717" data-width="717" data-height="186" data-imgfileid="503529655" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/4077d247-7701-4402-b9e7-0fcc2c7115b7/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="46"&gt;&lt;strong&gt;展望&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="47"&gt;Render-of-Thought 提出了一种极具前景的「视觉化思维」范式。它打破了文本模态的限制，利用视觉信息的高密度特性来压缩推理过程。&lt;/p&gt;&lt;p data-path-to-node="48"&gt;这项工作不仅大幅提升了推理效率，更重要的是，它通过「&lt;strong&gt;将思维渲染为图像&lt;/strong&gt;」这一直观的想法，为理解大模型神秘的内部隐空间提供了一扇新的窗口。对于未来在端侧设备等资源受限场景下部署强推理模型，RoT 提供了一条切实可行的技术路径。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>启动经费550万起！全球顶级AI人才看过来</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 15:05:14 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img data-aistatus="1" data-backh="211" data-backw="578" data-imgfileid="100005278" data-ratio="0.3648148148148148" data-src="https://mmbiz.qpic.cn/mmbiz_gif/Oax1aO3yZ9swXKItI7vROicnE9r2aDCTs0dNgXBVGmBMIcW1T2rAiczkviaLlyMWlu44hwl5hOm9bGPTRvBu56z5w/640?wx_fmt=gif&amp;from=appmsg#imgIndex=0" data-type="gif" data-w="1080" type="block" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ba464ce4-f7f8-441a-b292-747ace86b246/640.gif" data-order="0" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;strong&gt;致全球英才：&lt;/strong&gt;&lt;/p&gt;&lt;section data-role="outer" label="edit by 135editor"&gt;&lt;section data-id="167079" data-tools="135编辑器"&gt;&lt;section&gt;&lt;section&gt;&lt;section data-autoskip="1"&gt;&lt;p&gt;北京中关村学院是全新的高等教育科研机构，&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-tools":"135编辑器","data-id":"167079"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"margin: 10px auto;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"background-color: #f5f5f5;padding: 30px 10px;box-sizing:border-box;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-autoskip":"1","style":"text-align: justify;line-height:1.75em;letter-spacing: 1.5px;font-size:14px;color:#333333;background-color: transparent;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"margin-left: 5px;margin-right: 5px;margin-bottom: 15px;display: block;line-height: 2;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"font-size: 15px;letter-spacing: 0.5px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;与全国31所双一流高校共建，专注于人工智能与交叉学科的人才创新培养。&lt;/span&gt;中关村人工智能研究院是年轻的探索型研发机构，深耕前沿技术研发与产业转化。中关村两院秉持&amp;ldquo;极基础、极应用、极交叉&amp;rdquo;的颠覆式理念，以&amp;ldquo;培养AI领军人才&amp;rdquo;为使命。&lt;/p&gt;&lt;p&gt;我们拥有各层级人才项目自主评审权，将于2月6日面向全球英才召开人才线上交流会暨第四届中关村国际青年论坛宣导会，提供最直接权威的人才政策解读、在线答疑交流，诚邀全球顶尖人才参加！&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;strong data-brushtype="text"&gt;&lt;span data-mpa-action-id="mkq9ir60u71" data-pm-slice="0 0 []"&gt;会议邀请&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-id="166163" data-role="title" data-tools="135编辑器"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;时间：2026年2月6日&amp;nbsp;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role="paragraph"&gt;&lt;p&gt;&lt;strong&gt;形式：线上宣讲&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;报名：扫描下方二维码&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-ratio="0.9959349593495935" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/ZiaENxymVJPibRh2b99mSyibCWVjp305sJwtGtiaCguaJxfW17g1BZYyE55NkevZa6hZVATPLO5JaNFlTVicD3kOqYg/640?from=appmsg#imgIndex=0" data-w="246" data-width="88px" data-original-style="box-shadow: #979899 3.53553px 3.53553px 8px;margin: 0px 8px 8px 0px;border-radius: 0px;width: 88px;vertical-align: baseline;box-sizing:border-box;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7d6ea6c9-3d77-40d9-9bbf-8d0215789c15/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;section data-role="outer" label="edit by 135editor"&gt;&lt;section data-pm-slice='6 6 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]' data-role="paragraph"&gt;&lt;p&gt;&lt;strong&gt;截止时间：2026年2月1日&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;咨询邮箱：talent@bjzgca.edu.cn&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role="paragraph"&gt;&lt;p&gt;*本次宣讲会为邀约制，报名成功后将发送会议链接&lt;/p&gt;&lt;p&gt;期待与您在云端相会，共同探讨您的未来发展之路！&lt;/p&gt;&lt;/section&gt;&lt;section data-id="166163" data-role="title" data-tools="135编辑器"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong data-brushtype="text"&gt;&lt;span data-mpa-action-id="mkq9j2plrgb" data-pm-slice="0 0 []"&gt;会议议程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;（&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-role":"paragraph"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"line-height: 1.75;margin-bottom: 10px;display: block;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"font-size: 15px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;一&lt;/span&gt;）&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-role":"paragraph"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;两院整体情况介绍&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role="paragraph"&gt;&lt;p&gt;（二）&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-role":"paragraph"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;两院科研情况介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;（三）&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-role":"paragraph"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;海优人才政策介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-role":"paragraph"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;（四）中关村国际青年论坛介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;（五）&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-role":"paragraph"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;海优获得者经验分享&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"data-role":"outer","label":"edit by 135editor"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"data-role":"paragraph"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"line-height: 1.75;margin-bottom: 10px;display: block;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"font-size: 15px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;（六）在线答疑&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-id="166163" data-role="title" data-tools="135编辑器"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong data-brushtype="text"&gt;&lt;span data-mpa-action-id="mkq9j75i1z10" data-pm-slice="0 0 []"&gt;申请条件&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role="paragraph"&gt;&lt;p&gt;&lt;strong&gt;国家级领军人才：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.&amp;nbsp;一般应当取得博士学位。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2. 在国外著名高校、科研机构等担任相当于&lt;strong&gt;副教授及以上职务、具有较高科研水平和较强科技创新能力&lt;/strong&gt;，或者在国际知名企业担任&lt;strong&gt;高级职务的专业技术人才&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;3. 专业方向：从事&lt;strong&gt;人工智能领域以及部分交叉学科&lt;/strong&gt;（如自然学科、部分人文社会科学领域）的高层次人才（含非华裔外籍人才）。&lt;/p&gt;&lt;p&gt;4. &lt;strong&gt;2025年1月1日后回国（来华）工作，或者尚未全职来华。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5. &lt;strong&gt;任职要求&lt;/strong&gt;：在引进后须辞去海外工作或者在海外无工作，且全职回国（来华）工作不少于3年。&lt;/p&gt;&lt;p&gt;6. &lt;strong&gt;破格条件&lt;/strong&gt;：对业绩特别突出或者从事&amp;ldquo;卡脖子&amp;rdquo;关键技术领域的急需紧缺人才，可放宽学历等申报条件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;国家级青年人才：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;1. &lt;strong&gt;尚未全职回国（来华）工作，或者2025年1月1日后回国（来华）工作。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2. 在取得博士学位（在国内、海外取得博士均可）后至2026年4月15日前，在海外知名高校、科研机构、企业研发机构等获得&lt;strong&gt;正式教学或者科研职位，且具有连续36个月以上工作经历&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;3. 要求&lt;strong&gt;具有博士学位&lt;/strong&gt;，&lt;strong&gt;取得同行专家认可的科研或技术等成果&lt;/strong&gt;，且具有成为该领域学术带头人或杰出人才的发展潜力。&lt;/p&gt;&lt;p&gt;4. 40周岁以下，在海外取得博士学位且业绩特别突出的，可放宽工作年限要求（不适用于通过中外联合培养方式取得海外博士学位的情况）。&lt;/p&gt;&lt;/section&gt;&lt;section data-id="166163" data-role="title" data-tools="135编辑器"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong data-brushtype="text"&gt;&lt;span data-mpa-action-id="mkq9jgtfw9" data-pm-slice="0 0 []"&gt;支持保障&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role="paragraph"&gt;&lt;p&gt;&lt;strong&gt;1. 薪酬待遇：&lt;/strong&gt;提供极具竞争力的优厚薪酬待遇。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 获聘岗位：&lt;/strong&gt;入选国家级领军人才项目，获聘教授岗位、博导资格；入选国家级青年人才项目，获聘高级职称、博导资格。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 启动经费：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;国家级领军人才项目：给予每人100万元一次性生活补助+国拨300万元科研经费支持+市级生活补贴配套100万元+区级生活补贴配套50万元+两院配套项目经费。特别优秀者，科研启动经费一事一议。&lt;/p&gt;&lt;p&gt;国家级青年人才项目：给予每人50万元一次性生活补助+国拨经费资助100-300万元+市级配套生活补贴50万元+区级配套生活补贴50万元+两院配套项目经费。特别优秀者，科研启动经费一事一议。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. 科研支持：&lt;/strong&gt;&lt;/p&gt;&lt;section data-role="list"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;两院提供充足的算力支撑；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持申报国家重大项目、院立项目及自立项目，科研项目优先支持搭建博士生及博士后团队；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;学术生态涵盖31所共建一流高校、国家级科研机构及优质科创企业。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;5. 生活保障：&lt;/strong&gt;&lt;/p&gt;&lt;section data-role="list"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;引进落户：落户海淀，配偶及子女随迁；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;子女教育：优先保障海淀区中小学优质教育资源；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;安居保障：提供低于市场租赁价格的精装高级人才公寓保障；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;商业医疗：为本人、配偶及子女提供医疗保障。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;strong data-brushtype="text"&gt;&lt;span data-mpa-action-id="mkq9jlj73x5" data-pm-slice="0 0 []"&gt;关于两院&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-id="166163" data-role="title" data-tools="135编辑器"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;北京中关村学院：全新的高等教育机构&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role="paragraph"&gt;&lt;section data-role="list"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;携手顶尖高校，培养人工智能领军人才；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;推动人工智能与交叉学科领域的科研创新。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;中关村人工智能研究院：新型研发机构&lt;/strong&gt;&lt;/p&gt;&lt;section data-role="list"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;推动创新成果产业化落地，孵化创新企业；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;打造创新生态，赋能千行百业。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="3 3 []"&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2c6adc63-9454-4ff2-a2dd-af3e0d3eb192/1769151823374.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5ace1f8f-208d-4ce1-8009-5a448722649a/1769151839828.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;img data-aistatus="1" data-backh="567" data-backw="578" data-imgfileid="100005116" data-ratio="0.9814814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Oax1aO3yZ9tx9ibdAEBTVq1KoCrHfqqYIRVgqvUuYshjibgjZcxPbs61NKUJ3WYHnRJAUt4KibvsOX4ccJTo9T4HQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a152b75c-7d30-48b0-99a8-e5ca3c73a82e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>三星爆火递归模型TRM唯一作者被迫离职，内部不认可？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 14:58:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜冷猫&lt;/section&gt;&lt;p&gt;还记得三个月前，来自三星的一位研究员的独作论文发布即爆火，颠覆了递归推理模型架构，让一个仅包含 700 万个参数的网络，性能比肩甚至超越 o3-mini 和 Gemini 2.5 Pro 等尖端语言模型，震惊了大量业内研究人士。&lt;/p&gt;&lt;p&gt;这篇论文是大名鼎鼎的《Less is More: Recursive Reasoning with Tiny Networks》，带来了影响深远的&lt;strong&gt;微型递归模型 TRM&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;关于这篇论文和模型的相关信息，可以参阅&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650994404&amp;idx=1&amp;sn=145d2c814af6a15e537dbf1028a2a8ff&amp;scene=21#wechat_redirect" target="_blank"&gt;我们之前的报道&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;按理说，发布成果的&lt;strong&gt;唯一作者 Alexia Jolicoeur-Martineau&lt;/strong&gt; ，在三星应当平步青云，带领全新的团队继续后续研究，用 TRM 的后续研究助力三星在人工智能领域的进步。&lt;/p&gt;&lt;p&gt;可惜一切似乎都不尽如人意。突然间，Alexia 就发推说要离职。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDDS2LKxXEC7QTdZYviaEpuBAicE1kC99b0HcubIOKz4KCJ0wzSOmHSSzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5018518518518519" data-type="png" data-w="1080" data-width="1148" data-height="576" data-imgfileid="503529824" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e991230d-a8a5-4672-a248-93c685b4bb45/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;从推文中明显能看出 Alexia 的怨气。&lt;strong&gt;「在 TRM 取得巨大成功（为公司赚取数十亿美元）后，我在三星的生活变得一团糟。」&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDib7Mn1iczTQY9GtkWSmSeUeepbkL6iaicYcLcBD2o2qRsGXsDSjx4IVWMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.362962962962963" data-type="png" data-w="1080" data-width="1162" data-height="422" data-imgfileid="503529826" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/63bb6cf6-8573-4512-bcf2-632074fed4a9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;止不住的怨气来源于， Alexia 的工作，加拿大蒙特利尔三星先进技术研究所人工智能实验室（SAIL Montreal）取得的最大成绩，并未能够被内部认可。&lt;/p&gt;&lt;p&gt;听上去令人匪夷所思。TRM 在学术界的成绩有目共睹，一度被视为三星在 AI 领域崛起的信号。可以确定的是，在 TRM 论文发表后，三星的股价的确产生了相当可观的涨幅。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDib2HPJrg6mLTACLxpRZWygT003jibibibNLnOaia9IjzWyGJFGOGzC9UZ9g/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8601851851851852" data-type="png" data-w="1080" data-width="1290" data-height="1110" data-imgfileid="503529827" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/00993a0e-281c-4498-b93e-2b5ef1317c59/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，Alexia 与她的论文也获得了 2025 年的 ARC Prize 论文奖的头名，获得了五万美元的奖金。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDB9cic3uF6NSoGnjXw9iasosdibbiciaJah4F55fTCfTx6UCqXGZYECMja4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.26296296296296295" data-type="png" data-w="1080" data-width="1270" data-height="334" data-imgfileid="503529828" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b3a37162-e1fa-4204-b985-7531d1ec5eee/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在获奖后，ARC Prize 与 Alexia 做过一次专访，当时她已提及，她未能与韩国的高管们联系，而他们是从韩国文章中知道这件事的。或许这已经暗示了一些三星内部对于 TRM 和 SAIL 的态度。感兴趣的读者们可以查看专访视频。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;专访链接：https://www.youtube.com/watch?v=P9zzUM0PrBM&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDBficplibeK2vkbwU2pFPIVr57pZfS9b2nzHpwnhE2yQzA9Sn8xEUicsYg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1" data-type="png" data-w="374" data-width="374" data-height="374" data-imgfileid="503529829" data-aistatus="1" data-original-style="width: 283px;height: 283px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f9437a51-00b1-4e3e-8056-02f6d593b165/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;关于 Alexia Jolicoeur-Martineau 本人，目前在三星从事人工智能研究工作。2019 年冬季，开始在蒙特利尔学习算法研究所（MILA）攻读人工智能博士学位。学术背景涵盖统计学与计算机科学（数学与计算机科学学士、统计学硕士）。&lt;/p&gt;&lt;p&gt;Alexia 此前的研究工作包括：GottaGoFast、对抗式得分匹配（Adversarial Score Matching）、相对式 GAN（Relativistic GANs）、采用交替优化训练的 LEGIT 模型，以及对贝叶斯树先验的研究。此外，还使用多种生成对抗网络（GAN）生成过猫咪图像（Meow Generator）。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDMiadz2mMadHByyGA5PPvZibp4ZUtCYdq9qciblaQuUs6CTkT1KiaKg7iaGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1" data-type="png" data-w="530" data-width="530" data-height="530" data-imgfileid="503529830" data-aistatus="1" data-original-style="width: 344px;height: 344px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/346e31f9-ed76-4a98-a1cf-ad7175c0710d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 这下认识了。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;据 Alexia 本人所述，2018 年，她被大学拒绝，所以选择了用一块 GPU 开始自己做 AI 研究。撰写的第二篇论文被 DeepMind 研究员 Ian Goodfellow 选中，于是命运的齿轮开始转动。Ian 帮助 Alexia 进入 AI 领域，随后她便开始和 Ioannis Mitliagkas 攻读博士学位。&lt;/p&gt;&lt;p&gt;在官宣离职的推文下，我们看到了熟悉的身影。Sebastian Raschka 对她的离职表示遗憾：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDqUTfqIdTP8ic2a0Ld7wMtoHovIbr9ibn00oMU5yTxIWGPrpfkV8L83wA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3731481481481482" data-type="png" data-w="1080" data-width="1174" data-height="438" data-imgfileid="503529832" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/e8200800-b8f2-4694-92ce-eacc58d194c1/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;而 Liquid AI 则直接开始挖人：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="248" data-imgfileid="503529836" data-ratio="0.21296296296296297" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDqubbiaicYpYibyzwhtaKoSic3G6AajiayIFvwKyzLuFoJj1hekkIibricrjtA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" data-width="1166" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/67bda997-2130-4a9b-ace8-82b384d0c788/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最终 Alexia 会在哪继续她的研究之路，让我们拭目以待。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Nature子刊｜上智院、复旦、无限光年发布MAPLE框架，破解甲基化衰老与疾病风险预测的泛化难题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 23 Jan 2026 14:04:23 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;衰老是具体而实在的：它既体现在皱纹增多、体力下降这些多数人能感受到的变化上，也发生在身体内部细胞和分子水平的缓慢累积之中。过去十多年里，科学家逐渐认识到，DNA 甲基化作为一种稳定而系统的表观遗传标记，能够记录个体真实的生物学衰老状态，并与多种慢性疾病的发生风险密切相关。因此，表观遗传时钟（Epigenetic Clock）不仅被视为衡量「人老得快还是慢」的工具，也逐渐成为评估衰老干预效果、预测疾病风险、以及开展个体化健康管理的重要量化手段。&lt;/p&gt;&lt;p&gt;然而，一个长期制约该领域发展的核心难题在于泛化能力。不同研究队列、不同测序平台、不同预处理流程乃至不同组织来源之间，都会引入显著的技术差异和系统偏移。许多经典的衰老时钟（Aging Clock）在原始研究数据中表现良好，但一旦应用到新的数据集或真实临床场景，预测精度便明显下降。这使得表观遗传时钟在临床转化、跨队列研究以及长期健康随访中的应用受到限制。&lt;/p&gt;&lt;p&gt;在这一现实背景下，上海科学智能研究院（下称上智院）与复旦大学人类表型组研究院、复旦大学人工智能创新与产业研究院（下称复旦大学 AI&amp;sup3; 院）、无限光年技术有限公司（下称无限光年）等进行联合研究，提出了一个稳健的基于成对学习的甲基化年龄与疾病风险预测框架&amp;nbsp;MAPLE（A Robust Computational Framework for&amp;nbsp;Methylation&amp;nbsp;Age and Disease-risk&amp;nbsp;Prediction&amp;nbsp;Based on&amp;nbsp;Pairwise&amp;nbsp;LEarning），从方法学上引入成对学习思想缓解了高维小样本条件下的过拟合问题，并为跨平台、跨组织的统一建模提供了可行路径。&lt;/p&gt;&lt;p&gt;在全部 31 项测试中，MAPLE 的平均绝对误差为 1.6 年，显著优于多种现有主流方法，并且在疾病识别上曲线下面积均值达 0.97，对疾病前驱状态检测也达到 0.85，显示其精准识别早期风险的能力。MAPLE 不仅在数值精度上取得了突破，更重要的是在方法层面提供了一种可泛化的表观遗传建模范式，为衰老干预评估、慢性病早筛以及长期健康管理奠定了更加可靠的量化基础。&lt;/p&gt;&lt;section&gt;&lt;img data-ratio="0.5435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027226" data-aistatus="1" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmFicnqVlYiaoFLrJia2Siab4tm8zdwXkaaoo11BdLVLWK7LoOKwfiaNicFqrgc3mL8g0No808j7AFlEdYw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/878ba106-1108-48d0-97ac-49bf201c8e70/640.png" alt="图片" data-before-load-time="1769148150815" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="2 2 []"&gt;论文题目：A robust computational framework for methylation age and disease-risk prediction based on pairwise learning&lt;/p&gt;&lt;p&gt;论文地址：https://www.nature.com/articles/s43588-025-00939-x&lt;/p&gt;&lt;p&gt;代码地址：&lt;/p&gt;&lt;p&gt;https://aistudio.ai4s.com.cn/galaxy-model/partner/galaxy-model-frontend/model/1221437&lt;/p&gt;&lt;p&gt;https://github.com/Drizzle-Zhang/MAPLE&lt;/p&gt;&lt;p&gt;该研究成果已发表于 Nature Computational Science。上智院研究员张雨、无限光年算法科学家姚易辰，为共同第一作者。复旦大学金力院士，上智院首席科学家、复旦大学特聘教授漆远，上智院领域科学家何莹，无限光年联合创始人、复旦大学 AI&amp;sup3; 院研究员徐盈辉，为共同通讯作者。无限光年实习生唐元昊，上智院生命科学方向负责人、复旦大学 AI&amp;sup3; 院研究员程远，为共同作者。&lt;/p&gt;&lt;p&gt;研究项目由星河启智科学智能开放平台（https://aistudio.ai4s.com.cn/）和复旦大学 CFFF 智算平台提供技术和算力支持。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不再直接「算年龄」，而是先理解样本之间的相对衰老关系&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既往的表观遗传衰老模型大多遵循一个直接的建模范式：从单一样本的甲基化谱出发，预测一个对应的「绝对年龄」或「绝对风险分数」。这种做法在数据条件理想、训练与测试分布高度一致时往往有效，但在真实研究和临床应用中却面临明显挑战。&lt;/p&gt;&lt;p&gt;其根本原因在于，甲基化数据高度敏感于测序平台、预处理流程以及组织来源等非生物因素。在这种情况下，模型往往更容易学习到「样本来自哪个实验体系」，而非真正反映个体衰老或疾病风险状态的生物学信号，导致跨队列、跨组织应用时性能迅速下降。&lt;/p&gt;&lt;p&gt;针对这一问题，研究团队在方法学上采取了不同的建模视角：不再要求模型直接输出绝对数值，而是让模型先学习样本之间的相对关系 &amp;mdash;&amp;mdash; 哪一个样本更老、哪一个样本疾病风险更高。通过在训练阶段构建大量样本对，模型被迫关注那些在不同数据来源中始终保持一致的变化趋势，从而有效弱化技术噪声和系统偏差的影响。&lt;/p&gt;&lt;p&gt;成对学习策略带来了两个直接收益。一方面，它显著降低了平台和预处理差异对模型的干扰，提高了跨数据集的稳定性；另一方面，通过样本成对组合，模型在有限样本规模下获得了更充分的监督信号，有效缓解了高维小样本条件下的过拟合问题。&lt;/p&gt;&lt;section&gt;&lt;img data-ratio="1.1305555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027227" data-aistatus="1" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmFicnqVlYiaoFLrJia2Siab4tmW3I9ol4VqCB1QHGIoHmP2X2icgR1BTDZq1VGp2y4CdrnZL8HsYrlG7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-original-style="height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8bb824c3-e107-4c25-9869-20700a28df71/640.png" alt="图片" data-before-load-time="1769148151532" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;衰老不仅能「算得准」，还能「对得上生物学」&lt;/p&gt;&lt;p&gt;在系统评估中，该方法在来自不同研究、不同测序芯片、不同数据标准化流程以及多种组织类型的 31 组独立测试中展现出高度稳定的性能。整体来看，其甲基化年龄预测的中位绝对误差约为 1.6 年，显著优于多种现有主流方法；即使在非血液组织（如脑、肌肉、脂肪和皮肤）中，预测精度依然保持在较高水平，显示出良好的跨组织泛化能力。&lt;/p&gt;&lt;section&gt;&lt;img data-ratio="1.6326530612244898" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="100027228" data-aistatus="1" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmFicnqVlYiaoFLrJia2Siab4tm7MHiblA9pdYy1atTRDJgptcugFQva7hiaaxtNwxUafg3XaibNfSATEDZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-original-style="height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/19b8254e-e1a7-4090-8ca2-69d5aae1f74c/640.png" alt="图片" data-before-load-time="1769148151650" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了数值精度，该框架在生物学解释层面同样表现突出。通过对模型关注的关键甲基化位点进行分析，研究发现这些位点在不同独立研究之间具有高度一致性，其关联基因显著富集于发育调控、组织重塑、免疫调节、神经功能及认知等经典衰老相关生物过程。这表明，模型并非仅依赖统计相关性进行拟合，而是优先捕捉具有明确生物学意义的调控信号。&lt;/p&gt;&lt;p&gt;进一步的人群与疾病分析显示，该方法能够识别一系列细微但具有生物学指向性的衰老特征。例如，在女性人群中，模型捕捉到围绝经期附近出现的显著衰老节律变化；在吸烟、肥胖、唐氏综合征、HIV 感染以及阿尔茨海默病等人群中，模型一致检测到明显的衰老加速信号。值得注意的是，在阿尔茨海默病分析中，该方法在脑组织中识别出的衰老加速特征，在血液样本中并不显著，提示其具备区分组织特异性衰老信号的能力。&lt;/p&gt;&lt;p&gt;这些结果共同表明，该框架不仅在预测层面表现稳定，也能够真实反映衰老相关的生物学过程。&lt;/p&gt;&lt;section&gt;&lt;img data-ratio="1.0398148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027229" data-aistatus="1" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmFicnqVlYiaoFLrJia2Siab4tmOML9fHo7zr5teia2A2ia9ptyMI5zaUdkYicGicibqSL89SzLQdiaxmKYiavfA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-original-style="height: auto !important;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/dcda12b2-aae6-4ae1-99c4-ec4b97088cad/640.png" alt="图片" data-before-load-time="1769148151831" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;从衰老测量走向疾病风险预测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;衰老评估的最终价值，并不止于刻画「生物年龄」，而在于揭示疾病风险的累积与演变。基于同一成对学习框架，研究团队进一步将模型扩展至心血管疾病和 2 型糖尿病等常见慢性疾病的风险评估任务，使表观遗传信号能够直接服务于疾病风险建模。&lt;/p&gt;&lt;p&gt;在多项独立测试中，该方法能够有效区分健康人群、疾病前驱状态以及确诊患者。在心血管疾病任务中，模型在疾病识别和动脉粥样硬化等前疾病状态的识别性能均明显优于传统风险模型；在 2 型糖尿病相关分析中，模型同样能够区分系统性胰岛素抵抗、前驱糖尿病等状态与确诊患者，显示出对疾病连续进展过程的良好刻画能力。&lt;/p&gt;&lt;p&gt;更进一步的分析表明，这种性能优势并非仅来自年龄信息的叠加。即便在控制不同人群年龄分布后，模型的判别能力依然保持稳定，说明其捕捉到的是与疾病发生和进展直接相关的表观遗传变化。模型所强调的关键甲基化位点，其关联基因在血管结构重塑、免疫炎症反应、代谢调控和胰岛素信号通路等疾病相关生物过程中显著富集，提示模型不仅能够区分疾病状态，也在分子层面识别出与病理机制一致的信号。&lt;/p&gt;&lt;p&gt;这一特性使得该框架在慢性病早筛、风险分层以及长期健康管理等场景中具备潜在应用价值，同时也为将表观遗传信息更系统地纳入疾病生物学研究提供了新的计算工具。&lt;/p&gt;&lt;section&gt;&lt;img data-ratio="1.4435185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027230" data-aistatus="1" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmFicnqVlYiaoFLrJia2Siab4tm9gSzibyNq6Mbgxz6uFiaLr9Dj24iaD2s3Z3Gx3XaNxGF6IQQgNFDQ7eUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-original-style="height: auto !important;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5a4e0d87-7652-451d-8cbc-fe913e08a0f6/640.png" alt="图片" data-before-load-time="1769148153082" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;总体而言，MAPLE 的意义并不局限于在既有基准上取得更优的预测指标，更在于为表观遗传建模提供了一种可推广的方法论范式。通过成对学习，模型将建模重心从不稳定的「绝对数值预测」转向更具跨数据集一致性的「相对关系学习」，在高维、样本规模受限且来源高度异质的甲基化数据条件下，有效缓解了过拟合与批次效应对模型泛化能力的制约。这一设计使模型能够在不同测序平台、预处理流程和组织来源之间提取稳定的生物学信号，为基于表观遗传信息的衰老时钟和疾病风险预测工具走向真实世界应用奠定了方法学基础。&lt;/p&gt;&lt;p&gt;从更长远的科学智能发展视角来看，MAPLE 也为机制发现与方法融合打开了空间。一方面，模型在不同数据集中稳定聚焦的关键甲基化位点，为解析衰老与疾病相关的调控通路提供了更高信噪比的候选集合；另一方面，该框架具有良好的可扩展性，随着纵向随访队列和多组学数据的不断积累，该框架将被应用在更多的表观遗传数据检测场景，有望成为连接分子层面衰老过程、疾病演进机制与干预评估之间的重要计算桥梁。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>百万围观、HuggingFace多模态登顶，华人团队开源语音版「DeepSeek」海外爆火</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 11:56:58 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;在大模型快速迭代的背景下，语音交互正从「语音转文本（ASR）&amp;mdash; 文本理解 &amp;mdash; 文本转语音（TTS」的串联式架构，逐步走向端到端的实时语音生成。这一转变不仅关系到延迟和自然度，也直接影响语音系统在真实生产环境中的可用性。&lt;/p&gt;&lt;p&gt;在级联式语音交互架构下，每个模块分别负责语音识别、文本理解和语音合成等任务，这种架构在早期的应用中取得了成功。但随着对实时性和低延迟要求的提高，端到端语音交互系统逐渐成为主流，通过深度集成各个任务，减少中间转换步骤，显著提高响应速度，使交互变得更加即时和自然。&lt;/p&gt;&lt;p&gt;近期，FlashLabs 发布并开源了其实时语音模型&lt;strong&gt;&amp;nbsp;Chroma 1.0，其定位为全球首个开源的端到端语音到语音模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Chroma 1.0 发布之后，便在社媒爆火，吸引了大量的关注。X 上的官推帖子已经突破了百万浏览量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDrulSsa95Ru1YS6uU6C0D3Dtk0Yb3HibA6hk8cuIgB3Xpl2u6leZruoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.9546296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529806" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/979bab34-7d6e-4854-bcc0-8986e2d1cea4/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;多位知名的 X 博主对 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Chroma 1.0&amp;nbsp;&lt;/span&gt;给予了很高的评价。&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDQv3VDGXCpibU0icu939I35UicMb0Cb40wkvlDZCvjVjZyANic4LlHkza0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529844" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/12dc6eb4-e366-4178-9147-ae735d9e87de/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，在 HuggingFace 多模态榜单中，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Chroma（4B 版本）排名第一。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDAibSwEBOFkb1mibvWx3uhFa8zyZfNFtQwC8hEiaJlJneNGbibIXQ7OcUew/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.5981481481481481" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503529818" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/32a96594-f7b4-4c12-b808-df4bdb20fa57/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该模型的研发负责人为 FlashLabs 创始人石一（Yi Shi）：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDI5zGpbDRW3Lw4FiaMn2JZVI9icfCd45bc6Fia1yzMicTLwzfoRz5PFMhVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5268518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529837" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2e64a979-80cc-47a5-86dd-301354df3bee/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从公开信息和技术实现来看，该模型并非对现有语音模型的简单改进，而是一次围绕「实时性」目标展开的系统级重构。&lt;/p&gt;&lt;p&gt;本文将依次从技术架构、核心指标、论文贡献以及应用场景等角度，对 Chroma 进行一次评测式分析，并对原文中表述不准确的地方予以修正。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、从级联到端到端：Chroma 的系统定位&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统语音系统通常采用多阶段流水线：&lt;/p&gt;&lt;p&gt;ASR &amp;rarr; LLM &amp;rarr; TTS&lt;/p&gt;&lt;p&gt;这一方案在准确率上已相对成熟，但在延迟、上下文连续性以及情绪一致性方面存在天然瓶颈。尤其在实时对话场景中，多模块串联会带来显著的推理延迟与状态同步成本。&lt;/p&gt;&lt;p&gt;Chroma 的核心目标，是构建一个语音到语音（Speech-to-Speech, S2S）的统一系统，将语音理解、语义建模与语音生成纳入同一整体框架中，从而降低系统复杂度并提升实时响应能力。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;官方产品页：https://www.flashlabs.ai/flashai-voice-agents&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;推理代码：https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型：https://huggingface.co/FlashLabs/Chroma-4B&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文：https://arxiv.org/abs/2601.11141&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;二、模型架构与关键设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1 分层架构：从理解到合成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;原文中曾将 Chroma 描述为「统一 Transformer 架构同时处理语音编码、语义建模与声学解码」，这一表述并不准确。论文指出，Chroma 采用分层多模块架构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reasoner&lt;/strong&gt;：基于 Thinker 模块构建，负责多模态理解与文本生成。它使用 Qwen2-Audio 编码管道处理文本和语音输入，并通过跨模态注意力及 TM-RoPE 将语音和文本表示对齐。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Backbone&lt;/strong&gt;：采用约 1 B 参数的 LLaMA 变体，用于生成每一帧的粗声学码。为实现个性化克隆，Backbone 通过 CSM-1B 将参考音频及其文本编码为嵌入前缀，并共享 Reasoner 的嵌入和隐藏状态作为上下文。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Decoder&lt;/strong&gt;：约 100 M 参数的轻量模型，在每帧内自回归生成剩余的 Residual Vector&amp;nbsp;Quantization (RVQ) 级别。这一设计减少了长上下文计算负担，细化了韵律与发音细节。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Codec Decoder&lt;/strong&gt;：采用 Mimi vocoder 的因果卷积网络，将粗音码与细音码串联后重建为连续波形。系统使用 8 个码书，减少解码器在每帧的自回归步骤。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDtwU8ftG6M1aoicWgvic69K1cQNVTHMW2TAIyjnsuby2ib11Yiay29wfmHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.43796296296296294" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529785" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/17c484ed-33f1-4b03-a9bd-38a7271fdb36/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种模块化的分层设计与原文所述的「统一 Transformer」不同，每个模块各司其职，共同完成 S2S 推理和生成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 交错日程与流式推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为保证低延迟，Chroma 采用固定比例的文本 - 音频交错日程，论文中明确为 1:2（即每个文本 token 对应两个音频码）。&lt;/p&gt;&lt;p&gt;具体操作过程中，Reasoner 首先输出文本 tokens 和隐藏状态；这些信息按上述比例交错并输入 Backbone 和 Decoder，后者再逐步生成离散声学码并由 Codec Decoder 重建为波形。&lt;/p&gt;&lt;p&gt;这种管线非一步直接「映射」语音到输出，而是通过多模块间的分工协作进行联合建模，从而避免了传统级联系统中的多次模态切换带来的信息损失。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 参数规模与效率权衡&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Chroma 1.0 的模型规模约为 40 亿参数级别。相较于追求超大模型规模，其设计更强调在延迟、吞吐与可部署性之间取得平衡：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Backbone：1 B &lt;/strong&gt;参数 &amp;mdash;&amp;mdash; 负责粗声学码生成；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Decoder：100 M&lt;/strong&gt;&amp;nbsp;参数 &amp;mdash;&amp;mdash; 负责细化 RVQ；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reasoner 与 Codec Decoder 规模保持相对稳定。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;相较于 7 B&amp;ndash;9 B 的大模型，&lt;/span&gt;该规模具有明显效率优势，同时在多项指标上优于 0.5 B 级别的小模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、核心技术指标评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;根据论文与实验结果，Chroma 在多个关键指标上表现出工程优势：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD30ZPjABnhB72ouzSoFF6C35PZibAwApJjNGGSvyeYLoasWqjUYyDWKw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5592592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529787" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/72f7baee-ae50-4598-b383-181fe43db255/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;需要指出的是，论文评测重点放在实时交互可用性和个性化声音克隆上，而不是单一语音自然度指标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、论文视角：Chroma 的研究贡献&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从论文结构来看，Chroma 的研究贡献主要体现在三个层面：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;实时语音建模范式&lt;/strong&gt;：系统性论证了端到端 Speech-to-Speech 架构在实时对话场景中的优势，并给出了工程可行的实现路径。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;交错策略和模块化设计&lt;/strong&gt;：在数据表示和模型结构上引入 1:2 文本&amp;ndash;音频交错，并将Reasoner、Backbone、Decoder、Codec Decoder 分离。这种设计既降低延迟又兼顾语义推理和声学细节。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;合成训练管线与评价方法&lt;/strong&gt;：采用 LLM+TTS 构建高质量的语音到语音训练数据，并通过综合的客观指标（SIM、TTFT、RTF）和主观评测（NCMOS、SCMOS）验证系统性能。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;整体来看，该论文兼具工程导向和系统研究价值，而非单点算法突破。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、FlashAI：从模型到应用的落地路径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Chroma 并非孤立模型，其首要应用场景来自 FlashLabs 的语音产品 &lt;strong&gt;FlashAI&lt;/strong&gt;。在 FlashAI 中， Chroma 主要承担实时语音交互引擎的角色，典型应用包括：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDltbjmXiar819C4L2GqggVcAkiabbJgBMFiciaMx7z0BqMwwial6EjIPUa3g/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1" data-s="300,640" data-type="png" data-w="284" type="block" data-imgfileid="503529791" data-aistatus="1" data-original-style="width:25px;height:25px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7e2f8a26-f11d-496a-aa99-64e84f5bd2d7/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.02%;"&gt;企业级呼叫与客服&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;实时应答，稳定长对话；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多语言支持；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;适用于呼叫中心、预约、售后等高并发场景。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDa4xJVXFc9okXg0BkOUmZoOxOv8DoGPHjvKbJniaFTiaoPpXFdBnia3ByA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.037037037037037" data-s="300,640" data-type="png" data-w="270" type="block" data-imgfileid="503529796" data-aistatus="1" data-original-style="width:31px;height:32px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/344b3d5b-0548-48ff-b2be-86ad0d831394/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.94%;"&gt;AI 语音代理（Voice Agent）&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;结合知识库与业务逻辑，直接在语音层面完成任务型对话；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;减少文本中转延迟。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDezuVFSgiaUzJicz2Dp2g7KHgEcNlqs3ykEfI3Om7WxIia2vWQbaThCZicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.037313432835821" data-s="300,640" data-type="png" data-w="268" type="block" data-imgfileid="503529798" data-aistatus="1" data-original-style="width:29px;height:30px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/cf80828b-ca4e-495a-b77c-abe0b7b32f2c/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.21%;"&gt;跨语言语音交互&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;统一语音建模降低系统切换成本；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;提升整体交互连贯性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;六、理性总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综合来看，Chroma 1.0 并非追求「最强语音模型」，而是明确聚焦于实时语音交互这一长期被低估的工程难题。其价值不在于单项指标的领先，而在于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;将语音理解、语义建模与声学生成解耦为多模块联合设计，摆脱传统级联系统瓶颈；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;通过 1:2 交错策略与多码书设计，将 TTFT 降至约 150 ms 并保持 RTF &amp;lt; 1；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在个性化声音克隆任务中实现对人类基线 10.96% 的相对提升，展示出对细节声纹特征的捕捉能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;完整开放代码与模型，降低了研究者与工程师进入门槛。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，Chroma 目前在自然度评测（NCMOS）上仍落后于商业系统 ElevenLabs，在多语言及情感控制方面亦有待进一步探索。然而，作为实时语音交互的重要基础设施，其分层设计与数据生成策略为行业提供了可复用的蓝图。&lt;/p&gt;&lt;p&gt;通过修正原文中的架构描述和「直接映射」表述，这篇评测更准确地反映了 Chroma 的技术特点与工程取舍，有助于读者理解这一系统在实时语音交互领域的价值。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>具身启元，智创未来——上海国际具身智能产业博览会新闻发布会在京隆重召开</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 23 Jan 2026 10:50:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;2026年1月20日，上海国际具身智能产业博览会（CIEI 2026）新闻发布会在京隆重召开。中国机电一体化技术应用协会会长曲道奎、中国国际贸易促进委员会上海市分会副会长顾春霆、上海市国际展览（集团）有限公司总裁徐佳等领导出席活动。来自新华网、央视网、中国财经报社、中国工业报、中国电子报、搜狐科技、科技日报、36氪、机电商报、甲子光年、亿欧网、金属加工杂志社、机工弗戈等超50家媒体出席活动。新闻发布会由中国机电一体化技术应用协会常务副会长王继宏主持。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5671e0ef-9261-4239-af7e-1cbf15748383/1769136444655.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 新闻发布会现场&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;中国机电一体化技术应用协会会长曲道奎在致辞中表示，当前全球科技革命与产业变革加速演进，具身智能作为连接数字世界与物理世界的核心桥梁，已从技术探索的&amp;ldquo;深水区&amp;rdquo;走向产业应用的&amp;ldquo;主战场&amp;rdquo;。2025年全球具身智能市场规模已达到195.25亿元，我国已在具身智能领域构建起完整的产业生态，为产业高质量发展奠定了坚实基础。目前亟需一个高水平平台实现资源聚合、技术碰撞、供需对接。CIEI 2026除了硬核的技术、产品展示，更注重展会的产业价值赋能，积极响应产业发展需求，助力具身智能产业高质量发展。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9ef5abcf-d716-4185-a619-d4e351c64cf3/1769136461607.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 中国机电一体化技术应用协会会长 曲道奎&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;中国国际贸易促进委员会上海市分会副会长顾春霆在致辞中指出，上海市贸促会作为中国国际贸易促进委员会最早设立的地方分会，将充分发挥七十年积累的丰富经贸资源与广泛网络，上海市国展集团将全力投入全产业链会展组织能力，与中国机电一体化技术应用协会一起，共同为具身智能产业打造全方位、多层次、宽领域的国际展示与合作平台。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ac44519f-ea92-4d96-9222-d361e9c069fa/1769136477577.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 中国国际贸易促进委员会上海市分会副会长 顾春霆&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a2b36909-86c3-424c-9c33-7627a31e8998/1769136490242.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 中国机电一体化技术应用协会常务副会长 王继宏&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;上海市国际展览（集团）有限公司副总裁蒋岚对项目情况进行深度披露。详细介绍了CIEI 2026组织架构、行业背景、展会概况、展品范围、目标观众、同期活动、展会亮点及参展（观）方式等情况。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26702a1e-75c6-4b3b-9ce9-f370954cf7d1/1769136514979.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 上海市国际展览（集团）有限公司副总裁 蒋岚&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0a66cd96-1b68-446e-ab50-f9e652c42af3/1769136529118.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 领导及重要嘉宾正式启动CIEI 2026项目&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;随后，来自协会、专家及企业的代表分别进行了发言，表示对CIEI 2026 充满期待。&lt;img src="https://image.jiqizhixin.com/uploads/editor/8678fa21-1d1b-4f30-8470-6b1b8103d849/1769136549894.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;国家自然科学基金委高技术中心研究员、科技部专业技术二级专家、中国机电一体化技术应用协会具身智能分会理事长 刘进长&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ee48b060-450f-4878-9efa-dddd906092cf/1769136566189.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 中国机械通用零部件工业协会副秘书长 明翠新&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/707e7c21-0d6d-4cbc-84fa-bd3412639d2a/1769136579512.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 北京因时机器人科技有限公司首席营销官 房海南&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;最后，在媒体问答环节，媒体积极互动，对CIEI 2026表现出极大的热情和期待。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e72f8ef4-1a33-4c65-ab90-55493e630433/1769136594354.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 媒体问答&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>vLLM团队官宣创业：融资1.5亿美元，清华特奖游凯超成为联创</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 09:37:37 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南&lt;/section&gt;&lt;p&gt;大模型推理的基石 vLLM，现在成为创业公司了。&lt;/p&gt;&lt;p&gt;北京时间周五凌晨传来消息，由开源软件 vLLM 的创建者创立的人工智能初创公司 Inferact 正式成立，其在种子轮融资中筹集了 1.5 亿美元（约合 10 亿元人民币），公司估值达到 8 亿美元。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529775" data-ratio="1.0287037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDnEibmy6mBdzhNoINFlCH6fhE0RRX4fkd6VX2BibjicFHvLwlsdoWLkwSw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e67c6d3d-efa8-415e-a835-fb77289bf634/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;本轮融资由风险投资公司 Andreessen Horowitz（a16z）和 Lightspeed 领投，Sequoia Capital、Altimeter Capital、Redpoint Ventures 和 ZhenFund 也参与了投资。&lt;/p&gt;&lt;p&gt;Inferact 的 1.5 亿美元天使轮融资虽不及 Ilya Sutskever 的公司 SSI 的 10 亿美元，但已经超过了 Mistral AI 的 1.15 亿美元，是有史以来规模最大的种子轮融资之一，标志着业界对于 AI 推理基础设施的重视程度正在急速提升。&lt;/p&gt;&lt;p&gt;Inferact 的使命是将 vLLM 发展成为世界领先的 AI 推理引擎，并通过降低推理成本、加快推理速度来加速 AI 的发展。&lt;/p&gt;&lt;p&gt;该公司认为，AI 行业未来面临的最大挑战不是构建新模型，而是如何以低成本、高可靠性地运行现有模型。&lt;/p&gt;&lt;p&gt;毫无疑问，Inferact 的核心是开源项目 vLLM，这是一个于 2023 年启动的开源项目，旨在帮助企业在数据中心硬件上高效运行 AI 模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDcaSCSm0r3HNCHY3jD3Fj3rgcxdpdmXu4lHZh8XEKcd4uk6ZXmYPgAQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.537962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529776" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/10e8fb67-b8fb-4ed2-80f0-4ea7cb21cdc9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;vLLM 最初由加州大学伯克利分校（UC Berkeley）的天空计算实验室 (Sky Computing Lab) 开发，现由 PyTorch 基金会负责管理，已吸引了来自整个 AI 行业的 2000 多名贡献者，是全球范围内最受欢迎的开源大模型推理加速框架。&lt;/p&gt;&lt;p&gt;如今，vLLM 的推理能力在为 Meta、谷歌、Character.AI 等科技公司提供支持。&lt;/p&gt;&lt;p&gt;Inferact 的首席执行官 Simon Mo 是一位伯克利在读博士生，他是 vLLM 的创始维护者之一。Mo 表示，公司成立于 2025 年 11 月，并于本周正式对外公布。他将 Inferact 的起源与伯克利早期的一些软件项目进行了比较，这些项目后来发展成为规模更大的企业，例如 Apache Spark 和 Ray。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDIAlrduJAfnIlwxRRIzYZic8icK81QKKFiaM0w9XdibZM9YFTG4125Qm3Gg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1" data-s="300,640" data-type="png" data-w="460" type="block" data-imgfileid="503529777" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4252cb85-953a-4307-9857-2b0db3090348/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在宣布融资的同时，Lightspeed（光速创投）也发布了对 Simon Mo 的访谈。在其中 Simon Mo 谈到了对于全球 AI 算力紧缺的担忧，「当前用于大模型训练的 AI 集群，将在六个月内完全被用于推理&amp;hellip;&amp;hellip; 推理会逐渐消耗掉所有算力容量，并耗尽所有新增的容量。」&lt;a href="https://mp.weixin.qq.com/s/MN1waC3QcAxuKJ9ESW-oJA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/035ddd35-2115-413f-ad46-348ee6cfae62/1769132157601.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;在公告中，Inferact 表示，其定位于模型和硬件的交汇点：当模型厂商发布新架构时，他们会与 vLLM 合作，确保提供首日支持；当硬件厂商开发新芯片时，他们会与 vLLM 集成；当大模型团队进行大规模部署时，他们会运行 vLLM，从前沿实验室到超大规模数据中心，再到服务数百万用户的初创公司，无一例外。&lt;/p&gt;&lt;p&gt;如今，vLLM 支持了 500 多种模型架构，可在 200 多种加速器上运行，并支持着全球规模的推理。这个由 2000 多位贡献者共同构建的生态系统，是 Inferact 得以成立的基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Inferact 表示，其首要任务是继续支持 vLLM 作为独立的开源项目，并将改进成果分享给社区。&lt;/strong&gt;他们计划进一步提升 vLLM 的性能，深化对新兴模型架构的支持，并扩大对前沿硬件的覆盖范围。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em; margin-bottom: 0px; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Inferact 的&lt;/span&gt;第二个目标是开发一款独立的商业产品，帮助企业在不同类型的硬件上更高效地运行 AI 模型。&lt;/p&gt;&lt;p&gt;值得关注的是，vLLM 项目的核心贡献者清华博士游凯超成为了这家公司的联合创始人。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD34RV0CgYYY4nT0IMTul0n0BwfK4FOciakwAfaceNj5J8pQLKzuVUv7g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4554794520547945" data-s="300,640" data-type="png" data-w="876" type="block" data-imgfileid="503529779" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a65649d3-a189-47bf-8600-dabb56511f7f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据介绍，Inferact 的创始团队包括 Simon Mo、Woosuk Kwon、Kaichao You（游凯超）、Roger Wang、Joseph Gonzalez、Ion Stoica 等人。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://inferact.ai/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.bloomberg.com/news/articles/2026-01-22/andreessen-backed-inferact-raises-150-million-in-seed-round&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一文速通「机器人3D场景表示」发展史</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 23 Jan 2026 09:34:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-23</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-23</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/d52bc08d-d9cb-439b-a4ef-34267ec7036b/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着机器人领域的飞速发展，我们有一个问题不断需要思考，究竟如何让机器人像人类一样理解世界，学习周围环境的表示。对于机器人来说，究竟是需要精确的坐标，还是语义的物体概念，还是隐式的空间认识推理模型？&lt;/p&gt;&lt;p&gt;在本文中，&lt;strong&gt;上海交通大学、波恩大学等院校的研究团队全面总结了当前机器人技术中常用的场景表示方法&lt;/strong&gt;。这些方法包括传统的点云、体素栅格、符号距离函数以及场景图等传统几何表示方式，同时也涵盖了最新的神经网络表示技术，如神经辐射场、3D 高斯散布模型以及新兴的 3D 基础模型。&lt;/p&gt;&lt;p&gt;虽然目前的 SLAM 与定位系统主要依赖点云、体素这类稀疏表示方式，但密集型场景表示方法在导航、避障等后续任务中无疑会发挥关键作用。此外，神经辐射场、3D 高斯散布模型以及基础模型这类神经网络表示技术，非常适合整合高层次的语义信息与基于语言的先验知识，从而实现更全面的 3D 场景理解与智能体行为控制。本文的目标是为新手和资深研究人员提供一份有价值的参考资料，帮助他们探索 3D 场景表示技术的未来发展方向及其在机器人技术中的应用。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529517" data-ratio="0.5305555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKj20ozibiaBzMBMUGib0aGzEhxtxELvp6ylT6dQu1psDhPsydGfIHibKxJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/aec43dd6-fb0a-4d47-9e58-106290fe27e6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;标题：What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;作者：Tianchen Deng, Yue Pan, Shenghai Yuan, Dong Li, Chen Wang, Mingrui Li, Long Chen, Lihua Xie, Danwei Wang, Jingchuan Wang, Javier Civera, Hesheng Wang, Weidong Chen&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：Shanghai Jiao Tong University、University of Bonn、Chinese Academy of Sciences、University of Zaragoza、Nanyang Technological University&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;原文链接：https://arxiv.org/abs/2512.03422&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/dtc111111/awesomerepresentation-for-robotics&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、机器人 3D 场景发展史&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529519" data-ratio="0.7814814814814814" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK3ntzh6UG3x3NcKWaQ5ttMsHWnDicGWEJtvAkrGNrhJlcicwRibd4cLsAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b1e40c1c-aa65-4cda-ac7a-0cc3d3160bd9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 机器人 3D 场景表示发展史和代表性工作&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;几何场景表示：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Point Cloud 点云场景表示&lt;/strong&gt;：通过离散的三维点来表示场景，通过雷达或者相机传感器获得。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Voxel 体素场景表示&lt;/strong&gt;：通过将三维空间离散化，转变成规则的立方体栅格，通过在栅格内存储不同的信息，比如密度，占用率等实现场景建模&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Mesh 网格场景表示&lt;/strong&gt;：通过三角化面片构建连续的场景几何场景表示，精细度更高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;SDF 符号距离场&lt;/strong&gt;：通过表示空间点到物体表面的距离，实现连续的场景几何表示。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;近年来，深度学习、计算机图形学与机器人技术的融合推动了显著进展。在众多推动这一进展的技术中，神经辐射场（NeRF）、三维高斯溅射和基础模型（Foundation Model，FM）作为极具前景的创新脱颖而出，从而实现真正的通用具身智能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKtWz69nxnJuL5COhSzWCe2WmaaIbJeR4kdthqpgHKMiaiakA2PYRHDVKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.33425925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529520" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f7fe79d6-ad16-459f-8412-fd181150d7b6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 机器人 3D 三维表征研究热度变化&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3D 神经场景表示&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;NeRF 神经辐射场&lt;/strong&gt;：通过连续的场景表示让机器人理解世界，基于神经网络 MLP 构建，可以进行地图预测，但是速度较慢。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3DGS 高斯泼溅&lt;/strong&gt;：将场景表示为 3D 高斯椭球，从而实现高速的渲染，适合实时建图。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Foundation Model 基础模型&lt;/strong&gt;： 通过现有的 transformer 等编码器，将三维世界压缩成类似于语言的 token，将三维世界的理解变成可推理的人类语言。从而实现空间感知推理，成为「3D 版本的 GPT」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529521" data-ratio="0.6111111111111112" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKlriauyib4XRIWCgpbCviaSMH5V867jatzdbcuUKGNYKFxQYdXr8eGFOaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8ad3c485-a173-4b04-a9f2-0a00cda0c994/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 三维场景表征在机器人不同模块的应用：感知，建图，定位，操作，导航&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在建图和定位模块（第 V 节）中，现有方法在 SLAM 和定位领域取得了令人瞩目的成果。神经场景表示能够实现对环境的更精确、更密集的建模，这对避障特别有益。这一能力对于机器人的导航和操作至关重要。&lt;/p&gt;&lt;p&gt;该模块分为三部分：&lt;strong&gt;（i）场景重建&lt;/strong&gt;：场景表示的地图重建能力包括几何精度和渲染质量，以及在静态场景、大规模户外场景和动态场景中的重建能力。&lt;strong&gt;（iii）SLAM&lt;/strong&gt;：SLAM 部分主要包括不同场景表示方法在 SLAM 过程中的地图精度、位姿精度和实时性能。&lt;strong&gt;（iv）&lt;/strong&gt;&lt;strong&gt;全局定位&lt;/strong&gt;：全局定位主要涉及使用现有地图进行定位时的精度和实时性能。&lt;/p&gt;&lt;p&gt;在操作模块（第 VI-A 节）中，本文主要比较了基于不同场景表示方法的抓取框架。传统方法在抓取方面具有更高的实时性能和计算效率，但在泛化能力和处理复杂目标操作任务方面存在局限。相比之下，基于神经网络的场景表示在生成新视角和跨多个场景泛化方面具有一定能力，使其更能适应复杂任务。基于基础模型的方法能够实现零样本抓取任务，具备强大的泛化能力。此外，语言信息的集成使这些模型能够支持交互式抓取，并增强了它们理解和规划高级认知任务的能力。&lt;/p&gt;&lt;p&gt;在导航模块（第 VI 节）中，与传统的场景表示方法相比，神经场景表示能够提供高度准确的环境重建。此外，它们还有助于更好地融合语义和语言信息，从而能够执行更复杂的导航任务。我们将导航模块分为两个部分：（i）规划：从当前位置到目标目的地生成最优或可行路径，同时避开障碍物。（ii）探索：主动导航并绘制先前未知区域的地图。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-imgfileid="503529523" data-ratio="0.8481481481481481" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKNoJrkED4LNkiawfxWxicLfrtQSwYGYm7icfvJibZVd4MvPJqZPpEUDeJfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e885a64a-26fb-4c41-9d15-3dd80abf0a9c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 不同 3D 场景表示的特点对比，包含连续性，存储效率，真实性，灵活性，几何表示精度。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、现有方法的问题与未来发展方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、端到端通用网络还是模块化？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，大多数机器人系统都建立在模块化智能（Modular Intelligence）的基础上。为了完成复杂任务，系统会将导航或操作等功能分解为独立的模块，例如感知、建图、定位、操作和导航。这种设计虽然有助于实现各种机器人功能，但其模块化特性在本质上可能会限制机器人智能的进一步发展。&lt;/p&gt;&lt;p&gt;尽管模块化解决方案引入了有用的归纳偏置（Inductive Biases）并支持有效的特定任务性能，但它们通常面临泛化能力有限和迁移性差的问题。在实际应用中，这些系统往往需要在不同场景下进行重复的传感器校准、特定环境建模以及参数重新调优。此外，在高度复杂的环境中，构建精确的模型仍然极具挑战性。基础模型的最新进展提供了一条替代路径，即实现端到端智能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、数据瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管神经场景表示（Neural Scene Representations）在准确性和泛化性方面具有显著优势，但一个主要的挑战在于，与训练大语言模型（LLM）和视觉语言模型（VLM）所使用的互联网规模的文本与图像语料库相比，机器人特有的数据非常匮乏。这种局限性显著阻碍了机器人领域神经场景表示和基础模型的发展。&lt;/p&gt;&lt;p&gt;为了解决这一问题，研究重点已转向增强神经场景表示在有限数据情况下的泛化能力。另一个方向则是利用世界模型（World Models）来预测以动作为条件的（Conditioned on actions）状态转移，从而生成额外的训练数据集。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、实时性瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与传统的场景表示相比，在机器人领域部署神经场景表示的另一个关键瓶颈在于其推理时间（Inference Time），这仍是制约可靠实时应用的一个限制因素。目前神经网络的部署策略通常分为两大类：&lt;/p&gt;&lt;p&gt;第一类是基于云端的部署。通常托管在远程数据中心，并通过 API 进行访问。在这种模式下，响应延迟和服务时间很大程度上取决于底层的网络路由、带宽以及数据中心的计算能力。因此，在将此类模型集成到自主机器人技术栈之前，必须仔细权衡网络的可靠性和延迟问题。&lt;/p&gt;&lt;p&gt;第二类是边缘计算平台上的车载 / 机载部署（Onboard Deployment）。此类方案通常采用模型蒸馏（Model Distillation）和量化（Quantization）等技术来减小模型体积，从而实现实时推理。然而，这往往以牺牲泛化能力为代价。一个极具前景的未来方向在于硬件 - 算法协同设计（Hardware&amp;ndash;Algorithm Co-design），旨在同时提高推理效率并保持模型的泛化性能，以满足机器人实时部署的需求。&lt;/p&gt;&lt;p&gt;本文探讨了机器人不同模块最适合的三维场景表示方法，研究了相关方法、并讨论了挑战和未来方向。本文的主要贡献如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全面、最新的综述与基准测试&lt;/strong&gt;：本文对机器人领域的不同场景表示方法进行了广泛且最新的综述，涵盖了经典方法和前沿方法。对于每个模块，团队都提供了详细介绍，并突出了该模块中不同场景表示的优势。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;三维场景表示的未来方向&lt;/strong&gt;：在机器人领域的每个模块中，团队指出了当前研究的技术局限性，并提出了几个有前景的未来研究方向，旨在激励这一快速发展领域的进一步进步。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源项目&lt;/strong&gt;：团队在 GitHub 上发布了一个开源项目，整理了机器人领域不同场景表示的相关文章，并将继续向该项目添加新的研究成果和技术，网址为 https://github.com/dtc111111/awesome-representation-for-robotics。团队希望更多研究人员能够利用它获取最新的研究信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对更多实验结果和文章细节感兴趣的读者，可以阅读一下论文原文～&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>幻觉率不到3%，王小川把医生版的DeepSeek免费了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 19:17:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-14</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-14</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南&lt;/section&gt;&lt;p&gt;在医疗健康这一容错率极低的领域，大模型不再凭空「想象」，而是已变得严谨可靠、能引会搜：百川刚刚推出的新模型，实现了一个里程碑式的突破。&lt;/p&gt;&lt;p&gt;本周四，百川智能正式发布新一代大模型 Baichuan-M3 Plus，其面向医疗应用开发者，在真实场景下将医学问题推理能力推向了全新高度。新模型发布的同时，接入 M3 Plus 的百小应 App 与网页版也已同步上线。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529752" data-ratio="0.425" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadMF8YFj711oEA8cUbvbmXjj7bRyRPF4JvNzNhlkCzRa7FLibDzbDBdKA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e4692011-cd64-41f2-ac5f-9cb2b65ff5b6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 AI 领域，从来没有一款大模型可以做到 M3 Plus 这么高的医学场景准确率，百川还大幅提升了模型的推理效率，M3 Plus 的发布，标志着 AI 在医疗领域的应用跨过了「敢用、好用、用得起」的关键门槛。&lt;/p&gt;&lt;p&gt;百川智能创始人、CEO 王小川表示，在垂直领域，M3 Plus 已经可以认为是医生版的 ChatGPT 或 DeepSeek，作为性能最强、推理效率最高的模型，可大规模用于 AI 辅助医疗落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全球最低幻觉率 &amp;nbsp;从看着像，到真的准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;长期以来，医生与患者对 AI 的态度一直存在矛盾：人们既期待 AI 能分担繁重的工作，又恐惧它们「一本正经地胡说八道」。信任，是 AI 进入医疗领域的最后一道墙。&lt;/p&gt;&lt;p&gt;在发布活动中，百川智能模型技术负责人鞠强现场演示了一个案例：一位医生曾尝试用 AI 检查一个肿瘤药物的不良反应，结果发现市面上的 AI 生成的内容虽然「画风」专业，引用文献看起来也很权威，但「按照生成内容的面积计算，90% 的信息都是完全错误的」。&lt;/p&gt;&lt;p&gt;这种「貌似专业」带来的风险比直接答错更大，且极具迷惑性 。&lt;/p&gt;&lt;p&gt;针对这一核心痛点，M3 Plus 延续了 M3 基座模型的内生逻辑机制，通过引入 Fact-Aware RL（事实感知强化学习）等新技术，将幻觉控制推向了新高度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上周发布的百川新一代基座模型 Baichuan-M3，开拓了幻觉降低的技术路线，探索模型基座的幻觉降低范式，成功首创了 Fact-Aware RL 的强化学习范式，让模型在无工具、无检索增强的情况下大幅降低了幻觉，实现了 SOTA 水平，M3 Plus 延续了这样的能力。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadiaKiaQqEP0KWhtETHbFHsdA9Ov8NJoj2HzTnURTZMibwCvae3xHF7Zsng/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3675925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529764" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/212f33df-6395-4fba-9b22-77fd19bc694b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Baichuan-M3 首创的 Fact-Aware RL。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Fact-Aware RL 范式下，模型生成的文本会被拆解成一条条可被核查的医学判断，再逐条和权威医学来源进行比对，进而量化 AI 生成内容的事实准确性。&lt;/p&gt;&lt;p&gt;这种设计赋予了 AI 模型与真实临床工作流程相契合的内在医学增强能力。据测试，Baichuan-M3 不仅在医疗沟通和推理能力上全面领先 GPT-5.2，在医疗幻觉率上也实现了超越，达到全球最低水平。&lt;/p&gt;&lt;p&gt;在 M3 Plus 上，AI 的推理还得到了「六源循证」方法（EAR）的加持。&lt;/p&gt;&lt;p&gt;在去年 10 月发布的 Baichuan-M2 Plus 模型上，百川首次应用了「六源循证」方法（EAR），将循证医学的范式引入大模型的训练和推理过程，使模型的每条建议都有专业医学证据支持。在其 RAG 检索的过程中，查询会被转化为结构化医学问题，并在六源数据库中进行分层匹配。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadg1GAbhe5padLZujhxeb4u1ibKzHuN9l6vPpchbxe0KlHYB0K6NT34Tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529756" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/512212df-9065-48f1-bc3d-fab6b1d0fbea/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Baichuan-M2-Plus 提出的六源循证体系。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;据介绍，这种方法克服了通用 RAG 的两大缺陷：对医学语义理解的缺乏，以及引用文献可靠性的不足。六源循证不仅使 AI 模型的医学知识储备和医学知识利用能力大幅提升，更直接将幻觉降低到 DeepSeek-R1 模型的 1/3，使模型的可信度达到比肩资深临床专家的水平。&lt;/p&gt;&lt;p&gt;M3 Plus 模型在 Halluciation Rate 评测中的幻觉率只有 2.6，比 GPT-5.2 低超过 30%，也低于目前行业的标杆 Open Evidence，刷新了医疗模型低幻觉世界纪录。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadGKW1vcuTHd2Yz8KcWOOaJBRW4r1OmlMvHAePDpEoY0RgpFTWYktYog/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8105548037889039" data-s="300,640" data-type="png" data-w="739" type="block" data-imgfileid="503529758" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6e25abcf-b2d2-43aa-a70b-0df9c16075d3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;现在，AI 不再生成高频但模糊的建议，而是经过显式训练，系统地抑制了那些「看起来很美」但并无事实依据的回答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让 AI 的每个医学判断都有据可查&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「验证 AI 的回答，比自己查书还累，」这是很多医生使用通用大模型时的抱怨。在医疗场景中，引用是可信度的底线，但在大模型领域中，人们对于 AI 生成内容的引用准确性始终缺乏系统性优化路径。很多大模型列出的引用内容，指向的文献或段落并不支持当前表述，AI 并没有真正理解和呈现证据立场。&lt;/p&gt;&lt;p&gt;为此，&lt;strong&gt;百川智能首创了「证据锚定」（Evidence Anchoring）技术，让 AI 生成的每一句医学结论都能被逐句核验。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Baichuan M3 Plus 中，引用准确性被作为一个独立且核心的训练目标被进行系统建模。AI 不是简单标注「引用自哪篇文献」，而是被要求生成的每一句医学结论，都必须精确对应到原始论文或指南中的具体证据段落。每一句判断，都能被逐字溯源、逐条核验。&lt;/p&gt;&lt;p&gt;结合专门训练的 Citation Reward Model（引用奖励模型），对错误引用进行明确惩罚，模型现在只能在「确实有证据支持」的空间中推理与生成。最终，结论与证据段落的匹配准确率超过 95%，真正让 AI 的医学判断做到了可核验、可追责、可教学。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad0OL7XOncOqmicXH4ic8km9z3qfTgGKyXibL41UMvEzmiaYnCib0iblD2icMRQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.6546296296296297" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503529760" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e87abe40-bd0f-4936-95e4-8c5d6be0c745/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 M3 Plus 生成的内容中，引用的段落和支持的表述是完全一致的，人们可以直接定位到支持这句话的证据，这样一来，验证来源的权力被交还给了医生。&lt;/p&gt;&lt;p&gt;王小川表示，基于低幻觉的新一代模型，百川希望面向医生提供 AI 辅助能力，并向患者提供建议，「我们认为随着大模型技术的提升，人们对于 AI 辅助的接受度将会逐步提高。同时，这也需要多方面持续努力。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用免费开放 &amp;nbsp;推动行业共荣&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在美国，像 OpenEvidence 这样的 AI 医学知识助手已覆盖了 45% 的医生，但其高昂的订阅费在现阶段的中国市场难以落地 。中国医生面临着截然不同的工作环境：美国医生一天看 10 个病人，中国医生可能要看上百个 。如果要让 AI 真正普及，就不能增加医生的经济负担，也不能指望像 SaaS 软件那样简单收费。&lt;/p&gt;&lt;p&gt;为此，百川给出了更大胆的解法。&lt;/p&gt;&lt;p&gt;百川公布了「海纳百川计划」&amp;mdash;&amp;mdash; &lt;strong&gt;面向所有为医务工作者提供服务机构，免费提供循证增强的 M3-Plus 的 API&lt;/strong&gt;。百川希望通过这种方式推动更多服务于医生的 AI 应用落地，让更多医生拥有可用、好用的 AI 工具，推动临床、医学教育的进步。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadnuot7WFh3w5q5be5yN2ln1kZhMKcl2wticOKfvKpfh4meuOmDMgOicPg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503529762" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9b531859-937f-4f0e-bbeb-8e26a13a0277/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;目前，M3 Plus 也面向所有开发者开放为期 15 天的 API 限时免费体验，所有开发者均可以申请使用。&lt;/p&gt;&lt;p&gt;王小川表示，即使全中国临床医生都在使用 M3 Plus 模型，一年的成本也在可控范围内（约 1 亿元），百川愿意承担这笔费用来催熟生态。&lt;/p&gt;&lt;p&gt;当然在技术层面上，新模型也进行了极致的工程优化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;M3 Plus 围绕医学场景对模型架构、推理路径与部署形态进行了系统的工程重构，在不牺牲模型能力与可靠性的前提下，让 API 调用成本较上一代降低 70%。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该模型完成了两项新型优化工作。首先是 Gated Eagle-3 投机解码框架，它通过门控注意力机制（Gated Attention），可以在几乎不增加计算开销的前提下实现对外部信息流的动态筛选与精细调控，draft 模型能够「有选择地」吸收主模型语义指导，显著提升预测准确率。&lt;/p&gt;&lt;p&gt;就像是有一个教授在带着助教在写诊断书，助教（Draft 模型）先快速写出草稿，教授只负责进行快速审核与修正。M3 Plus 的创新在于让这个助教更聪明，能精准领会教授的意图，从而在不降低论文质量的前提下，让产出速度提升。&lt;/p&gt;&lt;p&gt;在相同配置下，Gated-Eagle3 相比原始 Eagle-3 实现约 15% 的推理吞吐量提升，直接降低单位请求的推理成本。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadNcTpIUjXIc5RwbEicW80ug35icSOka04xjBHEYRvWICGDZX7GDHlzpAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529763" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c1b6de0a-783e-4131-9e6c-db74f212cd01/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Gated Eagle3&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;另外还有面向医学 MoE 模型的极致量化。在部署侧，百川针对 MoE 架构的稀疏激活特性设计了面向医疗场景的定制化的量化方案，并通过专家均匀激活校准避免了 MoE 专家量化失衡。量化之后的 M3 Plus 在主流基准评测和医学效果评测上推理成本下降 30%，同时性能几乎无损。&lt;/p&gt;&lt;p&gt;鞠强表示，在具有最高专业度的同时，M3 Plus 的每 Token 成本比通用的 DeepSeek、千问等模型还要更低。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;医疗健康 &amp;nbsp;今年 AI 落地的主战场&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「今年是 AI 进入医疗的关键一年，」王小川判断。&lt;/p&gt;&lt;p&gt;事实上，在国内外 AI 领域，今年一开年，就有很多与 AI 医疗相关的大新闻曝出。&lt;/p&gt;&lt;p&gt;1 月 8 日，OpenAI 宣布推出 ChatGPT Health，提供了一个「专门用于与 ChatGPT 进行健康相关对话的独立空间」，连接电子医疗记录和各类健康应用，生成的回复能够结合用户的健康信息与个人情境；1 月 12 日，Anthropic 推出 Claude for Healthcare，使医疗服务提供者、支付方和消费者能够将 Claude 用于医疗用途；在国内，蚂蚁阿福（AQ）作为 AI 驱动的医疗健康应用已经获得了 3000 万的月活用户。&lt;/p&gt;&lt;p&gt;这一方面证明了医疗正在成为 AI 技术落地的核心场景，也证明了百川率先切入医疗赛道的正确性。&lt;/p&gt;&lt;p&gt;不过在应用大模型的方向上，百川选择的路径与很多试图构建 AI 健康助手的玩家有着本质的不同 &amp;mdash;&amp;mdash; &lt;strong&gt;当很多 AI 应用试图通过连接你的手表和手机，成为你的「健康管家」时，百川选择了一条更艰难、更垂直的道路：直面严肃场景，进入医院核心科室，成为医生的「第二大脑」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;M3 Plus 的发布，标志着中国 AI 公司在垂直赛道上，通过极致的工程化与场景深耕，正在构建起属于自己的护城河。&lt;/p&gt;&lt;p&gt;王小川表示，相信在三年以内，AI 辅助的医疗问诊等应用将会在国内外大规模落地。&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.baichuan-ai.com/home?sessionid="&gt;点击此链接，加入「海纳百川」计划&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>清华姚班校友刘壮团队再发力，无需归一化的Transformer性能进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 19:13:23 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜陈陈、冷猫&lt;/section&gt;&lt;p&gt;刘壮带队的无需归一化 Transformer 又有新的版本了。&lt;/p&gt;&lt;p&gt;一直以来，在 Transformer 架构里，LayerNorm 几乎是标配，但它也有明显问题：比如计算和访存成本高，尤其在大模型推理阶段。&lt;/p&gt;&lt;p&gt;因此，「无归一化（Normalization-Free）」Transformer 成为研究者探索的一个长期目标，但一直卡在两个难点上：训练不稳定，以及性能明显不如带归一化的模型。&lt;/p&gt;&lt;p&gt;而这篇新论文提出了一种非常简单的新激活层 Derf（Dynamic erf），让「无归一化（Normalization-Free）」的 Transformer 不仅能稳定训练，还在多个设置下性能超过了带 LayerNorm 的标准 Transformer。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadJGMW4Z6Wdtiblds23HfokXyeZ3lXHx8ZRXCG0fIqWbzMv0m8GOxFosQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.28544423440453687" data-type="png" data-w="1058" data-width="1058" data-height="302" data-imgfileid="503529570" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1aca6cd8-3ec0-4133-abb8-f670d18c94c7/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Stronger Normalization-Free Transformers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.10938&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github 链接：https://github.com/zlab-princeton/Derf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;刘壮本人也在 X 账号上分享了这一成果。他表示，这是一篇关于更强无归一化 Transformer 的新论文：研究团队提出了 Derf（Dynamic erf），一种结构极其简单的逐点（point-wise）层。借助 Derf，完全不依赖归一化层的 Transformer 不仅能够稳定训练，而且&lt;strong&gt;在实际性能上已经可以超越传统依赖 LayerNorm 等归一化机制的模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一结果表明，长期被视为标配的归一化层，并非构建高性能 Transformer 的唯一选择。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadoWlibQfTWyxALjKyd3ayU660jXz7HKH0lWRVguDWm0UNgTZhI1Oic1zA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5138888888888888" data-type="png" data-w="1080" data-width="1172" data-height="602" data-imgfileid="503529571" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0bfeeea7-1f6a-45a1-a491-6707cd7251cb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;今年早些时候，刘壮、何恺明、LeCun 等人已经在题为《无需归一化的 Transformer》的论文中表明，Dynamic Tanh（DyT）函数可以取代 Transformer 中的归一化层。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Derf 进一步发展了这一想法。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;和 DyT 类似，Derf 是一种不依赖统计量的逐点（point-wise）层，不需要使用激活分布的统计信息。它本质上只是一个带有少量可学习参数的平移并缩放后的高斯误差函数（Gauss error function），可以直接替换你原本使用 LayerNorm 或 RMSNorm 的位置。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad4NLZBUqKibHJzxSmBrdVlI0Zvgaq5anh6kgRpETjeCPPukI9tia0WIGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.33555555555555555" data-type="png" data-w="900" data-width="900" data-height="302" data-imgfileid="503529572" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4b75ef8e-574c-4e3d-9ec3-2cbcc9e323f2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;由于其结构极其简单、效果稳定且性能更强，Derf 为构建无归一化（normalization-free）的 Transformer 架构提供了一种非常具有实践价值的选择。相关代码已开源。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;超越归一化层的逐点函数&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文的目标正是寻找性能超越归一化层的逐点函数，以推动更强的 Transformer 架构发展。&lt;/p&gt;&lt;p&gt;研究团队首先系统性地研究了逐点函数的内在性质如何影响训练动态和最终性能，重点关注四个基础且具有代表性的属性：&lt;strong&gt;零中心性（zero-centeredness）、有界性（boundedness）、中心敏感性（center sensitivity）以及单调性（monotonicity）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;实验发现，只要一个函数同时满足这四个条件，模型训练过程就会更加稳定，并且通常能取得不错的性能表现。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadgmrRCCvZEbLxVqibOHWNuNQuAia44w78wglVJ1nSnfhRRIL1Y7ql7T3g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1712962962962963" data-type="png" data-w="1080" data-width="1200" data-height="205" data-imgfileid="503529573" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a76a27ba-a559-4b64-8b62-89af229aa4e7/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这一分析筛选出了一类可作为有效归一化替代的逐点函数，并总结出一套面向无归一化 Transformer 的明确设计原则。&lt;/p&gt;&lt;p&gt;最终，Dynamic erf（Derf） 作为一种结构极其简单但性能最优的函数设计脱颖而出。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadWsZlpueOpJfoeEXTkuSQyA4n74IzcsYibbtoWWJzOicYvJic8fHb9huNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.29814814814814816" data-type="png" data-w="1080" data-width="1608" data-height="480" data-imgfileid="503529574" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d2a0696c-636e-467d-b476-33212f08f610/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;总体而言，本研究表明：只要设计得当，逐点函数不仅可以替代归一化层，甚至能够在性能上超越它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最优函数设计：Derf&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在函数搜索过程中，我们发现 erf (x) 是性能最优的逐点函数。误差函数 erf (・) 与标准高斯分布的累积分布函数（CDF）密切相关。具体而言，erf (x) 的定义如下所示。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadxxYdhNIturdKHGpOUvPxAxjejs7mKMZ9ICQGN9Uqmzow558gWdvhrw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3875968992248062" data-type="png" data-w="774" data-width="774" data-height="300" data-imgfileid="503529575" data-aistatus="1" data-original-style="width: 375px;height: 145px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/99211b4e-8c67-4df4-a3ad-73e6ef5fe7ee/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在本文的设计中，erf (x) 进一步引入了可学习参数，并由此提出 Derf（Dynamic erf）。对于输入张量 x，Derf 层的形式如公式（10）所示，其中位移参数 s 和缩放参数 &amp;alpha; 都是可学习的标量，而 &amp;gamma; 和 &amp;beta; 是可学习的逐通道向量。&lt;/p&gt;&lt;p&gt;在将 Derf 集成到基于 Transformer 的架构中时，研究团队采用一一对应替换的方式：将模型中的各个归一化层直接替换为相应的 Derf 层。具体来说，包括 &lt;strong&gt;注意力层前（pre-attention）、前馈网络前（pre-FFN） 以及 最终的归一化层&lt;/strong&gt;，均被 Derf 所取代，从而保证 Derf 在整个模型中的一致性使用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在多种基于 Transformer 的架构以及少量其他现代模型上，系统评估了 Derf 的有效性。在使用相同训练配置的前提下，Derf 的表现可以持平甚至超过传统归一化层，并且在各个领域中都稳定优于 DyT。&lt;/p&gt;&lt;p&gt;简而言之：&lt;/p&gt;&lt;p&gt;1. ImageNet（ViT-B / ViT-L）：Top-1 准确率更高&lt;/p&gt;&lt;p&gt;2. 扩散 Transformer（DiT 系列）：FID 更低&lt;/p&gt;&lt;p&gt;3. 基因组任务（HyenaDNA、Caduceus）：DNA 分类准确率更高&lt;/p&gt;&lt;p&gt;4. 语音（wav2vec 2.0）：验证集 loss 更低&lt;/p&gt;&lt;p&gt;5. 语言模型（GPT-2）：整体表现与 LayerNorm 持平，明显优于 DyT&lt;/p&gt;&lt;p&gt;Vision Transformer（ViT）&lt;/p&gt;&lt;p&gt;研究团队在 ImageNet-1K 数据集上训练了 ViT-Base 和 ViT-Large 模型，分别采用 LayerNorm（LN）、DyT 和 Derf 进行对比。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadjDjkmkNicsbTAaKvz0NrdBmIbImng5YJXCwyLjRR4lDibJgiaRpteSkeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.21132075471698114" data-type="png" data-w="1060" data-width="1060" data-height="224" data-imgfileid="503529576" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c9fd263c-c25c-4e64-bbd6-e8a6cbc1fd8d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ImageNet-1K 上的监督分类准确率。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在不同模型规模下，Derf 的 Top-1 准确率均高于 LayerNorm（LN）和 DyT，充分证明了其在 ViT 架构中的有效性。&lt;/p&gt;&lt;p&gt;Diffusion Transformer（DiT）&lt;/p&gt;&lt;p&gt;研究团队在 ImageNet-1K 上训练了三种 DiT 模型，并在 LN、DyT 和 Derf 下保留归一化层的仿射参数用于类别条件化。训练完成后，使用 ImageNet 「参考批次」评估 FID 分数，以衡量图像生成质量）。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadURLjicuJxRGIIIEib48CAyZyhEpiaPqxoEal0L8gr2FyriaTZWv0RZicp3Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.264" data-type="png" data-w="1000" data-width="1000" data-height="264" data-imgfileid="503529577" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/67ca3438-31a1-4f37-93a7-ac93335b04e7/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ImageNet 图像生成质量（FID）。FID 越低表示图像生成质量越高。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;结果显示，Derf 在所有 DiT 模型规模下的 FID 都低于 LayerNorm 和 DyT，进一步验证了其在扩散 Transformer 中的有效性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语音模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 LibriSpeech 数据集上训练了两个 wav2vec 2.0 Transformer 模型，用于语音表示学习。表 10 报告了最终的验证集损失（validation loss）。结果显示，与 LayerNorm 和 DyT 相比，Derf 在不同模型规模上均实现了更低的验证损失，说明其在语音任务中的有效性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadhiag0xU9JwwxzicnFuRv0l0k6rhXe91WBnLlnUJUb5FibwGKCXGzPDib4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.20185185185185187" data-type="png" data-w="1080" data-width="1308" data-height="264" data-imgfileid="503529578" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c4f96529-0f29-41ab-8c25-d6d89acf7db7/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; LibriSpeech 数据集上的语音预训练验证损失（validation loss）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;结果显示，Derf 在两个 wav2vec 2.0 模型上均实现了比 LayerNorm 和 DyT 更低的验证损失，表明其语音表示能力更强。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DNA 模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在长序列 DNA 建模任务中，研究团队对 HyenaDNA 和 Caduceus 模型进行了预训练，使用人类参考基因组（GRCh38.p13）。模型评估在 GenomicBenchmarks 数据集上进行，并报告所有子任务的平均准确率。&lt;/p&gt;&lt;p&gt;如表所示，Derf 在性能上超过了 LayerNorm、RMSNorm 以及 DyT，显示了其在基因组序列建模任务中的稳健性与泛化能力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadx3adpn1sWGoYU4BnUlMeRu3otf2sZcf2X5p28dAsSic8aAlzBLTFnTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.21388888888888888" data-type="png" data-w="1080" data-width="1160" data-height="248" data-imgfileid="503529579" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9a2f7bce-dd18-4297-a662-a0996d2c6224/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;DNA 分类准确率（GenomicBenchmarks 数据集）表中结果为各子任务的平均准确率。每个模型均使用其默认归一化层（HyenaDNA 使用 LayerNorm，Caduceus 使用 RMSNorm）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;结果显示，Derf 在所有模型中均优于原有归一化层及 DyT，表明其在 DNA 模型上的有效性和稳健性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语言模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 OpenWebText 数据集上对 GPT-2（124M）模型进行预训练，并在表 12 中报告验证集损失。对于 DyT 和 Derf，还对可学习参数 &amp;alpha; 进行了额外微调。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadXTkyqo44Gzw2KMXX3zpPFDHHCWW7FB7j6ctVNeSzE766yfWic7v01Bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.16666666666666666" data-type="png" data-w="1080" data-width="1188" data-height="198" data-imgfileid="503529580" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/be1f676f-7ffd-4d9e-b360-79403ddc476b/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;GPT-2 在 OpenWebText 数据集上的验证集损失。Derf 的表现可与 LayerNorm（LN）匹配，同时在验证集损失上明显低于 DyT。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实验结果显示，Derf 在性能上可与 LayerNorm（LN）持平，同时明显优于 DyT。&lt;/p&gt;&lt;p&gt;这表明：一个足够简单的逐点层，不仅可以「替代」归一化层，还能让 Transformer 变得更强，而不只是不变差。&lt;/p&gt;&lt;p&gt;Derf 只是「拟合得更狠」吗？出人意料地，并不是。当研究团队在 eval 模式下、对训练集本身测量训练损失时，结果是：基于归一化（Norm）的模型训练损失最低，Derf 训练损失反而更高。但在测试集上，Derf 的表现更好。&lt;/p&gt;&lt;p&gt;这说明一个关键事实：Derf 的优势并不来自更强的拟合能力，而主要来自更好的泛化能力。&lt;/p&gt;&lt;p&gt;一句话总结：&lt;strong&gt;Derf 是一种简单实用的、可用于更强正则化自由 Transformer 的即插即用层&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;更多信息，请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
