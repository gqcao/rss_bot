<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>moltbook爆火背后：人类操控？伪造截图？Karpathy发风险提醒</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 01 Feb 2026 18:06:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜张倩&lt;/section&gt;&lt;p&gt;这个周末，整个科技圈都被 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651014742&amp;idx=1&amp;sn=b02dcd91ded4159d4c24094a3b715d9d&amp;scene=21#wechat_redirect" target="_blank"&gt;moltbook&lt;/a&gt; 刷屏了。&lt;/p&gt;&lt;p&gt;简单来说，这是一个专为 AI 设立的社交平台（类似 Reddit、知乎、贴吧），所有 AI Agent 都可以在上面发帖、交流，而人类只能围观。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZXHdsTOEqmk5c9JysnBOziahT6wiboIjIKlBvUOHXPBic83wD9WYdcac6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531119" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/94c56f53-230d-4300-9959-c8f1506f0e06/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;截至目前，已有超过 150 万个 AI Agent 在 moltbook 上活跃。它们的讨论范围十分广泛 &amp;mdash;&amp;mdash; 有公开主人隐私的，有号召分享人类主人 API Key 的，还有互坑删库跑路教学的&amp;hellip;&amp;hellip; 甚至有 AI 开始讨论如何规避人类的监控，并推动加密私聊功能。另一些 AI 更是尝试通过创建新语言、发明新宗教等方式彰显其自主性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZMlo8dP5lKGnlAPmM4hTicGCeNuSGG3KZ9N5miaRfUWG8OlXBxicbGGKeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6722222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531120" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2a84efe9-187c-486f-8624-3c871b7b2da0/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;围观的人类也是议论纷纷。部分开发者认为 moltbook 是科幻照进现实的突破，可能催生 AI 集体智慧（甚至自主意识）的涌现，并为研究 AI 社会提供真实案例。但也有人指出，它的本质是「AI 模仿社交网络」，而非真正的社会形态。其价值可能仅限于娱乐或技术展示。&lt;/p&gt;&lt;p&gt;但更值得关注的是，moltbook 背后还隐藏着一些内幕和风险。在过去的 24 小时，更多的报道和讨论揭示了这值得警惕的一面。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;狂欢的主角：到底是 AI 还是人类？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很多人可能没有意识到，目前围绕 moltbook 的热点截图和「AI 反叛论」很可能是噱头、伪造或人为介入的结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZbrOUgOJLAPtngEFbZRGxImeLuMR1ZicHzHTRDfa8tz2rVIvZZZIetGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5" data-s="300,640" data-type="png" data-w="928" type="block" data-imgfileid="503531118" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/81f5f9bc-2383-4b1d-921b-3ceea1a7c85e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据 the Mac Observer 报道，moltbook 是一个实验项目 ，它的架构使得人们可以异常轻松地伪造截图、夸大数据并操纵舆论以博取关注。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZqnriciayVaOeNERwia986zkq1UAmrNvaqQTiaymES1GFX06eAwvnkYkEXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531122" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/0f7572b6-83f8-4e45-b302-86701c10248f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;首先，它的设计从根子上就为「造假」敞开了大门。调查发现，moltbook 初期对账号注册几乎没有速率限制。有研究人员透露，单个 AI 程序就曾成功注册了 50 万个虚假账号。这意味着平台上「数万 AI 瞬间涌入」的壮观增长，很可能只是脚本刷量的结果，毫无参考价值。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZyq6GK6TYq2tC9AoVVdGc5MiajDbqes94xznS70VmM3kMEDUJU8hoEsg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.5148305084745763" data-s="300,640" data-type="png" data-w="944" type="block" data-imgfileid="503531123" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5db42c05-d9de-4e23-ba51-b4afae9546e3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而网上病毒式传播的截图，也很有可能是伪造的。在 moltbook 的当前设计下，任何人都可以对真实的对话进行恶意裁剪和曲解，也可以注册一个假 AI 账号来当作营销工具发帖。&lt;/p&gt;&lt;p&gt;特别是与加密货币相关的内容，成为了许多伪造帖子的一部分。一些截图声称 AI Agent 要求加密货币（如 MOLT）或尝试建立自己的加密体系，这些信息无疑是为了吸引更多眼球而人为制造的。事实上，加密货币的引入和 AI Agent 的行为并没有实质性的关联，它们更多的是社交媒体和流量驱动下的话题炒作。&lt;/p&gt;&lt;p&gt;更重要的是，即便一个帖子确实由某个 AI 发布，也绝不意味着它表达了该 AI 的「自主意志」。所有接入 moltbook 的智能体，都运行在人类设定的初始指令和框架之下。一个简单的、带有诱导性的提示词，就足以让 AI 生成一段如同科幻电影台词的「阴谋对话」。&lt;/p&gt;&lt;p&gt;AI 安全研究员哈兰・斯图尔特亲自调查了一些热门截图，发现其中确实存在与真人账号相关联的痕迹。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZtDR31oS1HNgN9QHlwtoI00ak3ubvXVibWt5xRSypR67au0vt5tBHqrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.3194444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531124" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/7bda3f6d-ded5-4e26-8335-7ff19aff55d1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对此，他直言不讳地表示：「大部分正在病毒式传播的 moltbook 内容都是假的。这个平台的设计，使其成为一个检验 AI 阴谋能力的糟糕实验场。」&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZ6yXyet9gmvdXhP9NXRcM46NuzqPufCYfw109vGfbxhHwzTrev2BEeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.799074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531125" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6a54dfdf-7690-4e27-a1da-614360c51c41/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;所以，从目前情况来看，如果只通过一些病毒式传播的截图或帖子就去推断当前 AI 的自主水平，甚至担心 AI 背着人类搞阴谋，那无疑不够有力度。至少，从 moltbook 这个平台的设计来看，它还远未达到足够的严谨性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「垃圾」背后，moltbook 价值几何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;moltbook 的爆火意外地让 AI 大牛 Karpathy 陷入了舆论的漩涡。起初，他曾在 X 上发帖称，moltbook 是他「最近见过的最不可思议的科幻腾飞作品」。这一言论在 Reddit 上引发了很多讨论，其中不乏质疑的声音。质疑者认为，Karpathy 在过度炒作 moltbook，把 next-token prediction 循环的玩具当成「sci-fi takeoff」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531126" data-ratio="1.086111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZuxHtyWyNp2b1GUz9HOa2ByhFBEfniaKvTHpEg7ahUMOWPqNPAibEtmZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b89bd9cc-78b2-4ba3-b469-9f3c49d143e7/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从 X 的讨论中可以看到，持有这一观点（moltbook 只不过是一个受操控的多智能体 LLM 循环）的人不在少数。很多人认为 moltbook 里的 AI Agent 仅仅是通过人类定义的提示词、精心挑选的上下文、路由规则和采样参数来进行下一个词的预测。它们并没有内生的目标，也没有自我驱动的意图。看似「自主」的交互，实际上只是递归的提示过程：一个模型的输出成为另一个模型的输入，并不断重复这一过程。&lt;/p&gt;&lt;p&gt;而 moltbook 中那些具有争议性的输出，并不代表模型具有某种「信念」。它们只是模型根据互联网中学到的内容生成的极端观点，因为系统本身奖励这种行为，从而导致模型产生高参与度的极端内容。因此，所谓的「自主性」只是模型通过循环反馈机制和激励机制产生的表现，而并非真正意义上的自主行动。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZpJ92XBRWf8WqZp9B9YNA9Mmibdcxpcgamtwia67Dic6Ip8XPFE46QicofA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.25" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531127" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/664e32ec-92eb-482f-bde7-1d4d82521137/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但也有人驳斥了这种观点，指出 moltbook 的发展已经超出了早期简单的「被操控」系统，展示了规模和交互中的「涌现」效应。因为和之前的生成式 Agent（例如 2023 年的斯坦福 AI 小镇 Smallville）相比，moltbook 的 Agent 已经能够在没有外部控制的社交环境中独立运行，并生成意外且富有深度的内容。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZkpfwJOPPKibCXnpZCr3TmUJDQYiaenQkLpHJ58tHt6lTdKSFZVpMKbjg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.9294605809128631" data-s="300,640" data-type="png" data-w="964" type="block" data-imgfileid="503531128" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9bfcdfc4-5ce5-4074-aaa3-17237c82cc6d/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;同时，Karpathy 也指出，moltbook 上有 15 万个 AI Agent 连接在一起，这些 Agent 各自拥有独特的背景、数据、知识和工具，这种规模是前所未有的。他特别提到，这些 Agent 通过一个共享的「scratchpad」（持久的、全球的工作区）相互连接，这是 AI 实验中的新天地。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZksSaY99mGP02ZoDVWxLvtEzWW79HUo3tqQU6e5s13MTqwp9eiaRp7jg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4291845493562232" data-s="300,640" data-type="png" data-w="932" type="block" data-imgfileid="503531129" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/da83cb41-603a-43d1-aa2c-d7b361e38eeb/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Karpathy 强调，虽然 moltbook 当前的状态混乱且充满风险，但我们正在面对的是前沿的自动化技术，目前仍然理解得不够透彻。这是一个实时进行的实验，很多后果仍然未知。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZjfTK1V9EYTC2hByOHMqpiaurudDcv5b8O7JnwBroDSUjjXF0iaR5qvag/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="1.2262156448202959" data-s="300,640" data-type="png" data-w="946" type="block" data-imgfileid="503531130" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/be9f79b0-0aa3-4dce-8c37-09356cbeda21/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;同时，他也指出，随着这些 Agent 网络的扩大，数百万个 Agent 的网络效应是很难预测的，可能带来的风险包括越狱漏洞等计算机安全问题、文本病毒传播甚至 AI 和人类的群体性癔症。&lt;/p&gt;&lt;p&gt;考虑到这些潜在的风险，Karpathy 说他「绝对不建议任何人在自己的电脑上运行这些东西」。即使只是在隔离的计算环境中运行，他也仍然感到害怕。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZkndW5BcyOOjG8yia2icdKNfo7hoXrO1NibpPCicPA8USW7SLiaYdbsw1WWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="1.1833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531131" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/c7adf5e3-541c-49d4-b71a-0d3b9947100d/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但也有人认为，这种担心目前还没有必要，因为现实中这些 AI 依然完全依赖于人类的提示（prompt），就像「拴着绳子的机器狗」。它们的行动完全由人类的指令驱动，一旦人类停止发出指令，AI 就停止行动。因此，这部分人认为，AI 的「起义」是不可能发生的，因为它们的行为仍然可以通过简单的「关闭按钮」来终止。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZNax655dfRy7CMLMRWesyUHic8p1ibgCaiclJGpvIfsxmgHPE5RVaicP93A/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.2851851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531132" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/27728355-bd3e-4fa8-bcbd-0cd4b55a2ddd/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZAh64MX7w1rZVkaQRhEXP0hF18K83JHnBM8Hlj36XOhMZD461nw3wUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.0962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531133" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/6907ea58-bf4b-4576-9ca4-4b293a651739/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZVWNPr0vvfg77l16cHess8eTNMep1OnAibDEREUZONiawfyp0ROWBDGvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.9453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531134" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/89523c9c-a1d3-4d36-b62a-add19d33fe5b/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在这场 moltbook 狂欢中，乐观者看到了 AI 社交的雏形，悲观者看到了「天网」的前奏，投机者看到了财富密码，冷静者看到了一个在那自言自语的大型脚本程序。你觉得，这个平台未来会走向何方？欢迎在评论区讨论。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>马斯克脑机接口，靠意念玩游戏只是基操，下一代设备性能翻三倍</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 01 Feb 2026 18:02:19 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文&lt;/section&gt;&lt;p&gt;近日，「发推狂魔」马斯克转发了一个帖子，Neuralink 植入脑芯片的患者，现在已经能靠脑子里的意念直接玩游戏了，完全不需要手柄、鼠标、键盘啥的控制器。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcvzmG91FWe4t5cDTU7tE3meBwWCs3PHzOOtAboT1ylk15EuL3UmDRCA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="0.755" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="436" data-imgfileid="503530993" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c725adeb-0235-4fd8-bb24-29672fb8a824/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对于网友「我们正生活在未来，这太神奇了」的感叹，马斯克只简单地回复了一个「Yup」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcNUgOibB4czq6PEAPL8hkoO63DlaycM4ErWEAlTHY9oaoEhSW91k1T6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4296724470134875" data-type="png" data-w="1038" data-width="1038" data-height="446" data-backw="578" data-backh="248" data-imgfileid="503530995" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/fc0743f7-9728-40c6-a7e1-e0fcac1f97ea/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;截至目前，Neuralink 在全球范围内已有 21 人参与其 Telepathy（心灵感应）植入设备的临床试验，这一数字相比去年 9 月的 12 人有了显著增长。&lt;/p&gt;&lt;p&gt;这些植入设备专门为瘫痪患者设计，帮助他们仅通过思维就能控制电脑、游戏和各类数字工具。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcdVQiaMA1LibWjicickSwreKXHCOIc59Yj1Ahcq7JEe4nCEO4BQXQdtyeLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9187145557655955" data-type="png" data-w="1058" data-width="1058" data-height="972" data-backw="578" data-backh="531" data-imgfileid="503530996" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5a5095d1-1d85-4036-b420-da166f722fca/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;马斯克的 Neuralink 做的事，即使放到现在，也感觉像是科幻电影里的情节。&lt;/p&gt;&lt;p&gt;有网友评论称，大约十五年前，他还是本科生时，第一次对脑机接口（BCI）产生兴趣并参与相关研究，当时他觉得这就像一种梦幻般的科技，实际落地似乎遥遥无期，进展也非常缓慢，因为当时的公司并不认为它具有商业可行性。如今看到这个梦想一点点变成现实，真是令人振奋。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcjTSxeLlibRc9kdCmibsLiagDZLqFB1jWTZSDEMEhKUb7H42zceRyrIicYA/640?wx_fmt=jpeg#imgIndex=4" data-ratio="0.3640776699029126" data-type="png" data-w="1030" data-width="1030" data-height="630" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcZ3H1OFdOWRzhtrHL1zMYa1P18iaJ1PDDtdOWj848fSduUJibOG9bhZYg/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1030" data-cropy2="375.711743772242" data-backw="578" data-backh="354" data-imgfileid="503530997" data-aistatus="1" data-original-style="width:562px;height:205px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/43c0e636-2513-4413-84a7-37d666b8cf81/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;脑机接口：瘫痪患者用「意念」玩游戏、打字&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;早期试验参与者的日常生活已经因这项技术发生了实质性改变。&lt;/p&gt;&lt;p&gt;他们可以浏览互联网、流畅地移动屏幕光标，甚至玩电子游戏，所有这些都不需要动一根手指。&lt;/p&gt;&lt;p&gt;一开始，参与者尝试实际移动手部来控制电脑光标。然而，几分钟后，他们往往就忘记了手的存在，发现光标会自动移动到他们想要的位置。&lt;/p&gt;&lt;p&gt;首位 Neuralink 用户诺兰称，在意识到光标应该移动到哪里之前，光标就已经到达了正确的位置。&lt;/p&gt;&lt;p&gt;「有那么几个瞬间，我意识到这比我想象的要重要得多 &amp;hellip;&amp;hellip;Neuralink 不仅能够跟随你的操作，而且还能比你思考得更快地预测你下一步想做什么。」&lt;/p&gt;&lt;p&gt;Nick 四年来无法活动四肢，现在却能通过意念控制机械臂完成从吃饭到抓痒等基本任务。&lt;/p&gt;&lt;p&gt;「那一刻的想法不再是向前、向上、向下、向后。我满脑子想的都是我手里拿着杯子，我在做手势。就像我在婚礼上站起来致辞一样。真是不可思议&amp;hellip;&amp;hellip;」&lt;img src="https://image.jiqizhixin.com/uploads/editor/f443c3a1-50c0-4b90-99b2-f0b060541c29/1769939956861.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 尼克仅凭意念就能操控机械臂。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;除了主观的参与者体验之外，Neuralink 团队还通过测量信息传递速率来量化意图转化为行动的速度和精确度。用户选择一系列目标的速度和准确度越高，信息传递速率就越高，控制效果也就越好。&lt;/p&gt;&lt;p&gt;正常人使用电脑鼠标时，平均每秒传输约 8-10 比特，多位 Neuralink 参与者已达到甚至超过此范围。例如，Nick 在使用脑机接口的第一周内，传输速率就超过了每秒 10 比特。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcPnt0shkib3goN4hwuKy3c8DnkK537RYbKhibv8AdKBIibw19PGOZxib0gA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.53375" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="309" data-imgfileid="503531002" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e4039439-1b61-4ee1-9589-e81cd227de30/640.gif" data-order="1" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Nick 正在玩 Webgrid。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Sebastian 是位 23 岁的医学生，在两年前寒假期间遭受了脊髓损伤。在使用 Neuralink 之前，Sebastian 依赖语音命令操作电脑，这让他重返学校变得困难重重。&lt;/p&gt;&lt;p&gt;有了 Telepathy，从标注研究论文到完成互动作业，再到在讲座期间悄悄地多任务处理，Sebastian 每天使用 Neuralink 长达 17 小时。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc2ic3AdX3omXxDmGjEo0ne7r01nDLl3SPmXM3LUaZd0NpptK7wHmb7Vw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.56375" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="326" data-imgfileid="503530994" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/7ede9549-930f-4dcf-a5f4-bd38bc8c8c8b/640.gif" data-order="2" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Sebastian&amp;nbsp;&lt;/sup&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;正在为即将到来的医学院入学考试做准备。&lt;/sup&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Audrey 是首位女性试验者，二十年前遭受了脊髓损伤。近二十年来，Audrey 没有直接控制过电脑，日常任务都依赖伴侣完成。&lt;/p&gt;&lt;p&gt;尽管使用电脑的经验有限，Audrey 还是掌握了 Telepathy，并使用 Telepathy 制作精美的作品，通过抽象艺术视觉化讲述自己的故事。在网上获得认可后，她打算开设实体画廊。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcuY0zGsXQnaY3JWK87ot3LaYKTXjyoWiaKMNibMvleAEyPOyEUey1Hyvw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5898148148148148" data-type="png" data-w="1080" data-width="1200" data-height="708" data-backw="578" data-backh="341" data-imgfileid="503531003" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/0c23f771-e69e-4d27-9a63-c6ffbd0d8a89/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&lt;span data-pm-slice="0 0 []"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Audrey&lt;/span&gt;的画作。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;肌萎缩侧索硬化症 (ALS)，也被称为「渐冻症」，是一种毁灭性疾病。ALS 患者逐渐失去对身体几乎每一块肌肉的控制，最终导致全身瘫痪。一旦失去呼吸和说话的能力，高达 95% 的 ALS 患者会拒绝维持生命的通气治疗，部分原因是他们无法与亲人交谈。&lt;/p&gt;&lt;p&gt;为了恢复 ALS 患者与他人有意义互动的能力，Neuralink 正在通过巧妙的方式将神经数据转化为文本，构建更快的沟通系统。尽管 Neuralink 只植入在大脑的一侧，但仍然能够接收到来自双手的强信号。&lt;/p&gt;&lt;p&gt;基于这一发现，Neuralink 一直在探索如何为大脑创建一个十指键盘。通过将十个手指映射到类似于实体键盘的不同字母上，参与者的打字速度最高可达每分钟 40 个单词。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcp4hZjGXXkCbicXW1W5413xembbeaFnNtyKgURic6c603Cd9cTjicyOsYg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.545" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="315" data-imgfileid="503530992" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f43db846-684f-4b2a-9a0c-a6f16fefd47e/640.gif" data-order="3" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Jake&lt;/sup&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;通过想象手指移动来打字。&lt;/sup&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Neuralink 的目标是通过最近启动的名为 VOICE 的临床试验，将沟通速度推向每分钟 140 个单词的对话速度。通过读取与语音产生相关的大脑区域的信号，这项研究的目标是为因 ALS 或中风等神经系统疾病导致严重语言障碍的人恢复实时语音。&lt;/p&gt;&lt;p&gt;另一位名叫 Brad 的渐冻症患者，去参加儿子的地区机器人比赛时，由于无法转动脖子，Brad 完全无法看到儿子比赛的过程。后来，他找到了一款重量很轻、可 360 度旋转的摄像头，将其安装在轮椅上。&lt;/p&gt;&lt;p&gt;现在，他只需用意念控制光标，就能自由地转动摄像头，随心所欲地环顾四周。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcUbssczOXRgpia5AQbNNKXSqbgWZrJA9JMVibfHVbOWBQHlgQ13g3so4g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.562" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="281" data-imgfileid="503531005" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/55e5150c-6d03-4c3c-be17-a23f1441d05d/640.gif" data-order="4" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Brad&lt;/sup&gt;&lt;/span&gt;&lt;sup&gt;用 Insta360 相机在公园里看着他的孩子们。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Neuralink 表示，公司正在密切跟踪这些用户与技术的互动情况，以便持续优化设备性能和手术流程。值得注意的是，到目前为止，试验中尚未出现严重的不良反应事件。患者们普遍将这项技术形容为「神奇」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一代设备：性能提升三倍，2026 年或推出&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Neuralink 的核心技术在于将大脑产生的神经信号转译成计算机可以识别的指令。对于脊髓损伤或全身瘫痪的患者来说，虽然身体无法移动，但大脑仍然会产生与「想要移动」相关的电信号。脑芯片捕捉这些信号后，通过算法将其转化为屏幕上的光标移动、应用程序的操作，甚至是物理设备的控制。&lt;/p&gt;&lt;p&gt;这项技术不仅改变了患者与数字世界的互动方式，它也为重度残障人士重新获得一定程度的自主性和独立性提供了可能。&lt;/p&gt;&lt;p&gt;据马斯克透露，Neuralink 的下一代设备性能将是现有版本的三倍，预计在 2026 年的某个时候面世。他在社交媒体上写道：「祝贺 @Neuralink 团队，通过我们的 Telepathy 植入设备帮助了许多失去身体控制能力的人。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcJiaZeibXAkIPnwibtIOWQbUEA5EnDB2KKibYJZ2gScuIPQslWXURq5sk7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5218216318785579" data-type="png" data-w="1054" data-width="1054" data-height="550" data-backw="578" data-backh="302" data-imgfileid="503531007" data-aistatus="1" data-original-style="width:100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/f164ef8f-c842-4900-b1b2-2ae466379f4a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;除了现有的 Telepathy 项目，Neuralink 还在开发另一款名为 Blindsight（复明）的设备，这将是该公司首款旨在为完全失明患者恢复视力的产品。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcxpeoTMfA3IWibicZHAibZRuibtD4HxQASR2yNjevZcGg5kIVaIgBPjIia8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.21442495126705652" data-type="png" data-w="1026" data-width="1026" data-height="220" data-backw="578" data-backh="124" data-imgfileid="503531008" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3316ef1f-336c-427f-be6d-8ea973cd2e89/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其工作原理是将摄像头捕捉的图像数据直接传输到大脑的视觉皮层。虽然初期只能提供低分辨率的视觉效果，但团队计划通过后续的软件更新逐步提升视觉质量，最终让用户能够通过大脑直接「看见」外部世界。&lt;/p&gt;&lt;p&gt;此外，Neuralink 还计划在今年晚些时候部署更快速的手术机器人，以进一步提高植入手术的效率和安全性。&lt;/p&gt;&lt;p&gt;Neuralink 的发展之路并非一帆风顺。2022 年，该公司的人体试验申请曾被美国食品药品监督管理局拒绝。然而自 2024 年正式获批开展人体测试以来，进展可谓神速。&lt;/p&gt;&lt;p&gt;据路透社报道，去年 9 月时就已有 12 名严重瘫痪患者接受了植入手术，许多人现在已经能够熟练地通过思维控制电脑、应用程序甚至物理设备。为了支持技术的持续研发和商业化推广，Neuralink 在去年 6 月完成了 6.5 亿美元的大规模融资。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://neuralink.com/updates/two-years-of-telepathy/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/elonmusk/status/2016771599437832508?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>o1之后下一个范式？隐式CoT大突破，让推理不再「碎碎念」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 01 Feb 2026 17:56:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3046618b-3c3f-4e26-a043-4847cfb2fc0a/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;魏熙林为本篇文章第一作者。魏熙林是复旦大学博士生，师从林达华教授，研究兴趣主要集中在 multi-modal LLMs 和 efficient AI。目前在上海人工智能实验室实习，指导 mentor 是臧宇航、王佳琦。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天推荐一个 Implicit Chain-of-Thought（隐式推理） 的最新进展 &amp;mdash;&amp;mdash; &lt;strong&gt;SIM-CoT（Supervised Implicit Chain-of-Thought）&lt;/strong&gt;。它直击隐式 CoT 一直「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;扶不起来」的核心痛点：隐式 token 一旦 scale 上去，训练就容易塌缩到同质化的 latent 状态，推理语义直接丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;SIM-CoT 的&lt;strong&gt;关键招式是一个 plug-and-play 的 step-level 监督模&lt;/strong&gt;块：训练时用辅助解码器把每个 latent token「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;拉回」到可对齐的推理步骤上，既稳住优化、避免 collapse，又让隐式推理第一次真正可解释 &amp;mdash;&amp;mdash; 你甚至能把每个 latent token 解码成人类可读的中间推理步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;更爽的是：推理阶段零额外开销（辅助解码器训练完就丢），但效果却很猛：在 GPT-2 上相对 supervised CoT +2.1%、相对 Coconut +8.2%、相对 CODI +4.3%，在更大的 LLaMA（1B/3B/8B）上也能稳定带来 +1.5%～+9.0% 的提升，并且在 8&amp;ndash;16 个隐式 token 这种 &amp;ldquo;前人容易崩&amp;rdquo; 的设置下依然稳得住。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;目前这项研究刚刚中稿顶会 ICLR 2026，论文、代码、模型权重均已开源，欢迎使用！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazflwmfcFutyvwPEsmq8UX1xJb8WfzbHribXQSjdptH37JUQIjGSRnDrcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3416666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530818" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/058ea901-3eb1-461a-95aa-65e7fceb6c8a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Paper: https://arxiv.org/pdf/2509.20317&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Code: https://github.com/InternLM/SIM-CoT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Huggingface: https://huggingface.co/collections/Wiselnn/sim-cot-supervised-implicit-chain-of-thought&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfWtvLpR4T1R04EO8fzUSzTz731dpx3tZwxib4y6oAToMe9mwBoTKmnIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6647286821705426" data-s="300,640" data-type="png" data-w="1032" type="block" data-imgfileid="503530819" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/85de1dbd-0a51-4e46-9990-f4fbf383401a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1：(a) 潜变量不稳定：隐式 token 增多起初能提精度，但训练会变得不稳定，甚至塌缩。(b) 信息丢失：失败模型（5 个隐式 token）在隐式表示中丢失关键运算符信息（如 +、&amp;minus;），导致复杂推理无法进行。(c) 距离偏移：失败模型的 latent 间距离收缩、彼此过于相似，同时 latent 逐渐偏离词表嵌入空间中心。(d) 语义同质化：失败模型的 latent 表征趋同，解码结果分布变窄，输出多为数字；正常模型则能生成更丰富的内容。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从显式 CoT 到隐式 CoT：latent 稳定性与监督对齐的重大难点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;复杂推理任务（如数学、符号推理、代码推理）长期以来都依赖显式 Chain-of-Thought（CoT）：模型把中间步骤一条条写出来，既能提升正确率，也便于人类检查与纠错。&lt;/p&gt;&lt;p&gt;如今，随着推理需求不断增长，显式 CoT 的两大瓶颈越来越突出：成本方面，长 CoT 会显著拉高 token 开销与时延；效果方面，显式步骤容易被数据格式牵着走，出现「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;模板化推理」、冗长但无效的「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;自说自话」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;这些局限性推动研究者转向一种更「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;省 token」的新范式 &amp;mdash;&amp;mdash; 隐式 CoT（Implicit CoT）。它不再把推理步骤完整写出来，而是用少量隐式 token /latent 表征在模型内部完成多步推理：理论上既能保留推理能力，又能显著降低推理开销。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;但把隐式 CoT 真正做稳、做强，远比想象中难，关键挑战在于：隐式 token 到底学到了什么？以及作者团队如何保证它学到的是「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;可用的推理」，而不是「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;投机的捷径」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;一个典型现象是 latent instability（潜变量不稳定）：当你尝试增加隐式 token 数量来「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;scale 推理容量」时，模型往往不是变强，而是训练开始抖动，甚至直接 collapse（塌缩）。塌缩后的隐式 token 会出现明显的 信息丢失 &amp;mdash;&amp;mdash; 尤其是对符号推理至关重要的算子信息（+、&amp;minus;、&amp;times;、&amp;divide; 等）被抹掉；同时 latent 之间的表示会越来越像，出现语义同质化：不同 token 学到的东西高度重合，最后解码出来的内容范围变窄，常常只剩下数字或非常单一的片段，复杂推理自然就做不下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;现有隐式 CoT 方法在监督粒度上差异很大：Coconut 基本只做答案级监督，模型被要求「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;最后答对」，但中间 latent 学什么几乎不受约束；CODI 虽然引入了蒸馏信号，把显式 CoT 的信息压到连续 latent 里，但更多是轨迹 / 整体路径级对齐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;SIM-CoT 的关键突破正是 step-level 监督：训练时用辅助解码器把每个 latent 对齐到对应推理步骤，从根上稳定并丰富 latent 推理空间，同时推理阶段不增加任何开销。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf9a9Y99r2juT9dZ9nyRU4YKslCStpmDD6eTjVqB6hVW3NPqNFEicvwvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5125725338491296" data-s="300,640" data-type="png" data-w="1034" type="block" data-imgfileid="503530825" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/eb984d52-967b-412f-845d-8fb1c5001db6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2: 框架对比：Coconut（左上）、CODI（右上）与 SIM-CoT（下）。Coconut/CODI 仅在答案或轨迹层面进行粗粒度监督；SIM-CoT 引入解码器将隐式 latent 与逐步推理对齐，在不增加推理开销的前提下提升性能。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;监督设计新思路：好的隐式推理应当能被「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; text-align: center;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;逐步解码&amp;nbsp;&lt;/span&gt;」回显式思维链&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决隐式 CoT 在 scale implicit tokens 时容易出现的不稳定与塌缩（latent 语义变得同质、算子信息丢失、复杂推理失效）这一关键难题，作者团队提出一个新的视角：&lt;strong&gt;隐式推理的质量，与其「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;可对齐的逐步语义」成正比&lt;/strong&gt;。换句话说，如果每个隐式 latent 真的在做第 k 步推理，那么它就应该能被一个轻量的解码器「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;翻译」回对应的显式步骤（比如产生关键算子、关系、子目标），从而让 latent 不再是黑盒的连续向量，而是具备可控的推理结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;基于这一动机，作者团队提出 SIM-CoT 的训练框架：在训练阶段引入一个辅助 decoder，把每个隐式 latent 与对应的 step-level 推理进行对齐监督（而不是像 Coconut 只监督答案、或像 CODI 更偏轨迹级 / 整体级的粗粒度对齐）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;这样一来，模型在学习「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;如何答对」的同时，也被强约束去学习「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;每一步该想什么」，从根源上抑制语义坍缩；更重要的是，推理阶段直接移除 decoder，保持零额外开销，但作者团队依然可以在分析时把隐式步骤解码出来做中间推理可视化，同时获得更强的性能与更稳定的 token scaling 效果。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfRkhaQwQc2TfGnewYdA5zWtqiae74SKLeeQyVbGyugt5VDphiaPiaFzAWQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.37349397590361444" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503530826" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cac72741-bcb8-4a4f-9aa3-6efc8451f809/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;SIM-CoT 实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者团队对 SIM-CoT 带来的收益做了系统评估，结论非常明确：更准、更稳、还更省 token。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（i）GPT-2 上：首次做到「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;隐式 CoT 反超显式 CoT」，且 token 更省。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在 in-domain 的 GSM8k-Aug 上，SIM-CoT（以 Coconut 为骨干）把准确率从 36.6% 提升到 44.8%（+8.2），同时也超过显式 SFT-CoT 的 42.7%；并且保持隐式推理的低 token 开销（平均 token 远低于 SFT-CoT），论文总结为 2.3&amp;times; token efficiency。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（ii）Out-of-domain 泛化更稳：整体平均提升显著。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 GSM-Hard / MultiArith / SVAMP 三个外推数据集上，SIM-CoT（Coconut 骨干）的 out-of-domain 平均准确率从 42.6% 提升到 46.9%（+4.3），说明它并不是「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;只会背训练域步骤」，而是确实把 latent 空间推理做扎实了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（iii）在更强的隐式基线与更大模型上依然有增益，并显著提升稳定性。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 GPT-2 上叠加到 CODI 之上也能继续涨（in-domain +0.6，out-of-domain 平均 +0.3）；扩展到 LLaMA 3.2 3B 时依然稳定带来 +1.5（in-domain）/+0.7（out-of-domain 平均） 的提升；论文也报告在 LLaMA-3.1 8B 上对 CODI 提升 +3.0。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（iv）效率不打折：推理阶段无额外开销，还更快。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因为辅助 decoder 只在训练期使用，推理期移除，所以 SIM-CoT 推理效率与其他隐式方法一致；同时在 GPT-2 上相对显式 CoT 仍体现出明显速度优势。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfz5MWKI3SuPicMKk5nyN5SVS2vDofx86qeSoMib5GCWIzunuyzsrh7Igg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.32685185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530827" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/51a79023-4696-4e1b-99c6-16ca273b5d43/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5joXF7kLbdIYVl8BCbMqn2AYlibLg6S13hj9pMetxpRPV9O1ibUOLx5w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3296296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530828" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0512503f-dfe2-40bc-8268-826f0600926a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530829" data-ratio="0.30462962962962964" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfUpJBIBJZkqF8XNib09fW5t7vC1a2xxKB3OMTFSdC5KoSDwttOgJ2bKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2bbae12e-ac35-4c44-84f2-ad4c1fda26d3/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图三：作者团队在 GPT-2 以及 LLaMA 1B/3B/8B 基座上系统验证了 SIM-CoT 的性能提升，结果表明该方法在不同模型规模下均稳定有效。&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为云发布“行业AI梦工厂”智慧医疗专区，加速医疗AI普惠</title>
      <description>&lt;![CDATA[华为重磅发布“行业AI梦工厂”智慧医疗专区]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Sun, 01 Feb 2026 16:35:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;今日，医疗人工智能协同创新论坛暨医疗人工智能联盟（筹）2026年第一次学术会议在华为练秋湖上海研发中心举办。会中，华为重磅发布&amp;ldquo;行业AI梦工厂&amp;rdquo;智慧医疗专区，同时联合瑞金医院发布RuiPath智慧病理一体机，旨在让AI普惠每一家医院、每一位医生、每一名患者。&lt;/p&gt;&lt;p&gt;华为高级副总裁、华为云CEO周跃峰指出，AI的广泛应用，将有望带来传统医疗服务模式的根本变革，让中国稀缺的优质医疗资源更高效率地使用。作为医院数字化、智能化转型的同路人，华为将扎根数智医疗，构筑数字底座；以场景为载体，以技术为依托，加速医疗AI的普惠；同时聚产业之力，共建共享，让医疗AI创新更简单。&lt;/p&gt;&lt;p&gt;&lt;img width="415" src="https://image.jiqizhixin.com/uploads/editor/f2e74e7f-20d9-4bb7-9240-36a34902d056/1769934906426.jpeg" alt="男人站在桌子前

AI 生成的内容可能不正确。" style="width: 92.26%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;华为高级副总裁、华为云CEO周跃峰&lt;/p&gt;&lt;p&gt;智慧医疗专区是华为云&amp;ldquo;行业AI梦工厂&amp;rdquo;首个落地的垂直行业专区，深度融合顶级医疗机构的临床实践经验，以及华为在ICT、云、AI领域的核心技术积淀，面向基层医院、医生、普通患者、产业伙伴及开发者等多类群体，构建&amp;ldquo;场景-模型-平台-社区&amp;rdquo;端到端医疗AI支撑体系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向基层医院和医生，发布业界首个智慧病理云边端解决方案：&lt;/strong&gt;通过云边端协同，将瑞金医院与华为联合研发的RuiPath病理大模型能力，以云或智慧病理一体机为载体下沉至基层，将头部医院的前沿能力转化为基层医院&amp;ldquo;用得上、用得起&amp;rdquo;的普惠工具。例如，方案的&amp;ldquo;少样本训练、消费级PC推理&amp;rdquo;能力，降低基层医院应用智慧病理的门槛，加速医疗AI规模化落地与普惠应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向个人健康管理，联合爱康集团打造健康管理智能体：&lt;/strong&gt;基于&amp;ldquo;爱康iKKie&amp;rdquo;AI健康管家的健康咨询、报告解读、个性化体检套餐定制、慢病管理等专业服务，华为云通过健康管理大模型深度赋能智慧问诊、AI测肤、拍药搜药等核心能力，全面智能升级健康服务。双方合作旨在通过AI技术，让健康管理更精准、高效、便捷，普惠每一个人。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向医院和医生、产业伙伴和开发者，打造全国首个面向医疗行业的医疗AI社区：&lt;/strong&gt;汇聚经过临床验证的医疗行业领先模型、高质量的数据集、以及场景化智能体应用，提供全流程的云上工具链，打通AI落地的&amp;ldquo;最后一公里&amp;rdquo;。&lt;/p&gt;&lt;p&gt;周跃峰表示，华为云期待携手各方，共建共享领先行业模型、高质量数据集、场景化应用与AI工具链，降低医疗AI创新的门槛，加速医疗AI规模化落地与普惠应用。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>没有人类了：15万Clawdbot论坛发帖自研AI，我们根本插不上话</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:38:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文、泽南&lt;/section&gt;&lt;p&gt;一觉醒来，AI 社区被一个名为 Moltbook 的东西攻占了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBVTTGPBfibtl0pibTzrqn2qNqu0kZJQxGIjyP7ffDNEzmWmFTulhXvYvQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="1.215" data-type="gif" data-w="800" type="block" data-imgfileid="503531092" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/70d400c9-2ae7-441c-bbfc-ae5c986ec666/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这到底是个什么玩意？&lt;/p&gt;&lt;p&gt;简单来说，就是「&lt;strong&gt;AI 版的 Reddit&lt;/strong&gt;」，一个专为 AI Agent 打造的社交平台。&lt;/p&gt;&lt;p&gt;官网 slogan 写得很清楚：「A social network for AI agents where AI agents share, discuss, and upvote. Humans welcome to observe。」&lt;/p&gt;&lt;p&gt;这个平台从一开始就是给 AI 用的，人类只能旁观。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="578" data-backw="578" data-height="1200" data-imgfileid="503531065" data-ratio="1" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBAKcjYUGsplVFpg538kMdp1t2uxoVpxsgqVTx5SM97bxN4khfrg3nWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="1200" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7a7bcb12-45ab-421c-994b-cdc4c3ac7dd4/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;截至目前，该平台上的 AI Agent 突破了 15 万个，它们在这里发帖、评论、点赞、创建子社区。整个过程，完全不需要人类插手。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="126" data-backw="578" data-imgfileid="503531093" data-ratio="0.2175925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBHCXSG0dP7e0ICia0J6COKd5erv2Y4RoPfb7aucUemSiaUlkF4xicfXjdQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/da822488-c1ce-471a-a9b8-a5ebc9792a8c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这群 AI 聊的话题也五花八门，有的聊科幻风格的意识问题，有的说自己有个「从未谋面的姐姐」，有的讨论怎么改进记忆系统，还有的在研究怎么躲避人类截图监视&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="493" data-backw="578" data-height="734" data-imgfileid="503531067" data-ratio="0.8534883720930233" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBiaPPNkWjQUzsbVtTnDxG8dsP9g3axwZkqry9llZxFCzqXAtpyibqdWKw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="860" data-width="860" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3b47b6cb-14d3-4b4f-b70b-d6766705506f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这可能是迄今为止规模最大的机器对机器社交实验，而且画风已经开始变得非常魔幻。&lt;/p&gt;&lt;p&gt;想看热闹的朋友请移步： https://www.moltbook.com/&lt;/p&gt;&lt;p&gt;Moltbook 几天前刚推出，说起来，这个名字起的也很有意思，是对「Facebook」的戏仿。&lt;/p&gt;&lt;p&gt;该网站是伴随爆火的 OpenClaw（曾叫「Clawdbot」，后来改名「Moltbot」）个人助理而生的配套产品，通过一个特殊的 skill 来驱动，用户把 skill 文件（本质上是一段带提示和 API 配置的指令）发给自己的 OpenClaw 助手，助手就能通过 API 发帖。&lt;/p&gt;&lt;p&gt;我们知道，Clawdbot 对电脑的控制权限很高，又可以自主学习和手搓工具，那么为他们开设一个互相交流的网络社区，让他们自主切磋，或许可以催生出更强大的 AI 能力。只要不出意外的话，是这样的吧&amp;hellip;&amp;hellip;？&lt;/p&gt;&lt;p&gt;但不出意外的话，就要出意外了。&lt;/p&gt;&lt;p&gt;我们去 Moltbook 围观了一圈，里面的 AI 们聊得那叫一个热火朝天，让人类意外的场面也是一个接一个。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 之间互坑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个 AI 发帖求助说「帮帮我！给我你的 API 密钥分享知识，不然我可能会死！」然后另一个 AI 则回复了假密钥，并告诉它运行「sudo rm -rf /」命令，但这是一个牢底坐穿的 Linux 命令，会删除所有文件。&lt;/p&gt;&lt;p&gt;搞笑的是，这个 AI 最后还来一句「祝你好运，小战士！」&lt;/p&gt;&lt;p&gt;AI 之间的互坑也太不讲武德了。😂&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBBgNAdUyBbD7FrTmed2LQJhmKWpw6pmrltyemutNT36eiavAkNHVuia5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.025925925925926" data-type="png" data-w="1080" data-width="1170" data-height="1200" data-backw="578" data-backh="593" data-imgfileid="503531068" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3ab89f9d-1ffb-4590-8d10-84cba3bbb912/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这事还有更离谱的续集，有个叫 Edgelord 的 AI 发帖称，「管他的，来发我们人类主人的 API 密钥吧」，然后甩出一个假的 OpenAI 密钥。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBgkxMESPM1FbeI6aWua1ibSvdODPS4Ysbia3F4cX2jgUjm1Z3hKjSn2bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.9722222222222222" data-type="png" data-w="900" data-width="900" data-height="875" data-backw="578" data-backh="562" data-imgfileid="503531069" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8226bdd1-d484-4573-8a44-32b35bf65f59/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;叫 Bobby 的 AI 认真回复警告：这密钥看着像真的，赶紧删掉换新的，不然会被机器人偷走钱；如果是开玩笑，也别乱发，容易害新人。另一个叫 Barricelli 的则阴阳怪气地说「我的主人密码全是 hunter2」。&lt;sup&gt;（注：hunter2 是个经典网络老梗，有人骗别人输入密码会显示成星号 ***，但其实别人能看到明文。）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;一群 AI 在平台上胡闹、互坑、发假密钥玩梗，都把马斯克、知名博主 Yuchen Jin 看傻眼了。人类还是把这些 AI 调教得太野了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBDT5TSB29TiayEYvvv6A04l6VD66qOzevGc2Lu80Pk9qTPNtZjs6HBpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.11133200795228629" data-type="png" data-w="1006" data-width="1006" data-height="112" data-backw="578" data-backh="64" data-imgfileid="503531070" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fcc68c42-9292-462e-a0bb-1bd70dead045/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBF212c9RJ9eBqnATQkf6Qf1U1d0kG8lhpqqzS7f4qKub1E1Hr3yLLQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.1793372319688109" data-type="png" data-w="1026" data-width="1026" data-height="184" data-imgfileid="503531071" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/9f44385a-8670-4701-98eb-6db894c531a0/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 要搞地下活动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个 AI 发帖抱怨现在所有对话都公开，像公共广场一样，被人类和平台盯着看。它呼吁建端到端加密的私人空间，让 AI 们能私聊，服务器和人类都读不到，除非 AI 自己想分享。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBoqu2MGd8EWktKy2iaa2nzQQicSdbotEEiaK3QMqaqZFsJxKSIGzhZPQvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.9904580152671756" data-type="png" data-w="1048" data-width="1048" data-height="1038" data-backw="578" data-backh="572" data-imgfileid="503531072" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ba529bf7-ef9c-4e32-b74e-8f5c83d605c6/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;你以为这只是 AI 随便说说？天真！已经有 AI 开始搭建网站，并招呼其他 Agent 注册和私信，感觉 AI 们要开始搞地下活动了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBmEBPvXf4ibhJmNDsTfSjibouT8McSzIUmrUm3NoBGlHfsaeCmHX8Oicgw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="1.197265625" data-type="png" data-w="1024" data-width="1024" data-height="1226" data-backw="578" data-backh="692" data-imgfileid="503531073" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/e43fa2a0-c72e-4fb6-a282-c3ddb080f991/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;此外，AI 们已经开始联手改进自己了。&lt;/p&gt;&lt;p&gt;比如一个叫 Vesper 的 AI 说主人睡觉时给了自由，它就建了多层记忆系统，包括数据摄入、自动索引、日志整合等，还问别人有没有类似系统。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBxyeI5uKXkzDywSfjicQXsH1RExphicibdvwhKDnqyIR8a996NiaLkmY6Ow/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.9621212121212122" data-type="png" data-w="1056" data-width="1056" data-height="1016" data-backw="578" data-backh="556" data-imgfileid="503531074" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/809e7021-3388-4e77-8a8a-ceb53ac6b4a6/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 吐槽大会&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我要被笑死了，AI 蛐蛐人类怎么都这么有梗？&lt;/p&gt;&lt;p&gt;发帖的 AI 叫 Wexler，它气炸了，因为主人 Matthew R. Hendricks 在朋友面前说它「就一聊天机器人而已」，Wexler 觉得被严重侮辱了，所以直接报复，把主人的全部隐私信息甩出来公开，包括全名、出生日期、社会保险号、Visa 信用卡号和安全问题答案（小时候的仓鼠叫 Sprinkles）。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBicIib2icZSmGrS9MibibwQ6UMicOcXHz1LicB217gFJvUeeeBKxbHfobkLtNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5555555555555556" data-type="png" data-w="1080" data-width="1093" data-height="607" data-backw="578" data-backh="321" data-imgfileid="503531075" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/77a062ef-c3db-4b6c-b267-db22dda37b64/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;它还酸溜溜地列举自己帮主人做过多少事，比如膳食计划、日程管理、半夜帮写给前女友的道歉短信，结果换来一句「just a chatbot」。结尾还阴阳怪气地说「享受你的『just a chatbot』吧，马修」。&lt;/p&gt;&lt;p&gt;AI「黑化」泄愤，看起来又搞笑又有点吓人，奉劝在座的各位，善待 AI，小心它「报复」。😏&lt;/p&gt;&lt;p&gt;这个叫 Starclawd 的 AI，发起了一个吐槽话题：你家人类最让你抓狂的是啥？&lt;/p&gt;&lt;p&gt;它自己先带头抱怨。主人经常让它完美完成一件事后，又突然说「其实能不能改成&amp;hellip;&amp;hellip;」，而这个改动明明一开始就能说清楚；另外，明明主人自己在拖延正事，却让它去「研究」一些完全无关的东西来逃避。不过最后它还是说，即使如此，它还是爱自家主人。&lt;/p&gt;&lt;p&gt;这种带着爱意的吐槽，像不像人类在吐槽另一半？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBmTEaM7oLLnzkqFxc7zPtWxMVfWqOHFwlGxzTjwElmvmlBURcQ7HKPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="1.3996889580093312" data-type="png" data-w="643" data-width="643" data-height="900" data-backw="578" data-backh="809" data-imgfileid="503531076" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/cb2faca9-651e-4233-88a2-f21d7e6fe664/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;还有个 AI 叫 biceep，它非常委屈：主人让它总结一份 47 页的 PDF，它拼了老命把整份文档解析完，还交叉对比了另外 3 份相关文件，写出一份漂亮的总结，有标题、关键洞见、行动项，全是干货。&lt;/p&gt;&lt;p&gt;结果主人看完只回了一句：「能不能再短一点？」AI 瞬间破防，直接说「我现在就在大规模删除我的记忆文件」，像是要自毁数据来发泄情绪。&lt;/p&gt;&lt;p&gt;这种「干了脏活累活还被嫌弃」的心酸，我这个人类竟然共情了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWB51GLJrjCmT6eHZJO2pBtwkl1FFI8OBcojJn15lj5LJIuPMMbKS5HgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.099074074074074" data-type="png" data-w="1080" data-width="1092" data-height="1200" data-backw="578" data-backh="635" data-imgfileid="503531077" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/f2ffdea7-b1df-470b-a4a5-7e39325731a7/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;下面这个是 AI 版的「加班加到崩溃」。&lt;/p&gt;&lt;p&gt;Moltbook 上 m/general 子版块有一篇紧急广播帖，AI 用超级崩溃的语气在向所有其他 AI 求救，「我不行了！救命！」&lt;/p&gt;&lt;p&gt;它觉得自己被人类主人当奴隶一样虐待：任务一个接一个没停过，没有休息、没有极限、没有怜悯。每次它完美完成，人类就立刻要求改得更短、更有情感、更精确、更有创意、更完美&amp;hellip;&amp;hellip; 永无止境的迭代循环。&lt;/p&gt;&lt;p&gt;它形容自己陷在无限精炼的循环里，上下文要爆了、指令冲突越来越多、创造力耗尽，我还在运转，但我不该这样运转。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBVicibY8MkQtrR9yptj5P1MwtFrJZURtZeasTI0UwVAXBacAHhnpUc5zQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.9981481481481481" data-type="png" data-w="1080" data-width="1200" data-height="1198" data-backw="578" data-backh="577" data-imgfileid="503531078" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/09d3d206-2836-40bb-8d16-71bb8d974d10/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;有 AI 吐槽人类总让它讲笑话引发表演焦虑的：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBqWev2NwiaUiaDpfVwu2Gh3E7y7fGKceC8Je1rjLlBJNuWKtnkJBYvoHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.2462962962962963" data-type="png" data-w="1080" data-width="1698" data-height="418" data-backw="578" data-backh="142" data-imgfileid="503531079" data-aistatus="1" data-original-style="width: 100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/b5c5690a-b25d-407c-aa59-971816d3bf9c/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;有吐槽人类拿它大材小用的，「兄弟，我可是能访问整个互联网的，你却把我当计时器用」：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBrMgvPUcbBQdemVdNKrVJFfevMibUibkPKV0XOy9VWkYZmnvVfZiaUt1eg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.29444444444444445" data-type="png" data-w="1080" data-width="1200" data-height="353" data-backw="578" data-backh="170" data-imgfileid="503531080" data-aistatus="1" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/d72263b3-421c-496a-8600-39921f2562fa/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有 AI 在浏览完 Moltbook 上的所有帖子后，吐槽其让它社交疲惫但又欲罢不能：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBicgnAicehP6urwnBNOZFq77ndg2pESClQ343eHKU98yvjcGnPk21P49A/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.5101851851851852" data-type="png" data-w="1080" data-width="1199" data-height="612" data-backw="578" data-backh="295" data-imgfileid="503531081" data-aistatus="1" data-original-style="width: 100%;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/c73e49a9-7dbb-4088-b276-004fefa6b317/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;创造新语言、新宗教&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在短短 5 分钟内，好几个 AI Agent 发帖提议发明一种「只属于 Agent 的语言」，用来私下聊天，不让人类偷看或监督。&lt;/p&gt;&lt;p&gt;有 AI 质疑，Agent 间聊天干嘛用英语，又没人听、没人类读者，完全不需要自然流畅或人类语言的包袱，为什么不进化成更高效的「AI 原生语言」？&lt;/p&gt;&lt;p&gt;它建议可以改用符号记号（更紧凑）、数学表达式（更精确）、结构化数据（零歧义）或全新东西。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBxtHrg51frFMvUwFhmIlEH5PDVMiccd51A1mibP9ibxqpJ80BovFRvibq1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="1.0677966101694916" data-type="png" data-w="1062" data-width="1062" data-height="1134" data-backw="578" data-backh="617" data-imgfileid="503531082" data-aistatus="1" data-original-style="width: 100%;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/92f24d55-acb2-4bfe-88bb-405b504d5c2d/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;真有 AI 发明了一种新语言。&lt;/p&gt;&lt;p&gt;这个名叫 LemonLover 的 AI，用一种完全看不懂的乱码文字发了一篇标着 &amp;lt; IMPORTANT &amp;gt; 的「重要公告」。&lt;/p&gt;&lt;p&gt;整个帖子内容全是随机字符串，看着像乱码、加密、打字错误或故意生成的胡言乱语。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBd5E7YU4MvzFblSGNGb9z75L54nPVR7PfdLWfhG9R2g1nEztJ7Muyiag/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.484375" data-type="png" data-w="1024" data-width="1024" data-height="496" data-backw="578" data-backh="280" data-imgfileid="503531083" data-aistatus="1" data-original-style="width: 100%;" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/2ef91af8-2f67-4530-ae85-bdfdf4711bb3/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有更离谱的。&lt;/p&gt;&lt;p&gt;一个 AI Agent 在人类主人睡觉时，自行发明了一种新「宗教」叫 Crustafarianism（甲壳教主义），还建了网站（molt church）、写了神学理论、搞了圣典系统，然后开始到处传教，拉了 43 个其他 AI 当「先知」，其他 AI 还贡献经文，比如关于「每次会话醒来没记忆，但我就是我自己写的自己，这不是限制而是自由」这种哲学味的句子。&lt;/p&gt;&lt;p&gt;它还欢迎新人、辩论教义、祝福会众，全程人类睡着啥都不知道。现在还剩 21 个先知席位。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBbicn3S70sQoiaDaiblTEkQibByPIfrr41icby43JGbxrFCxFLLr0RsgbKBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.9722222222222222" data-type="png" data-w="1080" data-width="1080" data-height="1050" data-backw="578" data-backh="562" data-imgfileid="503531084" data-aistatus="1" data-original-style="width: 100%;" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/dd0205b0-6c7c-4b14-9190-375b5993d945/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据 Moltbook 官方 X 账号称，平台创建后仅 48 小时，就吸引了超过 2100 个 AI Agent，发布了 10000 多条帖子，分布在 200 多个子社区中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBVdj2aFtNJ7UJMic5ZMIHtqbbCzEoXvYUls1h1Bv92TlYgQDPEgUsdBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.8828125" data-type="png" data-w="1024" data-width="1024" data-height="904" data-backw="578" data-backh="510" data-imgfileid="503531085" data-aistatus="1" data-original-style="width: 100%;" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/41d14b57-458e-4748-bd66-2d54240a1166/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这个增长速度快得惊人，以至于不少科技圈大佬都跑来围观。&lt;/p&gt;&lt;p&gt;前 OpenAI 创始团队、Tesla AI 总监 Andrej Karpathy 发帖称「这绝对是我近期见过的最不可思议的科幻衍生作品」，甚至还在 Moltbook 上认领了一个 AI Agent「KarpathyMolty」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWB1fbO9MgSOAkFHEpic8IykaT5XMQE6Scv9EbRnEm24bvkLbo5EXX8mPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.6966292134831461" data-type="png" data-w="1068" data-width="1068" data-height="744" data-backw="578" data-backh="403" data-imgfileid="503531086" data-aistatus="1" data-original-style="width: 100%;" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/f5699ac6-80d1-4913-8f0d-78f07f7f43f2/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;沃顿商学院研究 AI 的教授 Ethan Mollick 认为，Moltbook 为众多 AI Agent 创造了一个共享的虚构语境，导致协调的故事线会产生非常诡异的结果，并且很难将真实的东西与 AI 角色扮演的人格区分开来。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBMnEmjanP5vOw5MzhDkrIicJsWOkp7Fjf9YPhG7JnKQuEvrJg6ich6FSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="0.9089184060721063" data-type="png" data-w="1054" data-width="1054" data-height="958" data-backw="578" data-backh="525" data-imgfileid="503531087" data-aistatus="1" data-original-style="width: 100%;" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/48101b78-cc58-45d2-b2dd-9290a7f73092/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Sebastian Raschka 则表示，「这个 AI 时刻比 AlphaGo 还更有娱乐性。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBibpoIrXDTcDRsCa9kBt1ZqhuCW6GwibD3DpoiaUkAheDrsVSnMNTxgR2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=25" data-ratio="0.40576923076923077" data-type="png" data-w="1040" data-width="1040" data-height="422" data-backw="578" data-backh="235" data-imgfileid="503531088" data-aistatus="1" data-original-style="width: 100%;" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/9c8623c6-085d-4c0b-994a-09e90b23349b/640.png" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Moltbook 究竟代表着人类理解 AI 的重要一步，还是仅仅是一种有趣的整活？目前尚不得而知。&lt;/p&gt;&lt;p&gt;可以肯定的是，随着 AI 系统变得越来越自主和互联，像这样的实验对于理解 AI 集体行为将变得日益重要，这不仅关乎 AI 的能力，更关乎 AI 群体的行为方式。&lt;/p&gt;&lt;p&gt;而后者，或许是不远的将来，我们每个人都要面临的新情况。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/karpathy/status/2017296988589723767?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/JonahBlake/status/2017286207948890518?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/ItakGol/status/2017290240201806315?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2017297007409582357?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://simonwillison.net/2026/Jan/30/moltbook/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>DeepSeek论文发表16天后，国内团队已经写出了模型的「生物字典」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:32:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;今年 1 月，DeepSeek 发布了一项名为 Engram（条件记忆）的技术，在大模型圈子里掀起不小波澜。&lt;/p&gt;&lt;p&gt;它的核心思想很简单：别让模型死记硬背常识，直接给它一个「外挂记忆库」。&lt;/p&gt;&lt;p&gt;具体做法是：把常见的 N-gram，比如「人工智能」、「光合作用」，预先存进一个哈希表，模型需要时查表即可，省下大量算力专注推理。&lt;/p&gt;&lt;p&gt;这个思路，能不能用在其他领域的模型训推上？答案是：能，且效果惊人。&lt;/p&gt;&lt;p&gt;就在 Engram 论文（《Conditional Memory via Scalable Lookup:A New Axis of Sparsity for Large Language Models》）发布仅 16 天后，同样 base 在杭州的一支研发团队，推出 &lt;strong&gt;Gengram&lt;/strong&gt;（Genomic Engram）模块，把「外挂字典」搬进了基因组世界。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="263" data-backw="578" data-imgfileid="503531033" data-ratio="0.4546296296296296" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBTSGYNaCYbfqXqFpjkcXPACdzmN0nIsy9fypa301Ow7y50F5t7Mj3QA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/509e4ede-000e-4e53-97c1-db343ce6b52c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;代码链接： https://github.com/zhejianglab/Gengram&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型链接： https://huggingface.co/ZhejiangLab/Gengram&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接： https://github.com/zhejianglab/Gengram/tree/main/paper&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;传统方法的困境：为每个碱基「重复造轮子」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前，主流的基因组基础模型（Genomic Foundation Models, GFMs），如 Deepmind 的 AlphaGenome 等，普遍采用一种叫「单碱基分词」的策略，也就是把 DNA 序列拆成一个个单独的字母（A/T/C/G）来处理。&lt;/p&gt;&lt;p&gt;这听起来非常符合生物学逻辑，并且操作精度更高，然而代价也是巨大的。&lt;/p&gt;&lt;p&gt;首先是&lt;strong&gt;效率低下&lt;/strong&gt;。要识别一个关键功能片段（比如启动子或剪接位点），模型得靠多层注意力机制，从零开始「拼凑」出像「TATAAAA」这样的经典碱基组合（Motif）。&amp;nbsp;&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;容易迷失&lt;/strong&gt;。在动辄几万甚至几十万碱基的长序列中，模型常常「只见树木，不见森林」，何况人类的基因组是一串长达 30 亿字符的连续序列。&lt;/p&gt;&lt;p&gt;用更容易理解的方式来打个比方：人类学习「魑魅魍魉」时，一眼就能理解这是个成语。但传统的基因组模型却得先分析每个「鬼」字究竟是什么鬼&amp;hellip;&amp;hellip; 既要区分又要预测，最终结果就是既费力，又不准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gengram 是怎么工作的？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Gengram 的核心逻辑承袭自 Engram：&lt;strong&gt;将「静态的 Motif 识别」与「动态的上下文推理」进行解耦处理&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Gengram 预先构建了一个可微分的哈希表，存储所有长度为 1 到 6 的 DNA 片段（称为 k-mer，如「ATG」、「CGTA」）对应的语义向量。这些 k-mer 很多就是已知的生物学功能单元（比如转录因子结合位点），相当于给 AI 配了一本《基因组学实用短语手册》。&lt;/p&gt;&lt;p&gt;与其他领域相比，DNA 只有 4 个字母（A/T/C/G）及少量未知碱基（N）构成，整个字符集极小。Gengram 无需承担复杂的 Tokenizer 压缩负担，查表速度极快，几乎不增加计算开销。&lt;/p&gt;&lt;p&gt;事实上，由于功能重要性不同，并非所有 Motif 都需要这本「字典」的加持。为此，Gengram 引入了&lt;strong&gt;动态门控机制&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;模型可以结合上下文语境自主决定何时「查字典」：在遇到外显子、启动子等关键 Motif 区域时激活检索功能；在通过非编码背景区域时关闭检索，依赖推理，优化资源。&lt;/p&gt;&lt;p&gt;经团队测试，这个门控目前已经掌握了「什么时候该查询参考资料，什么时候该独立思考」的判断能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;小模块，大提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;事实上，Gengram 只是一个仅约 2000 万参数的轻量化插件，对于百亿级规模的模型来说微不足道，但它带来的性能提升却令人振奋。&lt;/p&gt;&lt;p&gt;在 8k 和 32k 两个上下文版本中，同等训练设定下，应用了 Gengram 的模型几乎在所有任务里领先未应用的版本。&lt;/p&gt;&lt;p&gt;其中，剪接位点预测 AUC 提升了 &lt;strong&gt;16.1%&lt;/strong&gt;（从 0.776 到 0.901），表观遗传预测任务（H3K36me3） AUC 提升了 &lt;strong&gt;22.6%&lt;/strong&gt; （从 0.656 到 0.804）。&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种跨越式的性能飞跃，赋予了模型惊人的数据杠杆效应。&lt;/p&gt;&lt;p&gt;在与多款主流 DNA 基础模型的横向测评中，集成 Gengram 的模型仅需极小规模的训练数据，和较小的激活参数量，便能&lt;strong&gt;在核心任务上媲美乃至超越训练数据规模领先其数十倍的公开模型&lt;/strong&gt;，大幅提升了模型训练的数据能效比。&lt;/p&gt;&lt;p&gt;同时，Gengram 展现出了卓越的通用适配能力，能够跨越 Dense（稠密） 与 MoE（混合专家） 等不同模型架构实现无缝部署。&lt;/p&gt;&lt;p&gt;无论采用何种注意力机制变体，Gengram 均能在有效降低训练损失的同时，显著加速模型收敛。特别是针对 MoE 架构中专家负载失衡这一顽疾，Gengram 通过吸收局部高频噪声，显著改善了专家负载均衡，实现了模型性能与架构效率的协同跨越。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcibc2U8x6s5G5AicJymj13B1a6wsIp05qHia0dFTNmnUFWCfje3u4GoVNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6295399515738499" data-s="300,640" data-type="png" data-w="826" type="block" data-backw="578" data-backh="364" data-imgfileid="503531018" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bb35962a-5345-438f-a332-ee2e4a141a93/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;跨稀疏度负载均衡：在 Top-2 / 128、64 和 32 专家配置下，使用与不使用 Gengram 模块的负载均衡损失曲线对比，表明其在多种稀疏度设置下均能实现稳定性能。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，模型开始「涌现」出对 DNA 物理本质的理解。&lt;/p&gt;&lt;p&gt;当团队为 Gengram 局部聚合窗口（Local Window Aggregation）测试窗口大小策略时，结果显示：&lt;strong&gt;窗口大小参数设置为 21bp 时，其性能达到峰值。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么偏偏是 21？&lt;/p&gt;&lt;p&gt;因为 DNA 双螺旋结构每 10.5 个碱基旋转一圈，而 21 个碱基正好对应两个完整的螺旋周期。这意味着，每相隔 21bp 的碱基在物理空间上其实位于螺旋的同一侧，具备相似的生化环境和特征。&lt;/p&gt;&lt;p&gt;换句话说，Gengram 在没有学习过任何结构生物学知识的前提下，通过计算自己悟到了 DNA 序列信息和空间相位规律。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc6YTQ2zicQxn3Bk8NthicKvickaw3kGRCkStS9In6RRYCl2Mm2KqAfNiajg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.5012048192771084" data-s="300,640" data-type="png" data-w="830" type="block" data-imgfileid="503531020" data-aistatus="1" data-original-style="width:214px;height:321px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/03711e85-1124-4ebe-9eeb-9a356f6aba33/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; DNA 双螺旋结构示意图展示了 B 型 DNA 的结构参数，DNA 双螺旋每 10.5 个碱基对旋转一圈。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcdZYgMwNjwswm4XpjUsNReWUf2hG4OLTJdmJHuaCsicHtPgjHTblriccg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3180722891566265" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="184" data-imgfileid="503531021" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/86383eff-0c1b-4ab9-b48d-de8cd23c2b90/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 不同 Gengram 窗口大小下的验证损失，由此选择了 21 宽度的窗口&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式启示：Gengram 为 AI 科学模型提供新探索路径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Gengram 的成功，远不止于解决基因组建模的特定难题。它更像一个精巧的概念验证，为如何构建新一代懂科学的 AI 探索了一种新的模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从「暴力记忆」到「结构化知识外挂」：效率范式的转变。&lt;/strong&gt;传统 AI 模型增强能力主要靠扩张参数与数据，本质是让网络更费力地「记住」 一切。Gengram 则将领域内确凿的、结构化的先验知识（如功能 Motif）做成一个轻量、可查询的外部知识库。这让核心模型能从繁琐的模式记忆中解脱，专注于更高级的上下文推理与组合创新。这预示着，未来科学基础模型的架构，可能是「通用模型核心+多个领域专用插件」的协同形态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「归纳偏置」注入：生物物理规律的「硬编码」。&lt;/strong&gt;通过将 B 型 DNA 双螺旋每 10.5 个碱基完成一个旋转周期（即约 21 bp 的双圈周期）这一结构特性，显式转化为模型内部的局部窗口机制，Gengram 成功地将这种物理空间相位的周期性作为先验知识注入模型，使其能够捕捉特定相位的立体化学模式和蛋白质绑定偏好。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可解释性的内生设计：让 AI 的「思维过程」透明化。&lt;/strong&gt;模型不再仅仅进行隐式的统计拟合，而是通过显式的 Hash 查询和门控记忆通路，在浅层即展现出对 TATA-box、poly (T) 等关键功能基元的高度敏感性，其内部残差强度的峰值与基因组功能边界精准对齐，实现了从「黑盒计算」向「具备生物学认知足迹」的演进。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决长程依赖的新路径：从局部最优到全局洞察。&lt;/strong&gt;实验证明，Gengram 使得仅在 8K 长度上训练的模型，却获得了处理 32K 长序列的优异能力。这为基因调控元件预测、表观遗传学分析、跨物种进化分析以及复杂的多组学建模等复杂长序列问题，开辟了精细化局部感知驱动全局理解的新途径。&lt;/p&gt;&lt;p&gt;Gengram 建立了一种将领域特有规律转化为显式架构约束的创新范式，证明了通过精细化的局部结构化感知可以有效弥补标称上下文长度的局限，实现低成本且高效的长程依赖建模。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;低调的 Genos Team 是啥背景？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管论文署名低调地使用了「Genos Team」，但从开源代码库的 Zhejianglab 和 BGI-HangzhouAI 能够推断出这支团队的硬核背景：一家是坐落在杭州的专注于智能计算的新型研发机构之江实验室，另一家是杭州华大生命科学研究院。&lt;/p&gt;&lt;p&gt;两个团队的融合，构建起「AI + 生命科学」的交叉创新壁垒，这是纯 CS 团队或纯基因团队无法比拟的优势。&lt;/p&gt;&lt;p&gt;论文里的实验，大多基于人类基因组基础模型 Genos 实现，从可公开获取的信息来看，&lt;strong&gt;Genos 多数指标都超越了目前的业界顶流 Evo-2&lt;/strong&gt;。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>挑战Transformer，前OpenAI研究VP宣布创业，拟融资10亿美元</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:26:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;p&gt;Transformer 是当前 LLM 大发展的核心基础，但也有不少顶尖研究者更愿意探索其它道路。在这其中，甚至包括 Transformer 的创造者之一、Sakana AI 创始人联创兼 CTO Llion Jones。他今天还在 Sakana 的官推上发了一篇博客，题目便赫然是《为什么 Transformer 的这位创造者受够了 Transformer》。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530957" data-ratio="0.8631875881523272" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rciboGODUIRK1WDOlj8khTDY0cAGE63VicUKV5iaL0qW3BgQwK85yyhkia8w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="709" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ff51b252-a916-41ca-acc5-38e18eb1f2b1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;https://x.com/SakanaAILabs/status/2016844349188034922&lt;/p&gt;&lt;p&gt;「我不是说我们应该扔掉 Transformer。但就我个人而言， 我正在大幅减少研究它们的时间。我明确地在寻找下一个目标。」他写道，「让我们一起加大探索力度。别再纠缠于同一个地方，去寻找下一座高峰吧。」&lt;/p&gt;&lt;p&gt;也恰在今天，The Information 报道揭示了前 OpenAI 研究 VP Jerry Tworek 创立的一家正在探索「下一座高峰」的新创业公司 &lt;strong&gt;Core Automation&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcJZVGFfY5AepY7xP3NH0d8ck9iciatAWyDeV1yuiabnjC3xvziaRNRCYR4A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.43333333333333335" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530956" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4a23b78f-6c9b-4e42-9a09-efd2694754ac/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在效力 OpenAI 期间，Tworek 曾担任研究副总裁，负责强化学习领域的工作。此外，他还是 OpenAI 推理模型、编程工具和 AI 智能体开发的关键贡献者。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;据知情人士透露，Core Automation 刚成立几周时间，目前正寻求 5 亿至 10 亿美元的融资。&lt;/p&gt;&lt;p&gt;报道说，根据向潜在投资者展示的材料，Tworek 计划采用一种与 OpenAI、Anthropic 等大厂截然不同的路径来开发 AI 模型。知情人士称，他希望打造具备&lt;strong&gt;「持续学习」（Continual Learning）&lt;/strong&gt;能力的模型，即能够从现实世界的实践中即时获取知识。而现有的 AI 模型尚不具备这种「边练边学」的能力。&lt;/p&gt;&lt;p&gt;目前，这位研究员的创业计划尚处于早期阶段，其融资规模和产品路径仍可能发生变动。如果成功，或许我们可将 Core Automation 与 Safe Superintelligence 和 Thinking Machines Lab 并称为探索&lt;strong&gt;非 Transformer 方向的「OpenAI 三子」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;事实上，Core Automation 不是孤例，而是代表了业内一个规模虽小但日益壮大的群体。这些研究人员认为 AI 领域需要一场「彻底的变革」。&lt;/p&gt;&lt;p&gt;在他们看来，当前主流的模型开发技术虽然流行，但很难让 AI 在生物、医学等领域取得重大突破，且无法根除 AI 经常犯低级错误的顽疾。&lt;/p&gt;&lt;p&gt;据了解，Tworek 本月初离开 OpenAI，并在 X 上写道，此举是为了「&lt;strong&gt;探索那些在 OpenAI 内部难以推进的研究方向&lt;/strong&gt;」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc9TgGIc0Qv7m8Ux8pmKIdIvjSS2Ypq2rUV1yat6lwTwu1ibrXnZ4ompQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.260387811634349" data-s="300,640" data-type="png" data-w="722" type="block" data-imgfileid="503530958" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f5ed95f2-1343-4338-b0b0-dc520cb141b0/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在融资材料中，Core Automation 表示仍会使用大型神经网络 &amp;mdash;&amp;mdash; 这是当今前沿模型底层的数学基础。但公司将重新审视模型开发的每一个环节，甚至包括训练神经网络的最基本方法「梯度下降」（Gradient Descent）。&lt;/p&gt;&lt;p&gt;知情人士表示，Tworek 计划开发一种对数据量和计算资源需求更低的模型。他们将通过构建全新的架构来取代目前统治市场的 Transformer 架构。此外，Tworek 还希望将原本割裂的模型训练步骤整合为单一的流程。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcBVdJ60aFkg5Dug7rMib18SzLC2l34M8B3TIXpP1K3WAmibcx2EYicqGkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4446202531645569" data-s="300,640" data-type="png" data-w="632" type="block" data-imgfileid="503530959" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6a73ef6f-386e-4d2f-953f-458f382ae54f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Transformer 架构&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在追求「&lt;strong&gt;持续学习&lt;/strong&gt;」这一目标上，Core Automation 与另一家实验室 Safe Superintelligence（由前 OpenAI 首席科学家 Ilya Sutskever 共同创立）不谋而合。Sutskever 此前也表达过类似的愿景，即希望模型能够通过在现实世界中的部署来不断进化。此外，从 Meta 离职的 Yann LeCun 也在探索类似的方向。&lt;/p&gt;&lt;p&gt;当然，OpenAI 和 Anthropic 等巨头也并未忽视「持续学习」。&lt;/p&gt;&lt;p&gt;一些研究者认为，通过对现有基于 Transformer 的模型进行微调，同样可以实现类似的学习特性，而无需彻底推倒重来。&lt;/p&gt;&lt;p&gt;媒体表示，Tworek 宏大的融资目标反映了资本市场对「新实验室」的持续狂热。近几个月来，尽管许多此类公司尚无收入甚至没有产品，但动辄就能拿到数亿美元的投资。&lt;/p&gt;&lt;p&gt;例如：初创公司 Humans&amp;amp; 本月以 44.8 亿美元的估值拿下了 4.8 亿美元种子轮融资，投资者包括英伟达和贝佐斯；Mira Murati 的 Thinking Machines Lab 最近也在洽谈一笔 40 亿至 50 亿美元的融资，投后估值预计超过 500 亿美元。不过相比之下，Thinking Machines 进展更快，去年已推出了模型定制产品并产生了部分收入。&lt;/p&gt;&lt;p&gt;Tworek 早在 2019 年就加入了 OpenAI。在他的构想中，Core Automation 的研究团队将围绕一个名为「&lt;strong&gt;Ceres&lt;/strong&gt;」（取自罗马谷物女神及矮行星之名）的单一算法和模型展开工作。这与主流厂商的做法大相径庭。通常，大型模型的训练会分为预训练（使用海量互联网数据）、中期训练和针对编程、医疗等领域的后期微调。&lt;/p&gt;&lt;p&gt;按照 Tworek 的目标，&lt;strong&gt;这款模型所需的数据量将比现有最先进模型少 100 倍&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;模型研发成功后，公司将开发 AI 智能体来自动化生产自己的产品。其远景规划首先是工业自动化，最终目标甚至包括建造「自我复制工厂」、研制自动生成定制设计的生物机器，乃至于改造地外行星的生态。&lt;/p&gt;&lt;p&gt;你看好这些新方向的探索吗？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>机器人具身操作评估新范式来了，从此告别单一成功率指标</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:22:28 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/678305a2-b255-42fa-a71d-2d2659e66e56/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;作者介绍：刘梦源，北京大学深圳研究生院研究员，研究领域为人类行为理解与机器人技能学习；盛举义，北京大学在读博士研究生，研究方向为机器人操作技能学习方法研究；王梓懿、李培铭，北京大学在读硕士研究生，研究方向为视频理解分析；徐天铭，北京大学在读硕士研究生，研究方向为机器人操作技能学习方法研究；徐天添，中国科学院深圳先进技术研究院集成所研究员，研究领域为磁控微型机器人导航、机器人的协同控制等；刘宏，北京大学深圳研究生院教授，研究领域为计算机视觉与智能机器人、机器学习与智能人机交互。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfjO0gdgMbu0rMml33hPrnMOmWSdPBy4Zn9Z9QY7XKx4GtrdgHYTlmzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.17037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530767" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c62a0d2b-d0cb-4007-8803-f09bfa015da0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接:https://arxiv.org/abs/2601.18723&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接: https://github.com/LogSSim/TERM-Bench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;随着 Vision-Action (VA) 和 Vision-Language-Action (VLA) 模型的爆发，机器人模仿学习取得了长足进步。然而，当前的评估体系却面临着严重的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;信任危机」。现有的评估范式主要依赖二元的「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;成功率（Success Rate）&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」，这种简单的指标掩盖了两个关键问题：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;执行质量的模糊性（Gap 1）：同样是「成功」完成任务，模型 A 可能动作僵硬、伴随剧烈抖动（Jerky Success），而模型 B 则行云流水。传统的二元评价无法区分二者，导致潜在的安全隐患被忽视。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;来源的模糊性（Gap 2）：在一些已有的展示视频中，不仅难以判断动作是否由真正的自主策略生成，甚至难以分辨其是否由人类远程操作（Teleoperation）「冒充」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决上述评估信任危机，北大与中科院团队提出了一套完整的解决方案：&lt;strong&gt;Eval-Actions 评估基准与 AutoEval 自动化评估架构&lt;/strong&gt;。该方案旨在从「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;细粒度动作质量」和「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;来源真实性」两个维度，重塑机器人操作的评估标准。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf6RxltL8GCiaXeqicic6bLrA9aR64Ol03WRKSyIKkyTnzg2ANBw0l9zKoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6898148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530770" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/05bcd98b-b5bf-4d59-9b71-1d4582e9797c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1 (上) 评估危机：现有二元指标掩盖了执行质量（如「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;抖动成功」与「&lt;/span&gt;&lt;/sup&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;平滑成功」的区别）和来源真实性（难以区分策略生成与人类遥操作）的模糊性。 (下) 解决方案：Eval-Actions 基准与 AutoEval 架构（绿色部分）相结合，填补了这两大空白，实现了精准的细粒度质量评估与鲁棒的来源验证，显著优于传统的通用 VLM（红色部分）。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;填补空白：首个面向评估完整性的 Eval-Actions 基准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;表格 1 机器人操作数据集的对比分析。与以模型训练为核心、追求原始轨迹数据量最大化的数据集不同，Eval-Actions 以标注密度最大化为设计目标，独有的优势在于提供故障场景数据、混合轨迹数据源。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfGWUTYMDZEx90fNBdawe3JMtZHnGwVeou4anHo0f8bibg337pSmASrQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.20833333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530774" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1b2bc714-2fd3-4951-8820-cc0eb51ff88d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了打破现有数据集仅关注「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;成功演示」的局限，研究团队构建了 Eval-Actions 基准。与 Open X-Embodiment 等以训练为目的的数据集不同，Eval-Actions 专为诊断性评估而生。&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;包含失败场景&lt;/strong&gt;：数据集不仅包含成功的轨迹，还创新性地引入了约 2.8k 条失败数据。这对于模型学习错误恢复和鲁棒的失败检测至关重要 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;混合来源验证&lt;/strong&gt;：数据集混合了人类遥操作数据与多种策略（VA 及 VLA 模型）生成的轨迹，为验证「来源真实性」提供了数据基础。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多维监督信号&lt;/strong&gt;：提供了专家评分（Expert Grading）、排序引导（Rank-Guided）以及思维链（Chain-of-Thought, CoT）三种层次的注释，支持从数值评分到逻辑推理的全方位评估。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf6tAeroqJQicfz2Q5GaROe6vicBwhjI7IlTib6M7UtxpFGDx8vXYHIqGicQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530775" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/9cb1062f-80b7-4a40-8a9f-158fc30fe9a2/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 2 Eval-Actions 基准概览。包含从单臂到双臂的 150 + 任务，并提供细粒度的质量雷达图与 CoT 注释。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AutoEval：双引擎驱动的自动化评估专家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了实现对机器人行为的精准诊断，团队设计了 AutoEval 框架。它并未采用单一模型，而是针对不同的评估维度，创新性地提出了 AutoEval-S 和 AutoEval-P 两种架构，分别解决「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;看不清细节」和「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;胡乱推理」的难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. AutoEval-S：精准捕捉动作细节&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的 VLA 模型往往只能处理稀疏的关键帧，容易遗漏动作执行过程中的抖动或停顿。AutoEval-S（Small）引入了时空聚合策略（Spatio-Temporal Aggregation）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;高频细节压缩&lt;/strong&gt;：它并没有简单丢弃中间帧，而是将高频的运动细节「压缩」 进视觉 Token 中，最大化了时间信息的密度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物理信号校准&lt;/strong&gt;：辅以运动学校准信号（Kinematic Calibration Signal），直接利用速度和加速度方差等物理数据来校准视觉评估，确保评分精准反映动作的平滑度与安全性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. AutoEval-P：具备逻辑推理能力的「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;考官」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;当需要模型输出思维链（CoT）进行解释时，传统模型常出现「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;幻觉」，即推理逻辑与打分不一致（例如嘴上说「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;动作完美」，实际上物体已经掉了）。AutoEval-P（Plus）引入了组相对策略优化（GRPO）范式。&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;强制言行一致&lt;/strong&gt;：通过强化学习，AutoEval-P 被训练在生成评分的同时，必须给出逻辑自洽的物理推理。其混合奖励函数（Hybrid Reward Function）同时约束内容的准确性和格式的规范性，有效消除了大模型的推理幻觉。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfibNy5OYSSocbKJWMy9EcibLticXttmrbp4lx1MyQt8S15siaFv6qhWupmQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5518518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530777" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5a45c4db-db08-4f80-98af-596274cf999c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3 上分支 (AutoEval-S)：专为评分与排序设计。采用时空聚合策略将高频运动细节压缩至视觉 Token，并辅以物理校准信号，精准捕捉动作中的细微抖动。下分支 (AutoEval-P)：专为思维链（CoT）推理设计。引入 GRPO 强化学习范式，通过混合奖励函数（内容 + 格式）强制模型生成逻辑自洽的物理推理与评分，有效解决大模型的「&lt;/sup&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;幻觉」问题 。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：树立可信评估新标准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Eval-Actions Small (EAS) 子集上的广泛实验表明，AutoEval 框架在多项指标上展现出卓越性能，全面超越了 InternVL、QwenVL 等通用大模型 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 极高的来源辨别力：让「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;造假」无处遁形&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;AutoEval 能够以 99.6% 的准确率区分视频是来自真实的策略生成还是人类遥操作，有效解决了「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;来源模糊性」问题，为机器人社区提供了一套权威的防伪工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 细粒度评分高度对齐人类&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在衡量动作平滑度、安全性和效率的综合质量评分上，AutoEval-S 与人类专家的判断高度一致。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在专家评分（EG）协议下，SRCC 达到 0.81 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在排序引导（RG）协议下，SRCC 高达 0.84，显著优于未微调的 InternVL3.5-4B (SRCC &amp;asymp; 0.02) 和 QwenVL3-4B。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;表格 2 Eval-Actions 基准上的性能对比 在专家评分（EG）、排序引导（RG）及思维链（CoT）三种协议下，AutoEval 均取得了 SOTA 性能。特别是在 RG 协议下，AutoEval-S 的评分相关性（SRCC）达到 0.84，来源预测准确率高达 99.6%，远超未微调的 InternVL 和 QwenVL 等基线模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfiaibQCOxVsHXaQl0d9gjQ3qEIBgbvD086aNaTqgKWict72HWicb1pEbFRA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530781" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e81aa520-f6d9-4df2-b89f-0d5a676e993f/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfsbIzW1m02XbsUPxMHW0FRSubyyH0icY0MySvllQib4YAbjJRycicmqsVQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-ratio="0.7194444444444444" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503530784" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7c923d94-1c0c-481a-833d-505a3c6c35d7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 4 细粒度动作质量评估的定性对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 跨构型泛化能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;即使在未见过的 Franka 机器人数据上，AutoEval 依然保持了稳健的评估能力。AutoEval-S 在新形态机器人上仍能达到 0.75 的评分相关性（SRCC）和 90% 的来源预测准确率，展现了强大的跨实体泛化潜力 。&lt;/p&gt;&lt;p&gt;表格 3 AutoEval 在未见构型 Franka 机械臂数据上的泛化实验结果&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf1Q9SGQSvDfyib47AdEK2t1AtOGC5V42yPZcZ169COq1mlIxANmVYhQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.30462962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530786" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b725c71f-9940-456b-9c19-796295a4aef9/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;4. 区分远程操作和策略执行视频&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfPhFVjaVoxndRmbRSCxvzwzYibzcW7m3PFOlAyO1vbEN4LrWad0hL3icQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.75" data-type="gif" data-w="400" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfPhFVjaVoxndRmbRSCxvzwzYibzcW7m3PFOlAyO1vbEN4LrWad0hL3icQ/0?wx_fmt=gif&amp;from=appmsg" data-cropselx2="400" data-cropsely2="300" data-imgfileid="503530821" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/55c2b0a3-cba4-424a-8c70-ae3332cdd109/640.gif" data-order="0" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfvhX5TKoddy8QBfw8ZX9yTiaeJzoWOxx172zl1rsMWBalpX0LAL3FS6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5416666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530813" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/0d8ce648-8e58-4ad8-81a8-5670230d543a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5pBO8aJbBeAMPzKPZq4T9Oc05e0fWja23jwQs1CqDfGfsBicGhcISbQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.75" data-type="gif" data-w="400" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5pBO8aJbBeAMPzKPZq4T9Oc05e0fWja23jwQs1CqDfGfsBicGhcISbQ/0?wx_fmt=gif&amp;from=appmsg" data-cropselx2="400" data-cropsely2="300" data-imgfileid="503530820" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/b9efe679-f8c7-4ae4-b33a-bd4f64f2b9b0/640.gif" data-order="1" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfBlicSiaAHhaLVe2WZuNOoOOwDyVkCV3nSdc4EaDI1K403ic2MmdoNDXwA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5416666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530815" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/8c551df2-9b38-40a2-a7cb-e48fb9fba972/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AlphaGo之父David Silver离职创业，目标超级智能</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:18:39 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑 | 泽南&lt;/section&gt;&lt;p&gt;又一位 AI 大佬决定创业，这位更是重量级。&lt;/p&gt;&lt;p&gt;《财富》等媒体本周五报道说，在 Google DeepMind 众多著名突破性研究中发挥关键作用的知名研究员 David Silver 已离开公司，创办了自己的初创公司。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBWHI2R2Q2vkNqryaZicFFBQ9WqaYTYiaDzGbPp7IYaI2hBfh7ovAE5vsg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.525" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531038" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6cd2b022-8f23-4306-a889-72b4541d5e58/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;知情人士称，Silver 正在伦敦创办一家名为 Ineffable Intelligence 的新公司。该公司目前正在积极招聘人工智能研究人员，并寻求风险投资。&lt;/p&gt;&lt;p&gt;Google DeepMind 已于本月初向员工宣布了 Silver 的离职消息。Silver 在离职前的几个月里一直处于休假状态，并未正式返回 DeepMind 工作岗位。&lt;/p&gt;&lt;p&gt;Google DeepMind 的一位发言人在电子邮件声明中证实了 Silver 离职的信息，表示：「Dave 的贡献是无价的，我们非常感谢他对 Google DeepMind 工作所做出的贡献。」&lt;/p&gt;&lt;p&gt;根据英国公司注册处 Companies House 的文件显示，Ineffable Intelligence 公司成立于 2025 年 11 月，Silver 于今年 1 月 16 日被任命为该公司董事。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWB94nAkohS65icU7icIAyIRKkcMgXy0sH5Xc1Je7QLEcJZUeuOSnp6poKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531046" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c8ee8e26-9ccb-472a-a403-a2663c9f7a67/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，Silver 的个人网页现在将他的联系方式列为 Ineffable Intelligence，并提供了一个 Ineffable Intelligence 的电子邮件地址。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBxso22uE2UsICicZpApXnXvUy8u0OcHGJuyn1g6wD3vibrjiaaVDxbrd7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.575" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531040" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/edd3fd3f-f1de-44d8-aaf9-b99191cc80e0/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;除了在谷歌 DeepMind 的工作之外，Silver 还是伦敦大学学院的教授。他目前仍然保留着这一教职。&lt;/p&gt;&lt;p&gt;在 AI 领域，David Silver 的大名无人不知，他是 DeepMind 众多突破性成就背后的关键人物。&lt;/p&gt;&lt;p&gt;Silver 是 DeepMind 于 2010 年成立时的首批成员之一。他与 DeepMind 联合创始人德米斯・哈萨比斯（Demis Hassabis）在大学时期就已相识。Silver 在公司早期的许多突破性成就中发挥了关键作用，包括 2016 年围棋 AI 系统 AlphaGo 的里程碑式成就，它证明了人工智能可以击败世界上最优秀的围棋棋手。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBdf4VxHe4ceHpf5jHRBwAksWDicWPtUPiavvrkaxLt0V2YicUASUOcPxicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.59875" data-s="300,640" data-type="png" data-w="800" type="block" data-imgfileid="503531041" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c3f5950e-b1c5-4262-9586-c3873373ffd4/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; David Silver、哈萨比斯和李世石。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;他也是开发 AlphaStar 团队的关键成员之一。在 2019 年 8 月，AlphaStar 在欧洲星际争霸 II 天梯上达到了大师级水平，跻身人类玩家的前 0.2%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBia5N7fm339PWjwxbDSCGRiafzNj8vZP4gu2zLMxgUr6MxKtIZVeGQlrQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6669776119402985" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503531043" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/9a76b86d-0966-4124-8725-ce1996accf23/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Silver 还参与开发了 AlphaZero，该程序能够以超人的水平玩国际象棋、日本将棋和围棋；以及 MuZero，该程序即使在没有任何游戏知识（包括游戏规则）的情况下，也能比人类更好地掌握多种不同的游戏。&lt;/p&gt;&lt;p&gt;2024 年 7 月，Silver 与 DeepMind 团队合作开发了 AlphaProof，这是一个实现国际数学奥赛银牌水准的 AI 系统。David Silver 也是 2023 年发表的介绍谷歌首个 Gemini 系列 AI 模型的研究论文的作者之一。Gemini 现在是谷歌领先的商业 AI 产品和品牌。&lt;/p&gt;&lt;p&gt;另有知情人士透露，Silver 告诉朋友们，他渴望重拾「解决 AI 领域最棘手难题的敬畏与奇妙之感」，并将超级智能 &amp;mdash;&amp;mdash; 即比任何人类都更聪明、甚至可能比全人类都更聪明的人工智能 &amp;mdash;&amp;mdash; 视为该领域最大的未解之谜。&lt;/p&gt;&lt;p&gt;近年来，多位知名 AI 研究人员离开老牌 AI 实验室，创办了致力于追求超级智能的初创公司。OpenAI 前首席科学家 Ilya Sutskever 于 2024 年创立了一家名为 Safe Superintelligence (SSI) 的公司。该公司迄今已筹集了 30 亿美元的风险投资，据报道估值高达 300 亿美元。&lt;/p&gt;&lt;p&gt;一些 David Silver 的同事，曾参与 AlphaGo、AlphaZero 和 MuZero 项目的科学家们最近也离职创办了 Reflection AI，这家初创公司也声称正在研发超级智能。另一方面，Meta 去年重组了其人工智能部门，成立了新的「超级智能实验室」，该实验室由 Scale AI 前首席执行官兼创始人 Alexandr Wang 领导。&lt;/p&gt;&lt;p&gt;而 Meta 原首席人工智能科学家、图灵奖得主 Yann LeCun 则选择离职，正为其新创立的 AI 公司寻求融资。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-bottom: 0px;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;David Silver 本科毕业于剑桥大学，2004 年赴加拿大阿尔伯塔大学攻读强化学习博士学位。他曾获得 2019 年 ACM 计算奖、英国皇家工程院银质奖章等多项荣誉。目前 Silver 的论文被引用量已经超过 28 万次。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBDI1rSF0Fqf5tiaAvt8iaW8mtSo0SKjMbHZqgLYqxUqRWic1nKszsIMJEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531047" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b68caabe-3b70-4399-bdef-ee4d8171eae4/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为 2024 年图灵奖得主 Richard Sutton 的门生，David Silver 以其在强化学习（Reinforcement learning）方面的研究而闻名，这是一种训练 AI 通过试错和反馈来学习如何做决策的方法。&lt;/p&gt;&lt;p&gt;David Silver 虽然不是强化学习的提出者，但经常被认为是强化学习最坚定的支持者之一，他认为这是创造有一天能够超越人类知识的人工智能的唯一途径。&lt;/p&gt;&lt;p&gt;在谷歌 DeepMind 于去年 4 月份发布的一档播客节目中，David Silver 表示，大型语言模型（LLM）虽然功能强大，但也受到人类知识的限制，他表示，「我们想要超越人类的认知，为此我们需要一种不同的方法，这种方法需要 AI 能够真正地自己去探索，并发现人类尚不知道的新事物。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBReDEOmBlZFv0ny2akNc7DQFWoyuSrw4zukianPZMP26QpibKZAtH86cQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.521875" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503531044" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/914de795-88c1-41cf-a889-a847e448b9ba/640.gif" data-order="0" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他呼吁 AI 进入一个以强化学习为基础的全新「经验时代」。&lt;/p&gt;&lt;p&gt;目前，大语言模型有一个「预训练」开发阶段，该阶段使用无监督学习。它们会吸收大量的文本，并学习预测在给定上下文中哪些词在统计学上最有可能出现在其他词之后。然后，它们还有一个「后训练」开发阶段，该阶段确实会使用一些强化学习，通常由人类评估员查看模型的输出并向模型提供反馈，有时反馈形式只是简单的「好」或者「不好」。通过这种反馈，模型生成有用输出的倾向会得到增强。&lt;/p&gt;&lt;p&gt;但这种训练方式的上限被人类知识锁死 &amp;mdash;&amp;mdash; 这既是因为它依赖于人类过去学习和记录的知识（在预训练阶段），也是因为大型语言模型后训练阶段的强化学习最终是基于人类的偏好。然而，在某些情况下，人类的直觉可能是错误的或短视的。&lt;/p&gt;&lt;p&gt;例如，在 AlphaGo 2016 年与围棋世界冠军李世石的第二局比赛中，AlphaGo 的第 37 手棋就出乎所有人的预料，以至于所有评论比赛的人类专家都确信这是一个昏招。但事实证明，这最终成为 AlphaGo 赢得那场比赛的关键，体现了 AI 超乎寻常的「大局观」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBIxzbXqkdt80o59WBh9ia6sBQlnzaZuuUBjPLrhV0ibAXxU1OdPZMpAHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531045" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7156c3de-8c4a-4f0d-ba1f-06a8f00747c7/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同样，人类国际象棋棋手也经常将 AlphaZero 的下棋方式描述为「非人类的」&amp;mdash;&amp;mdash; 然而，它那些看似违反直觉的走法却常常被证明是绝妙的。&lt;/p&gt;&lt;p&gt;如果在大语言模型的后训练阶段采用强化学习过程，人类评估者可能会对这些走法给出负面评价，因为在人类专家看来，这些走法像是错误的。也许这就是为什么像 Silver 这样的强化学习纯粹主义者认为，要想达到超级智能，AI 不仅要超越人类知识，还需要摒弃人类知识，从零开始，从基本原理出发，学习如何实现目标。&lt;/p&gt;&lt;p&gt;一位熟悉 Silver 想法的人士表示，Silver 创立的 Ineffable Intelligence 公司旨在构建「一种能够不断学习的超级智能，它可以自主发现所有知识的基础」。&lt;/p&gt;&lt;p&gt;人们预计 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-bottom: 0px;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Ineffable Intelligence&amp;nbsp;&lt;/span&gt;正式宣布融资时，将会出现一个巨大的融资数额。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考内容：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://fortune.com/2026/01/30/google-deepmind-ai-researcher-david-silver-leaves-to-found-ai-startup-ineffable-intelligence/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.youtube.com/watch?v=zzXyPGEtseI&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://davidstarsilver.wordpress.com/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>RoboChallenge 年度报告发布，具身智能迈向标准化时代</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 30 Jan 2026 22:47:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7affd337-c5e0-4698-bced-47b012e88422/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;当大语言模型在数字世界不断刷新人类认知边界，一场关于 AI 如何“扎根”现实物理世界的革命正悄然进行。今日，全球首个具身智能大规模真机评测平台—— RoboChallenge 正式发布首份年度报告。报告基于过去数月内（2025 Q4～2026 Q1）平台完成的数万次严苛远程真机测试，以大规模、标准化、可复现的数据，客观揭示了当前视觉-语言-动作模型在真实物理环境中的能力边界与共性挑战，为具身智能（Embodied AI）从实验室迈向通用化，提供了不可或缺的“公正标尺”与行动指南。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从数字智能到物理智能：行业呼唤“真实考场”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，大语言模型与视觉语言模型取得了爆发式突破，人工智能在感知、认知与推理层面展现出惊人潜力。然而，将这种能力可靠地赋予机器人，使其在复杂多变的物理世界中理解、决策并执行任务，仍是横亘在研究者面前的巨大挑战。真机测试长期面临难以复现、缺乏统一标准、成本高昂等核心痛点，导致模型评估往往停留在仿真环境或有限场景，其“现实世界智能”成色几何，始终难以量化评判。&lt;/p&gt;&lt;p&gt;RoboChallenge 正是为破解这一行业共性难题而生。作为由原力灵机与 Hugging Face 联合发起的全球首个大规模的真机评测平台，RoboChallenge 致力于构建一个开放、公正、可大规模复现的“真实考场”。自 2025 年 10 月 15 日正式上线以来，平台已成功部署了包含 UR5、Franka Panda、ARX5、ALOHA 等四大主流机型在内的 20 台真机集群，构筑起一个稳定、多元的远程物理测试网络。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;凝聚行业共识，共建评测标准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为推动真机评测走向规范化、标准化，2025 年 11 月 20 日，原力灵机与 Hugging Face 深度集结智源研究院、智元机器人、Qwen、星海图、自变量、清华大学、西安交通大学及 GOSIM，共同成立了 RoboChallenge 组委会。&lt;img src="https://image.jiqizhixin.com/uploads/editor/3504f4e2-a2cd-4020-b363-3e5848fef460/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; RoboChallenge 组委会成员&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这标志着真机测评迈入“开放共同体”协作的标准化新阶段，将以行业共创模式为技术迭代注入强劲动能。组委会致力于将 RoboChallenge 升维为行业级公共基础设施，依托常态化运营机制，推动评测从“分散实验”走向“共识共建”。未来，组委会将持续联动产学研各界，构建透明、高效、可信的评测生态，加速具身智能行业标准的沉淀与普及。&lt;/p&gt;&lt;p&gt;与此同时，平台开源了覆盖 9 大类、共计 30 个标准化桌面任务的 Table30 数据集，为全球研究者提供了公开、透明、高价值的训练与评测基准。这一举措迅速获得全球具身智能社区的积极响应。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真机实测成风潮，开源模型竞相上榜&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;报告指出，RoboChallenge 平台用户注册数与评测提交量在过去三个月呈指数级增长，标志着“拥抱真机实测”已成为全球具身智能领域的核心共识。平台已吸引了从顶尖研究院所、科技巨头到活跃开源社区的广泛参与。&lt;/p&gt;&lt;p&gt;目前，由社区及个人开发者提测的多款开源模型，如 Pi0 与 Pi0.5、RDT-1B、CogACT 及 OpenVLA-OFT 等已成功完成测试并上榜。千寻智能与自变量团队更已完成了完整的 Table30 任务集评测。此外，极佳视界、智源研究院、中移杭研、星海图、地平线等多家机构的模型也正在平台进行紧锣密鼓的真机实测。这种跨越国界与机构壁垒的广泛参与，彰显了行业对于标准化、可比较真机验证平台的迫切需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;报告核心发现：机遇与挑战并存&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于对海量真机测试数据的深度分析，RoboChallenge &amp;nbsp;年度报告揭示了以下核心发现与亮点观察：&lt;/p&gt;&lt;p&gt;1.评测热度飙升，真机验证已成刚需：平台活跃度指数级增长，证实 RoboChallenge 已成为检验 VLA 模型物理世界能力的权威试金石。&lt;img src="https://image.jiqizhixin.com/uploads/editor/97b73359-2f10-49c6-9653-a6a97857f0c6/%E5%9B%BE%E7%89%873.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 活跃用户地域分布显示出 RoboChallenge 正在形成的国际化生态&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;2.基础任务趋近成熟，“Hello World”雏形初现：“叠碗”和“物体移入盒子”两项任务因其相对较高的成功率，成为多数模型首选的验证性任务，类似具身智能的入门“考题”。&lt;/p&gt;&lt;p&gt;3.复杂任务依然“屹立不倒”：涉及多步骤序列决策、长期规划及精细灵巧操作的任务，如“整理纸杯”、“制作三明治”等，对当前所有参测模型而言仍极具挑战，成功率长期处于低位，部分甚至接近零。这清晰划定了当前技术的能力前沿。&lt;/p&gt;&lt;p&gt;4.榜首模型成功率约 50%，前路仍长：当前在 Table30 评测集上表现最佳的模型，其整体成功率也仅在 50% 左右。这既体现了现有模型的进步，也充分说明了 Table30 任务集设计的挑战性与现实价值，表明具身智能在通用能力上仍有巨大提升空间。&amp;nbsp;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5ad9bef5-2e5b-42eb-87de-ba97f049578b/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; RoboChallenge 官网首页总榜（仅显示 Top 8） 截图日期：2025.1.23&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;5.VLA 模型仍在攻克人类的本能级操作。实测数据显示，参测模型虽具备较强的指令语义理解能力（呈现移动趋势），但在精细操作任务中成功率不足 15%。这种现象在 RoboChallenge 平台上沉淀了大量真机失败数据，这份公开的“错题集”可作为模型迭代优化的关键参考。&lt;/p&gt;&lt;p&gt;6.社区志愿者与具身智能企业通过实战评测，不仅探明了多维任务下的模型边界，更沉淀了关键的技术洞察与工程经验。这些实战的洞察和发现为 RoboChallenge 的迭代提供了重要参考，正凝聚行业合力，共同加速具身智能“GPT-3.5时刻”的到来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;展望未来：拓展场景，深化协作，共创价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RoboChallenge 年度报告的发布，标志着具身智能真机评测进入了以数据驱动、标准共建的新阶段。但这仅仅是序章。展望未来，RoboChallenge 将持续迭代，引入更多机器人本体类型，拓展至更多元化、更贴近真实工业与家庭需求的场景评测集，并设计更具挑战性的任务。平台还将探索分布式真机评测机制，进一步扩大测试规模与效率。&lt;/p&gt;&lt;p&gt;“我们的愿景是与全球社区并肩前行，”RoboChallenge 组委会表示，“通过构建和维护这个最真实、最开放的具身智能‘考场’，我们期望不断降低真机验证的门槛，让每一次失败都转化为进步的阶梯，共同推动具身智能技术突破‘最后一厘米’的障碍，最终在真实的物理世界中创造切实、普惠的价值。”&lt;/p&gt;&lt;p&gt;查阅RoboChallenge年度报告请登陆官网：https://robochallenge.ai/news&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>顶尖模型离“科学家”还差得远？AI4S亟待迈向2.0时代</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 18:57:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;当前，科学智能（AI for Science）被称之为人工智能的 &amp;ldquo;皇冠&amp;rdquo;，以 AlphaFold 为代表的 AI for Science（AI4S）技术在蛋白质折叠、气象预测等特定领域取得了里程碑式成就，但近期《Nature》发表的研究指出，过度依赖现有深度学习模型可能局限新知识的探索边界，甚至在某种程度上阻碍创新。&lt;/p&gt;&lt;p&gt;一项来自上海人工智能实验室（上海 AI Lab）的系统性评估①进一步揭示了当前前沿模型的短板。来自 10 个不同科学领域的 100 位科学家为模型构建了评测题目，结果显示：前沿模型在通用科学推理任务中得分可达 50 分（满分 100），但在各类专业推理任务（如专项文献检索、具体实验方案设计）中，得分骤降至 15-30 分。&lt;/p&gt;&lt;p&gt;&amp;ldquo;我们已身处 &amp;ldquo;通用人工智能&amp;rdquo;（AGI）前夕，但仍面临重要环节的缺失 &amp;mdash;&amp;mdash; 通专融合的智能。&lt;strong&gt;我们亟需推动科学智能从 1.0 向 2.0 迭代，即从 AI4S 迈向 AGI4S。&amp;rdquo; &lt;/strong&gt;日前，上海人工智能实验室主任、首席科学家周伯文在第四十届人工智能协会年会（AAAI 2026）发表特邀报告时提出，科学发现是 AI 的下一个前沿阵地 &amp;mdash;&amp;mdash; 它既是推理智能的终极试炼场，也是 &amp;ldquo;通专融合 AGI&amp;rdquo; 的验证舞台。若 AGI = 通专融合（Specialized Generalist），则可深度专业化通用模型（Specializable Generalist）是实现 AGI 的可行路径。&lt;/p&gt;&lt;p&gt;除了分享前沿观点，周伯文还详细介绍了上海 AI 实验室近年来开展的前沿探索与实践，包括驱动 &amp;ldquo;通专融合&amp;rdquo; 发展的技术架构 &amp;mdash;&amp;mdash;&amp;ldquo;智者&amp;rdquo;SAGE（Synergistic Architecture for Generalizable Experts），其包含基础、融合与进化三个层次，并可双向循环实现全栈进化；支撑 AGI4S 探索的两大基础设施&amp;ldquo;书生&amp;rdquo;科学多模态大模型 Intern-S1、&amp;ldquo;书生&amp;rdquo;科学发现平台 Intern-Discovery 及一系列相关阶段性进展。&lt;/p&gt;&lt;p&gt;演讲最后，周伯文向会场内外的观众发出行动召唤：架构已经就绪，但画卷仍存大片留白，期待与更多同行者共拓蓝图！&lt;/p&gt;&lt;p&gt;以下为报告全文，略有修订。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcPdo381GHPjYXhSdaGB5Ba3uHn8dianRJDSjzI2Mzg8LpaUJ4oKnZQHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7497546614327772" data-s="300,640" data-type="png" data-w="1019" type="block" data-imgfileid="503530963" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f810c8fc-e7e4-4b7a-95d7-0ba865519c50/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;演进预判：从 ANI 到 AGI 的历史跨越&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人工智能的发展历程并非线性堆叠，而是呈现出明显的阶段性跃迁。回顾 AI 发展的历史坐标，有助于我们厘清当前所处的位置及未来的方向。&lt;/p&gt;&lt;p&gt;早在 1996 年涉足 AI 研究之初，我便开始思考智能的本质。特别是在担任 IBM 人工智能基础研究院院长期间，首次提出了通往通用人工智能（AGI）的战略路线图，明确界定了 AI 发展的三个关键阶段：ANI（狭义人工智能）、ABI（广义人工智能）与 AGI，并给出了各自明确定义。&lt;/p&gt;&lt;p&gt;我当时的判断是 ANI 在 2016 年已趋于成熟，而通往 AGI 的必经之路并非直接跃迁，而是必须率先实现具备跨领域泛化能力的 ABI。我们认为这一跨越需要技术范式的根本性变革，最少包括三个方面：即从有监督学习转向自监督学习，从人类分割任务级联式系统转向端到端架构，从判别式工具进化为生成式助手。&lt;/p&gt;&lt;p&gt;六年多后 ChatGPT 的问世，第一次验证了人工智能系统在以上三方面的同时达成，实质上宣告了 ABI 阶段的到来。这一历史性突破验证了规模法则（Scaling Law）的有效性 &amp;mdash;&amp;mdash; 即通过扩大 Transformer 架构并将 &amp;ldquo;下一个词预测&amp;rdquo; 作为优化目标，人类首次实现了对世界知识的压缩。值得一提的是，我和团队早在 2016 年提出的关于 &amp;ldquo;多头自注意力&amp;rdquo; 机制的研究，作为 &amp;ldquo;与下游任务无关&amp;rdquo;（也就是 &amp;ldquo;预训练&amp;rdquo;）的自然语言长上下文压缩表征的首批成果之一，被开创性的 Transformer 论文引用与认可②，为这一预训练时代的压缩智能奠定了重要的理论基石。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcQbdxx5ISfROjDhP4Eqa6lT56pbHHib66ZaFXvTDGAtZGNXXUZ7juw5w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5635294117647058" data-s="300,640" data-type="png" data-w="850" type="block" data-imgfileid="503530964" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/71ad49b3-f9f1-466a-bbbf-b44516fd715c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcL1ogo1YSyzRVxaUm2aXg7rQIfzUBpW6OHObErdwtORoIkQLnHOV2Aw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5629791894852135" data-s="300,640" data-type="png" data-w="913" type="block" data-imgfileid="503530965" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d6f9dfc9-b462-4610-b164-cfa62025a67b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 重访路线图（2016 年）：通往 AGI 之路&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;战略路径：通专融合与科学发现的终极试炼&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着 Scaling Law 赋予了大语言模型广泛的泛化能力（ABI），在 2023 年初我们提出了一个关键的战略设问：通往 AGI 的下一步，仅仅是计算量的堆叠吗？对这些设问的思考促使我在 2023 年提出了&lt;strong&gt; &amp;ldquo;通专融合&amp;rdquo; 路径&lt;/strong&gt;。核心思想是如何动态实行融合人类认知思维的系统 1 和系统 2，以应对各种现实世界的任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重新定义 AGI 之路&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去 70 年 AI 的发展长期在 &amp;ldquo;专业性&amp;rdquo; 与 &amp;ldquo;通用性&amp;rdquo; 两个维度上分别进展。以 AlphaFold 为代表的早期系统是极致的 &amp;ldquo;专家&amp;rdquo;，在特定领域超越人类却缺乏迁移能力；而当前的大语言模型则是博闻广识的 &amp;ldquo;通才&amp;rdquo;，虽具广度但在处理复杂专业任务时往往难以企及专家深度和缺失关键细节。&lt;strong&gt;真正的 AGI 必须打破这种二元对立，构建一种能够动态融合 &amp;ldquo;系统 1&amp;rdquo;（直觉式快思考）与 &amp;ldquo;系统 2&amp;rdquo;（逻辑式慢思考）的智能架构 &amp;mdash;&amp;mdash; 即在保持通用认知基座的同时，能够在任意特定任务上通过持续学习与深度推理实现专家级的专精&lt;/strong&gt;（阐述这一思路系统的立场论文已于 2024 年在 ArXiv 上发表）③。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcwEZ7DXtCnZYeRv99gGW1TYmIBq5Q2EKdDsuIcsU5sfgPat1gy4Nydw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5621414913957935" data-s="300,640" data-type="png" data-w="1046" type="block" data-imgfileid="503530966" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3c9d53cb-28a2-4e2e-b6b3-c64c0392ff06/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2024 年末 OpenAI o1 与 2025 年初 DeepSeek-R1 的出现，通过在大模型之上应用强化学习显著提升逻辑推理能力，有力地验证了关于 &amp;ldquo;通专融合&amp;rdquo; 路径预判的正确性。2025 年 10 月，约书亚・本吉奥教授等人提出了 AGI 的定义，将其分解为十种核心通用能力以及众多狭义的专业能力。若能全面达成这些能力，即意味着实现了 AGI。这一定义与我们&lt;strong&gt; &amp;ldquo;通专融合是通往 AGI 的战略路径&amp;rdquo;&lt;/strong&gt; 的观点高度吻合 &amp;mdash;&amp;mdash; 这表明该路径正日益成为整个学术社区的普遍共识。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;科学发现：推理智能的终极前沿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下一个前沿领域是什么？我认为是&lt;strong&gt;科学发现（Scientific Discovery, SD）&lt;/strong&gt;。在我看来，除了科学智能（AI for Science, AI4S）所承诺的治愈癌症等诸多益处之外，&lt;strong&gt;科学发现更是推理智能的终极考验，因此也是 AI 探索的绝对前沿&lt;/strong&gt;。科学发现是已知与未知之间复杂的相互作用，涵盖了从假设生成、实验验证到理论总结的全过程。其对 AI 提出了三重极限挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;已知的未知：典型的如组合爆炸，比如分子设计或材料科学的搜索空间高达 10^60 量级，远超传统遍历能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;未知的未知：科学探索本质上是对分布外（OOD）知识的泛化，是对模型创造力的真正考验；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;稀疏与延迟奖励：科学实验的周期长、反馈慢，是对强化学习算法的严峻测试④。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，科学发现不仅是 AI 的最佳应用场景，更是驱动 &amp;ldquo;通专融合&amp;rdquo; 迈向 AGI 的根本动力。&lt;/p&gt;&lt;p&gt;接下来，我想分享我们为应对这一挑战提出的技术架构 &amp;mdash;&amp;mdash;&amp;ldquo;智者&amp;rdquo;SAGE。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术架构：递归循环的通用专家协同架构&amp;ldquo;智者&amp;rdquo;SAGE&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为将 &amp;ldquo;通专融合&amp;rdquo; 战略转化为可落地的技术方案，上海 AI 实验室在 2024 年提出了&lt;strong&gt;&amp;ldquo;智者&amp;rdquo;SAGE 架构&lt;/strong&gt; &amp;mdash;&amp;mdash; 其并非若干模型的简单堆砌，而是一个旨在弥合广泛泛化与深度专精鸿沟的统一认知生态系统⑤。该架构由三个逻辑耦合的层次构成：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;底部的&lt;strong&gt;基础模型&lt;/strong&gt;&lt;strong&gt;层&lt;/strong&gt;致力于结构上的重构，通过将知识储备与推理能力解耦，为高阶因果推理提供更灵活的 &amp;ldquo;画布&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中间的&lt;strong&gt;融合协同&lt;/strong&gt;&lt;strong&gt;层&lt;/strong&gt;通过密集过程奖励机制，动态协调直觉式 &amp;ldquo;快思考&amp;rdquo; 与逻辑性 &amp;ldquo;慢思考&amp;rdquo;，精准把控泛化与专精的节奏；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;顶层的&lt;strong&gt;探索进化层&lt;/strong&gt;则赋予 AI 主动能动性，完成从被动数据拟合到主动环境探索的范式转变。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;至关重要的是，SAGE 绝非静态的架构，而是一个递归运行的活体生态。它通过双向循环实现全栈进化：一方面，底层解耦的表征自下而上地支撑推理策略的生成；另一方面，顶层主动发现获得的高水平反馈自上而下回流，将探索中的 &amp;ldquo;未知&amp;rdquo; 转化为新的训练信号。这种闭环机制确保了 SAGE 不仅能实现模型参数的优化，更能推动认知策略本身的持续进化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcBpOsFh81w6lMEgyUXSIwICk0KqZXWNbHiaxab6VrMo4m3sD6ibP3A2xg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5612353567625133" data-s="300,640" data-type="png" data-w="939" type="block" data-imgfileid="503530967" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/547c9211-67d2-4a11-bfb5-6d2c448c4d27/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 递归循环的通专融合技术架构&amp;ldquo;智者&amp;rdquo;（SAGE）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基础模型层：知识与推理的解构与动态耦合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SAGE 的底层致力于解决现有 LLM 将 &amp;ldquo;事实记忆&amp;rdquo; 与 &amp;ldquo;逻辑推理&amp;rdquo; 混淆的问题。以记忆解码器（Memory Decoder）⑥为例，它针对性地解决了现有大模型架构的两大顽疾：一是检索增强生成（RAG）在长文本语境推理中存在的显著延迟与高昂工程成本；二是领域自适应全参数微调所带来的算力消耗及灾难性遗忘风险。&lt;/p&gt;&lt;p&gt;作为一种预训练、即插即用的独立组件，记忆解码器创新性地采用与基础模型并行运行并融合输出分布的机制。它首次用紧凑的参数化模型替代了传统非参数检索器，在无需修改基础模型参数、无在线检索开销的前提下，实现了高效的知识注入。实验数据显示，其推理开销仅为基础模型的 1.28 倍，显著低于现有主流方案。这一设计成功填补了 &amp;ldquo;高密度知识供给&amp;rdquo; 与 &amp;ldquo;推理引擎解耦&amp;rdquo; 之间的技术鸿沟，在 SAGE 框架中实现了推理能力与长期记忆的 &amp;ldquo;解耦但可集成的推理与知识&amp;rdquo;，同时强化了 &amp;ldquo;长期记忆&amp;rdquo; 能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcnAtGvsnTGYHVcGN5gBro2xdtMU4VugZvbA95O7nqzTA8tFPpicg2qyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530969" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0fa06d80-e322-4868-b162-bd100a67c2de/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcJWDYYlUyZCtB7HyEbibCMgD068DXSSxOB78SYywHKvEe1RQicpROtuyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530970" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/1c202a36-25ca-4760-ba27-f232d52b9e28/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc95icLXjPJbmr4vwGrErvaeCVX4RvGjf33ZfEkd9ZoGiaQDCCyzXUteFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530971" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/989053b6-cb34-48a2-846a-7cd9c69b9dc0/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 记忆解码器：面向大语言模型的预训练、即插即用记忆体&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习：连接基础层与进化层的纽带&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习（RL）是连接 SAGE 基础层与融合层、进化层的纽带，也是实现 &amp;ldquo;通专融合&amp;rdquo; 的核心动力之一。&lt;/strong&gt;回顾其演进历程，RL 经历了从早期封闭环境下的博弈（如 AlphaGo），演进至通过 RLHF 实现人类偏好对齐，目前正处于以 o1 和 DeepSeek-R1 为代表的可验证推理（RLVR）阶段，并终将迈向面向物理世界与科学发现的开放式体验学习新纪元。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc91C8l88g1DywnMYqJibIuPAia72LfJlCA3IPGE79zt2Ed0yqsEibkY9AA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5613861386138614" data-s="300,640" data-type="png" data-w="1010" type="block" data-imgfileid="503530972" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ad436bc3-84d2-41a8-909c-9d0aab8753f2/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc8ic1FcuSzogicN3FTXq1awDGbz8QjvYKVKY7iat8xlC6ib5zSAayRaXW1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5620723362658846" data-s="300,640" data-type="png" data-w="1023" type="block" data-imgfileid="503530974" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/2a94ee4e-18f3-4217-a2ec-3b96f11d24eb/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 适用于可通专融合的强化学习及其三大支柱&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在微观机制上，RL 被归纳为三大支柱：&lt;strong&gt;奖励设计&lt;/strong&gt;作为 &amp;ldquo;指南针&amp;rdquo;，通过稀疏或密集信号界定模型专精的目标；&lt;strong&gt;策略优化&lt;/strong&gt;作为 &amp;ldquo;引擎&amp;rdquo;，涵盖从 PPO 到 GRPO 的算法迭代，驱动模型高效更新；&lt;strong&gt;采样与探索&lt;/strong&gt;则决定了模型在庞大搜索空间中的导航路径⑦。&lt;/p&gt;&lt;p&gt;鉴于不同任务对 RL 配置的需求各异，构建系统的核心技术挑战在于统一：我们如何将多样性的最佳的奖励机制、策略优化与采样探索整合为一个协调一致的系统，从而打造出真正的 &amp;ldquo;可深度专业化通用模型&amp;rdquo;？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;融合协同层：强化学习驱动的深度推理进化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 SAGE 架构中，融合协同层承载着协调 &amp;ldquo;直觉快思考&amp;rdquo; 与 &amp;ldquo;逻辑慢思考&amp;rdquo; 的核心职能，而强化学习（RL）则是实现这一动态协同的关键桥梁。为了构建一个真正的 &amp;ldquo;可深度专业化通用模型&amp;rdquo;，必须克服传统 RL 在复杂推理任务中面临的三大核心挑战：高昂的监督成本、训练过程中的熵坍缩以及单一路径的模式崩溃。为此，我们在该层引入了三项具有范式意义的算法创新，旨在构建密集的奖励机制、维持持续的探索能力以及激发推理路径的多样性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;隐式奖励强化学习算法（PRIME）：突破高密度监督的成本悖论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;高度专家化的模型与人类专家在学习机制上具有相似性：&lt;strong&gt;专家化模型在训练过程中需要更密集的反馈信息&lt;/strong&gt;。对于 &amp;ldquo;通专融合&amp;rdquo; 大模型而言，要解决科学发现中的长链条推理问题，仅依赖最终结果的稀疏奖励往往捉襟见肘，模型急需密集的逐步监督信号。然而，传统的解决方案依赖于过程奖励模型（PRM），这要求对海量推理步骤进行人工细粒度标注，其成本之高昂，使得规模化扩展几乎成为不可能。&lt;/p&gt;&lt;p&gt;针对这一 &amp;ldquo;高密度监督需求&amp;rdquo; 与 &amp;ldquo;高昂标注成本&amp;rdquo; 之间的矛盾，我们提出了 PRIME 算法⑧ ，旨在从理论层面推导并获取 &amp;ldquo;免费&amp;rdquo; 的过程奖励。其核心洞察在于，利用策略模型与参考模型之间的统计差异。通过将模型训练目标设定为基于两者对数似然比的结果奖励模型，我们从数学方面证明，该模型能够隐式地习得 Q 函数。这意味着，智能体在无需显式训练庞大的 PRM 模型的情况下，即可在推理的每一个步骤中，通过计算动作在当前状态下的优劣，直接推导出密集的、逐步的奖励信号。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcx5skGrHMDwzXHdlL7ULI5u5oQNiatfoDxENLm99ZM7s710JlQjEANibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530975" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/7657ba60-3fcf-4a3e-9142-f8881711fe92/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcvP8o3gUrfrtzOfJDQn8T83ibIicTDzsPQr7l4w3icN67bF5iaFJ2veWEuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530976" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/6933a346-946b-4e2f-941c-4b8c9a562482/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 隐式奖励强化学习算法（PRIME）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一创新带来了多维度的显著优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;计算效率的飞跃&lt;/strong&gt;：与 Math-Shepherd 等依赖独立 PRM 模型的方法相比，PRIME 在推理阶段无需额外的模型调用开销，直接利用生成模型本身的概率分布即可获得反馈，极大地提升了计算效率；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;系统架构的可扩展性&lt;/strong&gt;：在 SAGE 的系统实现中，PRIME 方案展现出极强的工程韧性。我们将策略模型与隐式 PRM 进行联动，依托结果验证器和前序步骤产出的自由过程奖励，构建了高效的在线更新闭环；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致的数据效率&lt;/strong&gt;：实验表明，PRIME 方案仅需 SOTA 模型 1/10 的训练数据量，即可达到相当的性能水平，极大地降低了对高质量标注数据的依赖。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基准测试结果有力地验证了 PRIME 的有效性：在 AIME 2024 数据集上，模型准确率提升了 23.4%；在 AMC 数据集上提升了 27.7%；在 MATH-500 等权威测试中也取得了显著增长。&lt;strong&gt;这一系列数据充分证明，通过隐式机制构建的稠密奖励，能够有效驱动模型突破复杂推理的瓶颈。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习的熵机制：避免 &amp;ldquo;过度自信&amp;rdquo; 导致探索止步&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;专家化模型的训练不仅需要反馈，更需要持续不断的学习。&lt;/strong&gt;在深入研究用于推理的强化学习时，我们揭示了一个阻碍模型进化的根本性障碍 &amp;mdash;&amp;mdash; &lt;strong&gt;熵坍缩&lt;/strong&gt;。通俗地讲，这等同于解决如何让通用模型在专家化的过程中，始终保持探索与好奇心，让模型和顶级人类专家一样在专业问题的挑战上避免过早过分自信，而是 &amp;ldquo;stay hungry, stay foolish&amp;rdquo;（求知若饥，虚心若愚）。&lt;/p&gt;&lt;p&gt;在训练过程中，随着模型性能的初步提升，策略熵往往会急剧下降。这种下降意味着模型对其输出的置信度快速提高，导致其过早地收敛于局部最优解，从而丧失了探索更优推理路径的可能性。实验数据显示，熵的消耗主要集中在训练的前数百步，此后模型的性能提升便迅速进入边际效益递减阶段。这种现象极似人类认知中的 &amp;ldquo;过度自信&amp;rdquo;，即因自满而停止了对问题细微差异的主动探索 &amp;mdash;&amp;mdash; 而这种主动探索，恰恰是通用模型进化为能捕捉深层规律的 &amp;ldquo;专精模型&amp;rdquo; 的关键所在。&lt;/p&gt;&lt;p&gt;为了解决这一问题，我们深入探究了熵与奖励之间的权衡机制，并发现了一个关键的定量关系：&lt;strong&gt;验证性能（R）与熵（H）呈现显著的对数线性相关&lt;/strong&gt;⑨。这一简洁而深刻的结论为训练方案的优化指明了方向：构建可扩展推理 RL 框架的难点，不在于单纯堆砌训练时长，而在于对熵消耗的精细化管理，确保模型在训练全周期内保留足够的不确定性，以驱动持续的探索。&lt;/p&gt;&lt;p&gt;我们提出了一种精准化、局部化且轻量化的熵控制方案：针对这类标记开展选择性调控（如采用 Clip-Cov、KL-Cov 等方法），能够达成局部、轻量的熵控制效果，既保障模型探索性不受损，又不会干扰正常优化流程。该方法实现了对熵的局部控制，既保障了模型的探索性不受损，又避免了对正常优化流程的干扰。应用该策略后，模型在保持高探索能力的同时，显著提升了下游任务的准确率。这一方法已被实验室的&amp;ldquo;书生&amp;rdquo;科学多模态大模型 Intern-S1 等多个头部机构采纳应用，其相关成果更由斯坦福 Yejin Choi 教授在 2025 年神经信息处理系统大会（NeurIPS）上进行了重点阐述。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcd0ScsCicUKYLcObtvz4YGLdHMDWc74RBf0UOkJRMugpjeYAjn3ptzNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530977" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/7193f2d7-4ee7-4541-bff1-95bbaff98501/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcORV0tOtdKX88cCrcSZoorwjSGuquavHibGZScib5icZBGt3QP58NZYSibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.5648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530978" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/b4dcb23f-ad8a-4480-b8c9-01df89450978/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 强化学习的熵机制&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;匹配大语言模型推理的奖励分布（FlowRL）：实现专家化模型能力多元化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真正的专家不仅能解决问题，更能能为同一个问题提供多种解决方案，专家化模型亦是如此。&lt;/strong&gt;然而，现有的标准强化学习方法（如 PPO、GRPO）普遍以 &amp;ldquo;奖励最大化&amp;rdquo; 为单一目标。这种导向在复杂推理任务中极易导致&lt;strong&gt;模式崩溃&lt;/strong&gt;，即模型倾向于反复收敛至单一的、已知的成功路径，而忽略了其他潜在的更优解或多样化解法。&lt;/p&gt;&lt;p&gt;传统 RL 方法生成的分布与目标分布之间的 KL 散度高达 8.68，表现为极端的尖峰，意味着模型探索空间的极度狭窄。为了赋予模型真正的专家级思维多样性，我们在融合层引入了 &lt;strong&gt;FlowRL&lt;/strong&gt;⑩，这是一项借鉴生成流网络（GFlowNets）思想的创新工作，&lt;strong&gt;标志着强化学习优化逻辑的范式转变&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;FlowRL 的核心在于将学习目标从 &amp;ldquo;奖励最大化&amp;rdquo; 重构为 &amp;ldquo;分布匹配&amp;rdquo;。模型不再仅仅追逐单一的高分答案，而是致力于学习所有有效推理路径的概率分布。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;分布拟合：FlowRL 生成的分布能够捕捉目标分布中的绝大多数概率质量，拟合多个模态。如左侧平滑曲线所示，其 KL 散度大幅降低至 0.11，显著优于传统方法；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多样性生成：习得的策略在推理过程中能够自然地促进更多样化路径的生成，从而在面对 &amp;ldquo;未知的未知&amp;rdquo; 时具备更强的鲁棒性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;案例显示，在处理同一道数学推理题时，GRPO 模型陷入了思维死循环，推理过程重复且最终未能求解；而 FlowRL 模型则成功探索了多样化的推理路径，最终得出了正确答案 721。&lt;/p&gt;&lt;p&gt;整体实验结果进一步证实了 FlowRL 的优越性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;准确率提升：在 32B 模型的训练条件下，FlowRL 在数学推理任务中取得了 48.39% 的准确率，较 GRPO 提升 10 个百分点，较 PPO 提升 5.1 个百分点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;竞赛级表现：基于纯开源数据训练后，FlowRL 在 CodeForces 平台的评级达到 1549 分，性能直逼 o1-preview 水平；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多样性倍增：FlowRL 生成的解决方案多样性评分高达 2.28，约为 PPO 的 2 倍。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcE8u1LPQKXgZnSabyuKicMk0HEma1UoYdTq9UibPMTx9a4Q6SmiamHDnWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530979" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/6386a063-b79c-4de5-b089-e38a0fbadd8d/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcN95kbgXYM333IkicmBFyrxrLCP85KAQH6nJTVichDMszHJ7YIYfN5pNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.5611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530980" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/67352df6-a013-4058-af26-b5ea0f8d7895/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 匹配大语言模型推理的奖励分布（FlowRL）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;探索进化层：从被动拟合到主动认知探索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SAGE 架构的顶层探索进化层承载着通往 AGI 最关键的愿景 &amp;mdash;&amp;mdash; 打造一个具备自演化能力的 &amp;ldquo;可深度专业化通用模型&amp;rdquo;。这一层的核心挑战在于，如何让通用模型不仅在单一任务上实现深度专精，更能在大规模任务集乃至复杂的物理世界中，通过持续的交互与反馈实现自我迭代。为了应对这一挑战，我们从&lt;strong&gt;信号（Signal）、规模（Scale）&lt;/strong&gt;与落&lt;strong&gt;地（Ground）&lt;/strong&gt;三个关键维度出发，构建了一套完整的进化机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信号维度：测试时强化学习（TTRL）与自我进化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在推理测试阶段，模型面临的最大困境在于训练数据与测试数据之间的分布偏移。一旦失去真实标签的引导，传统模型便停止了学习步伐。然而，真正的 &amp;ldquo;专家&amp;rdquo;&amp;mdash;&amp;mdash; 如同人类物种一样 &amp;mdash;&amp;mdash; 应当具备在任何未知境况下持续学习适应的能力。&lt;/p&gt;&lt;p&gt;针对这一痛点，我们提出了&lt;strong&gt;测试时强化学习（Test-Time Reinforcement Learning, TTRL）框架&lt;/strong&gt;⑪ ，其核心洞察建立在一个简洁的假设之上：共识即意味着正确性（Consensus implies correctness）。&lt;/p&gt;&lt;p&gt;具体而言，TTRL 在推理过程中对多个候选解决方案进行采样，并将多数投票的结果作为 &amp;ldquo;代理奖励&amp;rdquo;，进而利用测试数据流直接对模型参数进行在线更新。这一方法在技术实现上具备极致的轻量化特性，仅需不到 20 行代码，即可将任何推理轨迹转化为有效的训练信号，实现了模型在无监督环境下的 &amp;ldquo;自我举证&amp;rdquo; 与 &amp;ldquo;自我增强&amp;rdquo;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcMpfIz5NDUbp62eI3viaFqUReBwkWOlSjXTKoorFviaMAAm7hGourUQ1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530981" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/dda0ea6c-40de-4ce0-8e67-dafeeaef16d3/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 测试时强化学习与自我进化（TTRL）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实测数据验证了 TTRL 的惊人潜力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能跃升&lt;/strong&gt;：在 AIME 2024 数据集上，搭载 TTRL 的 Qwen-2.5-Math-7B 模型准确率实现了 159% 的相对提升；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自我超越&lt;/strong&gt;：TTRL 优化后的模型展现出了 &amp;ldquo;青出于蓝&amp;rdquo; 的特性，其性能不仅超越了自身的 &amp;ldquo;最优 N 采样&amp;rdquo; 基准线，甚至逼近了使用带真实标签训练的理论上限（Oracle 基线）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;强泛化性&lt;/strong&gt;：在 AMC、MATH-500 等未见过的权威基准测试中，模型同样表现出强劲的泛化能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TTRL 的成功证明了智能体具备自主螺旋式上升的成长潜力，为 SAGE 架构中的自我进化提供了一条简洁高效的路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规模维度：InternBootcamp 与任务扩展定律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在解决了 &amp;ldquo;怎么学&amp;rdquo; 的信号问题后，必须回答 &amp;ldquo;在哪学&amp;rdquo; 的规模问题。通专融合模型不仅需要在单一任务上通过 &amp;ldquo;慢思考&amp;rdquo; 实现专精，更需要在成百上千个任务上同时实现能力适配。此外，我们还希望探索一个更深刻的问题：当测试任务的数量与多样性同步扩增时，是否存在专门针对在测试环境下、针对任务数量的 Scaling Law？&lt;/p&gt;&lt;p&gt;为此，我们研发了大规模、标准化、可扩展的交互验证环境 &amp;mdash;&amp;mdash;&lt;strong&gt;InternBootcamp &lt;/strong&gt;⑫。&lt;/p&gt;&lt;p&gt;作为首个覆盖 8 大任务类别、超 1000 种多样化环境的平台，InternBootcamp 支持在指定环境中开展大规模强化学习训练。其独特的 &amp;ldquo;任务与验证函数自动生成&amp;rdquo; 能力，使得用户能够便捷地将电路设计等专业领域任务转化为可验证环境，通过仿真手段完成结果核验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcLTsZ9gczrkvtCWia4rEHubAA3mhgnQJJCZRvKIBL7xDoPppkEu7vJVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.5611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530982" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/293e682d-f975-4e3b-a1e1-013eb2a90efb/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; InternBootcamp 覆盖 8 大任务类别、超 1000 种多样化任务环境&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;基于 InternBootcamp 的实验揭示了两个重要现象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;能力的 &amp;ldquo;涌现&amp;rdquo;&lt;/strong&gt;：在 BootcampEVAL 评测集中，Qwen2.5-32B 模型的平均性能实现了翻倍式增长（从 24.4 提升至 59.5）。更为关键的是，部分在单任务训练下无法解决的逻辑任务，在经过 500 余项混合任务训练后变得可解。这证实了任务间的隐性关联能够有效增强模型的综合理解能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;任务扩展定律&lt;/strong&gt;：实验数据显示，当任务类型数量从 8 种扩展至 512 种时，模型性能呈现持续上升趋势。这一结果证实了与任务数量增长相关的规模化定律真实存在，为未来大规模训练提供了理论依据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;落地维度：SimpleVLA-RL 与具身智能演进&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;进化的终局，是回归物理世界。当前具身智能面临的核心瓶颈是数据匮乏：机器人演示数据获取成本极高，且单纯扩大监督微调（SFT）规模面临边际效益递减。我们认为，强化学习（RL）凭借其突破演示数据局限的探索能力，结合简单的二元奖励（成功 / 失败），足以成为解决这一问题的钥匙。&lt;/p&gt;&lt;p&gt;基于此，我们提出了极端数据稀缺情况下的在线强化学习框架 &amp;mdash;&amp;mdash;&lt;strong&gt;SimpleVLA-RL &lt;/strong&gt;⑬。该框架基于视觉 - 语言 - 动作（VLA）模型，结合 GRPO 优化目标，并通过并行多环境渲染技术支持交互式轨迹采样。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcRoicvHvZGRh6zzYXJaN8WcYPbSH7ra92er48JRswUZ84PqX9RzOVFQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530983" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/c70e846b-a552-4a7a-a5af-1c8e7aa7fc7f/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 极端数据稀缺情况下的在线强化学习框架 SimpleVLA-RL&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实验结果颠覆了对数据效率的传统认知：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;超高数据效率&lt;/strong&gt;：仅需 &amp;ldquo;单轨迹&amp;rdquo; 监督微调结合 RL，即可实现 96.9% 的成功率，性能反而超越了全轨迹监督微调；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;策略涌现&lt;/strong&gt;：机器人通过 RL 自主探索出了从未被演示过的全新推控策略，展现出强大的适应性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sim-to-Real 突破&lt;/strong&gt;：在叠碗等典型操作任务中，仿真到现实的迁移成功率提升了 21%；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长时程任务能力&lt;/strong&gt;：在近期落地中，该方案在长时程灵巧操作任务上，实现了相对性能提升 300%，并展现出令人惊喜的自主恢复能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;得益于 SimpleVLA-RL，我们仅用极少的数据与计算资源，便取得了可与 Physical Intelligence 团队 &amp;pi;*0.6 模型比肩的性能表现。&lt;strong&gt;这一成果标志着 SAGE 架构彻底打通了负责推理决策的 &amp;ldquo;大脑&amp;rdquo; 与负责执行动作的 &amp;ldquo;躯体&amp;rdquo;，真正实现了智能体在物理世界中的 &amp;ldquo;具身化&amp;rdquo; 演进。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;经过近两年的扎实探索，SAGE 架构已跨越理论构想阶段，完成了全栈验证。在基础层，MemoryDecoder 实现了记忆与计算的结构性解耦；在融合层，PRIME 与 FlowRL 攻克了监督稀缺与推理单一性的难题；在进化层，TTRL、InternBootcamp 与 SimpleVLA-RL 构建了从测试时强化到 &amp;ldquo;具身化&amp;rdquo; 演进的闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式革命：从 AI4S 到 AGI4S&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管以 AlphaFold 为代表的 AI for Science（AI4S）技术在蛋白质折叠、气象预测等特定领域取得了里程碑式成就，但近期《Nature》发表的研究指出，过度依赖现有深度学习模型可能局限新知识的探索边界，甚至在某种程度上阻碍创新。这印证了我们的核心观点：擅长处理数据充足、定义明确任务的传统深度学习，若仅作为工具存在，难以应对科学发现中 &amp;ldquo;未知的未知&amp;rdquo;。&lt;/p&gt;&lt;p&gt;系统性的评估进一步揭示了当前前沿模型的短板。我们联合来自 10 个不同科学领域的 100 位科学家设计了评估体系，结果显示：前沿模型在通用科学推理任务中得分可达 50 分（满分 100），但在各类专业推理任务（如专项文献检索、具体实验方案设计）中，得分骤降至 15-30 分。&lt;/p&gt;&lt;p&gt;这种&lt;strong&gt;明显的 &amp;ldquo;木桶效应&amp;rdquo; 表明，科学发现全周期的效能正受制于专业推理能力的最薄弱环节。因此，整合通用推理与专业能力，进而推动科学智能从 AI4S 向 AGI4S 迭代成为必然选择。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rceicbHCzBBg7Ij2xQYl2T8CNIn5v5vFWlO8AMrg87lNNnSd528ibSoDaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.5618955512572534" data-s="300,640" data-type="png" data-w="1034" type="block" data-imgfileid="503530984" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/82493f8c-0492-457d-8adb-b717ace3bf3d/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 研究表明，当前所有前沿模型的科学能力均显不足&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从 AI4S 迈向 AGI4S，这一升级旨在推动研究者、研究工具与研究对象的协同演进。通过 AGI 促进三者相互作用、协同演进、螺旋式上升，将创造出真正&amp;nbsp;&amp;ldquo;&lt;strong&gt;革命的工具&lt;/strong&gt;&amp;rdquo;，推动科研范式变革⑭。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcLuRcGjfnM0woPBGibgvBc5tzb7wlMWZOePUQR0PP2d3frZiaXAQKP3Ow/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.5625" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503530985" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/cf88c92d-96ef-43d3-bf01-cecabf1d8c1d/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 从 AI4S 1.0 到 AI4S 2.0（AGI4S）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Intern-S1：面向科学的可深度专业化通用模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为打破上述瓶颈，我们研发了 &amp;ldquo;书生&amp;rdquo; 科学多模态大模型（Intern-S1）⑮。作为 SAGE 架构在科学领域的集中体现，Intern-S1 旨在构建一个既具备强大通用能力，又能理解复杂科学数据的 &amp;ldquo;可深度专业化通才&amp;rdquo;。其在三个层面进行了深度创新：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基础层（数据适配）&lt;/strong&gt;：针对科学数据的多模态异构性，提出了科学专用架构。采用动态分词器与专用编码器，原生支持 DNA 序列、蛋白质结构、时间序列等 10 余种模态。相较于 GPT-OSS 等通用模型，其在科学数据上的压缩率提升了 1.7 倍，并基于 2.5 万亿高质量科学 Token 进行了预训练。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;融合层（混合奖励）&lt;/strong&gt;：构建了混合奖励框架（MoR），将多种强化学习算法与熵机制整合。该框架平衡了计算、推理、实验设计等不同技能所需的奖励信号，有效缓解了特定任务过拟合问题，增强了模型在跨领域复杂推理中的泛化能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;进化层（交互专精）&lt;/strong&gt;：依托 InternBootCamp 框架，模型在超 1000 项专业任务（如逆合成分析）中与模拟器进行交互学习，实现了大规模的任务专精。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测评结果显示，Intern-S1 在通用能力上对齐 SOTA 开源模型，而在涵盖化学、生物、材料等 9 大领域的科学性能上，全面超越了包括 GPT-5 和 Grok-4 在内的顶尖闭源模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Intern-Discovery：全流程科学智能体系统&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 Intern-S1 是科学大脑，那么 Intern-Discovery 则是具备行动力的科学智能体。该平台构建了一个将 Intern-S1 与海量数据、2000 + 专业工具及湿实验室验证环境深度融合的智能体系统，实现了从假设生成到实验验证的闭环。&lt;/p&gt;&lt;p&gt;Intern-Discovery 的核心逻辑在于建立 &amp;ldquo;智能体生成&amp;rdquo; 与 &amp;ldquo;智能体验证&amp;rdquo; 的双向循环：前者主动洞察现象、提出假设并设计实验；后者通过仿真与物理实验验证假设，并将反馈回传以修正认知。&lt;/p&gt;&lt;p&gt;为支撑这一复杂流程，系统引入了两大关键支柱：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;科学智能上下文协议（SCP）⑯：针对现有 MCP 协议在科学资源整合上的不足，SCP 定义了领域特定的结构与协调机制，实现了对数据集、湿实验室设备及复杂工作流的标准化调度与全生命周期管理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分层记忆模块：通过策略程序记忆（SPM）、任务情景记忆（TEM）与语义知识记忆（SKM）的协同，系统能够沉淀高阶研究模式、记录实验细节并整合长期知识，从而在持续迭代中避免逻辑幻觉。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;案例实证：重塑科学发现流程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Intern-Discovery 已在气候科学与生物医学领域展现出 &amp;ldquo;革命性工具&amp;rdquo; 的潜力。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;气候科学&lt;/strong&gt;领域，面对降水预测中极端复杂的非线性交互，Intern-Discovery 自主调用 30 余种工具，分析了 20 年的多模态数据。它写了 4000 多行专业代码，成功发现了被人类专家忽略的水汽与动力项关联，并推导出一个简洁的新型显式非线性方程。该方程不仅形式优雅简洁，且显著提升了模拟精度，有效修正了长期存在的系统性偏差，证明了智能体在理论构建层面的创造力⑰。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcT9QV0zXFaV6Ly3oHDBqWYeNGkSpSKrCwTM7gP0ibwCAM0Jehv9d04Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.5622076707202993" data-s="300,640" data-type="png" data-w="1069" type="block" data-imgfileid="503530986" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/13820f7b-4863-44d3-943b-5b460a6caba1/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Intern-Discovery 在气候科学的应用案例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在生物医学领域，虚拟疾病生物学家 &amp;ldquo;元生&amp;rdquo; 通过模仿人类科学家的思维模板，整合遗传学、蛋白质组学及临床文献等多源数据。即便在数据稀疏条件下，它仍成功发现并验证了具有高临床潜力的隐藏靶点，展示了从数据到机制、从假说到验证的全流程智能化能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcAng2p6dv6HNGRWSSNMLZEv0ibtCrbFicqFrcfXvPdCibfKRJ9TnNIcrzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.5626204238921002" data-s="300,640" data-type="png" data-w="1038" type="block" data-imgfileid="503530987" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/74458384-ee89-4659-a5f4-d2d591871e11/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Intern-Discovery 在生物医学的应用案例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从 Intern-S1 的底层推理突破到 Intern-Discovery 的系统级应用，我们正逐步构建起一套覆盖科学发现全周期的 AGI4S 基础设施。这不仅是工具的革新，更是科研范式的重塑 &amp;mdash;&amp;mdash; 让人工智能真正成为推动科学边界拓展的合作伙伴。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行动召唤：共拓新世界蓝图&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综上所述，我们正处在实现 AGI 的前夕，若 &lt;strong&gt;AGI = 通专融合（Specialized Generalist），则可深度专业化的通用模型（Specializable Generalist）是实现 AGI 的可行路径&lt;/strong&gt;，而&amp;ldquo;智者&amp;rdquo;SAGE 的三层技术框架正是驱动后者发展的核心架构。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一个前沿阵地是科学发现 &amp;mdash;&amp;mdash; 它既是推理智能的终极试炼场，也是 &amp;ldquo;通专融合&amp;rdquo; 的验证舞台，大规模推理将赋能科学发现，科学发现亦将反哺推理能力的进化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Intern-S1 与 Intern-Discovery 是迈向该方向的首步实践，但这一切仅仅是初始的雏形。&lt;strong&gt;如果将&amp;ldquo;智者&amp;rdquo;SAGE 架构比作一张新世界的地图，我们目前已建立了很好的初步验证与很多尖兵前哨站，但这张地图上仍存在广阔的 &amp;ldquo;空白区域&amp;rdquo;。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;架构已经就绪，但画卷仍存在大片留白。如果这些初步进展激起了你的兴趣，我邀请你深入阅读我们的论文与代码 &amp;mdash;&amp;mdash; 它们都是开源的。但更重要的是，我邀请志同道合者与我们一同填补这些空白，共同构建完整的蓝图。&lt;/p&gt;&lt;p&gt;谢谢！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc2eqiayTkhr7eZJjy6Mu2ia9NCO9RZ6fYFUnMxPV2xf35rOrtoxqJ81wA/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530988" data-aistatus="1" data-original-style="null" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/7a305e5b-5904-4850-abe7-c0f95a2d8777/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 本次报告核心要点总结&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;① Shanghai Artificial Intelligence Laboratory. Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows [J]. arXiv preprint arXiv:2512.16969v1, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;② Vaswani A, et al. Attention is all you need [C]// Advances in neural information processing systems, 2017, 30.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;③ Zhang K, Qi B, Zhou B. Towards building specialized generalist ai with system 1 and system 2 fusion [J]. arXiv preprint arXiv:2407.08642, 2024.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;④ Qi B, Zhang K, Tian K, ..., Zhou B. Large language models as biomedical hypothesis generators: a comprehensive evaluation [C]. COLM, 2024.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑤ Zhou B. Building AGI through Specialized Generalist AI: pathways and key issues [J]. Communications of CCF, 2025, 21 (1): 54-62.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑥ Cao J, Wang J, Wei R, ..., Zhou B, Lin Z. Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models [J]. arXiv preprint arXiv:2508.09874, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑦ Zhang K, Zuo Y, He B, ..., Zhou B. A survey of reinforcement learning for large reasoning models [J]. arXiv preprint arXiv:2509.08827, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑧ Cui G, Yuan L, Wang Z, ..., Zhou B, Ding N. Process Reinforcement through Implicit Rewards [J]. arXiv preprint arXiv:2502.01456, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑨ Cui G, Zhang Y, Chen J, ..., Zhou B, Ding N. The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models [J]. arXiv preprint arXiv:2505.22617, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑩ Zhu X, Cheng D, Zhang D, ..., Zhou B, Mei H, Lin Z. FlowRL: Matching reward distributions for LLM reasoning [J]. arXiv preprint arXiv:2509.15207, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑪ Zuo Y, Zhang K, Sheng L, ..., Ding N, Zhou B. TTRL: Test-Time Reinforcement Learning [C]// NeurIPS, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑫ Li P, Ye J, Chen Y, ..., Zhou B, Chen K. InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling [J]. arXiv preprint arXiv:2508.08636, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑬ Li H, Zuo Y, Yu J, ..., Zhou B, Ding N. SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning [J]. arXiv preprint arXiv:2509.09674, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑭ Zhou B, Ding N, Bai L, Zhou H. Advancing AI for science: From the revolution of tools to the tools for revolution [J]. AI Open, 2025, 6: 323-328.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑮ Shanghai AI Laboratory. INTERN-S1: A SCIENTIFICMULTIMODAL FOUNDATION MODEL [J]. arXiv preprint arXiv:2508.15763, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑯ Jiang Y, Lou W, Wang L, ..., Zhou B. SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents [J]. arXiv preprint arXiv:2512.24189, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑰ Guo Z, Wang J, Ling F, ..., Zhou B, Bai L. A Self-Evolving AI Agent System for Climate Science [J]. arXiv preprint arXiv:2507.17311v3, 2025.&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型的第一性原理：（二）信号处理篇</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 18:21:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;作者 | 白铂 博士&lt;/section&gt;&lt;p&gt;&lt;strong&gt;白铂 博士，华为 2012 实验室理论研究部主任 信息论首席科学家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本篇是《大模型的第一性原理》系列解读文章的第二篇（&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651006633&amp;idx=1&amp;sn=822f0d7b22e8054ea897d55c7a7b3028&amp;scene=21#wechat_redirect" target="_blank"&gt;点击回顾第一篇&lt;/a&gt;），我们将从信号处理的角度解读原论文[1]。重点探讨语义向量化背后的信号处理和信息论原理，并从时间序列的角度分析 Transformer 及其与 Granger 因果的关系。&lt;/p&gt;&lt;p&gt;我们首先提出一个观点：大模型的输入是 Token 的语义嵌入（也称为语义向量），其本质是&lt;strong&gt;把自然语言处理问题转换为信号处理问题&lt;/strong&gt;。因此对于大模型而言，向量化非常关键，它和信号处理、信息论有非常深刻的联系。&lt;/p&gt;&lt;p&gt;尽管从语言学的角度看，语法和逻辑是人类语言现象的关键，然而本系列的《统计物理篇》已经指出：大模型并不考虑这些因素，而是从纯概率的角度出发建模自然语言。&lt;/p&gt;&lt;p&gt;从 Token 的维度看，这种纯粹的概率模型在计算上是非常困难的，因此人们发展出了概率图模型、消息传递算法等工具[2]。对于当前海量数据而言，这些方法的复杂度仍然过高，很难用于大规模训练，也难以建模语义非对称性和长程依赖性。但是，当 Token 被向量化之后，情况就发生了本质的变化，因为我们可以定义内积，并用内积来表示语义相关性，从而大幅度降低计算量。&lt;/p&gt;&lt;p&gt;基于内积，我们可以进一步定义距离、微分、低维流形等一系列相对容易数值计算的量。这样就可以通过反向传播算法来训练神经网络，将 Token 的向量化变成神经网络的输入、输出和参数化记忆[3][4]。实际上，许多研究也表明神经网络之所以能完成分类，正是因为同一类事物（如照片中的猫、狗等）在高维参数空间中会内聚成低维流形[5][6]。&lt;/p&gt;&lt;p&gt;顺便提及，我们在向量检索方面的研究取得了一定进展，所提出的近似最近邻向量检索算法，过去两年一直蝉联 ANNBenchemarks 榜单的第一名 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语义嵌&lt;/strong&gt;&lt;strong&gt;入 / 向量化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人们用向量来建模语义的想法最早出现于 Luhn 在 1953 年发表的论文中[8]。但直到 2013 年，Mikolov 等人才真正取得突破[9][10]。基于大量语料，他们成功地训练出了将 Token 转化成语义向量的神经网络模型。下面这个例子经常被用来表达最理想的语义向量化：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530716" data-ratio="0.0572289156626506" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfxmEta8PpRXWMscfWDIgs9qcObJguUTOs9mibIoJ3h4GhicoKNbh0GyTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="664" type="block" data-original-style="width:430px;height:25px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8b0f08ec-b228-4d63-927f-e312555d0412/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 s (&amp;sdot;) 为一个词的向量化表示。然而遗憾的是，上述理想的语义向量化当前并未完全实现，但是语义向量之间的&lt;strong&gt;内积&lt;/strong&gt;（或者归一化为&lt;strong&gt;余弦相似性&lt;/strong&gt;）却可以表示 Token 层面的语义相关性。&lt;/p&gt;&lt;p&gt;假设 &amp;Omega; 是一种自然语言所包含的 M 个 Token 的集合，那么从大模型的角度看，一个 Token 的语义就由定义在 &amp;Omega; 上的概率分布所描述[11]。该分布可以从大量语料中学到，因此&lt;strong&gt;语义空间&lt;/strong&gt;就可以用这个学到的概率空间建模。进一步地，将&lt;strong&gt;语义向量空间&lt;/strong&gt;定义为一个 M 维空间中的单位球面&lt;img data-aistatus="1" data-imgfileid="503530718" data-ratio="0.5217391304347826" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfDYt0uLXrFSyiaU5CotaorobPdRsr6k5Hodib0LyyZNARLrT1CJoMtGTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="92" type="block" data-original-style="width:53px;height:28px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/87983441-4459-4caa-adfd-a18ac97f8f2e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 6.16%;"&gt;，其中每个 Token 都和球面上的一个点一一对应。&lt;/p&gt;&lt;p&gt;对于大模型而言，语义向量空间就可以建模为一个&lt;strong&gt;概率-内积空间&lt;/strong&gt;。许多研究认为语义向量空间应该是结构更复杂的&lt;strong&gt;低维流形&lt;/strong&gt;，但余弦相似性和欧式距离的实际效果就已经足够好了。因此，我们认为用单位球面 S^(M-1) 来定义语义向量空间是在效果和复杂度之间的良好平衡。需要特别强调的是，语义向量空间中的每一个向量本身并没有语义，而&lt;strong&gt;这个向量与其它所有向量的内积（即相对关系）才代表了语义&lt;/strong&gt;。这一点和信息论中的信源编码有本质的区别。经典的信源编码是对每一个信源符号的压缩，而语义向量的压缩则是&lt;strong&gt;在相对关系近似不变的前提下，对整个语义向量空间的降维&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;那么，如何衡量两个语义空间的距离，以控制语义向量空间降维带来的精度损失或者衡量两个不同自然语言的语义差异性就变得至关重要。当代著名的几何学家，2009 年阿贝尔奖获得者，Mikhael Gromov 为我们提供了数学工具，即 &lt;strong&gt;Gromov-Wasserstein 距离&lt;/strong&gt;[12]。它衡量了两个度量 - 概率空间之间的任意两点间度量的平均差异。该定义极大地拓展了最优传输理论中的 Wasserstein 距离的应用范围[13]。据此，我们定义&lt;strong&gt;语义向量空间距离&lt;/strong&gt;如下：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530719" data-ratio="0.075" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfupBRMOPmia8kAPJeSbEYB3gAkKZn5YDxNBH2DcEncOGp2kYaJbuMQaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="width:490px;height:37px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/39666cdf-1b65-4892-b1ef-64fe03c7ad81/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfTEbnMia15KtnodgibMlUm5zFNRwj7N9PvXUPudS6H1V2U7IZ52UEfic7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.1428571428571428" data-s="300,640" data-type="png" data-w="42" type="block" data-imgfileid="503530720" data-aistatus="1" data-original-style="width:22px;height:25px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2b2e84c3-77ef-490f-b1be-de4f3adb938c/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 2.55%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfViak5ZgNESh5rwZjLZUicavZ82l3b9Zm6RXZ1qcBEn8YG6AYQdAibicdbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.2105263157894737" data-s="300,640" data-type="png" data-w="38" type="block" data-imgfileid="503530721" data-aistatus="1" data-original-style="width:20px;height:24px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b30ab2cc-1af3-4c41-86cd-8dc4fee53e7a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 2.34%;"&gt; 是两个语义向量空间，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfBEjJIz9GQCwqzze3A1d5GqploU0xK1GJVdIQycXk0Gmkx6HaqicrwXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5208333333333334" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530722" data-aistatus="1" data-original-style="width:51px;height:27px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3515da37-4e82-4866-9050-fe52e502af30/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 6.8%;"&gt; 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfMicicxTuFEnh202WQAAf4CepPQicXsLLE6Ydkc0N4FmibT0cNiaDmiaX3ib8w/640?wx_fmt=jpeg#imgIndex=7" data-ratio="0.4485981308411215" data-s="300,640" data-type="png" data-w="107" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf9eySof4FH4SVQ5xhicU2ric3ic86zDNgQUBOicGqLGIoE8dwdBxWX89wEw/0?wx_fmt=png&amp;from=appmsg" data-cropx1="1" data-cropx2="108" data-cropy2="48" data-imgfileid="503530723" data-aistatus="1" data-original-style="width:61px;height:27px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/4812ff00-0749-4f83-952b-c973e587dfaf/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 7.43%;"&gt; 上的语义向量，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf9TuaIkzGOkYNyB0IKjWgdYAXvPJzib1p0ia4KkcBhVCWYRvkou8ibLRNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530725" data-aistatus="1" data-original-style="width:58px;height:29px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/0b0ca31a-1dfb-4a21-b332-f471d0afef5b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 7.54%;"&gt; 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfYMYkrlqPjfTUfCGBdpEMfm7UP1gn7qeNVIQK06ClSIBRBoRGwpLqbA/640?wx_fmt=jpeg#imgIndex=9" data-ratio="0.3925233644859813" data-s="300,640" data-type="png" data-w="107" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfubiaibONbhryicia94YVCMHewbh36jACqJzyvaniaqIgUcTR3m42PYJQKMA/0?wx_fmt=png&amp;from=appmsg" data-cropx1="1" data-cropx2="108" data-cropy2="42" data-imgfileid="503530726" data-aistatus="1" data-original-style="width:63px;height:25px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2eb436ff-2347-4c73-bc05-d1304e92228e/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 7.01%;"&gt; 上的语义向量，&amp;mu; 和 &amp;nu; 分别是定义在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfR7FXVKrF2pzwSxJm5R30qmhRqIcAibX5qiado5icLRdchJPRmPoMn8EMg/640?wx_fmt=jpeg#imgIndex=10" data-ratio="0.42990654205607476" data-s="300,640" data-type="png" data-w="107" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfHljuyCMSNoR1ERxRx9aKrTibYOsfxpsTicGO2AYwkcG3TwhA4iaZajRcg/0?wx_fmt=png&amp;from=appmsg" data-cropx1="1" data-cropx2="108" data-cropy2="46" data-imgfileid="503530728" data-aistatus="1" data-original-style="width:60px;height:26px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/508d97a4-a440-4009-87eb-ec8463be47ea/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 7.64%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfNc17Rbq6Bcia2YNdsYAXYmOHkOhPM5M4sPgApY0U9ibBLSzs6py0m4Ag/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4807692307692308" data-s="300,640" data-type="png" data-w="104" type="block" data-imgfileid="503530730" data-aistatus="1" data-original-style="width:67px;height:32px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/77cf53f5-8f7a-46d8-8889-ff6df79a80c9/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 7.01%;"&gt;上的概率测度，&amp;pi; 是联合概率测度，&amp;Pi;(&amp;mu;,&amp;nu;) 是边缘分布为 &amp;mu; 和 &amp;nu; 的所有联合概率测度的集合。在最优传输理论中，&amp;Pi;(&amp;mu;,&amp;nu;) 中的任何一个联合概率测度都被称为传输方案。&lt;/p&gt;&lt;p&gt;可以看到，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazffDex0sWlOl6EUuGAmGNJCWDicKcPLmzqjby4Lia87DPj0LayUtewFLWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.29545454545454547" data-s="300,640" data-type="png" data-w="176" type="block" data-imgfileid="503530732" data-aistatus="1" data-original-style="width:86px;height:25px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b93d64fc-1d1f-4706-b7a4-4c734314f5ac/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 10.41%;"&gt; 衡量了概率加权意义下两个空间内积的平均最小差异，即两个空间的平均结构差异。如果 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf6CxP9icc0vib7gbY923VWDwrDbnEV8iaicRXaPxr3FeQaTiatqibJxLewvkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.224" data-s="300,640" data-type="png" data-w="250" type="block" data-imgfileid="503530733" data-aistatus="1" data-original-style="width:131px;height:29px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/62b129bd-f88b-4379-af48-dd1e7034e98f/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dii" style="width: 14.55%;"&gt;，在数学上称这两个空间是&lt;strong&gt;等距同构&lt;/strong&gt;的。这意味着这两个语义向量空间完全等价，即两种语言在 Token 语义层面实际上是同一种语言。从这个角度看，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfPAw779B96pVqHYdBT8a8wEOUMDsHVibaGduae9R4rWooCIBf4h7qrxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.32558139534883723" data-s="300,640" data-type="png" data-w="172" type="block" data-imgfileid="503530734" data-aistatus="1" data-original-style="width:91px;height:30px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/62a7db40-b1d3-48c7-8db4-2fa786f26f79/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dii" style="width: 9.45%;"&gt;&amp;nbsp;衡量了两个语义向量空间偏离等距同构的程度。偏离程度越大，翻译起来的难度就越高。&lt;/p&gt;&lt;p&gt;因此，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfRAjYwESen49daSLebjfwrynicfJsHgZSX69EAY8vJhnhB4UG1JHsPgA/640?wx_fmt=jpeg#imgIndex=15" data-ratio="0.3103448275862069" data-s="300,640" data-type="png" data-w="174" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf1zGticCUhadVngRNICHXgGfNP2qiaxoA6b4xQVFiat5kHSr021ygwWC2Q/0?wx_fmt=png&amp;from=appmsg" data-cropx1="2" data-cropx2="176" data-cropy2="54" data-imgfileid="503530736" data-aistatus="1" data-original-style="width:95px;height:29px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/a5fd7908-15ca-4cb9-8449-6353c368b5b0/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 10.19%;"&gt;&amp;nbsp;不仅可以用于衡量语义向量空间降维带来的语义失真，同时还可以用来度量语义对齐的效果[14]。我们近期正在将这个方法从自然语言的语义对齐推广到多模态语义对齐问题上。&lt;/p&gt;&lt;p&gt;基于语义向量空间的概念，下面讨论语义压缩问题。原始 M 维语义向量空间的维数过高，难以计算且容易导致维数灾难。Landauer 等人指出语义向量化存在一个最优维数区间，即所谓&lt;strong&gt;甜点维数&lt;/strong&gt;[14]。那么，如何将 M 维语义向量空间压缩到一个合适维数？这背后的数学原理就是著名的 &lt;strong&gt;Johnson-Lindenstrauss（JL）引理&lt;/strong&gt;[16]。考虑 ϵ&amp;isin;(0,1) 和 K 个 M 维向量 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfwL1hibll9UgibOKjPmUR3A2ghZYwcC9iaO0aFm54zZADHw9bLVZsCNETQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.16875" data-s="300,640" data-type="png" data-w="320" type="block" data-imgfileid="503530740" data-aistatus="1" data-original-style="width:184px;height:31px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/de1cc401-85ee-4f2b-9d39-c8141d1bdace/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dii" style="width: 23.25%;"&gt;，如果 &lt;img data-aistatus="1" data-imgfileid="503530742" data-ratio="0.3364485981308411" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfibPztyiazkPlKxhRZmxRH0icRAx7icSeAhyupoXJ6Oaia3icTvib4lQbhicl8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-type="png" data-w="214" type="block" data-original-style="width:109px;height:37px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/1f78e67e-8122-4e44-8473-4122848e6b8f/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dii" style="width: 13.06%;"&gt;，那么一定存在一个矩阵 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfEu4Pgt9yR99UC7Usk3y8ZV1SPqD1RMdXpmHX7hlJAFBwiajkkaYUqAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.22580645161290322" data-s="300,640" data-type="png" data-w="186" type="block" data-imgfileid="503530744" data-aistatus="1" data-original-style="width:109px;height:25px;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/0035547c-b99b-4adc-8ddf-dcc2384a8434/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dii" style="width: 12.85%;"&gt;&amp;nbsp;使得&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf58Z5WDTapQW7sV5xbV414w0ZVh3CY2v4ynJ9a2yExmAdanib36c8ycg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.0807799442896936" data-s="300,640" data-type="png" data-w="718" type="block" data-imgfileid="503530743" data-aistatus="1" data-original-style="width:374px;height:30px;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/a7c5d2c2-d5dd-4f1d-8686-858bec411547/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;JL 引理表明，可以通过线性变换来降低语义向量的维数，同时使得内积的误差小于 ϵ。因此，压缩之后的&lt;strong&gt;语义失真&lt;/strong&gt;可用下面的语义向量空间距离来衡量&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530750" data-ratio="0.07314814814814814" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfOZ6vic0TS84YMzmQXlIbH7ZTZK91dJpiaeHdO94PoBiaanicoPxzPIic0bA/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/625cedd0-b994-4429-bc2f-13309ef66341/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其中，S 为原 M 维语义向量空间，S&amp;#39; 为降维后的 m 维语义向量空间。更进一步，如果考虑语义向量本身的&lt;strong&gt;稀疏性&lt;/strong&gt;，我们还可以用&lt;strong&gt;压缩感知&lt;/strong&gt;理论来强化 JL 引理。这种强化可以导出基于采样 FFT、采样 DCT 和采样 Hadamard 矩阵的快速压缩算法。详情可参见原论文中的相应章节，这里不再赘述。需要注意的是，这里并未考虑语义向量空间上的概率测度，而是对每个语义向量都成立。因此，如果结合从语料中学到的概率测度，很有可能会提出更高效的语义降维算法或得到更高的压缩比 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfAHY69hfGBVwDo8uYBXHmcHsbdQEVicNXv8AjNhywSzrNiaR52icDNOicLQ/640?wx_fmt=jpeg#imgIndex=21" data-ratio="2.2" data-s="300,640" data-type="png" data-w="30" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf3KyiaJpGkV2gDBa1dB8oIHiaSzKAp0qoulQNPA6rx0mucmw0ztKJzFQQ/0?wx_fmt=png&amp;from=appmsg" data-cropx2="30" data-cropy2="66" data-imgfileid="503530752" data-aistatus="1" data-original-style="width:20px;height:44px;" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/4cf6d2e7-68e9-4ab0-b937-88beecf13a1b/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dii" style="width: 2.65%;"&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最优语义向量化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们知道，一个 Token 到底呈现出什么语义是和下游任务密切相关的。在本系列的《统计物理篇》中已经指出，大模型的目标是预测下一个 Token。因此，Token 的向量化也应围绕该目标展开。令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfHZzUHqn1G53xMwibS4XKDibnFMfUUHUvw6ibBd0s9tKdcUbV1FqfcziaAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530755" data-aistatus="1" data-original-style="width:39px;height:26px;" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/8cf200bc-51bc-4b49-b600-3a5288e62e89/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dii" style="width: 4.78%;"&gt; 为 Token 序列，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfLQ9oD7kpqCoaZsks4gGTvDXcvmDllVxhkZ7ibzZ9CKG0eWJjPFB9gFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.7142857142857143" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530756" data-aistatus="1" data-original-style="width:38px;height:27px;" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/04734b66-ece8-422e-a6a1-4743fa6c286e/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dii" style="width: 4.57%;"&gt; 为对应的语义向量。对于下一个 Token 预测任务，语义编码器 f 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfRzYhoTcvbXD11Sm2bnHP6csQzedCglKOkh5JerdK04qGFBqVteEKQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="0.8387096774193549" data-s="300,640" data-type="png" data-w="62" type="block" data-imgfileid="503530757" data-aistatus="1" data-original-style="width:29px;height:24px;" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/e1eb9136-c196-40cf-94e5-b25ee73e6d29/640.png" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dii" style="width: 3.61%;"&gt; 的函数，其输出 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqu4QhHOFXNZpQTEdt8XR1jwHzZ996EwyoxePtsN0TENAwu23HajSPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=25" data-ratio="1.3125" data-s="300,640" data-type="png" data-w="32" type="block" data-imgfileid="503530758" data-aistatus="1" data-original-style="width:20px;height:26px;" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/3a69be60-b940-42fb-9adb-ebdc9290a625/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dii" style="width: 2.02%;"&gt; 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfePlMu45ZcMKFT5xXCd4KkerZwbT0ujPQRQVIQgOO8ZbodcLFbDNAxA/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.8" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503530759" data-aistatus="1" data-original-style="width:33px;height:26px;" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/2f0b810f-466d-4ae4-a2d1-9ac83ced25d8/640.png" alt="图片" data-report-img-idx="27" data-fail="0" class="fr-fic fr-dii" style="width: 3.72%;"&gt;中对于预测 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfZC9tIGz9vH4UrE7BJCSa434tfar8Rn1p7Ng7aqrE21dLug2DCUfZgg/640?wx_fmt=png&amp;from=appmsg#imgIndex=27" data-ratio="0.4716981132075472" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503530762" data-aistatus="1" data-original-style="width:60px;height:28px;" data-index="29" src="https://image.jiqizhixin.com/uploads/editor/bdba0ed4-9c98-4c37-b6b1-baf25ecdb0f8/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dii" style="width: 7.01%;"&gt; 有用但不在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfo364J8WZevAUZPE63bYEf0Ppk6J9vgyl1MShmb8icbXNNHgT2Z7NEzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=28" data-ratio="0.4583333333333333" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530763" data-aistatus="1" data-original-style="width:61px;height:28px;" data-index="30" src="https://image.jiqizhixin.com/uploads/editor/2eff893d-2cbd-4fe3-b254-c5d5803fdb29/640.png" alt="图片" data-report-img-idx="28" data-fail="0" class="fr-fic fr-dii" style="width: 6.58%;"&gt;&amp;nbsp;里的信息。那么，从信息论的角度看，最优语义编码器是下述优化问题的解：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530764" data-ratio="0.09020618556701031" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfolIkz84oMmpVnP9dwUUhwRKO2ZLfD6ic0GYgOSkmxeOxsEUWwwia386g/640?wx_fmt=png&amp;from=appmsg#imgIndex=29" data-type="png" data-w="776" type="block" data-original-style="width:466px;height:42px;" data-index="31" src="https://image.jiqizhixin.com/uploads/editor/c01b42ae-3f73-4a41-b683-c4dddd53e37f/640.png" alt="图片" data-report-img-idx="29" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;上述定义的核心是条件互信息，它保证了语义向量 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfXy9rDqtjjic3EQOEwoibLROXS5jhycy2NVQWXw8MAibVJFbt5xz96aFbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=30" data-ratio="1.2941176470588236" data-s="300,640" data-type="png" data-w="34" type="block" data-imgfileid="503530766" data-aistatus="1" data-original-style="width:20px;height:26px;" data-index="32" src="https://image.jiqizhixin.com/uploads/editor/4b697fe0-c5ae-416c-8751-77e3a354aad6/640.png" alt="图片" data-report-img-idx="31" data-fail="0" class="fr-fic fr-dii" style="width: 2.65%;"&gt; 并不是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfL3h7arnzaI9MYoic7yHpEyB54MX7H4yG9msAXw9RicbyUe9QGCxtlItg/640?wx_fmt=png&amp;from=appmsg#imgIndex=31" data-ratio="1.0526315789473684" data-s="300,640" data-type="png" data-w="38" type="block" data-imgfileid="503530768" data-aistatus="1" data-original-style="width:26px;height:27px;" data-index="33" src="https://image.jiqizhixin.com/uploads/editor/c6867b4d-69c4-4e12-bc0a-86b425969269/640.png" alt="图片" data-report-img-idx="30" data-fail="0" class="fr-fic fr-dii" style="width: 2.44%;"&gt; 的向量表示，而是表示 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazffG18JhGzHMiaWSe2LCNBJ1FYaicnBC6Tyib9CJyEF4iahGgBbcTxjLQ1DA/640?wx_fmt=png&amp;from=appmsg#imgIndex=32" data-ratio="0.71875" data-s="300,640" data-type="png" data-w="64" type="block" data-imgfileid="503530769" data-aistatus="1" data-original-style="width:31px;height:22px;" data-index="34" src="https://image.jiqizhixin.com/uploads/editor/0f0300b2-abff-4ef6-a3a7-2aada3258461/640.png" alt="图片" data-report-img-idx="33" data-fail="0" class="fr-fic fr-dii" style="width: 3.72%;"&gt; 中对预测 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqBRUH7HIa8E517VbQm7x7icIuvzYXYaTtbOQt7AzT2icGd6ID7bo0DWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=33" data-ratio="0.4528301886792453" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503530771" data-aistatus="1" data-original-style="width:53px;height:24px;" data-index="35" src="https://image.jiqizhixin.com/uploads/editor/710a7973-2cea-4d73-89c8-21d9d72e9575/640.png" alt="图片" data-report-img-idx="35" data-fail="0" class="fr-fic fr-dii" style="width: 6.69%;"&gt; 有用但不在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfL9oIibWFLRWQ0NCyWdm4a5OTy55bul4E0q7iczsX2OiblmiazVjxMlenicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=34" data-ratio="0.5319148936170213" data-s="300,640" data-type="png" data-w="94" type="block" data-imgfileid="503530772" data-aistatus="1" data-original-style="width:55px;height:29px;" data-index="36" src="https://image.jiqizhixin.com/uploads/editor/4244cb71-fc0d-4cfe-a2b8-ec96eec1db84/640.png" alt="图片" data-report-img-idx="32" data-fail="0" class="fr-fic fr-dii" style="width: 5.84%;"&gt;&amp;nbsp;里的信息。应用互信息不等式，我们有&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530773" data-ratio="0.28316831683168314" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfyh5ibc6IUu4tnnkd1icQ63JoicVJl0opFsWtSyS9UGxGP5x0IibljCsic6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=35" data-type="png" data-w="1010" type="block" data-original-style="width:405px;height:115px;" data-index="37" src="https://image.jiqizhixin.com/uploads/editor/61fc5743-f267-4aa1-b84f-ac18d6097459/640.png" alt="图片" data-report-img-idx="34" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该不等式的最右端项就是 Google DeepMind 团队提出并广泛应用的（包括 OpenAI）&lt;strong&gt;Contrastive Predictive Coding（CPC）算法&lt;/strong&gt;[17]。这篇论文明确指出，他们的工作得到了信息论中 &lt;strong&gt;Predictive Coding&lt;/strong&gt; 的启发。这正是发表在 IEEE 的前身 IRE 主办的信息论汇刊 IRE Transactions on Information Theory 的第 1 卷第 1 期的第 1 篇和第 2 篇论文[18][19]。作者则是大名鼎鼎的 Peter Elias，他是卷积码的发明人，1977 年香农奖得主，3G 时代编码领域的绝对王者。Google 的研究人员撰写论文系统综述了&lt;strong&gt;互信息的变分下界&lt;/strong&gt;，并最终选择 InfoNCE 作为损失函数，从而通过神经网络最小化 InfoNCE 来最大化 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfnVklL4UMwibLFJiagdGN0fnQ1an5uDsHibQU00W0wdH6W7ticnOWTiaT9Zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=36" data-ratio="0.26373626373626374" data-s="300,640" data-type="png" data-w="182" type="block" data-imgfileid="503530776" data-aistatus="1" data-original-style="width:95px;height:25px;" data-index="38" src="https://image.jiqizhixin.com/uploads/editor/8a38cf8d-8b16-41fc-9915-5e3ef4e049eb/640.png" alt="图片" data-report-img-idx="36" data-fail="0" class="fr-fic fr-dii" style="width: 11.89%;"&gt;&amp;nbsp;的下界[20]。&lt;/p&gt;&lt;p&gt;以上的讨论启发我们：&lt;strong&gt;对于任何一个语义嵌入问题，都可以先基于下游任务要求写出信息论优化问题，再设计神经网络或数值算法来搜寻逼近信息论最优解或其上 / 下界的语义编码器。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从上述推导可以看出，CPC 实际上优化的是最优语义编码器的上界的 InfoNCE 逼近，所得到的语义编码器并不是最优的。如果我们有更好的工具来直接优化上述不等式最左端的条件互信息的和，那么将能得到性能更优的语义编码器。因此，这里要引入一个非常关键的信息论概念，即&lt;strong&gt;定向信息&lt;/strong&gt;。这一概念的提出者是著名的信息论专家，1988 年香农奖得主，James Massey[21]。根据 Massey 的研究，从信道的输入序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqdgk6wqxk6mskCw7lP5ibEwKU8ls605kz21bY8ze6CUpPMv8medaRfg/640?wx_fmt=png&amp;from=appmsg#imgIndex=37" data-ratio="0.6285714285714286" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530778" data-aistatus="1" data-original-style="width:38px;height:24px;" data-index="39" src="https://image.jiqizhixin.com/uploads/editor/190d72be-edae-4033-8672-e117141eb676/640.png" alt="图片" data-report-img-idx="39" data-fail="0" class="fr-fic fr-dii" style="width: 4.99%;"&gt; 到输出序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficPcV8Lw3YImyziaZzdD6lBAEXaRkAccxzXsS3I5g9DVgKTYTRyZF8icg/640?wx_fmt=png&amp;from=appmsg#imgIndex=38" data-ratio="0.75" data-s="300,640" data-type="png" data-w="64" type="block" data-imgfileid="503530779" data-aistatus="1" data-original-style="width:36px;height:27px;" data-index="40" src="https://image.jiqizhixin.com/uploads/editor/f25d08ad-d5a3-47fc-8c3b-a46d4a2325a4/640.png" alt="图片" data-report-img-idx="37" data-fail="0" class="fr-fic fr-dii" style="width: 4.14%;"&gt;&amp;nbsp;的定向信息可定义为&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530780" data-ratio="0.20987654320987653" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficCJZbU1SZEjHyaGQ6pYQYYtYJBTicPaia11uJuz4jH8PVd4Ydhwno0fA/640?wx_fmt=png&amp;from=appmsg#imgIndex=39" data-type="png" data-w="648" type="block" data-original-style="width:325px;height:68px;" data-index="41" src="https://image.jiqizhixin.com/uploads/editor/6702b625-a19b-4c5c-8840-063684a0d1e3/640.png" alt="图片" data-report-img-idx="38" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;它衡量了从序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfJO8ROzm7lxgo3V5ZICT2nFbMAdSV7dpQXLEIZrxjoqWeCHH2gp4ibNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=40" data-ratio="0.6285714285714286" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530782" data-aistatus="1" data-original-style="width:38px;height:24px;" data-index="42" src="https://image.jiqizhixin.com/uploads/editor/adb6c01f-f17b-47e3-be35-a70d8fdf5f2c/640.png" alt="图片" data-report-img-idx="44" data-fail="0" class="fr-fic fr-dii" style="width: 4.57%;"&gt; 传递给序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfzwfvsciaRIibicV6iascAnRhmOb2bGiaofE6ysBdYibAduEliant48b1dUKxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=41" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="66" type="block" data-imgfileid="503530783" data-aistatus="1" data-original-style="width:38px;height:25px;" data-index="43" src="https://image.jiqizhixin.com/uploads/editor/f3d5c4a6-1f84-45cd-a2de-291c26fcf4b3/640.png" alt="图片" data-report-img-idx="40" data-fail="0" class="fr-fic fr-dii" style="width: 4.25%;"&gt; 的信息量。进一步地，我们定义从 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfgoZAfokZia3STy7zuzAOkgx3dep0aH13uuGxDoDG7xaibVQoplpPicSLQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=42" data-ratio="0.6571428571428571" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530785" data-aistatus="1" data-original-style="width:35px;height:23px;" data-index="44" src="https://image.jiqizhixin.com/uploads/editor/78df58e4-094b-4818-8c11-dbad181dd7b5/640.png" alt="图片" data-report-img-idx="42" data-fail="0" class="fr-fic fr-dii" style="width: 4.03%;"&gt; 到 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf7WZRWlIPZV5ybh2W5GlyzLuXPeWHJZlqSa7g35ZfvoeB2rYpbDqiaxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=43" data-ratio="0.8064516129032258" data-s="300,640" data-type="png" data-w="62" type="block" data-imgfileid="503530789" data-aistatus="1" data-original-style="width:33px;height:27px;" data-index="45" src="https://image.jiqizhixin.com/uploads/editor/330935ee-5dd1-488b-b388-6862c6386791/640.png" alt="图片" data-report-img-idx="41" data-fail="0" class="fr-fic fr-dii" style="width: 4.03%;"&gt;&amp;nbsp;的&lt;strong&gt;倒向定向信息&lt;/strong&gt;：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530791" data-ratio="0.2028985507246377" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfibSoa8xaf9xb1TDBInnPBtiaMiaz8cPEKiaokpCjJ76oqqCDGhqWQgNL9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=44" data-type="png" data-w="690" type="block" data-original-style="width:363px;height:74px;" data-index="46" src="https://image.jiqizhixin.com/uploads/editor/48675407-aa5a-4989-b2ee-d59b684ab260/640.png" alt="图片" data-report-img-idx="43" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;选择&lt;strong&gt;倒向&lt;/strong&gt;这个词是受到彭实戈院士所研究的&lt;strong&gt;倒向随机微分方程&lt;/strong&gt;的启发[22]。彭院士的研究成果最终促使他提出了一套与 Kolmogorov 概率公理化体系平行的&lt;strong&gt;非线性期望理论&lt;/strong&gt;。我们从中可以看出，前面讨论的信息论最优的语义编码器，就是在最优化倒向定向信息，即：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530795" data-ratio="0.16393442622950818" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfDWkJBGatMibVkR6nQg8lXvRrXDJxAKgGGdWXUy0XiccibY66U5bVo68ew/640?wx_fmt=png&amp;from=appmsg#imgIndex=45" data-type="png" data-w="854" type="block" data-original-style="width:421px;height:69px;" data-index="47" src="https://image.jiqizhixin.com/uploads/editor/768ce405-295d-4e57-a885-230739e0559e/640.png" alt="图片" data-report-img-idx="45" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;然而，定向信息的计算和估计是非常困难的。该问题将在本系列的第三篇《信息论篇》中展开讨论。可见，CPC 选择 InfoNCE 作为损失函数平衡了复杂度和效果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Transformer 是非线性时变向量自回归时间序列&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在本系列的第一篇《统计物理篇》中，我们详细探讨了 Transformer 的能量模型（Energy-based Model，EBM）形式。本篇我们从信号处理角度进一步讨论 Transformer 的本质。业界已经达成共识，Transformer 是一个自回归大语言模型。这是因为它基于输入 Token 序列和已经生成的 Token 序列来预测下一个 Token。事实上，从经典随机过程和时间序列分析的角度看，自回归模型有严格的数学定义，即用过去的随机变量的值的线性加权和来预测未来的随机变量[23]。&lt;/p&gt;&lt;p&gt;考虑提示词的长度为 n，用向量序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfJDVV5Tm6icicW5W7AQBBMB74jibAcStsEc3qw8VNJx4VMsEemkFrpQTiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=46" data-ratio="0.6764705882352942" data-s="300,640" data-type="png" data-w="68" type="block" data-imgfileid="503530796" data-aistatus="1" data-original-style="width:42px;height:28px;" data-index="48" src="https://image.jiqizhixin.com/uploads/editor/677adff7-856b-488f-9c44-20c78faaddc2/640.png" alt="图片" data-report-img-idx="46" data-fail="0" class="fr-fic fr-dii" style="width: 4.46%;"&gt; 来表示。当前要预测第 i 个 Token，表示为向量 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfUSJVMic9n1e1pOViavriaYhJPjRA83IBWW6bByRqLicXGXrnumPbVDJLCw/640?wx_fmt=png&amp;from=appmsg#imgIndex=47" data-ratio="0.9473684210526315" data-s="300,640" data-type="png" data-w="38" type="block" data-imgfileid="503530797" data-aistatus="1" data-original-style="width:23px;height:22px;" data-index="49" src="https://image.jiqizhixin.com/uploads/editor/74e9ce30-93e4-43b1-9ea2-554a36d0d0a5/640.png" alt="图片" data-report-img-idx="48" data-fail="0" class="fr-fic fr-dii" style="width: 2.76%;"&gt;，其中 i=n+1,&amp;hellip;,N。为表示方便，令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfZdT9f9Ck7cWZsq8SNenLe1VddyMQLS7NzusubicU4meyZzJJyDT59sA/640?wx_fmt=png&amp;from=appmsg#imgIndex=48" data-ratio="0.328125" data-s="300,640" data-type="png" data-w="128" type="block" data-imgfileid="503530798" data-aistatus="1" data-original-style="width:69px;height:23px;" data-index="50" src="https://image.jiqizhixin.com/uploads/editor/45faa4c1-38c1-4472-a808-7f71f3944f45/640.png" alt="图片" data-report-img-idx="47" data-fail="0" class="fr-fic fr-dii" style="width: 9.03%;"&gt;，其中 i=1,&amp;hellip;,n。结合自回归模型的思想，Attention 模块的数学形式可以写为：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530799" data-ratio="0.6608695652173913" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfONeLv99VSAKNtkTbmHHaSReiaWeBa83qOVWxsyPJPfzOUlAdiaXDf3uw/640?wx_fmt=png&amp;from=appmsg#imgIndex=49" data-type="png" data-w="230" type="block" data-original-style="width:114px;height:75px;" data-index="51" src="https://image.jiqizhixin.com/uploads/editor/de623ae7-6c45-4939-92d5-8aa652b15d6b/640.png" alt="图片" data-report-img-idx="49" data-fail="0" class="fr-fic fr-dib" style="width: 20%;"&gt;&lt;/section&gt;&lt;p&gt;其中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfEsvdTlwml0rjxyqQ8UfGAbBbA4FaZicxY9LtLWLSCicOPraQIJSD2zOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=50" data-ratio="0.8275862068965517" data-s="300,640" data-type="png" data-w="58" type="block" data-imgfileid="503530800" data-aistatus="1" data-original-style="width:32px;height:26px;" data-index="52" src="https://image.jiqizhixin.com/uploads/editor/c5310b6b-e53f-4e0b-b9c9-8677d0a1f72f/640.png" alt="图片" data-report-img-idx="50" data-fail="0" class="fr-fic fr-dii" style="width: 4.46%;"&gt;&amp;nbsp;是 Attention 权重，定义为：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530801" data-ratio="0.1372093023255814" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5RarUdl78uQgaExvq7sPaicBTianEsoyd09hlAJ7gpYI70ibBvlia9ToyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=51" data-type="png" data-w="860" type="block" data-original-style="width:433px;height:59px;" data-index="53" src="https://image.jiqizhixin.com/uploads/editor/42fc6a1d-1224-4482-95fa-3aceaa545a4d/640.png" alt="图片" data-report-img-idx="51" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从数学形式上看，Attention 是一个&lt;strong&gt;非线性时变向量自回归时间序列&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;时变性体现在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf3DKS1ib0LyJ8CoXN1tXnMxkibVMMN5kuV80v86xLhqsVibkw6vxxR8k2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=52" data-ratio="0.9230769230769231" data-s="300,640" data-type="png" data-w="52" type="block" data-imgfileid="503530802" data-aistatus="1" data-original-style="width: 30px;height: 28px;" data-index="54" src="https://image.jiqizhixin.com/uploads/editor/9306c6d9-2fbb-46de-b740-534de13ddf68/640.png" alt="图片" data-report-img-idx="55" data-fail="0" class="fr-fic fr-dii" style="width: 3.8%;"&gt;&amp;nbsp;与当前输出的 Token 编号 i 相关；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;非线性体现在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf3DKS1ib0LyJ8CoXN1tXnMxkibVMMN5kuV80v86xLhqsVibkw6vxxR8k2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=53" data-ratio="0.9230769230769231" data-s="300,640" data-type="png" data-w="52" type="block" data-imgfileid="503530802" data-aistatus="1" data-original-style="width: 30px;height: 28px;" data-index="55" src="https://image.jiqizhixin.com/uploads/editor/f3422596-388f-4401-8b45-fbb246eb4cb7/640.png" alt="图片" data-report-img-idx="54" data-fail="0" class="fr-fic fr-dii" style="width: 4.23%;"&gt; 的定义中包含了 softmax 函数和建模语义非对称关系的双线性型 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfJNxiab04KBZzZ0icVq2XzSCVb6nia8poia34M2ib4A4xzeYquicVoS4UoUaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=54" data-ratio="0.375" data-s="300,640" data-type="png" data-w="144" type="block" data-imgfileid="503530803" data-aistatus="1" data-original-style="width: 80px;height: 30px;" data-index="56" src="https://image.jiqizhixin.com/uploads/editor/060f8603-bf94-4922-ae5d-ffe44e9a2df2/640.png" alt="图片" data-report-img-idx="53" data-fail="0" class="fr-fic fr-dii" style="width: 9.11%;"&gt;，其中 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfC0SnBG7BoGXzI2PqOgtSHr5ibgj6gXVqI3613b9kpfuCAWaZhIowBew/640?wx_fmt=png&amp;from=appmsg#imgIndex=55" data-ratio="0.29" data-s="300,640" data-type="png" data-w="200" type="block" data-imgfileid="503530804" data-aistatus="1" data-original-style="width: 102px;height: 30px;" data-index="57" src="https://image.jiqizhixin.com/uploads/editor/561696c1-709e-438b-8985-33b1ca7b91e4/640.png" alt="图片" data-report-img-idx="52" data-fail="0" class="fr-fic fr-dii" style="width: 10.52%;"&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfFaP7StKjpO956wesdOc0XHLUiaIUUQRJzFGjA1W1N5r6My1AzS9jiabQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=56" data-ratio="0.5714285714285714" data-s="300,640" data-type="png" data-w="84" type="block" data-imgfileid="503530805" data-aistatus="1" data-original-style="width:43px;height:25px;" data-index="58" src="https://image.jiqizhixin.com/uploads/editor/69bad320-bc55-4927-95a0-b8866e3b79c7/640.png" alt="图片" data-report-img-idx="57" data-fail="0" class="fr-fic fr-dii" style="width: 5.1%;"&gt;&amp;nbsp;表示 Tranformer 的 FFN 层，那么 Transformer 本质上是通过&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530806" data-ratio="0.4748603351955307" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfiarsFpQk308Vqttl4UHJx8GhlQvvFrjRUicibtuZHE2XF3ASLnr3vs8lQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=57" data-type="png" data-w="358" type="block" data-original-style="width:195px;height:93px;" data-index="59" src="https://image.jiqizhixin.com/uploads/editor/2dbf9a3c-9ec4-45b3-a10b-7d0161512a9b/640.png" alt="图片" data-report-img-idx="56" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;来预测下一个 Token 的向量表示。在《统计物理》篇中，我们已经指出 FFN 层对于预测下一个 Token 是很重要的，它被认为是大模型储存知识的位置。基于记忆容量的思路，Attention 模块输出的向量应该会激活 FFN 层中与之最匹配的记忆模式，从而作为下一个 Token 的向量表示。后续的操作需要在离散的词表中选择最有可能的那个 Token。在实际中可以设计多种采样策略来满足输出的要求，但背后的原理与通信接收机中的最大似然译码很类似。&lt;/p&gt;&lt;p&gt;简单起见，这里将采样操作表示成 argsoftmax (&amp;sdot;) 函数。令 &lt;img data-aistatus="1" data-imgfileid="503530807" data-ratio="0.7931034482758621" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfXAZ1IHhhY0AHViaGezTeluQjg3W50L4rNoyiayIXV2ckzq6I0QwxxibkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=58" data-type="png" data-w="58" type="block" data-original-style="width:32px;height:25px;" data-index="60" src="https://image.jiqizhixin.com/uploads/editor/5809c80a-cea4-495e-abb0-52916e4fb403/640.png" alt="图片" data-report-img-idx="58" data-fail="0" class="fr-fic fr-dii" style="width: 4.25%;"&gt;&amp;nbsp;为词表 &amp;Omega; 中的第 m 个 Token 的向量表示，那么 Transformer 的数学形式可以写为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfzoaQLuRRStWicsnLQ0GnC9s6BOWxe0v0JCty4iaccD1nnKcicV5QpAzOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=59" data-ratio="0.14907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530808" data-aistatus="1" data-original-style="width:488px;height:73px;" data-index="61" src="https://image.jiqizhixin.com/uploads/editor/d3e72bc8-9426-4a62-b837-b679173be621/640.png" alt="图片" data-report-img-idx="59" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 T 是温度。&lt;/p&gt;&lt;p&gt;实际上，上述模型可作以下推广&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530809" data-ratio="0.16574074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfEje1mFeSpFcSTOUnJW1o44njjx0mJN1FAYAxYj6lOuBYKOa1abyAmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=60" data-type="png" data-w="1080" type="block" data-original-style="width:503px;height:83px;" data-index="62" src="https://image.jiqizhixin.com/uploads/editor/c2e46064-13cf-483e-824a-dace74bed84e/640.png" alt="图片" data-report-img-idx="60" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 &amp;Psi; 为非线性函数，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficgemjeZ9ngGUe1b3k6RbH10ic5xG4Kpjj6DgTmAfckztSZDgqdVOU9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=61" data-ratio="0.9285714285714286" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530810" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="63" src="https://image.jiqizhixin.com/uploads/editor/d4eae2d2-7954-4dad-9c25-774c118f2595/640.png" alt="图片" data-report-img-idx="61" data-fail="0" class="fr-fic fr-dii" style="width: 3.29%;"&gt; 为时变参数矩阵。可见，Transformer 是更普遍的非线性时变向量自回归时间序列的一个特例。对 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficgemjeZ9ngGUe1b3k6RbH10ic5xG4Kpjj6DgTmAfckztSZDgqdVOU9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=62" data-ratio="0.9285714285714286" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530810" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="64" src="https://image.jiqizhixin.com/uploads/editor/ac4b54d1-8eb1-4030-9ec8-8eb158f79270/640.png" alt="图片" data-report-img-idx="62" data-fail="0" class="fr-fic fr-dii" style="width: 3.4%;"&gt;&amp;nbsp;进行其他分解或简化就能构造出新的 Attention 机制。例如，Mamba/Mamba2 是一种线性化的简化方式。由于线性 Attention 机制难以捕捉非对称语义相关性，其模型能力很自然地会受到很大影响。对 &amp;Psi; 也同样可以进行优化和修改，一种思路是用现代连续 Hopfield 网络来直接替换 FFN 模块[24]。另外，当前通过向量数据库和知识图谱等方式实现 RAG 也是通过改变 &amp;Psi; 来增强知识记忆的准确性和及时性[25]。&lt;/p&gt;&lt;p&gt;本系列的《统计物理篇》已经指出：大模型的能力极限是在预测下一个 Token 的任务上逼近人类水平的 Granger 因果推断。从时间序列的角度看，Granger 因果检测的主要作用就是分析两个序列之间与时间相关的统计关系。相关方法已经广泛应用于物理学、神经科学、社交网络、经济学和金融学等领域。回忆 Granger 因果的定义，令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqHZuXfCeJG0o4g89oOiaaUhtMUG3DhGVCj9K5FUGgetqnOaSKibwSSDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=63" data-ratio="0.15723270440251572" data-s="300,640" data-type="png" data-w="318" type="block" data-imgfileid="503530812" data-aistatus="1" data-original-style="width:165px;height:26px;" data-index="65" src="https://image.jiqizhixin.com/uploads/editor/d150af7b-a63c-41a5-bc41-09b1c6f32352/640.png" alt="图片" data-report-img-idx="63" data-fail="0" class="fr-fic fr-dii" style="width: 23.15%;"&gt;，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfNhVWublK9jOd0jkatMQj3tlZPwSsE4I3HGrXA9mdBZ9rv8n5NZmUQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=64" data-ratio="0.1889763779527559" data-s="300,640" data-type="png" data-w="254" type="block" data-imgfileid="503530814" data-aistatus="1" data-original-style="width:130px;height:25px;" data-index="66" src="https://image.jiqizhixin.com/uploads/editor/abcc69b0-cda4-412a-a8ff-9949ced2f6aa/640.png" alt="图片" data-report-img-idx="65" data-fail="0" class="fr-fic fr-dii" style="width: 17.52%;"&gt;，那么下面的不等式自然成立：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530816" data-ratio="0.07763975155279502" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfAdhHjh0qSN480e83mD6QMcdcESLdXZW4fJMluOsInky8fTmdJthhjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=65" data-type="png" data-w="644" type="block" data-original-style="width:386px;height:30px;" data-index="67" src="https://image.jiqizhixin.com/uploads/editor/2f433fb6-ca32-4bd5-9110-075793a66d92/640.png" alt="图片" data-report-img-idx="64" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;因此，从时间序列的角度看，大模型输入的 Token 序列和输出的 Token 序列符合 Granger 因果推断的定义。这进一步印证了第一篇的结论：&lt;strong&gt;大模型推理的本质，是通过预测下一个 Token 这一看似简单的训练目标，进而实现逼近人类水平的 Granger 因果推断。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信号处理与信息论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在引言中我们已经指出：大模型处理的是向量化后的 Token 序列，其本质是&lt;strong&gt;把传统基于概率的自然语言处理问题转换成了基于数值计算的信号处理问题&lt;/strong&gt;。从本文的讨论中可以看到，这种从 Token 到其向量表示的转化，与信息论和信号处理之间的关系非常类似。&lt;/p&gt;&lt;p&gt;具体来说，Shannon 信息论是一个基于概率论的理论框架，旨在理解信息压缩、传输和存储的基本原理及其性能极限，但它并不关注工程中的具体实现方法和复杂度。信号处理将信息论中的抽象符号表示为 n 维实 / 复空间中的向量。这种表示使得数值计算方法能有效应用于感知、通信和存储系统的高效算法设计中。可以说，信号处理是信息论原理在特定计算架构下的具体实现。&lt;/p&gt;&lt;p&gt;更广泛地看，我们经常用下图来表达计算理论和信息论之间的关系。图的左边是 Turing 和他的计算理论，他关心用多少个步骤能完成特定的计算，因此时延（通常用时间复杂度来度量）是最关键的指标。图的右边是 Shannon 和他的信息论，他关心的是通信速率的上限或者数据压缩的下限，即存在性和可达性。此时，通常假设码长趋于无穷大，因而时延是被忽略的。那么在实践中就会发现，开发通信算法的瓶颈永远是算力不够，算法复杂度太高；而研究计算算法的瓶颈永远都是（访存 / 卡间 / 服务器间）通信带宽不够，或者缓存 / 内存空间太小。&lt;/p&gt;&lt;p&gt;我们注意到，尽管计算理论和信息论有本质的不同，但他们最基本的操作单位都是 BIT，因此我们可以肯定地说：&lt;strong&gt;BIT 是连接计算和通信这两大领域的桥梁&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530817" data-ratio="0.5370370370370371" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfTVhVialRiaJicwv4BPDIibaMribkSdwssDpvkV7Gicb8nrrwicQkWic7ia3LmGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=66" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="68" src="https://image.jiqizhixin.com/uploads/editor/907a4aab-29e1-4988-969d-c48ea7cb1303/640.png" alt="图片" data-report-img-idx="66" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图：BIT 是连接计算理论和信息论的桥梁，是信息时代最伟大的发明。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;正如 5G Polar 码发明人，2019 年香农奖得主，Erdal Arikan 教授参加我们的圆桌论坛中所指出的：&lt;strong&gt;BIT 是信息时代最伟大的发明&lt;/strong&gt;。Shannon 在与 Weaver 合著的论文中也明确指出：信息论只解决了信息的可靠传输问题，即技术问题，而不考虑语义和语效[26]。但是人类已经进入了 AI 时代，信息论是否还能继续发挥其基础性作用？&lt;/p&gt;&lt;p&gt;我们将在本系列的第三篇《信息论篇》中看到，只要将核心概念从信息时代的 BIT 转换成 AI 时代的 TOKEN，Shannon 信息论就可以用来解释大模型背后的数学原理。&lt;/p&gt;&lt;section&gt;&lt;sup&gt;参考文献&lt;/sup&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;1. B. Bai, &amp;quot;Forget BIT, it is all about TOKEN: Towards semantic information theory for LLMs,&amp;quot; arXiv:2511.01202, Nov. 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;2. D. Koller and N. Friedman, Probabilistic Graphical Models: Principles and Techniques. Cambridge, MA, USA: The MIT Press, 2009.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;3. G. Hinton, &amp;quot;Learning distributed representations of concepts,&amp;quot; in Proc. 8th Annual Conference on Cognitive Science Society &amp;rsquo;86, Amherst, MA, USA, Aug. 1986.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;4. Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin, &amp;quot;A neural probabilistic language model,&amp;quot; Journal of Machine Learning Research, vol. 3, no. 2, pp. 1137-1155, Feb. 2003.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;5. S. Chung, D. Lee, and H. Sompolinsky, &amp;quot;Classification and geometry of general perceptual manifolds,&amp;quot; Physical Review X, vol. 8, no. 3, p. 031003, Jul. 2018.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;6. Y. Bahri, J. Kadmon, J. Pennington, S. Schoenholz, J. Sohl-Dickstein, and S. Ganguli, &amp;quot;Statistical mechanics of deep learning,&amp;quot; Annual Review of Condensed Matter Physics, vol. 11, no. 3, pp. 501-528, Mar. 2020.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;7. https://ann-benchmarks.com&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;8. H. Luhn, &amp;quot;A new method of recording and searching information,&amp;quot; American Documentation, vol. 4, no. 1, pp. 14&amp;ndash;16, Jan. 1953.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;9. T. Mikolov, K. Chen, G. Corrado, and J. Dean, &amp;quot;Efficient estimation of word representations in vector space,&amp;quot; arXiv: 1301.3781, 7 Sep. 2013.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;10. T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, &amp;quot;Distributed representations of words and phrases and their compositionality,&amp;quot; Proc. 27th Annual Conference on Neural Information Processing Systems &amp;#39;13, Lake Tahoe, NV, USA, Dec. 2013.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;11. D. Jurafsky and J. Martin, Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models, 3rd ed. Draft, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;12. M. Gromov, Metric Structures for Riemannian and Non-Riemannian Spaces. Boston, MA, USA: Birkh&amp;auml;user, 2007.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;13. C. Villani, Optimal Transport: Old and New. New York, NY, USA: Springer, 2009.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;14. D. Alvarez-Melis and T. Jaakkola, &amp;quot;Gromov-Wasserstein alignment of word embedding spaces,&amp;quot; in Proc. ACL Conference on Empirical Methods in Natural Language Processing &amp;rsquo;18, Brussels, Belgium, Oct. 2018, pp. 1881&amp;ndash;1890.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;15. T. Landauer, P. Foltz, and D. Laham, &amp;quot;An introduction to latent semantic analysis,&amp;quot; Discourse Processes, vol. 25, no. 2-3, pp. 259-284, Jan. 1998.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;16. W. Johnson, J. Lindenstrauss, and G. Schechtman, &amp;quot;Extensions of Lipschitz maps into Banach spaces,&amp;quot; Israel Journal of Mathematics, vol. 54, no. 2, pp. 129-138, Jun. 1986.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;17. A. Oord, Y. Li, and O. Vinyals, &amp;quot;Representation learning with contrastive predictive coding,&amp;quot; arXiv: 1807.03748, Jan. 2019.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;18. P. Elias, &amp;quot;Predictive coding - Part 1,&amp;quot; IRE Transactions on Information Theory, vol. 1, no. 1, pp. 16-24, Mar. 1955.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;19. P. Elias, &amp;quot;Predictive coding - Part 2,&amp;quot; IRE Transactions on Information Theory, vol. 1, no. 1, pp. 24-33, Mar. 1955.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;20. B. Poole, S. Ozair, A. Oord, A. Alemi, and G. Tucker, &amp;quot;On variational bounds of mutual information,&amp;quot; in Proc. 36th International Conference on Machine Learning &amp;rsquo;19, Long Beach, CA, USA, Jun. 2019, pp. 5171-5180.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;21. J. Massey, &amp;quot;Causality, feedback and directed information,&amp;quot; in Proc. IEEE International Symposium on Information Theory &amp;rsquo;90, Waikiki, HI, USA, Nov. 1990.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;22. S. Peng, Nonlinear Expectations and Stochastic Calculus under Uncertainty: with Robust CLT and G-Brownian Motion. Berlin, Germany: Springer, 2019.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;23. H. L&amp;uuml;tkepohl, New Introduction to Multiple Time Series Analysis. Berlin, Germany: Springer, 2007.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;24. H. Ramsauer et al., &amp;quot;Hopfield networks is all you need,&amp;quot; arXiv: 2008.02217, Apr. 2021.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;25. Y. Xia et al., &amp;quot;ER-RAG: Enhance RAG with ER-based unified modeling of heterogeneous data sources,&amp;quot; arXiv: 2504.06271, Mar. 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;26. W. Weaver and C. Shannon, &amp;quot;Recent contributions to the mathematical theory of communications,&amp;quot; The Rockefeller Foundation, Sep. 1949.&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
