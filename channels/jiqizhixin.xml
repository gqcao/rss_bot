<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>顶尖模型离“科学家”还差得远？AI4S亟待迈向2.0时代</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 18:57:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;当前，科学智能（AI for Science）被称之为人工智能的 &amp;ldquo;皇冠&amp;rdquo;，以 AlphaFold 为代表的 AI for Science（AI4S）技术在蛋白质折叠、气象预测等特定领域取得了里程碑式成就，但近期《Nature》发表的研究指出，过度依赖现有深度学习模型可能局限新知识的探索边界，甚至在某种程度上阻碍创新。&lt;/p&gt;&lt;p&gt;一项来自上海人工智能实验室（上海 AI Lab）的系统性评估①进一步揭示了当前前沿模型的短板。来自 10 个不同科学领域的 100 位科学家为模型构建了评测题目，结果显示：前沿模型在通用科学推理任务中得分可达 50 分（满分 100），但在各类专业推理任务（如专项文献检索、具体实验方案设计）中，得分骤降至 15-30 分。&lt;/p&gt;&lt;p&gt;&amp;ldquo;我们已身处 &amp;ldquo;通用人工智能&amp;rdquo;（AGI）前夕，但仍面临重要环节的缺失 &amp;mdash;&amp;mdash; 通专融合的智能。&lt;strong&gt;我们亟需推动科学智能从 1.0 向 2.0 迭代，即从 AI4S 迈向 AGI4S。&amp;rdquo; &lt;/strong&gt;日前，上海人工智能实验室主任、首席科学家周伯文在第四十届人工智能协会年会（AAAI 2026）发表特邀报告时提出，科学发现是 AI 的下一个前沿阵地 &amp;mdash;&amp;mdash; 它既是推理智能的终极试炼场，也是 &amp;ldquo;通专融合 AGI&amp;rdquo; 的验证舞台。若 AGI = 通专融合（Specialized Generalist），则可深度专业化通用模型（Specializable Generalist）是实现 AGI 的可行路径。&lt;/p&gt;&lt;p&gt;除了分享前沿观点，周伯文还详细介绍了上海 AI 实验室近年来开展的前沿探索与实践，包括驱动 &amp;ldquo;通专融合&amp;rdquo; 发展的技术架构 &amp;mdash;&amp;mdash;&amp;ldquo;智者&amp;rdquo;SAGE（Synergistic Architecture for Generalizable Experts），其包含基础、融合与进化三个层次，并可双向循环实现全栈进化；支撑 AGI4S 探索的两大基础设施&amp;ldquo;书生&amp;rdquo;科学多模态大模型 Intern-S1、&amp;ldquo;书生&amp;rdquo;科学发现平台 Intern-Discovery 及一系列相关阶段性进展。&lt;/p&gt;&lt;p&gt;演讲最后，周伯文向会场内外的观众发出行动召唤：架构已经就绪，但画卷仍存大片留白，期待与更多同行者共拓蓝图！&lt;/p&gt;&lt;p&gt;以下为报告全文，略有修订。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcPdo381GHPjYXhSdaGB5Ba3uHn8dianRJDSjzI2Mzg8LpaUJ4oKnZQHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7497546614327772" data-s="300,640" data-type="png" data-w="1019" type="block" data-imgfileid="503530963" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f810c8fc-e7e4-4b7a-95d7-0ba865519c50/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;演进预判：从 ANI 到 AGI 的历史跨越&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人工智能的发展历程并非线性堆叠，而是呈现出明显的阶段性跃迁。回顾 AI 发展的历史坐标，有助于我们厘清当前所处的位置及未来的方向。&lt;/p&gt;&lt;p&gt;早在 1996 年涉足 AI 研究之初，我便开始思考智能的本质。特别是在担任 IBM 人工智能基础研究院院长期间，首次提出了通往通用人工智能（AGI）的战略路线图，明确界定了 AI 发展的三个关键阶段：ANI（狭义人工智能）、ABI（广义人工智能）与 AGI，并给出了各自明确定义。&lt;/p&gt;&lt;p&gt;我当时的判断是 ANI 在 2016 年已趋于成熟，而通往 AGI 的必经之路并非直接跃迁，而是必须率先实现具备跨领域泛化能力的 ABI。我们认为这一跨越需要技术范式的根本性变革，最少包括三个方面：即从有监督学习转向自监督学习，从人类分割任务级联式系统转向端到端架构，从判别式工具进化为生成式助手。&lt;/p&gt;&lt;p&gt;六年多后 ChatGPT 的问世，第一次验证了人工智能系统在以上三方面的同时达成，实质上宣告了 ABI 阶段的到来。这一历史性突破验证了规模法则（Scaling Law）的有效性 &amp;mdash;&amp;mdash; 即通过扩大 Transformer 架构并将 &amp;ldquo;下一个词预测&amp;rdquo; 作为优化目标，人类首次实现了对世界知识的压缩。值得一提的是，我和团队早在 2016 年提出的关于 &amp;ldquo;多头自注意力&amp;rdquo; 机制的研究，作为 &amp;ldquo;与下游任务无关&amp;rdquo;（也就是 &amp;ldquo;预训练&amp;rdquo;）的自然语言长上下文压缩表征的首批成果之一，被开创性的 Transformer 论文引用与认可②，为这一预训练时代的压缩智能奠定了重要的理论基石。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcQbdxx5ISfROjDhP4Eqa6lT56pbHHib66ZaFXvTDGAtZGNXXUZ7juw5w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5635294117647058" data-s="300,640" data-type="png" data-w="850" type="block" data-imgfileid="503530964" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/71ad49b3-f9f1-466a-bbbf-b44516fd715c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcL1ogo1YSyzRVxaUm2aXg7rQIfzUBpW6OHObErdwtORoIkQLnHOV2Aw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5629791894852135" data-s="300,640" data-type="png" data-w="913" type="block" data-imgfileid="503530965" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d6f9dfc9-b462-4610-b164-cfa62025a67b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 重访路线图（2016 年）：通往 AGI 之路&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;战略路径：通专融合与科学发现的终极试炼&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着 Scaling Law 赋予了大语言模型广泛的泛化能力（ABI），在 2023 年初我们提出了一个关键的战略设问：通往 AGI 的下一步，仅仅是计算量的堆叠吗？对这些设问的思考促使我在 2023 年提出了&lt;strong&gt; &amp;ldquo;通专融合&amp;rdquo; 路径&lt;/strong&gt;。核心思想是如何动态实行融合人类认知思维的系统 1 和系统 2，以应对各种现实世界的任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重新定义 AGI 之路&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去 70 年 AI 的发展长期在 &amp;ldquo;专业性&amp;rdquo; 与 &amp;ldquo;通用性&amp;rdquo; 两个维度上分别进展。以 AlphaFold 为代表的早期系统是极致的 &amp;ldquo;专家&amp;rdquo;，在特定领域超越人类却缺乏迁移能力；而当前的大语言模型则是博闻广识的 &amp;ldquo;通才&amp;rdquo;，虽具广度但在处理复杂专业任务时往往难以企及专家深度和缺失关键细节。&lt;strong&gt;真正的 AGI 必须打破这种二元对立，构建一种能够动态融合 &amp;ldquo;系统 1&amp;rdquo;（直觉式快思考）与 &amp;ldquo;系统 2&amp;rdquo;（逻辑式慢思考）的智能架构 &amp;mdash;&amp;mdash; 即在保持通用认知基座的同时，能够在任意特定任务上通过持续学习与深度推理实现专家级的专精&lt;/strong&gt;（阐述这一思路系统的立场论文已于 2024 年在 ArXiv 上发表）③。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcwEZ7DXtCnZYeRv99gGW1TYmIBq5Q2EKdDsuIcsU5sfgPat1gy4Nydw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5621414913957935" data-s="300,640" data-type="png" data-w="1046" type="block" data-imgfileid="503530966" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3c9d53cb-28a2-4e2e-b6b3-c64c0392ff06/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2024 年末 OpenAI o1 与 2025 年初 DeepSeek-R1 的出现，通过在大模型之上应用强化学习显著提升逻辑推理能力，有力地验证了关于 &amp;ldquo;通专融合&amp;rdquo; 路径预判的正确性。2025 年 10 月，约书亚・本吉奥教授等人提出了 AGI 的定义，将其分解为十种核心通用能力以及众多狭义的专业能力。若能全面达成这些能力，即意味着实现了 AGI。这一定义与我们&lt;strong&gt; &amp;ldquo;通专融合是通往 AGI 的战略路径&amp;rdquo;&lt;/strong&gt; 的观点高度吻合 &amp;mdash;&amp;mdash; 这表明该路径正日益成为整个学术社区的普遍共识。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;科学发现：推理智能的终极前沿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下一个前沿领域是什么？我认为是&lt;strong&gt;科学发现（Scientific Discovery, SD）&lt;/strong&gt;。在我看来，除了科学智能（AI for Science, AI4S）所承诺的治愈癌症等诸多益处之外，&lt;strong&gt;科学发现更是推理智能的终极考验，因此也是 AI 探索的绝对前沿&lt;/strong&gt;。科学发现是已知与未知之间复杂的相互作用，涵盖了从假设生成、实验验证到理论总结的全过程。其对 AI 提出了三重极限挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;已知的未知：典型的如组合爆炸，比如分子设计或材料科学的搜索空间高达 10^60 量级，远超传统遍历能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;未知的未知：科学探索本质上是对分布外（OOD）知识的泛化，是对模型创造力的真正考验；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;稀疏与延迟奖励：科学实验的周期长、反馈慢，是对强化学习算法的严峻测试④。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，科学发现不仅是 AI 的最佳应用场景，更是驱动 &amp;ldquo;通专融合&amp;rdquo; 迈向 AGI 的根本动力。&lt;/p&gt;&lt;p&gt;接下来，我想分享我们为应对这一挑战提出的技术架构 &amp;mdash;&amp;mdash;&amp;ldquo;智者&amp;rdquo;SAGE。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术架构：递归循环的通用专家协同架构&amp;ldquo;智者&amp;rdquo;SAGE&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为将 &amp;ldquo;通专融合&amp;rdquo; 战略转化为可落地的技术方案，上海 AI 实验室在 2024 年提出了&lt;strong&gt;&amp;ldquo;智者&amp;rdquo;SAGE 架构&lt;/strong&gt; &amp;mdash;&amp;mdash; 其并非若干模型的简单堆砌，而是一个旨在弥合广泛泛化与深度专精鸿沟的统一认知生态系统⑤。该架构由三个逻辑耦合的层次构成：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;底部的&lt;strong&gt;基础模型&lt;/strong&gt;&lt;strong&gt;层&lt;/strong&gt;致力于结构上的重构，通过将知识储备与推理能力解耦，为高阶因果推理提供更灵活的 &amp;ldquo;画布&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中间的&lt;strong&gt;融合协同&lt;/strong&gt;&lt;strong&gt;层&lt;/strong&gt;通过密集过程奖励机制，动态协调直觉式 &amp;ldquo;快思考&amp;rdquo; 与逻辑性 &amp;ldquo;慢思考&amp;rdquo;，精准把控泛化与专精的节奏；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;顶层的&lt;strong&gt;探索进化层&lt;/strong&gt;则赋予 AI 主动能动性，完成从被动数据拟合到主动环境探索的范式转变。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;至关重要的是，SAGE 绝非静态的架构，而是一个递归运行的活体生态。它通过双向循环实现全栈进化：一方面，底层解耦的表征自下而上地支撑推理策略的生成；另一方面，顶层主动发现获得的高水平反馈自上而下回流，将探索中的 &amp;ldquo;未知&amp;rdquo; 转化为新的训练信号。这种闭环机制确保了 SAGE 不仅能实现模型参数的优化，更能推动认知策略本身的持续进化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcBpOsFh81w6lMEgyUXSIwICk0KqZXWNbHiaxab6VrMo4m3sD6ibP3A2xg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5612353567625133" data-s="300,640" data-type="png" data-w="939" type="block" data-imgfileid="503530967" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/547c9211-67d2-4a11-bfb5-6d2c448c4d27/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 递归循环的通专融合技术架构&amp;ldquo;智者&amp;rdquo;（SAGE）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基础模型层：知识与推理的解构与动态耦合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SAGE 的底层致力于解决现有 LLM 将 &amp;ldquo;事实记忆&amp;rdquo; 与 &amp;ldquo;逻辑推理&amp;rdquo; 混淆的问题。以记忆解码器（Memory Decoder）⑥为例，它针对性地解决了现有大模型架构的两大顽疾：一是检索增强生成（RAG）在长文本语境推理中存在的显著延迟与高昂工程成本；二是领域自适应全参数微调所带来的算力消耗及灾难性遗忘风险。&lt;/p&gt;&lt;p&gt;作为一种预训练、即插即用的独立组件，记忆解码器创新性地采用与基础模型并行运行并融合输出分布的机制。它首次用紧凑的参数化模型替代了传统非参数检索器，在无需修改基础模型参数、无在线检索开销的前提下，实现了高效的知识注入。实验数据显示，其推理开销仅为基础模型的 1.28 倍，显著低于现有主流方案。这一设计成功填补了 &amp;ldquo;高密度知识供给&amp;rdquo; 与 &amp;ldquo;推理引擎解耦&amp;rdquo; 之间的技术鸿沟，在 SAGE 框架中实现了推理能力与长期记忆的 &amp;ldquo;解耦但可集成的推理与知识&amp;rdquo;，同时强化了 &amp;ldquo;长期记忆&amp;rdquo; 能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcnAtGvsnTGYHVcGN5gBro2xdtMU4VugZvbA95O7nqzTA8tFPpicg2qyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530969" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0fa06d80-e322-4868-b162-bd100a67c2de/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcJWDYYlUyZCtB7HyEbibCMgD068DXSSxOB78SYywHKvEe1RQicpROtuyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530970" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/1c202a36-25ca-4760-ba27-f232d52b9e28/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc95icLXjPJbmr4vwGrErvaeCVX4RvGjf33ZfEkd9ZoGiaQDCCyzXUteFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530971" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/989053b6-cb34-48a2-846a-7cd9c69b9dc0/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 记忆解码器：面向大语言模型的预训练、即插即用记忆体&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习：连接基础层与进化层的纽带&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习（RL）是连接 SAGE 基础层与融合层、进化层的纽带，也是实现 &amp;ldquo;通专融合&amp;rdquo; 的核心动力之一。&lt;/strong&gt;回顾其演进历程，RL 经历了从早期封闭环境下的博弈（如 AlphaGo），演进至通过 RLHF 实现人类偏好对齐，目前正处于以 o1 和 DeepSeek-R1 为代表的可验证推理（RLVR）阶段，并终将迈向面向物理世界与科学发现的开放式体验学习新纪元。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc91C8l88g1DywnMYqJibIuPAia72LfJlCA3IPGE79zt2Ed0yqsEibkY9AA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5613861386138614" data-s="300,640" data-type="png" data-w="1010" type="block" data-imgfileid="503530972" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ad436bc3-84d2-41a8-909c-9d0aab8753f2/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc8ic1FcuSzogicN3FTXq1awDGbz8QjvYKVKY7iat8xlC6ib5zSAayRaXW1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5620723362658846" data-s="300,640" data-type="png" data-w="1023" type="block" data-imgfileid="503530974" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/2a94ee4e-18f3-4217-a2ec-3b96f11d24eb/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 适用于可通专融合的强化学习及其三大支柱&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在微观机制上，RL 被归纳为三大支柱：&lt;strong&gt;奖励设计&lt;/strong&gt;作为 &amp;ldquo;指南针&amp;rdquo;，通过稀疏或密集信号界定模型专精的目标；&lt;strong&gt;策略优化&lt;/strong&gt;作为 &amp;ldquo;引擎&amp;rdquo;，涵盖从 PPO 到 GRPO 的算法迭代，驱动模型高效更新；&lt;strong&gt;采样与探索&lt;/strong&gt;则决定了模型在庞大搜索空间中的导航路径⑦。&lt;/p&gt;&lt;p&gt;鉴于不同任务对 RL 配置的需求各异，构建系统的核心技术挑战在于统一：我们如何将多样性的最佳的奖励机制、策略优化与采样探索整合为一个协调一致的系统，从而打造出真正的 &amp;ldquo;可深度专业化通用模型&amp;rdquo;？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;融合协同层：强化学习驱动的深度推理进化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 SAGE 架构中，融合协同层承载着协调 &amp;ldquo;直觉快思考&amp;rdquo; 与 &amp;ldquo;逻辑慢思考&amp;rdquo; 的核心职能，而强化学习（RL）则是实现这一动态协同的关键桥梁。为了构建一个真正的 &amp;ldquo;可深度专业化通用模型&amp;rdquo;，必须克服传统 RL 在复杂推理任务中面临的三大核心挑战：高昂的监督成本、训练过程中的熵坍缩以及单一路径的模式崩溃。为此，我们在该层引入了三项具有范式意义的算法创新，旨在构建密集的奖励机制、维持持续的探索能力以及激发推理路径的多样性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;隐式奖励强化学习算法（PRIME）：突破高密度监督的成本悖论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;高度专家化的模型与人类专家在学习机制上具有相似性：&lt;strong&gt;专家化模型在训练过程中需要更密集的反馈信息&lt;/strong&gt;。对于 &amp;ldquo;通专融合&amp;rdquo; 大模型而言，要解决科学发现中的长链条推理问题，仅依赖最终结果的稀疏奖励往往捉襟见肘，模型急需密集的逐步监督信号。然而，传统的解决方案依赖于过程奖励模型（PRM），这要求对海量推理步骤进行人工细粒度标注，其成本之高昂，使得规模化扩展几乎成为不可能。&lt;/p&gt;&lt;p&gt;针对这一 &amp;ldquo;高密度监督需求&amp;rdquo; 与 &amp;ldquo;高昂标注成本&amp;rdquo; 之间的矛盾，我们提出了 PRIME 算法⑧ ，旨在从理论层面推导并获取 &amp;ldquo;免费&amp;rdquo; 的过程奖励。其核心洞察在于，利用策略模型与参考模型之间的统计差异。通过将模型训练目标设定为基于两者对数似然比的结果奖励模型，我们从数学方面证明，该模型能够隐式地习得 Q 函数。这意味着，智能体在无需显式训练庞大的 PRM 模型的情况下，即可在推理的每一个步骤中，通过计算动作在当前状态下的优劣，直接推导出密集的、逐步的奖励信号。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcx5skGrHMDwzXHdlL7ULI5u5oQNiatfoDxENLm99ZM7s710JlQjEANibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530975" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/7657ba60-3fcf-4a3e-9142-f8881711fe92/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcvP8o3gUrfrtzOfJDQn8T83ibIicTDzsPQr7l4w3icN67bF5iaFJ2veWEuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530976" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/6933a346-946b-4e2f-941c-4b8c9a562482/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 隐式奖励强化学习算法（PRIME）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一创新带来了多维度的显著优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;计算效率的飞跃&lt;/strong&gt;：与 Math-Shepherd 等依赖独立 PRM 模型的方法相比，PRIME 在推理阶段无需额外的模型调用开销，直接利用生成模型本身的概率分布即可获得反馈，极大地提升了计算效率；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;系统架构的可扩展性&lt;/strong&gt;：在 SAGE 的系统实现中，PRIME 方案展现出极强的工程韧性。我们将策略模型与隐式 PRM 进行联动，依托结果验证器和前序步骤产出的自由过程奖励，构建了高效的在线更新闭环；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致的数据效率&lt;/strong&gt;：实验表明，PRIME 方案仅需 SOTA 模型 1/10 的训练数据量，即可达到相当的性能水平，极大地降低了对高质量标注数据的依赖。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基准测试结果有力地验证了 PRIME 的有效性：在 AIME 2024 数据集上，模型准确率提升了 23.4%；在 AMC 数据集上提升了 27.7%；在 MATH-500 等权威测试中也取得了显著增长。&lt;strong&gt;这一系列数据充分证明，通过隐式机制构建的稠密奖励，能够有效驱动模型突破复杂推理的瓶颈。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习的熵机制：避免 &amp;ldquo;过度自信&amp;rdquo; 导致探索止步&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;专家化模型的训练不仅需要反馈，更需要持续不断的学习。&lt;/strong&gt;在深入研究用于推理的强化学习时，我们揭示了一个阻碍模型进化的根本性障碍 &amp;mdash;&amp;mdash; &lt;strong&gt;熵坍缩&lt;/strong&gt;。通俗地讲，这等同于解决如何让通用模型在专家化的过程中，始终保持探索与好奇心，让模型和顶级人类专家一样在专业问题的挑战上避免过早过分自信，而是 &amp;ldquo;stay hungry, stay foolish&amp;rdquo;（求知若饥，虚心若愚）。&lt;/p&gt;&lt;p&gt;在训练过程中，随着模型性能的初步提升，策略熵往往会急剧下降。这种下降意味着模型对其输出的置信度快速提高，导致其过早地收敛于局部最优解，从而丧失了探索更优推理路径的可能性。实验数据显示，熵的消耗主要集中在训练的前数百步，此后模型的性能提升便迅速进入边际效益递减阶段。这种现象极似人类认知中的 &amp;ldquo;过度自信&amp;rdquo;，即因自满而停止了对问题细微差异的主动探索 &amp;mdash;&amp;mdash; 而这种主动探索，恰恰是通用模型进化为能捕捉深层规律的 &amp;ldquo;专精模型&amp;rdquo; 的关键所在。&lt;/p&gt;&lt;p&gt;为了解决这一问题，我们深入探究了熵与奖励之间的权衡机制，并发现了一个关键的定量关系：&lt;strong&gt;验证性能（R）与熵（H）呈现显著的对数线性相关&lt;/strong&gt;⑨。这一简洁而深刻的结论为训练方案的优化指明了方向：构建可扩展推理 RL 框架的难点，不在于单纯堆砌训练时长，而在于对熵消耗的精细化管理，确保模型在训练全周期内保留足够的不确定性，以驱动持续的探索。&lt;/p&gt;&lt;p&gt;我们提出了一种精准化、局部化且轻量化的熵控制方案：针对这类标记开展选择性调控（如采用 Clip-Cov、KL-Cov 等方法），能够达成局部、轻量的熵控制效果，既保障模型探索性不受损，又不会干扰正常优化流程。该方法实现了对熵的局部控制，既保障了模型的探索性不受损，又避免了对正常优化流程的干扰。应用该策略后，模型在保持高探索能力的同时，显著提升了下游任务的准确率。这一方法已被实验室的&amp;ldquo;书生&amp;rdquo;科学多模态大模型 Intern-S1 等多个头部机构采纳应用，其相关成果更由斯坦福 Yejin Choi 教授在 2025 年神经信息处理系统大会（NeurIPS）上进行了重点阐述。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcd0ScsCicUKYLcObtvz4YGLdHMDWc74RBf0UOkJRMugpjeYAjn3ptzNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530977" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/7193f2d7-4ee7-4541-bff1-95bbaff98501/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcORV0tOtdKX88cCrcSZoorwjSGuquavHibGZScib5icZBGt3QP58NZYSibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.5648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530978" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/b4dcb23f-ad8a-4480-b8c9-01df89450978/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 强化学习的熵机制&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;匹配大语言模型推理的奖励分布（FlowRL）：实现专家化模型能力多元化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真正的专家不仅能解决问题，更能能为同一个问题提供多种解决方案，专家化模型亦是如此。&lt;/strong&gt;然而，现有的标准强化学习方法（如 PPO、GRPO）普遍以 &amp;ldquo;奖励最大化&amp;rdquo; 为单一目标。这种导向在复杂推理任务中极易导致&lt;strong&gt;模式崩溃&lt;/strong&gt;，即模型倾向于反复收敛至单一的、已知的成功路径，而忽略了其他潜在的更优解或多样化解法。&lt;/p&gt;&lt;p&gt;传统 RL 方法生成的分布与目标分布之间的 KL 散度高达 8.68，表现为极端的尖峰，意味着模型探索空间的极度狭窄。为了赋予模型真正的专家级思维多样性，我们在融合层引入了 &lt;strong&gt;FlowRL&lt;/strong&gt;⑩，这是一项借鉴生成流网络（GFlowNets）思想的创新工作，&lt;strong&gt;标志着强化学习优化逻辑的范式转变&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;FlowRL 的核心在于将学习目标从 &amp;ldquo;奖励最大化&amp;rdquo; 重构为 &amp;ldquo;分布匹配&amp;rdquo;。模型不再仅仅追逐单一的高分答案，而是致力于学习所有有效推理路径的概率分布。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;分布拟合：FlowRL 生成的分布能够捕捉目标分布中的绝大多数概率质量，拟合多个模态。如左侧平滑曲线所示，其 KL 散度大幅降低至 0.11，显著优于传统方法；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多样性生成：习得的策略在推理过程中能够自然地促进更多样化路径的生成，从而在面对 &amp;ldquo;未知的未知&amp;rdquo; 时具备更强的鲁棒性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;案例显示，在处理同一道数学推理题时，GRPO 模型陷入了思维死循环，推理过程重复且最终未能求解；而 FlowRL 模型则成功探索了多样化的推理路径，最终得出了正确答案 721。&lt;/p&gt;&lt;p&gt;整体实验结果进一步证实了 FlowRL 的优越性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;准确率提升：在 32B 模型的训练条件下，FlowRL 在数学推理任务中取得了 48.39% 的准确率，较 GRPO 提升 10 个百分点，较 PPO 提升 5.1 个百分点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;竞赛级表现：基于纯开源数据训练后，FlowRL 在 CodeForces 平台的评级达到 1549 分，性能直逼 o1-preview 水平；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多样性倍增：FlowRL 生成的解决方案多样性评分高达 2.28，约为 PPO 的 2 倍。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcE8u1LPQKXgZnSabyuKicMk0HEma1UoYdTq9UibPMTx9a4Q6SmiamHDnWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530979" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/6386a063-b79c-4de5-b089-e38a0fbadd8d/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcN95kbgXYM333IkicmBFyrxrLCP85KAQH6nJTVichDMszHJ7YIYfN5pNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.5611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530980" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/67352df6-a013-4058-af26-b5ea0f8d7895/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 匹配大语言模型推理的奖励分布（FlowRL）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;探索进化层：从被动拟合到主动认知探索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SAGE 架构的顶层探索进化层承载着通往 AGI 最关键的愿景 &amp;mdash;&amp;mdash; 打造一个具备自演化能力的 &amp;ldquo;可深度专业化通用模型&amp;rdquo;。这一层的核心挑战在于，如何让通用模型不仅在单一任务上实现深度专精，更能在大规模任务集乃至复杂的物理世界中，通过持续的交互与反馈实现自我迭代。为了应对这一挑战，我们从&lt;strong&gt;信号（Signal）、规模（Scale）&lt;/strong&gt;与落&lt;strong&gt;地（Ground）&lt;/strong&gt;三个关键维度出发，构建了一套完整的进化机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信号维度：测试时强化学习（TTRL）与自我进化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在推理测试阶段，模型面临的最大困境在于训练数据与测试数据之间的分布偏移。一旦失去真实标签的引导，传统模型便停止了学习步伐。然而，真正的 &amp;ldquo;专家&amp;rdquo;&amp;mdash;&amp;mdash; 如同人类物种一样 &amp;mdash;&amp;mdash; 应当具备在任何未知境况下持续学习适应的能力。&lt;/p&gt;&lt;p&gt;针对这一痛点，我们提出了&lt;strong&gt;测试时强化学习（Test-Time Reinforcement Learning, TTRL）框架&lt;/strong&gt;⑪ ，其核心洞察建立在一个简洁的假设之上：共识即意味着正确性（Consensus implies correctness）。&lt;/p&gt;&lt;p&gt;具体而言，TTRL 在推理过程中对多个候选解决方案进行采样，并将多数投票的结果作为 &amp;ldquo;代理奖励&amp;rdquo;，进而利用测试数据流直接对模型参数进行在线更新。这一方法在技术实现上具备极致的轻量化特性，仅需不到 20 行代码，即可将任何推理轨迹转化为有效的训练信号，实现了模型在无监督环境下的 &amp;ldquo;自我举证&amp;rdquo; 与 &amp;ldquo;自我增强&amp;rdquo;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcMpfIz5NDUbp62eI3viaFqUReBwkWOlSjXTKoorFviaMAAm7hGourUQ1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530981" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/dda0ea6c-40de-4ce0-8e67-dafeeaef16d3/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 测试时强化学习与自我进化（TTRL）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实测数据验证了 TTRL 的惊人潜力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能跃升&lt;/strong&gt;：在 AIME 2024 数据集上，搭载 TTRL 的 Qwen-2.5-Math-7B 模型准确率实现了 159% 的相对提升；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自我超越&lt;/strong&gt;：TTRL 优化后的模型展现出了 &amp;ldquo;青出于蓝&amp;rdquo; 的特性，其性能不仅超越了自身的 &amp;ldquo;最优 N 采样&amp;rdquo; 基准线，甚至逼近了使用带真实标签训练的理论上限（Oracle 基线）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;强泛化性&lt;/strong&gt;：在 AMC、MATH-500 等未见过的权威基准测试中，模型同样表现出强劲的泛化能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TTRL 的成功证明了智能体具备自主螺旋式上升的成长潜力，为 SAGE 架构中的自我进化提供了一条简洁高效的路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规模维度：InternBootcamp 与任务扩展定律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在解决了 &amp;ldquo;怎么学&amp;rdquo; 的信号问题后，必须回答 &amp;ldquo;在哪学&amp;rdquo; 的规模问题。通专融合模型不仅需要在单一任务上通过 &amp;ldquo;慢思考&amp;rdquo; 实现专精，更需要在成百上千个任务上同时实现能力适配。此外，我们还希望探索一个更深刻的问题：当测试任务的数量与多样性同步扩增时，是否存在专门针对在测试环境下、针对任务数量的 Scaling Law？&lt;/p&gt;&lt;p&gt;为此，我们研发了大规模、标准化、可扩展的交互验证环境 &amp;mdash;&amp;mdash;&lt;strong&gt;InternBootcamp &lt;/strong&gt;⑫。&lt;/p&gt;&lt;p&gt;作为首个覆盖 8 大任务类别、超 1000 种多样化环境的平台，InternBootcamp 支持在指定环境中开展大规模强化学习训练。其独特的 &amp;ldquo;任务与验证函数自动生成&amp;rdquo; 能力，使得用户能够便捷地将电路设计等专业领域任务转化为可验证环境，通过仿真手段完成结果核验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcLTsZ9gczrkvtCWia4rEHubAA3mhgnQJJCZRvKIBL7xDoPppkEu7vJVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.5611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530982" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/293e682d-f975-4e3b-a1e1-013eb2a90efb/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; InternBootcamp 覆盖 8 大任务类别、超 1000 种多样化任务环境&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;基于 InternBootcamp 的实验揭示了两个重要现象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;能力的 &amp;ldquo;涌现&amp;rdquo;&lt;/strong&gt;：在 BootcampEVAL 评测集中，Qwen2.5-32B 模型的平均性能实现了翻倍式增长（从 24.4 提升至 59.5）。更为关键的是，部分在单任务训练下无法解决的逻辑任务，在经过 500 余项混合任务训练后变得可解。这证实了任务间的隐性关联能够有效增强模型的综合理解能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;任务扩展定律&lt;/strong&gt;：实验数据显示，当任务类型数量从 8 种扩展至 512 种时，模型性能呈现持续上升趋势。这一结果证实了与任务数量增长相关的规模化定律真实存在，为未来大规模训练提供了理论依据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;落地维度：SimpleVLA-RL 与具身智能演进&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;进化的终局，是回归物理世界。当前具身智能面临的核心瓶颈是数据匮乏：机器人演示数据获取成本极高，且单纯扩大监督微调（SFT）规模面临边际效益递减。我们认为，强化学习（RL）凭借其突破演示数据局限的探索能力，结合简单的二元奖励（成功 / 失败），足以成为解决这一问题的钥匙。&lt;/p&gt;&lt;p&gt;基于此，我们提出了极端数据稀缺情况下的在线强化学习框架 &amp;mdash;&amp;mdash;&lt;strong&gt;SimpleVLA-RL &lt;/strong&gt;⑬。该框架基于视觉 - 语言 - 动作（VLA）模型，结合 GRPO 优化目标，并通过并行多环境渲染技术支持交互式轨迹采样。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcRoicvHvZGRh6zzYXJaN8WcYPbSH7ra92er48JRswUZ84PqX9RzOVFQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530983" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/c70e846b-a552-4a7a-a5af-1c8e7aa7fc7f/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 极端数据稀缺情况下的在线强化学习框架 SimpleVLA-RL&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实验结果颠覆了对数据效率的传统认知：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;超高数据效率&lt;/strong&gt;：仅需 &amp;ldquo;单轨迹&amp;rdquo; 监督微调结合 RL，即可实现 96.9% 的成功率，性能反而超越了全轨迹监督微调；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;策略涌现&lt;/strong&gt;：机器人通过 RL 自主探索出了从未被演示过的全新推控策略，展现出强大的适应性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sim-to-Real 突破&lt;/strong&gt;：在叠碗等典型操作任务中，仿真到现实的迁移成功率提升了 21%；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长时程任务能力&lt;/strong&gt;：在近期落地中，该方案在长时程灵巧操作任务上，实现了相对性能提升 300%，并展现出令人惊喜的自主恢复能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;得益于 SimpleVLA-RL，我们仅用极少的数据与计算资源，便取得了可与 Physical Intelligence 团队 &amp;pi;*0.6 模型比肩的性能表现。&lt;strong&gt;这一成果标志着 SAGE 架构彻底打通了负责推理决策的 &amp;ldquo;大脑&amp;rdquo; 与负责执行动作的 &amp;ldquo;躯体&amp;rdquo;，真正实现了智能体在物理世界中的 &amp;ldquo;具身化&amp;rdquo; 演进。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;经过近两年的扎实探索，SAGE 架构已跨越理论构想阶段，完成了全栈验证。在基础层，MemoryDecoder 实现了记忆与计算的结构性解耦；在融合层，PRIME 与 FlowRL 攻克了监督稀缺与推理单一性的难题；在进化层，TTRL、InternBootcamp 与 SimpleVLA-RL 构建了从测试时强化到 &amp;ldquo;具身化&amp;rdquo; 演进的闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式革命：从 AI4S 到 AGI4S&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管以 AlphaFold 为代表的 AI for Science（AI4S）技术在蛋白质折叠、气象预测等特定领域取得了里程碑式成就，但近期《Nature》发表的研究指出，过度依赖现有深度学习模型可能局限新知识的探索边界，甚至在某种程度上阻碍创新。这印证了我们的核心观点：擅长处理数据充足、定义明确任务的传统深度学习，若仅作为工具存在，难以应对科学发现中 &amp;ldquo;未知的未知&amp;rdquo;。&lt;/p&gt;&lt;p&gt;系统性的评估进一步揭示了当前前沿模型的短板。我们联合来自 10 个不同科学领域的 100 位科学家设计了评估体系，结果显示：前沿模型在通用科学推理任务中得分可达 50 分（满分 100），但在各类专业推理任务（如专项文献检索、具体实验方案设计）中，得分骤降至 15-30 分。&lt;/p&gt;&lt;p&gt;这种&lt;strong&gt;明显的 &amp;ldquo;木桶效应&amp;rdquo; 表明，科学发现全周期的效能正受制于专业推理能力的最薄弱环节。因此，整合通用推理与专业能力，进而推动科学智能从 AI4S 向 AGI4S 迭代成为必然选择。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rceicbHCzBBg7Ij2xQYl2T8CNIn5v5vFWlO8AMrg87lNNnSd528ibSoDaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.5618955512572534" data-s="300,640" data-type="png" data-w="1034" type="block" data-imgfileid="503530984" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/82493f8c-0492-457d-8adb-b717ace3bf3d/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 研究表明，当前所有前沿模型的科学能力均显不足&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从 AI4S 迈向 AGI4S，这一升级旨在推动研究者、研究工具与研究对象的协同演进。通过 AGI 促进三者相互作用、协同演进、螺旋式上升，将创造出真正&amp;nbsp;&amp;ldquo;&lt;strong&gt;革命的工具&lt;/strong&gt;&amp;rdquo;，推动科研范式变革⑭。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcLuRcGjfnM0woPBGibgvBc5tzb7wlMWZOePUQR0PP2d3frZiaXAQKP3Ow/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.5625" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503530985" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/cf88c92d-96ef-43d3-bf01-cecabf1d8c1d/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 从 AI4S 1.0 到 AI4S 2.0（AGI4S）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Intern-S1：面向科学的可深度专业化通用模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为打破上述瓶颈，我们研发了 &amp;ldquo;书生&amp;rdquo; 科学多模态大模型（Intern-S1）⑮。作为 SAGE 架构在科学领域的集中体现，Intern-S1 旨在构建一个既具备强大通用能力，又能理解复杂科学数据的 &amp;ldquo;可深度专业化通才&amp;rdquo;。其在三个层面进行了深度创新：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基础层（数据适配）&lt;/strong&gt;：针对科学数据的多模态异构性，提出了科学专用架构。采用动态分词器与专用编码器，原生支持 DNA 序列、蛋白质结构、时间序列等 10 余种模态。相较于 GPT-OSS 等通用模型，其在科学数据上的压缩率提升了 1.7 倍，并基于 2.5 万亿高质量科学 Token 进行了预训练。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;融合层（混合奖励）&lt;/strong&gt;：构建了混合奖励框架（MoR），将多种强化学习算法与熵机制整合。该框架平衡了计算、推理、实验设计等不同技能所需的奖励信号，有效缓解了特定任务过拟合问题，增强了模型在跨领域复杂推理中的泛化能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;进化层（交互专精）&lt;/strong&gt;：依托 InternBootCamp 框架，模型在超 1000 项专业任务（如逆合成分析）中与模拟器进行交互学习，实现了大规模的任务专精。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测评结果显示，Intern-S1 在通用能力上对齐 SOTA 开源模型，而在涵盖化学、生物、材料等 9 大领域的科学性能上，全面超越了包括 GPT-5 和 Grok-4 在内的顶尖闭源模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Intern-Discovery：全流程科学智能体系统&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 Intern-S1 是科学大脑，那么 Intern-Discovery 则是具备行动力的科学智能体。该平台构建了一个将 Intern-S1 与海量数据、2000 + 专业工具及湿实验室验证环境深度融合的智能体系统，实现了从假设生成到实验验证的闭环。&lt;/p&gt;&lt;p&gt;Intern-Discovery 的核心逻辑在于建立 &amp;ldquo;智能体生成&amp;rdquo; 与 &amp;ldquo;智能体验证&amp;rdquo; 的双向循环：前者主动洞察现象、提出假设并设计实验；后者通过仿真与物理实验验证假设，并将反馈回传以修正认知。&lt;/p&gt;&lt;p&gt;为支撑这一复杂流程，系统引入了两大关键支柱：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;科学智能上下文协议（SCP）⑯：针对现有 MCP 协议在科学资源整合上的不足，SCP 定义了领域特定的结构与协调机制，实现了对数据集、湿实验室设备及复杂工作流的标准化调度与全生命周期管理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分层记忆模块：通过策略程序记忆（SPM）、任务情景记忆（TEM）与语义知识记忆（SKM）的协同，系统能够沉淀高阶研究模式、记录实验细节并整合长期知识，从而在持续迭代中避免逻辑幻觉。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;案例实证：重塑科学发现流程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Intern-Discovery 已在气候科学与生物医学领域展现出 &amp;ldquo;革命性工具&amp;rdquo; 的潜力。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;气候科学&lt;/strong&gt;领域，面对降水预测中极端复杂的非线性交互，Intern-Discovery 自主调用 30 余种工具，分析了 20 年的多模态数据。它写了 4000 多行专业代码，成功发现了被人类专家忽略的水汽与动力项关联，并推导出一个简洁的新型显式非线性方程。该方程不仅形式优雅简洁，且显著提升了模拟精度，有效修正了长期存在的系统性偏差，证明了智能体在理论构建层面的创造力⑰。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcT9QV0zXFaV6Ly3oHDBqWYeNGkSpSKrCwTM7gP0ibwCAM0Jehv9d04Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.5622076707202993" data-s="300,640" data-type="png" data-w="1069" type="block" data-imgfileid="503530986" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/13820f7b-4863-44d3-943b-5b460a6caba1/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Intern-Discovery 在气候科学的应用案例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在生物医学领域，虚拟疾病生物学家 &amp;ldquo;元生&amp;rdquo; 通过模仿人类科学家的思维模板，整合遗传学、蛋白质组学及临床文献等多源数据。即便在数据稀疏条件下，它仍成功发现并验证了具有高临床潜力的隐藏靶点，展示了从数据到机制、从假说到验证的全流程智能化能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcAng2p6dv6HNGRWSSNMLZEv0ibtCrbFicqFrcfXvPdCibfKRJ9TnNIcrzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.5626204238921002" data-s="300,640" data-type="png" data-w="1038" type="block" data-imgfileid="503530987" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/74458384-ee89-4659-a5f4-d2d591871e11/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Intern-Discovery 在生物医学的应用案例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从 Intern-S1 的底层推理突破到 Intern-Discovery 的系统级应用，我们正逐步构建起一套覆盖科学发现全周期的 AGI4S 基础设施。这不仅是工具的革新，更是科研范式的重塑 &amp;mdash;&amp;mdash; 让人工智能真正成为推动科学边界拓展的合作伙伴。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行动召唤：共拓新世界蓝图&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综上所述，我们正处在实现 AGI 的前夕，若 &lt;strong&gt;AGI = 通专融合（Specialized Generalist），则可深度专业化的通用模型（Specializable Generalist）是实现 AGI 的可行路径&lt;/strong&gt;，而&amp;ldquo;智者&amp;rdquo;SAGE 的三层技术框架正是驱动后者发展的核心架构。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一个前沿阵地是科学发现 &amp;mdash;&amp;mdash; 它既是推理智能的终极试炼场，也是 &amp;ldquo;通专融合&amp;rdquo; 的验证舞台，大规模推理将赋能科学发现，科学发现亦将反哺推理能力的进化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Intern-S1 与 Intern-Discovery 是迈向该方向的首步实践，但这一切仅仅是初始的雏形。&lt;strong&gt;如果将&amp;ldquo;智者&amp;rdquo;SAGE 架构比作一张新世界的地图，我们目前已建立了很好的初步验证与很多尖兵前哨站，但这张地图上仍存在广阔的 &amp;ldquo;空白区域&amp;rdquo;。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;架构已经就绪，但画卷仍存在大片留白。如果这些初步进展激起了你的兴趣，我邀请你深入阅读我们的论文与代码 &amp;mdash;&amp;mdash; 它们都是开源的。但更重要的是，我邀请志同道合者与我们一同填补这些空白，共同构建完整的蓝图。&lt;/p&gt;&lt;p&gt;谢谢！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc2eqiayTkhr7eZJjy6Mu2ia9NCO9RZ6fYFUnMxPV2xf35rOrtoxqJ81wA/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530988" data-aistatus="1" data-original-style="null" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/7a305e5b-5904-4850-abe7-c0f95a2d8777/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 本次报告核心要点总结&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;① Shanghai Artificial Intelligence Laboratory. Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows [J]. arXiv preprint arXiv:2512.16969v1, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;② Vaswani A, et al. Attention is all you need [C]// Advances in neural information processing systems, 2017, 30.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;③ Zhang K, Qi B, Zhou B. Towards building specialized generalist ai with system 1 and system 2 fusion [J]. arXiv preprint arXiv:2407.08642, 2024.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;④ Qi B, Zhang K, Tian K, ..., Zhou B. Large language models as biomedical hypothesis generators: a comprehensive evaluation [C]. COLM, 2024.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑤ Zhou B. Building AGI through Specialized Generalist AI: pathways and key issues [J]. Communications of CCF, 2025, 21 (1): 54-62.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑥ Cao J, Wang J, Wei R, ..., Zhou B, Lin Z. Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models [J]. arXiv preprint arXiv:2508.09874, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑦ Zhang K, Zuo Y, He B, ..., Zhou B. A survey of reinforcement learning for large reasoning models [J]. arXiv preprint arXiv:2509.08827, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑧ Cui G, Yuan L, Wang Z, ..., Zhou B, Ding N. Process Reinforcement through Implicit Rewards [J]. arXiv preprint arXiv:2502.01456, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑨ Cui G, Zhang Y, Chen J, ..., Zhou B, Ding N. The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models [J]. arXiv preprint arXiv:2505.22617, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑩ Zhu X, Cheng D, Zhang D, ..., Zhou B, Mei H, Lin Z. FlowRL: Matching reward distributions for LLM reasoning [J]. arXiv preprint arXiv:2509.15207, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑪ Zuo Y, Zhang K, Sheng L, ..., Ding N, Zhou B. TTRL: Test-Time Reinforcement Learning [C]// NeurIPS, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑫ Li P, Ye J, Chen Y, ..., Zhou B, Chen K. InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling [J]. arXiv preprint arXiv:2508.08636, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑬ Li H, Zuo Y, Yu J, ..., Zhou B, Ding N. SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning [J]. arXiv preprint arXiv:2509.09674, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑭ Zhou B, Ding N, Bai L, Zhou H. Advancing AI for science: From the revolution of tools to the tools for revolution [J]. AI Open, 2025, 6: 323-328.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑮ Shanghai AI Laboratory. INTERN-S1: A SCIENTIFICMULTIMODAL FOUNDATION MODEL [J]. arXiv preprint arXiv:2508.15763, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑯ Jiang Y, Lou W, Wang L, ..., Zhou B. SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents [J]. arXiv preprint arXiv:2512.24189, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;⑰ Guo Z, Wang J, Ling F, ..., Zhou B, Bai L. A Self-Evolving AI Agent System for Climate Science [J]. arXiv preprint arXiv:2507.17311v3, 2025.&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型的第一性原理：（二）信号处理篇</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 18:21:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;作者 | 白铂 博士&lt;/section&gt;&lt;p&gt;&lt;strong&gt;白铂 博士，华为 2012 实验室理论研究部主任 信息论首席科学家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本篇是《大模型的第一性原理》系列解读文章的第二篇（&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651006633&amp;idx=1&amp;sn=822f0d7b22e8054ea897d55c7a7b3028&amp;scene=21#wechat_redirect" target="_blank"&gt;点击回顾第一篇&lt;/a&gt;），我们将从信号处理的角度解读原论文[1]。重点探讨语义向量化背后的信号处理和信息论原理，并从时间序列的角度分析 Transformer 及其与 Granger 因果的关系。&lt;/p&gt;&lt;p&gt;我们首先提出一个观点：大模型的输入是 Token 的语义嵌入（也称为语义向量），其本质是&lt;strong&gt;把自然语言处理问题转换为信号处理问题&lt;/strong&gt;。因此对于大模型而言，向量化非常关键，它和信号处理、信息论有非常深刻的联系。&lt;/p&gt;&lt;p&gt;尽管从语言学的角度看，语法和逻辑是人类语言现象的关键，然而本系列的《统计物理篇》已经指出：大模型并不考虑这些因素，而是从纯概率的角度出发建模自然语言。&lt;/p&gt;&lt;p&gt;从 Token 的维度看，这种纯粹的概率模型在计算上是非常困难的，因此人们发展出了概率图模型、消息传递算法等工具[2]。对于当前海量数据而言，这些方法的复杂度仍然过高，很难用于大规模训练，也难以建模语义非对称性和长程依赖性。但是，当 Token 被向量化之后，情况就发生了本质的变化，因为我们可以定义内积，并用内积来表示语义相关性，从而大幅度降低计算量。&lt;/p&gt;&lt;p&gt;基于内积，我们可以进一步定义距离、微分、低维流形等一系列相对容易数值计算的量。这样就可以通过反向传播算法来训练神经网络，将 Token 的向量化变成神经网络的输入、输出和参数化记忆[3][4]。实际上，许多研究也表明神经网络之所以能完成分类，正是因为同一类事物（如照片中的猫、狗等）在高维参数空间中会内聚成低维流形[5][6]。&lt;/p&gt;&lt;p&gt;顺便提及，我们在向量检索方面的研究取得了一定进展，所提出的近似最近邻向量检索算法，过去两年一直蝉联 ANNBenchemarks 榜单的第一名 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语义嵌&lt;/strong&gt;&lt;strong&gt;入 / 向量化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人们用向量来建模语义的想法最早出现于 Luhn 在 1953 年发表的论文中[8]。但直到 2013 年，Mikolov 等人才真正取得突破[9][10]。基于大量语料，他们成功地训练出了将 Token 转化成语义向量的神经网络模型。下面这个例子经常被用来表达最理想的语义向量化：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530716" data-ratio="0.0572289156626506" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfxmEta8PpRXWMscfWDIgs9qcObJguUTOs9mibIoJ3h4GhicoKNbh0GyTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="664" type="block" data-original-style="width:430px;height:25px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8b0f08ec-b228-4d63-927f-e312555d0412/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 s (&amp;sdot;) 为一个词的向量化表示。然而遗憾的是，上述理想的语义向量化当前并未完全实现，但是语义向量之间的&lt;strong&gt;内积&lt;/strong&gt;（或者归一化为&lt;strong&gt;余弦相似性&lt;/strong&gt;）却可以表示 Token 层面的语义相关性。&lt;/p&gt;&lt;p&gt;假设 &amp;Omega; 是一种自然语言所包含的 M 个 Token 的集合，那么从大模型的角度看，一个 Token 的语义就由定义在 &amp;Omega; 上的概率分布所描述[11]。该分布可以从大量语料中学到，因此&lt;strong&gt;语义空间&lt;/strong&gt;就可以用这个学到的概率空间建模。进一步地，将&lt;strong&gt;语义向量空间&lt;/strong&gt;定义为一个 M 维空间中的单位球面&lt;img data-aistatus="1" data-imgfileid="503530718" data-ratio="0.5217391304347826" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfDYt0uLXrFSyiaU5CotaorobPdRsr6k5Hodib0LyyZNARLrT1CJoMtGTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="92" type="block" data-original-style="width:53px;height:28px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/87983441-4459-4caa-adfd-a18ac97f8f2e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 6.16%;"&gt;，其中每个 Token 都和球面上的一个点一一对应。&lt;/p&gt;&lt;p&gt;对于大模型而言，语义向量空间就可以建模为一个&lt;strong&gt;概率-内积空间&lt;/strong&gt;。许多研究认为语义向量空间应该是结构更复杂的&lt;strong&gt;低维流形&lt;/strong&gt;，但余弦相似性和欧式距离的实际效果就已经足够好了。因此，我们认为用单位球面 S^(M-1) 来定义语义向量空间是在效果和复杂度之间的良好平衡。需要特别强调的是，语义向量空间中的每一个向量本身并没有语义，而&lt;strong&gt;这个向量与其它所有向量的内积（即相对关系）才代表了语义&lt;/strong&gt;。这一点和信息论中的信源编码有本质的区别。经典的信源编码是对每一个信源符号的压缩，而语义向量的压缩则是&lt;strong&gt;在相对关系近似不变的前提下，对整个语义向量空间的降维&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;那么，如何衡量两个语义空间的距离，以控制语义向量空间降维带来的精度损失或者衡量两个不同自然语言的语义差异性就变得至关重要。当代著名的几何学家，2009 年阿贝尔奖获得者，Mikhael Gromov 为我们提供了数学工具，即 &lt;strong&gt;Gromov-Wasserstein 距离&lt;/strong&gt;[12]。它衡量了两个度量 - 概率空间之间的任意两点间度量的平均差异。该定义极大地拓展了最优传输理论中的 Wasserstein 距离的应用范围[13]。据此，我们定义&lt;strong&gt;语义向量空间距离&lt;/strong&gt;如下：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530719" data-ratio="0.075" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfupBRMOPmia8kAPJeSbEYB3gAkKZn5YDxNBH2DcEncOGp2kYaJbuMQaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="width:490px;height:37px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/39666cdf-1b65-4892-b1ef-64fe03c7ad81/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfTEbnMia15KtnodgibMlUm5zFNRwj7N9PvXUPudS6H1V2U7IZ52UEfic7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.1428571428571428" data-s="300,640" data-type="png" data-w="42" type="block" data-imgfileid="503530720" data-aistatus="1" data-original-style="width:22px;height:25px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2b2e84c3-77ef-490f-b1be-de4f3adb938c/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 2.55%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfViak5ZgNESh5rwZjLZUicavZ82l3b9Zm6RXZ1qcBEn8YG6AYQdAibicdbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.2105263157894737" data-s="300,640" data-type="png" data-w="38" type="block" data-imgfileid="503530721" data-aistatus="1" data-original-style="width:20px;height:24px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b30ab2cc-1af3-4c41-86cd-8dc4fee53e7a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 2.34%;"&gt; 是两个语义向量空间，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfBEjJIz9GQCwqzze3A1d5GqploU0xK1GJVdIQycXk0Gmkx6HaqicrwXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5208333333333334" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530722" data-aistatus="1" data-original-style="width:51px;height:27px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3515da37-4e82-4866-9050-fe52e502af30/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 6.8%;"&gt; 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfMicicxTuFEnh202WQAAf4CepPQicXsLLE6Ydkc0N4FmibT0cNiaDmiaX3ib8w/640?wx_fmt=jpeg#imgIndex=7" data-ratio="0.4485981308411215" data-s="300,640" data-type="png" data-w="107" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf9eySof4FH4SVQ5xhicU2ric3ic86zDNgQUBOicGqLGIoE8dwdBxWX89wEw/0?wx_fmt=png&amp;from=appmsg" data-cropx1="1" data-cropx2="108" data-cropy2="48" data-imgfileid="503530723" data-aistatus="1" data-original-style="width:61px;height:27px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/4812ff00-0749-4f83-952b-c973e587dfaf/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 7.43%;"&gt; 上的语义向量，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf9TuaIkzGOkYNyB0IKjWgdYAXvPJzib1p0ia4KkcBhVCWYRvkou8ibLRNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530725" data-aistatus="1" data-original-style="width:58px;height:29px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/0b0ca31a-1dfb-4a21-b332-f471d0afef5b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 7.54%;"&gt; 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfYMYkrlqPjfTUfCGBdpEMfm7UP1gn7qeNVIQK06ClSIBRBoRGwpLqbA/640?wx_fmt=jpeg#imgIndex=9" data-ratio="0.3925233644859813" data-s="300,640" data-type="png" data-w="107" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfubiaibONbhryicia94YVCMHewbh36jACqJzyvaniaqIgUcTR3m42PYJQKMA/0?wx_fmt=png&amp;from=appmsg" data-cropx1="1" data-cropx2="108" data-cropy2="42" data-imgfileid="503530726" data-aistatus="1" data-original-style="width:63px;height:25px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2eb436ff-2347-4c73-bc05-d1304e92228e/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 7.01%;"&gt; 上的语义向量，&amp;mu; 和 &amp;nu; 分别是定义在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfR7FXVKrF2pzwSxJm5R30qmhRqIcAibX5qiado5icLRdchJPRmPoMn8EMg/640?wx_fmt=jpeg#imgIndex=10" data-ratio="0.42990654205607476" data-s="300,640" data-type="png" data-w="107" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfHljuyCMSNoR1ERxRx9aKrTibYOsfxpsTicGO2AYwkcG3TwhA4iaZajRcg/0?wx_fmt=png&amp;from=appmsg" data-cropx1="1" data-cropx2="108" data-cropy2="46" data-imgfileid="503530728" data-aistatus="1" data-original-style="width:60px;height:26px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/508d97a4-a440-4009-87eb-ec8463be47ea/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 7.64%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfNc17Rbq6Bcia2YNdsYAXYmOHkOhPM5M4sPgApY0U9ibBLSzs6py0m4Ag/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4807692307692308" data-s="300,640" data-type="png" data-w="104" type="block" data-imgfileid="503530730" data-aistatus="1" data-original-style="width:67px;height:32px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/77cf53f5-8f7a-46d8-8889-ff6df79a80c9/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 7.01%;"&gt;上的概率测度，&amp;pi; 是联合概率测度，&amp;Pi;(&amp;mu;,&amp;nu;) 是边缘分布为 &amp;mu; 和 &amp;nu; 的所有联合概率测度的集合。在最优传输理论中，&amp;Pi;(&amp;mu;,&amp;nu;) 中的任何一个联合概率测度都被称为传输方案。&lt;/p&gt;&lt;p&gt;可以看到，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazffDex0sWlOl6EUuGAmGNJCWDicKcPLmzqjby4Lia87DPj0LayUtewFLWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.29545454545454547" data-s="300,640" data-type="png" data-w="176" type="block" data-imgfileid="503530732" data-aistatus="1" data-original-style="width:86px;height:25px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b93d64fc-1d1f-4706-b7a4-4c734314f5ac/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 10.41%;"&gt; 衡量了概率加权意义下两个空间内积的平均最小差异，即两个空间的平均结构差异。如果 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf6CxP9icc0vib7gbY923VWDwrDbnEV8iaicRXaPxr3FeQaTiatqibJxLewvkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.224" data-s="300,640" data-type="png" data-w="250" type="block" data-imgfileid="503530733" data-aistatus="1" data-original-style="width:131px;height:29px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/62b129bd-f88b-4379-af48-dd1e7034e98f/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dii" style="width: 14.55%;"&gt;，在数学上称这两个空间是&lt;strong&gt;等距同构&lt;/strong&gt;的。这意味着这两个语义向量空间完全等价，即两种语言在 Token 语义层面实际上是同一种语言。从这个角度看，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfPAw779B96pVqHYdBT8a8wEOUMDsHVibaGduae9R4rWooCIBf4h7qrxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.32558139534883723" data-s="300,640" data-type="png" data-w="172" type="block" data-imgfileid="503530734" data-aistatus="1" data-original-style="width:91px;height:30px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/62a7db40-b1d3-48c7-8db4-2fa786f26f79/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dii" style="width: 9.45%;"&gt;&amp;nbsp;衡量了两个语义向量空间偏离等距同构的程度。偏离程度越大，翻译起来的难度就越高。&lt;/p&gt;&lt;p&gt;因此，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfRAjYwESen49daSLebjfwrynicfJsHgZSX69EAY8vJhnhB4UG1JHsPgA/640?wx_fmt=jpeg#imgIndex=15" data-ratio="0.3103448275862069" data-s="300,640" data-type="png" data-w="174" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf1zGticCUhadVngRNICHXgGfNP2qiaxoA6b4xQVFiat5kHSr021ygwWC2Q/0?wx_fmt=png&amp;from=appmsg" data-cropx1="2" data-cropx2="176" data-cropy2="54" data-imgfileid="503530736" data-aistatus="1" data-original-style="width:95px;height:29px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/a5fd7908-15ca-4cb9-8449-6353c368b5b0/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 10.19%;"&gt;&amp;nbsp;不仅可以用于衡量语义向量空间降维带来的语义失真，同时还可以用来度量语义对齐的效果[14]。我们近期正在将这个方法从自然语言的语义对齐推广到多模态语义对齐问题上。&lt;/p&gt;&lt;p&gt;基于语义向量空间的概念，下面讨论语义压缩问题。原始 M 维语义向量空间的维数过高，难以计算且容易导致维数灾难。Landauer 等人指出语义向量化存在一个最优维数区间，即所谓&lt;strong&gt;甜点维数&lt;/strong&gt;[14]。那么，如何将 M 维语义向量空间压缩到一个合适维数？这背后的数学原理就是著名的 &lt;strong&gt;Johnson-Lindenstrauss（JL）引理&lt;/strong&gt;[16]。考虑 ϵ&amp;isin;(0,1) 和 K 个 M 维向量 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfwL1hibll9UgibOKjPmUR3A2ghZYwcC9iaO0aFm54zZADHw9bLVZsCNETQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.16875" data-s="300,640" data-type="png" data-w="320" type="block" data-imgfileid="503530740" data-aistatus="1" data-original-style="width:184px;height:31px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/de1cc401-85ee-4f2b-9d39-c8141d1bdace/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dii" style="width: 23.25%;"&gt;，如果 &lt;img data-aistatus="1" data-imgfileid="503530742" data-ratio="0.3364485981308411" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfibPztyiazkPlKxhRZmxRH0icRAx7icSeAhyupoXJ6Oaia3icTvib4lQbhicl8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-type="png" data-w="214" type="block" data-original-style="width:109px;height:37px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/1f78e67e-8122-4e44-8473-4122848e6b8f/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dii" style="width: 13.06%;"&gt;，那么一定存在一个矩阵 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfEu4Pgt9yR99UC7Usk3y8ZV1SPqD1RMdXpmHX7hlJAFBwiajkkaYUqAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.22580645161290322" data-s="300,640" data-type="png" data-w="186" type="block" data-imgfileid="503530744" data-aistatus="1" data-original-style="width:109px;height:25px;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/0035547c-b99b-4adc-8ddf-dcc2384a8434/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dii" style="width: 12.85%;"&gt;&amp;nbsp;使得&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf58Z5WDTapQW7sV5xbV414w0ZVh3CY2v4ynJ9a2yExmAdanib36c8ycg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.0807799442896936" data-s="300,640" data-type="png" data-w="718" type="block" data-imgfileid="503530743" data-aistatus="1" data-original-style="width:374px;height:30px;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/a7c5d2c2-d5dd-4f1d-8686-858bec411547/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;JL 引理表明，可以通过线性变换来降低语义向量的维数，同时使得内积的误差小于 ϵ。因此，压缩之后的&lt;strong&gt;语义失真&lt;/strong&gt;可用下面的语义向量空间距离来衡量&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530750" data-ratio="0.07314814814814814" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfOZ6vic0TS84YMzmQXlIbH7ZTZK91dJpiaeHdO94PoBiaanicoPxzPIic0bA/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/625cedd0-b994-4429-bc2f-13309ef66341/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其中，S 为原 M 维语义向量空间，S&amp;#39; 为降维后的 m 维语义向量空间。更进一步，如果考虑语义向量本身的&lt;strong&gt;稀疏性&lt;/strong&gt;，我们还可以用&lt;strong&gt;压缩感知&lt;/strong&gt;理论来强化 JL 引理。这种强化可以导出基于采样 FFT、采样 DCT 和采样 Hadamard 矩阵的快速压缩算法。详情可参见原论文中的相应章节，这里不再赘述。需要注意的是，这里并未考虑语义向量空间上的概率测度，而是对每个语义向量都成立。因此，如果结合从语料中学到的概率测度，很有可能会提出更高效的语义降维算法或得到更高的压缩比 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfAHY69hfGBVwDo8uYBXHmcHsbdQEVicNXv8AjNhywSzrNiaR52icDNOicLQ/640?wx_fmt=jpeg#imgIndex=21" data-ratio="2.2" data-s="300,640" data-type="png" data-w="30" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf3KyiaJpGkV2gDBa1dB8oIHiaSzKAp0qoulQNPA6rx0mucmw0ztKJzFQQ/0?wx_fmt=png&amp;from=appmsg" data-cropx2="30" data-cropy2="66" data-imgfileid="503530752" data-aistatus="1" data-original-style="width:20px;height:44px;" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/4cf6d2e7-68e9-4ab0-b937-88beecf13a1b/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dii" style="width: 2.65%;"&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最优语义向量化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们知道，一个 Token 到底呈现出什么语义是和下游任务密切相关的。在本系列的《统计物理篇》中已经指出，大模型的目标是预测下一个 Token。因此，Token 的向量化也应围绕该目标展开。令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfHZzUHqn1G53xMwibS4XKDibnFMfUUHUvw6ibBd0s9tKdcUbV1FqfcziaAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530755" data-aistatus="1" data-original-style="width:39px;height:26px;" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/8cf200bc-51bc-4b49-b600-3a5288e62e89/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dii" style="width: 4.78%;"&gt; 为 Token 序列，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfLQ9oD7kpqCoaZsks4gGTvDXcvmDllVxhkZ7ibzZ9CKG0eWJjPFB9gFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.7142857142857143" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530756" data-aistatus="1" data-original-style="width:38px;height:27px;" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/04734b66-ece8-422e-a6a1-4743fa6c286e/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dii" style="width: 4.57%;"&gt; 为对应的语义向量。对于下一个 Token 预测任务，语义编码器 f 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfRzYhoTcvbXD11Sm2bnHP6csQzedCglKOkh5JerdK04qGFBqVteEKQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="0.8387096774193549" data-s="300,640" data-type="png" data-w="62" type="block" data-imgfileid="503530757" data-aistatus="1" data-original-style="width:29px;height:24px;" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/e1eb9136-c196-40cf-94e5-b25ee73e6d29/640.png" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dii" style="width: 3.61%;"&gt; 的函数，其输出 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqu4QhHOFXNZpQTEdt8XR1jwHzZ996EwyoxePtsN0TENAwu23HajSPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=25" data-ratio="1.3125" data-s="300,640" data-type="png" data-w="32" type="block" data-imgfileid="503530758" data-aistatus="1" data-original-style="width:20px;height:26px;" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/3a69be60-b940-42fb-9adb-ebdc9290a625/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dii" style="width: 2.02%;"&gt; 是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfePlMu45ZcMKFT5xXCd4KkerZwbT0ujPQRQVIQgOO8ZbodcLFbDNAxA/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.8" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503530759" data-aistatus="1" data-original-style="width:33px;height:26px;" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/2f0b810f-466d-4ae4-a2d1-9ac83ced25d8/640.png" alt="图片" data-report-img-idx="27" data-fail="0" class="fr-fic fr-dii" style="width: 3.72%;"&gt;中对于预测 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfZC9tIGz9vH4UrE7BJCSa434tfar8Rn1p7Ng7aqrE21dLug2DCUfZgg/640?wx_fmt=png&amp;from=appmsg#imgIndex=27" data-ratio="0.4716981132075472" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503530762" data-aistatus="1" data-original-style="width:60px;height:28px;" data-index="29" src="https://image.jiqizhixin.com/uploads/editor/bdba0ed4-9c98-4c37-b6b1-baf25ecdb0f8/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dii" style="width: 7.01%;"&gt; 有用但不在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfo364J8WZevAUZPE63bYEf0Ppk6J9vgyl1MShmb8icbXNNHgT2Z7NEzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=28" data-ratio="0.4583333333333333" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530763" data-aistatus="1" data-original-style="width:61px;height:28px;" data-index="30" src="https://image.jiqizhixin.com/uploads/editor/2eff893d-2cbd-4fe3-b254-c5d5803fdb29/640.png" alt="图片" data-report-img-idx="28" data-fail="0" class="fr-fic fr-dii" style="width: 6.58%;"&gt;&amp;nbsp;里的信息。那么，从信息论的角度看，最优语义编码器是下述优化问题的解：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530764" data-ratio="0.09020618556701031" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfolIkz84oMmpVnP9dwUUhwRKO2ZLfD6ic0GYgOSkmxeOxsEUWwwia386g/640?wx_fmt=png&amp;from=appmsg#imgIndex=29" data-type="png" data-w="776" type="block" data-original-style="width:466px;height:42px;" data-index="31" src="https://image.jiqizhixin.com/uploads/editor/c01b42ae-3f73-4a41-b683-c4dddd53e37f/640.png" alt="图片" data-report-img-idx="29" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;上述定义的核心是条件互信息，它保证了语义向量 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfXy9rDqtjjic3EQOEwoibLROXS5jhycy2NVQWXw8MAibVJFbt5xz96aFbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=30" data-ratio="1.2941176470588236" data-s="300,640" data-type="png" data-w="34" type="block" data-imgfileid="503530766" data-aistatus="1" data-original-style="width:20px;height:26px;" data-index="32" src="https://image.jiqizhixin.com/uploads/editor/4b697fe0-c5ae-416c-8751-77e3a354aad6/640.png" alt="图片" data-report-img-idx="31" data-fail="0" class="fr-fic fr-dii" style="width: 2.65%;"&gt; 并不是 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfL3h7arnzaI9MYoic7yHpEyB54MX7H4yG9msAXw9RicbyUe9QGCxtlItg/640?wx_fmt=png&amp;from=appmsg#imgIndex=31" data-ratio="1.0526315789473684" data-s="300,640" data-type="png" data-w="38" type="block" data-imgfileid="503530768" data-aistatus="1" data-original-style="width:26px;height:27px;" data-index="33" src="https://image.jiqizhixin.com/uploads/editor/c6867b4d-69c4-4e12-bc0a-86b425969269/640.png" alt="图片" data-report-img-idx="30" data-fail="0" class="fr-fic fr-dii" style="width: 2.44%;"&gt; 的向量表示，而是表示 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazffG18JhGzHMiaWSe2LCNBJ1FYaicnBC6Tyib9CJyEF4iahGgBbcTxjLQ1DA/640?wx_fmt=png&amp;from=appmsg#imgIndex=32" data-ratio="0.71875" data-s="300,640" data-type="png" data-w="64" type="block" data-imgfileid="503530769" data-aistatus="1" data-original-style="width:31px;height:22px;" data-index="34" src="https://image.jiqizhixin.com/uploads/editor/0f0300b2-abff-4ef6-a3a7-2aada3258461/640.png" alt="图片" data-report-img-idx="33" data-fail="0" class="fr-fic fr-dii" style="width: 3.72%;"&gt; 中对预测 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqBRUH7HIa8E517VbQm7x7icIuvzYXYaTtbOQt7AzT2icGd6ID7bo0DWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=33" data-ratio="0.4528301886792453" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503530771" data-aistatus="1" data-original-style="width:53px;height:24px;" data-index="35" src="https://image.jiqizhixin.com/uploads/editor/710a7973-2cea-4d73-89c8-21d9d72e9575/640.png" alt="图片" data-report-img-idx="35" data-fail="0" class="fr-fic fr-dii" style="width: 6.69%;"&gt; 有用但不在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfL9oIibWFLRWQ0NCyWdm4a5OTy55bul4E0q7iczsX2OiblmiazVjxMlenicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=34" data-ratio="0.5319148936170213" data-s="300,640" data-type="png" data-w="94" type="block" data-imgfileid="503530772" data-aistatus="1" data-original-style="width:55px;height:29px;" data-index="36" src="https://image.jiqizhixin.com/uploads/editor/4244cb71-fc0d-4cfe-a2b8-ec96eec1db84/640.png" alt="图片" data-report-img-idx="32" data-fail="0" class="fr-fic fr-dii" style="width: 5.84%;"&gt;&amp;nbsp;里的信息。应用互信息不等式，我们有&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530773" data-ratio="0.28316831683168314" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfyh5ibc6IUu4tnnkd1icQ63JoicVJl0opFsWtSyS9UGxGP5x0IibljCsic6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=35" data-type="png" data-w="1010" type="block" data-original-style="width:405px;height:115px;" data-index="37" src="https://image.jiqizhixin.com/uploads/editor/61fc5743-f267-4aa1-b84f-ac18d6097459/640.png" alt="图片" data-report-img-idx="34" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该不等式的最右端项就是 Google DeepMind 团队提出并广泛应用的（包括 OpenAI）&lt;strong&gt;Contrastive Predictive Coding（CPC）算法&lt;/strong&gt;[17]。这篇论文明确指出，他们的工作得到了信息论中 &lt;strong&gt;Predictive Coding&lt;/strong&gt; 的启发。这正是发表在 IEEE 的前身 IRE 主办的信息论汇刊 IRE Transactions on Information Theory 的第 1 卷第 1 期的第 1 篇和第 2 篇论文[18][19]。作者则是大名鼎鼎的 Peter Elias，他是卷积码的发明人，1977 年香农奖得主，3G 时代编码领域的绝对王者。Google 的研究人员撰写论文系统综述了&lt;strong&gt;互信息的变分下界&lt;/strong&gt;，并最终选择 InfoNCE 作为损失函数，从而通过神经网络最小化 InfoNCE 来最大化 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfnVklL4UMwibLFJiagdGN0fnQ1an5uDsHibQU00W0wdH6W7ticnOWTiaT9Zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=36" data-ratio="0.26373626373626374" data-s="300,640" data-type="png" data-w="182" type="block" data-imgfileid="503530776" data-aistatus="1" data-original-style="width:95px;height:25px;" data-index="38" src="https://image.jiqizhixin.com/uploads/editor/8a38cf8d-8b16-41fc-9915-5e3ef4e049eb/640.png" alt="图片" data-report-img-idx="36" data-fail="0" class="fr-fic fr-dii" style="width: 11.89%;"&gt;&amp;nbsp;的下界[20]。&lt;/p&gt;&lt;p&gt;以上的讨论启发我们：&lt;strong&gt;对于任何一个语义嵌入问题，都可以先基于下游任务要求写出信息论优化问题，再设计神经网络或数值算法来搜寻逼近信息论最优解或其上 / 下界的语义编码器。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从上述推导可以看出，CPC 实际上优化的是最优语义编码器的上界的 InfoNCE 逼近，所得到的语义编码器并不是最优的。如果我们有更好的工具来直接优化上述不等式最左端的条件互信息的和，那么将能得到性能更优的语义编码器。因此，这里要引入一个非常关键的信息论概念，即&lt;strong&gt;定向信息&lt;/strong&gt;。这一概念的提出者是著名的信息论专家，1988 年香农奖得主，James Massey[21]。根据 Massey 的研究，从信道的输入序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqdgk6wqxk6mskCw7lP5ibEwKU8ls605kz21bY8ze6CUpPMv8medaRfg/640?wx_fmt=png&amp;from=appmsg#imgIndex=37" data-ratio="0.6285714285714286" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530778" data-aistatus="1" data-original-style="width:38px;height:24px;" data-index="39" src="https://image.jiqizhixin.com/uploads/editor/190d72be-edae-4033-8672-e117141eb676/640.png" alt="图片" data-report-img-idx="39" data-fail="0" class="fr-fic fr-dii" style="width: 4.99%;"&gt; 到输出序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficPcV8Lw3YImyziaZzdD6lBAEXaRkAccxzXsS3I5g9DVgKTYTRyZF8icg/640?wx_fmt=png&amp;from=appmsg#imgIndex=38" data-ratio="0.75" data-s="300,640" data-type="png" data-w="64" type="block" data-imgfileid="503530779" data-aistatus="1" data-original-style="width:36px;height:27px;" data-index="40" src="https://image.jiqizhixin.com/uploads/editor/f25d08ad-d5a3-47fc-8c3b-a46d4a2325a4/640.png" alt="图片" data-report-img-idx="37" data-fail="0" class="fr-fic fr-dii" style="width: 4.14%;"&gt;&amp;nbsp;的定向信息可定义为&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530780" data-ratio="0.20987654320987653" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficCJZbU1SZEjHyaGQ6pYQYYtYJBTicPaia11uJuz4jH8PVd4Ydhwno0fA/640?wx_fmt=png&amp;from=appmsg#imgIndex=39" data-type="png" data-w="648" type="block" data-original-style="width:325px;height:68px;" data-index="41" src="https://image.jiqizhixin.com/uploads/editor/6702b625-a19b-4c5c-8840-063684a0d1e3/640.png" alt="图片" data-report-img-idx="38" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;它衡量了从序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfJO8ROzm7lxgo3V5ZICT2nFbMAdSV7dpQXLEIZrxjoqWeCHH2gp4ibNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=40" data-ratio="0.6285714285714286" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530782" data-aistatus="1" data-original-style="width:38px;height:24px;" data-index="42" src="https://image.jiqizhixin.com/uploads/editor/adb6c01f-f17b-47e3-be35-a70d8fdf5f2c/640.png" alt="图片" data-report-img-idx="44" data-fail="0" class="fr-fic fr-dii" style="width: 4.57%;"&gt; 传递给序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfzwfvsciaRIibicV6iascAnRhmOb2bGiaofE6ysBdYibAduEliant48b1dUKxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=41" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="66" type="block" data-imgfileid="503530783" data-aistatus="1" data-original-style="width:38px;height:25px;" data-index="43" src="https://image.jiqizhixin.com/uploads/editor/f3d5c4a6-1f84-45cd-a2de-291c26fcf4b3/640.png" alt="图片" data-report-img-idx="40" data-fail="0" class="fr-fic fr-dii" style="width: 4.25%;"&gt; 的信息量。进一步地，我们定义从 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfgoZAfokZia3STy7zuzAOkgx3dep0aH13uuGxDoDG7xaibVQoplpPicSLQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=42" data-ratio="0.6571428571428571" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530785" data-aistatus="1" data-original-style="width:35px;height:23px;" data-index="44" src="https://image.jiqizhixin.com/uploads/editor/78df58e4-094b-4818-8c11-dbad181dd7b5/640.png" alt="图片" data-report-img-idx="42" data-fail="0" class="fr-fic fr-dii" style="width: 4.03%;"&gt; 到 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf7WZRWlIPZV5ybh2W5GlyzLuXPeWHJZlqSa7g35ZfvoeB2rYpbDqiaxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=43" data-ratio="0.8064516129032258" data-s="300,640" data-type="png" data-w="62" type="block" data-imgfileid="503530789" data-aistatus="1" data-original-style="width:33px;height:27px;" data-index="45" src="https://image.jiqizhixin.com/uploads/editor/330935ee-5dd1-488b-b388-6862c6386791/640.png" alt="图片" data-report-img-idx="41" data-fail="0" class="fr-fic fr-dii" style="width: 4.03%;"&gt;&amp;nbsp;的&lt;strong&gt;倒向定向信息&lt;/strong&gt;：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530791" data-ratio="0.2028985507246377" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfibSoa8xaf9xb1TDBInnPBtiaMiaz8cPEKiaokpCjJ76oqqCDGhqWQgNL9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=44" data-type="png" data-w="690" type="block" data-original-style="width:363px;height:74px;" data-index="46" src="https://image.jiqizhixin.com/uploads/editor/48675407-aa5a-4989-b2ee-d59b684ab260/640.png" alt="图片" data-report-img-idx="43" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;选择&lt;strong&gt;倒向&lt;/strong&gt;这个词是受到彭实戈院士所研究的&lt;strong&gt;倒向随机微分方程&lt;/strong&gt;的启发[22]。彭院士的研究成果最终促使他提出了一套与 Kolmogorov 概率公理化体系平行的&lt;strong&gt;非线性期望理论&lt;/strong&gt;。我们从中可以看出，前面讨论的信息论最优的语义编码器，就是在最优化倒向定向信息，即：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530795" data-ratio="0.16393442622950818" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfDWkJBGatMibVkR6nQg8lXvRrXDJxAKgGGdWXUy0XiccibY66U5bVo68ew/640?wx_fmt=png&amp;from=appmsg#imgIndex=45" data-type="png" data-w="854" type="block" data-original-style="width:421px;height:69px;" data-index="47" src="https://image.jiqizhixin.com/uploads/editor/768ce405-295d-4e57-a885-230739e0559e/640.png" alt="图片" data-report-img-idx="45" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;然而，定向信息的计算和估计是非常困难的。该问题将在本系列的第三篇《信息论篇》中展开讨论。可见，CPC 选择 InfoNCE 作为损失函数平衡了复杂度和效果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Transformer 是非线性时变向量自回归时间序列&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在本系列的第一篇《统计物理篇》中，我们详细探讨了 Transformer 的能量模型（Energy-based Model，EBM）形式。本篇我们从信号处理角度进一步讨论 Transformer 的本质。业界已经达成共识，Transformer 是一个自回归大语言模型。这是因为它基于输入 Token 序列和已经生成的 Token 序列来预测下一个 Token。事实上，从经典随机过程和时间序列分析的角度看，自回归模型有严格的数学定义，即用过去的随机变量的值的线性加权和来预测未来的随机变量[23]。&lt;/p&gt;&lt;p&gt;考虑提示词的长度为 n，用向量序列 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfJDVV5Tm6icicW5W7AQBBMB74jibAcStsEc3qw8VNJx4VMsEemkFrpQTiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=46" data-ratio="0.6764705882352942" data-s="300,640" data-type="png" data-w="68" type="block" data-imgfileid="503530796" data-aistatus="1" data-original-style="width:42px;height:28px;" data-index="48" src="https://image.jiqizhixin.com/uploads/editor/677adff7-856b-488f-9c44-20c78faaddc2/640.png" alt="图片" data-report-img-idx="46" data-fail="0" class="fr-fic fr-dii" style="width: 4.46%;"&gt; 来表示。当前要预测第 i 个 Token，表示为向量 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfUSJVMic9n1e1pOViavriaYhJPjRA83IBWW6bByRqLicXGXrnumPbVDJLCw/640?wx_fmt=png&amp;from=appmsg#imgIndex=47" data-ratio="0.9473684210526315" data-s="300,640" data-type="png" data-w="38" type="block" data-imgfileid="503530797" data-aistatus="1" data-original-style="width:23px;height:22px;" data-index="49" src="https://image.jiqizhixin.com/uploads/editor/74e9ce30-93e4-43b1-9ea2-554a36d0d0a5/640.png" alt="图片" data-report-img-idx="48" data-fail="0" class="fr-fic fr-dii" style="width: 2.76%;"&gt;，其中 i=n+1,&amp;hellip;,N。为表示方便，令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfZdT9f9Ck7cWZsq8SNenLe1VddyMQLS7NzusubicU4meyZzJJyDT59sA/640?wx_fmt=png&amp;from=appmsg#imgIndex=48" data-ratio="0.328125" data-s="300,640" data-type="png" data-w="128" type="block" data-imgfileid="503530798" data-aistatus="1" data-original-style="width:69px;height:23px;" data-index="50" src="https://image.jiqizhixin.com/uploads/editor/45faa4c1-38c1-4472-a808-7f71f3944f45/640.png" alt="图片" data-report-img-idx="47" data-fail="0" class="fr-fic fr-dii" style="width: 9.03%;"&gt;，其中 i=1,&amp;hellip;,n。结合自回归模型的思想，Attention 模块的数学形式可以写为：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530799" data-ratio="0.6608695652173913" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfONeLv99VSAKNtkTbmHHaSReiaWeBa83qOVWxsyPJPfzOUlAdiaXDf3uw/640?wx_fmt=png&amp;from=appmsg#imgIndex=49" data-type="png" data-w="230" type="block" data-original-style="width:114px;height:75px;" data-index="51" src="https://image.jiqizhixin.com/uploads/editor/de623ae7-6c45-4939-92d5-8aa652b15d6b/640.png" alt="图片" data-report-img-idx="49" data-fail="0" class="fr-fic fr-dib" style="width: 20%;"&gt;&lt;/section&gt;&lt;p&gt;其中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfEsvdTlwml0rjxyqQ8UfGAbBbA4FaZicxY9LtLWLSCicOPraQIJSD2zOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=50" data-ratio="0.8275862068965517" data-s="300,640" data-type="png" data-w="58" type="block" data-imgfileid="503530800" data-aistatus="1" data-original-style="width:32px;height:26px;" data-index="52" src="https://image.jiqizhixin.com/uploads/editor/c5310b6b-e53f-4e0b-b9c9-8677d0a1f72f/640.png" alt="图片" data-report-img-idx="50" data-fail="0" class="fr-fic fr-dii" style="width: 4.46%;"&gt;&amp;nbsp;是 Attention 权重，定义为：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530801" data-ratio="0.1372093023255814" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5RarUdl78uQgaExvq7sPaicBTianEsoyd09hlAJ7gpYI70ibBvlia9ToyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=51" data-type="png" data-w="860" type="block" data-original-style="width:433px;height:59px;" data-index="53" src="https://image.jiqizhixin.com/uploads/editor/42fc6a1d-1224-4482-95fa-3aceaa545a4d/640.png" alt="图片" data-report-img-idx="51" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从数学形式上看，Attention 是一个&lt;strong&gt;非线性时变向量自回归时间序列&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;时变性体现在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf3DKS1ib0LyJ8CoXN1tXnMxkibVMMN5kuV80v86xLhqsVibkw6vxxR8k2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=52" data-ratio="0.9230769230769231" data-s="300,640" data-type="png" data-w="52" type="block" data-imgfileid="503530802" data-aistatus="1" data-original-style="width: 30px;height: 28px;" data-index="54" src="https://image.jiqizhixin.com/uploads/editor/9306c6d9-2fbb-46de-b740-534de13ddf68/640.png" alt="图片" data-report-img-idx="55" data-fail="0" class="fr-fic fr-dii" style="width: 3.8%;"&gt;&amp;nbsp;与当前输出的 Token 编号 i 相关；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;非线性体现在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf3DKS1ib0LyJ8CoXN1tXnMxkibVMMN5kuV80v86xLhqsVibkw6vxxR8k2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=53" data-ratio="0.9230769230769231" data-s="300,640" data-type="png" data-w="52" type="block" data-imgfileid="503530802" data-aistatus="1" data-original-style="width: 30px;height: 28px;" data-index="55" src="https://image.jiqizhixin.com/uploads/editor/f3422596-388f-4401-8b45-fbb246eb4cb7/640.png" alt="图片" data-report-img-idx="54" data-fail="0" class="fr-fic fr-dii" style="width: 4.23%;"&gt; 的定义中包含了 softmax 函数和建模语义非对称关系的双线性型 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfJNxiab04KBZzZ0icVq2XzSCVb6nia8poia34M2ib4A4xzeYquicVoS4UoUaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=54" data-ratio="0.375" data-s="300,640" data-type="png" data-w="144" type="block" data-imgfileid="503530803" data-aistatus="1" data-original-style="width: 80px;height: 30px;" data-index="56" src="https://image.jiqizhixin.com/uploads/editor/060f8603-bf94-4922-ae5d-ffe44e9a2df2/640.png" alt="图片" data-report-img-idx="53" data-fail="0" class="fr-fic fr-dii" style="width: 9.11%;"&gt;，其中 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfC0SnBG7BoGXzI2PqOgtSHr5ibgj6gXVqI3613b9kpfuCAWaZhIowBew/640?wx_fmt=png&amp;from=appmsg#imgIndex=55" data-ratio="0.29" data-s="300,640" data-type="png" data-w="200" type="block" data-imgfileid="503530804" data-aistatus="1" data-original-style="width: 102px;height: 30px;" data-index="57" src="https://image.jiqizhixin.com/uploads/editor/561696c1-709e-438b-8985-33b1ca7b91e4/640.png" alt="图片" data-report-img-idx="52" data-fail="0" class="fr-fic fr-dii" style="width: 10.52%;"&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfFaP7StKjpO956wesdOc0XHLUiaIUUQRJzFGjA1W1N5r6My1AzS9jiabQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=56" data-ratio="0.5714285714285714" data-s="300,640" data-type="png" data-w="84" type="block" data-imgfileid="503530805" data-aistatus="1" data-original-style="width:43px;height:25px;" data-index="58" src="https://image.jiqizhixin.com/uploads/editor/69bad320-bc55-4927-95a0-b8866e3b79c7/640.png" alt="图片" data-report-img-idx="57" data-fail="0" class="fr-fic fr-dii" style="width: 5.1%;"&gt;&amp;nbsp;表示 Tranformer 的 FFN 层，那么 Transformer 本质上是通过&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530806" data-ratio="0.4748603351955307" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfiarsFpQk308Vqttl4UHJx8GhlQvvFrjRUicibtuZHE2XF3ASLnr3vs8lQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=57" data-type="png" data-w="358" type="block" data-original-style="width:195px;height:93px;" data-index="59" src="https://image.jiqizhixin.com/uploads/editor/2dbf9a3c-9ec4-45b3-a10b-7d0161512a9b/640.png" alt="图片" data-report-img-idx="56" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;来预测下一个 Token 的向量表示。在《统计物理》篇中，我们已经指出 FFN 层对于预测下一个 Token 是很重要的，它被认为是大模型储存知识的位置。基于记忆容量的思路，Attention 模块输出的向量应该会激活 FFN 层中与之最匹配的记忆模式，从而作为下一个 Token 的向量表示。后续的操作需要在离散的词表中选择最有可能的那个 Token。在实际中可以设计多种采样策略来满足输出的要求，但背后的原理与通信接收机中的最大似然译码很类似。&lt;/p&gt;&lt;p&gt;简单起见，这里将采样操作表示成 argsoftmax (&amp;sdot;) 函数。令 &lt;img data-aistatus="1" data-imgfileid="503530807" data-ratio="0.7931034482758621" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfXAZ1IHhhY0AHViaGezTeluQjg3W50L4rNoyiayIXV2ckzq6I0QwxxibkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=58" data-type="png" data-w="58" type="block" data-original-style="width:32px;height:25px;" data-index="60" src="https://image.jiqizhixin.com/uploads/editor/5809c80a-cea4-495e-abb0-52916e4fb403/640.png" alt="图片" data-report-img-idx="58" data-fail="0" class="fr-fic fr-dii" style="width: 4.25%;"&gt;&amp;nbsp;为词表 &amp;Omega; 中的第 m 个 Token 的向量表示，那么 Transformer 的数学形式可以写为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfzoaQLuRRStWicsnLQ0GnC9s6BOWxe0v0JCty4iaccD1nnKcicV5QpAzOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=59" data-ratio="0.14907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530808" data-aistatus="1" data-original-style="width:488px;height:73px;" data-index="61" src="https://image.jiqizhixin.com/uploads/editor/d3e72bc8-9426-4a62-b837-b679173be621/640.png" alt="图片" data-report-img-idx="59" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 T 是温度。&lt;/p&gt;&lt;p&gt;实际上，上述模型可作以下推广&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530809" data-ratio="0.16574074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfEje1mFeSpFcSTOUnJW1o44njjx0mJN1FAYAxYj6lOuBYKOa1abyAmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=60" data-type="png" data-w="1080" type="block" data-original-style="width:503px;height:83px;" data-index="62" src="https://image.jiqizhixin.com/uploads/editor/c2e46064-13cf-483e-824a-dace74bed84e/640.png" alt="图片" data-report-img-idx="60" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 &amp;Psi; 为非线性函数，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficgemjeZ9ngGUe1b3k6RbH10ic5xG4Kpjj6DgTmAfckztSZDgqdVOU9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=61" data-ratio="0.9285714285714286" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530810" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="63" src="https://image.jiqizhixin.com/uploads/editor/d4eae2d2-7954-4dad-9c25-774c118f2595/640.png" alt="图片" data-report-img-idx="61" data-fail="0" class="fr-fic fr-dii" style="width: 3.29%;"&gt; 为时变参数矩阵。可见，Transformer 是更普遍的非线性时变向量自回归时间序列的一个特例。对 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazficgemjeZ9ngGUe1b3k6RbH10ic5xG4Kpjj6DgTmAfckztSZDgqdVOU9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=62" data-ratio="0.9285714285714286" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530810" data-aistatus="1" data-original-style="width:32px;height:30px;" data-index="64" src="https://image.jiqizhixin.com/uploads/editor/ac4b54d1-8eb1-4030-9ec8-8eb158f79270/640.png" alt="图片" data-report-img-idx="62" data-fail="0" class="fr-fic fr-dii" style="width: 3.4%;"&gt;&amp;nbsp;进行其他分解或简化就能构造出新的 Attention 机制。例如，Mamba/Mamba2 是一种线性化的简化方式。由于线性 Attention 机制难以捕捉非对称语义相关性，其模型能力很自然地会受到很大影响。对 &amp;Psi; 也同样可以进行优化和修改，一种思路是用现代连续 Hopfield 网络来直接替换 FFN 模块[24]。另外，当前通过向量数据库和知识图谱等方式实现 RAG 也是通过改变 &amp;Psi; 来增强知识记忆的准确性和及时性[25]。&lt;/p&gt;&lt;p&gt;本系列的《统计物理篇》已经指出：大模型的能力极限是在预测下一个 Token 的任务上逼近人类水平的 Granger 因果推断。从时间序列的角度看，Granger 因果检测的主要作用就是分析两个序列之间与时间相关的统计关系。相关方法已经广泛应用于物理学、神经科学、社交网络、经济学和金融学等领域。回忆 Granger 因果的定义，令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfqHZuXfCeJG0o4g89oOiaaUhtMUG3DhGVCj9K5FUGgetqnOaSKibwSSDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=63" data-ratio="0.15723270440251572" data-s="300,640" data-type="png" data-w="318" type="block" data-imgfileid="503530812" data-aistatus="1" data-original-style="width:165px;height:26px;" data-index="65" src="https://image.jiqizhixin.com/uploads/editor/d150af7b-a63c-41a5-bc41-09b1c6f32352/640.png" alt="图片" data-report-img-idx="63" data-fail="0" class="fr-fic fr-dii" style="width: 23.15%;"&gt;，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfNhVWublK9jOd0jkatMQj3tlZPwSsE4I3HGrXA9mdBZ9rv8n5NZmUQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=64" data-ratio="0.1889763779527559" data-s="300,640" data-type="png" data-w="254" type="block" data-imgfileid="503530814" data-aistatus="1" data-original-style="width:130px;height:25px;" data-index="66" src="https://image.jiqizhixin.com/uploads/editor/abcc69b0-cda4-412a-a8ff-9949ced2f6aa/640.png" alt="图片" data-report-img-idx="65" data-fail="0" class="fr-fic fr-dii" style="width: 17.52%;"&gt;，那么下面的不等式自然成立：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530816" data-ratio="0.07763975155279502" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfAdhHjh0qSN480e83mD6QMcdcESLdXZW4fJMluOsInky8fTmdJthhjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=65" data-type="png" data-w="644" type="block" data-original-style="width:386px;height:30px;" data-index="67" src="https://image.jiqizhixin.com/uploads/editor/2f433fb6-ca32-4bd5-9110-075793a66d92/640.png" alt="图片" data-report-img-idx="64" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;因此，从时间序列的角度看，大模型输入的 Token 序列和输出的 Token 序列符合 Granger 因果推断的定义。这进一步印证了第一篇的结论：&lt;strong&gt;大模型推理的本质，是通过预测下一个 Token 这一看似简单的训练目标，进而实现逼近人类水平的 Granger 因果推断。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信号处理与信息论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在引言中我们已经指出：大模型处理的是向量化后的 Token 序列，其本质是&lt;strong&gt;把传统基于概率的自然语言处理问题转换成了基于数值计算的信号处理问题&lt;/strong&gt;。从本文的讨论中可以看到，这种从 Token 到其向量表示的转化，与信息论和信号处理之间的关系非常类似。&lt;/p&gt;&lt;p&gt;具体来说，Shannon 信息论是一个基于概率论的理论框架，旨在理解信息压缩、传输和存储的基本原理及其性能极限，但它并不关注工程中的具体实现方法和复杂度。信号处理将信息论中的抽象符号表示为 n 维实 / 复空间中的向量。这种表示使得数值计算方法能有效应用于感知、通信和存储系统的高效算法设计中。可以说，信号处理是信息论原理在特定计算架构下的具体实现。&lt;/p&gt;&lt;p&gt;更广泛地看，我们经常用下图来表达计算理论和信息论之间的关系。图的左边是 Turing 和他的计算理论，他关心用多少个步骤能完成特定的计算，因此时延（通常用时间复杂度来度量）是最关键的指标。图的右边是 Shannon 和他的信息论，他关心的是通信速率的上限或者数据压缩的下限，即存在性和可达性。此时，通常假设码长趋于无穷大，因而时延是被忽略的。那么在实践中就会发现，开发通信算法的瓶颈永远是算力不够，算法复杂度太高；而研究计算算法的瓶颈永远都是（访存 / 卡间 / 服务器间）通信带宽不够，或者缓存 / 内存空间太小。&lt;/p&gt;&lt;p&gt;我们注意到，尽管计算理论和信息论有本质的不同，但他们最基本的操作单位都是 BIT，因此我们可以肯定地说：&lt;strong&gt;BIT 是连接计算和通信这两大领域的桥梁&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530817" data-ratio="0.5370370370370371" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfTVhVialRiaJicwv4BPDIibaMribkSdwssDpvkV7Gicb8nrrwicQkWic7ia3LmGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=66" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="68" src="https://image.jiqizhixin.com/uploads/editor/907a4aab-29e1-4988-969d-c48ea7cb1303/640.png" alt="图片" data-report-img-idx="66" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图：BIT 是连接计算理论和信息论的桥梁，是信息时代最伟大的发明。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;正如 5G Polar 码发明人，2019 年香农奖得主，Erdal Arikan 教授参加我们的圆桌论坛中所指出的：&lt;strong&gt;BIT 是信息时代最伟大的发明&lt;/strong&gt;。Shannon 在与 Weaver 合著的论文中也明确指出：信息论只解决了信息的可靠传输问题，即技术问题，而不考虑语义和语效[26]。但是人类已经进入了 AI 时代，信息论是否还能继续发挥其基础性作用？&lt;/p&gt;&lt;p&gt;我们将在本系列的第三篇《信息论篇》中看到，只要将核心概念从信息时代的 BIT 转换成 AI 时代的 TOKEN，Shannon 信息论就可以用来解释大模型背后的数学原理。&lt;/p&gt;&lt;section&gt;&lt;sup&gt;参考文献&lt;/sup&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;1. B. Bai, &amp;quot;Forget BIT, it is all about TOKEN: Towards semantic information theory for LLMs,&amp;quot; arXiv:2511.01202, Nov. 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;2. D. Koller and N. Friedman, Probabilistic Graphical Models: Principles and Techniques. Cambridge, MA, USA: The MIT Press, 2009.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;3. G. Hinton, &amp;quot;Learning distributed representations of concepts,&amp;quot; in Proc. 8th Annual Conference on Cognitive Science Society &amp;rsquo;86, Amherst, MA, USA, Aug. 1986.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;4. Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin, &amp;quot;A neural probabilistic language model,&amp;quot; Journal of Machine Learning Research, vol. 3, no. 2, pp. 1137-1155, Feb. 2003.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;5. S. Chung, D. Lee, and H. Sompolinsky, &amp;quot;Classification and geometry of general perceptual manifolds,&amp;quot; Physical Review X, vol. 8, no. 3, p. 031003, Jul. 2018.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;6. Y. Bahri, J. Kadmon, J. Pennington, S. Schoenholz, J. Sohl-Dickstein, and S. Ganguli, &amp;quot;Statistical mechanics of deep learning,&amp;quot; Annual Review of Condensed Matter Physics, vol. 11, no. 3, pp. 501-528, Mar. 2020.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;7. https://ann-benchmarks.com&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;8. H. Luhn, &amp;quot;A new method of recording and searching information,&amp;quot; American Documentation, vol. 4, no. 1, pp. 14&amp;ndash;16, Jan. 1953.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;9. T. Mikolov, K. Chen, G. Corrado, and J. Dean, &amp;quot;Efficient estimation of word representations in vector space,&amp;quot; arXiv: 1301.3781, 7 Sep. 2013.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;10. T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, &amp;quot;Distributed representations of words and phrases and their compositionality,&amp;quot; Proc. 27th Annual Conference on Neural Information Processing Systems &amp;#39;13, Lake Tahoe, NV, USA, Dec. 2013.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;11. D. Jurafsky and J. Martin, Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models, 3rd ed. Draft, 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;12. M. Gromov, Metric Structures for Riemannian and Non-Riemannian Spaces. Boston, MA, USA: Birkh&amp;auml;user, 2007.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;13. C. Villani, Optimal Transport: Old and New. New York, NY, USA: Springer, 2009.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;14. D. Alvarez-Melis and T. Jaakkola, &amp;quot;Gromov-Wasserstein alignment of word embedding spaces,&amp;quot; in Proc. ACL Conference on Empirical Methods in Natural Language Processing &amp;rsquo;18, Brussels, Belgium, Oct. 2018, pp. 1881&amp;ndash;1890.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;15. T. Landauer, P. Foltz, and D. Laham, &amp;quot;An introduction to latent semantic analysis,&amp;quot; Discourse Processes, vol. 25, no. 2-3, pp. 259-284, Jan. 1998.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;16. W. Johnson, J. Lindenstrauss, and G. Schechtman, &amp;quot;Extensions of Lipschitz maps into Banach spaces,&amp;quot; Israel Journal of Mathematics, vol. 54, no. 2, pp. 129-138, Jun. 1986.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;17. A. Oord, Y. Li, and O. Vinyals, &amp;quot;Representation learning with contrastive predictive coding,&amp;quot; arXiv: 1807.03748, Jan. 2019.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;18. P. Elias, &amp;quot;Predictive coding - Part 1,&amp;quot; IRE Transactions on Information Theory, vol. 1, no. 1, pp. 16-24, Mar. 1955.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;19. P. Elias, &amp;quot;Predictive coding - Part 2,&amp;quot; IRE Transactions on Information Theory, vol. 1, no. 1, pp. 24-33, Mar. 1955.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;20. B. Poole, S. Ozair, A. Oord, A. Alemi, and G. Tucker, &amp;quot;On variational bounds of mutual information,&amp;quot; in Proc. 36th International Conference on Machine Learning &amp;rsquo;19, Long Beach, CA, USA, Jun. 2019, pp. 5171-5180.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;21. J. Massey, &amp;quot;Causality, feedback and directed information,&amp;quot; in Proc. IEEE International Symposium on Information Theory &amp;rsquo;90, Waikiki, HI, USA, Nov. 1990.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;22. S. Peng, Nonlinear Expectations and Stochastic Calculus under Uncertainty: with Robust CLT and G-Brownian Motion. Berlin, Germany: Springer, 2019.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;23. H. L&amp;uuml;tkepohl, New Introduction to Multiple Time Series Analysis. Berlin, Germany: Springer, 2007.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;24. H. Ramsauer et al., &amp;quot;Hopfield networks is all you need,&amp;quot; arXiv: 2008.02217, Apr. 2021.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;25. Y. Xia et al., &amp;quot;ER-RAG: Enhance RAG with ER-based unified modeling of heterogeneous data sources,&amp;quot; arXiv: 2504.06271, Mar. 2025.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;26. W. Weaver and C. Shannon, &amp;quot;Recent contributions to the mathematical theory of communications,&amp;quot; The Rockefeller Foundation, Sep. 1949.&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谷歌开放世界模型一夜刷屏，AI游戏门槛归零时刻来了？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 18:06:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杜伟&lt;/section&gt;&lt;p&gt;谷歌世界模型，再一次惊艳了所有人！&lt;/p&gt;&lt;p&gt;今天一早，&lt;strong&gt;谷歌 DeepMind 开放了世界模型 Genie 3 的实验性研究原型「Project Genie」，允许用户创建、编辑并探索虚拟世界&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在世界模型 Genie 3 之外，Project Genie 同样由图像生成与编辑模型 Nano Banana Pro 和语言模型 Gemini 提供技术支撑。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530917" data-ratio="0.7064814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc8h4ZHNswUnSTCYicW7wCFweodBPNlORnkANV72zGsMLPJcdUC9CbWNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2299c29a-ff7b-41e5-95b1-13d5241aa114/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;去年 8 月，谷歌预发布了通用世界模型 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650983908&amp;idx=1&amp;sn=f33650540bdffd2558dea77ba3ab7377&amp;scene=21#wechat_redirect" target="_blank"&gt;Genie 3&lt;/a&gt;，它能够生成多样化的交互式环境。在这一早期阶段，受邀测试者们已经创造出了令人印象深刻且极具吸引力的虚拟世界与沉浸式体验，并挖掘出了全新的使用方式。&lt;/p&gt;&lt;p&gt;接下来的目标是构建一个专注于「沉浸式世界创建」的交互式原型，进一步扩大受众范围。&lt;/p&gt;&lt;p&gt;因此自即日起，谷歌面向&lt;strong&gt;美国 18 岁及以上的 Google AI Ultra 用户&lt;/strong&gt;开放了 Project Genie 的访问权限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Project Genie 的多样性玩法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;世界模型能够模拟环境的动态变化，并预测环境的演变方式以及动作对环境的影响。&lt;/p&gt;&lt;p&gt;与静态 3D 快照中的可探索体验不同，谷歌通用世界模型 Genie 3 会在用户移动并与世界交互时，实时生成前方的路径。&lt;/p&gt;&lt;p&gt;它能够为动态世界模拟出物理效果和交互，并且其突破性的一致性使得模拟任何现实场景成为可能，从机器人技术、动画建模和小说创作，到地点探索和历史场景还原。&lt;/p&gt;&lt;p&gt;如今，在 Genie 3、Nano Banana Pro 和 Gemini 等三大模型的支持下，Project Genie 具备了以下三大核心能力：&lt;/p&gt;&lt;p&gt;首先是，&lt;strong&gt;世界草绘（World sketching）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;通过文本提示词以及生成或上传的图片，用户即可创建一个生动且不断扩张的环境。用户可以创建自己的角色和世界，并定义自己想要的探索方式，比如行走、骑行、飞行或者驾驶，等等。&lt;/p&gt;&lt;p&gt;为了实现更精准的控制，谷歌将「世界草绘」与 Nano Banana Pro 进行了整合。这样一来，用户在正式进入世界之前，可以预览世界的样貌并修改图像以进行微调。&lt;/p&gt;&lt;p&gt;用户还可以定义角色的视角（第一人称或第三人称），在进入场景前掌控自己的视觉体验。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530918" data-ratio="0.66875" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcm9ExuI0IgMjZTvUhrZhuOmLkzpt1NXH5SUD00lhIUmymLJ7Fyd5SaA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bf0176a0-43e1-469b-b0c3-8db37444afb8/640.gif" data-order="0" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其次是，&lt;strong&gt;世界探索（World exploration）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;用户创建的世界是一个等待探索的可导航环境。在移动时，Project Genie 会根据用户采取的行动实时生成前方路径。在穿行过程中，用户还可以调整相机视角。&lt;/p&gt;&lt;p&gt;最后是，&lt;strong&gt;世界重混（World remixing）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;通过在原有提示词的基础上进行创作，将现有世界重混成新的演绎版本。用户也可以在画廊或「随机生成」图标中探索精选世界以获取灵感，并在此基础上继续构建。&lt;/p&gt;&lt;p&gt;完成后，用户可以下载关于自己的世界和探索过程的视频。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530919" data-ratio="0.565625" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcd0D2ZMfZtnXBQUFdhjTt6uJ1vX4aaKmoghia2ic4xtAjIjciadZ8bG3SA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/725a3cd7-05f7-48e1-9008-a52751d426c3/640.gif" data-order="1" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不过目前，谷歌也承认，Genie 3 仍处于早期研究阶段， 以下几个方面需要进一步改进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;生成的世界可能看起来并不完全逼真，或者并不总是能严格遵循提示词、图像或现实世界的物理规律；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;角色有时可能不太受控，或者在控制上存在较高的延迟；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;生成内容的时长限制在 60 秒以内；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;此前宣布的部分 Genie 3 功能（例如在探索时改变世界的提示事件「promptable events」）尚未包含在此原型中。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;第一手体验出炉&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;谷歌开放 Project Genie，终于让更多用户亲身体验到了世界模型 Genie 3 的「AI 生万物」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcticjRvuTw3DnkgEWQNRSm0O7B98vzw7b8FTiaIX4e11jQvL7NhiaXB74g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0416666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530923" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b5faa540-3e75-46e2-844e-1ee9283e5cca/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;已经上手的 Ultra 用户纷纷晒出了自己的作品，给予了不错的评价。&lt;/p&gt;&lt;p&gt;「刚刚用 Genie 3 做出了我的第一款 AI 游戏。提示词：一位法国女子必须攀越一个违背逻辑的世界，到处都是飞行物体。这会是游戏行业的终结吗？」&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530924" data-ratio="0.534375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rceqBX8UmzSksxVNmx6NxxibG3Ghtp8sfIIJE5UJs0wYOw32icSpuPZic2w/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/aef37973-b6d1-407b-af2f-373fc5ebbb7d/640.gif" data-order="2" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;「Genie 3 能运行《毁灭战士》（Doom）吗？看它生成的《毁灭战士》，墙壁全是由同样在运行《毁灭战士》的屏幕组成；主角是《毁灭战士》里的陆战队员，但他的头也是一个正在运行《毁灭战士》的屏幕。」&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc1TZEWjictXsUZXXgibEDibvW3nRwf1gjIe6XA7hXKZc1mmyyJGGuU1foA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.5359477124183006" data-s="300,640" data-type="gif" data-w="612" type="block" data-imgfileid="503530930" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/18f97b0c-d721-47cd-b328-74b4eefbc908/640.gif" data-order="3" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;「Genie 3 在建模和物理模拟方面是一个巨大的飞跃，但仍存在一些待解决的问题，比如一只头顶着鸭子的水獭飞行员正走在一家罗斯科（Rothko）风格的机场里；以及一只穿着翼装的水獭正飞越一座充满哥特式塔楼的城市。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rckSahT2eHWqwAr8QUw3ruYL2vGsVpNnHL8q8zib3MG0WC87y9iavVgavw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.5163398692810458" data-s="300,640" data-type="gif" data-w="612" type="block" data-imgfileid="503530931" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/15d7cd3a-7518-4508-bb9f-53eb3a3ebedb/640.gif" data-order="4" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcuiaia2BfFL0yxvg5Ke2VfAfIXc5m1dhKUWMNEyqlZbqkomDzLyOwe4KQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.5163398692810458" data-s="300,640" data-type="gif" data-w="612" type="block" data-imgfileid="503530932" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8d012c20-5802-409a-b6f2-d63a4ed837de/640.gif" data-order="5" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;「看 Genie 3 生成的人物是怎么打开车门的，这简直太令人震撼了。」&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcsZoHXw6oWR1icjBBWaPTUzxkdicQXXWyjxBmgTZibGbibNndmzLEDGuSgA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.5163398692810458" data-s="300,640" data-type="gif" data-w="612" type="block" data-imgfileid="503530933" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/1cf6657a-3a05-4f3a-9b87-1cb45b954498/640.gif" data-order="6" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;「画面提示词为：一个男人正沿着好莱坞大道漫步。不仅能控制这个男人的动作，还能实时操控相机的视角。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcRtHf560K4S6J32y8LVmxQzick2orggvByuibxz5gwMAI81ngPUDnEbicQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.5163398692810458" data-s="300,640" data-type="gif" data-w="612" type="block" data-imgfileid="503530935" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/1fc99637-5540-4796-b5f2-6f7b2a230218/640.gif" data-order="7" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/TrueSlazac/status/2016959063699906740?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/emollick/status/2016982218506199531&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/emollick/status/2016919989865840906?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/EHuanglu/status/2016926887151354255?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>揭秘！RLVR/GRPO中那些长期被忽略的关键缺陷</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 17:37:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/4188c4a4-eb59-46a0-9b27-17066f141a3a/640.png" alt="图片" data-report-img-idx="51" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近年来，大模型在数学推理、代码生成等任务上的突破，背后一个关键技术是 &lt;strong&gt;RLVR（Reinforcement Learning with Verifiable Rewards）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;简单来说，RLVR 不是让模型「听人打分」，而是让模型自己尝试多种解法，然后用可验证的规则（如答案是否正确）来反向改进自己。这使得模型能够通过反复试错不断变强，被广泛应用于当前最先进的推理模型中。&lt;/p&gt;&lt;p&gt;在实际训练中，为了让学习过程更稳定、避免引入额外的价值网络，许多 RLVR 方法（如 GRPO）都会对同一个问题生成一组回答，并在组内进行相对比较。模型不是直接看「这个回答好不好」，而是看「它在这一组回答中相对好不好」，这就是所谓的&lt;strong&gt;组内优势估计（group-relative advantage）&lt;/strong&gt;，也是目前几乎所有 group-based 强化学习方法的核心设计。优势估计并不仅仅是一个「评估指标」，而是直接决定策略梯度更新方向的核心信号。&lt;/p&gt;&lt;p&gt;然而，一个长期被忽视的关键问题在于：&lt;strong&gt;组内优势估计并不像人们通常直觉认为的那样是「近似无偏」的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;相反，&lt;strong&gt;北航、北大、UCB、美团&lt;/strong&gt;最新的工作揭示了，这种组内优势估计在统计意义上存在&lt;strong&gt;明确且系统性的方向性偏差：困难题的优势会被持续低估，而简单题的优势则被不断高估&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tSAghRXo2ft0za8WWMtAKXAkU3RSCBNcvZnMgTJsJvLhNbcmqMTjdqw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.26944444444444443" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530526" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1006ee0b-42f6-4e93-a166-655007999a73/640.png" alt="图片" data-report-img-idx="50" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/pdf/2601.08521&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一偏差带来的后果往往十分隐蔽，却极具破坏性。训练过程中，曲线表面上看似「稳定收敛」，但模型实际上正在&lt;strong&gt;逐渐回避困难问题、转而偏好简单样本&lt;/strong&gt;。随着训练的推进，探索与利用之间的平衡被悄然打破，模型的泛化能力与长期训练稳定性也随之下降。&lt;/p&gt;&lt;p&gt;更关键的是，这并非一个可以通过简单调整超参数来缓解的问题，而是组内优势估计这一设计在统计结构层面本身就存在的内在缺陷。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;接下来，我们先引入若干必要的定义，以便于清晰表述后续的核心发现。我们首先给出最常用的组内相对优势估计的数学定义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;组内相对优势估计（Group-relative Advantage） ：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在一个训练回合&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t33tyWOicD1DpBrl49SZfRZzftqY7ud57PvNic5BiaG6qQBRhamiaMvuZgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.391304347826087" data-s="300,640" data-type="png" data-w="46" type="block" data-imgfileid="503530528" data-aistatus="1" data-original-style="width: 20px;height: 28px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9e49e5a4-62e8-4c14-9bc6-2a4d18cef471/640.png" alt="图片" data-report-img-idx="48" data-fail="0" class="fr-fic fr-dii" style="width: 2.86%;"&gt;，对于一个给定的提示（prompt）&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t5jGUCqO6icnOgiciciaWv95uTP3VYcLictjicyS4mwv7QzKxu39Igrx1xLWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8857142857142857" data-s="300,640" data-type="png" data-w="70" type="block" data-imgfileid="503530529" data-aistatus="1" data-original-style="width: 31px;height: 27px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/208c8848-2780-4315-9657-46f0a7cf5266/640.png" alt="图片" data-report-img-idx="47" data-fail="0" class="fr-fic fr-dii" style="width: 3.7%;"&gt;，算法从当前策略&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCTUr8rlgotGSEibakfpd9YYUtD6Fka1vxPxZ4HkicbzAsx9nW9rRgCPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0277777777777777" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530530" data-aistatus="1" data-original-style="width: 30px;height: 31px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/fed17959-76e3-4c81-bc8e-703ba39ca42a/640.png" alt="图片" data-report-img-idx="45" data-fail="0" class="fr-fic fr-dii" style="width: 3.7%;"&gt; 中独立采样 G 个响应，并获得对应的 G 个奖励&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tvX3PKlNMvjBVwU8ZxOX4A5D9Vw9ObjgV02J01gzk1d1FnSmaEFk6bA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.3181818181818181" data-s="300,640" data-type="png" data-w="44" type="block" data-imgfileid="503530531" data-aistatus="1" data-original-style="width: 20px;height: 26px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3b1b3f64-fc1e-45c9-94b2-8b7ce3b054e4/640.png" alt="图片" data-report-img-idx="49" data-fail="0" class="fr-fic fr-dii" style="width: 2.86%;"&gt;。随后，将组内的平均奖励 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tSyJYC6VxbqO1AjGdO1cTOqUDcCBLwpbwc0jlXXj1HjT0VTIvGP4ic5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.394736842105263" data-s="300,640" data-type="png" data-w="76" type="block" data-imgfileid="503530532" data-aistatus="1" data-original-style="width: 20px;height: 28px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/f2bb8e89-2bc4-40f9-b293-d7ffa7863860/640.png" alt="图片" data-report-img-idx="46" data-fail="0" class="fr-fic fr-dii" style="width: 2.64%;"&gt;作为 baseline ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tZrs8QYkd2ZBeLxoWBaTjc8y7RDQpXsxG9UPt8g2IDOMjAf5RfUk9Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.47435897435897434" data-s="300,640" data-type="png" data-w="312" type="block" data-imgfileid="503530533" data-aistatus="1" data-original-style="width: 162px;height: 77px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/27915dd6-2f31-4352-9b9c-20db4378d76b/640.png" alt="图片" data-report-img-idx="44" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;并据此计算每个响应的组内相对优势估计&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tvMsm32PRdh2apHbdhuQWqgzMahf7AQSAG0zjfW2X3MZkcqXxLDzWUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.0476190476190477" data-s="300,640" data-type="png" data-w="84" type="block" data-imgfileid="503530534" data-aistatus="1" data-original-style="width: 27px;height: 28px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/54461544-32bf-4d62-b408-f0030fa70163/640.png" alt="图片" data-report-img-idx="42" data-fail="0" class="fr-fic fr-dii" style="width: 4.76%;"&gt;：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tPnMop0LFaZPibSONiarpLKV8bmBibh3eUNruzCTtslaib9WaB8yv2onETQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.37373737373737376" data-s="300,640" data-type="png" data-w="396" type="block" data-imgfileid="503530535" data-aistatus="1" data-original-style="width: 161px;height: 60px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/00995323-990e-4915-82dd-717197c3b1c8/640.png" alt="图片" data-report-img-idx="43" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;为便于阐述理论结论，下文中我们忽略标准化项。为了分析组内优势估计的统计性质，我们需要引入策略在给定提示下的真实期望表现和优势，并将其作为后续讨论的参照基准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;期望奖励：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 &lt;strong&gt;RLVR &lt;/strong&gt;设定下，考虑一个给定的提示&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5358fb56-d924-42b8-8635-2a0a41c36974/640.png" alt="图片" data-report-img-idx="39" data-fail="0" class="fr-fic fr-dii" style="width: 3.81%;"&gt;, 在 0&amp;ndash;1 奖励假设下，我们将策略 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCTUr8rlgotGSEibakfpd9YYUtD6Fka1vxPxZ4HkicbzAsx9nW9rRgCPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0277777777777777" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530530" data-aistatus="1" data-original-style="width: 30px;height: 31px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/b8b69657-0341-4887-84cf-2a707e6ab668/640.png" alt="图片" data-report-img-idx="41" data-fail="0" class="fr-fic fr-dii" style="width: 4.55%;"&gt;在该提示上&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/7d90ad0a-74be-470c-b19b-3ffe590164cd/640.png" alt="图片" data-report-img-idx="40" data-fail="0" class="fr-fic fr-dii" style="width: 4.44%;"&gt;的期望奖励定义为&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tAcuhBMGVzxnBaeibibvAvvQhpegY9cjceUIicfWSoX54knV9n6DibibQrEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.10648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530537" data-aistatus="1" data-original-style="width: 365px;height: 39px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/c90aa69e-1b7e-419d-9903-77edf88f1994/640.png" alt="图片" data-report-img-idx="38" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;由此构造的组内平均奖励&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tSyJYC6VxbqO1AjGdO1cTOqUDcCBLwpbwc0jlXXj1HjT0VTIvGP4ic5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.394736842105263" data-s="300,640" data-type="png" data-w="76" type="block" data-imgfileid="503530532" data-aistatus="1" data-original-style="width: 20px;height: 28px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/85efd063-4b32-4b8a-bd7b-b3860b318dae/640.png" alt="图片" data-report-img-idx="36" data-fail="0" class="fr-fic fr-dii" style="width: 3.07%;"&gt;，可被视为&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tLHvlZ0qykWSriaVtQeyq9dj3MTcAx7PsS7yrsLV8goG6J760IGW332A/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.2857142857142858" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530538" data-aistatus="1" data-original-style="width: 20px;height: 26px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/5265935a-8bfa-4aaf-960b-0bc27575dcc8/640.png" alt="图片" data-report-img-idx="37" data-fail="0" class="fr-fic fr-dii" style="width: 3.38%;"&gt;的一个有限样本经验估计。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;期望优势：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于此，对于每一个响应&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tQhV5TnHXN4pGUBOyW6rkM0EH8ibMBoQE6sPOMmjM8LqhhAt1PIxMd1w/640?wx_fmt=jpeg#imgIndex=16" data-ratio="0.8064516129032258" data-s="300,640" data-type="png" data-w="93" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t0Iu9SJ6e0Q8XktyDvXJwKT4BkXxI7tr8wP6LTrmyrc2qAeEBe1hV6w/0?wx_fmt=png&amp;from=appmsg" data-cropx1="10" data-cropx2="104" data-cropy1="3" data-cropy2="78" data-imgfileid="503530539" data-aistatus="1" data-original-style="width: 34px;height: 27px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/2b5e37ad-9f02-4486-8c03-319839ecfd15/640.png" alt="图片" data-report-img-idx="34" data-fail="0" class="fr-fic fr-dii" style="width: 4.97%;"&gt;和其奖励&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t6NCv3NLXiafeF4S5kXnibTc8YvpSzf4DzVgUGSyC3CFTD9QbrDotAdbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6875" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530541" data-aistatus="1" data-original-style="width: 36px;height: 25px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/3c305a8f-13d3-4929-818f-253e660041a6/640.png" alt="图片" data-report-img-idx="35" data-fail="0" class="fr-fic fr-dii" style="width: 5.82%;"&gt;，其&lt;strong&gt;真实（期望）优势&lt;/strong&gt;定义为&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tNcSbKYCjY39N43Ws7W0Q1ewpgoSJlI8p3lNZ53AujIQqDl2EcJicCgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.3090909090909091" data-s="300,640" data-type="png" data-w="550" type="block" data-imgfileid="503530542" data-aistatus="1" data-original-style="width: 185px;height: 57px;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/351a9878-9cb1-418d-b382-e64e523f9d10/640.png" alt="图片" data-report-img-idx="30" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;在 RLVR 中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiabXwGOviau01XNEzfPgEJdtGzJQYTqh26euRhOtgXPupHSPzaLXPzNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.8292682926829268" data-s="300,640" data-type="png" data-w="82" type="block" data-imgfileid="503530543" data-aistatus="1" data-original-style="width: 31px;height: 26px;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/884757d8-bd32-403c-bee4-150bcda4f1e1/640.png" alt="图片" data-report-img-idx="31" data-fail="0" class="fr-fic fr-dii" style="width: 4.87%;"&gt;表示响应&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tQhV5TnHXN4pGUBOyW6rkM0EH8ibMBoQE6sPOMmjM8LqhhAt1PIxMd1w/640?wx_fmt=jpeg#imgIndex=20" data-ratio="0.8064516129032258" data-s="300,640" data-type="png" data-w="93" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t0Iu9SJ6e0Q8XktyDvXJwKT4BkXxI7tr8wP6LTrmyrc2qAeEBe1hV6w/0?wx_fmt=png&amp;from=appmsg" data-cropx1="10" data-cropx2="104" data-cropy1="3" data-cropy2="78" data-imgfileid="503530539" data-aistatus="1" data-original-style="width: 34px;height: 27px;" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/5149b21b-25b5-482b-8ca5-7a03181258af/640.png" alt="图片" data-report-img-idx="32" data-fail="0" class="fr-fic fr-dii" style="width: 4.97%;"&gt;在真实期望意义下的优势，而&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmoPK1ictgFBKFNV9U7qmKBwqWibrj7KdJKavrvdBoU3y9O9jePUkFOvw/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.9166666666666666" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530544" data-aistatus="1" data-original-style="width: 28px;height: 26px;" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/f310dd24-9978-4c58-80af-55a2d87654f8/640.png" alt="图片" data-report-img-idx="33" data-fail="0" class="fr-fic fr-dii" style="width: 4.76%;"&gt;则是通过有限组内采样得到的优势经验估计量。&lt;/p&gt;&lt;p&gt;为了刻画不同提示在训练中所处的难易程度，并分析偏差在不同难度区域的行为差异，我们引入如下基于期望奖励的题目难度定义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;题目难度：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这里，我们首先给出题目难度定义，即给一个&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/ea2d6764-4953-4a49-8325-c92bef7a0319/640.png" alt="图片" data-report-img-idx="27" data-fail="0" class="fr-fic fr-dii" style="width: 3.91%;"&gt;, 如果&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiauznOHt9JiaCjeg6Vu7grWpcghb4NZXZath4GeibZ7fAbnpxsGM0AcIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="1.2758620689655173" data-s="300,640" data-type="png" data-w="58" type="block" data-imgfileid="503530545" data-aistatus="1" data-original-style="width: 23px;height: 29px;" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/42856b64-9759-4c92-b5c8-489f0ee2cd46/640.png" alt="图片" data-report-img-idx="29" data-fail="0" class="fr-fic fr-dii" style="width: 3.81%;"&gt;小于 0.5，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;我们认为他是难题。相反，如果&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiauznOHt9JiaCjeg6Vu7grWpcghb4NZXZath4GeibZ7fAbnpxsGM0AcIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="1.2758620689655173" data-s="300,640" data-type="png" data-w="58" type="block" data-imgfileid="503530545" data-aistatus="1" data-original-style="width: 23px;height: 29px;" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/f41fafa5-c816-45a3-896e-1c665f05d069/640.png" alt="图片" data-report-img-idx="28" data-fail="0" class="fr-fic fr-dii" style="width: 3.91%;"&gt;&amp;nbsp;大于 0.5，&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;我们认为它是一道简单题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;最后，在基于组的策略优化方法中，并非所有采样组都会对参数更新产生有效贡献。为聚焦于真正驱动学习的情形，我们需要显式排除那些导致梯度消失的退化情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;非退化梯度事件：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;R 表示奖励总和:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0trjC74B7iaibp0Iwb6jSgibADYfWOtQNf8wGuqwk9XpUMeMBTGgZDsdamg/640?wx_fmt=png&amp;from=appmsg#imgIndex=25" data-ratio="0.31636363636363635" data-s="300,640" data-type="png" data-w="550" type="block" data-imgfileid="503530546" data-aistatus="1" data-original-style="width: 204px;height: 65px;" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/3fb86117-cd1e-4582-8dc6-c4e088bcfd8a/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;则组内优势估计也可以表示为&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t2Cah3ibCgw8R0oIOeFADTSCd4xHIsjQ1mmrSEVrH3WqP90AicIdlmqJQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.336283185840708" data-s="300,640" data-type="png" data-w="226" type="block" data-imgfileid="503530547" data-aistatus="1" data-original-style="width: 85px;height: 29px;" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/d2e59b0e-1b0e-4565-a61e-e329fdee4bdc/640.png" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dii" style="width: 12.59%;"&gt;。在基于组的策略优化方法中，当某一提示&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tCnGuuEw4vE0M0dV7VSvlztic13wbcEEmbUaQIqLlyhmJg9NiaJmRg2xw/640?wx_fmt=png&amp;from=appmsg#imgIndex=27" data-ratio="0.8888888888888888" data-s="300,640" data-type="png" data-w="72" type="block" data-imgfileid="503530536" data-aistatus="1" data-original-style="width: 27px;height: 24px;" data-index="29" src="https://image.jiqizhixin.com/uploads/editor/d44f6b27-c86a-416e-9d13-d7d74c1fd755/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dii" style="width: 4.23%;"&gt;的 G 个采样响应&lt;strong&gt;全部错误（R=0）或全部正确（R=G）&lt;/strong&gt;时，组内相对优势满足:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tvb7Lh5LIFaNAwzzmZ7WSGaU6z6EObcnnPMB6ntpQoSn3YqzNq7V2mA/640?wx_fmt=png&amp;from=appmsg#imgIndex=28" data-ratio="0.21777777777777776" data-s="300,640" data-type="png" data-w="450" type="block" data-imgfileid="503530548" data-aistatus="1" data-original-style="width: 164px;height: 36px;" data-index="30" src="https://image.jiqizhixin.com/uploads/editor/3d55a307-85e6-4567-bf8e-ad14c068810f/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;从而导致梯度消失，参数不发生更新。实践中，这类&lt;strong&gt;退化组&lt;/strong&gt;不提供有效学习信号，通常被 GRPO 及其变体显式或隐式地忽略。因此，我们将分析聚焦于&lt;strong&gt;实际驱动学习的有效更新区间&lt;/strong&gt;，即至少存在一个非零优势的情形。形式化地，定义&lt;strong&gt;非退化事件&lt;/strong&gt;:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tXfPc3OhgJmjOQaAghZ6LwOnsUEPVzaEI3BMha6bgscEF8KMqgcxQnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=29" data-ratio="0.1891891891891892" data-s="300,640" data-type="png" data-w="518" type="block" data-imgfileid="503530550" data-aistatus="1" data-original-style="width: 235px;height: 44px;" data-index="31" src="https://image.jiqizhixin.com/uploads/editor/ea57387a-f86f-49ad-9de7-85797e61536f/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;&lt;p&gt;对 S 进行条件化并不会改变优化目标或训练轨迹，而仅刻画那些真正参与参数更新的样本子集，使我们能够精确分析组相对优势估计中的系统性偏差。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心发现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重要发现 1：&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0twmKtwDmDpdCXia3yR2Nb9Nvm0FcalePu9TcicXQBlKiaIv0tkMfwuPiaRg/640?wx_fmt=png&amp;from=appmsg#imgIndex=30" data-ratio="0.7022900763358778" data-s="300,640" data-type="png" data-w="786" type="block" data-imgfileid="503530551" data-aistatus="1" data-original-style="width: 295px;height: 207px;" data-index="32" src="https://image.jiqizhixin.com/uploads/editor/2436bef0-1c15-40ee-8209-eec30a7154cc/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;定理 1 揭示了组相对优势估计的一个根本性质。在非退化事件 S 条件下，&lt;strong&gt;基于组的优势估计&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tyuLG4qXylAHiaKsfls2WKFlIEfGdAY4yuiapwPpfQDjicnibeQ5gGicc07A/640?wx_fmt=png&amp;from=appmsg#imgIndex=31" data-ratio="1" data-s="300,640" data-type="png" data-w="74" type="block" data-imgfileid="503530552" data-aistatus="1" data-original-style="width: 23px;height: 23px;" data-index="33" src="https://image.jiqizhixin.com/uploads/editor/d36cb460-7b16-4835-8403-f71e44fc4770/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dii" style="width: 4.23%;"&gt;, 对不同难度的提示表现出&lt;strong&gt;系统性偏差&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;困难提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=32" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="34" src="https://image.jiqizhixin.com/uploads/editor/256b9a23-6848-4ab8-b0b3-3c2ff9546787/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dii" style="width: 3.03%;"&gt;&amp;lt;0.5)，其期望值&lt;strong&gt;系统性低于&lt;/strong&gt;真实优势&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0ttA8QkO3fdnzu8oxPMLUDf7rU4ibhh7my9a4roHssTEaKZPtReSfnUKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=33" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530554" data-aistatus="1" data-original-style="width: 30px;height: 24px;" data-index="35" src="https://image.jiqizhixin.com/uploads/editor/b29352c2-5968-45d7-9eb7-f26ec6363c34/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dii" style="width: 5.4%;"&gt;（即其真实优势被低估）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;简单提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=34" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="36" src="https://image.jiqizhixin.com/uploads/editor/07830a85-727f-4a98-a55c-b4e4068948f3/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 3.24%;"&gt;&amp;gt;0.5$$)，其期望值&lt;strong&gt;系统性高于&lt;/strong&gt;真实优势&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0ttA8QkO3fdnzu8oxPMLUDf7rU4ibhh7my9a4roHssTEaKZPtReSfnUKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=35" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="96" type="block" data-imgfileid="503530554" data-aistatus="1" data-original-style="width: 30px;height: 24px;" data-index="37" src="https://image.jiqizhixin.com/uploads/editor/f9a2770a-4c68-4a5e-92de-9eb4af436056/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dii" style="width: 5.4%;"&gt;（即其真实优势被高估）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;仅当&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=36" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="38" src="https://image.jiqizhixin.com/uploads/editor/60337073-f9a2-40be-bfcb-414fdfe0a77c/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dii" style="width: 3.24%;"&gt;=0.5，组相对优势估计才是&lt;strong&gt;无偏&lt;/strong&gt;的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一结论表明，组相对优势的偏差并非由有限采样噪声引起，而是源自其相对优势估计机制本身，且与提示难度密切相关。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tlHLXGKJ2eqgseCMf26CdKBDXOIgicQIM7EEo4zJ8C8zibqLQ9ic6xp3dw/640?wx_fmt=png&amp;from=appmsg#imgIndex=37" data-ratio="0.6648148148148149" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530555" data-aistatus="1" data-original-style="width: 305px;height: 203px;" data-index="39" src="https://image.jiqizhixin.com/uploads/editor/be5e2d3a-0e91-4e71-a3ed-e3e5cb441451/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时，我们对这种优势估计偏差进行了&lt;strong&gt;系统性的可视化分析&lt;/strong&gt;。如图所示，在非退化事件 S 条件下，组相对优势估计的偏差&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tiakbtg8uGmk9ElY8DjKhbKq58wbRIxepQIH8gTIxsXZs9V6FJGpw0Dw/640?wx_fmt=png&amp;from=appmsg#imgIndex=38" data-ratio="0.24175824175824176" data-s="300,640" data-type="png" data-w="364" type="block" data-imgfileid="503530556" data-aistatus="1" data-original-style="width: 112px;height: 27px;" data-index="40" src="https://image.jiqizhixin.com/uploads/editor/54ec4e2a-a3dc-4925-80bf-3a81790220dc/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dii" style="width: 17.24%;"&gt;，随提示难度呈现出明显的结构性变化 :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;当&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=39" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="41" src="https://image.jiqizhixin.com/uploads/editor/e4d262a9-1669-4d79-b730-63c8c2dd1be7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 3.35%;"&gt;&amp;nbsp;偏离 0.5 越远（即提示越困难或越简单）时，优势估计的偏差越大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在相同的提示难度下，G 越小，优势估计偏差越大；随着 G 的增加，偏差虽有所缓解，但在有限采样范围内仍然不可忽略。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;举例 1：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;假设一个非常难的问题，模型原本做对的概率只有 1%（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=40" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="42" src="https://image.jiqizhixin.com/uploads/editor/b725a1fc-43bb-479a-b9a2-51bd26fec397/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.49%;"&gt;=0.01）。如果你采样了 8 次，按照 1% 的这个概率来做的话原本模型大概率是全错的，这些数据会被丢弃，不产生梯度。但是一旦这 8 个回答里面至少有 1 个问题做对了，这个时候组内的 Baseline &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tEGfibZMkJ6E9ibrOLUPhvvsmQ4Tm8WXQrxJib1u0GfI7oyFgu8egkEVibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=41" data-ratio="1.2058823529411764" data-s="300,640" data-type="png" data-w="68" type="block" data-imgfileid="503530557" data-aistatus="1" data-original-style="width: 24px;height: 29px;" data-index="43" src="https://image.jiqizhixin.com/uploads/editor/105226c1-9ae6-4060-9126-ac7e9bb55658/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 3.81%;"&gt;就会瞬间被拉高到至少 0.125 参加梯度更新，和原本&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=42" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="44" src="https://image.jiqizhixin.com/uploads/editor/d69f4a9b-9b86-4a99-98a5-6c1bc554e0a2/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.38%;"&gt; =0.01 差距非常大。这导致计算出的优势估计就会变小&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tf3P8cF7rDZAM5c2y4RpdI66LErpYXlo3H3udjEpotsPHkZXIUvUBBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=43" data-ratio="1.02" data-s="300,640" data-type="png" data-w="100" type="block" data-imgfileid="503530559" data-aistatus="1" data-original-style="width: 27px;height: 28px;" data-index="45" src="https://image.jiqizhixin.com/uploads/editor/d9c3292f-27b8-47f1-823f-0b19fd740cd9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 4.02%;"&gt;&amp;le; 0.875，与真实的优势&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t7AlCclxCwCbIZGXRDjQdiaSA2ocwh9jmxgxQyGWmQ0toEXRBEH5h5mw/640?wx_fmt=png&amp;from=appmsg#imgIndex=44" data-ratio="0.7878787878787878" data-s="300,640" data-type="png" data-w="66" type="block" data-imgfileid="503530560" data-aistatus="1" data-original-style="width: 32px;height: 25px;" data-index="46" src="https://image.jiqizhixin.com/uploads/editor/7b35985d-b4b0-4140-b908-e0ce6bffff37/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 4.97%;"&gt;=0.99 产生巨大偏差，即优势被显著低估。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;举例 2：&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t0wqqib7O98rrZtGS3ZFVvfXtEfwYmRTeeMu3R0oO8UlFqZhRvdsnbkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=45" data-ratio="0.6764044943820224" data-s="300,640" data-type="png" data-w="890" type="block" data-imgfileid="503530561" data-aistatus="1" data-original-style="width: 377px;height: 255px;" data-index="47" src="https://image.jiqizhixin.com/uploads/editor/f9a8a113-cb8c-4138-aeb3-a89f912eb5d0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该图展示了在 MATH 数据集上，对于同一道困难题目，组相对优势估计在不同回答采样数量下的表现差异。当采用 8 次采样时，对正确回答所计算得到的优势为 A=2.65；而当采样数量提升至 128 次时，所估计的优势增大至 A=3.64，更接近其真实优势值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重要发现 2：&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tU4JWDcUiauf5mibj9GzObqG7pEPd8yCMBkW9xDQ4bNADTGzGuhLFzvfQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=46" data-ratio="0.7843137254901961" data-s="300,640" data-type="png" data-w="612" type="block" data-imgfileid="503530562" data-aistatus="1" data-original-style="width: 348px;height: 273px;" data-index="48" src="https://image.jiqizhixin.com/uploads/editor/c625565e-5df0-47e8-b7b1-88c9a407e9f9/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为此，进一步给出了优势估计偏差的概率化刻画。如推论 1 所示，在实际常用的组大小范围 G = 8 时，组相对优势估计以&lt;strong&gt;较高概率&lt;/strong&gt;对不同难度的提示产生系统性偏差：对于&lt;strong&gt;困难提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=47" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="49" src="https://image.jiqizhixin.com/uploads/editor/6a0286de-4bb0-4b2f-8c00-93f03b5391be/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 3.38%;"&gt;&amp;lt;0.5），其优势被低估的概率超过 0.63；对于&lt;strong&gt;简单提示&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=48" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="50" src="https://image.jiqizhixin.com/uploads/editor/94700379-9f1c-44d0-925f-30682a1d2299/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 3.6%;"&gt;&amp;nbsp;&amp;gt;0.5），其优势被高估的概率同样超过 0.63。当提示难度进一步加剧扩大时，这一概率上界进一步提升至 0.78 甚至 100%，表明偏差随难度加深而显著放大。&lt;/p&gt;&lt;p&gt;论文也提供具体偏差量估计：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t2iasLnTnsa8XLn9TUVGZFplSjnEqH2o6QhUTW1xE3DTompEn8BBZJMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=49" data-ratio="1.0496688741721854" data-s="300,640" data-type="png" data-w="604" type="block" data-imgfileid="503530563" data-aistatus="1" data-original-style="width: 334px;height: 351px;" data-index="51" src="https://image.jiqizhixin.com/uploads/editor/3d226803-01c1-46a7-9e38-4dd66f3f4037/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综上所述，组相对优势估计（Group-relative Advantage）在理论上除&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tmZ1ZKsd4vicCoicljqraZ9jeKeKJnwA3N5C2I5baECfqtr1uHUrGCr2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=50" data-ratio="1.1071428571428572" data-s="300,640" data-type="png" data-w="56" type="block" data-imgfileid="503530553" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="52" src="https://image.jiqizhixin.com/uploads/editor/555f22c1-41e8-4fc5-99c6-08b91415fc0b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dii" style="width: 3.17%;"&gt;= 0.5 外均是有偏的。因为 GRPO/Group-based PO 会优势估计机制会强制将样本限制在子集 S 上，相当于对原来的样本全集进行了加权，即加权之后的优势估计是有偏的。&lt;/p&gt;&lt;p&gt;具体而言，该估计方法会对困难提示系统性地低估真实优势，而对简单提示系统性地高估真实优势。进一步地，对于极其困难的提示，优势估计必然被低估；而对于极其简单的提示，则必然被高估。&lt;/p&gt;&lt;p&gt;尽管上述分析主要基于 &lt;strong&gt;0&amp;ndash;1 二值奖励&lt;/strong&gt;的设定，该假设覆盖了大量 RLVR 场景，尤其是依赖硬判别 verifier 的推理任务，但真实应用中的奖励信号往往更加一般。&lt;/p&gt;&lt;p&gt;为此，论文在附录 D.5 中将分析推广至&lt;strong&gt;连续且有界的奖励分布&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;结果表明，组相对优势估计中的核心偏差现象并非 Bernoulli 奖励假设的偶然产物，而是在更广泛的有界奖励模型中同样普遍存在。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这个发现告诉我们什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该发现对 RLVR 训练具有直接而深远的影响。&lt;/p&gt;&lt;p&gt;具体而言，组相对优势估计的系统性偏差会导致不同难度提示在学习过程中受到不平衡的梯度信号：对于困难提示，其真实优势被低估，从而产生较小的梯度更新，导致学习进展缓慢；而对于简单提示，其优势被高估，模型则容易对其过度强化。最终，这种不对称的优势估计会抑制有效探索，使训练过程偏向于反复强化简单样本，而忽视真正具有挑战性的提示。&lt;/p&gt;&lt;p&gt;基于上述分析，我们认为优势估计应当根据提示难度进行自适应调整：&lt;strong&gt;对于困难提示，应适当放大其估计优势以鼓励探索；而对于简单提示，则应抑制其优势以防止过度利用。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为在实践中判定提示难度，论文提出算法 &lt;strong&gt;HA-DW&lt;/strong&gt;，引入&lt;strong&gt;短期历史平均奖励&lt;/strong&gt;作为动态锚点，将新提示与该锚点进行对比，从而判断其相对难度，并据此对优势估计进行自适应重加权。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0t87gcI2zwD0riauscOK5GhrbwmeNZeEozSDWRbgBFmGJqOBplPDj5VUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=51" data-ratio="0.9220055710306406" data-s="300,640" data-type="png" data-w="718" type="block" data-imgfileid="503530565" data-aistatus="1" data-original-style="width: 293px;height: 270px;" data-index="53" src="https://image.jiqizhixin.com/uploads/editor/be34ad98-7667-416d-9459-4118e5717aca/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该图展示了在对组相对优势估计进行校正之后，不同难度提示上的性能变化。可以观察到，引入优势校正机制后（GRPO+HA-DW），&lt;strong&gt;模型在困难提示（Hard）上的性能提升最为显著，相比原始 GRPO 提升了 3.4%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GRPO/Group-based PO 的问题不只是 variance，而是 bias&lt;/strong&gt;。这项工作也释放了一个很强的信号：&lt;strong&gt;LLM 强化学习正在从「工程上能跑出效果就行」，回到「估计是不是准确」的根本问题和可解释性。&lt;/strong&gt;以后 RLVR 里，bias analysis /estimator correctness 很可能会成为标配。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>千问C端应用团队一口气四篇论文入选ICLR 2026国际顶会！</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 30 Jan 2026 16:29:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;当AI助手越来越多地参与到学习、工作辅助、医疗咨询等生活场景，能否稳定输出、是否懂得追问关键信息，正成为衡量AI能力的重要标准。&lt;/p&gt;&lt;p&gt;1月30日消息，千问C端应用团队的四篇人工智能领域研究论文入选2026国际学习表征会议（ICLR 2026），论文聚焦扩散模型训练、多轮对话决策、信息验证及模型价值观对齐等关键问题，部分成果已有实际应用，推动AI助手在复杂场景下更加聪明、可靠、实用。&lt;img src="https://image.jiqizhixin.com/uploads/editor/89d73168-232b-40a4-93c3-2af09a6621c5/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;ICLR与NeurIPS、ICML并称为机器学习和人工智能领域三大顶级国际会议。本届会议投稿量接近19000篇，接收率创下近年来新低。&lt;/p&gt;&lt;p&gt;本次四篇论文在多个前沿领域取得创新突破。在扩散语言模型（Diffusion Models）研究方面，千问C端应用团队针对dLLM独特的掩码训练不稳定性，将其系统分解为了三种不同的噪声来源，并相应提出帕累托最优的无偏训练算法。该算法显著降低了dLLM的训练波动、进而提升其图文生成质量。这意味着在内容生成、创作辅助等应用中，AI输出将更加稳定。&lt;/p&gt;&lt;p&gt;围绕医疗多轮对话中的复杂推理任务，团队提出了自适应树策略优化（ATPO）方法，使AI能够根据对话中的不确定性动态调整决策路径。当信息不足时，AI会主动追问关键问题；当线索清晰时，则快速给出判断。这一能力可帮助AI助手在医疗咨询等专业场景学会&amp;ldquo;主动问诊&amp;rdquo;，让AI像经验丰富的医生一样，只问最关键的问题，避免无用的来回对话。&lt;/p&gt;&lt;p&gt;在信息检索与验证方面，研究团队构建了&amp;ldquo;提问&amp;mdash;解答&amp;mdash;验证&amp;rdquo;的自博弈强化学习框架，使AI在无需人工标注的情况下不断自我验证与进化。这一机制有助于提升AI在复杂问题下的检索与核验能力，在学习辅助、研究支持等知识密集型场景中表现更为可靠。&lt;/p&gt;&lt;p&gt;此外，在模型价值观对齐研究中，团队引入信息论偏见消除方法，引导奖励模型关注真正与人类偏好相关的信号，减少冗长、格式化但信息密度不高的输出。这使得AI在训练过程中真正关注能够帮助到用户的核心要点，降低模型输出中出现&amp;ldquo;表面迎合但缺乏实质内容价值&amp;rdquo;的情况。&lt;/p&gt;&lt;p&gt;业内专家指出，当前大模型竞争正从&amp;ldquo;参数规模&amp;rdquo;转向&amp;ldquo;算法深度与工程实效&amp;rdquo;。千问C端应用团队在生成稳定性、多轮对话决策和模型对齐等方向上的系统性探索，体现了其在基础算法与应用导向研究上的持续投入。&lt;/p&gt;&lt;p&gt;值得一提的是，此次千问C端应用团队入选 ICLR 2026 的四篇论文相关代码均已开源。通过开放核心实现细节，将为行业在提升AI可用性、可靠性方面提供有益参考。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>蚂蚁灵波开源具身世界模型LingBot-VA，机器人复杂任务成功率较Pi0.5提升20%</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 30 Jan 2026 15:07:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1 月 30 日，继空间感知模型、具身大模型与世界模型&amp;ldquo;三连发&amp;rdquo;后，蚂蚁灵波科技今日宣布开源具身世界模型LingBot-VA。LingBot-VA首次提出自回归视频-动作世界建模框架，将大规模视频生成模型与机器人控制深度融合，模型在生成&amp;ldquo;下一步世界状态&amp;rdquo;的同时，直接推演并输出对应的动作序列，使机器人能够像人一样&amp;ldquo;边推演、边行动&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在真机评测中，LingBot-VA展现出对复杂物理交互的强适应能力。面对长时序任务（制作早餐、拾取螺丝）、高精度任务（插入试管、拆快递）以及柔性与关节物体操控（叠衣物、叠裤子）这三大类六项高难度挑战，仅需 30~50条真机演示数据即可完成适配，且任务成功率相较业界强基线 Pi0.5平均提升20%。&lt;img src="https://image.jiqizhixin.com/uploads/editor/cb3f5003-ae41-4d63-865b-52ac4b1a0909/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图说：真机评测中，LingBot-VA在多项高难操作任务上性能超越业界标杆 Pi0.5&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在仿真评测中，LingBot-VA在高难度双臂协同操作基准 RoboTwin 2.0 上首次将成功率提升至超过 90%，在长时序终身学习基准 LIBERO上达到 98.5% 平均成功率，均刷新了行业纪录。&lt;img src="https://image.jiqizhixin.com/uploads/editor/cd043118-5a3e-48b9-aa66-18a3ad57514b/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;图说：LingBot-VA在LIBERO与RoboTwin2.0仿真基准测试中刷新现有SOTA&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;据悉，LingBot-VA 采用Mixture-of-Transformers（MoT）架构，让视频处理与动作控制实现跨模态融合。通过独特的闭环推演机制，模型在每一步生成时都会纳入真实世界的实时反馈，确保持续生成的画面与动作不偏离物理现实，从而控制机器人完成高难复杂任务。&lt;/p&gt;&lt;p&gt;为突破大规模视频世界模型在机器人端侧落地的计算瓶颈，LingBot-VA 设计了异步推理管线，将动作预测与电机执行并行化处理；同时引入基于记忆缓存的持久化机制与噪声历史增强策略，让推理时只需更少生成步骤即可输出稳定、精确的动作指令。这一系列优化使得 LingBot-VA既拥有大模型的理解深度，又具备真机低延迟控制的响应速度。&lt;/p&gt;&lt;p&gt;蚂蚁灵波表示，承接前几日开源发布的 LingBot-World（模拟环境）、LingBot-VLA（智能基座）与 LingBot-Depth（空间感知），LingBot-VA 探索出一条&amp;ldquo;世界模型赋能具身操作&amp;rdquo;的全新路径。蚂蚁集团将持续依托 InclusionAI 社区开源开放，与行业共建具身智能基础能力，加速构建深度融合开源开放、且服务于真实产业场景的AGI生态。&lt;/p&gt;&lt;p&gt;目前，LingBot-VA的模型权重、推理代码已全面开源。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>中国科学院等提出的可扩展顺序式多PTM集成平台，处理时间缩短87.5%</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 30 Jan 2026 14:04:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;蛋白质翻译后修饰（post-translational modifications, PTMs）决定了蛋白质在细胞中的真实功能状态，其中以糖基化与磷酸化最具系统调控意义。然而，在实际蛋白组学研究中，由于样本拆分、并行处理、分别富集，再在计算层面勉强拼接，这些信息长期被迫分散在不同实验流程中获取。&lt;/p&gt;&lt;p&gt;这种策略在方法学上并非优雅的选择，而是一种历史妥协&amp;mdash;&amp;mdash;它带来的问题并不隐蔽：样本损耗成倍放大、流程时间冗长、批次效应叠加、定量一致性被结构性削弱。&lt;/p&gt;&lt;p&gt;来自中国科学院、重庆医科大、南昌赣江中药创新中心等研究团队提出并系统验证了一种顺序式多 PTM 蛋白组学平台&amp;nbsp;&lt;strong&gt;MuPPE（Multiplexed PTM Proteomics by Protein Aggregation）&lt;/strong&gt;。其核心思想是在单一样本、单一反应体系中，依次完成蛋白组、糖基化蛋白组与磷酸化蛋白组的捕获与解析，从根本上重构多 PTM 蛋白组学的工程逻辑。&lt;/p&gt;&lt;p&gt;相关研究内容以「A versatile platform for sequential glyco-, phospho-, and proteomics with multi-PTMs integration」为题，于 2026 年 1 月 28 日发布在《Nature Communications》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibtrVUzaeoWiaibGyrh0fjy31lt0jESSics8NtJF7D5VDn61alwV9vvfTpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.29692470837751855" data-type="png" data-w="943" data-width="943" data-height="280" data-imgfileid="100027322" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1af03c48-0b20-4ef2-8c74-b3870ca1358a/640.png" alt="图片" data-before-load-time="1769753031791" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41467-025-68270-7&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;蛋白聚集驱动的顺序式富集&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统多 PTM 蛋白组学流程的核心假设，是不同修饰类型需要彼此独立的富集化学环境与处理条件。因此，研究者通常在样本裂解后即进行拆分，每一份样本对应一种 PTM 富集策略。&lt;/p&gt;&lt;p&gt;这一做法在概念上简单，却在工程上代价高昂。首先，样本拆分会直接降低每一分支的起始物质量，使得低丰度修饰位点更易丢失；其次，不同富集流程之间不可避免地产生处理偏差，最终反映为定量噪声的系统性放大；更关键的是，这种并行流程天然不适用于样本量受限的场景，如临床体液或稀有组织。&lt;/p&gt;&lt;p&gt;研究团队在论文中明确指出，问题并不在于富集材料或质谱灵敏度的不足，而在于&lt;strong&gt;流程结构本身并不为「多层信息一致性」服务&lt;/strong&gt;。MuPPE 正是在这一判断基础上被提出，其目标不是增加某一 PTM 的覆盖率，而是&lt;strong&gt;在同一物理样本轨迹中，最大限度保留不同修饰层之间的真实对应关系&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibibnTD46hPbuZTv8j5pT8IDjCLNdAlgFL3RNzUDf0yAwpIkwiavibZNV2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9124087591240876" data-type="png" data-w="685" data-width="685" data-height="625" data-imgfileid="100027324" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/67dd3c74-3006-4d6b-967c-374a4992e853/640.png" alt="图片" data-before-load-time="1769753031848" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：MuPPE 平台实现了集成的多层次蛋白质组学，提升了效率和覆盖范围。&lt;/p&gt;&lt;p&gt;MuPPE 平台是一个整合蛋白质聚集捕获（PAC）、珠上消化和序列 PTM 富集的统一流程。作为原理验证，该平台使蛋白质组、糖蛋白组和磷蛋白组同时被探测成为可能。它从蛋白质变性、还原和烷基化开始，引入一种经过修改且可扩展的 PAC 方法，实现高效的蛋白质分离。&lt;/p&gt;&lt;p&gt;随后，研究者通过精心设计的顺序洗脱与酶解策略，使不同修饰层在同一载体上被依次释放并分析。整个过程中，样本始终处于单管、单体系中完成，没有发生任何物理拆分。这种顺序式设计的直接结果，是&lt;strong&gt;样本损耗被系统性压缩&lt;/strong&gt;，同时不同修饰层之间的相对定量关系得以最大程度保留。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率、一致性与覆盖度的系统评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在方法学评估中，研究团队首先对 MuPPE 与传统并行富集流程进行了直接对比。在处理时间上，MuPPE 将完整多 PTM 分析流程压缩至约 4 小时，相较传统方法动辄 24&amp;ndash;36 小时的处理周期，时间成本降低约 87.5%。这一压缩并非通过减少步骤实现，而是通过消除并行流程中的冗余处理完成。&lt;/p&gt;&lt;p&gt;在定量一致性方面，MuPPE 在多个生物重复实验中表现出显著更低的变异系数。无论是蛋白组、糖基化蛋白组还是磷酸化蛋白组，变异系数（CV%）均稳定维持在约 12&amp;ndash;15% 区间（平均 CV = 12.3%，而溶液中消化为 17.6%），而传统并行方法在相同条件下普遍超过 20%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibjcnuQPNQuqbwh6PRkSb751ca2T8xEjZ5RD2qFKOibPiafXiauNwYlSBJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0525547445255474" data-type="png" data-w="685" data-width="685" data-height="721" data-imgfileid="100027325" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/11619b8c-0ce8-4f46-874b-18679d4060cd/640.png" alt="图片" data-before-load-time="1769753032182" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：使用 MuPPE 对糖蛋白组、磷酸蛋白组和蛋白质组进行序列化分析。&lt;/p&gt;&lt;p&gt;覆盖度分析显示，MuPPE 在不牺牲深度的前提下，实现了对三类分子层级的稳定检测。数千个蛋白、上万条糖基化与磷酸化位点在单次实验中被同时解析，且不同修饰层之间的对应关系清晰可追溯。这一点在后续的生物学应用中尤为关键。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibz9ujTOa31EzKKzBicJ0kntsecR1XU4Pf2El2MeV7U9FCKCRKsjCXSOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.1167883211678833" data-type="png" data-w="685" data-width="685" data-height="765" data-imgfileid="100027323" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6fdc5e49-c55a-4edc-b718-07c778dbeba7/640.png" alt="图片" data-before-load-time="1769753032216" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 3：小鼠衰老队列的磷蛋白组、糖蛋白组和蛋白质组整合分析。&lt;/p&gt;&lt;p&gt;应用层面，MuPPE 适用于多种复杂生物样本，包括血清、脑组织以及脑脊液等低起始量或高复杂度体系。该平台在样本量受限条件下依然保持稳定的检测能力，且不同 PTM 层的信号强度与定量分布高度一致。&lt;/p&gt;&lt;p&gt;值得注意的是，论文并未刻意放大某一具体生物学发现，而是将重点放在方法本身在真实样本条件下的稳健性验证。这种克制的呈现方式，反而凸显了 MuPPE 作为平台级工具的通用潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;针对流程结构的蛋白组学重构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MuPPE 首次实现了单一样本中糖基化、磷酸化与总蛋白的串联分析，解决了传统方法样本需求量大、修饰间关联性难以捕捉的痛点。其在低样本量、高复杂性样本中表现出优异的富集效率和重现性，拓展了未注释 PTM 位点的发现。&lt;/p&gt;&lt;p&gt;该平台目前对单细胞水平的低蛋白样本仍需进一步优化，但不妨碍它在效率、一致性与样本利用率之间实现了难得的平衡。对于需要在有限样本中同时解析多层蛋白修饰信息的研究场景而言，这种工程层面的改变，可能比单一指标的提升更具长期影响。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>姚顺雨现场颁奖，吉嘉铭、董冠霆等15位青年人才获腾讯「青云奖学金」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 13:05:11 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;刚刚，腾讯「青云奖学金」正式在深圳颁奖。&lt;/section&gt;&lt;p&gt;作为腾讯支持青年人才和科学研究的项目，「青云奖学金」首期评选出 15 位获奖者，并为每位获奖者提供总价值 50 万的激励，包括 20 万现金和价值 30 万的云异构算力资源。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「我们希望青年研究者敢于探索未知、富有创新精神，追逐那些大胆的、前沿的、具有长远影响力的科研方向，共同探索更广阔的科技前沿。」腾讯集团高级副总裁、首席人才官奚丹说。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcI5t5mWTtOMCC0iarvlpGD8Prx9ZlR9NwrlyzrZIEHTfUicmMiavcnrvcg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="385" data-imgfileid="503530953" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9ff02c97-efd1-42c1-9b45-d8878c57cb13/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;不久之前正式入职腾讯出任「CEO / 总裁办公室」首席 AI 科学家的姚顺雨（Vinces Yao），也现身为获奖者颁奖。&lt;/span&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcyMwxFibmvibQDLeDqBiaFdg2WibZkZuyjrkwgMmicYUib5eGVgnicXOgRRicsA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.75" data-type="jpeg" data-w="1080" data-width="1706" data-height="1279" data-backw="578" data-backh="433" data-imgfileid="503530904" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/51941f1e-8211-4554-96e1-db25d062877e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;吉嘉铭、董冠霆、张金涛等多位机器之心熟知的青年 AI 学者获奖，以下为全部获奖者介绍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;白雨石&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcASm9eNKUQQPXt63akwVGntOiasqoI2KyjTLX1eSM3bahhibOLia36yIYg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5074074074074074" data-type="png" data-w="1080" data-width="1084" data-height="550" data-backw="578" data-backh="293" data-imgfileid="503530934" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/464a351a-9337-4ce6-87cd-d9ae97db862b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的白雨石，研究领域涉及长上下文大模型与大模型评测。截至目前，他已在 NeurIPS、ICML、ICLR、ACL 等国际顶会发表 10 篇一作论文，总引用量 4000 + 次，一作论文被引近 2000 + 次。开源的 LongBench、Long-Writer、LongAlign 等工作在 GitHub 共获 3000+ stars 及 300+ forks，在 HuggingFace 上开源的数据集和模型共被下载 200 万+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陈俊松&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc84gEniasZ8WdawBfQicibubFLC9N2w9JJ92ocTk081Yq6tRVj6VQsybqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.49907235621521334" data-type="png" data-w="1078" data-width="1078" data-height="538" data-backw="578" data-backh="288" data-imgfileid="503530936" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f92be927-fa3e-4001-bf0d-8008f8285414/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港大学的陈俊松，研究领域围绕 AIGC 高效视觉生成大模型，专注于扩散模型的高效部署研究，早期贡献了里程碑式的 PixArt 模型，近期主导的 SANA 系列实现效率突破：SANA 原生支持 4K 图像生成，SANA-Sprint 达成 0.1 秒实时成像，SANA-Video 支持分钟级长视频合成。成果累计引用量 2500 + 次及在 GitHub 获得 1 万 + stars，有力推动了高性能生成式 AI 在实时消费级场景的落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;董冠霆&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc9ll4vOLgPcKVOdVGeq2uAaJkdm9QnJLmATyOjuOyuWicp74Z2lCquGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5223880597014925" data-type="png" data-w="1072" data-width="1072" data-height="560" data-backw="578" data-backh="302" data-imgfileid="503530937" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/99a90f60-6e58-4dbd-b0df-771165a2a9e5/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自中国人民大学的董冠霆，主要研究方向为智能信息检索和智能体强化学习，曾获国家奖学金、北京市优秀毕业生等荣誉，并入选国家自然科学基金青年学生基础研究项目 (博士生)、中国科协青年人才托举工程博士生专项计划资助，代表工作包括 ARPO、AUTOIF.DMT、Search-o1、Webthinker、 FlashRAG 等, 受到国内外研究者的广泛关注。其中监督微调数据配比策略 DMT、自动化指令遵循对齐策略 AUTOIF 被落地应用于模型的对齐训练中。以第一 / 共一作身份在 ICLR、NeurlPS 等国际顶会发表论文 10 + 篇，谷歌学术引用量 1 万 + 次，GitHub 获得 8000+ stars。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;邓洋涛&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcKahbEqxL2Wg04DK6HfMTwT5vG3lDE9iaJ46cmACSoD1EZibsYYwBTKiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5046296296296297" data-type="png" data-w="1080" data-width="1082" data-height="546" data-backw="578" data-backh="292" data-imgfileid="503530938" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5b751551-894d-43e5-8371-deba7bee3a65/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港中文大学的邓洋涛，研究领域聚焦 AI 基础设施与系统，致力于攻克大语言模型预训练中的稳定性难题，设计并研发了细粒度、实时的数据依赖追踪与根因分析系统，研究工作已录用或发表于 SOSP、NSDI、NDSS、FSE 等会议，相关系统已在工业级预训练集群中部署，能针对异常进行快速告警。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;吉嘉铭&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcgbX3Kr49hOsm5UvNoXU7A8CSxN8icq7LycicoAbhkceXM35YaFibBSvzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5056179775280899" data-type="png" data-w="1068" data-width="1068" data-height="540" data-backw="578" data-backh="292" data-imgfileid="503530940" data-aistatus="1" data-original-style="width:100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/97b2c048-a63b-4300-aec9-8f00992c3e4d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自北京大学的吉嘉铭，研究领域是大模型安全与强化学习对齐，致力于构建和人类的偏好与意图对齐的人工智能系统，曾获北京大学 2025 年度人物，以第一 / 共一作身份发表人工智能领域顶会论文 14 篇，代表论文被评为 ACL 2025 最佳论文，相关成果谷歌学术总引用量 4600 + 次，GitHub 开源项目获得 3.2 万 + stars，开源模型累积下载量 500 万 + 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;林彬&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcTFxia3ZbKzfJl2D8yBHsFJAK5tds8gs7npPFzxL8nIVOeOk6YOQwpGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.49536178107606677" data-type="png" data-w="1078" data-width="1078" data-height="534" data-backw="578" data-backh="286" data-imgfileid="503530941" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/84d27559-86e4-4f4b-b1c5-fee35586d52c/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同样来自北京大学的林彬，研究方向聚焦于视频生成与多模态大模型，连续一年获评 HuggingFace 社区 Top100 影响力用户，代表作 Open-Sora Plan 与 Video-LLaVA，在 GitHub 累计获得 2 万 + stars，模型开源下载量突破 1300 万+ 次。在 CVPR、ICLR、NeurlPS 等国际顶会期刊发表十余篇论文，多项开源成果获 GitHub 与 Papers With Code 热度榜 Top1，谷歌学术引用量 3200+ 次，单篇一作引用量 1000+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;李磊&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc7wvGGXsvicDGPTxrfsMwDDcA3uhb4kKibOlqqp0pLspSzhOg9EiauhssQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5112359550561798" data-type="png" data-w="1068" data-width="1068" data-height="546" data-backw="578" data-backh="295" data-imgfileid="503530942" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c8fedafd-32d5-493d-a066-acfb5d17bbbd/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港大学的李磊专注于多模态大语言模型与可解释性研究，现任 ACL ARR 领域主席，获评 EMNLP 2025 杰出领域主席，与微信 AI 合作论文获 EMNLP 2023 最佳长文奖，多篇论文入选 CVPR Highlight 及 PaperDigest 最具影响力论文。核心参与开发 MiMo-VL-7B、MiMo-V2-Flash 并获得广泛关注，以第一作者在 ICLR、CVPR、ACL 等国际顶会发表多篇论文，谷歌学术引用量 8700+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;刘松铭&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcrgja38v4Qjr8IpWicwH09x0KMbFJ9TqBpyS86ylyYxtgIALjpUIHebA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5083798882681564" data-type="png" data-w="1074" data-width="1074" data-height="546" data-backw="578" data-backh="294" data-imgfileid="503530944" data-aistatus="1" data-original-style="width:100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/01eaefaa-410f-41eb-919e-015e47259c48/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的刘松铭，致力于具身大模型方向研究，曾获清华本科生特奖，主导研发机器人基础模型 RDT 系列：RDT-1B (ICLR 2025) 获得 1600+stars，RDT-2 作为全球首个 UMI 无本体训练的 7B 大模型，支持任意机械臂零样本部署，实现接箭、打乒乓球等毫秒级动态操控。累计发表 12 篇文章，总引用量 1300+ 次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;刘子君&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcQPFTPAOGvvmo1fBubNkKRIZts2Bn5hJGmSw0DeDH4DvKIeZjkCEcMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5103189493433395" data-type="png" data-w="1066" data-width="1066" data-height="544" data-backw="578" data-backh="295" data-imgfileid="503530945" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5afd6374-5fdf-45af-8269-2f2f2ced4909/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的刘子君，聚焦于大模型群体智能体系与推理时扩展方向研究，曾获国家奖学金、清华大学未来学者等荣誉，主持完成北京市自然科学基金学生项目，提出大模型群体智能体系的动态协同网络 DyLAN 与跨环境迁移算法 CollabUlAgents，实现了推理时高效扩展的通用奖励模型，在 ACL、ICML、COLM 等国际顶会发表多篇论文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;宋立阳&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcFdOfCGTKKU2wDbNr7vH85PP84ZGUB99CZLycmNGuboACby9vaKKuPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5" data-type="png" data-w="1064" data-width="1064" data-height="532" data-backw="578" data-backh="289" data-imgfileid="503530946" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c3fab14f-dfa7-4b36-b0da-52135c2457a1/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自西湖大学的宋立阳主要研究如何利用统计与深度学习算法来理解复杂疾病的遗传机制，围绕遗传数据与多组学数据的整合，开发了 MeDuS (Nature Computational Science,2023) 和 qsMap (Nature,2025) 等方法, 将遗传关联信号解析到具体的细胞状态和组织空间中，实现对疾病相关遗传根源细胞的精准定位。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;胥嘉政&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcjgib6HXcweDrkzhP7FbAzBS39qTAvQoPvZJPXbyIfgINmGCOEuhianTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.515828677839851" data-type="png" data-w="1074" data-width="1074" data-height="554" data-backw="578" data-backh="298" data-imgfileid="503530947" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/abe2b986-e53e-49d9-81a0-3b6cb21133ae/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的胥嘉政，专注于多模态生成模型和强化学习方向研究，代表作包括图像生成模型偏好强化对齐工作 lmageReward 和视频生成偏好框架 VisionReward，其中 lmageReward 是最早将人类偏好引入文生图领域的工作之一，并设计了首个基于梯度对扩散模型直接完成偏好对齐的算法 ReFL。谷歌学术总引用量 4000+ 次，lmageReward 研究引用量 1000+ 次，GitHub 获得 1600+ stars，Python 工具包 PyPi 官方下载量接近百万次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;徐明皓&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcm7Z7a0VauDJTPklJRmwLmXPlqBHlTNZO8LQdvEHG8eWqBK6mtaAclg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.5065913370998116" data-type="png" data-w="1062" data-width="1062" data-height="538" data-backw="578" data-backh="293" data-imgfileid="503530948" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/67d71d28-6fe8-4388-9de4-3f4f8d50ce9b/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自北京大学的徐明皓，研究聚焦于 Al for Science，北京大学和 Mila 魁北克人工智能研究所联培博士，在国际顶会和期刊上发表 20+ 篇论文，论文累计引用量 3000+ 次, 多次受邀在大会上进行报告分享，并组织开展生命科学大语言模型 tutorial。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;杨丽鹤&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rciatuMQvQXQudKKKhhOOkkiaiaxqPsKFibtRuJwVVNyEuutgSerq9AhLQZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.49906542056074765" data-type="png" data-w="1070" data-width="1070" data-height="534" data-backw="578" data-backh="288" data-imgfileid="503530949" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/2a770ac1-cfd4-4a39-bce4-322c97682ca0/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自香港大学的杨丽鹤研究方向专注于计算机视觉，曾获知名企业奖学金、世界人工智能大会青年优秀论文奖等荣誉，相关工作入选 CVPR 2024、NeurlPS 2024 十大最具影响力论文。在 CVPR、ICCV、NeurlPS、TPAMI 等国际顶会发表若干论文，谷歌学术引用量 5000+ 次，GitHub 获得 1.6 万+ stars。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;张金涛&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rca9eokbiciaPR38NxKkeCe0PlAKEUb9zqcQ8via0fguvuM9J2FkBQwNmJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.5112781954887218" data-type="png" data-w="1064" data-width="1064" data-height="544" data-backw="578" data-backh="296" data-imgfileid="503530951" data-aistatus="1" data-original-style="width:100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/1e43c7cd-a30d-4d07-b8cb-05769ec479a9/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的张金涛，研究聚焦高效机器学习系统，发表一作 A 类国际顶会长文 9 篇，均发表于 ML/DB 的三大顶会，代表作 SageAttention 是首个专注于低比特量化加速注意力计算的研究，相关成果在 GitHub 获得 3000+ stars，被 200+ 家知名企业的真实产品采用，其他一作代表作有 TurboDiffusion、SpargeAttn、Sparse-Linear Attention 等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;赵威霖&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="287" data-backw="578" data-height="530" data-imgfileid="503530952" data-ratio="0.4971857410881801" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcLHsQnCTV9hzxvUh6WxZyC90DyWxLdf4icl6dIEyxB70spquic8Ja6Opg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-type="png" data-w="1066" data-width="1066" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/9ebc0f60-e7d8-4f41-884e-8a57cd9cd62c/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;来自清华大学的赵威霖，研究领域是大模型高效架构，针对推理效率与长文本瓶颈进行探索，围绕高频词子空间提出了 FR-Spec，辅助投机采样实现更高效的并行生成，设计 InfLLM-V2 稀疏注意力架构，实现长短文本稀疏稠密的动态切换并获约 4 倍加速，相关成果已整合并开源至 CUDA 框架 CPM.cu。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>LLM-in-Sandbox：给大模型一台电脑，激发通用智能体能力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 13:00:42 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/1d867b8f-290d-4bb5-b8d3-ae59b4c22d38/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大模型的能力正在被不同的范式逐步解锁：In-Context Learning 展示了模型无需微调即可泛化到新任务；Chain-of-Thought 通过引导模型分步推理来提升复杂问题的求解能力；近期，智能体框架则赋予模型调用工具、多轮交互的能力。&lt;/p&gt;&lt;p&gt;沿着这条技术演进路线，下一步是什么？&lt;/p&gt;&lt;p&gt;近日，来自中国人民大学高瓴人工智能学院、微软研究院和清华大学的研究者提出了一个简洁而有效的范式：&lt;strong&gt;LLM-in-Sandbox&lt;/strong&gt;&amp;mdash;&amp;mdash;让大模型在代码沙盒（即虚拟电脑）中自由探索来完成任务。实验表明，这一范式不仅在代码任务上有效，更能显著提升模型在数学、物理、化学、生物医学、长文本理解、指令遵循等多个非代码领域的表现，且无需额外训练，同时显著减少长文本场景下的 token 消耗，并保持相当水平的推理速度。&lt;/p&gt;&lt;p&gt;研究者已将 LLM-in-Sandbox 开源为 Python 包，可与 vLLM、SGLang 等主流推理后端无缝集成。&lt;strong&gt;LLM-in-Sandbox 应当成为大模型的默认部署范式，取代纯 LLM 推理&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tLIkvia1j4VNNIwwnzm6MLAEoiaOL0e4LXNzWtsZnDvmEiaZiaGufJkhdZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.275" data-type="png" data-w="1080" data-width="415" data-height="114" data-imgfileid="503530494" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7b186e64-f7d3-4646-be0c-131662197365/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：LLM-in-Sandbox Elicits General Agentic Intelligence&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.16206&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/llm-in-sandbox/llm-in-sandbox&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://llm-in-sandbox.github.io&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;1. 核心思想：给大模型一台电脑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;电脑可能是人类创造的最通用的工具，几乎任何任务都可以通过电脑完成。这种通用性源于三大&lt;strong&gt;元能力（Meta-Capabilities)&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;外部资源访问：通过网络获取信息和知识&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;文件管理：持久化地读写和组织数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;程序执行：编写并运行任意程序&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;正如人类借助电脑完成各种任务，研究者假设：将大模型与虚拟电脑结合，或许能够解锁其通用智能的潜力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="302" data-imgfileid="503530495" data-ratio="0.7287037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tN06uJUU2icjDRuJOAib9tZv3F5gnCXhc6kzDvdUZmMYOAbjf8XiaFc1qA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="415" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bbf7607e-ed3d-4d7d-8d17-834ae0dcbe9a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. LLM-in-Sandbox：代码沙盒激发通用能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.1 轻量级通用沙盒&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与现有软件工程智能体（SWE-Agent）需要为每个任务配置特定环境不同，LLM-in-Sandbox 采用轻量级、通用化的设计：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于 Docker 的 Ubuntu 环境&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;仅预装 Python 解释器和基础科学计算库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;将领域特定工具的获取交给模型自主完成&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tLQm2iajYFwbbzg05MicibFQKibh58PAw8YDIhTjj9VdWeaAopH1WMbOMvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.20462962962962963" data-type="png" data-w="1080" data-width="415" data-height="85" data-imgfileid="503530496" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/e7999ff4-89a7-4993-837c-44a593f29e31/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种设计带来两个优势：&lt;strong&gt;泛化性&lt;/strong&gt;（同一环境支持多种任务）和&lt;strong&gt;可扩展性&lt;/strong&gt;（无需为每个任务维护独立镜像）。例如，当扩展到数千个任务时，SWE 智能体可能需要高达 6TB 的存储空间用于任务特定镜像，而 LLM-in-Sandbox 仅需约 1.1GB 的共享镜像。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.2 最小化工具集&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究者为模型配备了三个基础工具：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;execute_bash：执行任意终端命令&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;str_replace_editor：文件的创建、查看和编辑&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;submit：标记任务完成&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这三个工具共同实现了电脑的核心能力，足以支撑复杂任务的完成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.3 探索式工作流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM-in-Sandbox 采用多轮交互的工作流：模型在每一轮生成工具调用，接收执行结果作为反馈，然后决定下一步行动，直到调用 submit 或达到最大轮次限制。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tM55rK64GjiawKOLzicnCFTVy4xpAfD3N2EbtiaP3h0W6bIGlPTc71Y8mg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5046296296296297" data-type="png" data-w="1080" data-width="415" data-height="209" data-imgfileid="503530497" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7ca271ab-3173-4c07-914a-9daccafaee29/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2.4 实验结果：无需训练的显著提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究者在六个非代码领域进行了实验：数学、物理、化学、生物医学、长文本理解和指令遵循。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tNmjJTgWnZUuajGibcYmujVgUDiboNuaiaU3Nf5n1vaAp6ENEbcF3qxxcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.687037037037037" data-type="png" data-w="1080" data-width="415" data-height="285" data-imgfileid="503530498" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/40743da3-5355-446b-b973-3ff34c0d1b48/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验结果表明，强大的语言模型在 LLM-in-Sandbox 模式下获得了一致性的提升。值得注意的是，这些提升完全无需额外训练：模型能够自发地利用沙盒环境来增强任务表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.5 涌现的工具使用能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究者通过案例分析揭示了模型如何自主利用沙盒的三大能力。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;外部资源访问&lt;/strong&gt;：在化学任务中，模型被要求根据化合物名称预测分子性质。为此，模型自主安装了 Java 运行环境，并下载了 OPSIN 库来将化学名称转换为分子结构，这些工具并非预装在基础环境中。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tBDBvAryz7nK3DMvcgwxgQsaz0u9VEEqyZEaicH4PjhXGSYyiaDGJgqpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.46111111111111114" data-type="png" data-w="1080" data-width="415" data-height="191" data-imgfileid="503530514" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e352a155-9d75-423f-a5da-84ab6a93a900/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文件管理&lt;/strong&gt;：在长文本理解任务中，面对超过 100K tokens 的行业报告，模型并未尝试在 prompt 中处理整个文档，而是使用 grep、sed 等 shell 工具定位相关段落，然后编写 Python 脚本系统性地提取信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tbmqLPP0KJVP00ibqGYKyUnfB7pOC0tqWQ040vyZyrwNge5bOILZIYng/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.575" data-type="png" data-w="1080" data-width="415" data-height="238" data-imgfileid="503530500" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/81ef982b-a4df-4d5e-ab95-859a569ae039/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;计算执行&lt;/strong&gt;：在指令遵循任务中，模型被要求生成三个满足严格约束的句子：所有句子必须具有相同的字符数，同时使用完全不同的词汇。模型编写了 Python 脚本来统计字符、检测词汇重叠，并迭代优化候选句子。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tbmqLPP0KJVP00ibqGYKyUnfB7pOC0tqWQ040vyZyrwNge5bOILZIYng/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.575" data-type="png" data-w="1080" data-width="415" data-height="238" data-imgfileid="503530501" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/abd3ca33-4a11-48fc-99c4-33f227157df3/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. LLM-in-Sandbox RL：通过强化学习增强泛化能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然强大的智能体模型能够直接受益于 LLM-in-Sandbox，但较弱的模型（如 Qwen3-4B-Instruct）往往难以有效利用沙盒环境，甚至表现不如纯 LLM 模式。&lt;/p&gt;&lt;p&gt;为此，研究者提出了&lt;strong&gt; LLM-in-Sandbox RL&lt;/strong&gt;：使用&lt;strong&gt;非智能体数据&lt;/strong&gt;在沙盒环境中训练模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.1 方法设计&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tqrgs07zDoQicRq5BgFLG0WsoCJa3zPoMrbetM9Gqx6GbUHOChsvJtJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.375" data-type="png" data-w="1080" data-width="415" data-height="155" data-imgfileid="503530502" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/e675e824-ffbd-4368-b115-7e85f5761394/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;核心思想是采用基于上下文的任务（context-based tasks）：每个任务包含背景材料和需要基于这些材料完成的目标。由于完成目标依赖于提供的材料，模型必须主动探索沙盒以找到相关信息，从而自然地学会利用沙盒能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.2 泛化能力&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tQIicSicgDpUhjFU3Fh4cxkoQ9s5CHuDERYc5icOxA6xybVU7JFIl61Ftg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5435185185185185" data-type="png" data-w="1080" data-width="415" data-height="225" data-imgfileid="503530503" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/1ed930ab-c5f9-4ec0-907e-162500d7e79e/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验在 Qwen3-4B-Instruct 和 Qwen3-Coder-30B-A3B 两个模型上进行。关键发现是&lt;strong&gt; LLM-in-Sandbox RL 展现出强大的泛化能力&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨领域泛化&lt;/strong&gt;：&amp;nbsp;训练数据来自通用领域，但模型在数学、物理、化学、长文本、指令遵循等多个下游任务上都获得了一致的提升，甚至在软件工程任务上也有改善。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨推理模式泛化&lt;/strong&gt;：有趣的是，LLM-in-Sandbox RL 不仅提升了沙盒模式的表现，还同时提升了纯 LLM 模式的表现。这说明在沙盒中学到的探索和推理能力可以迁移到非沙盒场景。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨模型能力泛化&lt;/strong&gt;： 无论是较弱的通用模型（Qwen3-4B-Instruct）还是较强的代码专用模型（Qwen3-Coder-30B-A3B），LLM-in-Sandbox RL 都能带来一致的提升，表明这一方法具有良好的模型通用性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;4. 效率分析：LLM-in-Sandbox 的实际部署价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.1 Token 消耗&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tzr7SrHicwGicxwnBVpHSwvPaXjsMPStgrNjdUBdS1GamMnhENaP6ZdDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.462037037037037" data-type="png" data-w="1080" data-width="415" data-height="191" data-imgfileid="503530504" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/eb5034a7-889f-47e8-901d-79044e40db36/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在长文本场景下，LLM-in-Sandbox 将文档存储在沙盒中而非放入 prompt，&lt;strong&gt;可将 token 消耗降低最多 8 倍&lt;/strong&gt;（100K &amp;rarr; 13K tokens）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.2 推理速度&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0thnzO7xoUedyqALMPuC6mg5zqSBSdwGw6eOS2eZfMh4af91dLvrurLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3194444444444444" data-type="png" data-w="1080" data-width="415" data-height="132" data-imgfileid="503530505" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b1474711-d944-49f1-88ad-9bfe8c955a46/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;通过将计算卸载到沙盒，LLM-in-Sandbox 将工作负载从慢速的自回归生成（decode）转移到快速的并行预填充（prefill)，在平均情况下保持有竞争力的吞吐量（QPM）：&lt;strong&gt;MiniMax 可实现 2.2 倍加速。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. LLM-in-Sandbox 超越文本生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前面的实验评估的是 LLM 和 LLM-in-Sandbox 都能完成的任务。然而，LLM-in-Sandbox 还能实现纯&lt;strong&gt; LLM 根本无法完成&lt;/strong&gt;的能力。通过给 LLM 提供虚拟电脑，LLM-in-Sandbox 突破了 text-in-text-out 的范式，解锁了新的可能性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跨模态能力&lt;/strong&gt;：LLM 局限于文本输入输出，但 LLM-in-Sandbox 可以通过在沙盒中调用专业软件来处理和生成图像、视频、音频和交互式应用&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;文件级操作&lt;/strong&gt;：不再是描述文件应该包含什么，而是直接生成可用的文件 &amp;mdash;&amp;mdash;.png、.mp4、.wav、.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自主工具获取&lt;/strong&gt;：不同于预定义的工具调用，LLM-in-Sandbox 使 LLM 能够自主发现、安装和学习使用任意软件库&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibtx4RYLibJR5sfY68p6jG0tR9cLVkc5jtHickcYAib7oPNMHTKyicXzZN416QTwzmhJAhHBpsSqicJkWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.7833333333333333" data-type="png" data-w="1080" data-width="415" data-height="325" data-imgfileid="503530506" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/980b8961-452d-4ffa-a7ff-280d4e0cfd97/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这些案例揭示了一个有前景的方向：随着 LLM 能力的增强和沙盒环境的完善，&lt;strong&gt;LLM-in-Sandbox 可能演化为真正的通用数字创作系统。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6. 总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM-in-Sandbox 提出了一个简洁而有效的范式：通过给大模型提供一台虚拟电脑，让其自由探索来完成任务。实验表明，这一范式能够显著提升模型在非代码领域的表现，且无需额外训练。&lt;/p&gt;&lt;p&gt;研究者认为，&lt;strong&gt;LLM-in-Sandbox 应当成为大模型的默认部署范式，取代纯 LLM 推理&lt;/strong&gt;。当沙盒可以带来显著的性能提升，并且部署成本几乎可以忽略不计时，为什么还要用纯 LLM？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Clawdbot接入10000+数据和工具后，7×24小时监听股票，杀疯了！</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 30 Jan 2026 11:44:26 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;Clawdbot（现已更名为 Moltbot）在 AI 圈彻底火了。&lt;/p&gt;&lt;p&gt;这两天，我的朋友圈分裂成了两派人。&lt;/p&gt;&lt;p&gt;一派是还没用上 Clawdbot 的人，在疯狂转发部署教程。&lt;/p&gt;&lt;p&gt;另一派是用上 Clawdbot 的人。&lt;/p&gt;&lt;p&gt;但是，&lt;strong&gt;大部分人玩的，都是「玩具版」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Clawdbot 虽然能跑起来，但是不稳定、不聪明。因为没接专业数据源，只能做些基础对话，真正要干活时就抓瞎。&lt;/p&gt;&lt;p&gt;不过，今天我发掘了一个好东西。&lt;/p&gt;&lt;p&gt;现在，&lt;strong&gt;Teamo 平台竟然把 Clawdbot 接入了金融、商业、社媒等 10000 + 领域数据库和工具 Skills，用户可以一键认领自己的 Clawdbot 了！真正做到了 0 部署 0 配置&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfr8ud56yzYcia3bviaTsaqzqOybteicgHRNXla5J8kA5giaXQdF1MTlEqvA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.42592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530884" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b3e20c66-02cf-4d4d-9a10-3489ec9dc34a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;免费认领链接：https://teamoteam.com/t?a=clawdbot&lt;/p&gt;&lt;p&gt;如果你还不知道 Clawdbot，先来了解一下。&lt;/p&gt;&lt;p&gt;Clawdbot 是一个开源的 AI 助手，可以通过 WhatsApp、Telegram、Discord 等渠道与用户互动，国内可以接入飞书、企业微信。&lt;/p&gt;&lt;p&gt;它可以 7&amp;times;24 小时驻守在你的平台上，能监控市场、能回复消息、能提醒日常、能操作文件、能管理邮件，总之，就是你可以让它 7&amp;times;24 小时替你干活儿。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么说之前是玩具版？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你不对 Clawdbot 做特殊配制，它就只能调用大模型的通用能力，只能和它瞎聊。&lt;/p&gt;&lt;p&gt;因为 Clawdbot 只是提供了一个框架，&lt;strong&gt;没有专业数据源&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;你让它分析股票，它给你「根据公开信息」的模糊总结。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;你让它监控市场，它只能搜新闻。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;你让它做商业分析，它说「我需要更多数据」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;真正让 Clawdbot 有用的，是接入专业数据，比如同花顺、Wind 金融、同花顺，Amazon，arXiv，Pubmed，Alpha Advantage。所以市场上跑的快的团队已经发现这个问题！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Teamo + Clawdbot = YYDS&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，Teamo 平台上线了超级强化版本的 Clawdbot，狠狠的打通了 &lt;strong&gt;10000 +&lt;/strong&gt; 个专业数据库和工具 Skills，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;金融数据源（A 股、美股、港股实时行情）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;加密货币数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;社交媒体数据（Twitter、微博等）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;商业分析工具：企业工商信息，招投标，专利商标，行业报告&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;各类专业 API 接口&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf0YfCNawuq2l3tCn7KEb31PDXiaJCPS5zLU49ib5xHSTxXJuC4M41qyzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5194444444444445" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530885" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/cf1f3fc6-3171-48f1-a69b-53333a42d0d3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这些数据源，单独购买的话，一年成本轻松上万。&lt;/p&gt;&lt;p&gt;最最厉害的是，&lt;strong&gt;现在你可以直接「认领」一个配置好的 Clawdbot。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;0 部署、0 配置、开箱即用&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;你只需要在 Teamo 平台上点击「&lt;strong&gt;免费认领&lt;/strong&gt;」，就能立即获得一个属于自己的 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Clawdbot&lt;/span&gt; 实例。&lt;/p&gt;&lt;p&gt;不需要懂 Docker，不需要买服务器，不需要配任何环境变量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfhwSwCcNK37mjkBD4RQgib7dleU7UgVbhK3xwficNE7KjJPSzUoqgUR1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6046296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530886" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ec5b269b-6722-481b-8ebf-e9545fde904a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;免费认领链接：https://teamoteam.com/t?a=clawdbot&lt;/p&gt;&lt;p&gt;另外，据说 Clawdbot 实例资源有限，手慢无...&lt;/p&gt;&lt;p&gt;剩下的看你们了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真实场景上手：股票分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果自己手速慢了，没抢到，Teamo 官方还开放了一个 &amp;ldquo;公开版&amp;rdquo; 的 Clawdbot 给大家提供服务。&lt;/p&gt;&lt;p&gt;Teamo 官方把这个超级加强版的 Clawdbot 接进了飞书群里，在飞书群里 7&amp;times;24 小时待命，你随时撩拨。&lt;/p&gt;&lt;p&gt;这个 Clawdbot 会实时调用专业数据库，给你专业分析。&lt;/p&gt;&lt;p&gt;比如：「A 股的人工智能 ETF 技术面分析」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfpulMGF8B9WJEVNiaqZurIcLTVQ6ECSZ0tfJnKRveHC2kdZWkiaichezMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.3249027237354085" data-s="300,640" data-type="png" data-w="1028" type="block" data-imgfileid="503530887" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6a9bf3ab-c368-4e57-9e39-676cbe74a8f5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;再比如：「分析一下铜的走势」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfibdvdwl7apGH1icjlGyBciabfqibgljGEsvTaKhUn7bOTkuRK9ibgrNRQGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="2.275186567164179" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503530888" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/347456c9-6b9a-4551-83cf-dd065b3e723f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;再比如：&amp;ldquo;帮我分析一下宝钛股份最近的走势」&amp;rdquo;，&amp;ldquo;提醒我，如果中国平安跌破 50 元就通知我&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfhzx0Eq1tXQGGmMOibTKW8Y6ocRTd7ghrd7w1p8vNDBw2mibPNjrv0Lhg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="2.205761316872428" data-s="300,640" data-type="png" data-w="972" type="block" data-imgfileid="503530889" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4fd6092c-e68d-49b1-b05e-d60e66d77439/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;（以上仅为功能演示，不构成投资建议）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;彩蛋：支持 Skills&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Teamo 版 Clawdbot 不仅是一个专业版的 Clawdbot，还是一个增强版的 Clawdbot。 支持安装各种 Skills。&lt;/p&gt;&lt;p&gt;官方已经支持了几十个 Skills，包括编程场景、金融分析工具等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfouTTkbYbMLcSGrfI3DU8JwomWZbu6nMYMUZ9S1ELdBM8yRhvmzUpicw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530890" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3a2b7f16-406a-4690-8f7c-fbed49b79602/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;上线一个小时，光小红书社媒分析工具都已经有 10 个了...&lt;/p&gt;&lt;p&gt;真的是，用的人越多越强大啊...&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfAwpzGvMibMWvYAWyuY0NyVlRpINsZFt94y0CKoDQ2q0jCBxlWBliaNUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7861873226111636" data-s="300,640" data-type="png" data-w="1057" type="block" data-imgfileid="503530891" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/a17ab734-b2e3-4713-97f1-fad1272de626/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;比如你可以直接让它去搜索达人。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfZ92YeSiaQPejCw9qzSn8BBCBGzN81bLoCq0O2c3xAoKKUCL9IaoFDmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.2080200501253133" data-s="300,640" data-type="png" data-w="798" type="block" data-imgfileid="503530892" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/b470a915-3fc2-4afb-a694-a778dac59a0d/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然你也可以在群里直接告诉它，安装制定的 Skills。&lt;/p&gt;&lt;p&gt;&amp;ldquo;新建一个写作长文的 skills&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfiaoPkvuycib5RWiaeetpRrknnAxjNkmQnZ62b1zMg6TAE5NQVb9raIdwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.29074074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530893" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/84236e2a-280d-4948-9ef0-206c46b847c3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Teamo Clawdbot 可以立即创建技能，并且可以在 10 分钟后提醒你写小红书文案。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfjL8jSlkOyz9rVtIXAniaUtEW8ovKicEZpr7YNpYFyqDiaWTacKVpABxDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.1944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530894" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/4ef6f2fb-b9c0-4ed0-94ca-d6eac216f0a8/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;现在就可以体验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Teamo 版 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Clawdbot&lt;/span&gt; 现已开放认领通道。&lt;/p&gt;&lt;p&gt;无论你是想做金融分析、社交媒体运营、数据监控，还是单纯想体验一下「AI 主动工作」的感觉，都可以来试试。&lt;/p&gt;&lt;p&gt;认领链接：https://teamoteam.com/t?a=clawdbot&lt;/p&gt;&lt;p&gt;没领到的，也可以添加 Teamo 官方的 Clawdbot 飞书体验群，成为朋友圈里第一个用上 Clawdbot 的人。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfzr70v5jVcMBwYToFTVibT67BSCrbRgrO7zib7avWPWzyCPP4NShH0cyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.7142857142857143" data-type="png" data-w="483" data-imgfileid="503530900" data-aistatus="1" data-original-style="width: 419px;height: 299px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/3a61baa3-8ab7-4e79-9dd1-abd3e61443e9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>商汤开源SenseNova-MARS，突破多模态搜索推理天花板</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 30 Jan 2026 10:44:43 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-30</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-30</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;今日，商汤正式开源多模态自主推理模型 SenseNova-MARS（8B/32B 双版本），其在多模态搜索与推理的核心基准测试中以 69.74 分超越Gemini-3-Pro（69.06 分）、GPT-5.2（67.64 分）。&lt;/p&gt;&lt;p&gt;SenseNova-MARS是&lt;strong&gt;首个支持动态视觉推理和图文搜索深度融合的&amp;nbsp;Agentic&amp;nbsp;VLM&amp;nbsp;模型&lt;/strong&gt;，它能自己规划步骤、调用工具，轻松搞定各种复杂任务，让AI真正具备&amp;ldquo;执行能力&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在MMSearch、HR-MMSearch、FVQA、InfoSeek、SimpleVQA、LiveVQA等基准测试中，SenseNova-MARS取得开源模型中的&lt;strong&gt;&amp;nbsp;SOTA 成绩，&lt;/strong&gt;&lt;strong&gt;还&lt;/strong&gt;&lt;strong&gt;超越Gemini-3&lt;/strong&gt;&lt;strong&gt;.0&lt;/strong&gt;&lt;strong&gt;-Pro&lt;/strong&gt;&lt;strong&gt;、&lt;/strong&gt;&lt;strong&gt;GPT-5&lt;/strong&gt;&lt;strong&gt;.2&lt;/strong&gt;&lt;strong&gt;等顶级闭源模型&lt;/strong&gt;，在搜索推理和视觉理解两大核心领域全面领跑。&lt;strong&gt;更多&lt;/strong&gt;&lt;strong&gt;细节请参见技术报告&lt;/strong&gt;（https://arxiv.org/abs/2512.24330），欢迎开发者、各行业用户测试与体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全能冠军&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;strong&gt;自主&lt;/strong&gt;&lt;strong&gt;解决复杂&lt;/strong&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS在多项多模态搜索评测中展现出明显的领先优势，平均得分达到 69.74 分，成功超过了 Gemini-3-Pro 的 69.06 分与 GPT-5.2 的 67.64 分。&lt;img src="https://image.jiqizhixin.com/uploads/editor/054c9722-7258-4699-b553-6ff4def2a92c/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;在 MMSearch 榜单（图文搜索核心评测）中，模型以 74.27 分登顶，超GPT-5.2（66.08 分）；HR-MMSearch（高清细节搜索评测）中&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;以&lt;/em&gt;&lt;em&gt;54.43 分领先，显著拉开与闭源模型的差距&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/67abeb0c-435f-4bdb-9da5-2bbe2a5a2e89/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;HR-MMSearch&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;的测试&lt;/em&gt;&lt;em&gt;题目堪称&amp;ldquo;AI界的奥林匹克&amp;rdquo;&lt;/em&gt;&lt;em&gt;：采&lt;/em&gt;&lt;em&gt;用305张2025年最新的4K超高清图片，确保AI无法依赖旧知识&amp;ldquo;作弊&amp;rdquo;；所有问题都针对图片中占比不到5%的细节，比如小标志、小字、微小物体，必须用图像裁剪工具才能看清；覆盖体育、娱乐文化、科学技术、商业金融、游戏、学术研究、地理旅行等&lt;/em&gt;&lt;em&gt;八&lt;/em&gt;&lt;em&gt;大领域，&lt;/em&gt;&lt;em&gt;60%的&lt;/em&gt;&lt;em&gt;问题&lt;/em&gt;&lt;em&gt;都&lt;/em&gt;&lt;em&gt;需要至少&lt;/em&gt;&lt;em&gt;使用三&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;种工具才能解答。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;简单说，无论是需要&amp;ldquo;查遍全网&amp;rdquo;的知识密集型任务，还是需要&amp;ldquo;火眼金睛&amp;rdquo;的细粒度视觉分析，它都是当前的&amp;ldquo;全能冠军&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用&lt;/strong&gt;&lt;strong&gt;组合拳&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;strong&gt;解决&lt;/strong&gt;&lt;strong&gt;真实场景&lt;/strong&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS还能实实在在落地到我们生活和工作的场景，解决需要&amp;ldquo;多步骤推理+多工具协作&amp;rdquo;的问题。&lt;/p&gt;&lt;p&gt;普通AI的工具调用，要么只能搜文字，要么只能看图片，遇到需要&amp;ldquo;先放大细节、再识别物体、最后查背景&amp;rdquo;的复杂任务就束手无策。&lt;img src="https://image.jiqizhixin.com/uploads/editor/2ab9ffe0-8e9b-4ac1-9140-15cd4df5d910/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;面对识别赛车服微小&amp;nbsp;&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;L&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;ogo + 查询公司成立年份 + 匹配车手出生年月 + 计算差值&amp;rsquo;的复杂任务，SenseNova-MARS 可自主调用图像裁剪、文本 / 图像搜索工具，无需人工干预完成闭环解答。&lt;img src="https://image.jiqizhixin.com/uploads/editor/4cd36172-20aa-4fad-8de8-b08e96943a79/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;SenseNova-MARS能&lt;/sup&gt;&lt;/em&gt;&lt;sup&gt;&lt;em&gt;从&lt;/em&gt;&lt;em&gt;产品和&lt;/em&gt;&lt;em&gt;行业峰会&lt;/em&gt;&lt;em&gt;的&lt;/em&gt;&lt;em&gt;照片中，识别企业的标志，快速搜集&lt;/em&gt;&lt;em&gt;产品、&lt;/em&gt;&lt;em&gt;企业&lt;/em&gt;&lt;em&gt;的信息，以及&lt;/em&gt;&lt;em&gt;时间&lt;/em&gt;&lt;em&gt;、数量、参数等细节要素&lt;/em&gt;&lt;em&gt;，辅助分析行业&lt;/em&gt;&lt;em&gt;情况和&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;&lt;sup&gt;格局。&lt;img src="https://image.jiqizhixin.com/uploads/editor/edce7081-8c9a-4776-b485-e42227cb4477/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;SenseNova-MARS能从赛事照片中识别画面中的Logo、人物等信息，追溯比赛或人员背景信息，帮助快速补充重要细节。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1744d5a0-5f2b-4c7e-b64f-9b68ee23f38a/%E5%9B%BE%E7%89%876.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;SenseNova-MARS甚至能够轻松处理，这类超长步骤的多模态推理，和超过三种工具调用，自动裁剪分析细节、搜索相关研究数据，快速验证假设，得出关键判断。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;拥有这种&amp;ldquo;自主思考+多工具协作&amp;rdquo;的能力，SenseNova-MARS能够自动解决&amp;ldquo;细节识别 + 信息检索 + 逻辑推理&amp;rdquo;复杂任务，帮助实现工作效率提升。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;图像裁剪&lt;/strong&gt;：能精准聚焦图片上的微小细节，哪怕是占比不到5%的细节&amp;mdash;&amp;mdash;比如赛车手衣服上的微小Logo、赛事照片里观众席的标语，都可通过裁剪放大清晰分析。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;图像搜索&lt;/strong&gt;：能在看到物体、人物或场景，的瞬间自动匹配相关信息&amp;mdash;&amp;mdash;比如识别出赛车手的身份，或是某款冷门设备的型号。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;文本搜索&lt;/strong&gt;：能快速抓取精准信息&amp;mdash;&amp;mdash;无论是公司成立年份、人物出生年月，还是最新的行业数据，都能秒级获取。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从练中&lt;/strong&gt;&lt;strong&gt;学，&lt;/strong&gt;&lt;strong&gt;形成&amp;quot;直觉&amp;quot;和&amp;quot;经验&amp;quot;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS采用了&amp;ldquo;因材施教&amp;rdquo;的训练方法。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;第一阶段：打基础&lt;/strong&gt;。针对跨模态多跳搜索推理训练数据稀缺的痛点，创新性的提出了基于多模智能体的自动化数据合成引擎，采用细粒度视觉锚点 + 多跳深度关联检索的机制，动态挖掘并关联跨网页实体的逻辑，自动化构建高复杂度的多跳推理链路，同时引入闭环自洽性校验来去除幻觉数据，构造出具备严密逻辑链条与高知识密度的多跳搜索问答数据。用精心筛选的&amp;ldquo;高难度案例&amp;rdquo;做教材，每个案例都标注了&amp;ldquo;该用什么工具、步骤是什么&amp;rdquo;，让AI先学会基本的&amp;ldquo;破案逻辑&amp;rdquo;。这些案例都是从海量数据中挑出的&amp;ldquo;硬骨头&amp;rdquo;，确保AI一开始就接触真实复杂场景。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;第二阶段：练实战&lt;/strong&gt;。采用&amp;ldquo;强化学习&amp;rdquo;&amp;mdash;&amp;mdash;就像侦探在一次次破案中积累经验，AI每做对一次决策（比如选对工具、步骤合理）就会获得奖励，做错了就调整策略。为了避免AI&amp;ldquo;学偏&amp;rdquo;，研究团队还加了个&amp;ldquo;稳定器&amp;rdquo;&amp;mdash;&amp;mdash;BN-GSPO算法，让它在处理简单题和复杂题时都能保持稳定进步，不会出现&amp;ldquo;偏科&amp;rdquo;。这种基于双阶段归一化的优雅机制有效平滑了动态工具调用返回分布多样性带来的优化波动并确保了学习信号分布的一致性，从而成功解决了跨模态多步多工具智能体训练过程中的收敛性难题。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;经过这样的训练，AI不仅学会了用工具，更培养&amp;quot;工具使用直觉&amp;quot;&amp;mdash;&amp;mdash;知道在什么情况下应该使用哪些工具，以及如何将不同工具的结果有机结合起来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型、代码、数据全开源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;商汤日日新SenseNova-MARS模型、代码、数据集全开源，支持 Hugging Face 直接下载。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Github 仓库：&lt;/strong&gt;&lt;a href="https://github.com/OpenSenseNova/SenseNova-MARS"&gt;&lt;u&gt;https://github.com/OpenSenseNova/SenseNova-MARS&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型仓库：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;32B：&lt;a href="https://huggingface.co/sensenova/SenseNova-MARS-32B"&gt;&lt;u&gt;https://huggingface.co/sensenova/SenseNova-MARS-&lt;/u&gt;&lt;u&gt;32&lt;/u&gt;&lt;u&gt;B&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;8B&lt;a href="https://huggingface.co/sensenova/SenseNova-MARS-8B"&gt;&lt;u&gt;https://huggingface.co/sensenova/SenseNova-MARS-8B&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术报告：&lt;/strong&gt;&lt;a href="https://arxiv.org/abs/2512.24330"&gt;&lt;u&gt;https://arxiv.org/abs/2512.24330&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，创智+模思发布开源版Sora2，电影级音视频同步生成，打破闭源技术垄断</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 29 Jan 2026 18:59:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-29-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-29-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南、Panda&lt;/section&gt;&lt;p&gt;今天上午，上海创智学院 OpenMOSS 团队联合初创公司模思智能（MOSI），正式发布了端到端音视频生成模型 &amp;mdash;&amp;mdash; &lt;strong&gt;MOVA（MOSS-Video-and-Audio）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;作为&lt;strong&gt;中国首个高性能开源音视频模型&lt;/strong&gt;，MOVA 实现了真正意义上的「音画同出」。它不仅能生成长达 8 秒、最高 720p 分辨率的视听片段，更在多语言口型同步、环境音效契合度上展现了极高的工业水准。&lt;/p&gt;&lt;p&gt;更具行业意义的是，在 Sora 2 和 Veo 3 等顶尖技术普遍走向闭源的当下，MOVA 选择将模型权重、训练代码、推理代码以及微调方案进行全栈开源。&lt;/p&gt;&lt;p&gt;它生成视频的效果，给人一种身临其境的真实感：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fffa3d0e-3d0e-46ba-add1-5b40144e4393/1769683950741.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;GitHub: https://github.com/OpenMOSS/MOVA&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页: https://mosi.cn/models/mova&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;效果亮眼 &amp;nbsp;可称开源最强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去一年，视频生成模型（Video Generation）经历了爆发式增长。从 Sora 到 Wan，再到 LTX Video，AI 输出的画面越来越逼真，能生成的时间越来越长。但仔细观察 AI 生成的视频你就会发现，这些视频有的是「哑巴」，有的配音出戏。音视频生成（Video-Audio Generation）模型正是通过端到端的模态融合弥补了传统视频模型的音频维度缺陷。&lt;/p&gt;&lt;p&gt;虽然以 Veo3 为代表的音视频端到端模型展示了极高的生成上限，但是其闭源的策略造成了严重的技术垄断，割裂了技术生态的连贯性，也让社区难以通过协作改进模型缺陷（如幻觉、不同步等），导致音视频生成领域缺乏像 LLM 时代那样的「开源爆发式」演进。&lt;/p&gt;&lt;p&gt;为了推倒这堵墙，让音视频生成能力真正回归社区，&lt;strong&gt;MOVA&lt;/strong&gt; 应运而生。它具备高质量的端到端音视频生成能力，完整开源了 360p、720p 两个基础模型，以及包括微调、推理、生成工作流在内的全链路组件，补全了音视频生成基础模型的开源拼图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;电影级别物理智能：音与画的共振&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在物理仿真层面，MOVA 展现了极其出色的「物理直觉」。在这里，声音是具备空间感与质感的环境反馈，而不仅仅是可有可无的音效。&lt;/p&gt;&lt;p&gt;当一辆 SUV 在沙漠中高速掉头时，漫天飞舞的狂沙不仅在视觉上极具冲击力，音轨中同步生成的马达轰鸣声与配乐紧密交织，营造出极强的速度感：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ca13bdd9-785a-408d-abcf-c2387162ccd3/1769683979877.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：一辆 SUV 在沙漠里奔驰，并打方向盘掉头，狂沙飞舞，配上激动人心的音乐，并听到马达轰鸣声。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这种声画逻辑在复杂的巷战模拟中更为突出：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fba636de-0b6d-43f1-8b46-87e779a0ff32/1769684016838.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;360p 模型生成，提示词：在阴天漫射光下的城市巷道中，多名穿沙色迷彩的武装人员保持固定防御队形：左前跪姿射手持续向左侧射击，左中射手掩护，右侧两到三名队员贴墙半蹲警戒，尘土飞扬、电线密集、街道纵深明显，固定稳定中景偏广机位、纪录片式电影写实质感、低饱和灰黄色调与轻微颗粒，短促橙色枪口火光但曝光稳定，音频包含密集近距枪声、子弹掠过与击中声、街区混响、装备摩擦与急促呼吸，人物、站位与构图始终不变。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这种对物理动态的捕捉同样体现在日常生活场景中。比如在下面的例子中，本・斯蒂勒在公路上滑滑板，随着他左右摇摆加速，耳边会传来风掠过路面的呼啸声，可以说相当好地还原了他在《白日梦想家》中的经典场景。&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bd882351-2157-4a8d-aa11-f122b4b5c508/1769684032129.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面是一名穿着红色上衣、灰色裤子的男子在空旷的公路上滑板的场景，公路周边是草地和低山。男子通过左右摇摆的方式不断加速，展开手臂沿着公路不断滑行。背景声音为高速滑行时风吹过的呼啸声。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;电影级别的口型同步能力：精准捕捉叙事灵魂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOVA 另一大突破在于其电影级别的口型同步（Lip-sync）能力。它能够根据中英文指令，生成与语义、情感高度契合的多人物谈话场景。比如下面的公园散步视频中，对话的衔接极其自然：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/669bd1b3-183a-489a-b55f-da3a98b44d8c/1769684049711.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面中是一个男子和孩子在公园中散步的场景。男子转过头疑惑地问孩子说：&amp;ldquo;你长大想要干什么？&amp;rdquo; 男孩一脸自信地回答：&amp;ldquo;债券交易员。唐恩就是做这个的，他带我去过他的办公室&amp;rdquo;。男子笑了笑，回答道：&amp;ldquo;是一个不错的职业。&amp;rdquo;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;MOVA 也能流利地说英语，下面就还原了《王牌特工：特工学院》中「看到西装男人别去惹他，你打不过他的」的经典名场面。这里可以看到，人物的口型、表情与语调的变化严丝合缝，告别了以往 AI 视频中的「对口型感」。&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/91eaf311-1ad6-4a19-9514-45df4093cff6/1769684066040.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面中是在一处英国大街上发生的谈话，背景包含了西欧风格的建筑物、电线杆和一面英国的国旗。画面左边穿着灰色西装、戴着墨镜的男子说道：&amp;ldquo;成为绅士和口音毫无关系，真正的高贵在于超越自我。&amp;rdquo; 右边穿着黄黑色夹克、戴着白色帽子的青年脸色逐渐严肃地回答道：&amp;ldquo;我记住了。&amp;rdquo; 随后陷入了沉思。（原提示词为英文）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;涌现出来的进阶能力：视频文字生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;有意思的是，在提升 MOVA 模型口型精度和语音能力的过程中，OpenMOSS 团队还收获了一个「意外之喜」：文字生成能力&lt;/p&gt;&lt;p&gt;MOVA 能够生成视频中的文字内容。比如下面这个例子，虽在「快」这里还有些瑕疵，但整体效果已超越了很多前沿闭源模型，表现令人相当满意。&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/333e69f1-e22b-4255-8a99-46efdd474627/1769684085198.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;提示词：画面开始于创智学院宽敞而对称的中庭，日光透过透明的玻璃天窗洒落下来。镜头沿着中轴线缓缓向前移动，空间逐渐发生变化，光线化作细小的粒子向上飘散，空中浮现出若隐若现的数据流与抽象的智慧图形。天窗之外的天空逐渐转化为深邃的星空，仿佛整座建筑与宇宙连通。随着镜头推进，玻璃与植物微微发光，整个大厅呈现出安静而充满想象力的未来氛围。画面接近尾声时，所有光芒在中央汇聚，形成闪耀着星光的文字：&amp;ldquo;上海创智学院祝您 2026 年元旦快乐！&amp;rdquo; 神秘而震撼的电子配乐始终伴随画面，在文字出现时略微收束。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;作为对比，Veo 3.1 使用同样提示词的结果是这样的：&lt;a href="https://mp.weixin.qq.com/s/ZP1-Sv1ygvvXCX97ohUYDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8a4e2ec-9825-4f85-8708-1971c12c8698/1769684099268.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;在惊艳的效果背后，更加值得关注的是 MOVA 模型的一体化架构。下面我们就来系统性地看看 MOVA 背后的技术。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;背后的技术 &amp;nbsp;从模态孤岛到端到端共鸣&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;全球音视频生成 AI 模型正处于一个从「纯视频生成」向「音视频端到端生成」（Native Video-Audio Generation）跨越的关键时期，视频生成 AI 模型的优先目标已不再仅仅是更拟真的画面，而是声音与视觉的完美共鸣。&lt;/p&gt;&lt;p&gt;在音视频生成问题上，传统的解决方案是「级联流水线」：先生成无声的视频，再通过 Video-to-Audio 模型配音；或者先有语音，再驱动画面。这种「拼凑」感导致了音画割裂 &amp;mdash;&amp;mdash; 爆炸声可能比火光慢半拍，人物口型由于缺乏底层交互而显得僵硬。&lt;/p&gt;&lt;p&gt;对此，OpenMOSS 团队决定挑战最为困难，但效果更好的音视频端到端生成模式。&lt;/p&gt;&lt;p&gt;他们针对音视频生成任务专门构建了一个基础模型 MOVA（MOSS Video and Audio），其不仅能合成与视频同步的语音，也能精准地合成环境音效。从名字也能看出来，该模型属于模思智能的 MOSS 系列 &amp;mdash;&amp;mdash; 此前已有文本到对话生成模型 MOSS-TTSD、语音到语音生成模型 MOSS-Speech 以及多说话人语音识别模型 MOSS-Transcribe-Diarize。&lt;/p&gt;&lt;p&gt;MOVA 是一个规模约 320 亿参数（MoE 架构，推理时激活 180 亿参数）的模型，支持图像 - 音视频和文本 - 音视频的处理方式。&lt;/p&gt;&lt;p&gt;具体技术上，OpenMOSS 团队进行了模型架构、数据工程、训练策略等多方面的创新，验证了音视频大模型的规模化趋势与性能提升。&lt;/p&gt;&lt;p&gt;下面我们就来看看 MOVA 是如何炼成的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;异构双塔与跨模态时间对齐&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对音频和视频两个模态本身的信息密度，MOVA 巧妙地搭建了一套非对称双塔架构，结合了大尺寸的预训练&lt;strong&gt;视频塔&lt;/strong&gt;和小尺寸的预训练&lt;strong&gt;音频塔&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;具体来说，OpenMOSS 团队采用了 14B 参数的 Wan 2.2 I2V 作为视频骨干网络（用于图像 + 文本条件的 I2VA），并预训练了 1.3B 的文本到音频扩散模型作为音频骨干网络。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5WVSXI0iaRrtPpSIBSNnicBxAaWMibg8IjFsM18tP1zlEIHXsbbUenktA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530872" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ee40cd36-14f8-43e6-8f8b-5cccbb1aa889/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;MoVA 通过一个双向桥接模块将一个 A14B 视频 DiT 主干网络与一个 1.3B 音频 DiT 主干网络耦合在一起，实现模态融合与交互&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在这两座「塔」之间，团队引入了一个&lt;strong&gt;双向桥接模块（Bridge）&lt;/strong&gt;。这个模块的存在，让视频与音频的隐藏状态在每一层都能进行深度的交叉注意力运算。这意味着画面在生成的每一瞬间，图像都在感知声音的节奏，而音频也在捕捉画面的光影。&lt;/p&gt;&lt;p&gt;然而，音视频的物理属性天然互斥。视频通常以每秒 24 帧的频率离散存在，而音频信号的密度则要高出几个量级。为了防止两者在生成过程中产生时间轴上的「漂移」，团队设计了 &lt;strong&gt;Aligned ROPE（对齐旋转位置嵌入）&lt;/strong&gt;机制。通过精确的缩放比例映射，视频与音频的 Token 被巧妙地放置在了同一个物理时间尺度上，避免了音频和视频模态的天然不对齐。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多阶段细粒度数据管线&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;成功的模型根基于架构，更离不开数据。多阶段的高质量音视频数据处理管线是 MOVA 成功规模化的保障。&lt;/p&gt;&lt;p&gt;为了把海量数据真正转化为模型训练真正用得上的知识，OpenMOSS 团队构建了一套涵盖三阶段的精细化管线。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazffzOJbdFnWPRU485TqUUmkDL1Up4FVypVLiaXTxficEsQW94trVEtuIhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5472222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530869" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5771d79c-b664-4cda-9ce5-8c9abfbf7933/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;三阶段的数据处理流程：第一阶段，将原始数据预处理为固定长度的视频片段，分辨率为 720p，帧率为 24fps，时长为 8.05 秒。第二阶段，根据音频质量、视频质量以及音视频同步性对这些片段进行筛选，以获得高质量且同步的视频片段。第三阶段，分别使用音频理解模型和视觉理解模型对视频中的音频和视觉信息进行单模态标注，并最终利用大语言模型将这些单模态描述进行融合，形成细粒度音视频描述。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;相比于传统的视频数据处理管线，MOVA 提出的管线尽可能多地保留了原始音视频数据，减少了裁剪和丢弃，并且通过细粒度的标注避免不同类型和质量的数据之间互相影响，使得模型具备了复杂场景泛化的潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多阶段规模化策略&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;音视频生成的大规模训练是一项计算量非常大的任务，在大规模训练过程中，MOVA 团队展现了敏锐的工程直觉，设计了三阶段由粗到细的训练策略。首先，为了平衡随机初始化的 Bridge 模块与已经具备强大预训练先验的双塔，他们采用了异构学习率的策略。Bridge 模块的学习率被设为两倍于骨干塔，从而加快 Bridge 模块的参数更新效率，取得比较快的初步收敛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf4NgeCfWIibjSMJ5rdMmtynMlqSPSmSIxjQ870No5q58ibVC7pmaL673A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530877" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/782a4d46-d754-4ebb-9aef-65e2312e1687/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 不同训练阶段口型同步指标随着训练步数的持续下降趋势&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了提升训练效率，MOVA 将训练过程分为了三个阶段，&lt;strong&gt;360P 训练、360P 退火训练&lt;/strong&gt;以及&lt;strong&gt; 720P 训练&lt;/strong&gt;，并持续监控口型同步指标随着训练步数增长的变化。更有趣的创新在于 &lt;strong&gt;Dual Sigma Shift（双模态噪声偏移）&lt;/strong&gt;。对于音视频双模态联合去噪的模型，业界并没有明确最优的加噪方案，由于音频和视频模态天生的特性，使用同样的噪声偏移不一定能达到最优的学习效果，可能会导致隐式的模态依赖。基于这个猜测以及先前的研究工作，因此，MOVA 在第一阶段训练中对于音频和视频模态使用了不同的 Sigma Shift 进行加噪，希望避免可能出现的隐式模态依赖。&lt;/p&gt;&lt;p&gt;具体来说，一开始的 Stage 1 用的是 360p 的低分辨率，本质目标不是追求画面细节，而是让模型尽快学会「音频和嘴型应该怎么对齐」。因为 Bridge 是随机初始化的，如果一开始就追求高画质，很容易学不稳或者学偏。所以这里故意让视频端去更激进地去噪，音频端相对平滑，再配合比较高的文本 dropout，让模型不得不依赖音频和视觉之间的桥接关系来建立对齐能力。你可以从曲线看到，虽然一开始误差还有点波动，但整体 LSE-D 很快下降、LSE-C 明显上升，说明模型逐步抓住了嘴型同步的基本规律。&lt;/p&gt;&lt;p&gt;进入 Stage 2 之后，分辨率仍然是 360p，但重点从「学会对齐」转为「把对齐质量拉高、稳定下来」。这里把音频和视频的噪声调度对齐起来，本质是在时间尺度上让两种模态更加同步，这样跨模态注意力会更稳定；同时降低文本 dropout，让文本重新参与细化语义和细节，而不是完全靠音视频对齐硬学；再通过响度归一化避免 CFG 带来的音量失真。你能看到在这一段，LSE-D 继续缓慢下降，LSE-C 有一个明显跃升，说明模型不只是「能对上」，而是「对得更自信、更一致」。&lt;/p&gt;&lt;p&gt;最后的 Stage 3 才真正把分辨率拉到 720p，这一步更像是「高清重制」。此时模型已经具备稳定的跨模态对齐能力，所以可以安全地把算力用在更高分辨率和更细致的空间建模上，而不会破坏之前学到的嘴型同步结构。为了应对高分辨率带来的显存和收敛速度变化，引入了更细粒度的 checkpoint 和更激进的并行优化策略。从曲线看，这一阶段 LSE-D 进一步压低并趋于平台，LSE-C 稳定在较高水平，说明性能已经进入收敛区间，更多是在做质量的精修。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 工作流 &amp;nbsp;让模型更好理解需求&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;拥有了高性能的基模，并不意味着能直接产出完美的视听大片。在 MOVA 的实际部署中，研发团队设计了一套 Agent 工作流，以适应不同粒度和风格的用户输入，最大程度激发模型能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三阶段协同工作流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决视频生成中常见的「描述与视觉不一致」问题 &amp;mdash;&amp;mdash; 即当用户文本与初始帧存在细微偏差时，生成过程容易偏离首图先验并误解用户意图 &amp;mdash;&amp;mdash;MOVA 并未让基模单独承担对齐压力，而是设计了一套三阶段生成流程，将理解、改写与生成分工协作，显著提升首帧一致性与指令遵循能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfSn10YQPcMgqt8tgtpmkdfW80hM6UBj75QGakKjfsLNCNibmtQdP4cUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5425925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530871" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/623a8a1f-2d14-44d8-a86a-0945430c8640/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;三阶段 Agent 工作流，赋予 MOVA 产品级理解能力，更好的处理更加原始、多样的用户需求。&lt;/sup&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉解析&lt;/strong&gt;：系统首先通过 Qwen3-VL 对用户提供的初始图进行结构化解析，将画面的色彩基调、构图信息、核心主体与文字元素抽取为可执行的视觉约束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;提示词重构&lt;/strong&gt;：在视觉约束与用户原始指令共同输入下，借助通用 LLM（如 Gemini）进行上下文示例驱动的提示词重写，将需求转译为更贴近训练分布、具备动态叙事的生成提示词。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;双重条件生成&lt;/strong&gt;：最后，MOVA 结合重写后的提示词和初始帧图像进行「双重条件生成」，使视频在产生运动与变化的同时，最大化保持首帧图的视觉风格与关键元素，并更好地对齐用户意图。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这种多模型协同的思路，让 MOVA 不仅仅是一个基模，更像是一套成熟的视听内容生产系统。&lt;/p&gt;&lt;p&gt;除此之外，MOVA 也展现出扎实的纯文本音视频生成能力：即使不提供真实首帧，用户仅需输入文本，系统会自行传入一张纯色占位图作为初始条件，并生成音画同步、观感统一的高质量视频，从而降低素材门槛，让「零素材创作」成为可能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;双重 CFG：在画质与对齐间寻找平衡&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在推理逻辑的底层，OpenMOSS 团队引入了&lt;strong&gt;双重 Classifier-Free Guidance (Dual CFG)&lt;/strong&gt; 公式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfTw46yeEm5R7BE2oe6MQlhcafWicyXzzS0DlUf5d4xv7icQOLWpNF7wFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.151033386327504" data-s="300,640" data-type="png" data-w="629" type="block" data-imgfileid="503530873" data-aistatus="1" data-original-style="width: 377px;height: 57px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/87c089f8-1e79-4e13-8ae7-e7f5e4b6d11d/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在传统的视频生成中，CFG 往往只服务于「让画面更像描述」。但在音视频联合生成任务中，存在文本指令和模态桥接（Bridge）两个控制源。如果盲目追求提示词契合度，往往会牺牲音画同步率；反之亦然。&lt;/p&gt;&lt;p&gt;MOVA 允许用户根据场景调整这两者的权重：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在一般的生成任务中，侧重文本引导以保证画质和意图实现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在对话、演讲等「口型敏感」场景下，则通过强化模态桥接的引导力，实现毫秒级的对齐精度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对高强度引导可能带来的「音量爆炸」和波形畸变，MOVA 还内置了 LUFS 响度归一化算法，将输出音频强制修正至 -23 dB 的广播级标准，确保了即便在极端推理参数下，声音依然清晰自然。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验表现 &amp;nbsp;打破闭源巨头的技术垄断&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证 MOVA 的视听对齐能力，OpenMOSS 团队将其与目前开源社区最顶尖的两个项目 LTX-2 和 Ovi，以及「WAN 2.1 + MMAudio」这一传统级联方案进行了全方位对比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最佳的口型精度&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf2IvD0GVgUW3vZ7J1Ullkc0Gp29lFhDuZnFXa0L41eWyrVe3FF2aEaw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.3592592592592593" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503530874" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/04952c91-b39c-4406-84f5-2101ab7b7e26/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 Verse-Bench 上的视听生成性能的量化比较。Audio 和 AV-Align 指标是在所有子集上进行评估的；Lip Sync 和 Speech 指标是在 Verse-Bench set3 上进行评估的；ASR Acc 是在团队提出的多说话人子集上进行评估的。加粗和下划线的数值分别表示最佳和第二佳结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在最能拉开差距的口型同步（Lip-sync）任务中，MOVA 展现出了明显的优势。根据 Lip Sync Error 指标，在开启 Dual CFG 模式后，MOVA-720p 的 LSE-D 得分为 7.094，LSE-C 得分为 7.452。其次，在反应语音准确度和说话人切换准确度的 cpCER 指标上，MOVA 也取得了最佳的结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;竞技场真实评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;考虑到当前音视频生成模型的客观评价体系仍不够完善，MOVA 引入了竞技场（Arena）人为主观评测范式，包含了全球最新的开源音视频生成模型，累计获得 5000 次有效投票并对结果进行了系统统计。评测结果显示，MOVA 生成内容在整体偏好上保持领先：其在对战中更频繁获得用户选择，ELO 评分达到了 1113.8（初始分 1000），显著高于各基线模型；并稳定保持超过 50% 的胜率，其中面对 OVI 和级联系统（WAN+MMAudio）的胜率更是超过了 70%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfHAEt0fmSape3DnP7rMiaVqcfGRPYehbOkwprkiaibUiblqibCaPPGZtrcUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7981481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530875" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/aea9d7e9-7b76-4246-a195-24c29ab1a294/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfm1c2JyzYyOpmaJFOGYP1yuBFDJwSJkHzVnLNLJn21cWs7ia1YjdNbFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.38796296296296295" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530876" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/88fd8880-9ddf-49b7-b956-5f1fc452f548/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;开源突围与国产生态 &amp;nbsp;补全多模态拼图&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOVA 的出现对于音视频生成 AI 方向有着重要意义。目前全球范围内，处于第一梯队、被大众或行业认可的模型，如我们耳熟能详的 Sora 2、Veo 3、Kling 2.6、Runway Gen-3 等，绝大多数是闭源的，它们甚至仅向小部分付费用户开放；而在开源的另一边，Wan 2.1、HunyuanVideo 等模型着重于纯视频生成的质量，支持端到端音视频的较少。&lt;/p&gt;&lt;p&gt;MOVA 的出现，改变了「领先技术不开源」的现状。&lt;/p&gt;&lt;p&gt;作为中国首个高性能开源音视频模型，MOVA 通过全栈开源的方式，将训练代码、推理代码、模型权重以及微调代码全部公开。这意味着，开发者不仅可以用 MOVA 生成视频，也能深入底层，理解双塔 Diffusion 架构如何处理多模态数据的交互，甚至在此基础上训练出垂直领域的专用模型。&lt;/p&gt;&lt;p&gt;MOVA 支持了 SGLang 等主流高性能推理框架。其 360p 版本更加面向于较低的硬件门槛，让音视频生成不再是仅限于 GPU 集群的奢侈游戏。在整个音视频生成领域趋向于闭源的大环境下，MOVA 的出现是一次开源社区的突围，它补全了中国音视频生成基模的开源版图，或许能够驱使音视频生成领域走向开源共创。&lt;/p&gt;&lt;p&gt;在 MOVA 音视频大模型的研发进程中，昇腾AI提供了全栈算力支撑，助力MOVA完成了从数据标注到预训练验证的关键环节。目前，MOVA 已成为昇腾首个支持的开源多模态音视频一体生成模型，微调与推理功能已同步上线社区。&lt;/p&gt;&lt;p&gt;MOVA 的发布，距离模思智能上一款引发行业热议的语音识别模型 &amp;mdash;&amp;mdash;MOSS-Transcribe-Diarize 仅仅过去了 20 多天的时间。而 MOSS-Transcribe-Diarize，也在 MOVA 的快速迭代中发挥了关键作用。&lt;/p&gt;&lt;p&gt;如果说上一次发布的语音识别模型让 AI 学会了在嘈杂真实环境中「听懂」人类复杂对话的能力，那么今天发布的 MOVA，则宣告了他们让 AI 具备了「创造」同步音视频的能力。&lt;/p&gt;&lt;p&gt;从感知到生成，从单一模态到端到端多模态，从理解到生成，环环相扣，死磕情境智能（Contextual Intelligence）每一个关键环节的模思智能正在快速构建它的多模态基础模型版图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;研究、创新、与学生培养&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOVA 是上海创智学院与模思智能在&lt;strong&gt;研究、创新和学生培养&lt;/strong&gt;模式上的一次成功实践。上海创智学院「&lt;strong&gt;研创学&lt;/strong&gt;」模式成功融合了学术研究的深度与产业落地的敏锐度，让研究不再拘泥于简单场景，也同时深入到了工业场景，并从中培养一流 AI 人才。&lt;/p&gt;&lt;p&gt;在上海创智学院，学生被视为共同创新创业的合伙人，他们在 MOVA 这种千卡级规模的工业级基模训练中承担核心任务。这种阵地式培养让学生在解决大规模训练 Infra 框架、高性能海量数据分布式处理框架、模型架构从 0 到 1 设计等硬核工程问题的过程中，积累了极具稀缺性的实战经验。&lt;/p&gt;&lt;p&gt;模思智能作为创新的出口，一方面为人才培养提供了验证大规模基模性能的闭环环境，并通过持续的技术迭代，将前沿理论转化为可商用的生产力工具。在这一机制下，技术研发与商业价值形成了互为因果、相互加速的良性循环。&lt;/p&gt;&lt;p&gt;这一模式更深远的意义在于对 AI 顶尖人才培养路径的重塑，让年轻大脑在技术演进最前线接受真火淬炼，为未来的 AGI 竞争储备具备破局能力的澎湃力量。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
