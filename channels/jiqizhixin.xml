<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>OpenAI前CTO首个创业产品Tinker，这里全量升级开放了，还有羊毛可薅</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 07 Jan 2026 13:40:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4fda1c36-38b5-4f99-a2a1-80f770da010c/1767764057228.png" style="width: 700%;" class="fr-fic fr-dib"&gt;当 OpenAI 前 CTO Mira Murati 创立的 Thinking Machines Lab (TML) 用 Tinker 创新性的将大模型训练抽象成 forward backward，optimizer step 等⼀系列基本原语，分离了算法设计等部分与分布式训练基础设施关联，把 &amp;ldquo;训练&amp;rdquo; 大模型变成了简单的 &amp;ldquo;函数调用&amp;rdquo; 时，行业进入一场从 &amp;ldquo;作坊式炼丹&amp;rdquo; 到 &amp;ldquo;工业化微调&amp;rdquo; 的升级。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;潞晨云微调 SDK 正式开放上线&lt;/strong&gt;：基于 Thinking Machine Lab 开源的 Tinker SDK 构建，作为&lt;strong&gt;国内首个兼容 Tinker 范式且全面开放的 Serverless 微调平台&lt;/strong&gt;，为复杂昂贵的强化学习提供更具成本优势的工业级解法 &amp;mdash;&amp;mdash; 开发者无需囤卡，rollout&amp;rarr;reward&amp;rarr;update 全链路按 Token 计价，让每一分钱都花在产生梯度的 &amp;ldquo;刀刃&amp;rdquo; 上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;拥抱后训练与 RL &amp;nbsp; 算法层与底层算力架构的解耦&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着 OpenAI o1 在推理能力上的突破，业界逐渐形成共识：大模型的能力突破已不再单纯依赖预训练（Pre-training）阶段的参数堆砌，&lt;strong&gt;后训练（Post-Training） 特别是强化学习正成为决定模型实用价值的核心战场&lt;/strong&gt;。以 DeepSeek‑R1 为例，仅靠强化学习训练，模型在 AIME 数学推理基准上的 pass@1 从 15.6% 提升至 77.9%，充分展示了 RL 在低数据量条件下即可实现大幅能力跃升，迅速成为后训练赛道的新范式。&lt;/p&gt;&lt;p&gt;然而，摆在算法工程师面前的问题依旧严峻。强化学习涉及到更为复杂的系统设计，训练过程中存在一系列的问题，如多个模型的优化，数据的传递，以及模型权重的传递；一系列工程化的工作，给算法的设计带来了更多的困难，同时也对基础设施提出了更高的要求。&lt;/p&gt;&lt;p&gt;Tinker 的出现，就是为了解决这个问题：&lt;strong&gt;把繁杂训练变成标准易用的 API。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;潞晨云把这一范式写进底层假设，&lt;strong&gt;算法设计与基础设施解耦&lt;/strong&gt; &amp;mdash;&amp;mdash; 开发者只负责定义数据与 Loss 函数，底层的异构集群调度、并行策略优化、容错运维等应被封装为基础设施服务，对开发者实现&lt;strong&gt;全托管与无感支持&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;致敬创新，更致力于落地。潞晨云微调 SDK 兼容 Tinker 接口&lt;/strong&gt;， 消除了从 &amp;ldquo;算法灵感&amp;rdquo; 到 &amp;ldquo;模型落地&amp;rdquo; 之间的工程化壁垒，在&lt;strong&gt;零代码微调与裸机全手写&lt;/strong&gt;之间落在最佳平衡点，将研究精力和算力成本从集群运维还原至算法本身，带给开发者 &amp;ldquo;本地写码，云端计算的 &amp;ldquo;&lt;strong&gt;训练即服务（Training as a Service）&lt;/strong&gt;&amp;rdquo; 流畅体验 。&lt;a href="https://mp.weixin.qq.com/s/wQMKxRcDTwHSkrYzQBNMDw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7479cd6e-a38a-4f37-b3ce-56faa134d848/1767764138792.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;潞晨云微调 SDK 今日起全量开放，前 150 名用户通过专属链接注册，可获得 30 元 Token 使用额度：&lt;/p&gt;&lt;p&gt;https://cloud.luchentech.com/account/signup?invitation_code=JQZX&lt;/p&gt;&lt;p&gt;&lt;strong&gt;颠覆性人力效能比 &amp;nbsp;1 名算法工程师顶替原庞大 Infra 团队&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;潞晨云微调 SDK 的核心思路可以概括为：算法工程师定义算法逻辑，潞晨云搞定 Infra 。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在传统的开发中，用户往往要花大量精力去租赁合适的算力集群、管理环境配置、调训练框架和集群运维。但潞晨云将大模型训练拆解成了一组标准的函数原语，打通了&lt;strong&gt;从 SFT 到 RL 的全链路&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Forward &amp;amp; Backward&lt;/strong&gt;： 处理前向传播与梯度计算&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Optimizer Step&lt;/strong&gt;： 执行权重更新策略&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sample (Rollout)&lt;/strong&gt;： 做推理生成和评估，使用户不仅可以完成 SFT，更能轻松构建 PPO、GRPO、DPO 等复杂的强化学习（RLHF/RLAIF）训练流&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Save State&lt;/strong&gt;： 管理模型检查点与状态保存&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNFV27sD3QnQdWECez0jp9LpdERN8j0IaSxiblLTjKHpCGhiaZhzic7ic5gw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4675925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527059" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ef67d4d1-4bf5-43fa-b596-08324f0f45f1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着，用户可以在本地熟悉的 Jupyter Notebook 或 IDE 里，用最标准的 Python 语法像搭积木一样自由组合，掌控训练逻辑的细节。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这种模式带来了颠覆性的&amp;lsquo;人力效能比&amp;rsquo;提升：它将原本需要运维工程师、Infra 工程师、平台工程师和算法工程师紧密配合的庞大团队，简化为了&amp;lsquo;一个算法工程师&amp;rsquo;的独立闭环。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;用户不再被底层繁杂的基建拖累，不再背负多职能的枷锁，也不再是黑盒填参的被动执行者，而是能够独立驾驭大规模训练流的主动设计师。无论是监督微调（SFT）还是更复杂的强化学习（RL）Pipeline，都能通过组合这些原子函数来灵活构建。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNmodlDmQdU6Iua0wP50K2kgg2NiabUdYHQBBDSsK8uxIUGXmXiboXycBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4111111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527060" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/fdee3e8c-05f3-43ef-93e0-fed73106d479/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为什么这种体验如此丝滑？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了实现极致的流畅度，潞晨云基于现有的 GPU 云服务架构实现了一套完整的后端系统。在具体实现中，潞晨云采&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;用&lt;/span&gt;控制面与计算面分离设计，通过统⼀ API Server 管理跨地域的多个 GPU 计算集群，实现多云部署能力。核心采用基于 Future 模式的异步 API，所有训练操作⽀持非阻塞调用，用户无需等待 GPU 计算完成即可继续执行后续逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNP6iaEt1uXBgLnicZI0EEYwmibZCmYYQ6QxK9APibGqs3uZgrUJHcPTvNqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527061" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3e398271-7426-406b-bca5-f0d693dc3348/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;潞晨云微调 SDK 还具备智能队列系统，即使在资源洪峰期，任务也会自动进入持久化队列（Persistence Queue），一旦底层资源可用，毫秒级启动，队列等待期间 0 计费，仅对实际 prefill + sample + train 的 Token 量收费，无资源闲置，将用户每一分钱都用在产生梯度的刀刃上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型微调的算力零售革命 &amp;nbsp;从 &amp;ldquo;包机租赁&amp;rdquo; 到 &amp;ldquo;按 Token 计费&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 &amp;ldquo;易用性&amp;rdquo; 是后训练平台的入场券，那么 &amp;ldquo;成本结构&amp;rdquo; 则是决定谁能走得更远的护城河。&lt;/p&gt;&lt;p&gt;在传统云主机的 &amp;ldquo;包机 / 时租&amp;rdquo; 模式中，用户一直在为 &amp;ldquo;过程&amp;rdquo; 买单 &amp;mdash;&amp;mdash; 无论是在加载数据、调试代码，还是仅仅在思考 Loss 函数，只要占用了显卡，计费表就在跳动。这种模式下，&lt;strong&gt;开发过程中有一半以上的预算都浪费在了这些没有实际产出的 &amp;ldquo;垃圾时间&amp;rdquo; 里。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;潞晨云为微调大模型场景引入了 Serverless 架构，推行 &amp;ldquo;按 Token 计费&amp;rdquo; 的商业模式，将微调场景的算力服务切分到了最细的颗粒度：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;为价值付费&lt;/strong&gt;： 就像使用推理 API 一样，用户只需为 Prefill (输入)、Sample (推理输出) 和 Train (训练) &amp;nbsp;产生的&lt;strong&gt;有效计算 Tokens 量&lt;/strong&gt;付费。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;其他环节全免费&lt;/strong&gt;： 本地代码调试、环境配置、数据预处理、模型 Checkpoint 保存&amp;hellip;&amp;hellip; 这些在传统租卡模式下分秒必争的环节，在潞晨云&lt;strong&gt;全部免费&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致性价比&lt;/strong&gt;：通常，RL 需要同时维护高吞吐的推理集群（vLLM）和训练集群，算力成本极高。但在潞晨云上，实测基于官方 Cookbook 的 math_rl recipe 跑通包含 Rollout 采样、Reward 评分和 PPO 更新的&lt;strong&gt;完整 RL 流程&lt;/strong&gt;（~300 steps），总算力成本仅&lt;strong&gt; 8.61 元&lt;/strong&gt;。这意味着，个体开发者也能低成本复现 RLHF/RLAIF 探索。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNKTeKFAkVHslO7OFDvIPC4icz5VMgib73as3lDIQysh0HiayR7BFrjMNAQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.4111111111111111" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527062" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a99ea3f7-aad7-4686-b4ac-566409912998/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;技术落地的三个场景 &amp;nbsp;SFT 与 RL 同时 &amp;ldquo;开箱即用&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这种新模式，也将彻底改变不同领域开发者的工作流：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;科研场景：告别资源焦虑 &amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;学术界，时间与算力往往是最紧缺的资源。研究人员不仅要面对繁琐的集群运维（Slurm/Docker 配置），还要应对昂贵的实验复现成本。潞晨云微调 SDK 支持 &amp;ldquo;白盒级&amp;rdquo; 的科研探索，全面兼容 Tinker API。研究人员可以自定义 Evaluation 逻辑、通过 Forward/Backward，Sample 等原语精确控制后训练和强化学习 Pipeline，而无需关心底层的分布式实现，让实验复现成本大幅降低。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;创业与独立开发：极速验证 MVP &lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于初创团队，&amp;ldquo;快&amp;rdquo; 是生存根本。利用潞晨云微调 SDK 的 Serverless 特性，开发者无需等待资源排期。配合极低的 Token 成本，实测从 pip install 到跑通一个包含 1000 条样本的 SFT 或 RL 微调实验，仅需数分钟。这种极致的边际成本，让创业者敢于在有限预算下快速迭代 Reward 模型，实现真正的 &amp;ldquo;低成本试错&amp;rdquo;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工业级落地：复杂架构突围 &amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在金融、医疗等垂直领域的工业应用中，已有微调 API 往往难以应对复杂的异构架构与 RLHF/RLAIF 需求。潞晨云微调 SDK 允许工程师通过 train_step 自由定义 Loss 逻辑与强化学习奖励函数。开发者拥有对模型权重与训练细节的完整控制权，实现端到端定制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;极简实战：三步上手&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;没有复杂的集群配置，没有冗长的 Docker 构建。使用潞晨云微调 SDK，训练一个大模型就像写普通 Python 脚本一样简单：&lt;/p&gt;&lt;p&gt;1.Install &amp;amp; Import:&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="nginx"&gt;&lt;code&gt;Bash&lt;/code&gt;
&lt;code&gt;pip install hpcai&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;2.Initialize Client: 目前已支持 Qwen3 系列 (4B-32B) ，更多模型即将上线&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="makefile"&gt;&lt;code&gt;Python&lt;/code&gt;
&lt;code&gt;import hpcai&lt;/code&gt;
&lt;code&gt;# 初始化 LoRA 训练客户端，无需配置复杂的分布式参数&lt;/code&gt;
&lt;code&gt;training_client = service_client.create_lora_training_client (&lt;/code&gt;
&lt;code&gt;    base_model=&amp;quot;Qwen/Qwen3-4B&amp;quot;,&lt;/code&gt;
&lt;code&gt;    rank=32&lt;/code&gt;
&lt;code&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;3.Define Training Loop &amp;amp; Run: 像在本地写 PyTorch 一样，拥有对训练循环的完整控制权：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="cs"&gt;&lt;code&gt;Python&lt;/code&gt;
&lt;code&gt;# 训练循环：完全可控&lt;/code&gt;
&lt;code&gt;for step in range (target_steps):&lt;/code&gt;
&lt;code&gt;    # 前向与反向传播&lt;/code&gt;
&lt;code&gt;    fwd_bwd = training_client.forward_backward (batch, &amp;quot;cross_entropy&amp;quot;)&lt;/code&gt;
&lt;code&gt;    # 优化器步进&lt;/code&gt;
&lt;code&gt;    optim = training_client.optim_step (adam_params)&lt;/code&gt;
&lt;code&gt;    # 实时获取 Loss 进行监控&lt;/code&gt;
&lt;code&gt;    loss = fwd_bwd.result ().metrics.get (&amp;quot;loss:mean&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;目前，微调 SDK 已覆盖 Qwen3 系列模型（4B、8B、14B、32B），支持监督学习和强化学习训练方式，并将持续扩展更多模型能力与细分落地场景，大家也可以向官⽅提交需求 push 更新。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;平台还准备了开箱即用的 HPC-AI Cookbook&lt;/strong&gt;，提供包括 &lt;strong&gt;DeepSeek-R1 &amp;nbsp;GRPO 算法、基于 Verifier 的数学推理、自定义 Reward 函数&lt;/strong&gt;等复杂 RL 场景的完整代码实现。开发者无需从零构建复杂的 PPO/GRPO 流水线，只需复制 Cookbook 中的 &amp;ldquo;配方&amp;rdquo;，&lt;strong&gt;运行轻量级本地 train.py 脚本，即可驱动云端复杂的分布式 RL 训练流&lt;/strong&gt;，在潞晨云上复现具备复杂逻辑推理能力的 SOTA 模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;现在体验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;后训练正从学术支线升级为工程主线，AI 基础设施的终极形态应该是 &amp;ldquo;零认知负荷&amp;rdquo;&amp;mdash;&amp;mdash; 开发者只需描述数据与算法，其余（租卡、配环境、并行策略、运维调度、故障自愈，乃至 RL 涉及的一系列工程化的工作）全部下沉到用户无感。当 GPU 闲置成本趋近于 0，环境配置时间趋近于 0，长序列 RLHF 也能按 Token 即时计费，应用创新效率直接逼近算力上限。&lt;/p&gt;&lt;p&gt;潞晨云微调 SDK 今日起全量开放：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;无需白名单，无需预约&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;前 150 名注册即得 30 元体验金（填写专属福利码 JQZX）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;把资源弹性交给平台，把算法自由度留给自己，每一分钱都用在产生梯度的刀刃上！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;立即体验：https://cloud.luchentech.com/fine-tuning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用文档：https://cloud.luchentech.com/doc/docs/finetune-sdk/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;sup&gt;Reference&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[1] Tinker SDK: https://github.com/thinking-machines-lab/tinker&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[2] DeepSeek-R1: https://arxiv.org/pdf/2501.12948&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型最难的AI Infra，用Vibe Coding搞定</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 07 Jan 2026 13:32:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d7b33447-8e48-40fe-b0d9-cd592d86c4de/1767763555070.png" style="width: 700%;" class="fr-fic fr-dib"&gt;Andrej Karpathy 大神力荐的 Vibe Coding，正在成为开发者的新宠。这种「只需聊一聊，AI 可以把功能写出来」的体验，极大提升了简单任务的开放效率。&lt;/p&gt;&lt;p&gt;然而，当我们目光转向实际的系统，特别是 AI Infra 这种复杂系统时，Vibe Coding 就会常常会陷入「水土不服」的困境。&lt;/p&gt;&lt;p&gt;总结下来，主要有这三个方面的问题。&lt;/p&gt;&lt;p&gt;首先是&lt;strong&gt;上下文丢失&lt;/strong&gt;问题：对话历史被压缩，关键设计决策在多轮交互中逐渐遗忘，导致后续生成的代码与前期讨论脱节。其次是&lt;strong&gt;决策偏离&lt;/strong&gt;困境：AI 在面对复杂系统时需要做出大量技术决策（如架构选择、接口设计、错误处理策略等），自主决策容易偏离开发者意图，生成的代码难以符合预期。最后是&lt;strong&gt;质量不稳定&lt;/strong&gt;挑战：即使提供了完整的需求描述，生成代码的质量仍然波动很大，同样的需求在不同时间可能得到截然不同的实现方案。&lt;/p&gt;&lt;p&gt;而这些问题背后的根源在于：AI Infra 到底还是个复杂系统，动辄数万行代码、成百上千个相互关联的决策点，而当前的对话式编程缺乏持久化、结构化的决策管理机制。&lt;/p&gt;&lt;p&gt;换句话说，Vibe 本身是模糊且不稳定的，无法支撑严肃复杂的 Infra。&lt;/p&gt;&lt;p&gt;不过 Vibe Coding 的发展不可逆，其广泛应用的潜力不应就此止步。要让 Vibe Coding 真正适用于 AI Infra 开发，我们实践了&lt;strong&gt;文本驱动的 Vibe Coding&lt;/strong&gt; 方法：通过设计文档将所有关键决策体系化、持久化。&lt;/p&gt;&lt;p&gt;将复杂系统的关键决策前置到设计阶段，通过结构化文档让开发变得有章可循，大幅降低复杂度门槛。&lt;/p&gt;&lt;p&gt;程序员只需要专注于高层设计决策，AI 负责代码实现细节，真正实现「几乎不写一行代码，就可以完成复杂功能」。&lt;/p&gt;&lt;p&gt;整个过程通过详细的设计规范和代码逻辑来约束 AI 生成，确保实现复合预期，同时提升系统健壮性。&lt;/p&gt;&lt;p&gt;而要验证这一新范式的有效性，我们需要一个兼具高复杂度、强工程约束和真实业务价值的典型场景。&lt;/p&gt;&lt;p&gt;AI Infra 中的资源调度系统，尤其是面向 Agentic RL，正是这样一个理想试验场。该系统是数万行代码的分布式训练系统，面临 GPU 利用率优化的复杂挑战，涉及核心调度逻辑改动。&lt;/p&gt;&lt;p&gt;新开发范式是如何在这一场景实操的？阿里巴巴未来生活实验室与智能引擎团队带你进一步来看。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一部分：Agentic RL 中的 GPU 利用率挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Agentic RL 的采样过程中，系统需要支持越来越高的交互轮数，让智能体有足够的环境交互来处理复杂任务。然而，这一趋势带来了显著的资源调度挑战。&lt;/p&gt;&lt;p&gt;在实际采样中，智能体执行任务的时间分布呈现典型的长尾特征：绝大多数样本能够在较少轮数内快速完成采样并得出结果，而只有少数复杂样本需要执行到最大轮数限制才能终止。这种极不均匀的执行分布成为 GPU 资源利用的核心瓶颈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问题的本质&lt;/strong&gt;在于分布式计算中经典的 &amp;quot;落后者效应&amp;quot;（Straggler Effect）：无论有多少样本已经完成，系统都必须等待最慢的那个样本执行完毕，才能进入下一阶段。等待过程成为整个训练流程的性能瓶颈，更造成 GPU 资源浪费。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.2 方案对比与技术优势&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;业界针对 Agentic RL 训练存在两种主流解决方案，但都存在根本性缺陷：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;共置方案采&lt;/strong&gt;用严格的串行执行策略：所有 GPU 首先统一投入 rollout 阶段，等待全部样本采样完成后再切换至 training 模式。这种方案存在双重效率问题。首先是阶段内的资源闲置：在 rollout 阶段，由于落后者效应的存在，大量 GPU 在短样本完成后进入闲置等待状态，无法有效利用。其次是阶段间的严格串行限制：rollout 和 training 完全无法并行执行，training 阶段必须等待 rollout 完全结束才能开始，导致整体迭代时间被显著拉长。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;异步分离方案&lt;/strong&gt;通过静态分配专用的 rollout GPU 和 training GPU 实现流水线并行。虽然理论上能够缩短单轮迭代时间，但引入了严重的 &amp;quot;双边空泡&amp;quot; 问题。在 rollout 侧，短样本快速完成后，rollout GPU 进入闲置状态等待长尾样本执行完毕；在 training 侧，训练任务完成后需要等待新一轮 rollout 数据，training GPU 同样处于闲置状态。使得理论上的并行优势在实际运行中大打折扣。&lt;/p&gt;&lt;p&gt;我们提出的&lt;strong&gt;时分复用方案&lt;/strong&gt;通过 GPU 池动态分配机制解决上述问题。其核心创新基于一个关键洞察：&lt;strong&gt;异步训练过程中，rollout 对 GPU 资源的需求呈现动态波动特征&lt;/strong&gt;。在 training 触发前，大量样本已进入完成阶段，系统处于样本数目的低谷期，此时对 GPU 资源的需求自然下降。相反，在训练结束后，新一轮大量样本涌入系统，对 GPU 资源的需求急剧激增，形成明显的高峰期。基于这一波动规律，我们设计了智能资源调度机制，在采样需求低谷期分配部分 GPU 资源用于执行训练任务，从而实现需求波动与资源调度的有效匹配。&lt;/p&gt;&lt;p&gt;系统采用&lt;strong&gt;两阶段执行流程&lt;/strong&gt;来实现这一设计理念。在全力采样阶段，所有 GPU 协同处理大多数样本，快速推进系统至需求低谷状态。当采样完成度达到训练要求时，系统执行缩容操作，释放固定的 rollout GPU 资源转入训练模式。随后进入并行执行阶段，被释放的 GPU 专门执行训练任务（充分利用低谷期的闲置资源），而长尾样本被迁移至剩余 GPU 继续处理。训练任务完成后，系统立即执行扩容操作，回收所有 GPU 资源恢复全力采样状态，为应对下轮需求高峰做好准备。&lt;/p&gt;&lt;p&gt;这种基于工作负载特征的智能时分复用策略，不是简单的资源分割，而是将训练的快速执行特性与 rollout 需求波动在时间维度巧妙匹配提升了整体的 GPU 资源利用效率。&lt;/p&gt;&lt;p&gt;以 4GPU 系统为例，我们比较各个方案的任务执行时间线。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN7XoW59LiaplGYQF8VhD0755hBSs89n5FxpV45UtmIcHjIEG4xZgLG9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.0694444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526956" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/af69fdc5-fa2a-4fc6-b15d-00a819a02d03/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;时分复用方案的核心挑战在于&lt;strong&gt;系统复杂度的显著提升&lt;/strong&gt;。为了追求高性能，需要精细复杂的控制机制，在分布式高并发的系统中实现尤其困难。相比串行执行和静态资源分配，动态调度引入了诸多技术难点：分布式环境下的精确同步控制，以及扩缩容操作的原子性保证，并发场景下样本状态的无缝迁移。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNL5FBmS2jjhIXrvG4T9gEOVZ903CEqibGckKrdd7t24T4dEeNVMYvszw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.17777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526981" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0e0da803-757f-40ea-b58e-7a0d619e868a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 各个方案的优缺点&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在一个包含数万行代码的分布式 RL 系统中，手工编码不仅周期长，更易引入隐蔽的状态不一致 bug。传统的开发方式已难以应对这种「高价值、高复杂度」的功能迭代需求。&lt;/p&gt;&lt;p&gt;正是在这一背景下，我们创新性地采用了文档驱动的 Vibe Coding 方法论，通过系统化的设计文档驱动开发流程，显著提升了复杂系统的实现效率和代码质量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二部分：文档驱动的 Vibe Coding 方法论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前文提到的氛围编程三大痛点，上下文丢失、决策偏离、质量不稳定，其根源都指向同一个问题：&lt;strong&gt;缺乏持久化、结构化的决策管理机制&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;要理解设计文档如何解决这一问题，我们需要先认识到代码实现的本质：它是由成百上千个相互关联的决策点构成的。从顶层的架构选择、接口设计，到底层的变量命名、错误处理，每个决策都影响着最终的代码质量。在理想情况下，如果 AI 已经掌握了完整的代码改动（如代码迁移任务），它可以直接复制执行这些修改。但现实中，我们要解决的往往是全新的问题，比如本文的 &amp;quot;训练 - 推理时分复用优化&amp;quot; 功能此前从未实现过。&lt;/p&gt;&lt;p&gt;既然没有现成的代码可以参考，那么退而求其次，如果我们能够&lt;strong&gt;系统化地枚举出所有决策点&lt;/strong&gt;，AI 就可以按照这些明确的决策逐步生成代码。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计文档正是实现这一目标的关键工具&lt;/strong&gt;：它通过结构化的方式，将高层的设计思路逐步细化为具体的代码改动，完整记录每一个决策点。&lt;/p&gt;&lt;p&gt;经过程序员审阅的设计文档，意味着人与 AI 在关键决策上达成一致。这直接解决了氛围编程的三大痛点：&lt;strong&gt;持久化文档&lt;/strong&gt;消除上下文丢失，&lt;strong&gt;明确决策&lt;/strong&gt;避免 AI 偏离意图，&lt;strong&gt;规范和代码逻辑&lt;/strong&gt;确保代码质量稳定。这带来工作方式的根本转变：程序员从编码、调试、测试等执行层面，转向与 AI 讨论设计，通过文档明确决策点直到完全对齐，然后 AI 负责实现。设计文档同时记录实施进度，确保可追溯性。更重要的是，设计文档本身由 AI 管理，大大降低了编写门槛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNAL5bsRPufjy1y5fqOoW5NDqVQLPt3w0icZQib2mf7PhAw2JKKv2L9a6w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5712962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526959" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f66aeeec-22b6-472c-a8f0-1767426d462f/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 设计文档驱动的氛围编程和传统的 vibe coding 的工作流对比&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNRhXQBxs1icJInWJLr9YCiaNnUH7JicBNxFFYaUfRyWySicBJ3iaNB4XvZhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526984" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/99ebff51-452c-4400-a650-1bf843bd09d5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;这三种开发方式的优缺点&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.1 核心方法论：设计文档驱动开发&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在明确了设计文档的必要性后，我们需要建立一套系统化的方法论来指导实际操作。设计文档驱动开发不仅仅是编写文档，更是一种全新的开发范式：通过结构化的文档组织决策过程，通过迭代审阅确保决策质量，通过分步实施降低实现风险。&lt;/p&gt;&lt;p&gt;这一方法论的核心在于将复杂的系统开发问题分解为三个可管理的环节：&lt;strong&gt;内容组织&lt;/strong&gt;（如何构建决策体系）、&lt;strong&gt;审阅修改&lt;/strong&gt;（如何确保决策质量）、&lt;strong&gt;分步实施&lt;/strong&gt;（如何将决策转化为代码）。每个环节都有明确的操作流程和质量标准，确保整个开发过程的可控性和可预测性。&lt;/p&gt;&lt;p&gt;2.1.1 流程概览&lt;/p&gt;&lt;p&gt;设计文档的审阅是一个迭代优化的过程，需要人和 AI 协作来确保文档质量。我们建立了系统化的审阅流程，通过多轮迭代逐步完善设计文档，直到达到实施标准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总体审阅流程&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNJDerbLc4XYmhmt4wnZpTsia83pjB9AWNyUe0cK0icgFPAdcqbErs5SJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.2731481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526964" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/cfc8e3ac-de7c-452c-b0ab-debbf9c0259e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2.1.2 如何组织内容：开发者与 AI 共同完成&lt;/p&gt;&lt;p&gt;代码实现的结果是由一系列自顶向下的决策决定的，顶层的关键决策包括新功能如何融入已有架构，底层的决策如是否需要增加成员变量。组织设计文档的核心目的是系统性的跟进这些决策点，并逐步完善解决。由于底层的决策，往往依赖于顶层或者上层的决策，设计文档需要层次化的拆解决策，形成决策体系。开发者需要按照章节的先后顺序和目录层次结构审阅文档中的自顶向下的决策过程，当我们指出前面顶层设计的错误时，AI 会自动修改后面章节的中层和下层决策以保持内部逻辑的一致性。因此，我们可以按章节层次和顺序和 AI 逐个对齐自顶向下的决策。同时，在开发者和 AI 共同修正这些决策的过程中文档不断演进，文档需要自包含这个迭代的过程，记录迭代的版本。最后，文档也需要记录代码实施的进度和一些衍生的待办。&lt;/p&gt;&lt;p&gt;具体而言我们的设计文档模板包含如下内容：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNOOOB9oh9K1JgU1heOU9NkiaYVNqOX8Mz8hlROO69BXr36J9uPbvW5pQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7972222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526987" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5446b4c4-04dc-45a8-aad3-d9dc17fe3062/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2.1.3 如何审阅修改：复用 iFlow CLI 的 prompt 模板&lt;/p&gt;&lt;p&gt;上文描述的逐章节审阅对齐的过程理论上已经完备，但实践中会遇到一系列挑战。为应对这些挑战，我们建立了多层次的文档质量保证机制。&lt;/p&gt;&lt;p&gt;由于这些场景在文档审阅中反复出现，我们利用 iFlow CLI 的 Sub Command 功能，将不同场景的指令逻辑固化成了自定义的 prompt 模板。&lt;/p&gt;&lt;p&gt;审阅挑战与解决方案对照表&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNBV1ydXVTVGK4FFL2eiaaUuJZlibmHia4eyXJCQAGCt9SH1ciaLaGDKgMZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.1268518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526988" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/77e0716d-ddbf-4be4-9dd5-e4b877d0dac1/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2.2 设计文档的实施&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2.2.1 如何分步计划和实施&lt;/p&gt;&lt;p&gt;当 Section 5 完成所有 API 和 Implementation 的设计后，我们需要将这些设计转化为可执行的代码。这个转化过程分为两个阶段：首先规划 Section 6 制定实施步骤，然后进入 AI 辅助的增量开发循环。&lt;/p&gt;&lt;p&gt;规划实施步骤： 规划的核心目标是将 Section 5 中的方法拆解为依赖有序的小步骤。我们首先分析每个方法的 deps: 字段，识别底层 helper 方法和高层 orchestration 方法之间的依赖关系，绘制出完整的依赖图。在拆解步骤时，我们遵循 &amp;quot;每步越小越好&amp;quot; 的原则，通常一个 Step 包含 3-5 个相互关联的方法，避免单个 Step 包含超过 10 个方法。步骤的排序遵循依赖关系：Step 1 通常是基础设施（配置、常量、基础类），Step 2 到 Step N 按照从底层到高层的顺序排列，最后一个 Step 负责集成和端到端测试。每个 Step 都定义清晰的验证点和测试用例覆盖，确保可以独立验证和方便回退。&lt;/p&gt;&lt;p&gt;规划完成后，我们得到一个清晰的依赖图，指导后续的增量开发：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNBmbCMERjftsbTcqMwfiauaSI9lmonibXDJ2HsoZdDvwUjpprD0zwXCjQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.40925925925925927" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526993" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8255f44f-7db0-4949-8f81-e4e28f72e830/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;增量开发循环： Section 6 规划完成后，我们进入实施阶段。对于每个 Step，AI首先读取 Section 6 中的 purpose 和 dependencies，以及 Section 5 中相关方法的 Signature 和 Implementation，然后按照 docstring 和代码实现具体代码，同时展开 validation placeholders 为实际的验证逻辑。AI 完成编码后，会自动更新 Section 6 中该 Step 的状态，将方法从 NOT_STARTED 改为 DONE。&lt;/p&gt;&lt;p&gt;接下来是人工代码审查环节。我们使用 IDE 的 Local History 功能查看当前 step 的代码改动，重点检查代码是否符合 Section 5 的设计、是否正确实现了 validation 和 assertion、是否存在明显 bug。如果发现问题，小范围修正或进入错误处理流程（见 2.2.3）。审查通过后，我们创建一个 git commit，commit message 遵循 &amp;quot;Step N: [描述]&amp;quot; 的格式，然后继续下一个 Step，重复这个循环直到所有 Steps 完成。&lt;/p&gt;&lt;p&gt;2.2.2 防御性编程：让复杂系统更可靠&lt;/p&gt;&lt;p&gt;在分布式 AI 训练环境中，微小的错误可能触发级联故障，而异步操作和资源调度的复杂性使得问题追溯本就困难。更糟糕的是，AI 编程倾向于主动做错误处理，这种 &amp;quot;善意&amp;quot; 的处理机制往往弄巧成拙，掩盖了真实的错误信息，使得问题定位变得更加复杂。我们真正需要的是防御性编程，让错误主动暴露而不是被掩盖。然而，传统的防御性编程因其开发繁琐性和进度压力常被开发人员选择性忽略，导致系统健壮性完全依赖个人自觉。为此，我们将防御性思维前置到设计阶段：在关键节点设置验证点，构建标准化的错误处理模式库，利用 AI 技术自动生成健壮的防御代码，从而在保证开发效率的同时实现快速问题定位，显著降低维护成本。&lt;/p&gt;&lt;p&gt;统一的验证模式库： 我们维护了一个包含常用验证模式的库，每个模式都有唯一的 ID 和标准化的实现。这些模式遵循单一定义，多处复用原则。当需要在代码内增加某个验证逻辑时，只需在注释中加入模式库中的一处定义，AI 实施时会按 ID 查表展开，确保整个代码库中相同验证逻辑的一致性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNJDK2CwDP9Xbhj5xRLVPKEFeKSPFOO7gtKQNnQBuyEfdjWPT7Z89SJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.18703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527002" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/cab31d9f-c4d7-419e-b584-736bfa449492/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;设计阶段的验证标注： 在 Section 5 的设计文档中，我们不直接编写完整的验证代码，而是用标准化的注释标注验证需求。以 shrinksampler () 函数为例，通过 VALINTRANGE 标注 GPU 列表的合法性验证，通过 ASTPOSTCONDITION 标注返回结果的有效性检查。这种标注方式清晰表达了验证意图，同时保持了设计文档的简洁性。&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="php"&gt;&lt;code&gt;def shrink_sampler (self, target_gpus: List [int]):&lt;/code&gt;
&lt;code&gt;    # VAL: VAL_INT_RANGE (min=0, max=7)&lt;/code&gt;
&lt;code&gt;    # 将在实施时展开为实际 validation 代码&lt;/code&gt;
&lt;code&gt;    offload_ranks = self._calculate_offload_ranks (target_gpus)&lt;/code&gt;
&lt;code&gt;    # AST: AST_POSTCONDITION (len (offload_ranks) &amp;gt; 0)&lt;/code&gt;
&lt;code&gt;    # 将在实施时展开为 assert 语句&lt;/code&gt;
&lt;code&gt;    return offload_ranks&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;AI 自动展开验证逻辑： 当 AI 根据设计文档生成代码时，会自动将标注中的模式 ID 展开为具体的验证逻辑。参数范围验证会展开为完整的条件检查语句，后置条件会生成带有详细错误信息的 assert 语句。这种自动展开机制避免了人工编码时的遗漏和不一致。&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="python"&gt;&lt;code&gt;# 设计文档中的标注：&lt;/code&gt;
&lt;code&gt;# AST: AST_POSTCONDITION (len (offload_ranks) &amp;gt; 0)&lt;/code&gt;
&lt;code&gt;# AI 实施时展开为带详细信息的断言：&lt;/code&gt;
&lt;code&gt;assert len (offload_ranks) &amp;gt; 0, \&lt;/code&gt;
&lt;code&gt;    f&amp;quot;Post-condition: offload_ranks not empty, got {offload_ranks}&amp;quot;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;复杂验证的独立处理： 当验证逻辑超过 10 行时，内联展开会让代码变得臃肿难读。对于这类复杂验证，我们在设计文档中定义专门的验证函数，详细描述验证项和错误处理策略。例如 validategpuallocation () 函数负责验证 GPU 分配逻辑的完整性，包括检查 targetgpus 非空、确保 GPU ID 在有效范围内等。在实施计划中，我们会安排专门的步骤来实现这些复杂验证函数，为后续的核心逻辑步骤提供坚实的基础。&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="python"&gt;&lt;code&gt;#### 5.2.8 _validate_gpu_allocation () - Full Specification&lt;/code&gt;
&lt;code&gt;def _validate_gpu_allocation (self, target_gpus, current_allocation):&lt;/code&gt;
&lt;code&gt;    &amp;quot;&amp;quot;&amp;quot; 验证 GPU 分配的复杂逻辑。&lt;/code&gt;
&lt;code&gt;    检查项：&lt;/code&gt;
&lt;code&gt;    - target_gpus 非空且元素唯一&lt;/code&gt;
&lt;code&gt;    - GPU ID 在有效范围内&lt;/code&gt;
&lt;code&gt;    Raises:&lt;/code&gt;
&lt;code&gt;        ValueError: 违反任何检查条件&lt;/code&gt;
&lt;code&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;
&lt;code&gt;    # 10-20 行的详细 validation 逻辑&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;第三部分：在生产级别的大规模集群上验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.1 实验配置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们在生产级别的大规模集群上验证了时分复用方案的实际效果。实验环境采用 160 卡 GPU 集群，选择了具有代表性的 SWE Agentic 工作负载作为测试场景。模型使用 Qwen3-235B-A22B，这是一个具有 235B 参数规模、22B 激活参数的大规模语言模型，能够充分体现真实生产环境的计算压力。&lt;/p&gt;&lt;p&gt;为了模拟真实的智能体长时交互场景，我们将最大交互轮数设置为 100 轮，最大 token 长度为 64K，batch size 为 512。我们设置异步训练的 async ratio 为 1，这样的配置确保了实验的真实性和挑战性。在对比方案设置上，我们将时分复用方案与传统的异步分离方案进行对比：baseline 采用 128 卡用于 training、32 卡用于 rollout 的静态分配策略，而时分复用方案则采用 128 卡 training、160 卡 rollout 的动态调度策略。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.2 性能对比分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验结果显示时分复用的 rollout 吞吐率提升了 3.5 倍。时分复用方案的 rollout 阶段几乎始终比完全分离的 baseline 要快，甚至在某些情况下训练任务无需等待 rollout 即可开始，性能提升明显。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNQKZwk5t5iaadkibY2PANvBok5vxbF1c0HqVftPicMsRndf5rHDoy7a3cw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526976" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c03c130d-c221-4296-9450-67812bcb0c5d/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更值得关注的是任务完成率的提升。在 baseline 的完全分离方案中，由于 rollout 资源受限（仅 32 卡），导致采样速度较慢，大量任务触发了环境默认的超时限制，采样轨迹的 timeout 比例居高不下。而时分复用方案通过动态释放更多 GPU 资源用于 rollout，显著加快了采样速度，完全避免了 timeout，提升了整体训练的稳定性和样本利用效率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNuBjB5nOpErmicrkbmKBZr5yqUwfzb805gqicXZvU8YjMY417w2WWbT3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526977" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/4d16f844-ae87-4dc3-bf45-acf4e2ecbd6f/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3.3 系统开销分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在评估时分复用方案时，我们也仔细分析了引入的系统开销。参数同步开销方面，由于时分复用方案需要在更多的 GPU 之间进行参数同步（160 卡 vs 32 卡），相比分离方案会产生额外的通信开销，但这一开销在整体训练整体时间中占比极小。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNk7qbjiaSkoLZT7Rrfd1WDLuT5kOGH4zSOxRwrsYuichllM1KuGcKNDoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526978" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/32c56a44-919e-44f9-8564-f9166744d6a0/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;缩容操作的开销主要来自于 rollout 模型参数的 offload 过程。当系统需要将部分 GPU 从 rollout 模式切换到 training 模式时，需要从显存中将 rollout 参数释放，实测耗时在秒级。尽管这一操作引入了额外的同步点，但由于缩容操作开销极低，因此并未成为性能瓶颈。&lt;/p&gt;&lt;p&gt;综合来看，时分复用方案通过智能的资源调度策略，在引入极小系统开销的前提下，显著提升了 GPU 利用率和训练效率，特别是在降低 timeout 率方面表现突出，充分证明了该方案在大规模 Agentic RL 训练中的实用价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第四部分：团队介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文是 ROCK &amp;amp; ROLL 团队使用 iFlow CLI 在开源框架实践中的探索成果，后续相关功能将持续迭代并陆续发布。&lt;/p&gt;&lt;p&gt;ROCK &amp;amp; ROLL 由阿里巴巴未来生活实验室与智能引擎团队联合打造，致力于开拓强化学习（RL）的未来，探索面向未来的创新生活方式。ROLL 是灵活高效的 Agentic RL 训练框架，支持从十亿到千亿参数大模型的优化训练；ROCK 是易用、可扩展的沙箱环境管理器，可在分钟级拉起海量环境。我们坚持工程系统与算法协同创新，持续关注 RL 社区发展并分享开源实践，为 RL 在不同场景中的规模化落地提供坚实的基础设施支持。&lt;/p&gt;&lt;p&gt;iFlow CLI 是阿里巴巴未来生活实验室推出的一款终端 AI 智能体，支持通过自然语言进行交互。它能够高效分析代码仓库、完成各类编程任务，并准确理解特定的上下文需求；同时可将从基础文件操作到复杂工作流的流程自动化，显著提升开发者的工作效率。&lt;/p&gt;&lt;p&gt;欢迎关注、Star、试用并贡献代码，一起推动 RL for LLM 走向更广阔的实用化未来。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;ROCK： https://github.com/alibaba/ROCK&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ROLL：http://github.com/alibaba/ROLL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;iFlow CLI： https://cli.iflow.cn/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>注意力机制大变革？Bengio团队找到了一种超越Transformer的硬件对齐方案</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 07 Jan 2026 13:23:02 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/163fb967-50da-48d1-aa34-9918c945de3c/1767763224055.png" style="width: 700%;" class="fr-fic fr-dib"&gt;Transformer 已经改变了世界，但也并非完美，依然还是有竞争者，比如线性递归（Linear Recurrences）或状态空间模型（SSM）。这些新方法希望能够在保持模型质量的同时显著提升计算性能和效率。&lt;/p&gt;&lt;p&gt;然而，现有的线性递归或状态空间模型虽然在理论上具有线性复杂度，但在高性能 GPU 上的实际表现往往并不如人意，会受限于内存带宽和全局同步带来的高昂通信成本。&lt;/p&gt;&lt;p&gt;近日，Radical Numerics 与蒙特利尔大学 Yoshua Bengio 团队找了一个新思路，为 LLM 的效率进化提供了一个极具启发性的工程视角。该团队通过将线性递归重新定义为硬件对齐的矩阵运算，提出了一套能够相当完美契合 GPU 内存层级的算法框架。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeXdI1BDWwbh6HgyPKIRJN2ckgqBe26kVVIEQT27HGKN1cdYxpibYibcibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5972222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526232" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/246bbcdf-cb8e-4c9a-8079-563ed418e3eb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Sliding Window Recurrences for Sequence Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.13921&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该研究有三位共一作者：Dragos Secrieru、Garyk Brixi 和 Stefano Massaroli。他们都是 Radical Numerics 的成员，这家旨在打造科学超级智能的创业公司已经取得了一些亮眼的突破性进展，包括首批使用百万级上下文窗口训练的模型以及 Evo 和 Evo 2 这两个生成式基因组学模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心挑战：打破线性递归的「内存墙」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该团队首先指出，尽管并行扫描（Parallel Scan）算法在逻辑上能以 O（log n）的深度并行化处理递归，但它们在现代分级内存硬件上表现得并不理想。&lt;/p&gt;&lt;p&gt;传统的并行扫描算法，如 Kogge-Stone，具有极低的算法深度，但其数据访问模式往往跨越全局地址空间，导致频繁的全局内存同步和洗牌操作。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeibWBUr8LGSlByMZgfRrQZlHQwoj2p8zlz1nhcNPIGJccCHb4CByZHuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4083333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526233" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6c5d676c-9021-426a-b660-a843bf3a2a6e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 GPU 这种具有多级缓存（寄存器、共享内存、显存）的架构中，这种「扁平化」的算法策略不仅无法有效利用数据局部性，更无法发挥 Tensor Core 等专用矩阵乘法硬件的计算峰值。&lt;/p&gt;&lt;p&gt;这种由于数据移动而非计算本身导致的瓶颈，正是长文本大模型训练和推理中亟待解决的「内存墙」问题。&lt;/p&gt;&lt;p&gt;为了从数学层面拆解这一问题，论文引入了&lt;strong&gt;转移算子（Transfer Operator）&lt;/strong&gt;的矩阵理论。&lt;/p&gt;&lt;p&gt;线性递归系统 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeCmic7uQgJ6tAvW21P7Tn8JsEDro3icXsubFUIx0JcsKicEHpfAuSicYupw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.17829457364341086" data-s="300,640" data-type="png" data-w="258" type="block" data-imgfileid="503526231" data-aistatus="1" data-original-style="width: 130px;height: 23px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/014f8cd6-6172-4857-8820-51388ec238e7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 17.08%;"&gt; 可以被视为一个单位下三角线性系统 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibermEJ8gTiaxuVrKViaa0nfUib5JYUK7YgQ8IMnuh5iaWKwGd5pf4bN4vuFg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1975806451612903" data-s="300,640" data-type="png" data-w="248" type="block" data-imgfileid="503526236" data-aistatus="1" data-original-style="width: 103px;height: 20px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4836cb3d-0379-448f-99c6-b11680c555a2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 13.92%;"&gt;。通过对该系统进行分块处理，该团队揭示了转移矩阵 𝑳 背后深层的层级分解结构：&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeUlbj86GBZ8zCd7XgXoM6zjTxUDmnTf30kFAaOMl4yxdaqQiaEMRvnwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.16265060240963855" data-s="300,640" data-type="png" data-w="332" type="block" data-imgfileid="503526235" data-aistatus="1" data-original-style="width: 141px;height: 23px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/dbe200ad-48e3-4d40-ad45-2b29b30650fa/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 16.24%;"&gt;&lt;/p&gt;&lt;p&gt;在这个公式中，𝓛 代表各数据块内部的独立计算，而 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe84H7lCoRv0ETg3LDO6pjQGXCG86XW2qCsZaMqfXThHKmgcxlibe3BHw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.23228346456692914" data-s="300,640" data-type="jpeg" data-w="254" type="block" data-imgfileid="503526245" data-aistatus="1" data-original-style="width: 80px;height: 20px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/a4d8606c-45c3-4689-be42-7643d4c3da72/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 8.54%;"&gt;&amp;nbsp;则描述了跨块之间的「载体（Carrier）」信息传递。&lt;/p&gt;&lt;p&gt;这一分解揭示了一个关键点：&lt;strong&gt;跨块通信的本质是秩 - 1（Rank-one）的低秩更新&lt;/strong&gt;。这为消除全局同步提供了理论上的切入点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决方案：滑动窗口循环与 B2P 算法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该论文最核心的贡献是提出了&lt;strong&gt;滑动窗口循环（SWR）&lt;/strong&gt;，这是一种通过策略性截断计算视界来换取极高吞吐量的原语。&lt;/p&gt;&lt;p&gt;作者观察到，在实际训练的稳定系统中，系数 a_i 往往满足 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeGzqEQWxvOiczPdTRnXU2f307UFA8ban9iaYLiaQKARXavxcCbJUcQM6RA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.2358490566037736" data-s="300,640" data-type="png" data-w="212" type="block" data-imgfileid="503526234" data-aistatus="1" data-original-style="width: 96px;height: 23px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/53d0baa6-4a6b-4843-878c-de6f208e9d53/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 12.23%;"&gt;，这意味着输入对状态的影响会随距离呈指数级衰减。因此，强制维护长程依赖在数值上往往是冗余且昂贵的。SWR 采用了独特的锯齿状窗口（Jagged Window）结构，而非传统的均匀窗口，这种结构能自然地对齐硬件的工作负载。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe8mibRuGT1JqickGTwpIttHcoTFJK2nHpuDgfqQxRnIvYoDOkDXbpbuyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.35648148148148145" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526237" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/6dc79102-54ed-4711-bef4-8e42210f2e85/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了将这一理论落地，作者开发了&lt;strong&gt;块两步（Block Two-Pass, B2P）算法&lt;/strong&gt;及其对应的 CUDA 内核。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeI3DKkNCShrJvmPZYMgjqMYuZRPqtyFttUmNT5WbpjBvSNoMg6dQwdg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5574074074074075" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526239" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2f2754ac-473b-42fa-8946-5371b6af6848/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该算法将计算过程分为两个阶段：&lt;/p&gt;&lt;p&gt;在第一阶段，每个线程束（Warp）并行处理一个大小为 16 的本地块（与 Warp 大小对齐），利用 Tensor Core 通过 GEMM 方式完成高效的本地递归求解。&lt;/p&gt;&lt;p&gt;在第二阶段，算法通过 GPU 片上的共享内存（SMEM）或分布式共享内存（DSMEM）在相邻块之间传递状态载体，并进行即时的秩-1 补偿。&lt;/p&gt;&lt;p&gt;这种设计确保了输入数据只需从显存读取一次，所有中间通信均发生在芯片内部，实现了接近恒定的 O (1) 算法深度和极佳的硬件利用率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeAmHygXGsBoC9ralhNJgFPicHSRg9uibnFJ4j9wWmAmeg9k9pmhV4Gl4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.37592592592592594" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526238" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/f551b3a8-e153-4485-88a2-7e04380f6401/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeQqZ4GJtQI6mOap8k6ViathQkU1eoqVPVVvCff51p21dI4cqnRth23Eg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5027777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526240" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5c7a5356-afbb-4751-81d4-cc6f70c3e64a/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Phalanx 层设计与层级架构集成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于 B2P 算法，作者设计了名为 &lt;strong&gt;Phalanx &lt;/strong&gt;的新型计算层，它可以作为滑动窗口注意力或线性递归层的无缝替代品。在层参数化方面，Phalanx 遵循极简原则，通过 Sigmoid 激活函数将递归系数 a_i 限制在 (0, 1) 的稳定区间内，从而保证了长序列处理时的数值稳定性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe4PAzGvqFjzZINicxutRnXpCuQS3Cv1jV5jZJJ7rHlibxm1aJem1IsiaQQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6342592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526242" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c5da82be-1aa4-4a68-a5ef-469638039b07/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时，该层采用了基于头（Head）的参数共享模式，每个头共享一套递归系数，这与 Tensor Core 处理 16&amp;times;16 矩阵瓦片的计算模型完美契合。&lt;/p&gt;&lt;p&gt;Phalanx 被定位为混合架构中的「局部专家」，专门负责高效捕获短程令牌互动，而将长程路由任务交给全局注意力层。这种职能分工使得模型能够在不损失精度的前提下，大幅减少跨内存层级的数据移动。&lt;/p&gt;&lt;p&gt;更多细节请访问原论文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：速度与质量的双重突破&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在针对 1.3B 参数规模模型的系统性测试中，Phalanx 展现出了显著的性能优势。在 FineWeb-Edu 数据集上，Phalanx+Attention 混合模型在多个维度上超越了优化的 Transformer 和滑动窗口注意力（SWA）基准。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeukPDjSs7qaWXWTyU8lu3K0NtOEbQ1rYibLx5JA3FZK0f6rNicSOdKhIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526241" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/757d0613-1569-41eb-abdc-66dd9bbac08e/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在训练吞吐量方面，当上下文长度在 4K 到 32K 之间时，Phalanx 混合模型实现了 10% 到 40% 的端到端提速。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibelibdcpJUKxOaOfaoOADSoq3PvicLRHCcboCF5TLBFeLIJGTwuZpI4Z2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526243" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/7efd0dd2-b3fa-46b7-8a8d-c282c4f79a7d/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 8K 上下文的训练任务中，Phalanx 混合模型的训练速度比传统的 SWA/Attention 混合架构快 28%，甚至在短序列长度下也表现卓越，在 Hopper GPU 上比纯注意力模型提升了 10% 的训练吞吐量。&lt;/p&gt;&lt;p&gt;在模型精度方面，实验数据显示 Phalanx 在匹配 Transformer++ 基准性能的同时，甚至在特定比例下取得了更低的困惑度。&lt;/p&gt;&lt;p&gt;例如，在 1:1 的混合比下，Phalanx 达到了 10.85 的困惑度，优于 Transformer++ 的 10.95。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibefDMGT3iaDdejTruzkJkbR896AUKPicXUIYwoZribrTiaw2vY45lsg0ianNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.34074074074074073" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526244" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/1dc39ae8-ad50-4338-9e20-52e793facc1c/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，通过对衰减系数和门控机制的消融实验，作者证明了其精心设计的参数化方案对于维持模型表现的关键作用。更多详情请参阅原论文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结与行业意义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;《Sliding Window Recurrences for Sequence Models》为下一代长文本模型架构指明了一个方向：&lt;strong&gt;真正的效率并非仅仅来自算法复杂度的降低，更来自于对底层计算硬件物理特性的深刻理解与对齐。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过将数学上的线性递归转化为硬件友好的块级矩阵运算，Phalanx 层成功在训练速度与模型质量之间找到了一个更优的平衡点。&lt;/p&gt;&lt;p&gt;随着 2025 年之后 LLM 继续向超大规模上下文和实时具身智能演进，这种硬件感知的算子设计将成为构建更绿色、更强大 AI 系统的核心基石。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>曾对AI嗤之以鼻，如今2周生成7万行代码：Rust大佬与Claude联手打造新语言Rue</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 07 Jan 2026 10:17:49 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/416f25fa-d296-472f-9c62-7021ebe89b92/1767752055137.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2025 年 12 月 21 日，Steve Klabnik 迎来了他使用 Rust 的第十三个年头。作为 Rust 社区早期的核心人物之一，他在技术圈有着特殊的地位。在即将迈入 40 岁门槛之际，他在博客中坦言，过去几年过得颇为艰难，但现在的状态是「非常快乐」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="744" data-imgfileid="503526901" data-ratio="0.8671328671328671" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNVsTh2f8N2HOSsPWpD0V50IFAaFyqVXE0ntM5BcXLwTwtkJ06LI2Q4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="858" data-width="858" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2d582c95-efd7-4127-95b7-aa0641b72415/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="6"&gt;这种心态的转变，很大程度上源于他对工具看法的改变。Klabnik 坦言，自己曾经是个不折不扣的 AI 怀疑论者。然而，到了 2025 年，他发现自己已经无法忽视工具带来的便利，&lt;strong&gt;他现在编写的大部分代码，实际上都是由 Claude 完成的&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="7"&gt;他并没有鼓吹 AI 无所不能，只是务实地表示：对于非编程领域的生成式 AI，他依然保留意见；但在软件开发这块，目前的 LLM 已经足够好用，真正成为了得力的工具。&lt;/p&gt;&lt;p data-path-to-node="8"&gt;既然有了新工具，他决定重启一个搁置多年的念头：设计一门属于自己的编程语言。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;&lt;strong&gt;Rue：在缝隙中生长的语言&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;这个新语言被命名为 &lt;strong&gt;Rue&lt;/strong&gt;。起名的逻辑很「程序员」：因为他做过 Ruby，也做过 Rust，按照字母顺序，新语言必须以 Ru 开头。Rue 既有「后悔」（to rue the day）的自嘲意味，也指代一种植物（芸香），就像 Rust 既是铁锈也是锈菌一样，兼具好坏双重隐喻。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;但在玩笑之外，Rue 的技术定位非常严肃。Klabnik 试图探索编程语言设计中一个长期被忽视的「中间地带」：&lt;strong&gt;既要像 Rust 那样实现没有垃圾回收（GC）的内存安全，又要像 Go 或脚本语言那样易于上手。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;目前的系统编程语言往往处于两个极端：要么是 C++ 或 Rust 这样性能极致但学习曲线陡峭的「硬核」语言；要么是带垃圾回收、牺牲部分控制权的语言。Rue 试图做个妥协，它不追求 C 语言级别的极致性能，愿意牺牲一点点运行效率，换取更符合直觉的开发体验。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;但 Rue 最值得关注的不是语法，而是它的开发方式。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;Klabnik 透露，仅仅两周时间，Rue 项目就已经包含了约 70,000 行 Rust 代码。如果是纯手工编写，这个进度简直不可想象。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;他在接受技术媒体 &lt;i data-index-in-node="9" data-path-to-node="15"&gt;The Register&lt;/i&gt; 采访时，详细描述了这种「新式编程」的工作流：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="16,0,0"&gt;人类（Klabnik）：负责所有的顶层设计、架构决策、以及最关键的代码审查。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,1,0"&gt;AI（Claude）：负责编写具体的实现代码。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="17"&gt;甚至在一篇项目日志中，Claude「亲自」总结了进度，并留下了一句颇为精准的评价：「诚实地说，这 130 次提交中大多数都有我的指纹&amp;hellip;&amp;hellip; Steve 负责导演，而我负责写代码。」&lt;/p&gt;&lt;p data-path-to-node="18"&gt;Klabnik 对此有一个精辟的见解。他认为，AI 并不是让不懂编程的人突然变成了大师，它更像是一种高阶工具，类似于 Vim 编辑器，&lt;strong&gt;它门槛很低，谁都能聊两句；但上限很高，只有懂软件工程原理的人，才能用它构建出结构严谨的复杂系统。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19" skip="true"&gt;&lt;strong&gt;为什么 Rust 成了 AI 的「完美搭档」？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;就在 Klabnik 公布 Rue 的几天后，OpenAI 的联合创始人 Greg Brockman 在 X 上发的一条帖子，从另一个侧面印证了 Klabnik 的实践。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNkns96IdRAgjodCKLGseCGHO1icfcZH85VZtI6DnicxHibNcFc2IraSqicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4583333333333333" data-type="png" data-w="1080" data-width="1140" data-height="522" data-imgfileid="503526902" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9889a725-523f-4ffe-b08e-f44792d9d2a2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="21"&gt;这个帖子在技术圈引起了不小的共鸣。用过 Rust 的人都知道，它的编译器出了名的「严格」甚至「啰嗦」，很多在 Python 或 C 中能跑但会崩溃的写法，在 Rust 里根本无法编译。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNvjW7xx0YFasbOtEXWSZGLicMOjLtBsXBYGib6Bwe1HbaUzpIdPqkZruw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8027777777777778" data-type="png" data-w="1080" data-width="1524" data-height="1223" data-imgfileid="503526903" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ed9c25d0-5fd9-4a09-9712-e14201552b11/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22,0"&gt;&lt;sup&gt;「Frustracean」是对 Rust 吉祥物（螃蟹）和处理编译器时产生的挫败感的双关语。它形象地描绘了 AI 智能体在应对 Rust 严格性时的挣扎。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="23"&gt;在 AI 编程的语境下，这个曾经让初学者头疼的特性，竟然成了最大的优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24,0,0"&gt;AI 的短板：AI 生成代码容易出现逻辑微小但致命的错误（幻觉）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,1,0"&gt;Rust 的互补：编译器充当了第一道严苛的质检员。如果 Claude 写的 Rust 代码能过编译，那么内存安全、类型匹配等一大类错误就已经被排除了。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN7JRb2vTyeQuCG5aJiav2Kc0a1wWCpmSmKSgWIPB98J3H2OzW8wMPb1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0675925925925926" data-type="png" data-w="1080" data-width="1548" data-height="1653" data-imgfileid="503526904" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/9a4228b5-cfda-4362-9eac-438c11c9e76c/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNOkpvvMBicj5BJzBBXjwIrRF2S7yto7BEUlGlmpjSrNNpI7TX56MVrsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.24722222222222223" data-type="png" data-w="1080" data-width="1542" data-height="381" data-imgfileid="503526905" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/16ecb2a0-2734-4670-968e-edc9e4de719e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="25"&gt;这就是为什么 Klabnik 能放心让 AI 写几万行代码的原因&amp;mdash;&amp;mdash;编译器帮他守住了底线。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;目前的 Rue 还很粗糙，Klabnik 也表现得非常佛系。他没有承诺要建立什么庞大的社区，也不打算把它变成下一个 Rust，仅仅是作为一个「为了好玩」的业余项目。他保留了随时因为「不好玩了」而停更的权利。&lt;/p&gt;&lt;p data-path-to-node="27"&gt;但这个实验本身已经足够说明问题：到了 2026 年，即使是构建编程语言这样硬核的系统工程，人类开发者的角色也正在从「泥瓦匠」转变为「建筑师」，而那些拥有严格约束的语言，反而因为「难写」，意外地成为了 AI 时代最可靠的地基。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;https://steveklabnik.com/writing/thirteen-years-of-rust-and-the-birth-of-rue/&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="29,1,0"&gt;&lt;sup&gt;https://www.theregister.com/2026/01/03/claude_copilot_rue_steve_klabnik/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>近十年后谷歌与波士顿动力再「牵手」，这次要为人形机器人注入「灵魂」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 07 Jan 2026 10:12:19 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-07</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-07</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/025c97fc-2a79-4fe7-bf66-34fbc66cc976/1767751819963.png" style="width: 700%;" class="fr-fic fr-dib"&gt;近日消息，在拉斯维加斯举行的 CES 2026 上，&lt;strong&gt;波士顿动力与谷歌 DeepMind 宣布达成一项全新的 AI 合作伙伴关系&lt;/strong&gt;，旨在为人形机器人开启一个全新的人工智能时代。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNGBj4QCTCC1OpvffXHScUicMA4kjeZkuuj6MGtDhNluEQbypYWrFP69g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526910" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/98323a19-97f1-4db8-be13-90a2165565b6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;谷歌 DeepMind 也同步更新了这一消息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNFxAGvibGFRnU1As4r6yW7fYejhcpTmpXXUWJE5nHFbIEXhGoCHrrGtQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526912" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/87d92c60-ac76-4def-a8d7-11c6404beacc/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据了解，双方计划将前沿的 Gemini Robotics AI 基础模型与波士顿动力全新的 Atlas 人形机器人进行深度整合。&lt;/p&gt;&lt;p&gt;这项战略合作将&lt;strong&gt;重点放在赋能人形机器人完成多种工业任务，并有望成为制造业转型的重要推动力，首个重点应用领域便是汽车行业&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;资料显示，联合研究工作预计将在未来数月内启动，并将在两家公司内部同步展开。&lt;/p&gt;&lt;p&gt;波士顿动力公司 Atlas 机器人行为负责人 Alberto Rodriguez 表示，对这次双方的合作感到非常高兴。&lt;/p&gt;&lt;p&gt;据他透露，当前波士顿动力计划打造全球能力最强大的人形机器人，因此需要一个合作伙伴，帮助为这些高度复杂的机器人建立全新的视觉 - 语言 - 动作（VLA）模型。&lt;strong&gt;「在构建可靠、可扩展的模型方面，没有比 DeepMind 更合适的团队了，这些模型可以安全高效地部署到各种任务和行业中。」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;诚然，从 BigDog 到 Spot，再到如今的 Atlas，波士顿动力机器人在动力学、平衡控制等方面确实声名远播，但随着大模型的快速发展与落地，机器人也早已开启新的叙事方式，在强健的「身体」之外，能感知、推理、学习和决策的机器人「大脑」显得更为重要。但在这一点上，无疑是波士顿动力的短板。&lt;/p&gt;&lt;p&gt;而谷歌 DeepMind 近年来在机器人 AI 基础模型上面的进展也是有目共睹的，例如基于大规模多模态 Gemini 模型构建的 Gemini Robotics，旨在赋予机器人感知环境、理解指令、规划行动和与人交互的能力。&lt;/p&gt;&lt;p&gt;对此，谷歌 DeepMind 机器人高级总监 Carolina Parada 表示，「我们开发 Gemini Robotics 模型是为了将 AI 带入物理世界，很高兴能与波士顿动力公司团队合作，探索他们新型 Atlas 机器人的各种可能性，同时开发新的模型来扩大机器人技术的影响范围，并安全高效地扩展机器人规模。」&lt;/p&gt;&lt;p&gt;此次双方展开合作可谓是强强联手，&lt;strong&gt;一方面，DeepMind 为波士顿动力的机器人注入「灵魂」，使其具备了前所未有的智能水平，另一方面，波士顿动力则提供了一流的硬件平台，让 DeepMind 的先进 AI 算法有了施展拳脚的舞台&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;而网友们也纷纷看好他们彼此的合作，或将人形机器人的发展推向新高度。「看来超级大脑找到了它的超级身体。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN43FLtCCkUj8JuaCf6hJOJeicIG7AKXr0ZticAVrZfhqibbPffQ6D8rjNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.1259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526913" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/51d9511e-98d2-4227-b0ad-3fc64222dbbb/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Today in AI 则认为，Gemini Robotics 的基础能力与 Atlas 硬件相结合，代表了前沿模型与物理驱动的融合，应用于机器人的 Scaling Laws 重新定义了具身智能，通用智能体是合乎逻辑的结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNGNGx43jsyqpL2H5ARnUxYdNxR5KZtM04Xt4cfb1QnicbAXm7KpO4gew/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.18796296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526914" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/23b66081-4430-4dd8-8e0e-cb5a597cf841/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;有意思的是，前段时间宇树人形机器人在舞台上与舞蹈演员劲歌热舞的视频在 X 上流传甚广，引起网友们的惊呼，而此次谷歌与波士顿动力的合作似乎让他们看到了希望。&lt;/p&gt;&lt;p&gt;一位名为 Super Nick 的网友称，太期待看到一场真正的「智能正面对决」了：一边是像 Gemini 驱动的 Atlas 这样的西方机器人，另一边是中国阵营里动作迅猛的宇树或优必选人形机器人。也许就在 RoboCup 2026，或者下一届世界人形机器人运动会上，这一切就会发生，那一定会非常震撼。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNdguOnPv1wCR0w7crCe1gYdRPibpal1TEuNSw377G2KYMiaLPr8ExAcrg/640?wx_fmt=jpeg#imgIndex=5" data-ratio="0.1881371640407785" data-s="300,640" data-type="png" data-w="1079" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNshicwCaNTZsgibyRG8KuicJYxcZictgx3fLsfSHjAfdajXjMzULGzdMrcg/640?wx_fmt=png&amp;from=appmsg" data-cropx1="1.9217081850533808" data-cropx2="1080" data-cropy2="203.70106761565836" data-imgfileid="503526915" data-aistatus="1" data-original-style="width:561px;height:106px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2481b31f-a6ee-4b9a-a090-d3a6d8c6b36c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有一些资深网友乍一看到消息，有点懵，&lt;strong&gt;「一时间还以为是买断。」「那你当时为什么还要卖掉它？」&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNm8MvVPhLxP3TMOWSuJoexB1WZjcWcq0yrtpBdyxWSQLtKrsicGe72Tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.1537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526916" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/17f3b51a-9779-4bdf-aaba-44f8008daa28/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNvnibZUIVgicl04ejP6ZibuMoTG6hUrox0RNyyoyBCjy1ABhgzicjiclf9uw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.16018518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526917" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/567c687c-1ffd-4373-879d-30af5e8ce25f/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;其实，&lt;strong&gt;这并非谷歌与波士顿动力第一次产生交集&lt;/strong&gt;，只不过彼时的合作结果并不理想。&lt;/p&gt;&lt;p&gt;早在 2013 年 12 月，谷歌就曾通过并购将波士顿动力收入麾下，成为其机器人版图中的核心资产之一。然而三年半后，或许是认为波士顿动力难以在短期内推出可市场化产品，谷歌便转手将其出售给软银集团。&lt;/p&gt;&lt;p&gt;此后，两者沿着各自的故事线演进，波士顿动力在软银与现代汽车集团的支持下，持续深耕机器人本体与运动控制能力，而谷歌则将重心进一步收敛到 AI 基础研究与大模型方向&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;如今，&lt;strong&gt;双方再度「牵手」，更像是一次技术条件成熟后的回归&lt;/strong&gt;，谷歌历经低谷，却又凭借以 Gemini 为代表的大规模、多模态基础模型体系强势逆袭，重夺 AI「铁王座」，而波士顿动力则完成了新一代 Atlas 人形机器人的形态与能力重构。&lt;/p&gt;&lt;p&gt;一方需要成熟的人形机器人平台来补足硬件的拼图，另一方则需要面向物理世界的 AI 基础模型来强化「盔甲」，多年前合作时缺乏的生长条件在当下得到完善了。&lt;/p&gt;&lt;p&gt;那么问题来了，这次的合作到底于谁的意义更大？到底是波士顿动力的胜利，还是谷歌机器人的开端？而有一点可以肯定的是，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;波士顿动力与 DeepMind 的合作无疑为大家描绘了一幅令人神往的未来图景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;接下来就拭目以待，看这两位科技巨头如何携手创造历史，进入一个人机共存、共创未来的新纪元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://bostondynamics.com/blog/boston-dynamics-google-deepmind-form-new-ai-partnership/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/GoogleDeepMind/status/2008283100254494916&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>英伟达展示台式AI超算DGX Spark新能力：能跑千亿参数模型</title>
      <description>&lt;![CDATA[DGX Spark 的性能已经提升了一倍以上。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Tue, 06 Jan 2026 20:55:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;本周的 CES 展会上，英伟达展示了 DGX Spark 和 DGX Station 桌面 AI 超级计算机的能力。&lt;/p&gt;&lt;p&gt;这些系统号称「全球最小 AI 超算」，基于 Grace Blackwell 架构算力，拥有 128G 统一内存和千万亿次级 AI 性能，为开发者提供了在本地开发并轻松扩展到云端的全新能力。&lt;/p&gt;&lt;p&gt;其中，DGX Spark 可以运行 1000 亿参数的大模型，DGX Station 可运行 1 万亿参数模型。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6782fa2b-e466-4689-b16b-3a6944b90af9/image.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;自去年 10 月份发布以来，DGX Spark 的 token 生成性能已经提升了一倍以上，这主要归功于软件方面的提升。&lt;/p&gt;&lt;p&gt;英伟达表示，由于模型优化技术的不断进步以及与开源社区的合作，以前需要数据中心才能运行的各种开源模型现在可以在桌面级的 DGX Spark 和 DGX Station 上加速运行。&lt;/p&gt;&lt;p&gt;DGX Spark 预配置了 NVIDIA AI 软件和 NVIDIA CUDA-X 库，为开发人员、研究人员和数据科学家提供强大的即插即用优化功能，用于构建、微调和运行 AI。&lt;/p&gt;&lt;p&gt;Spark 为所有开发者提供了一个基础平台，让人们可以在桌面级设备上运行最新的 AI 模型；Station 则使企业和研究实验室能够运行更高级、更大规模的前沿 AI 模型。这些系统支持直接从桌面运行最新的框架和开源模型，包括最近发布的 Nemotron 3 模型。&lt;/p&gt;&lt;p&gt;NVIDIA Blackwell 架构为 DGX Spark 提供支持（具备大致相当于 RTX 5070 的算力），其支持 NVFP4 数据格式，可将 AI 模型压缩高达 70%，并在不损失推理性能的情况下提高速度。&lt;/p&gt;&lt;p&gt;NVIDIA 正在与开源软件生态系统的合作，例如与 llama.cpp 的合作，从而进一步提升性能。在 DGX Spark 上运行最先进的 AI 模型时，平均可实现 35% 的性能提升。llama.cpp 还包含一项提升用户体验的升级，可加快 LLM 的加载速度。&lt;/p&gt;&lt;p&gt;DGX Station 搭载了 GB300 Grace Blackwell Ultra 超级芯片和 775GB FP4 精度的一致性内存，可运行高达 1 万亿参数的模型，为前沿 AI 实验室提供桌面级大规模模型的尖端计算能力。这包括多种先进的人工智能模型，例如 Kimi-K2 Thinking、DeepSeek-V3.2、Mistral Large 3、Meta Llama 4 Maverick、Qwen3 和 OpenAI gpt-oss-120b。&lt;/p&gt;&lt;p&gt;vLLM 核心维护者、清华博士游凯超表示：「GB300 通常以机架式系统的形式部署。这使得像 vLLM 这样的项目难以直接在强大的 GB300 超级芯片上进行测试和开发。DGX Station 改变了这种现状。通过将 GB300 集成到紧凑的单系统桌面环境中，DGX Station 使 vLLM 能够以更低的成本测试和开发 GB300 的特定功能。这加快了开发周期，并使 vLLM 能够轻松地持续验证和优化 GB300 的性能。」&lt;/p&gt;&lt;p&gt;除了 AI 能力的提升，英伟达还宣布计划在本月晚些时候以订阅服务的形式在 Spark 上提供完整的 AI 企业套件。该套件包含对一系列面向企业的应用程序、框架、模型和微服务的访问权限，旨在简化 AI 应用和服务的开发。&lt;/p&gt;&lt;p&gt;英伟达计划在今年内发布一个完全可在 Spark 上运行的 Nsight CUDA 代码助手版本。此前，该助手使用的模型体积过大，无法在英伟达的消费级显卡上运行，只能在云端使用，这对于注重隐私的企业来说实用性受到限制。&lt;/p&gt;&lt;p&gt;对于游戏玩家而言，英伟达正在将 RTX Remix 支持扩展到 Spark 平台。该平台旨在支持利用英伟达的光线追踪加速器开发游戏模组。通过此次集成，诸如文本生成等任务可以在 Spark 上实现运行。&lt;/p&gt;&lt;p&gt;对于机器人爱好者，英伟达表示正在开发一份新的指南，将 Spark 与 Hugging Face 的 Reachy 机器人搭配使用。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fa91f4e6-310e-4250-bdd0-4b54c875b564/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;英伟达表示，DGX Spark 及合作伙伴的 GB10 系统现已可通过宏碁、华硕、戴尔、技嘉、惠普、联想、微星、新华三、超聚变、紫光晓通、丽台科技、英迈，神州数码购买。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>密瓜智能获数千万元天使轮融资：植根开源基因，驱动异构算力效率跃升</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 06 Jan 2026 18:15:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;div&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8b9314a2-608e-440a-a35d-eaa185b45503/1767753979760.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/div&gt;专注于异构算力调度和虚拟化的 AI 初创企业&lt;strong&gt;上海密瓜智能科技有限公司（&amp;ldquo;密瓜智能&amp;rdquo;）已于近期完成数千万元的天使轮融资&lt;/strong&gt;，本轮融资由&lt;strong&gt;复星创富&lt;/strong&gt;领投，&lt;strong&gt;拙朴投资、种子投资人及产业方&lt;/strong&gt;强力跟投。自去年 3 月获得超五百万元种子轮融资以来，密瓜智能在不足一年时间内已迅速完成 2 轮融资，展现出强劲的发展势能，其技术前景与商业价值备受市场认可。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;strong&gt;密瓜智能：让异构算力因开源而好用&lt;/strong&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;密瓜智能始终致力于&lt;strong&gt;打造全球领先的开源异构算力调度方案，以技术驱动 AI 时代的算力效率革命&lt;/strong&gt;。该公司&lt;strong&gt;主导并发起了 CNCF 项目 HAMi&lt;/strong&gt;，这是目前行业内&lt;strong&gt;唯一专注于异构 GPU 资源虚拟化、高效调度的开源项目&lt;/strong&gt;，通过灵活、可靠、按需、弹性的 GPU 虚拟化来提升资源利用率，可以插拔式、轻量化、无侵入地部署在任意公有云、私有云、混合云环境中。在生态兼容层面，HAMi 已全面支持 NVIDIA、昇腾、沐曦、寒武纪、海光、摩尔线程、天数智芯、昆仑芯、燧原及 AWS 等国内外主流 GPU 芯片。同时无缝支持 vLLM, Volcano, Koordinator, Kueue 等上下游主流开源项目，逐步形成稳定的异构算力生态。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;目前，HAMi 已集结了来自&lt;strong&gt;&amp;nbsp;16 个国家的 360 余位贡献者&lt;/strong&gt;，社区活跃度持续提升，&lt;strong&gt;最终用户已经超过 200 家企业&lt;/strong&gt;，覆盖国内主流云厂商、互联网以及 KA 用户，并已拓展至东南亚、欧洲等海外地区，行业影响力十分广泛。2025 年，由密瓜智能发起的&amp;ldquo;不卷算力卷效率&amp;rdquo;系列 Meetup 亦备受关注。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;在短短一年的商业化发展中，&lt;strong&gt;密瓜智能获得多个头部客户商业订单，渠道合作体系迅速拓展&lt;/strong&gt;，正逐步获得市场的广泛认可。基于现有生态发展与广泛的用户反馈，密瓜智能将进一步推动 HAMi 与更多 GPU 厂商实现兼容适配，持续挖掘高价值的场景需求，推动其在大模型推理侧的生态适配，构建上下游协同的算力服务体系。与此同时，将基于 HAMi 推出面向企业级市场的核心产品，为客户的生产级场景持续赋能。&lt;div&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c4000e65-a8e1-4751-bac3-c36f88a90a90/1767753992058.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/div&gt;密瓜智能的创始团队成员均来自于&lt;strong&gt;「DaoCloud 道客」、第四范式、百度等 AI 基础设施领域代表厂商&lt;/strong&gt;以及&lt;strong&gt;清华大学、浙江大学等国内高校&lt;/strong&gt;，在云计算、云原生以及 GPU 共享与调度技术上具备丰富的技术积累和行业经验。&lt;strong&gt;创始人张潇和联合创始人李孟轩是 HAMi 的作者&lt;/strong&gt;，团队其他成员也都是 HAMi 的核心贡献者和维护者，拥有广泛的技术影响力与行业前瞻性。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;strong&gt;投资人说：从开源到产业，他们以创新赋能异构算力&lt;/strong&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;strong&gt;复星创富投资执行总经理叶丽娟&lt;/strong&gt;表示，异构将成为算力市场的长期格局，无论是 GPU 还是新型算力芯片，是 AI 最重要的底座，密瓜智能在 AI 大生态中不可或缺地链接算力端与应用端，为客户极大程度提升算力效率，节省昂贵的算力成本。开源的 HAMi 已建立起颇具规模的开发者与用户生态&amp;mdash;&amp;mdash;这一路径也与 AI 行业开源化、协同化的发展趋势高度契合。HAMi 提供的灵活、弹性、按需且可靠的虚拟化技术，能够实现算力的高效切分与调度，显著提升算力利用率，从而为全球客户带来极具竞争力的投资回报率（ROI）。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;strong&gt;拙朴投资总监陈敏洁&lt;/strong&gt;在与密瓜智能的沟通中提到，在上一代以 CPU 为核心的云计算时代，诞生了像 VMware 这样的虚拟化巨头。如今到了以 GPU 为核心的 AI 智算时代，AI 任务负载对算力的需求与底层硬件分配方式之间也同样存在巨大的错配，虚拟化是通向 AI 普惠的核心钥匙。国产算力多元异构百家争鸣的现状，也赋予 HAMi 开源更深远的意义，开源不再只是情怀，而是生存发展的必需，是对当前算力秩序的重塑。HAMi 想要打破硬件的藩篱，让算力成为像水一样随手可得的公共基础设施，帮助多元异构芯片与全球生态共振。在这一趋势中，HAMi 有望成为异构算力调度虚拟化的全球通用标准。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;strong&gt;孵化股东「DaoCloud 道客」创始人兼 CEO 陈齐彦&lt;/strong&gt;表示，HAMi 已在 AI 基础设施中形成关键生态位。「DaoCloud 道客」期待密瓜智能将其能力打造为统一、通用的异构 GPU 管理与虚拟化标准。随着 AI 技术向开源社区收敛，密瓜智能具备成为该领域领军者的潜力，双方产品体系已与 HAMi 企业版深度结合，实现协同赋能。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;strong&gt;持续深耕开源，加速企业级产品布局&lt;/strong&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;strong&gt;密瓜智能创始人兼 CEO 张潇&lt;/strong&gt;对各位新老投资人的信任与支持表示衷心感谢。他提到，密瓜智能自创立之初，便&lt;strong&gt;以开源为技术基因，聚焦于异构算力这一核心赛道&lt;/strong&gt;。过去一年，凭借这一关键的生态卡位和在开源社区的持续深耕，密瓜智能在技术沉淀与产品迭代上取得了扎实的进展，&lt;strong&gt;这既离不开团队的努力，也受益于投资人在战略与资源上的持续赋能&lt;/strong&gt;。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;本轮融资将主要用于公司发展的三个方面。&lt;strong&gt;第一，深化开源生态建设&lt;/strong&gt;，公司将持续贯彻开源战略，保持在这一路径上的领先投入。&lt;strong&gt;第二，加速团队建设与全球化布局&lt;/strong&gt;，重点扩大核心技术研发与生态营销团队，并构建完善的渠道体系。（如果有想要加入密瓜智能全球渠道体系的伙伴，欢迎与我们取得联系）&lt;strong&gt;第三，企业级产品研发&lt;/strong&gt;，密瓜智能将围绕弹性扩容、任务优先级调度、显存超配及全链路可观测性等企业级能力，推出企业核心产品，进一步推动开源项目的企业赋能及商业化变现。&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;&lt;br&gt;&lt;/div&gt;&lt;div data-docx-has-block-data="true" data-lark-html-role="root" data-page-id="VNqkdwPOpoqsVnxT6QfcrhBGnod"&gt;从技术创新到生态共建，从开源社区到全球客户，密瓜智能身上丰富的开源基因与创新力让它在短短一年间展现出惊人的成长速度，印证了其以开源驱动算力变革的前瞻性。未来，随着推理需求持续深化与应用场景不断拓展，密瓜智能将持续为企业提升算力效率，在通向AGI的道路上注入核心动力。&lt;/div&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，智元提出SOP，让VLA模型在真实世界实现可扩展的在线进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 06 Jan 2026 18:11:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e017edb5-947a-4abf-ab17-a1d7dab2ed00/1767693873504.png" style="width: 700%;" class="fr-fic fr-dib"&gt;对于电子产品，我们已然习惯了「出厂即巅峰」的设定：开箱的那一刻往往就是性能的顶点，随后的每一天都在折旧。&lt;/p&gt;&lt;p&gt;但对于通用机器人来说，这个设定必须被颠覆。&lt;/p&gt;&lt;p&gt;试想，如果一个在实验室里完成训练的 AI 机器人，一进家门面对光线稍暗的房间或堆满杂物的茶几就大脑宕机，那它就永远只能是一个昂贵的实验品。这正是当前具身智能面临的尴尬真相：我们在互联网知识里训练出了博学的预训练模型，可一旦让它们走进充满未知的物理世界，这些「理论巨人」往往会因为环境变化而束手无策：「懂」很多道理，却依然干不好家务。&lt;/p&gt;&lt;p&gt;通用机器人的出路，绝不应是被困在出厂设置里的「静态标品」，而应当是能在真实部署中、在每一次失败和纠正中持续变强的生命体。&lt;/p&gt;&lt;p&gt;为了实现这一跨越，智元具身研究中心提出了 &lt;strong&gt;SOP（Scalable Online Post-training）框架&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNJ23GOdCQ83XLUvovIkK9viaRGSy57lb6e3ynbwEwCnkic9TDq8F7Tia7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527026" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4eb3d760-2808-441d-a94f-3aea4fe797ff/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：SOP: A Scalable Online Post-Training System for Vision-Language-Action Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;官方博客：https://www.agibot.com/research/sop_zh&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;SOP，即&lt;strong&gt;可扩展在线后训练&lt;/strong&gt;，是一种颠覆性的机器人学习新范式。据了解，&lt;strong&gt;这是业界首次在物理世界的后训练中深度整合了在线、分布式和多任务机制&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;通过 SOP 框架，智元具身研究中心构建了一个「多机平行现实」与「云端集中进化」的闭环，进而打破了机器人认知的时间边界，让智能的进化不再止步于出厂的那一刻。&lt;a href="https://mp.weixin.qq.com/s/3I-zhRIZe6gPk_wR2GklcA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d3573f40-602b-4550-b415-d9c2527fbefe/1767693912163.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SOP：让机器人实现在真实世界中的分布式持续学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在过去几年里，基于互联网海量数据预训练的 VLA（视觉 - 语言 - 动作）模型，虽然赋予了机器人一定的通用泛化能力，但始终面临一个难以逾越的鸿沟：&lt;strong&gt;「懂」不代表「能」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;预训练模型或许「懂」什么是叠衣服，但当它真正面对一件材质松软、光照复杂的真实衣物时，往往会因为&lt;strong&gt;分布偏移&lt;/strong&gt;而束手无策。&lt;/p&gt;&lt;p&gt;为了解决这个问题，传统的做法是&lt;strong&gt;后训练（post-training）&lt;/strong&gt;。但这通常是一条&lt;strong&gt;离线、单机、顺序&lt;/strong&gt;的漫漫长路：采集数据、离线训练、更新模型、再次部署。这种模式下，机器人探索慢、迭代慢，且很容易在学习新任务时遗忘旧能力。&lt;/p&gt;&lt;p&gt;智元具身研究中心提出的 SOP 颠覆了这一陈旧范式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNIAT13cBBwmchqbbSBpEQ5TicUibrsFgO8TFibadAzTe4T5TsCTHL9qgVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527003" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/09e5f2fb-77d8-4292-bbc1-44b40f309e7a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;它将 VLA 的后训练从「单机单打独斗」转变为「&lt;strong&gt;在线、集群、并行&lt;/strong&gt;」的集团军作战。形象地说，SOP 构建了一个「&lt;strong&gt;多机平行现实 &amp;rarr; 云端集中学习 &amp;rarr; 模型即时回流&lt;/strong&gt;」的超级闭环。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNfNoykDHTEBveWjhO6fHvCS2S9Ex5oXhDMlax25jJ5KmFmhKEUnaDBg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.45732838589981445" data-s="300,640" data-type="gif" data-w="1078" type="block" data-imgfileid="503527004" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/fe832591-58e3-4cdb-81e7-96126c40b07e/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;分布式机器人队伍：构建「平行现实」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 SOP 架构下，不再是一台机器人在苦苦探索，而是多台机器人组成集群，共享同一个 VLA 策略。&lt;/p&gt;&lt;p&gt;这就好比在同一时间开启了多个「平行现实」：有的机器人在尝试叠衣服，有的在整理杂货，有的在处理纸盒。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNHZJw8ianCuFBKwVssOmZYwFCH6RMY4uO14q58DzF764qmFibwBO35hgQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.546875" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503527005" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6b0f0e48-6a2d-4b5a-b17d-795a6ea0b027/640.gif" data-order="1" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种空间上的并行，大幅拓宽了真实世界中状态 - 动作分布的覆盖面，让系统能瞬间接触到极其广泛的场景，直接避开了单机学习容易陷入的局部瓶颈。&lt;/p&gt;&lt;p&gt;值得注意的是，&lt;strong&gt;人类还可以通过施加少量的干预性修正来加速学习过程。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNbz9TozgdSkV4uTpJrmylJHMOmsOMVHNlR3vnuGySBb3BAW5ibKLV19g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.54125" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503527006" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ea8ab8aa-6a83-4bd1-9357-fff4401cd7b8/640.gif" data-order="2" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;云端集中在线更新：分钟级的进化速度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;所有的运行轨迹、奖励信号甚至人工纠正信息，都会被实时流式上传至云端 GPU 集群。在这里，一个&lt;strong&gt;通才学习器（Generalist Learner）&lt;/strong&gt;夜以继日地运转，持续对策略模型进行在线更新。&lt;/p&gt;&lt;p&gt;为了支撑这种大规模的实时并发，SOP 在底层架构上搭建了一套&lt;strong&gt;工业级的分布式数据基座&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;系统采用了先进的 &lt;strong&gt;Actor-Learner 分离架构&lt;/strong&gt;，通过消息队列完全解耦了数据生产与消费。这意味着系统具备了「零配置」的&lt;strong&gt;弹性水平扩展能力&lt;/strong&gt;：新的机器人加入集群无需修改任何代码或停机配置，只需连接消息队列即可即插即用，自动分担数据采集任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNbTKZMDq2OZavkIEDjSn4cR1dbLUpsUrAmhLgV9S7v9nGUQ6fic1fbAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.28888888888888886" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527007" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b1bd801b-b523-43bd-abe4-97f3f4a9141a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时，针对物理世界复杂的网络环境，SOP 建立了严苛的容错与数据原子性机制。依靠本地缓冲和对象存储的原子写入特性，确保了即便在网络波动或节点故障时，数据要么完整保存，要么完全回滚，绝不让脏数据污染核心训练池。&lt;/p&gt;&lt;p&gt;为了让学习更高效，SOP 内置了一个聪明的&lt;strong&gt;动态采样器（Adaptive Sampler）&lt;/strong&gt;。它不像传统模型那样盲目混合数据，而是能根据任务的实时训练损失「查漏补缺」，也就是&lt;strong&gt;自动加大对当前薄弱环节的在线数据训练权重&lt;/strong&gt;。这种有的放矢的学习策略，让位于边缘端的机器人能在数秒至数十秒内获得云端最新进化的大脑，真正实现了群体智能的实时同步。&lt;/p&gt;&lt;p&gt;这意味着，如果一台机器人在北京学会了某个抓取动作的微调，几分钟后，位于上海的另一台机器人就能用上这套最新的记忆。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;破解灾难性遗忘：泛化与精度的共存&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的单机在线训练往往面临一个两难：为了精通某项任务（如叠衣服），模型很容易退化成只懂这一件事的专家，丧失了通用的 VLA 能力。&lt;/p&gt;&lt;p&gt;SOP 通过&lt;strong&gt;多任务并行&lt;/strong&gt;巧妙化解了这一矛盾。因为它是在更广阔的分布中同时进行多任务学习，而非按顺序一个个学，从而确保了 VLA 的通用性不会因针对某一任务的性能提升而受损。&lt;/p&gt;&lt;p&gt;下面展示 SOP 的伪代码：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNClicsf9N1AWPdbCZMviad8bm2krkab1SiaezC0z5p0yD3N1UzwgdJ2G0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7851851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527008" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f31d729e-6d13-4cad-a8d3-08abd02f5a68/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;有效性验证：从鲁棒性涌现到具身智能的 Scaling Law&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证 SOP 的有效性，智元具身研究中心团队思考了三个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;SOP 对于预训练 VLA 的性能究竟有多大的提升？跟之前的一些离线方案相比呢？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分布式机器人队伍的数量规模扩展会如何影响性能？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于不同质量的预训练模型，SOP 能否提供一致的性能增益？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解答这三个问题，智元具身研究中心基于自家的&lt;strong&gt;智元精灵 G1（Agibot G1）&lt;/strong&gt;机器人平台进行了实验验证。这是一款拥有双臂 14 个自由度的移动操纵机器人，其头顶与手腕配备的「三目」RGB 视觉系统，配合 7 自由度的灵活手臂和 30Hz 的高频控制，使其具备了在复杂非结构化环境中执行精细微操的硬件基础。&lt;/p&gt;&lt;p&gt;结果呢？相当亮眼！下面我们将深入挖掘实验数据，你将看到：SOP 的技术可行性不仅得到了验证，更展示了极高的「训练性价比」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;超越离线：不仅是成功率的提升，更是鲁棒性的涌现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先看看实验所选的任务 &amp;mdash;&amp;mdash; 可以说极具挑战性：从杂货补货任务中涵盖的 500 多种不同形态商品，到叠衣服任务中涉及的柔软易变形物体，甚至包括协同打开冰柜门等复杂动作。这些场景不仅考验机器人的认知能力，更对操作的鲁棒性提出了严苛要求。&lt;/p&gt;&lt;p&gt;在有效性验证中，团队选择了&lt;strong&gt;&amp;nbsp;HG-DAgger（典型的单机在线算法）和 RECAP（最新的 SOTA 离线方法）&lt;/strong&gt;作为对比基准。实验设计非常直观：先看基线模型表现，再看经过这些算法打磨后的效果，最后看接入 SOP 框架后的「终极形态」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNTc2xA1JKUmWjEMYao3nPHEEf1ib4kiasGREHeNA45QWEb015ib8I3SQQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527009" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3fbe8df3-5107-4f29-942d-307bc8b98733/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在各类测试场景下，结合 SOP 的在线多机方案全面碾压了传统单机或离线方法。更令人惊喜的细节出现在「叠衣服」和「叠纸盒」这类长序列任务中：SOP 训练出的模型展现了显著的「&lt;strong&gt;恢复行为&lt;/strong&gt;」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNM8PQuC55eCfBSu9f4A6xlHE95soWjkdyFBR4eKu5umlS7NJMSDGODg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.49875" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503527010" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/3d7164f7-d71a-4ccb-a10b-1cd8864a6794/640.gif" data-order="3" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNe90c6aPKeFibnOL3icaNumUMEruGBibxrwmTXdoDkBZgtM7RHLLYI32HA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.5" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503527012" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/ab35de7b-4f39-4e45-9e7b-4aa230bae728/640.gif" data-order="4" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着，当机器人在操作中出现细微偏差时，它不再像过去那样直接导致任务失败或中止，而是学会了类似人类的微调动作进行补救。&lt;/p&gt;&lt;p&gt;这种在动态交互中获得的鲁棒性，直接经受住了极限压力的考验：&lt;strong&gt;在叠衣服和组装纸盒的长程评估中，SOP 系统实现了超过 36 小时的连续运行且无性能衰减&lt;/strong&gt;。这种稳定性同时转化为效率的质变，特别是在叠衣服任务中，SOP 将系统的吞吐量直接翻倍，从每小时 21 件提升至 45 件。&lt;/p&gt;&lt;p&gt;以下视频展示了配备了 SOP 的智元精灵 G1 连续 36 小时叠衣服与叠纸盒的视频片段（已加速）：&lt;/p&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gWicXs2As91d0ugEiarVKrDQiaNibkBR0yTmsnc6sXABFOf692qw132V7iba58zHkPKJLgYbVYN3B35n8AQ%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4330074355775782924" data-ratio="1.7777777777777777" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4330074355775782924" data-vh="371.8125" data-vidtype="2" data-vw="661" data-w="1920" height="384" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4330074355775782924"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;a href="https://mp.weixin.qq.com/s/3I-zhRIZe6gPk_wR2GklcA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dc271be0-0c45-4db6-84c2-be292ec01ed4/1767694133763.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;具身智能的 Scaling Law：用硬件换时间，效率达到原来 2.4 倍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说单机试验只是「小试牛刀」，那么关于扩展性的实验则回应了工业界最关心问题：堆机器人数量，真的有用吗？&lt;/p&gt;&lt;p&gt;团队设置了单机、双机和四机三种配置。实验结果（见下表）展现了一个清晰的趋势：&lt;strong&gt;随着分布式集群规模的扩大，模型性能呈现出近乎线性的增长&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNsUGjZnOiauxxK3AOn0YVvuiaDrP7sbcAlrRhftl4S0vl5vvicf3TdJNuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.22030981067125646" data-s="300,640" data-type="png" data-w="581" type="block" data-imgfileid="503527013" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/2c55bc9e-8cb6-42fc-b08f-fad94c5603ab/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在严格限制总训练时长为 3 小时的前提下，四机并行学习的最终成功率达到了 &lt;strong&gt;92.5%&lt;/strong&gt;，比单机提升了 12%。更关键的是，SOP 成功将硬件的扩展转化为了学习时长的极致压缩。要达到 80% 的性能基准线，单机苦练需要 174 分钟，而四机战队仅需 72 分钟，&lt;strong&gt;训练速度达到原来的 2.4 倍&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这表明，多机并行采集不仅能防止模型对单机特征的过拟合，也证实了在物理世界中，&lt;strong&gt;通过增加设备数量来加速模型进化的 Scaling Law 是真实有效的。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;突破预训练瓶颈：3 小时实战 &amp;gt; 上百小时数据堆砌&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最后一组实验揭示了 SOP 在训练成本上的优势。&lt;/p&gt;&lt;p&gt;团队对比了分别使用 20 小时、80 小时和 160 小时数据预训练的模型。数据显示，虽然预训练规模决定了模型的初始能力，但 SOP 给所有不同基础的模型都带来了稳定的提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNicDtBjria7u5OPfsDq8ibywqYSDvWy4A5F30YdnSMllibCK5kiaBPrYGjdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527015" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/85400766-916b-476b-85c5-87a247c3ad9a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;关键的对比出现在投入产出比上：当预训练数据从 80 小时增加到 160 小时，巨大的算力和数据投入仅带来了 4% 的性能提升，明显的边际效应递减已经出现。然而，在同样的瓶颈期，&lt;strong&gt;SOP 仅用了 3 小时的在轨经验，就换来了约 30% 的性能提升&lt;/strong&gt;。这一数据有力地证明：部署后的在线学习不是对预训练的简单重复，而是更高维度的优化。&lt;/p&gt;&lt;p&gt;但也需要指出，SOP 并非万能药。实验发现，&lt;strong&gt;最终的性能上限依然被预训练模型的初始规模所锚定&lt;/strong&gt;。这表明在线学习本质上是既有知识的超级优化器，而非大规模预训练的完全替代品。&lt;/p&gt;&lt;p&gt;因此，对于追求极致性能的具身智能系统而言，在解决特定长尾问题和弥合「仿真 - 现实」差距时，几小时的真实场景交互，往往比单纯增加几十小时的离线数据更为关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当机器人开始进化&amp;hellip;&amp;hellip;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当我们重新审视 SOP 时，会发现它改变的不仅仅是某一项具体的训练技巧，而是整个通用机器人系统的生命周期。在传统的工业逻辑中，产品交付即意味着研发的终点，但在具身智能时代，这个逻辑正被反转。&lt;/p&gt;&lt;p&gt;智元具身研究中心通过 SOP 传达了一个核心理念：&lt;strong&gt;通用机器人应当是一个在真实运行中持续进化的「生命体」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种范式转变意味着机器人可以带着尚不完美的初始模型上线。对于产业而言，这极大地降低了落地的门槛：我们不再需要等到模型完美无缺才敢让机器人走出实验室，因为&lt;strong&gt;部署就是通往完美之路&lt;/strong&gt;。SOP 能让机器人的每一次任务执行、每一次失败后的纠正都转化为宝贵的训练数据。部署不再是技术迭代的终点，而是更大规模学习的起点。&lt;/p&gt;&lt;p&gt;随着远征、灵犀、精灵、Q1 等机器人走入真实世界，分布式集群的规模将呈指数级增长，我们也将见证一种前所未见的群体智能增长速度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN2rcrNaeTJgtlg47QuWh2UezgCckgT5WQ6zGzfn9c6emiawfe4XrFYdg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.5614285714285714" data-s="300,640" data-type="gif" data-w="700" type="block" data-imgfileid="503527048" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/de4dd2cb-164f-45f6-8e25-3acd8ee38959/640.gif" data-order="5" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;如果说 VLA 模型让机器人第一次具备了通用的理解与行动能力，那么 SOP 所做的是让众多机器人的经验共同驱动智能的快速成长。它让训练不再被锁死在过去的数据集中，而是让机器智能在每一次交互中不断成长。这或许就是通用机器人走向大规模真实世界部署的关键一步。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>独家解读｜2025年AI五大趋势与底层数据革命</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 06 Jan 2026 18:02:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/15c39015-80af-413d-b5bd-01d327a53689/1767693480979.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2025 年，人工智能的发展重心正在发生一次根本性转移：从追求模型的规模，转向构建其理解与解决复杂现实问题的能力。在这一转型中，高质量数据正成为定义 AI 能力的新基石。作为人工智能数据服务的前沿探索者，数据堂深度参与并支撑着这场变革的每一个关键环节。本文将深入解读 2025 年 AI 五大技术趋势及其背后的数据需求变革。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-imgfileid="503526739" data-ratio="0.562037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibjOGZCP2wb1mhrJrYiaZ4KpWlcxlafr8UCjupOXPy5uVWgwfCSYJ1P1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/94c8ea6a-e606-401c-bfa2-57e7e6963912/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势一：多语种 TTS 与全双工交互 &amp;nbsp;「人情味」与「实时性」革命&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势解码：追求更细腻的情感与更自然的实时互动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前，语音合成技术已超越追求「清晰准确」的基础阶段，正同时向两个深度智能化维度演进：一是为合成语音注入情感、个性与文化适配性，让虚拟助手、数字人、有声内容更具感染力和亲和力；二是从单向反应升级为支持实时打断、重叠对话与上下文连贯的全双工自然交互，这已成为高端智能座舱、实时翻译、拟真客服等前沿场景的刚需。技术的核心挑战在于，让 AI 不仅能「读」出文字，更能「理解」语境与情绪，并像真人一样实时聆听、思考与回应，实现有情感、有逻辑的连续对话。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据需求跃迁：从「清晰样本」到「生动语料」与「交互流」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练数据的重心正经历双重跃迁。一方面，需构建服务于音色、韵律、情感和风格精细控制的「表现力语料库」，包括覆盖多语种、多方言、多年龄层的音色基底，以及蕴含欢笑、叹息等副语言特征的语音样本。另一方面，为实现全双工交互，迫切需要多通道、真实、带有自然打断与话题转换的对话语音数据，以及对应的精确文本转录与对话状态标注，以训练模型理解对话逻辑、管理话轮并生成即时、恰当的语音响应。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibvibVOkMA6rv4PCv4ibobxlmNVKexkU1cpSglDt4TiauOibUKgLKghkXzUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562037037037037" data-type="png" data-w="1080" data-imgfileid="503526740" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f00952b8-9ae9-4f9b-99ae-5d43b2d9031e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;为高效赋能下一代语音交互模型，数据堂提供从标准化成品数据集到深度定制服务的完整方案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据堂提供可直接用于模型训练的成熟数据集。&lt;/strong&gt;核心数据资产包括：为高自然度合成准备的 100 万小时多语种自然对话语音数据集与 300 万条前端文本库；为情感合成优化的 2000 小时多情感普通话合成数据集；以及为训练实时交互模型关键的 1 万小时全双工多语种自然对话数据集。这些高质量数据资产，为客户模型的快速启动与效果优化提供了坚实基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依托覆盖全球 200 + 语种及方言的庞大语音资源网络与专业声优库，数据堂能够为各类定制化项目提供强大支持。&lt;/strong&gt;无论是潮汕语、客家语等特定方言，貂蝉、温柔白月光等特定音色与情感，还是多种场景下的全双工对话交互数据，数据堂均可通过专业的采集标注流程进行高效生产，精准匹配客户独特的模型训练与产品落地需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势二：多模态大模型 &amp;nbsp; &amp;nbsp;从「识别」到「认知与推理」的跃迁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势解码：DeepSeek-OCR 引爆多模态认知热潮&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年，以 DeepSeek-OCR 模型的开源为标志性事件，揭示了多模态大模型发展的核心方向：其价值远不止于文字识别的精度提升，更在于推动 AI 从处理单一模态信息，迈向对图像、文本、表格、图表、GUI 界面等多元信息进行统一理解、关联分析与深度推理的新阶段。其目标是让 AI 能像专家一样，解读混合图文的研究报告、理解软件界面的操作逻辑，或根据一份试卷推理解题步骤。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据需求跃迁：跨模态关联与推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统针对单一模态的训练数据已无法满足需求。要训练出具备「认知」能力的多模态模型，数据必须能够刻画不同模态元素之间的复杂关联与深层语义逻辑。这要求数据形态朝着跨模态语义对齐、深度结构化与语义图谱化的方向演进：不仅需要标注图像中的文字、界面元素，更需要建立「图表－总结文字」、「试题－解题步骤」、「图标－操作指令」之间的关联，甚至提供围绕整体任务的推理链条描述。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibNbQwGqlg8ZbcOVO8SolRLLa5bPbKLpGUUtDPLvU1zibOjrD2Wc2zIlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562037037037037" data-type="png" data-w="1080" data-imgfileid="503526741" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6da016cb-5aaf-4c94-8886-f8dfb087b573/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据堂提供覆盖多模态认知全链条的高质量数据，支撑客户模型实现从精准感知到深度理解的全面进阶。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;千万级 OCR 数据、百万级 GUI 界面，多领域专业文档等为模型认知世界提供了丰富的「原材料库」。300 万组涵盖动作、场景、建筑等的图文理解数据，直接助力模型学习「看图说话」与语义推理。而 20 万组 OCR 问答及图像视频编辑数据，则瞄准未来交互范式，训练模型理解指令并执行任务，真正推动 AI 从「看懂」走向「会做」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势三：大模型的深度演进 &amp;nbsp; 推理能力与专业精度的提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势解读：通用思维的「升维」与垂直领域的「深耕」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前大模型的发展呈现出两条清晰且并行的路径：一方面，主流研究持续追求更强大的通用推理与复杂常识能力；另一方面，产业应用落地则驱动模型向金融、法律、生物医药等垂直领域深入，追求高度的专业精度与可靠性。未来的成功模型，必然是强大的通用智能底座与深度领域知识融合的产物。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据需求跃迁：从「规模优先」到「质量与结构驱动」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;高质量训练数据的需求正高度集中于金融、法律、生物医药及科学研究等知识密度高、容错率低的专业领域。其核心已转变为获取能直接赋能模型专业推理与精准判断能力的关键数据资产，主要包括三大类：揭示复杂逻辑链条的「过程型数据」、经领域专家深度校验的「精标知识数据」，以及用于校准专业判断的「对齐与偏好数据」。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaib2PYkZvSSPLzoyVby6LPYf3qofRJl4As5NVFRcib1HvMm5UPYQkiclPSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-imgfileid="503526742" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/0ca45c39-1bdf-4c9b-b8ea-cd716db871e4/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;为应对大模型从通用智能迈向垂直领域深化的双轨需求，数据堂提供从标准化数据产品到深度定制服务的完整解决方案，以高质量数据驱动模型能力的精准进化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于大规模、高质量的成品数据集，数据堂为不同训练阶段的模型提供可直接部署的「标准燃料」。&lt;/strong&gt;包括 5000 万条新闻文本、3 亿条 STEM 试题等为预训练奠基的高质量无监督数据，以及 70 万组指令微调与 150 万条安全内容等为指令对齐提供关键支撑的 SFT 指令微调数据，确保模型获得广泛且专业的知识基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据堂组建了覆盖金融、医疗、法律、教育、电力、稀土工业等十余个领域的超 500 人专家团队&lt;/strong&gt;，所有成员均具备专业资质与大模型项目经验，已成功支持超 100 个大模型数据项目，能够高效交付高准确率、强场景适配的专业数据，助力模型实现从「通用智能」到「领域专家」的精准跃迁。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势四：具身智能 &amp;nbsp; AI 加速从数字世界迈向物理世界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势解码：从「纸上谈兵」到「动手实践」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具身智能成为 2025 年焦点，源于对 AI 本质缺陷的突破：传统大模型在纯数字环境中训练，缺乏物理交互经验，无法建立真实世界的因果认知。人类婴儿通过抓握、推拉等身体交互才能构建物理知觉。同样，机械臂面对杂乱抽屉时，仅靠视觉无法判断「能否伸手进入缝隙」，因为空间可感性取决于材质形变、摩擦系数等连续物理变量，必须通过实时交互感知。赋予 AI 物理载体，已成为突破认知天花板的必然选择。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据需求跃迁：构建物理交互的闭环数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具身智能的核心在于让 AI 通过数据习得物理世界的因果规律，这需要严格对齐时序的高维交互数据，其必须完整融合多视角视频、高精度力 / 触觉传感器流、动作指令序列及最终任务结果，以构成「感知－决策－行动－结果」的完整因果链。&lt;/p&gt;&lt;p&gt;当前，这类高质量数据的获取主要通过真机物理采集、高保真仿真环境生成以及人类行为视频记录等方式实现。然而，真实物理世界的交互数据获取成本极高，往往需要构建专业的采集环境及团队，在严格的安全约束下进行，这导致了能够直接驱动模型进化的高质量数据依然极度稀缺。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibM9Z7lCUZVibBq0uI2dEIpYOohZp3oyFeuDJhNxU7Qz9RV685ZY1bkrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.562037037037037" data-type="png" data-w="1080" data-imgfileid="503526743" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6fc43ea6-74d8-44e2-8569-1a0d54ba1315/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;为高效支持具身智能的研发，&lt;strong&gt;数据堂提供从标准化数据集到深度定制采集的完整服务&lt;/strong&gt;。目前已构建数亿组 3D 环境数据、第一人称任务视频、机器人抓取数据集等在内的完整体系，覆盖从环境理解、决策规划到动作执行的全链路，为模型提供高质量的训练起点。&lt;/p&gt;&lt;p&gt;此外，&lt;strong&gt;数据堂在中、美、日、韩、德等全球布局超过 20 个专业采集场，单个面积最大超 4000 平方米，部署有包括人形机器人&lt;/strong&gt;、机械臂、机械狗在内的 70 余台各品牌机器人，可在家居、工厂、商超等多样场景中，执行物体抓取、导航避障、人机交互等复杂任务。采集过程遵循严格的运动平稳性、操作成功率等质量规范，并同步输出多模态传感器数据。&lt;/p&gt;&lt;p&gt;同时，&lt;strong&gt;数据堂专业标注平台与团队能够完成从感知数据的目标检测、分割，视频分割，任务描述，COT 等全类型标注任务&lt;/strong&gt;，确保数据能直接用于算法迭代。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势五：自动驾驶的技术范式转移 &amp;nbsp; 从模块化到端到端&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;趋势解码：自动驾驶 VLA：从「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-indent: 0px;text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;割裂模块&lt;/span&gt;」到&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-indent: 0px;text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-indent: 0px;text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;统一认知&lt;/span&gt;&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-indent: 0px;text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;2025 年，自动驾驶系统正经历一场深刻的技术范式变革。核心架构正从传统的 「感知－规划－控制」模块化设计，向数据驱动的「端到端」一体化模型演进。这一转变的本质，是将驾驶任务视为一个整体，让单一模型直接从传感器输入（如图像、激光雷达点云）映射到控制输出（如方向盘转角、油门），从而避免了模块化架构中固有的信息损失、误差累积与系统复杂性问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据需求：从「感知信号」到「因果阐释」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;以特斯拉 FSD v12 为代表的经典端到端方法，核心在于获取海量真实驾驶视频与同步车辆控制信号。这类数据需求侧重于对「老司机」驾驶行为的模仿，依赖影子模式积累海量，尤其是覆盖边缘场景的未标注或轻标注数据，本质是以数据驱动的行为克隆。&lt;/p&gt;&lt;p&gt;而新一代的 VLM/VLA 多模态大模型路径则提出了颠覆性需求。其目标不仅是控制车辆，更要让模型具备推理、解释与人机交互能力。因此，训练数据必须实现视觉（图像 / 视频）、语言（指令 / 描述 / 问答）与行动（控制信号）三者在时序上的精细对齐与深度耦合。这催生了对高质量、强逻辑的标注数据的极度依赖，例如为视频中的每个决策匹配「为何如此驾驶」的语言解释，其复杂度和标注成本远超以往。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaiboFV9s12B9xaH9icCVdq5UISrk0iaRx5zwGYJziafDovXmPnyZ7Ih7TLLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-imgfileid="503526744" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/eb00e860-76f6-4bb2-8536-4d372af9a3b6/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;面对端到端驾驶模型对复杂逻辑标注的海量需求，数据堂的解决方案聚焦于专业标注实力与规模化交付的核心优势。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据堂能够对驾驶场景同步执行端到端的精确坐标标注与粗粒度的语义说明标注，并融合场景描述、决策依据、反思过程等深度逻辑，构建「感知－决策」闭环的训练数据对。&lt;/strong&gt;这一高质量产出得益于自研平台集成的预识别接口、自动化工具以及严格的一致性培训体系。&lt;/p&gt;&lt;p&gt;基于高效的标注工具及成熟的流程管理，数据堂具备稳定的规模化标注产能，可高效处理长时序驾驶视频流，其中&lt;strong&gt;车辆路线判断与行驶意图等关键任务的量产交付能力均达到每月 40 万组&lt;/strong&gt;，持续为客户的端到端模型从「行为模仿」到「因果理解」的进化提供可靠数据支撑。&lt;/p&gt;&lt;p&gt;2025 年人工智能的深入发展，其效能瓶颈与差异化优势，将日益取决于高质量、专业化、场景化数据的获取与构建能力。数据堂始终站在这一变革的前沿，从前沿趋势研判，到定制化采集方案设计，再到严格的质控体系，致力于为每一波技术浪潮构建坚实、精准、可扩展的数据基础设施。&lt;/p&gt;&lt;p&gt;欲了解更多数据服务，敬请关注数据堂公众平台：&lt;a href="https://mp.weixin.qq.com/s/IoP38i_T_fv_P94d_kjHFg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/da8e3110-38a7-4dea-afb6-1c1c3243f4a5/1767693459051.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>开源1万小时具身智能数据，这家公司是为了什么？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 06 Jan 2026 17:56:16 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0a984921-a6ba-4869-989d-ea9b3dacbd3b/1767693107422.png" style="width: 700%;" class="fr-fic fr-dib"&gt;想象一下，你正在训练一个未来的家庭机器人。你希望它能像人一样，轻松地叠好一件衬衫，整理杂乱的桌面，甚至系好一双鞋的鞋带。但最大的瓶颈是什么？不是算法，不是硬件，而是数据 &amp;mdash;&amp;mdash; 海量的、来自真实世界的、双手协同的、长程的、多模态的高质量数据。&lt;/p&gt;&lt;p&gt;因此为了整个具身智能探索加速，开源集合成为了大家的共同选择，从谷歌 Open-X Embodiment、智元 AgiBot Digital World，到智源 RoboCOIN 与它石智航的 World In Your Hands，都在试图构建更庞大、更完善的数据集合，并开源给到全行业。&lt;/p&gt;&lt;p&gt;但在 1 月 6 日，有一家公司将这件事做到新高度，进行了超过 1 万小时、接近百万 clips 的具身数据集合开放，这是行业最大规模、也是泛化程度最高的开源数据集合，它就是&lt;strong&gt;简智机器人的 &amp;ldquo;10Kh RealOmni-Open DataSet&amp;rdquo;&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526939" data-ratio="0.5564814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNTznkwlYXgOGMHHTEVtdNnbowDkXzGtCcsAxrWC6LeJ8KrNz36ibXn9g/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d48a5d4e-035f-4ac1-9bbe-442fdaa8651f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;（&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;text-align: left;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;下载地址为：https://huggingface.co/datasets/genrobot2025/10Kh-RealOmin-OpenData，其他数据正在陆续上传。国内也与阿里魔搭、百度百舸合作，方便国内用户下载。&lt;/span&gt;）&lt;/section&gt;&lt;p&gt;&lt;strong&gt;这批数据集合和之前不同点在哪儿？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;总体规模大，这个&lt;strong&gt;体量甚至已经超越很多具身公司自己所储备的数据&lt;/strong&gt;，而在量大的同时，这个数据集合&lt;strong&gt;还期望它更加&amp;ldquo;实用&amp;rdquo;&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;首先需要它具备&lt;strong&gt;足够强的 &amp;ldquo;技能深度&amp;rdquo;&lt;/strong&gt;，在简智开源数据集合中，没有选择去发散的扩充技能数量，而是聚焦在 10 个常见家庭任务集合中，从而对应&lt;strong&gt;每一项技能都有超过 1 万 Clips 规模&lt;/strong&gt;的数据覆盖，这使得其不只是总体规模的最大，也是&lt;strong&gt;单个技能的行业最多&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;质量、模态的要求&lt;/strong&gt;，这决定这些数据是否真正能被模型消化理解，而画面的超大 FOV、清晰的画质是基础，保证可以全方位录制到周围的环境和人的操作细节，&lt;strong&gt;简智这次数据集合的像素达到 &amp;ldquo;1600*1296&amp;rdquo;&amp;ldquo;30fps&amp;rdquo; 的水平&lt;/strong&gt;；&lt;/p&gt;&lt;p&gt;在这之上轨迹的精度是数据质量的关键，厘米级的轨迹精度对人来说可能足够精细，但对于机器人来说则需要达到毫米级别，因此简智这次开源数据对比行业，一方面具备了大多数不具备的轨迹信息，同时通过高精度 IMU 硬件和云端重建与还原，进一步&lt;strong&gt;将轨迹提升到亚厘米级别&lt;/strong&gt;。而在模态上，作为夹抓类的技能采集，夹抓的开合角度、位移也都在集合中包含。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNfRUx8fLdygiaHYLPx3tqNzqQcbiasK3nngEqbaV3etN9hcd3pCliccozw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.7212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526943" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f5822a99-4edb-472c-a277-8692826c14e5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而在技能方面，单手在实际场景中可以完成的任务优先，因此难得是在&lt;strong&gt;数据集中，99.2% 都是 &amp;ldquo;双手、长程任务&amp;rdquo;，这也让它变得更落地&lt;/strong&gt; &amp;mdash;&amp;mdash; 以第一批数据为例，平均 clips 长度为 1min37s。这意味着，它记录的不是一张张静态快照，而是从 &amp;ldquo;拿起散乱 T 恤&amp;rdquo; 到 &amp;ldquo;叠放整齐&amp;rdquo; 的完整过程，是动作逻辑与因果的连续学习。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNaSLXKTYUu2Z4x4ibhCviaqvSrEOtG1EGYY39ibNoENQca5uicOavs4SglQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526944" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/59b02ca8-5e0d-4ad4-b122-23d33d5cce90/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后则是在&lt;strong&gt;相同技能下，数据的场景、目标泛化上需要足够丰富，人员的操作要足够自然&lt;/strong&gt;，而非单一场景的重复、动作僵硬重复，这样才能让模型在真实的生活中，应对家庭环境、目标类型千变万化。&lt;strong&gt;简智这批数据来自 3000 个真实的家庭规模采集&lt;/strong&gt;，以叠衣服为例，不同的衣服种类、平铺的位置等多重因素变量都包含在其中，弥补了传统 &amp;ldquo;数采工厂&amp;rdquo; 方案过于单一的问题。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN4K1iakUDCWIj0MjrpQtGdRtLlfbXNtCnWYFz9wKrL3sm2nWr2eliacgw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.5546296296296296" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526946" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3a755466-72ef-4fd6-a8a3-9a1b5280caa6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为什么有底气开源这么大批量数据？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这些大规模、高质量、泛化程度高数据的背后，其实一套完整的 &amp;ldquo;数据生产链条&amp;rdquo;，在这方面简智也有自己的一套方法论，&lt;strong&gt;完成从采集设备到云端平台，再到数据的二次迭代的闭环&lt;/strong&gt;，这也使得简智在 2 个月时间内就积累了近百万小时规模的数据。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNcPUd9XnCnSX9xnZZ0W9OrLDiaPldA2eMZ048DZJjicsSq0CgDCqNISlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.31666666666666665" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526947" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/66dd8c08-eb62-4ede-9111-2b9bf2b1163c/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这其中，&lt;strong&gt;Gen DAS Gripper &lt;/strong&gt;是能完成简智规模化采集的首要触点，它相比传统的数据采集、UMI 等方案来看，可以&lt;strong&gt;更容易、快速地部署&lt;/strong&gt;，不需要做任何的场地布置；同时&lt;strong&gt;全栈自研的 ISP 图像处理、CMOS 传感器&lt;/strong&gt;，保证图像高质量、清晰。&lt;/p&gt;&lt;p&gt;同时可以做到基于车规级 IMU、双手设备同步，实现&lt;strong&gt;双手技能的高精度坐标对齐，异构数据时间误差小于 1ms&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在设备端，具备超强压缩能力：将&lt;strong&gt;数据体积压缩至原大小的 2%&lt;/strong&gt;，同时打通在线上传通道，实现分钟级快速上传，大幅提升数据流转效率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gen Matrix 则是中枢数据平台&lt;/strong&gt;，它将收集后数据进行高精准的轨迹还原、对齐、清洗处理：将众多分散设备数据收集，&lt;strong&gt;超强轨迹还原、环境重建能力，轨迹真值误差小于 1cm&lt;/strong&gt;，并将异构数据进行同步与清洗，保证数据质量，并具备&lt;strong&gt;自动化标注、切片等进阶能力&lt;/strong&gt;，可以高并发处理海量数据源。这在具身行业也是领先的数据平台基建。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gen ADP（AI Data Pipeline）则是规模化、自动化数据产线&lt;/strong&gt;，它是将 DAS 的数据完成自动化的脉搏。它将标注、加工流程自动化，让高质量数据的产出像流水一样持续、高速，&lt;strong&gt;2h 内完成采集与处理全过程。目前据简智公开信息，已经完成百万小时规模数据累计，并且每天以接近万小时规模增长&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN4Y3BtKU3U9AZVTwIwguE7ItBdo5EqvJAHic0KyAv8xz0l1GhH0bqgLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.46296296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526949" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/661184dd-2153-4835-a707-bcca61dee190/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;开源是一件需要持续做、加速做的事情&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具身智能的未来，建立在高质量数据的基石之上。在今天来看，大家对于数据的格式、规范还尚不成熟，这大大的影响了模型方案的进步速度，因此&lt;strong&gt;开源数据持续、加速推进，能快速填补数据鸿沟、统一技术标准、降低研发门槛、推动生态协同与自主可控&lt;/strong&gt;，最终加速具身智能从实验室走向规模化落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10Kh RealOmni-Open DataSet &lt;/strong&gt;的开放，不仅是一份海量数据资源，更是一种通过共享加速创新的可能性。简智团队后续将继续加强数据基建建设，推出更多行业有益的数据、服务，形成 &amp;ldquo;数据共享 &amp;mdash; 模型优化 &amp;mdash; 场景落地 &amp;mdash; 数据反哺&amp;rdquo; 的正向循环。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>别被室内基准高分骗了：大模型是在推理空间，还是在「背答案」？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 06 Jan 2026 17:50:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;h1&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3403b427-92eb-497d-a537-a99b539597d1/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/h1&gt;&lt;p&gt;2025 年，随着李飞飞等学者将 &amp;ldquo;空间智能&amp;rdquo;（Spatial Intelligence）推向聚光灯下，这一领域迅速成为了大模型竞逐的新高地。通用大模型和各类专家模型纷纷在诸多室内空间推理基准上刷新 SOTA，似乎 AI 在训练中已经更好地读懂了三维空间。&lt;/p&gt;&lt;p&gt;然而，这背后存在着隐忧：由于带有准确 3D 标注数据的稀缺，模型训练所用数据（如 ScanNet++、ARKitScenes）往往与测试基准高度同源。这种数据的 &amp;ldquo;近亲繁殖&amp;rdquo; 让我们不得不担忧：&lt;strong&gt;近期模型分数的飙升，究竟是真正习得了空间几何推理能力，还是仅仅因为 &amp;ldquo;看多了&amp;rdquo; 类似的室内数据分布，从而学会了 &amp;ldquo;背答案&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了回答这个问题，&lt;strong&gt;中国科学院大学机器学习与感知实验室联合微软亚洲研究院以及苏黎世联邦理工大学共同发布了&lt;/strong&gt;全新空间智能基准 &lt;strong&gt;OSI-Bench&lt;/strong&gt;，从数据源头出发，基于自采开放世界中带有准确 3D 标注的视频数据，提供了对空间智能真正诊断的能力。由此出发，该工作重新审视了当前大模型的空间能力是否得到了发展。真正的空间智能鸿沟，或许无法在现有数据范式下仅靠简单的微调来填平。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibwYsVFM0W0tXqyqDVzGtAPIffmQ96zlXemrNzqib1d1OfOC4Bq195K7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.22962962962962963" data-type="png" data-w="1080" data-width="1932" data-height="444" data-imgfileid="503526758" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/85072acf-569d-4c22-a5f8-c76668cf1b99/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：From Indoor to Open World: Revealing the Spatial Reasoning Gap in MLLMs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;作者：Mingrui Wu, Zhaozhi Wang, Fangjinhua Wang, Jiaolong Yang, Marc Pollefeys, Tong Zhang&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.19683&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://mingrui-wu.github.io/osi-bench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;室内场景的局限&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，空间智能的研究大多聚焦于室内场景。这很大程度上受限于源数据集的匮乏 &amp;mdash;&amp;mdash; 少数可用的室外数据集往往基于自动驾驶视角，与第一人称的行人视角存在本质差异。&lt;/p&gt;&lt;p&gt;这种对室内数据的过度依赖，不仅导致了训练集与测试集的高度同源，更因室内场景过强的&lt;strong&gt;语义先验&lt;/strong&gt;难以公平评估模型的空间感知和推理能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNH4fGMdUCbyApE2k2h7jcf1lPmciafcHyer1ZIqyt3ibHNqGZJK0kw9cg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526885" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4e269026-fd61-448b-b60d-cd80d83fe495/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当我们在室内场景提问时（例如：&amp;ldquo;浴缸和马桶之间相距多远？&amp;rdquo;），模型往往能基于 &amp;ldquo;典型浴室布局&amp;rdquo; 的先验知识做出合理推测。即便关闭视觉输入，模型也能仅从语言信息 &amp;ldquo;盲猜&amp;rdquo; 对部分此类问题。&lt;/p&gt;&lt;p&gt;OSI-Bench 选择的室外开放世界的一个核心优势在于其&lt;strong&gt;复杂性与随机性&lt;/strong&gt;。在这种环境下，语义先验变得微弱。面对 &amp;ldquo;告示牌和遮阳篷之间的距离是多远&amp;rdquo; 这样的问题，模型无法再仅凭语义关联获得正确答案，被迫回归到真正的视觉空间推理上来。这种&lt;strong&gt;对先验知识与视觉空间智能的解耦&lt;/strong&gt;，使得 OSI-Bench 可以评估模型的真实空间能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从数据到问答&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OSI-Bench 摒弃了从现有数据集二次提取的路径，完全基于由多传感器平台（双目相机、LiDAR、IMU/GPS）采集的&lt;strong&gt;原始视频流&lt;/strong&gt;。这些数据自带精确的 3D 信息，覆盖了公园、步行街、古建筑、校园等丰富多样的开放世界场景。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibiacWYOVkwp66BE2kHCCFNt8POJoYs3LmU718XbwjnEajniaK7uQSDXXA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3277777777777778" data-type="png" data-w="1080" data-width="2212" data-height="726" data-imgfileid="503526760" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b3e6ca95-825a-42e6-9dc2-8a440334046e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;我们的 Human-in-the-loop 流程从 20 小时的视频素材中生成约 9000 条高质量问答，涵盖 9 种任务。为了系统性评估模型能力，我们将这些任务划分为空间智能的三个层级：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 相对关系&lt;/strong&gt;&amp;nbsp;：针对空间位置的定性判断&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 静态尺度&lt;/strong&gt;&amp;nbsp;：针对静态空间物理量的定量估算&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 动态尺度 &lt;/strong&gt;：引入时间维度的动态物理量估计&lt;/p&gt;&lt;p&gt;&lt;strong&gt;评测结果：我们离空间智能还有多遥远？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 OSI-Bench 上的评测结果表明，当下的开源与闭源 SOTA 多模态大语言模型普遍在这些任务上失败了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN8IeAeNicanWIx1goE1wQ081ED394soLVCVN10WGZeUkU59EKQGCv1pg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7101851851851851" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526886" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7f3562ed-48eb-4905-a2b3-aa2dc8bc8b65/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管 Gemini-2.5-Pro 在一众模型中取得了相对显著的优势，但整体表现仍远低于人类水平。然而，比低分更令人担忧的是，我们目前看到的所谓 &amp;ldquo;空间智能提升&amp;rdquo;，可能只是一场&lt;strong&gt;虚假的繁荣&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNH8jhGMib2lQCvvia130wZIJ99UtEpRcTC4b7GbN3pFxJSRAicKc2LFIrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.19907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526888" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/dc0fee4f-a99e-4060-9f67-0b13edaf6547/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;我们为此研究了在 2025 年发布新版本并报告在 VSI-Bench（室内基准）上取得巨大提升的两个模型家族：Qwen-VL 与 InternVL 系列。&lt;/p&gt;&lt;p&gt;这两个系列在加入更多空间数据训练后，其同尺寸新旧版本在 VSI-Bench 上的得分显著上升了&lt;strong&gt;约 24.1 分，性能几乎翻倍&lt;/strong&gt;。然而，这种惊人的增长并未出现在同样考察空间推理的 OSI-Bench 上。&lt;/p&gt;&lt;p&gt;另外，结果显示，在绝对距离任务上，更新后的各尺寸模型在 VSI-Bench 上一致涨点，却在 OSI-Bench 上一致退步。由于两个基准在这一任务上采用的提问模版完全相同（仅场景不同），这提供了直接的证据：模型在室内基准上的分数提升，本质上是对特定场景分布的过拟合，而非真正习得了可泛化的空间智能。&lt;/p&gt;&lt;p&gt;我们正在经历的这场 &amp;ldquo;空间智能刷点狂潮&amp;rdquo;，或许只是空中楼阁。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语言先验：模型的捷径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当面对空间任务时，相比于费力地进行视觉几何推理，模型更倾向于走 &amp;ldquo;捷径&amp;rdquo;&amp;mdash;&amp;mdash; 利用语言先验知识，基于平均值进行猜测。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibErNKC6GGfp7bdQeMfD0kyfRibrQS1jeDPQ6UzPvUQnZDWialxwsZnLqg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4787037037037037" data-type="png" data-w="1080" data-width="1666" data-height="798" data-imgfileid="503526766" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e927d3bc-7050-4e19-9f10-acd69cd7469a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了量化这一现象，我们设计了两组实验。&lt;/p&gt;&lt;p&gt;盲测实验结果显示，模型在有 / 无视觉输入的情况下的得分差距极小，视觉输入并没有被有效地在推理中使用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNj2IYmg0SeFAAZbZDtS90SIZQy2c57Vk31MIarZib5icSyb2BiaPTsczicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.44074074074074077" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526890" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/8681e8d1-8d77-4d5d-9f0a-f1765549b2bd/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们构建了一组包含 &amp;ldquo;正常场景&amp;rdquo; 与 &amp;ldquo;反常场景&amp;rdquo;（物体尺寸被特意调整至违背常理）的合成数据。人类在面对反常场景时，空间判断力并未受太大影响；而模型在语言先验失效、常理不再适用的情况下，性能出现了断崖式下跌。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNoVMa57mNGHCT5kZ2De5AJ7cPScZocquW8UyicKjy93kdGovFRIfQ19g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.687037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526892" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/24dbe9cf-7497-4a39-8b5f-af139b49ba7f/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OSI-Bench 暴露了现有大模型在空间智能层面与实际应用需求之间的巨大鸿沟，更让我们对当前模型是否真正具备可泛化的空间能力提出了质疑。&lt;/p&gt;&lt;p&gt;我们呼唤一种全新的空间智能范式，相较于 data-driven 的分布拟合，我们需要真正赋予模型在空间中感知、在空间中思考的工具与能力。&lt;/p&gt;&lt;p&gt;OSI-Bench 的基准与评测代码已全部开源。未来，我们将持续开源更多带有高精度 3D 信息的开放世界视频数据，推动空间智能从室内场景走向复杂的开放世界。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>1956-2026：人类与机器智能的七十年对话</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 06 Jan 2026 14:27:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1956年夏天，当约翰&amp;middot;麦卡锡（John McCarthy）、马文&amp;middot;明斯基（Marvin Lee Minsky）等先驱在达特茅斯学院首次提出&amp;ldquo;人工智能&amp;rdquo;这个概念时，他们乐观地预言：十年内机器将具备人类级别的推理能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/42d998f1-b637-414c-9af3-bb37eba164e6/%E5%9B%BE%E7%89%871.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;七十年过去了，这个预言虽未完全实现，但AI的演进轨迹却远比当初设想的更加波澜壮阔&amp;mdash;&amp;mdash;从符号推理的黄金时代到&amp;ldquo;AI寒冬&amp;rdquo;的沉寂，从机器学习的复兴到深度学习的爆发，再到2026年AI全面融入产业基础设施的当下。&lt;/p&gt;&lt;p&gt;这七十年的历史揭示了一个关键规律：AI的每一次突破，都源于思想碰撞、跨界融合与全球协作。1997年深蓝战胜卡斯帕罗夫，标志着暴力计算与精妙算法的混合突破；2010年后深度学习革命的爆发，则得益于大数据、GPU算力与神经网络架构创新的三重汇聚。而站在2026年这个新起点，当生成式AI、AI4S、具身智能等前沿趋势加速涌现，&lt;strong&gt;当国际竞合格局重塑全球创新生态，我们比以往任何时候都更需要一个能够汇聚顶级思想、链接全球资源、激发跨界创新的高浓度平台。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&amp;ldquo;那么，东方为这场持续七十年的对话，按下了哪些关键按钮？&amp;rdquo;答案写在黄浦江畔。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;strong&gt;/&lt;/strong&gt;&lt;strong&gt;七十年的回响：浦江答卷&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上海的AI实践为这场全球对话提供了丰富的东方注脚。&lt;/p&gt;&lt;p&gt;这座城市不仅培育了像MiniMax、阶跃星辰这样的基础大模型先锋，在垂直领域，联影医疗将AI融入医疗影像诊断，松鼠AI打造个性化教育系统，小i机器人深耕政务智能化。&lt;/p&gt;&lt;p&gt;消费级市场则涌现出珞博智能与华为联合打造的&amp;ldquo;智能憨憨&amp;rdquo;情感陪伴硬件，探索人与AI之间超越工具性的&amp;ldquo;养成&amp;rdquo;关系；XREAL与Google合作深耕轻量级AR生态，推动AR设备从显示工具向日常化的空间计算终端演进。&lt;img src="https://image.jiqizhixin.com/uploads/editor/e4eee54c-6585-4ceb-92af-3be1aa417371/%E5%9B%BE%E7%89%872.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;更令人瞩目的是，沪产机器人&amp;ldquo;智元&amp;rdquo;打破了&amp;ldquo;人形机器人行走最远距离&amp;rdquo;的吉尼斯世界纪录，标志着中国在具身智能领域的硬核突破。这些看似分散的创新成果，共同勾勒出上海作为全球AI重要节点的完整生态图景。&lt;/p&gt;&lt;p&gt;然而，在AI这场高度依赖算力、数据与资本的长期竞赛中，任何单一创新节点都面临着资源整合与全球链接的挑战。特别是对于寻求国际化发展的AI企业而言，如何高效对接全球市场、资本与人才，成为必须跨越的门槛。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;strong&gt;/&lt;/strong&gt;&lt;strong&gt;七十年的回响：双城新篇章&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当上海的AI产业积累需要更广阔的国际化舞台时，中国香港以其独特的&amp;ldquo;超级联系人&amp;rdquo;角色进入了视野。&lt;/p&gt;&lt;p&gt;这座城市正在迅速崛起为亚洲AI枢纽，目前已汇聚约500个AI相关组织、290家AI企业及180家投资机构，形成了高密度的创新生态。&lt;/p&gt;&lt;p&gt;香港的优势远不止于数字。其资本市场在2025年以2860亿港元的IPO募资额位居全球第一，成为科技与AI企业上市的首选地之一。与此同时，香港政府宣布投入30亿港元设立人工智能专项资助计划，建设AI研发院与超算中心。&lt;/p&gt;&lt;p&gt;一边是扎实的产业&amp;ldquo;底座&amp;rdquo;，一边是强大的国际&amp;ldquo;接口&amp;rdquo;，两者的历史性握手，只差一个契机。这个契机，随着维多利亚港的海风如期而至。2026年AI领域首场高浓度思想盛宴&lt;strong&gt;&amp;ldquo;WAIC UP!全球年终盛会&amp;rdquo;&lt;/strong&gt;来到香港。这不仅是世界人工智能大会（WAIC）首次在港举办年度会议，更是上海AI产业实践与香港国际枢纽功能的一次历史性握手。&lt;/p&gt;&lt;p&gt;会议汇聚了WAIC旗下五大生态品牌&amp;mdash;&amp;mdash;&lt;strong&gt;创新孵化引擎WAIC Future Tech、产业对接枢纽WAIC CONNECT、思想启迪窗口WAIC UP!、青年科教阵地WAIC Young以及全球合作舞台AI GRAVITY&lt;/strong&gt;。这种多维度、立体化的平台设计，确保了不同背景的参会者都能找到自己的价值定位。&lt;img src="https://image.jiqizhixin.com/uploads/editor/67fb4174-ffff-4618-9006-e159c99e4efe/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;对于上海及内地的AI创业者而言，&lt;strong&gt;这场盛会提供的不仅是展示舞台，更铺设了一张更广阔的全球AI协作网络。&lt;/strong&gt;从港交所的上市通道，到香港投资推广署的落地支持，从科学园的研发设施，到数码港的孵化生态，这些以往需要数月才能打通的环节，如今在一天之内就能建立初步联系。然而，链接资源只是第一步。在范式转换的临界点上，比资源更稀缺的是洞察未来的&amp;ldquo;思想地图&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;strong&gt;/&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;WAIC UP!连接下一个七十年&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;国际级讲者阵容带来的历史纵深与前沿视野&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如今，我们正站在另一个范式转换的临界点：从单模态到多模态，从云端到边缘，从工具到伙伴&amp;hellip;&amp;hellip;这些AI趋势的把握，不能仅靠闭门研发，更需要站在巨人肩膀上的思想启迪。上午场&lt;strong&gt;&amp;ldquo;WAKE思想觉醒&amp;rdquo;&lt;/strong&gt;正是为此而设。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;皮埃罗&amp;middot;斯加鲁菲（Piero Scaruffi）&lt;/strong&gt;，作为硅谷人工智能研究院院长与硅谷精神布道师，见证了从专家系统兴衰到深度学习爆发的完整周期。他对AI演进周期性规律的洞察，将帮助参会者避免重蹈历史覆辙，在泡沫与实质之间保持清醒判断。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;史蒂夫&amp;middot;霍夫曼（Steve Hoffman）&lt;/strong&gt;，作为Founders Space创始人与硅谷创投教父，孵化过数百家AI创业公司。他将分享从实验室到市场的转化密码，揭示哪些技术趋势真正具备商业化潜力&amp;mdash;&amp;mdash;这正是避免1980年代专家系统式&amp;ldquo;虚假繁荣&amp;rdquo;的关键。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;朱晓波&lt;/strong&gt;教授，作为&amp;ldquo;祖冲之号&amp;rdquo;量子计算总师，代表着AI算力革命的下一个前沿。量子计算与AI的结合，可能重现2010年GPU为深度学习带来的颠覆性加速，这是理解未来十年AI发展的战略制高点。&lt;/li&gt;&lt;li&gt;&amp;hellip;&amp;hellip;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如AI历史所示，1997年深蓝的胜利不仅是技术突破，更重塑了人们对&amp;ldquo;智能&amp;rdquo;的理解；2023年ChatGPT的爆发不仅是产品成功，更引发了对AGI路径的全球讨论。这些思想领袖的价值不仅在于传递信息，更在于提供思维框架；参会者将获得的不是碎片化的技术细节，而是构建AI时代世界观的思想基石。&lt;img src="https://image.jiqizhixin.com/uploads/editor/7fee2783-b46d-49c6-932e-2d978070e15d/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;产业全链条的立体化资源网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;低代码/无代码AI平台的普及，使得非技术专家也能构建智能应用。但真正的挑战在于：如何将技术能力转化为产业价值？如何在垂直领域找到AI的最佳应用场景？&lt;strong&gt;下午场&amp;ldquo;UP拓维跃迁&amp;rdquo;&lt;/strong&gt;精准回应这一需求，通过垂直应用案例、商业实战与出海战略的三维透视，构建从技术到商业的完整闭环。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;技术供给侧：&lt;/strong&gt;商汤科技、科大讯飞等头部AI企业展示最新解决方案，从计算机视觉到语音交互，覆盖AI技术的全栈能力。这些企业经历了从研发到规模化部署的完整历程，其经验教训价值千金。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;产业需求侧：&lt;/strong&gt;中国移动国际、神州数码、易鑫集团等传统行业巨头分享数字化转型实践。他们的痛点与需求，正是AI创业者与技术提供商的机遇所在。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;基础设施层：&lt;/strong&gt;算丰等算力提供商、RTE开发者社区等技术生态，构成AI应用的底层支撑。正如深度学习革命依赖GPU算力突破，下一代AI应用同样需要新型基础设施的支撑。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;资本催化剂：&lt;/strong&gt;孚腾资本、Atma Capital等投资机构带来资本视角。他们对赛道的判断、对商业模式的洞察，能够帮助创业者避免方向性错误，加速从0到1的突破。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种产、投、创、研的四维聚合，令参会者可以在一天内完成通常需要数月的生态链接：上午吸收前沿思想，下午对接产业资源，实现从&amp;ldquo;知道&amp;rdquo;到&amp;ldquo;做到&amp;rdquo;的跨越。&lt;img src="https://image.jiqizhixin.com/uploads/editor/8352c942-0222-4b1e-a49e-b44cbe54262b/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI时代的&amp;ldquo;达特茅斯时刻&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;达特茅斯会议的真正价值，不仅在于定义了&amp;ldquo;人工智能&amp;rdquo;这个术语，更在于它创造了一个跨学科思想自由碰撞的场域。数学家、工程师、心理学家、语言学家齐聚一堂，在非正式讨论中激发出影响后世七十年的核心概念。&lt;strong&gt;夜晚场&amp;ldquo;MORE灵感迸发&amp;rdquo;&lt;/strong&gt;正是要重现这种魔力。当正式议程结束，当西装革履卸下，当不同代际、不同领域、不同文化背景的参与者在轻松氛围中交流，往往会产生最意想不到的化学反应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;跨代际对话的独特价值：&lt;/strong&gt;青年科学家带来未被传统范式束缚的新鲜视角；资深专家提供历史纵深与战略判断；初创团队展现颠覆式创新的勇气；企业决策者贡献产业落地的实战智慧。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;跨领域融合的创新源泉：&lt;/strong&gt;夜晚场汇聚的多元群体&amp;mdash;&amp;mdash;从机器人工程师到AGENT开发者，从科技媒体到社区运营者，从BIM国际青年联盟到WAYtoAGI社区&amp;mdash;&amp;mdash;构成了一个思想熔炉。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;历史反复证明，AI的突破往往发生在学科交叉点。一个机器人工程师与一个内容创作者的对话，可能催生下一个爆款AI应用；一个出海企业家与一个国际组织代表的邂逅，可能开启跨境合作的新篇章。这种&amp;ldquo;计划外的收获&amp;rdquo;往往比正式议程更有价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;04&lt;/strong&gt;&lt;strong&gt;/人类与未来的永恒对话&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;以1956年达特茅斯会议正式定名&amp;ldquo;人工智能&amp;rdquo;为起点，AI的发展虽然历程尚短，却以远超预期的速度穿越了一个又一个技术关口，从逻辑推理、统计学习，到今天的大模型与多模态系统，智能以持续涌现的方式重塑着现实世界的运行节奏。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;而愈是演进加速的时刻，愈需要重新思考人的位置。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;算法可以更快，模型可以更大，但人的判断、情感与责任，从未可被替代。在碳基生命与硅基智能在文明进化的路口相遇时，我们亟需重新建立认知框架，回望我们想成为什么样的人类。&lt;/p&gt;&lt;p&gt;站在2026年的起点，我们更能体会这场演进的复杂与惊奇，每一次技术跃迁，像是文明的回响。正是在这样的时代拐点上，WAIC作为全球AI的重要思想交流平台，正持续拓展其&amp;ldquo;科技&amp;times;人文&amp;rdquo;的边界，推动议题，凝聚共识。&lt;img src="https://image.jiqizhixin.com/uploads/editor/402a7b98-5165-42fe-bce1-3bb5eecbaf21/%E5%9B%BE%E7%89%8711.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;无论是思想刊物《WAIC UP!》，还是连接创业者、产业方、政策制定者、青年一代的多维平台，WAIC一直以来都承载着一个宏大的命题：我们愿意与AI共同走向怎样的未来。而即将到来的&amp;ldquo;WAIC UP!全球年终盛会&amp;rdquo;，也将为新一年的探索翻开新的篇章。&lt;/p&gt;&lt;p&gt;回顾这七十年，一个有趣的对比是：1956年的达特茅斯会议只有几十位参与者，而今天的WAIC将连接成千上万的全球头脑。规模的变化背后，是AI从学术课题到文明议题的演进。&lt;/p&gt;&lt;p&gt;我们的使命无比清晰，只要答案未至，步履永远不停。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;即刻锁票，与下一个70年对话&lt;br&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/98786665-43e0-4fd4-934a-c132dbf7ab84/%E5%9B%BE%E7%89%8721.png" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考资料：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[1] AI养成系潮玩受资本追捧，&amp;ldquo;不看好早期具身智能&amp;rdquo;的朱啸虎也出手了，每日经济新闻，202506.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[2] Hong Kong Cements AI Hub Status with 500 Organizations, 23% IPO Surge, and AI-for-Finance Ecosystemic Leadership，香港金融发展局，202511.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[3] 打造香港成全球AI重要枢纽，文汇网，202511.&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
