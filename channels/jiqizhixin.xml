<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>合合信息多模态文本智能产品“上新”，覆盖AI教育、AI健康、AI Infra多元场景</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 10:39:30 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;随着人工智能（AI）产业进入&amp;ldquo;落地为王&amp;rdquo;的新阶段，AI技术与多元化场景的融合成为行业焦点。近期，上海合合信息科技股份有限公司（简称：合合信息，股票代码：688615.SH）集中发布了系列基于多模态大模型的创新产品，覆盖AI教育、AI健康管理、AI Infra（AI&amp;nbsp;基础设施）、AI Agent应用等多个领域，展现了文本智能技术与垂直场景结合的创新潜力，为AI商业化落地提供了新思路。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;解锁文档服务、教育、健康管理&amp;ldquo;AI玩法&amp;rdquo;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;当前，AI大模型发展正从通用能力向行业纵深落地演进，在通用文档处理领域，合合信息旗下产品扫描全能王推出&amp;ldquo;CS-AI一站式智能化文档解决方案&amp;rdquo;，实现从影像数字化向文档全周期智能服务升级。CS-AI覆盖了扫描、阅读、编辑和学习等核心场景，可自动修复图像质量问题，实现智能重排文档、优化排版。据扫描全能王产品团队介绍，依托在文档解析、版面还原上的技术优势，CS-AI预计将在跨境电商、出境游、专业文档翻译等市场中展现强劲的出海潜力。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;strong&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;&lt;img width="453" src="https://image.jiqizhixin.com/uploads/editor/ae17f4cb-a8dc-4b44-b177-b58f8d5cab6f/1768357688399.jpeg" alt="descript" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;color:#7F7F7F;'&gt;图说：扫描全能王&amp;ldquo;CS-AI一站式智能化文档解决方案&amp;rdquo;功能一览&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:justify;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;依托多模态大模型文本智能技术，合合信息将AI能力拓展至教育、健康等垂直场景，将&amp;ldquo;千人千面&amp;rdquo;的体验变为现实。在教育领域，合合信息面向国内及海外市场，推出了AI错题学习管理工具&amp;ldquo;蜜蜂试卷&amp;rdquo;&amp;ldquo;QuizAI&amp;rdquo;，相关产品可智能识别手写体试卷，提供批改及&amp;ldquo;举一反三&amp;rdquo;等互动学习功能，实现个性化的&amp;ldquo;因材施教&amp;rdquo;。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;&lt;img width="453" src="https://image.jiqizhixin.com/uploads/editor/88b11d4d-6690-4921-8ef8-edc5bb60becd/1768357688404.png" alt="descript" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;color:#7F7F7F;'&gt;图说：&amp;ldquo;蜜蜂试卷&amp;rdquo;举一反三功能演示&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;在健康领域，合合信息推出AI饮食健康助手Appediet，用户通过拍照即可识别食物营养成分，生成热量报告。此外，Appediet还可结合用户健康数据定制饮食计划，并提供个性化营养分析报告、健康食谱推荐、定制饮食计划等服务，打造&amp;ldquo;人人可用的&amp;nbsp;AI&amp;nbsp;随身营养师&amp;rdquo;。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;u&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;&lt;img width="453" src="https://image.jiqizhixin.com/uploads/editor/6e9e22e8-7f7f-421b-9cee-bf98c8f5309a/1768357688408.jpeg" alt="descript" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;color:#7F7F7F;'&gt;图说：Appediet拍照识别食物营养成分&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;AI Infra&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;、Agentic AI产品重塑数据处理流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:justify;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;在企业级市场，Agent智能体的规模化落地正将AI Infra推至重要位置，高质量数据成为AI Infra&amp;nbsp;发挥效能的关键。据国际数据公司IDC预测，到2028年全球数据量将增长至393.8ZB，2023至2028年期间复合年均增长率达24.4%。目前，企业数据仍以碎片化、杂格式的形态沉淀在各类业务系统中，既拉低了模型训练效果，也限制了智能应用的落地深度。合合信息旗下智能文本处理企业级AI产品线TextIn发布了AI Infra&amp;nbsp;产品xParse，以AI赋能通用文档非结构化数据挖掘，释放数据价值，在知识库与Agent&amp;nbsp;落地、智能翻译、合规风险管理等场景中具备广阔的应用前景。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;AI&amp;nbsp;&lt;/span&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;与业务的深度融合是企业级智能体落地的方向。麦肯锡11月发布的2025年AI报告《The state of AI in 2025》提到，62%的受访组织（企业）已经在试验智能体类应用。TextIn打造了Agentic AI产品INTSIG Docflow，让产品能够像&amp;ldquo;数字员工&amp;rdquo;一样，对合同、票据、报表、招投标文件等高复杂度、非结构化文档进行解析、分类、抽取、审核、比对及跨系统业务流转，让AI深度作用于企业核心业务流程优化。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;AI&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;原生应用&amp;ldquo;一句话&amp;rdquo;开启商业数据智能新时代&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;本次发布过程中，面向商业数据智能分析领域，合合信息旗下启信慧眼推出了多项AI原生应用，让可信、可靠的数据真正作用于企业风险管控、营销与智能决策。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;例如，&amp;ldquo;AI智能寻源&amp;rdquo;功能用AI自动拆解寻源品类的结构化参数，过滤信息杂质，让客户实现&amp;ldquo;一句话从3.4亿家企业中，找到合作目标&amp;rdquo;的便利，在具体使用场景中，帮助客户寻源拓客效率平均提升超过30%；&amp;ldquo;AI准入尽调&amp;rdquo;功能将行业&amp;ldquo;Know-How&amp;rdquo;与全盘数据相结合，给出&amp;ldquo;靠谱&amp;rdquo;的供应商合作建议；&amp;ldquo;AI关系洞察&amp;rdquo;功能用AI透视隐形风险，智能锁定关键风险，降低决策门槛及业务风险。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;据悉，启信慧眼AI原生应用功能已在制造、医药、半导体、电子、能源、汽车、金融等多个行业中应用，日均风险扫描次数超过2000万次。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;未来，AI技术正向着多模态融合、Agent 智能体规模化的方向加速突破。合合信息将持续深耕AI领域，推进多模态文本智能技术研发工作，不断拓宽技术的应用边界，探索AI应用落地的新机遇、商业化增长的新路径。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>500万次围观，1X把「世界模型」真正用在了机器人NEO身上</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 10:21:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2ca205b5-ae1a-4076-816f-d2a6662ac99e/1768357071298.png" style="width: 700%;" class="fr-fic fr-dib"&gt;还记得那个穿着「Lululemon」紧身衣、主打温柔陪伴的&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650998749&amp;idx=1&amp;sn=614264e1d1fefcf5aa9064932a79c60c&amp;scene=21#wechat_redirect" target="_blank"&gt;家用人形机器人 NEO&lt;/a&gt; 吗？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsatpLSPbFMFhk1mPymfGavtaXQuF13ict3WO3icUAyVK0jKyTAythhryzg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5370370370370371" data-type="png" data-w="1080" data-width="1080" data-height="580" data-imgfileid="503528121" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5ad2d686-a48d-4e0d-8ab6-37c71a4477ca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="5"&gt;上次聊到它时，大家还在吐槽其「远程操控」的隐私安全问题，调侃每个机器人的背后可能都是一个「印度小哥」。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;昨天，1X 公司带着它的全新「大脑」亮相：&lt;strong&gt;1X World Model&lt;/strong&gt;。这一次，NEO 似乎准备把「背后的操作员」给解放了。&lt;a href="https://mp.weixin.qq.com/s/xFODYAk17WiRBp6eGAvRAw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/37768424-3a57-4d30-9a44-a106dd3f9f50/1768357095646.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;简单来说，现在的 NEO 不再只是死记硬背动作，它学会了像人一样「想象」。通过观看海量的网络视频和人类第一视角的实操录像，它理解了物理世界是如何运作的：东西掉了会下落，门是可以推开的。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;他们把类似 Sora 的视频生成技术装进了 NEO 的脑子里，接到指令时，它会先在脑海里生成一段「自己成功完成任务」的视频，然后倒推身体该怎么动，才能把这段想象变成现实。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;不过，官方博客中也表示，有时候会出现「脑子学会了，手没学会」的情况：脑补出的视频很完美，但实际动作可能会抓空。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaf7a9oUFeR0CEuYKFmOYuWxoHOCZLvAibsM2eu3fRwwrAuWmeYicS3EJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5131428571428571" data-type="png" data-w="875" data-width="875" data-height="449" data-imgfileid="503528122" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/de697d30-2f65-45ec-be50-1ad198edc117/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="11"&gt;那么这一次是「瑜伽服」下的真功夫，还是只存在于 Demo 里的「剪辑魔法」呢？不管技术落没落地，热度已经先爆表了。到截稿时间，官方推文浏览量已突破 500 万。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicITJN4FJYabK6gOKndKpt006gbgLSvL4KYRrMAiaYr9oGHpbas77Zr7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0608108108108107" data-s="300,640" data-type="png" data-w="740" type="block" data-imgfileid="503528182" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/eb5b879a-0143-40e0-8da5-74ed129cbd88/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;看来，在经历了 AI 时代各式各样炫酷 Demo 的轮番轰炸之后，大家还是忍不住想看看：这一回，它是真长脑子了吗？&lt;/p&gt;&lt;p data-path-to-node="13"&gt;以下是 1X 技术团队对这颗「新大脑」的硬核拆解：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaq8Rsh8BzlibYAU8eJs157EEnpZq89wwVT4GLReYrFNibPzpzjQGAwnqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528123" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/bebd967b-78aa-4a57-8904-08792475dfe2/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="14"&gt;家庭机器人要真正走进现实环境，必须具备常识性的行为能力以及对物理世界的深刻理解。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;当前许多机器人基础模型采用的是 VLA 范式：即在一个预训练的 VLM 之上，增加一个用于预测机器人动作的输出头（例如 PI0.6、Helix、Groot N1.5）。VLM 能够从互联网规模的数据中学习到丰富的知识，但其训练目标更侧重于视觉与语义理解，而非对物理动态过程的预测。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;因此，即便是对人类而言非常简单的任务，模型往往也需要数万小时、成本高昂的机器人数据才能学会完成。此外，为了进一步强化模型对物理交互中空间关系的理解，研究者通常还需要引入各种辅助训练目标（如 MolmoAct、Gemini-Robotics 1.5）。&lt;/p&gt;&lt;p data-path-to-node="17"&gt;在这篇博客中，1X 介绍了&lt;strong&gt;基于视频预训练的世界模型&amp;mdash;&amp;mdash;1XWM&lt;/strong&gt;，并将其集成进 NEO 机器人作为其控制策略。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;与 VLA 模型直接从静态的图像-语言输入中预测动作轨迹不同，世界模型驱动策略是通过文本条件下的视频生成来推导机器人应采取的动作。&lt;strong&gt;借助互联网规模视频中蕴含的真实世界动力学规律，该世界模型能够在无需大规模机器人数据预训练&lt;/strong&gt;、也不依赖任何相关的遥操作演示的情况下，即可泛化到全新的物体、运动方式和任务场景。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;这标志着机器人智能范式的一次转变：机器人开始直接受益于视频预训练规模化带来的能力跃迁，而这一切得以实现，离不开一整套为高保真人类具身到机器人具身迁移而设计的硬件系统支持。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsas2yRupVm3tXjHzYhRH61JZGfCGAgYicD1iaMTKVRsblZzWLQY7YrfKpw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.471875" data-type="gif" data-w="640" data-width="856" data-height="404" data-imgfileid="503528126" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e0845a64-4ac4-436a-9fec-4b2f3accf32f/640.gif" data-order="0" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;&lt;strong&gt;从视频知识到世界模型&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;如今，诸如 Veo 和 Sora 等前沿文生视频模型已经能够生成极其逼真的视频内容。然而，这些模型在零样本生成场景下并未与机器人具身形态对齐，因而在控制任务所需的多个关键维度上往往存在不足，表现在以下几个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="22,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="22,0,0"&gt;视觉/空间层面&lt;/b&gt;：生成的视频是否与机器人的相机内参和自我中心视角一致？是否能够准确保留操控任务所需的深度信息以及精确的空间关系？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="22,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="22,1,0"&gt;运动学层面&lt;/b&gt;：生成视频中的机器人动作是否在该具身形态下可实现，是否遵循其结构特性、关节极限、速度约束以及执行器能力？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="22,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="22,2,0"&gt;物理层面&lt;/b&gt;：生成过程是否避免了物理上不可能的结果（例如物体瞬移），从而保证其能够转化为现实世界中的成功执行？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="23"&gt;原始视频能够提供看起来会发生什么，但并未给出如何去做。为了将视频知识转化为真正可用于控制的世界模型，1X 借助自身的端到端系统架构，采用了一种两阶段的对齐过程，思路与 DreamGen、UniPi 等已有工作一脉相承：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,0,0"&gt;世界模型主干&lt;/b&gt;：这是一个文本条件扩散模型：先在互联网规模的视频数据上进行预训练，随后在人类第一视角视频数据上进行中期训练，并最终在 NEO 专属的传感器-运动日志上进行微调。该模型能够高保真地预测场景随时间演化的过程，在视觉、空间和物理一致性方面表现出色。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,1,0"&gt;逆动力学模型（Inverse Dynamics Model, IDM）&lt;/b&gt;：通过训练 IDM，将像素空间与执行器控制连接起来，使其能够预测在生成帧之间完成状态转移所需的精确动作序列。同时利用 IDM 的评估指标和拒绝采样机制，对生成结果施加运动学约束，从而确保动作在具身层面上的可行性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;在推理阶段，系统接收一个文本指令和一帧初始画面：世界模型负责生成符合意图的未来场景演化，逆动力学模型从中提取所需的动作轨迹，最终由机器人在现实世界中执行该动作序列。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsaMhBkAehic28chZuNGv2w5yWf04AU57HzQwR0tBsf9L2J2Sg7LJRic5Vw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.601113172541744" data-type="gif" data-w="1078" data-width="1308" data-height="786" data-imgfileid="503528127" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/af6d2e10-ff22-4b21-a7ef-95f5f24abd07/640.gif" data-order="1" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="26"&gt;&lt;strong&gt;1XWM 的训练与推理流程&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;1XWM 的主干模型基于一个 140 亿参数的生成式视频模型。为了使该模型适配 NEO 的具身形态，1X 还采用了一种多阶段训练策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="28,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,0,0"&gt;第一视角中期训练&lt;/b&gt;：使用 900 小时的人类第一视角视频数据进行训练，使模型对第一人称的操作任务产生对齐。在这一阶段，模型能够学习到通用的操作行为模式，但仍然难以生成由 NEO 执行具体任务的视频。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="28,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,1,0"&gt;具身微调&lt;/b&gt;：随后，使用 70 小时的机器人数据进行微调，使模型进一步适配 NEO 的视觉外观与运动学特性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="29"&gt;以 DALL&amp;middot;E 3 等工作为例，已有研究表明，通过使用更具描述性的视觉文本标注进行训练，可以显著提升视觉基础模型对提示词的遵循能力。然而，许多第一视角数据集仅包含简要的任务描述。为此，1X 利用一个 VLM 生成更加详细的描述性字幕，并通过字幕上采样的方式将其用于训练。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;此外，IDM 在 400 小时未经过滤的机器人数据上进行训练，其中既包括随机探索数据，也包含与任何具体任务无关的运动轨迹。这使得模型能够在任意状态下对 NEO 的运动进行准确追踪。&lt;/p&gt;&lt;p data-path-to-node="31"&gt;在测试阶段，系统接收一帧初始画面以及一条指导 NEO 执行动作的文本指令。1XWM 负责生成未来的视频序列，随后由 IDM 从生成视频中提取对应的机器人动作轨迹，并将其直接下发至机器人执行。为保证轨迹的平滑性，IDM 的输出会在多个初始噪声样本和滑动窗口维度上进行时间平均处理。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="762" data-imgfileid="503528128" data-ratio="0.8581081081081081" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaib3yZY9Ac0QOfp2hn9lDibeE4CdK1RV5jsW1cVT1ArwkE7Sl3osla8EA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="888" data-width="888" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6d2d90f7-ac16-44cb-acce-63667c5fff69/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="32"&gt;&lt;sup&gt;NEO 后训练数据集主要包含高质量的抓取和放置数据（98.5%），这些数据经过筛选，仅包含桌面操作且手部可见的场景。通过利用基础视频模型的网络级预训练，1XWM 模型可以泛化到各种未曾见过的物体、环境和任务。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;1XWM 到底能做啥&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;研究团队进一步评估了 1XWM 在任务泛化方面的能力，重点关注其是否能够完成 NEO 从未经历过的任务，以及生成视频与真实机器人执行之间的一致性程度。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;在实验中，搭载 1XWM 的 NEO 被用于执行多种超出既有经验的任务，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="36,0,0"&gt;抓取分布内与分布外的物体；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="36,1,0"&gt;操作此前从未见过、但具备复杂可供性的物体；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="36,2,0"&gt;完成需要全新动作模式的全新任务。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="37"&gt;实验结果显示，1XWM 生成的视频与真实世界中的执行过程整体高度一致。将模型生成的视频与机器人实际完成任务后拍摄的视频进行并排对比，可以发现二者在视觉表现上非常接近。这表明，1XWM 在空间结构理解、运动学约束建模以及物理一致性等方面已经具备较强能力。&lt;/p&gt;&lt;p data-path-to-node="38"&gt;&lt;b data-index-in-node="0" data-path-to-node="38"&gt;抓取：&lt;/b&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsafY224WBthhF7ib31QibGcA1tFgElWcX5dc6273YSjnOq2o7YNLwpmGXA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.4638888888888889" data-type="gif" data-w="1080" data-width="1940" data-height="900" data-imgfileid="503528130" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/e5cb3ca5-442b-4b2f-a0f2-7412febd73c1/640.gif" data-order="2" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="40"&gt;&lt;b data-index-in-node="0" data-path-to-node="40"&gt;新动作：清洁&lt;/b&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsa22x4nb6hjMJTejzGHEcwgD4YaadFAzsnocadLNeOMBUtJkOcxRozmQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.45597775718257644" data-type="gif" data-w="1079" data-width="1969" data-height="898" data-imgfileid="503528135" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/f1f201de-9aac-4c0d-a449-b2a71610f28f/640.gif" data-order="3" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="41"&gt;接下来，1X 尝试需要双手协调和人机交互的任务。这些能力并未包含在训练数据集中。这表明此类知识来源于视频预训练和以第一人称视角进行的人机交互训练。由于 NEO 的身体结构与人类非常相似，因此从人类视频数据中学习到的功能可以直接迁移应用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYYnDJJkJKh7NDwtc0YFt5eYa2GzkqfuW56GFbWGAbkVHJW0kiaYmorg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.45918367346938777" data-type="gif" data-w="1078" data-width="1962" data-height="901" data-imgfileid="503528131" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/43436d0f-edf7-4d4a-9cdc-ccd913d74eac/640.gif" data-order="4" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsaSQ288DgkjS2iby24QasMBgIXiawOGc8IicK3plibqe5ocqhodrto48w1CQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.48148148148148145" data-type="gif" data-w="1080" data-width="1960" data-height="944" data-imgfileid="503528132" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/6d648529-e593-4d86-b9e1-0df382800019/640.gif" data-order="5" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="42"&gt;研究团队还通过系统性的实物实验评估了 1XWM 在分布内（ID）与分布外（OOD）任务上的表现。每类任务均重复执行 30 次。结果显示，1XWM 在多种动作原语上都保持了稳定的成功率，不过部分对精细操作要求较高的任务（例如倒液体、绘图等）仍然具有一定挑战性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaQVdr2nABydOqc8NFARHQC6qAxPCiaLHflKEaDBbVI00Y2DtzCxv7Pbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.7564814814814815" data-type="png" data-w="1080" data-width="1110" data-height="840" data-imgfileid="503528129" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/2074235c-49ce-43c7-86ed-f223825b8404/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="43"&gt;&lt;strong&gt;能否将视频质量与任务成功率联系起来？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="44"&gt;如果可以，就能使用视觉指标来衡量和改进视频质量，并估计实际任务成功的可能性。&lt;/p&gt;&lt;p data-path-to-node="45"&gt;有时，生成的视频是否可能成功一目了然。例如，向 1XWM 模型输入拉取纸巾指令，有时会生成 NEO 机器人拿起纸巾盒而不是拉取纸巾的视频。执行这些错误生成的视频时，成功率几乎为 0%。&lt;/p&gt;&lt;p data-path-to-node="46"&gt;1X 团队注意到像测试时计算这样的方法可以提高任务成功率。受此启发，他们尝试并行生成多个视频，并执行其中质量最好的一个。这个选择过程可以手动完成，但也可以使用 VLM 评估器进行自动化。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaPbzzTlESRQWNhS2tMqc0fSglRFyomKKf2NhMicasSDtrRicGoKYqyfdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4975417895771878" data-type="png" data-w="1017" data-width="1017" data-height="506" data-imgfileid="503528133" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/ac78d71a-cead-4263-b3ed-8e1a5dea1eea/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="47"&gt;&lt;strong&gt;第一视角数据与高质量字幕的重要性&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="48"&gt;基于此前假设：生成视频的质量与任务成功率之间存在相关性，研究团队对若干训练选择进行了视觉层面的消融分析，重点考察了字幕上采样以及第一视角人类数据训练这两项因素的影响。&lt;/p&gt;&lt;p data-path-to-node="49"&gt;实验共使用了三个评测数据集，每个数据集均包含 500 组起始图像&amp;ndash;提示词对：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="50,0,0"&gt;分布内数据集：包含与机器人训练数据分布一致的复杂任务和场景，主要是杂乱环境中、物体位置较为困难的抓取与放置任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="50,1,0"&gt;新任务数据集：由一组全新的任务构成，例如搅拌碗、抽纸、相对尺寸判断（选择更大的物体）、双手协同操作等，数据采集于真实世界中的简单背景场景。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="50,2,0"&gt;分布外 T2I（OOD T2I）数据集：完全由抓取任务组成，其初始帧由文生图模型生成，随机采样分布外的家庭物体与背景场景。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="51"&gt;下面是新任务数据示例：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsazTYicyQF0bJNVg1hmKwkG61ewIqIZwSib10nNE902O03WzzLRl8g3x2A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-ratio="0.98125" data-type="gif" data-w="640" data-width="1031" data-height="1012" data-imgfileid="503528136" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/f1fe4ef0-d2d4-4dc1-93d9-72e8b73f2e9f/640.gif" data-order="6" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="52"&gt;团队还要求人工标注员审查每个生成的视频，并根据物理合理性、任务完成情况以及与 NEO 的形态和能力的一致性来决定接受或拒绝该视频。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsacAUthpib2lSZjeCp9wrkDRqRydmpUXC4HXkzYg4dKBPQznhYh8UwxKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.9635258358662614" data-type="png" data-w="987" data-width="987" data-height="951" data-imgfileid="503528134" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/bdcad60d-e62e-4270-9687-149f30e01b82/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="53"&gt;字幕上采样在所有评测数据集上都能提升视频生成质量，因为更细致的字幕与视频模型预训练时的文本条件更加匹配，也能更清晰地引导具体动作生成。&lt;/p&gt;&lt;p data-path-to-node="54"&gt;引入第一视角人类数据则显著提升了新任务和分布外场景下的生成质量，说明这类数据为操作任务提供了可迁移的通用先验，且与 NEO 的类人具身高度契合。&lt;/p&gt;&lt;p data-path-to-node="55"&gt;不过，在已有大量 NEO 数据覆盖的分布内任务上，额外加入第一视角数据可能会稀释后训练数据分布，对效果提升有限，甚至略有负面影响。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaboLTUMOAHxQFQBNV3xaLhBbG25CaNLxfdrQfPPxFQqFqDXNWATEKog/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.9522388059701492" data-type="png" data-w="1005" data-width="1005" data-height="957" data-imgfileid="503528137" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/d3683309-b9b9-46e9-9344-2529cb08d941/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="56"&gt;&lt;sup&gt;参考链接：https://www.1x.tech/discover/world-model-self-learning&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>跳出「黑盒」，人大刘勇团队最新大语言模型理论与机理综述</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 10:15:03 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/fcad1371-16af-44c3-ba7e-77b0e1e3b8c4/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大语言模型（LLMs）的爆发式增长引领了人工智能领域的范式转移，取得了巨大的工程成功。然而，一个关键的悖论依然存在：尽管 LLMs 在实践中表现卓越，但其理论研究仍处于起步阶段，导致这些系统在很大程度上被视为难以捉摸的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;黑盒」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;为了打破这一僵局，中国人民大学的研究者们采用了一种统一的基于生命周期的分类法，将 LLM 理论研究整合为六个阶段：数据准备、模型准备、训练、对齐、推理和评估。&lt;/p&gt;&lt;p&gt;本文系统综述了驱动 LLM 性能的底层理论与机制，深入分析了数据混合的数学依据、不同架构的表示极限以及对齐算法的优化动力学，并指出了合成数据自我提升、安全保证数学边界等前沿挑战。本综述旨在为 LLM 发展从工程启发式方法向严谨科学学科的转型提供结构化路线图。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528001" data-ratio="0.4101851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYqTX4hmbt5zlBSnkz24BJG7c8z8ttRMia5YQicTGmguA7Dwbbq0Rckcw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1de12a9e-107d-4b6b-833e-0564a13fe841/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Beyond the Black Box: Theory and Mechanism of Large Language Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.02907&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，ChatGPT、DeepSeek、Llama、Claude 等模型的涌现标志着 AI 领域的深刻变革。随着系统规模的扩大，LLMs 展现出类似人类推理的行为，正改变着人类与信息交互的方式。然而，正如核物理的发展经历了从爱因斯坦的质能方程到原子弹爆炸的 40 年跨度，AI 领域的理论与应用同步也存在显著滞后。&lt;/p&gt;&lt;p&gt;尽管工程上取得了巨大成功，LLM 的理论理解仍面临两大挑战：一是规模带来的前所未有的数学复杂度；二是模型展现出的诸多「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;涌现」现象（如幻觉、涌现能力、Scaling Laws 等）难以在统一框架下解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;为了解决研究碎片化的问题，来自&lt;strong&gt;中国人民大学高瓴人工智能学院&lt;/strong&gt;的研究团队发布了最新综述论文 《Beyond the Black Box: Theory and Mechanism of Large Language Models》。本文不仅是一份文献索引，更是一份试图将 LLM 研究从 「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;工程启发式」推向「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;严谨科学」的路线图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;本综述提出了涵盖六大阶段的生命周期路线图。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528022" data-ratio="0.42592592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkARHFgibQFgkMWGO8GofIh3R98Grh5ib6zMwicDNRtm6Sk5SActLYNaRiaNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/42f8b15b-df44-4b02-bd3b-43e99ce14f31/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 1: 大语言模型理论与机制路线图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LLM 理论与机制的六大阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据准备阶段 (Data Preparation)&lt;/strong&gt;：探讨如何保证更好的数据利用率，并量化数据特征对模型最终能力的影响，分析数据混合策略 (Data Mixture)、去重与过滤机制以及记忆 (Memorization) 与模型能力之间的关系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型准备阶段 (Model Preparation)&lt;/strong&gt;：从理论上评估架构能力，理解 Transformer 结构的表示能力极限、优化景观（如「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;河谷」假设）以及从展开优化视角设计新架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练阶段 (Training)&lt;/strong&gt;：研究简单的学习目标如何锻造出复杂的涌现能力，分析 Scaling Laws 的本质、预训练的获益机制以及参数高效微调（PEFT，如 LoRA）的机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对齐阶段 (Alignment)&lt;/strong&gt;：探讨鲁棒对齐是否在数学上可实现，分析 RLHF（的动力学，研究「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;超级对齐」（Superalignment）与「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;弱到强泛化」 (Weak-to-Strong Generalization)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理阶段 (Inference)&lt;/strong&gt;：解密冻结权重的模型如何在测试时模拟学习与算法执行，分析提示工程 (Prompt Engineering)、上下文学习 (In-Context Learning) 的机制以及推理时扩展 (Inference-Time Scaling) 带来的推理能力提升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;评估阶段 (Evaluation)&lt;/strong&gt;：从理论上定义与衡量复杂的、主观的人类价值观，探讨基准测试的有效性、LLM-as-a-Judge 的可靠性以及安全性与透明度的形式化保证。&lt;/p&gt;&lt;p&gt;各个阶段代表性的研究内容如下所述。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1 数据准备阶段：智能的基础&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528023" data-ratio="0.5305555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVRv5OkJcmuvXfaPduNl6kpBVsUwz2fhHFzVdjskkJbbsjgpQV65IAQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5b9c431e-ba85-415b-ba2e-63250e25f909/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 2: 数据准备阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;数据准备不仅仅是工程上的设计，而是决定模型能力的基石。研究者们从三个维度剖析了数据的理论机制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据混合的数学逻辑&lt;/strong&gt;：研究者利用多源学习视角，证明了当多任务结构共享时，泛化界限不再取决于模型海量的原始参数，而是取决于总压缩编码长度。通过引入「数据混合定律」（Data Mixing Laws），小规模实验拟合验证损失函数，实现对大规模混合策略性能的预先计算。最终，研究者们使用各种不同的理论框架，动态寻找最优数据混合权重的前沿方法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;去重与过滤的理论保障&lt;/strong&gt;：实证研究确认了去重能直接减少不必要的记忆，从而降低隐私风险。各种理论框架证明了高质量、高信息密度的网页数据甚至能超越人工精选语料。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;记忆机制的量化分析&lt;/strong&gt;：模型对数据的记忆并非简单的「死记硬背」。理解这种记忆机制是平衡知识获取与隐私保护的关键。研究者们认为模型通过整合模糊重复序列形成复杂记忆，也揭示了熵与记忆之间的相关性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，这一阶段也存在着重要的前沿开放问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;合成数据与自主进化&lt;/strong&gt;：合成数据能否为模型带来理论上的性能提升？模型是否能够通过生成合成数据从而实现自主进化？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据污染&lt;/strong&gt;：训练与测试数据的泄漏为 LLM 的隐私问题带来了挑战，能否从理论上规避或者缓解这一问题？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2 模型准备阶段：架构的表示极限&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528024" data-ratio="0.5222222222222223" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8Fz5ibfwBpfhF8PqU3NPmwAJI05zqnDMVK9rzJh8qTypdibagHvorINA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/330195d7-19e2-4814-b21a-5899d9d61c59/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 3: 模型准备阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;选择何种模型架构不仅关乎效率，更决定了信息的表示上限。研究者们通过以下视角探讨了架构的本质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;表示能力的边界&lt;/strong&gt;：研究者们探讨了 Transformer 作为通用逼近器的数学证明，并分析了在无限精度下 Transformer 的图灵完备性。通过电路复杂度（Circuit Complexity）理论，研究者分析了 Transformer 等架构在处理层级结构语言时的表达上限与下限，揭示了模型宽度如何成为函数组合能力的通信瓶颈。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;优化景观的几何特性&lt;/strong&gt;：研究者们提出了诸如「河谷（River Valley）模型」等假设，解释了 Warmup-Stable-Decay 类学习率调度如何引导参数在复杂的函数空间中跨越「山坡」并在「河床」方向高效前进。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;理论驱动的架构设计&lt;/strong&gt;：从「展开优化（Unrolled Optimization）」和「测试时训练（TTT）」的视角，研究者将网络层等效为优化算法的迭代步骤，为理解前沿的模型架构提供了统一框架。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除此之外，研究者们也在关注模型架构的演进，并从理论视角对新架构进行设计与分析：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;线性注意力模型&lt;/strong&gt;：线性递归模型在提升效率的同时，是否存在无法逾越的表示瓶颈（如关联回想能力的缺失）？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;循环模型与隐式推理&lt;/strong&gt;：权重共享的循环架构是否能通过增加推断深度，在更少的参数量下实现更强的泛化？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3 训练阶段：模型能力的锻造炉&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528025" data-ratio="0.5175925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAnIIoVWtAGibmPdST5yPqpKup4hllCYaic5w7zIFA35LmyN09icwhLKVcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/589c5a18-4c2c-4adc-9b69-2d1ff28cf0ab/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 4: 训练阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;训练阶段将静态架构转化为具备智能的实体。研究者们对预训练和微调的机制进行了深入解构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;预训练的收益机制&lt;/strong&gt;：研究者论证了预训练本质上是学习数据的底层上下文结构，并提出了「压缩即智能」的观点，认为语言模型的目标是实现对海量数据的无损压缩。从信息论视角出发，论证了 LLM 作为强大的无损压缩器，其压缩效率与下游任务性能之间存在强线性关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Scaling Laws 的本质&lt;/strong&gt;：通过对计算、数据和参数规模的幂律关系分析，研究者探讨了能力「涌现」背后的连续性过程，并分析了流形假设下内在维度如何决定缩放指数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;微调的数学保障&lt;/strong&gt;：针对 LoRA 等 PEFT 技术，研究者分析了其在低秩子空间中的优化动力学，证明了低秩适配器在对齐预训练特征梯度方面的有效性，并揭示了权重初始化（如 A 随机、B 置零）对收敛稳定性的关键影响。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，这一阶段也存在着优化层面的前沿探索：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;超参数迁移&lt;/strong&gt;：如何实现在小规模模型上寻找的最优超参数，能够「零样本」地直接应用于万亿级模型？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;优化算法的演进&lt;/strong&gt;：除了 Adam 等一阶优化器，矩阵敏感型优化器（如 Muon）如何利用 Hessian 结构的块对角特性加速收敛？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;4 对齐阶段：安全与价值的数学边界&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528027" data-ratio="0.5212962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAXJvycGnbBgvJlzFgaLFSk9Ve5aG6QT1iaiaGX84EgsNGlpGFgpxkQKQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3ac70102-6f95-40a1-bc36-8d26823f78a5/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;图表 5: 对齐阶段的理论概览。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对齐不仅是指令遵循，更是人类价值观的注入。研究者们从安全性与动力学视角进行了审视：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;对齐的理论基础&lt;/strong&gt;：研究者分析了安全对齐的数学边界，探讨了现有对齐方法是否只是「浅层防御」，以及对齐后的模型是否存在回复原始分布的「弹性」。研究者认为只要有害行为的概率不被完全消除，通过对抗性提示触发违规行为在数学上是不可避免的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;弱到强泛化（W2SG）&lt;/strong&gt;：在超智能时代，弱监督者如何可靠地控制强受训者？研究者从偏差 - 方差分解等视角，分析了强模型纠正弱信号错误的机制，并界定了泛化增益。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;强化学习的作用&lt;/strong&gt;：研究者探讨了 RL 是激活了预训练中的潜在模式（如代码能力、数学推理能力），还是通过长期的策略复位真正扩张了推理边界。同时量化了对齐与预训练知识保持之间的权衡，并从变分信息瓶颈视角提出了缓解「Reward Hacking」的方法。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，对齐阶段还面临着深层次的开放挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练与对齐的关系&lt;/strong&gt;：SFT 和 RL 在塑造模型行为上有何本质区别？为什么 RL 在泛化性上通常优于简单的行为克隆？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;RL 的前沿疆界&lt;/strong&gt;：在缺乏验证器的开放领域，如何设计高效的奖励信号？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;5 推理阶段：解密静态模型的前向过程&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528029" data-ratio="0.5203703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMh6lNNOaVvLJibh5KDOicZqRic5oMoxctGyiaWNfVLPFibbgRfRcJvia1uVw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3518a42f-7090-4137-8eed-25f18b8839d3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 6: 推理阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;推理是释放模型潜力的关键环节。研究者们解密了大模型推理中的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;思维」过程：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;提示工程与机制分析&lt;/strong&gt;：研究者从任务重参数化角度理解 Prompt，利用 Token 分布动力学和归纳头（Induction Heads）机制，剖析了 Prompt 如何引导模型内部的信息路由。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;上下文学习（ICL）的机制&lt;/strong&gt;：研究者对比了「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;算法执行」与「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;任务定位」两种观点，探讨了 Transformer 是否在推断时隐式地运行了优化算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;推理时扩展（Inference-Time Scaling）&lt;/strong&gt;：研究者分析了 CoT 如何作为模型的 「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;深度扩展器」，证明思维链能显著提升 Transformer 的计算复杂度上限，并探讨了搜索算法如何通过外部计算换取推理质量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，推理阶段也暴露了一些特殊的理论现象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;过度思考（Overthinking）&lt;/strong&gt;：在推理时投入更多计算资源是否总是正向的？模型为何会在简单问题上陷入冗余推理？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;隐式推理（Latent Reasoning）&lt;/strong&gt;：模型能否在不输出显式 Token 的情况下，直接在隐空间中完成多路径的思维并行？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;6 评估阶段：从基准测试到形式化保证&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528030" data-ratio="0.5120370370370371" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkABFOic2spzHLCebEvtZYY94brBtoHtRCyON4TDbQTJw7nFT4zAbCOmLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ae580a0b-3e07-470f-9a56-15d70e9dcf7d/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 7: 评估阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;评估是大模型进步的标准，但当前的评估手段正面临严峻挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基准测试理论&lt;/strong&gt;：研究者利用不同的理论框架分析了传统基准测试的饱和问题与捷径学习现象，并剖析了「LLM-as-a-Judge」模式中的系统性偏见。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;安全性与透明度&lt;/strong&gt;：研究者深入探讨了可解释性（如 Sparse Autoencoders），对模型内部特征进行解构，并利用计算不可解性证明了在任何可计算的 LLM 中，幻觉都是不可消除的理论必然。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;抗误用机制&lt;/strong&gt;：研究者通过水印（Watermarking）等技术，探讨了识别 AI 生成内容与保持文本质量之间的理论权衡。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，评估阶段也催生了关于模型内部表示的深刻讨论：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;线性表示假设&lt;/strong&gt;：语义概念（如真实性）在模型潜空间中是否真的以线性方向编码？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;推理失效模式&lt;/strong&gt;：如「逆转诅咒（Reversal Curse）」和「位置偏差（Lost-in-the-Middle）」，这些失败案例揭示了自回归模型在逻辑对称性上的本质缺陷。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;结语：迈向 AGI 的未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管我们已经迈出了从经验迈向科学的第一步，但随着 LLM 的不断发展，更多的前沿理论问题依然亟待解决。正如爱因斯坦所言：「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;科学的伟大目标是用最少数量的假设或公理推导出最大数量的经验事实。&lt;/span&gt;」我们希望为社区提供一份结构化的 LLM 理论研究路线图，共同揭开黑盒背后的真理。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;刘勇&lt;/strong&gt;，中国人民大学，长聘副教授，博士生导师，国家级高层次青年人才。长期从事机器学习基础理论研究，共发表论文 100 余篇，其中以第一作者 / 通讯作者发表顶级期刊和会议论文近 50 篇，涵盖机器学习领域顶级期刊 JMLR、IEEE TPAMI、Artificial Intelligence 和顶级会议 ICML、NeurIPS 等。获中国人民大学「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;杰出学者」、中国科学院「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;青年创新促进会」成员、中国科学院信息工程研究所「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;引进优青」等称号。主持国家自然科学面上 / 基金青年、北京市面上项目、中科院基础前沿科学研究计划、腾讯犀牛鸟基金、CCF - 华为胡杨林基金等项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;甘泽宇&lt;/strong&gt;，中国人民大学高瓴人工智能学院博士研究生，本科及硕士研究生毕业于中国人民大学信息学院。当前主要研究方向包括大模型机理分析。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>百川开源全球最强医疗大模型M3，「严肃问诊」定义AI医疗新能力</title>
      <description>&lt;![CDATA[多指标性能更强大、幻觉率更低的医疗大模型]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 09:26:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;昨天，百川智能正式开源新一代医疗大模型 Baichuan-M3，其在全球最权威的医疗 AI 评测 HealthBench 中以 65.1 分的综合成绩位列全球第一；在专门考验复杂决策能力的 HealthBench Hard 上，也以 44.4 分的成绩夺冠。&lt;/p&gt;&lt;p&gt;这一成绩，不仅刷新了 HealthBench 的最高分，更首次在医疗领域实现了对 GPT-5.2 的全面超越。在 OpenAI 引以为傲的低幻觉领域，M3 也实现了超越，幻觉率 3.5 全球最低。&lt;/p&gt;&lt;p&gt;此外，M3 还首次具备了原生的 “端到端” 严肃问诊能力。它能像医生一样主动追问、逐层逼近，把关键病史和风险信号问出来，进而在完整的信息上进行深度医学推理。评测显示，其问诊能力显著高于真人医生的平均水平。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Hugging Face 地址：https://huggingface.co/baichuan-inc/Baichuan-M3-235B&lt;/li&gt;&lt;li&gt;GitHub 地址：https://github.com/baichuan-inc/Baichuan-M3-235B&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;医疗沟通和推理能力超越 GPT-5.2，登顶世界第一&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;2025 年 5 月份，OpenAI 发布 HealthBench，由 262 位来自 60 个国家的医生共同构建，收录了 5000 组高度逼真的多轮医疗对话，构建了全球最权威、也最贴近真实临床场景的医疗评测集。这一事件，被视为 OpenAI 在医疗领域开始 “重兵投入”，吹响进军医疗的号角。&lt;/p&gt;&lt;p&gt;相当长一段时间里，无论是 HealthBench 总分还是 HealthBench-Hard 子集， GPT 系列模型从未被超越。2025 年 8 月，百川开源医疗增强大模型 M2 在 HealthBench 上力压 gpt-oss-120B、DeepSeek-R1 等同期所有开源模型，并在 HealthBench Hard 上取得 34.7 分的成绩，仅次于 GPT-5，成为全球唯二突破 32 分的模型。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/af4c0af2-6825-42b4-a119-489baef87e5c/1768353665316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2025 年，强化学习无疑是新一代 Scaling Law 的技术中轴。在 M2 发布后的五个月里，百川智能对强化学习系统进行了全面升级，将原本以患者模拟器和静态 Rubric 为主的半动态反馈，升级为随模型能力不断演进的全动态 Verifier System。随着监督信号持续变细、变难，模型得以不断突破能力上限，使 M3 在复杂医学问题上的表现实现跃迁，不仅在 HealthBench 总分上超越 OpenAI 最新模型 GPT-5.2，也在 HealthBench Hard 上登顶，成为当前全球医疗沟通和推理能力最强的医疗大模型。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;重构幻觉抑制的训练范式，刷新医疗幻觉率底线&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;幻觉是这一代大模型技术范式的通病，更是 AI 进入严肃医疗的拦路虎。在大多数场景幻觉只是体验问题，而在严肃医疗场景可导致安全事件。&lt;/p&gt;&lt;p&gt;降低幻觉，一直是 OpenAI 最重视的研究方向之一。几乎每一代 GPT 模型的幻觉率均为行业最低。OpenAI 也是第一个单独评测医疗能力和提供医疗服务的通用模型公司。&lt;/p&gt;&lt;p&gt;国内 DeepSeek 等模型的普及，让越来越多人开始使用 AI 并尝试进行医疗健康咨询。但大多数模型公司并没有把 “降幻觉” 提升到与推理、代码等相同的高度。用这样的模型获取健康咨询和诊疗建议，对 AI 医疗的普及和医患信任建立带来很大困扰。&lt;/p&gt;&lt;p&gt;百川 M3 将医疗幻觉抑制前移至模型训练阶段，在强化学习过程中将医学事实一致性作为核心训练目标之一，将 “知之为知之，不知为不知” 直接作用于模型自身能力的形成过程。这一新的训练方法将医学事实可靠性内化为 M3 自身的基础能力，使其在不借助任何外部系统的情况下，依然能够基于自身医学知识进行稳定、可信的作答。&lt;/p&gt;&lt;p&gt;通过将事实一致性约束融入训练流程，M3 重构了幻觉抑制的训练范式，在不依赖工具或检索增强的纯模型设置下，医疗幻觉率 3.5，超越 GPT-5.2，达到全球最低水平。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26310800-527a-4066-a8ff-63241be5aea9/1768353715138.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;h3 style="text-align: center;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;构建「严肃问诊」新能力，端到端问诊超越真人医生&lt;/strong&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;p&gt;除了强推理和低幻觉，端到端的问诊能力是本次 M3 最重要的一项突破。2025 年行业的技术共识是，用户提供更完整的上下文，模型才有更好的表现。可在医疗领域，患者很难完整表达自己的病症，需要模型像医生一样有能力把患者的混乱叙述转变成可做诊疗决策的信息。&lt;/p&gt;&lt;p&gt;HealthBench 代表了 OpenAI 对临床场景的认知高度，然而它本质上是一个切片式的评测，考核的更像是 “AI 会不会回答问题”，而不是带着诊疗目标，完整的患者信息收集。这也正说明了行业对问诊重要性和建模思路的理解不足。&lt;/p&gt;&lt;p&gt;应用实践中，通过 prompt “你是一位经验丰富的医生”，激活模型的 “角色扮演” 是更常见的做法。这种方式得到的是模型的表演行为，而非内生能力，激活的是模型应该提问的行为，而不是必须获取关键信息的思考。例如，临床医生面对患者的第一反应，永远是先排除危急重症，再考虑常规诊疗，这是刻在职业本能里的安全优先级。但常见的 “角色扮演” 的问诊方式，无法将 “红旗征识别与处置” 作为核心行动原则。这种不围绕关键风险点展开的信息收集，即便对话看似完整，也难以支撑安全、可靠的临床判断，从根本上偏离了医疗 “安全第一” 的原则。&lt;/p&gt;&lt;p&gt;针对这一行业困境，百川智能提出了 “严肃问诊范式” 与 “SCAN 原则”，通过 Safety Stratification（安全分层）、Clarity Matters（信息澄清）、Association &amp;amp; Inquiry（关联追问）与 Normative Protocol（规范化输出），将临床问诊中高度依赖经验的思维过程，第一次系统性地 “白盒化”。&lt;/p&gt;&lt;p&gt;围绕 SCAN 原则，百川智能借鉴医学教育里长期使用的 OSCE 方法，联合 150 多位一线医生，搭建了 SCAN-bench 评测体系，该体系以真实临床经验作为 “标准答案”，将诊疗过程拆解为病史采集、辅助检查、精准诊断三大阶段，通过动态、多轮的方式进行考核，完整模拟医生从接诊到确诊的全过程。相比于 HealthBench，SCAN-bench 是更加全流程端到端的动态评测新范式。&lt;/p&gt;&lt;p&gt;同时，百川智能还使用原生模型训练方法取代角色扮演 prompt，针对 GRPO 无法稳定进行长对话训练的问题，设计了新的 SPAR 算法，使模型能够在有限对话轮次中，把临床真正需要的关键问题问全、问准，把风险兜住，让输出经得起复核。&lt;/p&gt;&lt;p&gt;在实验过程中发现，问诊准确度每增加 2%，诊疗结果准确度就会增加 1%。评测结果显示，M3 在 SCAN 的四个维度均显著高于人类医生基线水平，并大幅领先于国内外顶尖模型，成功构建了从精准的临床问询、深度医学推理到安全可靠决策的闭环。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f0ee5beb-e7ff-4129-87fe-9ea83c3ad5b4/1768353751451.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;从 1 月初 OpenAI 发布医疗产品 ChatGPT Health，到今天 Anthropic 推出 Claude for Healthcare，AI 医疗正在全球范围内提档加速，竞争也正式进入深水区。在这场竞速中，作为国内唯一专注医疗的大模型企业，百川持续突破低幻觉率、端到端问诊和复杂临床推理等核心能力，已从 “跟随者” 跃迁为行业 “引领者” 与新范式的 “定义者”，正以硬核实力扛起中国 AI 医疗发展的旗帜。&lt;/p&gt;&lt;p&gt;百川智能的医疗应用 “百小应” 已同步接入 M3，面向医生与患者开放相关能力。医生可借助它推演问诊与诊疗思路，患者及家属也可通过该应用更系统地理解诊断、治疗、检查与预后背后的医学逻辑。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>相约AAAI 2026 | 上海AI实验室北极星 X 星启交流会（报名开启）</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 18:16:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-pm-slice="0 0 []"&gt;2026年1月20日至27日，第40届AAAI人工智能会议（AAAI 2026）将在新加坡召开。期间，上海人工智能实验室（上海AI实验室）将举办&amp;ldquo;&lt;strong&gt;北极星X星启交流会暨云帆AI Talent Meetup&lt;/strong&gt;&amp;rdquo;。届时，实验室相关领域专家将亲临现场，与全球同行展开深度交流与研讨。&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;诚邀AAAI论文作者，人工智能、自然科学、工程科学等多学科交叉领域的教授、博士后，以及产学研各界的创新实践者参加，共探探前沿技术。截至目前，&amp;ldquo;北极星&amp;rdquo;交流会已在中国、美国、新加坡、加拿大等地成功举办多场，为数千名AI英才连接全球机遇。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;&lt;span data-mpa-action-id="mgrf9l7z1mku" data-pm-slice="0 0 []"&gt;报名信息&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;strong&gt;交流会为邀约制&lt;/strong&gt;，请扫描下方二维码或点击文末阅读原文，提交报名信息。审核通过后，将收到邀请函邮件。席位有限，请即报名。&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp58IHScqCRlbkticruibeWyibCCrRYkKiafheZSia6wlVSibPqib57Inyiaf0WrA/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=1" alt="图片" data-ratio="1.3175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100079745" data-aistatus="1" data-original-style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;vertical-align: bottom;height: auto !important;width: 244px !important;visibility: visible !important;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/77b14239-14ff-47a3-8596-e273d2375209/640.png" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;截止时间：&lt;/strong&gt;1月19日12:00p.m.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;咨询邮箱&lt;/strong&gt;：&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"font-size: 16px;color: rgb(62, 62, 62);margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-bottom: 10px;width: 100%;align-self: flex-start;padding: 12px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: center;justify-content: center;display: flex;flex-flow: row;width: 100%;align-self: flex-start;background-color: rgb(255, 255, 255);padding: 14px 17px;box-shadow: rgb(225, 233, 246) 0px 0px 8px 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: justify;line-height: 2;letter-spacing: 1px;font-size: 15px;color: rgb(80, 100, 115);width: 100%;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"data-pm-slice":"0 0 []","style":"margin-bottom: 24px;text-align: left;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;luochen&lt;/span&gt;@pjlab.org.cn&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mpa-action-id="mgrf9haq1qc4" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;活动信息&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp50C1ufP8PWyBS5nSXFcc1fsB48dInzRQmMmK6k0dw9SJnibW7kRMcWQA/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=2" alt="图片" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp50C1ufP8PWyBS5nSXFcc1fsB48dInzRQmMmK6k0dw9SJnibW7kRMcWQA/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="316" data-backw="562" data-backh="316" data-imgfileid="100079737" data-aistatus="1" data-original-style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;vertical-align: bottom;height: auto !important;width: 661px !important;pointer-events: initial;visibility: visible !important;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/33f758d5-800b-4123-83be-7bda2c86070d/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;活动亮点：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖学术分享&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;上海AI实验科学家创新成果分享、前沿技术主题演讲，激发科研灵感。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;实验室直通车：&lt;/strong&gt;与上海AI实验室团队负责人零距离交流，直通核心科研、工程岗位。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;产学资源直通：&lt;/strong&gt;上海AI实验室特邀合作科研机构、高校及企业神秘嘉宾分享，解锁前沿技术洞察。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;活动时间&lt;/strong&gt;：1月22日17:30-20:30(新加坡时间)&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"font-size: 16px;color: rgb(62, 62, 62);margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: flex;width: 100%;flex-flow: column;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"z-index: 1;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: inline-block;width: auto;vertical-align: top;align-self: flex-start;flex: 0 0 auto;border-left: 1px solid rgb(0, 79, 132);border-bottom-left-radius: 0px;padding-left: 13px;min-width: 5%;height: auto;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: justify;font-size: 15px;color: rgb(0, 79, 132);line-height: 2;letter-spacing: 1px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"font-family: \"mp-quote\", -apple-system-font, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Hiragino Sans GB\", \"Microsoft YaHei UI\", \"Microsoft YaHei\", Arial, sans-serif;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;活动地点&lt;/strong&gt;：&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"font-size: 16px;color: rgb(62, 62, 62);margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: flex;width: 100%;flex-flow: column;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"z-index: 1;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"display: inline-block;width: auto;vertical-align: top;align-self: flex-start;flex: 0 0 auto;border-left: 1px solid rgb(0, 79, 132);border-bottom-left-radius: 0px;padding-left: 13px;min-width: 5%;height: auto;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"text-align: justify;font-size: 15px;color: rgb(0, 79, 132);line-height: 2;letter-spacing: 1px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"font-family: \"mp-quote\", -apple-system-font, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Hiragino Sans GB\", \"Microsoft YaHei UI\", \"Microsoft YaHei\", Arial, sans-serif;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;新加坡中心城区&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;议程速览&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oDpticHyXWJHuic3q8WXwZJVGm7UPaYkp5CsOSBubByBo6SBWjKczwKsZ5OSQ6mSdumklvtwmy2s67oiaazcibjx9A/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=3" alt="图片" data-ratio="0.7929515418502202" data-s="300,640" data-type="png" data-w="681" type="block" data-imgfileid="100079744" data-aistatus="1" data-original-style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;vertical-align: bottom;height: auto !important;visibility: visible !important;width: 603px !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3120497a-c92e-407c-b387-9bd1da5c25ec/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; *（以现场实际议程为准）&lt;/sup&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;We Want You！&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;上海人工智能实验室是国际级人工智能新型科研机构，采取有组织科研与原创探索深度融合的研究范式，开展前瞻性、基础性重大科学问题研究和关键核心技术攻关，凝聚和培养高水平人才，打造&amp;ldquo;突破型、引领型、平台型&amp;rdquo;一体化的大型综合性研究基地，目标建成世界一流的人工智能实验室，成为享誉全球的人工智能原创理论和技术的策源地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在这里，你将获得：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶级科研平台与资源&lt;/strong&gt;：超大规模算力集群和数据支持，投身具备规模化潜力、强泛化能力、长期价值的研究。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全球化创新团队协作&lt;/strong&gt;：参与跨团队、跨领域的重大项目，实现研究能力的指数级跃升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;清晰的职业发展通道&lt;/strong&gt;：由实验室出题，链接顶尖高校、科研机构和行业企业，助力承担重大项目，持续做有影响力的研究，获得在产业中验证价值的机会。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>视觉模型既懂语义，又能还原细节，南洋理工&amp;商汤提出棱镜假说</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 18:12:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/e660baee-2056-466c-a3f6-be1f3af836e1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作者来自 Nanyang Technological University（MMLab） 与 SenseTime Research，提出 Prism Hypothesis（棱镜假说） 与 Unified Autoencoding（UAE），尝试用 &amp;ldquo;频率谱&amp;rdquo; 的统一视角，把语义编码器与像素编码器的表示冲突真正 &amp;ldquo;合并解决&amp;rdquo;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAlyWBy1KknQm5lsFTk7N8U9xgTQCejxkVg5aGn1Q5U4mluIakaGTbiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527982" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/db9d9c4e-202c-4bc5-b35f-1ba97c6b3873/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; line-height: 1.75em; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库：https://github.com/WeichenFan/UAE&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/pdf/2512.19693&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;背景：为什么 &amp;ldquo;懂语义&amp;rdquo; 和 &amp;ldquo;还原细节&amp;rdquo; 总是很难兼得？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在视觉基础模型里，我们经常同时依赖两类能力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;语义理解：像 DINOv2 / CLIP 这类 &amp;ldquo;语义编码器&amp;rdquo; 更擅长类别、属性、关系等抽象信息；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;像素保真：像 SD 系列 VAE 这类 &amp;ldquo;像素编码器&amp;rdquo; 更擅长纹理、边缘、小字等细节重建。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但现实问题是：很多系统被迫把两套表示 &amp;ldquo;拼在一起用&amp;rdquo;：语义一套、像素一套，训练效率下降、表示互相干扰、而且很难得到一个既 &amp;ldquo;语义强&amp;rdquo; 又 &amp;ldquo;细节强&amp;rdquo; 的统一潜空间。&lt;/p&gt;&lt;p&gt;论文把这种矛盾归结为一个更本质的问题：世界的信息到底如何被表示，才能既共享语义，又保留各自模态的细粒度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心洞察：Prism Hypothesis（棱镜假说）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAWqF4P42Toh1Q6FPhR2FSfjUOSp0O2qT8swiaQvznZpYJericuJGS3G2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.35833333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527983" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a4a342d3-1f58-491d-a30a-8d15a8d090e1/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文给出了一个非常直观的统一解释：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;可以把真实世界的输入看成投影到同一条 &amp;ldquo;特征频谱&amp;rdquo; 上的不同切片；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;低频更像 &amp;ldquo;全局结构 / 语义&amp;rdquo;（类别、布局、关系）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高频更像 &amp;ldquo;局部细节 / 质感&amp;rdquo;（纹理、边缘、微小文字）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkASABicp8ERgu38QzfV9hjiagSHrh9w8NwniclLlnyB2ZbY2S5n2IUx83vA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8926380368098159" data-s="300,640" data-type="png" data-w="652" type="block" data-imgfileid="503527984" data-aistatus="1" data-original-style="width:437px;height:390px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1240001c-b582-47c1-90d6-6ecf03a00aa1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQibNibnpfUFQwicrDn4fG7l8VJekgNibicZtrLOjI7IutTvdia6as4ibkt8bQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9079754601226994" data-s="300,640" data-type="png" data-w="652" type="block" data-imgfileid="503527985" data-aistatus="1" data-original-style="width:453px;height:411px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1fd75430-ac2c-43c9-ac4a-fe639d0243e3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了验证，作者做了两类证据：&lt;/p&gt;&lt;p&gt;1. 能量谱分析：语义编码器（如 DINOv2、CLIP）能量更集中在低频，而像素型编码器（如 SD-VAE）保留更多中高频细节。&lt;/p&gt;&lt;p&gt;2. 频率过滤下的检索鲁棒性：文本 - 图像检索的 R@5 在低通情况下较稳定，但在高通 / 去掉低频基座后会明显崩塌、趋近随机，说明跨模态语义对齐主要来自共享低频基座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法：Unified Autoencoding（UAE）怎么把两种表示 &amp;ldquo;合成一套&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYIlvy9UO0cVsUxC2sYDuT2wbP3Zz6G2uItz94tJNyfhP8TCz0libcicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.43796296296296294" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527994" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/30d4043c-d040-4f3b-b097-b2ed3ee09930/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;围绕 &amp;ldquo;低频语义基座 + 高频细节残差&amp;rdquo; 的思路，UAE 的核心是把一个统一编码器学成多频段潜变量，并把 &amp;ldquo;语义该管什么、细节该放哪里&amp;rdquo; 结构化地拆开。&lt;/p&gt;&lt;p&gt;1) Unified Encoder：从语义编码器初始化，走向统一潜空间&lt;/p&gt;&lt;p&gt;以 DINOv2 为例，UAE 的统一编码器从预训练语义模型初始化，进入后续频域处理。&lt;/p&gt;&lt;p&gt;2) Residual Split Flow：在频域做 &amp;ldquo;可控的分带分解&amp;rdquo;&lt;/p&gt;&lt;p&gt;UAE 用 FFT 做频段投影（平滑径向 mask），并采用迭代残差拆分，把潜变量拆成多个频带：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低频带（低频）承载语义 / 全局结构&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更高 band（高频）逐步承载边缘、纹理等细节残差&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;同时强调分解的可逆性与空间一致性。&lt;/p&gt;&lt;p&gt;3) Frequency Band Modulator：只 &amp;ldquo;扰动细节&amp;rdquo;，再做频带融合给解码器&lt;/p&gt;&lt;p&gt;训练时对高频带进行噪声扰动以增强鲁棒性；然后把各频带在通道维拼接，融合后作为解码器唯一输入。&lt;/p&gt;&lt;p&gt;4) Semantic-wise Loss：语义只约束低频，细节放开学像素&lt;/p&gt;&lt;p&gt;为了既继承语义先验、又扩展到高频细节，UAE 的语义对齐损失只施加在最低频的前 K 个 band 上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;低频对齐 ；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高频不强行对齐；&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;论文也明确把 UAE 定位为 tokenizer，并强调其 &amp;ldquo;能与现有 diffusion transformers 无缝对齐&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：一个潜空间，同时要 &amp;ldquo;语义&amp;rdquo; 也要 &amp;ldquo;细节&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重建质量（ImageNet / MS-COCO）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 256&amp;times;256 重建任务上，UAE（DINOv2-L）在 ImageNet 上达到 PSNR=33.08、SSIM=0.94、rFID=0.16，在 MS-COCO 上达到 PSNR=32.84、SSIM=0.94、rFID=0.17。&lt;/p&gt;&lt;p&gt;同时，论文指出在相同 DINOv2 编码器设置下，UAE 相比 RAE 基线在 PSNR/SSIM 更高，并且 rFID 下降超过 90%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQbfSGFIzcNxvJaQhpNgbwj4CCVp24LicXwN9LBb2d5umseVdBjj9VicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527993" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3b472157-8e1a-4925-be2a-45af2e416de9/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8gsIlkgTIQBb5b7xtkeBcFo0y75tyZcqhm06TZj4o54RQOvViczs6LA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6981481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527992" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/75698afb-c8f5-4548-8d4f-816599178f88/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;生成能力（ImageNet 类条件生成）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 ImageNet 256&amp;times;256 类条件生成上，UAE 达到 gFID=1.68、IS=301.6。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语义理解（Linear Probing）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 ImageNet-1K 上，UAE 在 ViT-B 骨干下达到 Top-1=83.0%，与 RAE 持平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMjYwA7DgZzEPRzxaeqr6nDLCwFHw0JroeNt66abjhWOlyOARSYicojA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6720257234726688" data-s="300,640" data-type="png" data-w="933" type="block" data-imgfileid="503527989" data-aistatus="1" data-original-style="width:451px;height:303px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/53fda450-4656-4265-b4a4-b9bf39e9c759/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQf2MWEa8VMj8URg64icooqF6dfzibkcuEvsNrLBwx5QrpOIGhzMSQichQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.7563291139240507" data-s="300,640" data-type="png" data-w="948" type="block" data-imgfileid="503527990" data-aistatus="1" data-original-style="width:475px;height:359px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/93db05ef-c2e0-4b8a-be82-8db8edb6aadf/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>无需重新训练，即可学习新任务，Arc研究所开源单细胞基础模型Stack及细胞反应全景图谱</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Tue, 13 Jan 2026 16:25:14 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027134" data-ratio="0.5194444444444445" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLm0558h8aSPtXwRembmSujZkmIkIc0YaYsWD7WTXmXnPF6icxBKmg1nMRyZ29LDfibb3xJILGMb4IiaA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/2a33a020-7f98-4bb0-9f6c-9669402a2bd8/640.jpeg" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑丨coisini&lt;/span&gt;&lt;/p&gt;&lt;p&gt;单细胞转录组学技术为测量跨物种、跨疾病及各类生物条件下的细胞表型多样性提供了可能。去年，Arc 研究所发布了一个名为「State」的虚拟细胞模型，证明了使用细胞集合进行分析能提升扰动响应的预测能力。&lt;/p&gt;&lt;p&gt;然而，最核心的挑战依然存在：能否构建一个通用模型，无需特定环境的扰动数据即可预测细胞在全新环境中的反应？&lt;/p&gt;&lt;p&gt;现在，Arc 研究所宣布推出开源基础模型 Stack&amp;mdash;&amp;mdash; 该模型通过两项关键创新延伸了「细胞集合」理念，并在上述问题上取得突破性进展。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027129" data-ratio="0.21944444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLm0558h8aSPtXwRembmSujZLMlnLoticUrVjyxN4pzAWvfzzUibsvmEzOWYao8BhdmZQicdqfghjzCZA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/0814fc62-5253-44ad-8544-8a281fecdb32/640.jpeg" alt="图片" data-before-load-time="1768292670330" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文地址：https://www.biorxiv.org/content/10.64898/2026.01.09.698608v1&lt;/p&gt;&lt;p&gt;开源地址：https://github.com/ArcInstitute/stack&lt;/p&gt;&lt;p&gt;Stack 基础模型在 1.49 亿个标准化预处理的人类单细胞数据上进行训练，通过表格注意力机制生成基于上下文细胞信息的细胞表征。与基线模型相比，Stack 在零样本场景的下游任务中实现了显著性能提升。&lt;/p&gt;&lt;p&gt;开源基础模型 Stack&lt;/p&gt;&lt;p&gt;Stack 能够从代表任意条件的未标记细胞中进行上下文学习，并预测这些条件对目标细胞群的影响，而无需针对特定数据进行微调。通过两项关键创新，Stack 拓展了「细胞集合」理念：&lt;/p&gt;&lt;p&gt;首先是架构创新。Stack 采用表格化 Transformer 模块，将单细胞数据处理为包含细胞与基因的二维表格，使信息既能在单个细胞内流动（基因间关联），也能在细胞间传递（细胞间关联）。这种设计使模型能更好地捕捉生物学背景：炎症组织中的 T 细胞行为差异不仅源于自身基因，更受细胞环境影响。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027130" data-ratio="0.7222857142857143" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm0558h8aSPtXwRembmSujZXvc5Fdpz9m9tfLjDhGEEGpH92m9aDu27csIX0lbdho8T1BBwibxFpIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="875" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/fcf1d118-32ab-4441-b774-a5683d240725/640.png" alt="图片" data-before-load-time="1768292670355" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Stack 还创新性地引入可训练的「基因模块表征符」，通过多基因衍生的生物组件描述细胞状态，而非独立建模每个基因，使模型兼具更强可解释性与更高训练效率。&lt;/p&gt;&lt;p&gt;其次是训练策略创新。Stack 基于 scBaseCount 数据库中 1.49 亿个细胞（涵盖数百种组织、疾病、供体及状态）进行预训练，使其内化决定细胞环境的生物学关联。随后通过对公共数据库 CellxGene 和 Parse PBMC 中 5500 万个细胞进行后训练，Stack 学会了将一组细胞作为「提示指令」，指导其对另一组细胞的预测。&lt;/p&gt;&lt;p&gt;正如文本提示能引导语言模型生成回应，对 Stack 来说，细胞就是 prompt，界定着影响预测的生物学条件。例如，Stack 可观察经药物处理的免疫细胞，进而预测上皮细胞对同一药物的反应。&lt;/p&gt;&lt;p&gt;Stack 是首个能够在推理时无需重新训练即可学习新任务的单细胞基础模型。这种能力使其在标准测试中表现卓越。&lt;/p&gt;&lt;p&gt;研究团队采用严谨的扰动预测评估框架 cell-eval，结合疾病分类与细胞类型整合等标准任务对 Stack 进行评估。在各项测试中，Stack 的表现始终优于其他方法。在扰动预测指标上，Stack 更是全面超越现有方案，证明了零样本基础模型足以与专业定制方法相媲美。&lt;/p&gt;&lt;p&gt;Perturb Sapiens：&lt;/p&gt;&lt;p&gt;预测性细胞反应全景图谱&lt;/p&gt;&lt;p&gt;为了展现 Stack 模型的能力并为该领域创建新资源，研究团队开发了 Perturb Sapiens&amp;mdash;&amp;mdash; 一个基于 Tabula Sapiens 数据预测细胞反应的图谱。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027133" data-ratio="0.5055555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm0558h8aSPtXwRembmSujZbd6AXfAQY6hv7b7kUcOnJttFGs7cmlPggcZ6gj1cCWCPlKFSXPXVTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/15605f64-3074-44bb-b046-7d0c81750fdd/640.png" alt="图片" data-before-load-time="1768292670588" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Perturb Sapiens 解决了基础实验的空白：绝大多数「细胞类型 - 组织 - 扰动」组合从未被测量过。即便仅全面测试其中一小部分组合，也需要耗费数百万美元和数年实验工作。&lt;/p&gt;&lt;p&gt;为创建该图谱，该研究利用模型的上下文学习能力，将免疫细胞反应「翻译」至整个人体系统。针对每种扰动，Stack 模型通过观察免疫细胞反应，预测 Tabula Sapiens 中每种组织内所有细胞类型的反应，最终生成了约 20000 个预测的「细胞类型 - 组织 - 扰动」组合。&lt;/p&gt;&lt;p&gt;Perturb Sapiens 有何用途？某种对免疫细胞作用强烈的药物，可能对同组织的上皮细胞或基质细胞几乎无影响。干扰素信号在肺上皮与肠上皮中会产生不同的转录组特征。某些药物和细胞因子能在差异显著的细胞类型中激活相似的反应程序，暗示其存在共同的易感性机制。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027131" data-ratio="0.5574074074074075" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLm0558h8aSPtXwRembmSujZLSun4uu0BXDBLQ9WssAYKkeTDmaaKj34O6zvYzYGnWEtCs3wpI59pg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/56a49f5a-acbb-4d91-9a59-c68b442eb502/640.jpeg" alt="图片" data-before-load-time="1768292670628" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Perturb Sapiens 开源地址：https://huggingface.co/datasets/arcinstitute/Perturb-Sapiens&lt;/p&gt;&lt;p&gt;感兴趣的读者可以阅读论文原文，了解更多研究内容。&lt;/p&gt;&lt;p&gt;参考内容：https://arcinstitute.org/news/foundation-model-stack&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>不上云、不租卡，如何优雅地在本地微调Qwen-VL-30B？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:39:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9e5b9119-5d5e-4841-87c6-b36c5b804f42/1768278956181.png" style="width: 700%;" class="fr-fic fr-dib"&gt;假如你是一个致力于将 AI 引入传统行业的工程团队。现在，你有一个问题：训练一个能看懂复杂机械图纸、设备维护手册或金融研报图表的多模态助手。这个助手不仅要能专业陪聊，更要能精准地识别图纸上的零件标注，或者从密密麻麻的财报截图中提取关键数据。&lt;/p&gt;&lt;p&gt;首先，你需要选择一个合适的模型。&lt;/p&gt;&lt;p&gt;7B 参数的小模型虽然跑得快，但「脑容量」太小，面对复杂的图文逻辑经常一本正经地胡说八道；而 70B 甚至更大的模型虽然聪明，但部署和推理成本直接劝退了客户。最后，你可能发现 30B 参数级的开源多模态模型（例如 Qwen-VL-30B）是个不错的选择。&lt;/p&gt;&lt;p&gt;30B 被称为大模型的黄金尺寸：它在理解能力上远超小模型，又比巨型模型轻量，是企业私有化部署的完美平衡点。&lt;/p&gt;&lt;p&gt;不过呢，你可能也会发现，「30B 参数」也是一个极具欺骗性的数字。&lt;/p&gt;&lt;p&gt;在纯文本时代，一张前沿的消费级显卡或许还能勉强塞下 30B 的推理。但在多模态（Vision-Language）场景下，事情完全变了。当模型需要处理高分辨率图像时，视觉编码器会产生大量的视觉 Token；而为了让模型真正懂行业 Know-how，必须用数千张有标注图像进行 LoRA 微调。&lt;/p&gt;&lt;p&gt;这就意味着，除了模型本身的权重，我们还需要在显存里塞进梯度、优化器状态以及训练过程中的激活值。&lt;/p&gt;&lt;p&gt;原本以为只是「稍微大一点」的任务，瞬间撞上了物理学的墙。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这些方案不太行&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你的开发环境是顶级消费级旗舰，拥有 24 GB 的超大显存，但在这次的任务面前，它显得如此无力。&lt;/p&gt;&lt;p&gt;当你尝试启动微调脚本时，终端里那行熟悉的红色报错如期而至：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="cs"&gt;&lt;code&gt;RuntimeError: CUDA out of memory. &lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;对于 30B 多模态模型的微调来说，24 GB 的显存就是不够。为了让程序跑起来，你可能会选择牺牲性能，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Batch Size 降到 1&lt;/strong&gt;： 哪怕训练速度慢到像蜗牛爬。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;开启梯度检查点&lt;/strong&gt;： 这是一个典型的「时间换空间」策略，通过不缓存中间激活值而是在反向传播时重算，来节省显存。但这让训练时间直接翻倍。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极限量化&lt;/strong&gt;： 将模型量化到 4-bit 甚至更低。但这也会带来新的问题：对于精密图纸的识别，量化后的模型精度下降明显，连零件号都经常认错。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;即使做了所有这些妥协，只要稍微喂进去一张分辨率高一点的图表，显存还是瞬间溢出，程序直接崩溃。那种「只差一点点就能跑通」的挫败感，最是折磨人。&lt;/p&gt;&lt;p&gt;「要不试试隔壁美术组那台 Mac Studio？」你可能会这样想。那台机器拥有 128 GB 统一内存（Unified Memory）。从硬件上看，这简直是完美的救星 &amp;mdash;&amp;mdash; 别说 30B，就是 70B 也能塞得下。&lt;/p&gt;&lt;p&gt;但当你兴冲冲地把代码拷过去，才发现这是另一个深坑。&lt;/p&gt;&lt;p&gt;首先是环境配置的噩梦。开源社区的主流多模态模型（尤其是涉及底层 CUDA 优化的视觉算子）在苹果芯片上的适配往往慢半拍。你可能会花不少时间解决各种编译报错，好不容易跑通了推理，却发现训练速度受限于优化，效率远不及预期。&lt;/p&gt;&lt;p&gt;更致命的是「生态隔离」。在 Mac 上微调出的模型检查点，想要部署回公司的 Linux 服务器（基于 NVIDIA GPU）上，需要进行繁琐的格式转换和精度对齐。这种开发环境与生产环境的割裂，对于追求快速迭代的工程团队来说，是不可接受的风险。&lt;/p&gt;&lt;p&gt;那么，你到底需要什么？&lt;/p&gt;&lt;p&gt;难道为了跑通这个 30B 模型，你真的要走漫长的合规流程去申请昂贵的 A100 云实例，时刻防范私密数据出域的风险？又或者，仅仅为了这一个开发项目，就专门配置一个高成本的工作站，甚至去采购一台必须安置在专业机房、且维护成本高昂的机架式服务器？&lt;/p&gt;&lt;p&gt;你需要这样一台机器：它要有 Mac Studio 那样海量的统一内存，让你不再为显存精打细算；它同时又必须流淌着纯正的 NVIDIA 血液，拥有原生的 CUDA 生态，让代码无缝迁移。&lt;/p&gt;&lt;p&gt;这个「既要又要」的幻想，直到一台 1 升体积的小盒子的出现，才变成了现实。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;桌面上的一升解决方案&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个盒子就是&lt;strong&gt;联想 ThinkStation PGX&lt;/strong&gt;。&lt;a href="https://mp.weixin.qq.com/s/qeWJwnchS2qNFAKFaHu-TA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e0ee0cbe-e5a4-49d1-b2ae-69eef17029c6/1768278994471.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;如果你关注过英伟达之前的动作，可能会觉得眼熟。没错，联想 ThinkStation PGX 在核心配置上与 NVIDIA DGX Spark 完全一致。&lt;/p&gt;&lt;p&gt;准确地说，ThinkStation PGX 正是英伟达 DGX Spark 的 OEM 量产版本。英伟达已将这一参考设计授权给了联想等厂商，由它们负责具体的工程化制造与差异化定制。&lt;/p&gt;&lt;p&gt;这台机器最直观的冲击力来自于它的尺寸：&lt;strong&gt;仅有 1 升（1L）&lt;/strong&gt;。它小到可以轻松塞进通勤背包，放在办公桌的一角几乎没有存在感。但就在这方寸之间，联想塞进了一颗基于 NVIDIA Grace Blackwell 架构的 GB10 超级芯片。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA0426a2g3EeEUicsZGqIv62q93ypn8Cb5mfygcewWia1x2gpFMriabrZmQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.5879629629629629" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527947" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3d5b0310-6e10-44e9-bf0b-d35d5cd48d29/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而对于被显存折磨得死去活来的开发者来说，它最性感参数是：&lt;strong&gt;128 GB 统一内存（Unified Memory）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这不仅仅是数字的胜利，更是架构的胜利。ThinkStation PGX 的统一内存架构允许 CPU 和 GPU 共享这 128 GB 的海量空间，且可通过 NVLink-C2C 技术实现高速互联。这意味着，开发者终于可以在桌面上拥有接近甚至超越专业级计算卡（如 H100 80GB）的显存容量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACFNGwzs9rpqowOxffYOwVbpj3FJAnicr7KqyibdVUZ0bZ88LezicK2a5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.612037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527945" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e50bbc83-c24e-43e6-8b33-f70c73e6c8c2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了核心算力，在数据存储方面，联想贴心地提供了 1TB 和 4TB 两个存储版本。对于大部分只是想快速验证模型原型的开发者，1TB 版本足矣；而对于需要本地存放海量训练数据（如医疗影像、自动驾驶点云或数万张高清图纸）的团队来说，4TB 版本显然是更具安全感的选择。&lt;/p&gt;&lt;p&gt;更关键的是，它是一台「原生」的 AI 机器。预装了 &lt;strong&gt;NVIDIA AI &lt;/strong&gt;软件栈，底层运行的是开发者熟悉的 Linux 系统，跑的是最纯正的 CUDA 环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAUWHEEOH6UdalyZXJTUsVxoGCiaUvXbNpiaHGwkxEXLqH9fXqSdYe1yCQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527946" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/aa108d5a-a934-41f7-8cec-6fc7012a79b4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，就让我们亲手试一试这样显存巨大的性能小猛兽吧。&lt;/p&gt;&lt;p&gt;首先，掂一掂重量，着实非常小巧，甚至比 Mac mini M1 还小一些。同时，它的设计也非常精致，采用了标志性的蜂窝状散热设计，不仅看起来科技感十足，更是为了保证进风效率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAcqWFAJQD2rJNtPAWdVTPOeRib2zUu4WyXCF9Zy4wFzu3PXLuHiceg06Q/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527949" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/50317fdf-a6ba-4a5e-8474-0f85cd01bc2a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，把 ThinkStation PGX 连上显示器，通电开机，先来看看基本信息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkARuyPPVnt2obHricibVh9F3MZ9k2h0oDn84JcrKjPsJaDg0kRBa2yiao5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6724324324324324" data-s="300,640" data-type="png" data-w="925" type="block" data-imgfileid="503527948" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1b73c55f-9f80-453c-87ba-c3e779f185e6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在终端输入 nvidia-smi，可以看到显卡型号是 NVIDIA GB10，CUDA 版本为 13.0。但这里有一个有趣的细节：在 Memory-Usage 一栏，它显示的是 Not Supported。&lt;/p&gt;&lt;p&gt;为什么不支持？其实，这反而是最大的利好。&lt;/p&gt;&lt;p&gt;在传统的独立显卡（如 RTX 4090）上，显存是独立的，所以会显示具体 MiB 数值。这里的「Not Supported」以及下面进程列表里能显示显存占用（如 Firefox 用了 230MiB），直接证明了它是&lt;strong&gt;统一内存（Unified Memory）&lt;/strong&gt;架构。&lt;/p&gt;&lt;p&gt;是的，PGX 的 GPU 没有自己封闭的小显存墙，而是直接访问系统的大内存池。&lt;/p&gt;&lt;p&gt;接下来我们将通过一个真实的微调场景来检验这台机器的能力。&lt;/p&gt;&lt;p&gt;首先，我们选择的模型是完整版的 Qwen3-VL-30B-A3B-Instruct。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZw2oLxQjhQBY9V4afmSdMhnRnTyL9hiajLib3lUiciapxBlVv7N0ia1PUcQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.3203342618384401" data-type="gif" data-w="1077" type="block" data-imgfileid="503527952" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0ca3647f-8db1-4be5-ba05-5b72a7f66464/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;糟糕的网速下等待 1 个多小时，下载完成。而为了微调模型，我们还需要一个数据集，这里我们选择是的 lyan62 发布的 FoodieQA 数据集。据介绍，FoodieQA 是一个用于细粒度理解中国饮食文化的多模态数据集，其中包含多图像、单图像视觉问答（VQA）以及关于中国地方美食的文本问答问题。该数据集基于 350 种独特美食条目对应的 389 张独特美食图像构建而成。它要求模型不仅能看图，还要懂中国味。&lt;/p&gt;&lt;p&gt;接下来，我们先是自己尝试了编写微调脚本，但效果并不佳。于是我们决定直接让 AI 全程接管，来一次 vibe fine-tuning（氛围微调）！&lt;/p&gt;&lt;p&gt;给 PGX 装上 Claude Code，并配置好 MiniMax-M2.1。然后下达一小段指令：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;你是一位出色的 AI 模型微调专家，你现在需要在一台拥有 128GB 统一内存的联想 ThinkStation PGX 上微调一个 30B 大小的 MoE 模型。在这里，models/Qwen3-VL-30B 文件夹中是已下载的 Qwen3-VL-30B-A3B-Instruct 模型，FoodieQA 文件夹中是 lyan62/FoodieQA 数据集。请使用 FoodieQA 数据集完成对 Qwen3-VL-30B-A3B-Instruct 模型的进一步微调。&lt;/p&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAFYjISNZko35y7raGCbw1fIsRRp3few9KAJqJAWSrdu4iaIB8JiawuEPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.2092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527950" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/a49db964-d77f-41cb-8882-b2cb919662ab/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来就是等待。两三个小时后，训练方案终于确定下来。以下是训练稳定后 nvtop 监视画面。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAghCNzPibFDCthLo8ibG6aiczoG71fKbOHnhjo0ianR1GaYqzeicN3oSvjVQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.41929499072356213" data-type="gif" data-w="1078" type="block" data-imgfileid="503527957" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b1f9e8cb-9d44-44b2-bab6-7ad167c929de/640.gif" data-order="1" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可以看到，对于该任务，GPU 使用率大体在 23% 左右，显存（统一内存）的占用接近 60GB。&lt;/p&gt;&lt;p&gt;要知道，这 60GB 的显存占用，如果是消费级显卡早就炸了三次了，但在 ThinkStation PGX 上，显存条只吃了一半，它甚至游刃有余。更令人印象深刻的是温控。得益于出色的散热设计，在开了暖气的房间里，ThinkStation PGX 的 GPU 最高温度也仅达到了 40℃。&lt;/p&gt;&lt;p&gt;一夜之后，微调完成。在验证集上的损失从 4.03 成功降到了 1.06，下降了 74%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAJ2vv6xib7VCgKp2WUafTr4jID89da3mg14KLc3Qf2hB3uMnwo3n44mA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6832971800433839" data-s="300,640" data-type="png" data-w="461" type="block" data-imgfileid="503527951" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ce51367e-2baf-4cb2-bd34-40a9e33f39c4/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;来一张我们自己拍摄的食物照片来简单试试。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAArTTIicsI9ibKml8oWcpbx2mQpsHPzAACeSPJXqQXHia50Ht30zTichV9g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.5185185185185185" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527953" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/023683cd-22ad-43e9-a28d-7152e1ef0118/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAdkB1DbJFFB0s7v5mX0FLXiaibD2t6HGUevLA0UlSibRvpQeRmJZF9RrDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.550761421319797" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527954" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/4920ef56-3021-49ef-9645-d19b976df625/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;结果大体正确，这个微调过的 Qwen3-VL-30B-A3B-Instruct 正确识别了中间的阳春面，并正确地指出了其属于淮扬菜，不过它也忽略了旁边的蟹黄（确实有点难以辨认）。&lt;/p&gt;&lt;p&gt;整体体验下来，联想 ThinkStation PGX 展现出了几个让开发者无法拒绝的优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;从容加载&lt;/strong&gt;：128GB 内存意味着我们可以不需要任何量化，甚至可以直接加载 FP16/BF16 精度的原始模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;大胆训练&lt;/strong&gt;：可以直接开启较大的 Batch Size，不用担心 OOM，训练效率成倍提升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;英伟达原生体验&lt;/strong&gt;：基于 Linux+CUDA，可以直接 clone 官方的微调代码库，配置好环境，一行命令 bash finetune.sh 直接开跑，没有适配的痛苦。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;结论很明显：&lt;strong&gt;联想 ThinkStation PGX 是目前桌面上唯一能让 30B 多模态模型「跑得舒服」的设备&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;事实上，微调模型绝非 PGX 的唯一用途。打开想象力，我们能发现很多适合它的大显存 AI 场景，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;算法工程师的本地沙盒&lt;/strong&gt;：用于金融或医疗等数据敏感行业。工程师可以在本地完整加载 70B+ 模型验证想法，无需申请云端资源，数据绝不出域。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;野外科研的离线算力站&lt;/strong&gt;：对于珍稀动物监测或地质勘探，野外往往没有高速网络。PGX 可塞进背包，离线处理海量红外监控影像。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长视频生成的无限画布&lt;/strong&gt;：视频生成模型对显存需求随时间线性增长。PGX 的大内存能支持生成更长时间的连贯视频素材。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;具身智能的数字孪生&lt;/strong&gt;：在桌面运行高保真的 Isaac Sim 仿真环境，训练完成后直接部署到架构同源的 Jetson 模块，零迁移成本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数字艺术家的私有风格库&lt;/strong&gt;：长期累积创作者自己的 Style Checkpoint，本地运行风格迁移，不用担心独家画风泄露。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;为什么选择联想 ThinkStation PGX？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然核心芯片和架构与英伟达的参考设计（DGX Spark）一致，为什么我们更推荐联想的 PGX？&lt;/p&gt;&lt;p&gt;答案在于两个词：&lt;strong&gt;工程&lt;/strong&gt;与&lt;strong&gt;服务&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;驯服 240W 功耗的蜂窝美学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GB10 是一颗性能强悍的超级芯片，但其满载功耗高达 170W，整机功耗更达到 240W。在一个 1 升的极小空间内压制这种热量，如果设计不当，很容易导致积热降频，甚至变成桌面烫手宝。&lt;/p&gt;&lt;p&gt;联想没有简单照搬公版设计，而是沿用了 ThinkStation 家族标志性的「蜂窝状」散热设计。这种源自空气动力学的设计理念（灵感源于阿斯顿・马丁的进气格栅），最大化了机箱前后的进出风效率。&lt;/p&gt;&lt;p&gt;实测表明，相比于初期公版参考设计可能存在的积热问题，PGX 表现得更加「冷静」。对于需要连续跑几天几夜微调任务的开发者来说，这种基于 Top 1 工作站大厂的工程稳定性，意味着你不用半夜起来担心训练因过热而中断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据保险&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于购买 PGX 的企业和科研用户来说，最值钱的往往不是机器本身，而是硬盘里的数据：那些私有的行业数据集、微调后的模型权重、以及核心算法代码。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAw4gLEVCNd27YsBd72iae12KfRFnYCY4ahGrDJDvv5HA7ibTmMJfmJic1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527955" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/0cc2b8b1-d652-4d44-a03c-732d515db106/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为中国市场份额第一的专业工作站品牌，联想给 PGX 配备了中国区独享的顶格服务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3 年上门保修&lt;/strong&gt;：相比于海淘水货或部分竞品可能仅提供的 1 年质保，这是面向生产力用户更合理、也更负责任的保障方案。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;硬盘数据恢复服务&lt;/strong&gt;：这是最打动企业用户的痛点。万一硬盘发生物理损坏，联想提供专业的数据恢复服务。对于科研实验室等数据至关重要的机构来说，这项服务的价值远超机器价格本身。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;售后技术支持&lt;/strong&gt;：联想工作站在全国拥有超过 1 万名认证工程师，2300 多个专业服务站，100% 覆盖 1-6 线城市，能保证 7x24 小时在线支持。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;升级空间：双机 NVLink&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你觉得 128 GB 依然不够用，PGX 还预留了升级空间。&lt;/p&gt;&lt;p&gt;借助内置的 NVIDIA ConnectX-7 网络技术，你可以将两台 ThinkStation PGX 通过高速互联。在 NVLink 的加持下，两台机器瞬间化身为一个拥有&lt;strong&gt; 256 GB 统一内存&lt;/strong&gt;的超级怪兽。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAhwCw3k69fCAP2A9CcZuN3P3c4Bpn1gLCbWKhow073SzSF26Id5PC3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6416666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527956" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/cddb1bde-5c2d-4d97-8f49-baf256a666b8/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这时，你的桌面算力上限将被进一步打破：你甚至可以尝试挑战上千亿参数量级别的超大模型推理。从 1 升小盒子到双机并行，这给了开发者极大的灵活性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算力普及的「最后一公里」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回顾这几天的体验，联想 ThinkStation PGX 给我们留下的最深印象，并不是某个具体的跑分数字，而是它带来的「&lt;strong&gt;确定性&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;在过去，想要在本地搞定 30B 级别以上的多模态模型微调，总是充满了不确定性：显存会不会爆？量化会不会掉点？算子能不能跑通？&lt;/p&gt;&lt;p&gt;而 ThinkStation PGX 用 128 GB 的海量内存和原生的 CUDA 生态，把这些不确定性变成了一条平滑的直线。它填补了消费级显卡（显存太小）和工业级服务器（动静太大）之间那个巨大的真空地带。&lt;/p&gt;&lt;p&gt;至于大家都关心的价格，在拥有 128GB 统一内存和原生 CUDA 生态的前提下，&lt;strong&gt;ThinkStation PGX 1TB 版本售价为 31999 元，4TB 版本售价为 36999 元&lt;/strong&gt;。这仅仅相当于一块高端专业显卡的价格，却可以换来一台完整的、开箱即用的桌面 AI 超算。&lt;/p&gt;&lt;p&gt;如果要我以编辑的身份给一个购买建议，我的答案是：对于深陷显存焦虑的专业开发者而言，&lt;strong&gt;联想 ThinkStation PGX 不仅值得买，甚至可能是目前 4 万元以内唯一的最优解&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;不妨算一笔账：在市面上，要获得同等规模（128GB）的显存容量，你通常需要购买昂贵的专业级计算卡，或者租用按小时计费且数据需上传云端的 A100 实例。而 ThinkStation PGX 以不到 3.7 万元的顶配价格，提供了一个拥有海量统一内存、原生 CUDA 生态且数据完全私有的桌面级方案。&lt;/p&gt;&lt;p&gt;如果你只是偶尔跑跑 7B 小模型，它或许略显奢侈；但对于那些受够了环境配置错误的算法工程师、对数据安全有极高要求的科研团队，以及希望快速验证 idea 的初创公司来说，PGX 买到的不仅仅是硬件，更是「不折腾」的权利：让你不必再为显存溢出修改代码，也不必再为跨平台移植浪费时间。这种&lt;strong&gt;让开发者回归创造力&lt;/strong&gt;本身的价值，远超机器售价本身。&lt;/p&gt;&lt;p&gt;这或许才是 AI 基础设施普及过程中，最动人的「最后一公里」。&lt;/p&gt;&lt;p&gt;如果你也受够了在 OOM 的边缘试探，ThinkStation PGX 值得成为你桌面上的下一台设备。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>OpenAI的首款硬件：是AI耳机，今年销量要冲5000万</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:33:40 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/11e3dc79-d6e5-4b72-88d1-4e44558abb1a/1768278719983.png" style="width: 700%;" class="fr-fic fr-dib"&gt;以人工智能技术闻名的 OpenAI，终于也要搞硬件了，而且一上来就是和苹果正面对标。&lt;/p&gt;&lt;p&gt;最近，有关 OpenAI 硬件的消息越来越多。&lt;/p&gt;&lt;p&gt;今天一早，数码博主 @智慧皮卡丘透露了关于 OpenAI「To-go」硬件项目的最新细节。&lt;/p&gt;&lt;p&gt;该硬件已被确认是&lt;strong&gt;一款取代 AirPods 的特殊音频产品，内部代号为「Sweetpea」（香豌豆）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;据他所说，在制造端，富士康已接到通知，要求在 2028 年第四季度前为五款设备做好量产准备。目前这些设备尚未全部揭晓，但一款家居设备和一款手写笔仍在研发考量中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaev2XJQyC8Ga5Z85b4dNlWJCbOibXLQB2P5s0JWPVcGiaGarmEmyP8wRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528105" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5bc7eabe-54e4-4829-ae19-de07265a308f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 部分截图。原文链接：https://x.com/zhihuipikachu/status/2010745618734759946&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;多方消息来源反复确认了同一个信息：由于苹果前首席设计官 Jony Ive 团队的全力投入，&lt;strong&gt;「Sweetpea」目前处于最高优先级。该产品预计于 9 月左右发布，OpenAI 给它的第一年预估出货量高达 4000-5000 万部&lt;/strong&gt;（作为对比，苹果 AirPods 系列的年出货量约在 6000-7000 万支左右）。目前已知的具体细节如下，如下参考图所示。&lt;/p&gt;&lt;p&gt;在工业设计上，据称设计「独一无二、前所未见」，主机采用金属材质，外形酷似卵石（eggstone）。&lt;/p&gt;&lt;p&gt;在佩戴方式上，在「卵石」内部装有两个胶囊状单元，取出后可佩戴在耳后。&lt;/p&gt;&lt;p&gt;在核心性能上，主处理器目标锁定为 2nm 制程的智能手机级芯片（目前最看好三星 Exynos），因此可以让大部分 AI 推理任务在本地运行。此外，项目还开发了一款定制芯片，允许用户通过指令控制 Siri 来「替代 iPhone 的操作」。&lt;/p&gt;&lt;p&gt;在成本与定位上：由于选材和组件规格更接近手机，外界担心其 BOM（物料清单）成本极高，但据称该设备的功能将比现有产品更强大。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsac3fv7bvWn2TvfWOsRXdsukB93hFaiaNAhru6s5iaib7fKGatosE4MBMog/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8379629629629629" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528107" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9272e968-6864-4ab5-a0f3-60beee9a043b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在评论区，这位博主回答了更多关于这款设备的信息，比如「它的发声是通过骨传导，还是内置了扬声器？」，答案是「目前没有采用骨传导的计划。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsa6MTyV8rkh0BDkR4LibVpVZdoTZkzMNGoxxA50NeL5icEzRrvnuVDrpNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528109" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2a4b3109-8cba-49a5-8970-e5efcb03b4c7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;多位网友认为这款设备很酷，如果真的可以取代 Airpods，绝对是跨时代的产品。毕竟是苹果传奇设计师 Jony Ive 操刀的产品，期待可以拉高一些。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaSEQbdsJ9HopWTXJdwibnWp6w15kyKRX3jiaCHxQK2rY2QniabOCLThflg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528111" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e443b922-3b26-4c41-835b-6e06aba01b10/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;「这看起来是 OpenAI 进军可穿戴 AI 市场的一次大胆尝试。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYRT36XIOhUzM8GXaaxaict7YJXjTrK6kRxDQODqIXs2GpOXjlUQav7g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.16203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528113" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d32dc35b-3f59-4d9d-99af-334698ad3749/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;去年 5 月，OpenAI 宣布以 65 亿美元的价格收购了由苹果前首席设计官 Jony Ive 创办的秘密硬件初创公司 io，这是 OpenAI 自成立以来规模最大的收购案。双方在 2025 年 7 月正式完成了团队整合。&lt;/p&gt;&lt;p&gt;io 原来的目标是开发一种「为 AI 时代而生」的新型计算设备，旨在打破目前以智能手机屏幕为核心的交互逻辑，寻找一种更自然、更具直觉的 AI 交互形态。至少在 OpenAI 耳机上，我们能看到这种思路的延续。&lt;/p&gt;&lt;p&gt;目前，虽然 OpenAI 的智能硬件仍然处于保密状态，但通过越来越多的爆料，我们已经可以逐渐勾画出它的大致样貌了。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考内容：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theinformation.com/articles/openai-ramps-audio-ai-efforts-ahead-device&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/kimmonismus/status/2010804115543114099&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为推出软工代码智能体SWE-Lego，解锁SFT训练极致性能</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:30:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ed362392-6d9c-4a7e-b1b5-1043314720f5/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&amp;ldquo;软工任务要改多文件、多轮工具调用，模型怎么学透？高质量训练数据稀缺，又怕轨迹含噪声作弊？复杂 RL 训练成本高，中小团队望而却步？&amp;rdquo;&lt;/p&gt;&lt;p&gt;华为研究团队推出 &lt;strong&gt;SWE-Lego&lt;/strong&gt;， 仅基于监督微调（SFT）的软件工程代码智能体，无需复杂 RL 流程，在 SWE-bench Verified 基准中斩获同等规模开源模型 SOTA，甚至超越部分更大规模闭源模型！项目已开源，代码、模型和全部数据一键获取！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;arXiv 地址：https://arxiv.org/abs/2601.01426&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub 地址：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://github.com/SWE-Lego&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace 地址：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://huggingface.co/SWE-Lego&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;SWE-Lego 具有三大创新，包括数据、训练和测试时扩展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 混合数据集构建：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;双数据管道互补&lt;/strong&gt;：GitHub 真实 PR 数据 + 注入真实场景 Bug 的合成数据，产出 32k 高质量任务实例 + 18k 专家轨迹；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;严格轨迹筛选&lt;/strong&gt;：过滤 Git 历史泄露、工具错误等噪声，重用部分解决的优质轨迹，提升 SFT 训练有效性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 改进的监督微调：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;两大亮点&lt;/strong&gt;：① 步骤级错误掩码，让模型从长轨迹中学习有效子轨迹；② 课程学习，按交互轮次分级提升任务难度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能提升&lt;/strong&gt;：比传统 SFT 在不同模型上提升 2~4%，筑牢 SOTA 基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 测试时扩展策略（TTS）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;扩展优先级&lt;/strong&gt;：先串行扩展（增大轨迹最大交互轮数）至饱和，再分配资源给并行扩展（多备选答案选最优）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;打分器优选&lt;/strong&gt;：生成式打分器在并行扩展中，全程优于回归式打分器，适配不同模型规模与测试预算。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在软件工程领域，Code Agent 需要处理复杂的任务：修复 bug、重构代码、理解大型代码库。这些任务要求 Code Agent 具备&lt;strong&gt;长序列推理、多文件操作和工具使用&lt;/strong&gt;等能力。现有的训练方法通常需要复杂的训练范式，比如强化学习（RL）或者 RL 和 SFT 的迭代组合。&lt;/p&gt;&lt;p&gt;这些方法虽然有效，但计算成本高，训练过程复杂。能否用更简单的方法达到同样的效果？&lt;/p&gt;&lt;p&gt;华为的研究团队提出了 &lt;strong&gt;SWE-Lego，一个仅基于监督微调（SFT）的软工代码模型的解决方案&lt;/strong&gt;。在 SWE-bench Verified 基准测试上基于 Qwen3 系列模型作为起始模型，经过 SFT 之后得到 SWE-Lego-Qwen3-8B 和 32B 分别达到 42.2% 和 52.6%，&lt;strong&gt;达到了开源模型的 SOTA 水平，并超越了一些更大规模的闭源模型&lt;/strong&gt;。基于测试时扩展策略（TTS）可以进一步把性能提高 6~7%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85vGYcMUqPLFJw5FDvLG6p4n105QiajNXViboAhGic0no60zl9Xaib3vg7NA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527131" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/303b5186-1e49-430a-9d96-d89fcdfed42f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1：SWE-Lego 系列模型在 SWE-bench Verified 上的性能对比，在同等规模模型中表现达到 SOTA&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、挑战与动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;软件工程任务与传统的单文件编程任务有着明显区别&lt;/strong&gt;：一个 bug 修复可能涉及代码项目里多个文件的修改，需要多轮工具调用（读取文件、执行测试、编辑代码等），必须在真实的代码库环境中验证修复效果，还需要理解代码逻辑、定位问题、设计修复方案等复杂推理能力。&lt;/p&gt;&lt;p&gt;为了训练具备软件工程项目级代码编写能力的代码模型，研究者们尝试了多种方法。强化学习（RL）虽然不需要预定义的轨迹，但训练成本极高。复杂组合方法将多种训练范式结合，比如 SFT 和 RL 的迭代训练，进一步增加了训练复杂度。更重要的是，高质量的训练数据稀缺。现有的数据集要么规模有限，要么缺乏可执行环境，要么难以扩展到足够大的规模。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、SWE-Lego 的三大核心组件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 包含三个核心组件：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85lBhxibD6hKhdgRupdPUsiaJafSV05zaEu0LtFFFbNibyjCAScYiajtRqgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.438423645320197" data-s="300,640" data-type="png" data-w="1015" type="block" data-imgfileid="503527133" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9d19b42c-8640-441e-90c4-3117c8152d85/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：SWE-Lego-Qwen3-32B 的性能提升分解，混合数据集贡献最大（+25.6%），改进的 SFT 贡献 + 3.8%，TTS 贡献 + 6.2%&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从图 2 可以看到每个组件的贡献：混合数据集贡献 + 25.6%（最大贡献），改进的 SFT 贡献 + 3.8%，测试时扩展贡献 + 6.2%。总计从基线 23.2% 提升到 58.8%，提升了 35.6 个百分点。这些结果清楚地表明，好的数据集是性能提升的最大驱动力，而改进的 SFT 和测试时扩展提供了不错的增量收益。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件一：混合数据集构建&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 数据集包含 32,119 个高质量任务实例，18,110 个验证轨迹（其中 14,110 个完全解决，4,000 个半解决），覆盖 3,251 个代码仓库。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SWE-Lego 采用混合数据构建策略&lt;/strong&gt;，结合真实世界数据和合成数据。真实世界数据来自严格筛选的 GitHub Pull Requests （PRs），这里的 PRs 中非测试文件作为 Golden Patch, 也就是这个任务的解决方案。真实 PR 数据具有贴近生产环境的优势，能够提供真实的 bug 的复杂性，真实的任务参考 SWE-rebench [1]。但是&lt;strong&gt;真实数据数量有限，且每个任务需要独立的沙箱环境，成本较高&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;参考 SWE-smith [2] 的通过故意引入 Bug 来合成软工任务的方式，SWE-Lego 通过 AST 转换和 LLM 重写，基于真实代码仓得到相应的合成软工数据，对可以通过测试的代码库故意引入一些 Bug。具体地，AST 转换提取抽象语法树（AST）并应用随机变换，如移除条件 / 循环、修改运算符或依赖关系，而 LLM 重写则提示模型使用函数头和文档字符串等信息重写代码。引入 Bug 的补丁进行反转就可以得到解决这个任务的 Golden Patch。&lt;strong&gt;合成数据具有可扩展、成本低、多个任务可共享沙箱的优势，但复杂度相对较低&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在下一步，&lt;strong&gt;团队对真实和合成数据采用测试驱动的方式去得到验证后的软工数据实例&lt;/strong&gt;，筛选出合格的软工任务。具体地，在应用 Golden Patch 前可以通过的测试在应用 Golden Patch 之后仍然可以通过， 而应用 Golden Patch 前不通过的测试在应用 Golden Patch 之后也需要通过。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85bXdevAiaQDibeoMc08U2L0pYDoLIrWuoibBsj9icicNPSeg3DSYxQRMWdeg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.44814814814814813" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527134" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2dc7c643-6445-414d-a104-0b9830e869c5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：SWE-Lego 数据管道，结合真实 PR 和合成的软工任务实例，基于专家模型去生成可执行的轨迹用于 SFT 训练&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真实数据提供深度（复杂性和真实性），合成数据提供广度（数量和覆盖范围）&lt;/strong&gt;。两者互补：真实数据提供主要收益但难以扩展，合成数据通过进一步扩展提供额外收益。实验证明，增加合成数据可以显著提升有效轨迹数量和下游性能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85xia36DysWTXYFxLWibXjz24g5VNhpAldaYBJVyC9aK2klkm8R5o6HKag/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527135" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c75ce22d-38c6-425e-943a-570d855069d5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 4：随着合成实例的增加，有效轨迹数量显著增长&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85XibhMDqGBpCxvjE0NXFQrKk54rn4qOQ3qZy0fH9Doy7icibemNQNwF4YA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527136" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/be29d2b9-3f37-471a-8685-a2bf1f18f7e4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 5：随着混合数据的增加，模型的性能逐步提升&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;轨迹质量优化&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了确保训练数据的质量，SWE-Lego 实施了严格的轨迹生成和验证流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;防止解决方案泄露&lt;/strong&gt;：最近 SWE-Bench 社区 [3] 发现，LLM 可能通过查看 Git 历史来 &amp;quot;作弊&amp;quot;，直接找到正确答案。为了防止这种解决方案泄露，对于真实实例，SWE-Lego 移除问题创建日期之后的所有提交和日志消息，使未来的修复不可见；对于合成实例，由于有 bug 的版本在无 bug 的版本之前（由于故意的 bug 注入），完全移除整个 Git 历史和所有日志，只暴露 buggy 代码库的单个快照。这迫使模型真正推理代码和测试，而不是从版本控制中读取答案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;处理工具调用错误&lt;/strong&gt;：在使用 Qwen3-Coder-480B-A35B-Instruct 作为教师模型时，观察到对 str_replace_editor 工具的频繁格式错误调用，例如将字符串传递给 view_range 或指定超出范围的行范围，导致工具失败并浪费交互预算。为了缓解这些错误，SWE-Lego 应用轻量级后处理：如果 view_range 是字符串，则在执行工具之前将其转换为整数；如果请求的行范围超过文件长度，则返回有效行的子集而不是引发错误，使得模型能够更可靠地检查代码。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;精简工具集&lt;/strong&gt;：虽然任务管理工具（如 task_tracker）已被一些最近的专有模型采用，但发现 Qwen3-Coder-480B-A35B-Instruct 无法有效使用它们，经常导致执行错误。因此，SWE-Lego 丢弃此工具，将工具集限制为四个基本操作：execute_bash、str_replace_editor、think 和 finish，以保持轨迹精简。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;轨迹过滤策略&lt;/strong&gt;：SWE-Lego 通过应用预测补丁并运行测试集来验证轨迹。如果轨迹通过所有测试，则分类为已解决，否则为未解决。然后，过滤低质量的已解决轨迹（例如，通过修改测试文件来 &amp;quot;作弊&amp;quot; 的轨迹），并重用部分解决轨迹（那些正确识别了所有相关文件但未能修复的轨迹）。这些部分解决轨迹提供了有价值的故障定位监督，我们发现加入此类数据会适当提升模型的性能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85aqgAJhnEwht3BZ4QicS0TLKlJalnticUCI1A4VSt0UnWpXLnYib523xIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527141" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8b929db2-f5ae-4e82-9abd-7278171bc345/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 6：轨迹生成中的关键实践，包括防止 Git 泄露、处理工具错误、精简工具集&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85ElzKdAowjXhPXIqeOYlbdA8tcY8V3vTuwzNBqP81icCcxcnNG4Vxasw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527143" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/cf49ae17-ef08-48e6-8360-5a458b005b1a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 1：SWE-Lego 的可验证的任务实例和有效训练轨迹的统计以及和其他 SWE 相关工作的数据对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;具体的数据统计和对比见表 1，可以看出 SWE-Lego 的混合数据管道提供了数量充足的、代码仓多样的、环境可验证的 SWE 任务实例和轨迹。&lt;/p&gt;&lt;p&gt;总结：混合数据集是性能提升的最大驱动力。真实数据与合成数据互补确保了数据数量，严格的轨迹验证确保了轨迹的质量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件二：改进的监督微调&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通常的监督微调将通过测试验证的整条轨迹拿去训练，但实际上在软工的场景，专家轨迹需要多轮在沙箱中交互得到最后的预测补丁，即使&lt;strong&gt;最终成功解决的轨迹也可能包含中间错误步骤&lt;/strong&gt;，盲目学习这些错误可能强化不良行为。另外，不同数据的难度不同，&lt;strong&gt;在训练初期让模型学习难题可能比较吃力&lt;/strong&gt;。针对这些情况，SWE-Lego 提出了两个改进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;改进 1：步骤级错误掩码&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：保持完整轨迹上下文，但只对正确的步骤计算损失。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Nk2uT6COC4ZqEwyUPAfWKLkHNkMa1MzicUoaynibNWMqBp0Msor8oQQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527144" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/56d1eb5f-7d82-44dd-99f2-f12669881376/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 7：步骤级错误掩码示例，错误步骤被掩码，模型只学习正确的操作&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实现方法：使用正则表达式识别终端环境提供的错误消息，对相应的模型响应应用错误掩码。关键是要排除因复现 bug 或执行测试文件而产生的错误。&lt;strong&gt;这种方法保持完整的轨迹上下文，但只对正确的步骤计算损失&lt;/strong&gt;，使模型能够学习正确的操作和恢复策略，而不会强化错误。通过强调学习正确操作，直接减少了核心推理失败，如 &amp;quot;错误实现&amp;quot; 和 &amp;quot;定位错误&amp;quot;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;改进 2：基于难度的课程学习&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：从简单任务开始，逐步增加难度。&lt;/p&gt;&lt;p&gt;SWE-Lego 探索了两种难度分类方法：&lt;strong&gt;基于模型的评分和基于轨迹轮数的启发式&lt;/strong&gt;。研究发现，轨迹轮数与解决率之间存在强负相关（相关系数 - 0.95）。基于这一发现，&lt;strong&gt;SWE-Lego 采用可以直接获取的指标，轨迹轮数，作为轨迹的难度指标&lt;/strong&gt;，将数据分为三个难度等级：简单（0-50 轮）、中等（50-70 轮）、困难（70-100 轮）。训练策略采用三阶段课程：先训练简单任务，再逐步加入中等和困难任务。这种课程学习与训练动态一致：首先让模型在 &amp;quot;简单&amp;quot; 任务上克服基本的 &amp;quot;无法复现&amp;quot; 错误，然后引入 &amp;quot;困难&amp;quot; 任务以发展避免 &amp;quot;超出最大轮次&amp;quot; 失败所需的战略规划。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85X4dibbQLI0oiaS2Y95fY3B09vmGgztwKMOBed6NfZVZRGCTqEJ9tsVkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527147" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0577f126-d803-4eae-bf87-f3b605984a57/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8：轨迹轮次与平均解决率之间的强负相关关系&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;训练过程分析&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过分析训练过程中的错误类型演变，可以清楚地看到模型的学习轨迹：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Ey25EvOiahC5oibIUnAYmHoJE0gy0ib0l1C4dPibduUfAqkiaR9WwAUicl9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527148" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/57b0e284-aa3d-465f-bf90-89ffdb951c6f/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9：训练过程中解决率的提升趋势&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Ogmgib5lx8xXCEVLr16s50IGrLjiaHXicvia442GORicv820pBZJoYAMic3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527149" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/84f31828-103e-4cbb-8fe8-d246ea1d44c6/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10：训练过程中错误类型的演变，从早期的 &amp;quot;无法复现&amp;quot; 到后期的 &amp;quot;错误实现&amp;quot;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;错误类型的变化：训练初期时 &amp;quot;无法复现&amp;quot; 错误占主导，表明模型此时缺乏对软工任务基本的理解能力；训练中期时 &amp;quot;无法复现&amp;quot; 比例大幅减少，但 &amp;quot;定位错误&amp;quot; 比例仍有较多，表明缺乏战略规划；训练后期 &amp;quot;错误实现&amp;quot; 成为瓶颈，表明从过程失败转向推理失败。&lt;/p&gt;&lt;p&gt;改进的 SFT（错误掩码 + 课程学习）带来 3.8% 的性能提升。在 SWE-bench Verified 上，SWE-Lego-Qwen3-8B 达到 42.2%，SWE-Lego-Qwen3-32B 达到 52.6%。通过渐进式训练和选择性学习，模型能够更有效地掌握复杂任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件三：测试时扩展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;测试时扩展（TTS）可以在不重新训练的情况下，通过在测试阶段分配额外的计算资源来提升性能。SWE-Lego 系统研究了两个正交维度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;维度 1：串行扩展 vs 并行扩展&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;SWE-Lego 研究了串行扩展和并行扩展之间的资源分配。串行扩展通过增加最大交互轮次实现，在低测试预算的区域非常高效。额外轮次都能获得环境反馈，使模型能够纠正错误并迭代改进解决方案。这使得串行扩展在预算有限时成为首选策略。然而，模型性能在约 100-140 轮后开始饱和，此时相比于串行扩展，更加需要并行扩展来提升性能。&lt;/p&gt;&lt;p&gt;并行扩展生成多个候选轨迹，用打分器选择最佳的轨迹。&lt;strong&gt;在串行扩展饱和后，并行扩展变得更加有效，因为每个独立轨迹探索解决方案空间的不同路径。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85k1QHfdWvBNrJB9nhG1mLtXMw1QBcL34Wvk1os5XtNveuaanvjaPFAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5268518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527150" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b5bb352e-b62d-4fef-8885-7fea41384c79/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 11：串行扩展和并行扩展的权衡，等延迟曲线显示了最优资源分配策略&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;有限的测试阶段计算预算下，应优先进行串行扩展；在串行扩展饱和后，将剩余计算资源分配给并行扩展&lt;/strong&gt;。图 11 中的等延迟等高线说明了这种权衡：在等效延迟下，最优分配随着总延迟预算的增加从顺序主导转向并行主导。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;维度 2：生成式 vs 回归式打分器&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;打分器用于从多个候选轨迹中选择最佳方案。SWE-Lego 比较了两种范式：回归式打分器和生成式打分器。&lt;/p&gt;&lt;p&gt;回归式打分器在模型上添加一个头输出，使用二元交叉熵损失训练，对整个轨迹转化为单个标量去打分。生成式打分器将验证表述为文本生成任务，预测 &amp;quot;是&amp;quot; 或 &amp;quot;否&amp;quot;，从输出 &amp;quot;是&amp;quot; 或 &amp;quot;否的&amp;quot;token 概率计算分数。生成式打分器的训练目标与预训练的下一个 token 预测目标对齐，可能更好地利用模型的固有知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85edYQZtPKoaUMyNLjU1nk8oCzflosCwaOaruCZug5Wxiaplkl2VsmZTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527151" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/eb87310c-d0e8-48c4-b96c-ae00c543d0f4/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 12：生成式打分器与回归式打分器的对比，生成式打分器在 K 值较大时持续改进&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 rollout 的个数（K 值）比较小时，生成式打分器与回归式打分器两者的性能相近；&lt;strong&gt;随着 rollout 的次数（K）的增加，回归式打分器趋于饱和，而生成式打分器持续改进&lt;/strong&gt;。对于 SWE-Lego-Qwen3-8B，在 K=16 时差距达到 2.8%（49.6% vs 46.8%）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85r2NrjLgQMcTTFGTTKUVPYicCcjJicXRVV6G1UsRErhx3eBTMr0DiagEdQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527152" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/ed9437fe-3f12-44e2-b6ba-e50f4c5b7cab/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 13：SWE-Lego 打分器与现有公开打分器的对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego-Verifier-8B 在 TTS@16 上达到 49.6%，超越了 OpenHands-Critic-32B（44.0%）和 R2E-Gym-Verifier-14B（47.0%）。除了绝对性能外，还观察到不同打分器范式的定性不同缩放行为。OpenHands-Critic-32B 采用回归式范式，在更高的 K 值下表现出性能下降，这是一个反直觉的结果，表明更大的候选池压倒了其判别能力。相比之下，生成式打分器（SWE-Lego 和 R2E-Gym）保持单调改进，趋向于 Pass@K 上限，进一步确认生成式表述提供了更稳健的缩放属性。&lt;/p&gt;&lt;p&gt;总结：测试时扩展可以在测试阶段带来额外提升。在测试的计算预算比较低的时候，串行扩展优先于并行扩展。生成式打分器在并行扩展中表现更优。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、结语与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 证明了&lt;strong&gt;轻量级方法也能达到 SOTA&lt;/strong&gt;，不一定需要复杂的 RL 或 SFT 和 RL 的迭代训练，SFT 也可以取得软工任务的 SOTA 性能。数据质量至关重要，&lt;strong&gt;混合数据集和严格验证是性能提升的关键。训练技巧的价值也不容忽视&lt;/strong&gt;，错误掩码和课程学习等看似简单的改进也带来了性能提升。&lt;/p&gt;&lt;p&gt;未来将探索更大模型和更多数据的组合，&lt;strong&gt;扩展到 Python 之外的其他编程语言和其他类型的代码任务，处理企业级的长序列、多文件任务&lt;/strong&gt;，并将 SWE-Lego 应用到真实的软件开发流程中。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考文献&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[1] Badertdinov, I., Golubev, A., Nekrashevich, M., Shevtsov, A., Karasik, S., Andriushchenko, A., ... &amp;amp; Yangel, B. (2025). SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents. arXiv preprint arXiv:2505.20411.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[2] Yang, J., Lieret, K., Jimenez, C. E., Wettig, A., Khandpur, K., Zhang, Y., ... &amp;amp; Yang, D. (2025). Swe-smith: Scaling data for software engineering agents. arXiv preprint arXiv:2504.21798.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[3] https://github.com/SWE-bench/SWE-bench/issues/465&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型中标TOP10里的黑马：中关村科金的应用攻坚之道</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:46:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ac803b5a-ebae-4bb1-9db4-8ce61e88d0d6/1768271983190.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;一份大模型中标数据报告，揭示了产业重心转移的清晰轨迹：应用类项目占比近六成，市场用真金白银为 &amp;ldquo;落地&amp;rdquo; 投票。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;2025 年，中国大模型产业在招投标市场上演了一场令人瞠目的 &amp;ldquo;狂飙&amp;rdquo;。智能超参数的监测数据显示，全年大模型相关中标项目数量达到 &lt;strong&gt;7539 个&lt;/strong&gt;，披露金额 &lt;strong&gt;295.2 亿元&lt;/strong&gt;，较 2024 年分别激增 &lt;strong&gt;396%&lt;/strong&gt; 与 &lt;strong&gt;356%&lt;/strong&gt;。市场正以前所未有的速度，将技术潜力兑换为商业订单。&lt;/p&gt;&lt;p&gt;更关键的结构性变化在于项目类型：&lt;strong&gt;应用类项目占比高达 58%&lt;/strong&gt;，在 2025 年 11 月甚至达到 63% 的峰值。这明确宣告，产业的焦点已从实验室的参数竞赛，彻底转向商业场景的价值验证。市场用最直接的预算分配，为大模型的发展路径投下了决定性的一票。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;市场转向：从 &amp;ldquo;技术占位&amp;rdquo; 到 &amp;ldquo;价值锚地&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的大模型中标市场，描绘出一条陡峭的指数增长曲线。这不仅意味着市场规模在膨胀，更揭示了价值重心在迁移。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuYVeYtzyMbImVLgNf2uVeQ1BHP8BC9Sqzw9hn09RBly0qdy9CFJxibA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7046296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527965" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b58f84a2-87a3-47bb-9bbe-c3a83e20add0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;根据智能超参数的分类，大模型项目被划分为算力、数据、大模型（基座 / 平台）和应用（智能体 / 场景解决方案）四大类。2025 年的数据清晰地显示，&lt;strong&gt;应用类项目以 58% 的数量占比一骑绝尘&lt;/strong&gt;，成为绝对主流。从季度趋势看，其占比从第一季度的 44% 一路攀升至第三季度的 61%，并在第四季度稳定在 60.5%。&lt;/p&gt;&lt;p&gt;与此同时，&lt;strong&gt;算力类项目金额占比最高（52.9%）&lt;/strong&gt;，但数量占比（27%）远低于应用类。这背后是一个关键的市场信号：随着 DeepSeek、通义千问 Qwen 等高性能开源模型的成熟，更多企业选择直接采购算力，调用或微调现有成熟模型，以快速构建自己的应用。大模型（基座 / 平台）类项目占比为 10%，其中智能体开发平台的采购成为重要组成部分。&lt;/p&gt;&lt;p&gt;行业分布同样耐人寻味。教科、政务、通信、能源、金融是项目数量排名前五的行业。其中，&lt;strong&gt;政务行业以金额占比约 40% 位居榜首&lt;/strong&gt;，这与各地政府将智算中心升级为与大模型强绑定的产业赋能中心密切相关。金融行业则在下半年展现出从算力投资向应用部署的明显转向。&lt;/p&gt;&lt;p&gt;从厂商格局看，通用大模型厂商（如科大讯飞、百度、火山引擎、阿里云等）和拥有广泛渠道的三大运营商是中标主力。然而，一个值得注意的现象是，像&lt;strong&gt;中关村科金、蚂蚁数科这样的垂类大模型厂商，凭借在金融等细分赛道的深耕，同样在中标市场占据了一席之地&lt;/strong&gt;。这印证了一个产业判断：当通用模型的能力差距趋于收敛，&lt;strong&gt;生态构建能力与场景掌控力&lt;/strong&gt;，正取代单纯的模型性能，成为新的竞争壁垒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;攻坚样本：中关村科金的 &amp;ldquo;行业深潜&amp;rdquo; 与 &amp;ldquo;场景破局&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在通用大模型厂商凭借全栈能力横扫市场的同时，另一条深耕垂直领域的路径同样结出了硕果。中关村科金，这家并非以通用模型见长的企业，正是这条路径上的一个典型攻坚者，其在中标市场的表现，精准映射了 &amp;ldquo;应用为王&amp;rdquo; 时代的核心逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkArLp0HCauialpszTDMEvkN5GU1LqqF7UVA7Gd09GiblBmFyooR7S7t9vw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="1.8583333333333334" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527966" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6bcf4175-1285-4af1-b161-ccc93e228e7f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;智能超参数发布的《中国大模型中标项目监测与洞察报告 (2025)》显示，&lt;strong&gt;中关村科金以 23 个中标项目入围 2025 年应用类大模型项目中标厂商 TOP10 榜单，是榜单中少数聚焦垂类场景的大模型厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其战略自始就锚定 &amp;ldquo;应用&amp;rdquo; 与 &amp;ldquo;落地&amp;rdquo;。中关村科金自 2023 年起便战略布局大模型平台，并沿着&lt;strong&gt; &amp;ldquo;平台 + 应用 + 服务&amp;rdquo; 的三级引擎战略&lt;/strong&gt;，推动垂类大模型在垂直行业和场景的应用落地，为 &amp;ldquo;应用为王&amp;rdquo; 提供了多个维度的注脚，其在金融、政务、工业、汽车、零售等多个赛道的全面落地，展现了垂类大模型厂商的独特竞争力。&lt;/p&gt;&lt;p&gt;在工业制造这一复杂且专业壁垒极高的领域，中关村科金展现出将前沿 AI 技术与传统产业深度融合的深厚功力。其助力中国船舶集团经济研究中心打造的&lt;strong&gt;船舶行业大模型 &amp;ldquo;百舸&amp;rdquo;&lt;/strong&gt;，融合了船舶领域百万级专业知识库与长文本推理能力，构建了智能问答、研报写作、文档解读、情报分析等行业智能体，有效推动了船舶行业 &amp;ldquo;数智大脑&amp;rdquo; 的建设。&lt;/p&gt;&lt;p&gt;针对有色金属冶炼等高能耗场景，中关村科金与南方有色金属公司合作，打造了&lt;strong&gt;广西首个有色金属行业大模型&lt;/strong&gt;，通过落地冶炼工艺优化、能源管理、设备智能运维等核心场景智能体，取得了关键生产环节的量化突破：将主操手操作频率降低 90%，温度控制偏差由 &amp;plusmn;15℃收窄至 &amp;plusmn;5℃，并助力综合能耗下降 8%。这标志着垂类大模型已能深入高能耗流程的核心环节，为工业绿色智能化转型提供了关键技术支撑。&lt;/p&gt;&lt;p&gt;在交通基建这类传统上被认为与 AI 技术距离较远的行业，中关村科金也成功开辟了智能化新路径。其与宁夏交建联合打造的&lt;strong&gt;交通基建垂类大模型 &amp;ldquo;灵筑智工&amp;rdquo;&lt;/strong&gt;，基于上万份行业规范、工程技术文档等高质量数据训练，使模型在专业问题上的回答准确率较通用大模型提升 40%。基于该模型构建的专业智能体，在实际应用中平均提效超 60%，不仅解决了工程师撰写施工方案、核算工程量等耗时费力的痛点，更通过智能成本预警等功能，推动了整个行业从 &amp;ldquo;经验驱动&amp;rdquo; 向 &amp;ldquo;数据 + AI 驱动&amp;rdquo; 的转型。&lt;/p&gt;&lt;p&gt;如果说在工业等传统领域的突破证明了其技术下沉的能力，那么在数字化程度最高、要求最严苛的金融行业，中关村科金的深耕则更凸显了其 &amp;ldquo;行业 Know-how&amp;rdquo; 的价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依据智能超参数报告，中关村科金在金融行业大模型项目中标厂商中位列第四&lt;/strong&gt;，仅次于百度云、科大讯飞、火山引擎等大厂，成为垂类厂商深耕金融赛道的标杆代表。其中标项目广泛覆盖智能客服升级、远程视频银行、智能风控合规、智能运营提效等核心业务场景。&lt;/p&gt;&lt;p&gt;中关村科金深耕金融领域多年，已服务 500 多家头部金融机构，包括 50% 以上百强银行及 70% 的信托机构，沉淀了深厚的行业 Know-how。依托其 &amp;ldquo;得助大模型平台 + 金融行业智能体平台&amp;rdquo; 的核心产品组合，中关村科金打造了覆盖 &amp;ldquo;营销 - 风控 - 运营 - 企业服务&amp;rdquo; 全链路的金融智能体矩阵，这并非简单的工具叠加，而是将大模型能力深度融入金融机构从获客、服务到风险管理的核心业务流程。&lt;/p&gt;&lt;p&gt;例如，中关村科金与&lt;strong&gt;中信券商&lt;/strong&gt;合作打造大模型财富助手，能够实时洞察市场动态与数据，精准匹配理财产品与投资组合，并自动生成专业营销话术，助力展业效率提升 3 倍；为&lt;strong&gt;某国有大型商业银行&lt;/strong&gt;提供全栈音视频服务，实现视频银行、合规双录、视频客服、视频会议等全场景统一接入管理；与&lt;strong&gt;中国电建财务公司&lt;/strong&gt;联合打造 &amp;ldquo;财神大模型&amp;rdquo; 及办公智能体，实现员工业务知识获取效率提升 70%；为&lt;strong&gt;百年人寿&lt;/strong&gt;打造的保险知识库问答智能体，问答准确率稳定在 90% 以上，知识获取效率提升 50%，赋能内部 17 个部门；为&lt;strong&gt;申万宏源证券&lt;/strong&gt;打造合规垂直领域专有大模型，赋能员工高效查询制度文件，筑牢业务合规防线。&lt;/p&gt;&lt;p&gt;在智能客服与数字人这一大模型落地最火热的赛道，中关村科金的表现尤为突出，已成为该领域的核心参与者。IDC《中国智能客服市场份额，2024》报告显示，中关村科金位居中国智能客服市场第四，位列垂类大模型厂商第一。根据智能超参数的中标报告，&lt;strong&gt;在 &amp;ldquo;智能客服 &amp;amp; 数字人&amp;rdquo; 应用场景，科大讯飞、百度、中关村科金是中标项目数量排名前三的厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;中关村科金的核心支撑源于自研的得助智能客户平台 5.0，这一覆盖营销服全场景的新一代人机协作智能平台，以 &amp;ldquo;人类员工 + 数字员工&amp;rdquo; 协同为核心，通过多智能体深度联动，让数字员工成为人类员工的专业伙伴与高效延伸。其解决方案已成功赋能金融、汽车、零售、跨境出海、政务民生等多个行业领域，形成了兼具广度与深度的行业实践图谱。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;汽车行业&lt;/strong&gt;，中关村科金的解决方案已深度融入客户运营全链路。例如，其与&lt;strong&gt;丰田&lt;/strong&gt;合作，通过大模型语音智能体进行老客精准营销外呼，在实现超 60% 高接通率，激活沉睡客户；为&lt;strong&gt;岚图汽车&lt;/strong&gt;构建的销售洞察质检平台，则将销售流程合规性提升 70%。这些实践表明，中关村科金正将智能客服从传统的服务支持角色，升级为驱动销售增长与客户体验升级的核心引擎。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;零售与消费领域&lt;/strong&gt;，面对海量、高频的客户咨询与严苛的服务体验要求，中关村科金为&lt;strong&gt;瑞幸咖啡、添可、老板电器&lt;/strong&gt;等知名品牌提供了从智能应答、全渠道服务到全量质检的一体化方案。这些方案不仅有效应对了大促期间的咨询洪峰，更通过智能化工具将客服中心从成本部门转变为提升客户满意度、挖掘服务价值的关键环节。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;全球化服务&lt;/strong&gt;方面，通过构建支持多语种实时互译、全渠道智能路由的 Instadesk 全球客户联络中心解决方案，中关村科金帮助&lt;strong&gt; Imou 乐橙、阿里巴巴国际站&lt;/strong&gt;等出海企业攻克了跨时区、跨文化的服务难题，实现了服务效率与全球用户满意度的双重提升；也为 &lt;strong&gt;UniUni &lt;/strong&gt;这样的北美本地物流平台，以及&lt;strong&gt;泰国大都会水务局&lt;/strong&gt;这样的海外公共服务机构，提供了稳定、高效的多语言智能客服支持，成功将服务能力从企业出海延伸至本地化公共服务领域。&lt;/p&gt;&lt;p&gt;这些遍布多行业的落地案例共同表明，中关村科金的智能客服解决方案不再是简单的问答工具，而是深度嵌入客户旅程、与业务流程紧密耦合的 &amp;ldquo;价值挖掘引擎&amp;rdquo;。这正契合了当前大模型应用从 &amp;ldquo;功能实现&amp;rdquo; 向 &amp;ldquo;业务赋能&amp;rdquo; 演进的核心趋势。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;未来展望：2026，价值交付的深水区与垂类厂商的护城河&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标数据，已经为 2026 年乃至更远未来的发展轨迹画下了清晰的延长线。市场增长的 &amp;ldquo;陡峭曲线&amp;rdquo; 或许会逐渐平缓，但竞争的 &amp;ldquo;深度曲线&amp;rdquo; 将陡然加剧。行业将全面驶入&lt;strong&gt;价值的 &amp;ldquo;深水区&amp;rdquo;&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一，ROI 成为硬指标：从 &amp;ldquo;成本中心&amp;rdquo; 到 &amp;ldquo;利润引擎&amp;rdquo; 的证明之战。&lt;/strong&gt; 随着大模型技术本身日趋成熟和开源化，获取先进 AI 能力的门槛正在迅速降低。2026 年，企业客户将不再满足于 &amp;ldquo;拥有大模型&amp;rdquo; 的演示效果，而是会苛刻地追问每一个 AI 项目的投资回报率（ROI）。这意味着，大模型必须从 &amp;ldquo;成本中心&amp;rdquo; 证明自己作为 &amp;ldquo;利润中心&amp;rdquo; 或 &amp;ldquo;效率引擎&amp;rdquo; 的价值。峰瑞资本创始合伙人李丰的判断正在成为行业共识：AI 投资将进入 &amp;ldquo;第三阶段&amp;rdquo;，即投资真正落地、能挣到钱的应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二，行业 Know-how 与高质量私有数据，将构筑起最坚固的护城河。 &lt;/strong&gt;当通用模型的底层能力可以通过 API 便捷获取时，决定应用效果的将不再是模型的通用性能，而是对特定行业业务流程、专业术语、合规红线的深度理解，以及基于私有数据训练出的 &amp;ldquo;领域专家&amp;rdquo; 能力。中关村科金为中国电建财务公司打造的 &amp;ldquo;财神大模型&amp;rdquo;，与宁夏交建用上万份规范训练的 &amp;ldquo;灵筑智工&amp;rdquo; 大模型，其价值核心正在于此。这些基于海量、高价值、非公开行业数据构建的垂类模型，不仅效果远超通用模型，更因其数据资产的独特性和专业性，形成了竞争对手难以短时间复制的壁垒。未来，&amp;ldquo;数据资产化&amp;rdquo; 与 &amp;ldquo;知识工程化&amp;rdquo; 的能力，将比单纯的算法创新更为关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三，应用形态将从 &amp;ldquo;单点智能工具&amp;rdquo; 演进为 &amp;ldquo;全链路业务智能体&amp;rdquo;。&lt;/strong&gt; 当前的应用大多集中于客服、问答、内容生成等单点环节。下一步，大模型将更深入地与业务流程融合，进化为能够自主完成复杂任务的 &amp;ldquo;业务智能体&amp;rdquo;（Agent）。未来的智能客服将不再是孤立的问答机器人，而是融入客户旅程，能够主动进行销售外呼、完成复杂业务办理、甚至进行客户情绪安抚与挽留的 &amp;ldquo;全能型数字员工&amp;rdquo;。这要求供应商提供的不是单点产品，而是一整套能够与企业现有 IT 系统深度集成、随业务需求灵活编排的智能体生态系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGib2wScIJJRS3gBdbXdGaNic1ooYib28CmErmYgno8QrjDaoRE2YwKYWw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527998" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cfd2e9ac-9259-41e0-b7e5-1f31db85a9b2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;第四，生态协同将成为主流，垂类厂商与通用平台的关系从 &amp;ldquo;替代&amp;rdquo; 转向 &amp;ldquo;共生&amp;rdquo;。&lt;/strong&gt; 未来的市场格局很可能不是 &amp;ldquo;你死我活&amp;rdquo; 的替代关系，而是分层协作的共生生态。像中关村科金这样的垂类应用厂商，将更专注于在特定行业深挖场景，打造开箱即用的行业智能体解决方案；而通用大模型厂商和云厂商，则提供稳定、高效、低成本的算力与模型基座。&lt;strong&gt;中关村科金携手华为云、阿里云、百度智能云、火山引擎、亚马逊云科技、超聚变等企业共同发布的 &amp;ldquo;超级连接&amp;rdquo; 全球生态伙伴计划，正体现了这种开放协作的趋势。&lt;/strong&gt;2026 年，能否融入主流生态、能否与上下游高效协同，将决定一家厂商的市场边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标狂飙，是中国大模型产业从技术狂热走向商业理性的成人礼。市场用近 300 亿的订单，宣告了 &amp;ldquo;应用落地&amp;rdquo; 时代的正式开启。&lt;/p&gt;&lt;p&gt;2026 年的 &amp;ldquo;价值深水区&amp;rdquo;，将是检验真功夫的战场。大厂之外，像中关村科金这样，凭借对行业的深刻理解与扎实的产品和价值交付能力，已然为企业级大模型和智能体厂商如何穿越周期、赢得市场，提供了一个清晰的范本。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，梁文锋署名开源「记忆」模块，DeepSeek V4更细节了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:18:05 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/30c33348-2e2f-4927-8387-a39e06b425ed/1768270430059.png" style="width: 700%;" class="fr-fic fr-dib"&gt;就在十几个小时前，DeepSeek 发布了一篇新论文，主题为《Conditional Memory via Scalable Lookup:A New Axis of Sparsity for Large Language Models》，与北京大学合作完成，作者中同样有梁文锋署名。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALWDibzfe0HzEE5mIybPwTIAI5uGiaI0QA1ZZqyzr79hq8C0bwgj2SOiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528058" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8300495e-2055-4ff9-abf8-9873f1500199/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;简单总结一波&lt;strong&gt;这项新研究要解决的问题&lt;/strong&gt;：目前大语言模型主要通过混合专家（MoE）来实现稀疏化，这被称为「条件计算」。但是，现有的 Transformer 缺少原生的知识查找机制，只能被迫通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;针对这一现状，&lt;strong&gt;DeepSeek 提出了条件记忆（conditional memory），从而与 MoE 的条件计算互补，并通过引入一个新模块 Engram 来实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，模块「Engram」相关的实现已经上传到了 GitHub。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA86NTkhF1jNYqnOSG9OAujyOVQa3cUGicFmAPEXKXroicohumgL38XGqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528060" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c16a6833-4c22-46d2-a7f8-a93402bade79/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;项目地址：https://github.com/deepseek-ai/Engram&lt;/p&gt;&lt;p&gt;这让网友们感慨：「DeepSeek is back！」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALjBOxiceaogbXLPCibElgW4JDeWTo2491OtK0YJTS7emWDCWWCPJh3WA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9717514124293786" data-s="300,640" data-type="png" data-w="1062" type="block" data-imgfileid="503528062" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0a406ecb-aa43-4a96-923a-1b2ebd0b28f6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，结合元旦期间公布的研究《mHC:Manifold-ConstrainedHyper-Connections》，我们可以明确的是 DeepSeek v4 的模样愈发清晰，就等上新了！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;除了条件计算（MoE），LLM 还需要一个独立的条件记忆 Engram&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MoE 模型通过条件计算实现了模型容量的扩展，但现有的 Transformer 架构缺乏原生的知识查找原语，只能通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;为了解决这一问题，DeepSeek 提出了条件记忆（conditional memory）这一与条件计算互补的稀疏化维度，并通过 Engram 模块加以实现。Engram 在经典 𝑁-gram 嵌入的基础上进行了现代化改造，使其能够以 O (1) 时间复杂度完成知识查找。&lt;/p&gt;&lt;p&gt;通过形式化提出稀疏性分配问题，DeepSeek 还发现了一条&lt;strong&gt;呈 U 型的扩展规律&lt;/strong&gt;，用以刻画神经计算（MoE）与静态记忆（Engram）之间的最优权衡关系。&lt;/p&gt;&lt;p&gt;在这一规律的指导下，&lt;strong&gt;DeepSeek 将 Engram 扩展至 270 亿参数规模，并在严格等参数量、等 FLOPs 的条件下，其整体性能显著优于纯 MoE 基线模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;尤为值得注意的是，尽管记忆模块本身主要被用于提升知识检索能力（如 MMLU 提升 +3.4、CMMLU 提升 +4.0），但 DeepSeek 观察到其在通用推理能力（如 BBH 提升 +5.0、ARC-Challenge 提升 +3.7）以及代码与数学推理任务（HumanEval 提升 +3.0、MATH 提升 +2.4）上带来了更为显著的增益。&lt;/p&gt;&lt;p&gt;进一步的分析表明，&lt;strong&gt;Engram 能够将静态知识的重建负担从模型的浅层中剥离出来，从而有效加深网络用于复杂推理的有效深度&lt;/strong&gt;。此外，通过将局部依赖关系交由查表机制处理，Engram 释放了注意力机制的容量，使其能够更专注于全局上下文建模，从而显著提升了长上下文检索能力（例如 Multi-Query NIAH 的准确率从 84.2 提升至 97.0）。&lt;/p&gt;&lt;p&gt;最后，Engram 在系统层面同样展现出基础设施感知的高效性：其确定性的寻址方式支持在运行时从主机内存进行预取，几乎不会带来额外的性能开销。&lt;/p&gt;&lt;p&gt;DeepSeek 认为，&lt;strong&gt;条件记忆将成为下一代稀疏大模型中不可或缺的核心建模原语&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Engram 架构如下，其设计目标是在结构上将静态模式存储与动态计算过程从 Transformer 主干网络中分离出来，从而对其进行增强。该模块对序列中每一个位置依次执行两个功能阶段：检索与融合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAFKoRVttBOmQoIev9VHCpaVOlLtibYm336AibGdPxlqx2d1wa5kr1OEMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528063" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d9aef974-d08b-4723-be55-ed8ac921b9a5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在运行过程中，DeepSeek 首先对当前位置的后缀 N-gram 进行提取与压缩，并通过哈希机制以确定性的方式检索对应的静态嵌入向量。随后，这些被检索到的嵌入会在当前隐藏状态的调制下进行动态调整，并进一步通过一个轻量级卷积操作加以精炼。最后，Engram 与多分支架构进行集成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于哈希 𝑁-gram 的稀疏检索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一阶段的目标是将局部上下文映射到静态记忆条目，这一过程主要包括分词器压缩以及通过确定性哈希机制来检索对应的嵌入表示。&lt;/p&gt;&lt;p&gt;分词器压缩：为了最大化记忆单元的语义密度，DeepSeek 引入了一层词表投影（vocabulary projection）。为此，他们预先设计了一个映射函数&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAgSxiccS8q33sCb3TGn941oX3R7gPxTBPYUwhOuHPGQkUic5Y3KsYOmkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2389558232931727" data-s="300,640" data-type="png" data-w="996" type="block" data-imgfileid="503528064" data-aistatus="1" data-original-style="width:58px;height:20px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4b3f0322-af0a-4995-a5d2-f385e590fefe/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 12.44%;"&gt;，其将原始 token ID 映射为基于文本规范化等价关系（例如使用 NFKC 规范化、统一大小写等）得到的规范化标识符（canonical identifiers）。在实际应用中，对于一个规模为 128k 的分词器，该过程能够将有效词表规模缩减约 23%（详见附录 C）。&lt;/p&gt;&lt;p&gt;多头哈希：直接对所有可能的 N-gram 组合空间进行参数化在计算和存储上都是不可行的。借鉴 Tito Svenstrup 等（2017）的工作，DeepSeek 采用了一种基于哈希的近似方法。为了降低哈希冲突的影响，对于每一种 N-gram 阶数 n，引入 K 个相互独立的哈希头。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上下文感知门控&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前一阶段通过哈希 𝑁-gram 从条件记忆中检索得到的嵌入向量，本质上提供的是一种与具体语境无关的静态先验信息。然而，正因为其静态属性，这些嵌入缺乏对当前上下文的自适应能力，并且在实际应用中可能受到哈希冲突或词项多义性带来的噪声干扰。&lt;/p&gt;&lt;p&gt;为此，DeepSeek 在检索之后引入了一种上下文感知的门控机制，其设计灵感来源于注意力机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;系统效率：计算与存储的解耦&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在带有记忆机制的模型中，规模扩展往往受到 GPU 高带宽显存（HBM）容量有限的制约。然而，Engram 所采用的确定性检索机制天然支持将参数存储与计算资源进行解耦。不同于 MoE 依赖运行时隐藏状态进行动态路由，Engram 的检索索引完全由输入 token 序列决定。这种可预测性使得针对训练与推理阶段的专门优化策略成为可能，如图 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAD4Hibb8SMweeACleRMlsD8LmqQlMl1llDq9iciaO6Egveyo8RsPSLNpNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.725" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528065" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4fe509c8-9e8d-412b-9529-666695d72011/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在训练阶段，为容纳大规模嵌入表，DeepSeek 采用标准的模型并行方案，将嵌入表分片分布在多张 GPU 上。在前向传播过程中，通过 All-to-All 通信原语收集被激活的嵌入行；在反向传播阶段，则将对应梯度分发回各个分片，从而使总可用记忆容量能够随加速器数量线性扩展。&lt;/p&gt;&lt;p&gt;在推理阶段，这种确定性特性进一步支持一种预取&amp;ndash;重叠（prefetch-and-overlap）策略。由于在前向计算开始之前即可确定所需访问的记忆索引，系统能够通过 PCIe 从容量充足的主机内存中异步地预取嵌入向量。为有效掩蔽通信带来的延迟，Engram 模块被放置在主干网络中的特定层级，利用其前序 Transformer 层的计算作为缓冲，从而避免 GPU 计算停顿。&lt;/p&gt;&lt;p&gt;这也要求一种硬件 &amp;mdash; 算法协同设计（hardware&amp;ndash;algorithm co-design）：一方面，将 Engram 放置得更深可以拉长用于隐藏通信延迟的计算窗口；另一方面，从建模效果来看，较早地介入以卸载局部模式的重建更为有利。因此，Engram 的最优插入位置必须同时满足建模性能与系统时延两方面的约束。&lt;/p&gt;&lt;p&gt;此外，自然语言中的 𝑁-gram 天然遵循 Zipfian 分布，即少量高频模式贡献了绝大多数的记忆访问。这一统计特性启发研究者可以构建一种多级缓存层次结构（Multi-Level Cache Hierarchy）：将高频访问的嵌入缓存于更快的存储介质中（如 GPU HBM 或主机 DRAM），而将大量低频的长尾模式存放在容量更大但速度较慢的存储介质中（如 NVMe SSD）。这种分层设计使 Engram 能够扩展到极大规模的记忆容量，同时对有效访问延迟的影响保持在最低水平。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;U 型扩展规律与稀疏性分配&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为「条件记忆」的一种具体实现，Engram 在结构上与 MoE 专家提供的「条件计算」形成了互补。本节旨在探究这种二元特性（Duality）的扩展属性，以及如何最优地分配稀疏容量。&lt;/p&gt;&lt;p&gt;具体而言，本项研究由两个核心问题驱动：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;有限约束下的分配&lt;/strong&gt;：在总参数量和训练计算量固定（即等参数、等 FLOPs）的情况下，应该如何在 MoE 专家与 Engram 嵌入之间划分稀疏容量？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无限记忆范式&lt;/strong&gt;：考虑到 Engram 具有不随规模增长（Non-scaling）的&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAHcWDB842FnjQ5Q4PhGicvSibickXHW66FibPGUah3vTkP1UyWSE1iblunJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5721925133689839" data-s="300,640" data-type="png" data-w="374" type="block" data-imgfileid="503528067" data-aistatus="1" data-original-style="width:28px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6388a81a-17e5-41f7-ab56-1a51aee7b2c7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 5.39%;"&gt;查找开销，如果放宽记忆预算或进行激进扩展，Engram 自身会表现出怎样的扩展行为？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首先来看 &lt;strong&gt;MoE 与 Engram 之间的最优分配比例&lt;/strong&gt;。在计算匹配公式时，DeepSeek 使用以下三个参数度量来分析这个权衡：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;P_tot：总的可训练参数，不包括词汇嵌入和语言模型头。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;P_act：每个 token 激活的参数。这一量度决定了训练成本（FLOPs）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMRupgtg13d22OV6JrKF6CiaUEO14Bnv7XCTEib2lv2Mc1fnm8WZlfWMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.15789473684210525" data-s="300,640" data-type="png" data-w="836" type="block" data-imgfileid="503528069" data-aistatus="1" data-original-style="width:132px;height:21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/a97cfbce-f1f9-4dc5-87d8-5998968c4163/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 24.99%;"&gt;：不激活的参数，表示可用于扩大模型大小而不增加计算成本的「自由」参数预算（例如未选择的专家或未检索的嵌入）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DeepSeek 在每个 FLOPs 预算内保持 P_tot 和 P_act 固定，这样模型具有相同数量的参数和相同的每 token FLOPs。对于 MoE，P_act 由选定的 top-k 专家决定，而未选择的专家的参数贡献给 P_sparse。对于 Engram，每个 token 只检索固定数量的槽（slots），因此增加嵌入槽的数量会增加 P_tot，但不会增加每 token 的 FLOPs。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAH43shOXT1A8Alp089KGPz1kC74mepCkHpMicXaflpbr2icTfyas8NeXA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.08055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528070" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6544befb-5aa2-44cb-96da-70dd742d8244/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;「在无限内存模式下的 Engram」&lt;/strong&gt;。在固定参数预算下优化分配之外，DeepSeek 探索了互补的设置：激进的内存扩展。这个研究的动机来自于 Engram 独特的能力，能够将存储与计算解耦。&lt;/p&gt;&lt;p&gt;DeepSeek 使用一个固定的 MoE 主干，具有 P_tot &amp;asymp; 3B 和 P_act = 568M，并训练了 100B 个 token 以确保收敛。在此基础上附加了一个 Engram 表，并调整了槽的数量 M 从 2.58 &amp;times; 10⁵ 到 1.0 &amp;times; 10⁷（增加最多约 13 亿参数）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下图 3（左）揭示了验证损失与分配比例 𝜌 之间一致的 U 形关系&lt;/strong&gt;。值得注意的是，即使 MoE 分配减少到仅 𝜌 &amp;asymp; 40%（即 5.7B 模型为 46 个专家，9.9B 模型为 43 个专家），Engram 模型仍然达到了与纯 MoE 基准（𝜌 = 100%）相当的性能。&lt;/p&gt;&lt;p&gt;此外，纯 MoE 基准证明是次优的：将大约 20%-25% 的稀疏参数预算重新分配给 Engram 获得最佳性能。定量分析中，在 10B 范围内（𝐶 = 6 &amp;times; 10&amp;sup2;⁰），验证损失从 1.7248（𝜌 = 100%）改善到 1.7109，接近 𝜌 &amp;asymp; 80% 时的最优值（&amp;Delta; = 0.0139）。值得注意的是，这一最优点的位置在不同的范围内稳定（𝜌 &amp;asymp; 75%-80%），表明在固定稀疏性下，各个规模之间有一个稳健的分配偏好。这一观察到的 U 形确认了两种模块之间的结构互补性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;图 3（右）展示了增加内存槽数量会显著改善验证损失，并且这一改进在整个范围内持续稳定&lt;/strong&gt;。该曲线遵循严格的幂律（在对数空间中线性），这表明 Engram 提供了一个可预测的扩展旋钮：更大的内存在不需要额外计算的情况下继续带来收益。&lt;/p&gt;&lt;p&gt;关键一点是，在扩展效率方面：虽然 OverEncoding 通过更大的内存表受益，但 Engram 在相同的内存预算下释放了更大的扩展潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结合分配规律来看，这些结果验证了条件记忆作为稀疏容量的独立、可扩展轴的作用，它补充了 MoE 的条件计算。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYI9OhrrdFotHP42En2iajz85DmEC2doZWnOoJYLwSXO3e1sdqaCImJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.4925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528081" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/543c6639-1b21-4309-840f-f78637bb6ca7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过提出的 Engram 架构以及经验推导出的分配法则，DeepSeek 将 Engram 扩展至数十亿参数规模，以验证其在真实语言模型预训练中的有效性。&lt;/p&gt;&lt;p&gt;总共训练了以下四种模型：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Dense-4B（总参数量 41 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MoE-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Engram-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以及 Engram-40B（总参数量 395 亿）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所有模型均采用完全相同的数据训练流程（相同的 token 预算及顺序），且在激活参数量上严格匹配。&lt;/p&gt;&lt;p&gt;关于实验设置，所有模型均在包含 2620 亿 token 的语料库上进行预训练，并采用了 DeepSeek-v3 的分词器，其词表大小为 128k。DeepSeek 在涵盖语言建模、知识、推理、阅读理解以及代码 / 数学的多样化基准测试集上对模型进行评估。对于每项基准测试，均遵循标准的提示词协议和评估指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;先来看大规模预训练的实验结果，如下表 1 所示，稀疏架构展示了比密集模型更优的扩展规律。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在相同的训练计算预算下，所有三种稀疏变体（MoE-27B，Engram-27B/40B）在所有基准测试中显著超越了 iso-FLOPs 的 Dense-4B 基准。&lt;/p&gt;&lt;p&gt;更重要的是，&lt;strong&gt;Engram-27B 在 iso - 参数和 iso-FLOPs 的 MoE-27B 基准上持续取得改进&lt;/strong&gt;。有趣的是，这些提升并不限于知识密集型任务（例如，MMLU: +3.0，MMLU-Pro: +1.8，CMMLU: +4.0），在这些任务中，内存容量直观上是有益的。此外还观察到，在一般推理领域（例如，BBH: +5.0，ARC-Challenge: +3.7，DROP: +3.3）以及代码和数学推理任务（例如，HumanEval: +3.0，MBPP: +1.6，GSM8K: +2.2，MATH: +2.4）中，改进更加显著。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;扩展到 Engram-40B 进一步减少了预训练损失，并提高了大多数基准测试的性能&lt;/strong&gt;。尽管它尚未在每个任务上严格超越 Engram-27B，但这可能是由于训练不足的结果。此外，Engram-40B 与基准模型之间的训练损失差距在训练结束时继续扩大，表明扩展的内存容量尚未在当前的 token 预算内完全饱和。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACCBl08YcAEt8TJGEtgr6co2ElHKhympbpN6GoEMgJUSpFhSAichtaQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.1018518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528082" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3989c993-b2fb-4a25-b836-10319eb4d81b/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来是&lt;strong&gt;长上下文训练&lt;/strong&gt;。通过将局部依赖建模卸载至静态查找，Engram 架构为处理全局上下文保留了宝贵的注意力容量。DeepSeek 通过进行长文本扩展训练，对这一结构性优势进行了实验验证。通过采用严密的评估协议，将架构设计带来的贡献与基础模型本身的能力剥离开来，证明了 Engram 在长程检索和推理任务中带来了显著的性能增益。&lt;/p&gt;&lt;p&gt;DeepSeek 首先解耦基础模型能力与架构设计之间的影响，其次进行受控对照分析，结果如下表 2 所示，主要得出了以下两个结论：&lt;/p&gt;&lt;p&gt;一是&lt;strong&gt;超越注意力机制的长文本能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;虽然注意力机制和位置编码为上下文处理提供了结构基础，但实验结果表明，长文本性能并非仅由架构先验决定。通过观察 Engram 的演进轨迹（从 41k 步到 50k 步），即使在控制相同模型架构和固定长文本扩展阶段计算预算的前提下，长文本性能仍随预训练进程单调提升。这表明长文本性能与基础模型的通用建模能力存在内在耦合。因此，严谨的架构对比必须通过对齐「基础模型损失（Loss）」而非仅仅对齐「训练步数」来控制这一混淆变量。&lt;/p&gt;&lt;p&gt;二是&lt;strong&gt;受控设置下的架构优越性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;基于上述原则，DeepSeek 将 Engram 与 MoE 基准模型进行了对比测试。在控制基础能力的前提下，Engram 模块的效率增益变得十分显著：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等损耗设置（Iso-Loss Setting，41k 步 vs. 基准）&lt;/strong&gt;：该设置严格分离了架构效率的影响。当对比 Engram-27B（46k 步）与完整训练的 MoE-27B（50k 步），即预训练损失完全对齐的两个模型时，Engram 表现出显著增益。具体而言，它在复杂检索任务中大幅超越基准模型（例如，多查询「大海捞针」 NIAH：97.0 vs. 84.2；变量跟踪 VT：87.2 vs. 77.0）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等计算量设置（Iso-FLOPs Setting，50k 步 vs. 基准）&lt;/strong&gt;：在标准的等计算预算下，Engram-27B（50k 步）进一步拉大了差距，在所有指标上均实现了顶尖性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极端设置（约 82% 计算量）&lt;/strong&gt;：即使是提前停止训练的 Engram-27B（41k 步），在面对完整训练的 MoE-27B（50k 步）时依然极具竞争力。它在 LongPPL 指标上与基准持平，并在 RULER 测试中实现超越，这充分证明了 Engram 架构的内在优越性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528083" data-ratio="0.45555555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAfwbCxbtEKFLia4VL5J1662B4LxwO0Paq8m6Heic6ia4E5OCA0R09tvB4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/62e24474-5ef0-4253-8ddc-2de57dec69c3/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，下图 4 是&lt;strong&gt;对表示对齐与收敛速度的分析&lt;/strong&gt;。(a) 基于 LogitLens 的逐层 KL 散度分析。在模型浅层，KL 散度持续保持在较低水平，这表明 Engram 加速了预测的收敛。(b-c) 为基于 CKA 计算的相似度热力图。高相似度对角线显著的向上偏移表明，Engram 的浅层在功能上等效于 MoE 模型的深层，从而有效地增加了模型的深度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZIWf0cDNkZhTrlYbpiaicpZlRyIRuflwhEsYTJR8Cziatupd9FzHzJ6kg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528084" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/547b3877-47dc-45a6-9614-011ee6e43a5b/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更多细节请参考原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
