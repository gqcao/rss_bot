<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>DeepSeek-OCR是「长文本理解」未来方向？中科院新基准VTCBench给出答案</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 10 Jan 2026 20:56:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ab84ca9b-ce9c-42f0-9e42-757e7fd6dbe7/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;DeepSeek-OCR 的视觉文本压缩（VTC）技术通过将文本编码为视觉 Token，实现高达 10 倍的压缩率，大幅降低大模型处理长文本的成本。但是，视觉语言模型能否理解压缩后的高密度信息？中科院自动化所等推出 VTCBench 基准测试，评估模型在视觉空间中的认知极限，包括信息检索、关联推理和长期记忆三大任务。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;近期，DeepSeek-OCR 凭借其创新的「视觉文本压缩」（Vision-Text Compression, VTC）范式引发了技术圈的高度关注，以极少的视觉 Token 实现高效的文本信息编码，为长文本处理开辟了新路径。&lt;/p&gt;&lt;p&gt;这一突破性进展让大模型处理超长文本的成本大幅降低，但也抛出了一个核心问题：&lt;strong&gt;当长文本被高度压缩为 2D 图像后，视觉语言模型（VLM）真的能理解其中的内容吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解答这一疑问，来自&lt;strong&gt;中科院自动化所、中国科学院香港创新研究院等机构的研究团队推出了首个专门针对视觉 - 文本压缩范式的基准测试 &amp;mdash;&amp;mdash;VTCBench。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gSLXEev4kibGvoBtcNDzn1cfy4GxNAeyTQjMeZL7xVxtuYHk70iaQibChA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527415" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/96c6a5f7-d28c-4bb3-a93d-d6979ab7c73c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2512.15649&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VTCBench 链接: https://github.com/Moenupa/VTCBench&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VLMEvalKit 链接：https://github.com/bjzhb666/VLMEvalKit&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Huggingface 链接: https://huggingface.co/datasets/MLLM-CL/VTCBench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527417" data-ratio="0.3194444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gxV4xsUQM34fZghJkhUV4nO9BrsQEWlYIGP2Xv3C5OcPicwiahy5uyHSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bf625483-9a68-4fbb-9632-2731679aa28a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：视觉 - 文本压缩 (VTC) 流程演示及 VTCBench&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;与传统大模型直接读取成千上万的纯文本 Token 不同，VTC 范式（如 DeepSeek-OCR）先将长文档渲染 （Rendering）为高密度的 2D 图像，再由视觉编码器转化为少量的视觉 Token。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;该技术可实现 2 倍至 10 倍的 Token 压缩率&lt;/strong&gt;，显著降低了长文本处理时的计算与显存开销。&lt;/p&gt;&lt;p&gt;VTCBench 现已在 GitHub 和 Huggingface 全面开源，其衍生版本 VTCBench-Wild 是一个统一的、全方位评估模型在复杂现实场景下视觉文本压缩的鲁棒性，现已集成到 VLMevalkit。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心使命&amp;mdash;&amp;mdash;衡量「看得见」之后的「看得懂」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前的 VLM 也许能出色地完成 OCR 识别，但在处理 VTC 压缩后的高密度信息时，其长文本理解能力仍存疑。&lt;/p&gt;&lt;p&gt;VTCBench 通过三大任务，系统性地评估模型在视觉空间中的认知极限：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Retrieval (信息检索)&lt;/strong&gt;：在视觉「大海」中寻找特定事实的「针」（Needle-in-a-Haystack），测试模型对空间分布信息的捕捉能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Reasoning (关联推理)&lt;/strong&gt;：挑战模型在几乎没有文本重叠的情况下，通过关联推理寻找事实，超越单纯的词汇检索；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;VTC-Memory (长期记忆)&lt;/strong&gt;：模拟超长对话，评估模型在视觉压缩框架下，抵御时间与结构性信息衰减的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此外，团队同步推出了 VTCBench-Wild，引入 99 种不同的渲染配置（涵盖多种字体、字号、行高及背景），全方位检测模型在复杂现实场景下的鲁棒性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;揭秘视觉压缩背后的认知瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gbqrAOxuCJGZ1Xnwp3zSfibIEjZLFF2Niaiatv1O6308L9nkBA3Riag1BdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.36574074074074076" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527427" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d0a7a926-9533-43de-bd7c-2dca5f7bdc2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：VTCBench 针对模型在长图像中检索信息的热力图。横轴代表上下文长度，纵轴代表关键事实（Needle）在文档中的深度。展现了模型表现的「迷失」与突破。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;测试结果呈现出显著的 「U 型曲线」：与文本模型类似，视觉语言模型（VLM）能够精准捕捉开头和结尾的信息，但对于中间部分的事实，理解能力会随着文档变长而剧烈衰退。&lt;/p&gt;&lt;p&gt;这证明了&lt;strong&gt;即使在视觉空间，模型依然存在严重的「空间注意力偏见」，是未来 VTC 架构优化的关键方向。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行业洞察 &amp;mdash;&amp;mdash; 视觉压缩是长文本的终局吗？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527430" data-ratio="0.7342592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gjbrkawkian3iaRV30iaJceVDLc31ZQckxIB07M1GBIHt3cTqNtv4BZTOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d9770352-f624-427e-bd65-4fe473d74555/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;通过对 GPT、Gemini、Claude、QwenVL、InternVL、Gemma、KimiVL、Seed1.5 等 10 余种尖端模型的深度评测，可以发现：&lt;/p&gt;&lt;p&gt;虽然 VTC 极大提升了效率，但现有 VLM 在复杂推理和记忆任务上的表现仍显著弱于纯文本 LLM；&lt;/p&gt;&lt;p&gt;消融实验证明，&lt;strong&gt;信息密度是决定模型性能的关键因素，直接影响视觉编码器的识别精度；&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini-3-Pro 在 VTCBench-Wild 上表现惊艳，其视觉理解能力已几乎追平其纯文本基准，证明了 VTC 是实现大规模长文本处理的极其可行的路径！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说传统的长文本处理是「逐字阅读」，那么， DeepSeek-OCR 所引领的 VTC 范式就是「过目成诵」的摄影式记忆。&lt;strong&gt;VTCBench 的出现，正是为了确保模型在拥有这种「超能力」的同时，依然能够读懂字里行间的微言大义。&lt;/strong&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026在新加坡滨海湾畔共饮一杯：蚂蚁InTech之夜邀您共话AI未来</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 17:27:40 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgZ4GvEtZBfLYbT7OB1qLUjkQDm4ExPZFyofsicqOzFDWib7dD7oicByqzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="3.2666666666666666" data-s="300,640" data-type="png" data-w="750" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgZ4GvEtZBfLYbT7OB1qLUjkQDm4ExPZFyofsicqOzFDWib7dD7oicByqzQ/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="1836" data-imgfileid="503527455" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/f6b64fcb-5fdd-4a06-8a8c-04adc2aea7ca/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们为每位到现场的小伙伴准备了专属伴手礼，期待与你相聚新加坡滨海湾，共同度过一个难忘的夜晚。&lt;/p&gt;&lt;section&gt;&lt;a href="https://wj.qq.com/s2/25465624/tvxg/"&gt;点击此链接，预约活动席位。&lt;/a&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让两个大模型「在线吵架」，他们跑通了全网95%科研代码｜深势发布Deploy-Master</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 14:29:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;科学计算领域已经积累了数量空前的开源软件工具。从生物信息学、化学模拟，到材料计算、物理仿真与工程设计，几乎每一个学科方向，都形成了自己的生态。在 GitHub 等平台上，成千上万个代码仓库声称可以被用于科研实践。&lt;/p&gt;&lt;p&gt;但一个长期存在、却始终没有被系统性解决的事实是：&lt;strong&gt;绝大多数科学软件，停留在 &amp;ldquo;被发布过&amp;rdquo;，而不是 &amp;ldquo;可以直接运行&amp;rdquo; 的状态。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在科研实践中，我们往往需要花费数天甚至数周时间反复解决编译失败、依赖冲突、系统不兼容等问题，才能在本地 &amp;ldquo;勉强跑通&amp;rdquo; 一个工具。这样的运行环境高度依赖个人经验，往往是临时的、不可移植的，也很难被他人复现或复用。每个研究者、每个实验室，都在手工维护自己的运行环境，而不是在一个共享、可复现的执行基础设施之上开展工作。&lt;/p&gt;&lt;p&gt;这种模式带来的问题，并不只是效率低下。更关键的是，它在结构上限制了科学软件的三件事情：&lt;strong&gt;可复现性、大规模评估，以及系统性集成&lt;/strong&gt;。即便容器化、云计算和 HPC 平台已经显著降低了算力门槛，这一 &amp;ldquo;部署瓶颈&amp;rdquo; 依然真实存在，并且长期制约着科学软件的可用性。&lt;/p&gt;&lt;p&gt;随着 &lt;strong&gt;AI for Science（AI4S）&lt;/strong&gt; 的兴起，这一问题被进一步放大。在新的科研范式中，AI 系统不再只是输出预测结果，而是需要与真实的科学工具发生紧密交互：调用求解器、执行模拟程序、运行分析管线、处理真实数据。在这样的背景下，一个工具是否 &amp;ldquo;真的能跑&amp;rdquo;，不再是工程细节，而是第一性问题。&lt;/p&gt;&lt;p&gt;这一问题在 &lt;strong&gt;Agentic Science&lt;/strong&gt; 场景中表现得更加尖锐。如果工具依赖隐含环境、执行高度脆弱，那么智能体的规划将无法真正落地，执行失败也无法被结构化分析，更不可能转化为可学习的执行轨迹。&lt;/p&gt;&lt;p&gt;从这个角度看，工具是否部署就绪，已经成为制约 AI4S 与 Agentic Science 规模化发展的结构性瓶颈。&lt;/p&gt;&lt;p&gt;基于这些观察，我们逐渐形成了一个判断：科学软件的问题，并不在于工具不够多，而在于缺乏一个能够将工具系统性转化为可执行事实的共享基础设施。Deploy-Master，正是在这一背景下被提出的。&lt;/p&gt;&lt;p&gt;在真实世界中，部署并不是一个孤立步骤，而是一条连续链路：工具能否被发现、是否被正确理解、能否构建环境，以及是否真的可以被执行。&lt;strong&gt;Deploy-Master 正是围绕这条链路，被设计为一个以执行为中心的一站式自动化工作流&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgPnPiapjiagvxxfs1BOyNDRyAficeHyNUuMiaYWdcrhicDcH88agszXyyIIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527457" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9586545d-c900-4d87-8145-e9988a0fdf25/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Search Agent &amp;nbsp;搜索科研锚点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大规模场景下，部署的第一个难题并不在构建，而在于发现。如果候选工具集合本身存在系统性偏差，后续所有自动化都会被放大为偏差。&lt;/p&gt;&lt;p&gt;为此，我们从 &lt;strong&gt;91 个科学与工程领域&lt;/strong&gt;出发，构建了一个覆盖 AI4S 实际应用场景的学科空间，并使用语言模型扩展搜索关键词，在 GitHub 与公共网络中进行大规模检索。初始召回得到的仓库，会作为 &amp;ldquo;锚点&amp;rdquo;，通过依赖关系、引用关系、共享贡献者和文档链接等信号进行迭代扩展，从而避免仅依赖关键词搜索带来的盲区。&lt;/p&gt;&lt;p&gt;随后，我们通过结构启发式规则剔除明显不可执行的仓库，并由 Agent 进行语义判断，确认其是否构成一个可执行科学工具。通过这一多阶段漏斗流程，&lt;strong&gt;我们将最初约 50 万个仓库，收敛为 52550 个进入自动部署流程的科学工具候选&lt;/strong&gt;。这一步的意义，不仅在于筛选工具，更在于第一次以结构化方式刻画了真实科学工具世界的规模与边界。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527458" data-ratio="0.5583333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgACicI7TkibbichYkY1mw8sibWmSeNuHGBZqeiaD7TgfMl3qdG7LqHt6brEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/897914ff-e33d-466e-92ab-66b690bc6e02/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;双模型博弈 &amp;nbsp;实现 95% 成功率&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在构建阶段，我们面对的并不是一个 &amp;ldquo;有明确说明书&amp;rdquo; 的世界。大量科学软件仓库的构建信息是零散的、不完整的，甚至相互矛盾的。README 文件可能早已过期，已有 Dockerfile 也未必反映当前代码状态，而关键依赖往往只存在于作者本地环境中。&lt;/p&gt;&lt;p&gt;Build Agent 会系统性地遍历仓库中的构建线索，并在必要时进行补充信息检索，生成初始构建方案。早期实验表明，仅依赖单一模型生成构建规格，成功率只有 50%&amp;ndash;60%，失败主要源于构建信息中大量隐含、未被显式表达的假设。&lt;/p&gt;&lt;p&gt;为此，&lt;strong&gt;Deploy-Master 引入了双模型评审与辩论（debate）机制&lt;/strong&gt;：一个模型提出构建规格，另一个模型独立审查并主动寻找潜在不一致、缺失依赖或环境假设，提出修正建议。两者通过多轮交互，不断修正方案，直到形成稳定、可执行的构建规格。这一机制&lt;strong&gt;将整体成功率提升到了 95% 以上&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;每一个工具最终都会通过一个最小可执行命令进行验证。只有通过执行验证的工具，才会被视为成功部署，并被进一步结构化、注册和发布到玻尔与 SciencePedia 上，使其可以被直接使用，或被其他 Agent（例如 SciMaster）调用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKggicia79U6xIpFUjVqxcz7EWeakLpG9BazHmicwOp0oFfiapplcRh09CeTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527460" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/113d7560-b30f-43f9-bce7-9a0c65f488f0/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从构建时间的分布来看，大规模部署并不是一个 &amp;ldquo;均匀&amp;rdquo; 的过程。尽管大多数工具可以在 7 分钟左右完成构建，但整体分布呈现出明显的长尾特征。一部分工具仅包含轻量级脚本或解释型代码，构建过程相对简单；而另一部分工具则涉及复杂的编译流程、深层依赖以及系统级库配置，其构建时间显著更长。&lt;/p&gt;&lt;p&gt;这种差异并不会阻止整体流程的推进，但它决定了部署在规模化条件下的成本结构。&lt;/p&gt;&lt;p&gt;在成功部署的 50112 个工具中，我们观察到一个高度异构的语言分布。&lt;strong&gt;工具覆盖了 170 多种编程语言&lt;/strong&gt;，其中 Python 占据了最大比例，其次是 C/C++、Notebook 形式的工具、R、Java 等。绝大部分语言部署成功率都稳定维持在较高水平。少数成功率相对较低的语言，主要集中在依赖复杂编译链或系统级库的场景，例如 C/C++、Fortran 以及部分 R 工具。&lt;/p&gt;&lt;p&gt;这并不意味着这些语言 &amp;ldquo;天生更难部署&amp;rdquo;，而是反映了其工具链对底层环境的耦合程度更高，从而放大了构建规格中的不确定性。从部署的角度看，语言本身并不是决定性因素，环境耦合强度才是。在 2438 次失败的构建尝试中，我们对失败原因进行了系统性统计。结果显示，失败并非均匀分布，而是高度集中在少数几类问题上。最主要的失败来源是构建流程错误，包括构建步骤与仓库当前状态不一致、关键依赖缺失、编译器或系统库不匹配等。这类失败远远多于资源不足、网络异常或权限问题。与此同时，资源相关错误在高并发阶段也确实出现过，并直接推动了我们对调度策略和隔离机制的后续改进。&lt;/p&gt;&lt;p&gt;这进一步说明，在规模化部署中，失败不应被视为异常，而应被视为系统暴露问题、进而自我修正的信号。&lt;/p&gt;&lt;p&gt;通过统一的执行基础设施，我们得以系统性地观察科学软件在真实环境中的部署行为：哪些环节最容易失败，哪些隐含假设最常被触发，哪些工具链最容易放大不确定性。这种可观测性本身，正是 Deploy-Master 希望建立的基础之一。它让 &amp;ldquo;科学软件难以部署&amp;rdquo; 从一种经验判断，转化为可以被量化、被分析、被持续改进的工程对象。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为 Agentic Science 构建行动基座&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Deploy-Master 的直接产出，是一个由数万条执行验证工具构成的集合。但更重要的是，&lt;strong&gt;它为社区 Agent 与各类 Master Agent 提供了一个长期缺失的基础前提。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对 Agent 而言，工具调用并不是抽象动作，而是必须在现实环境中成功落地的执行过程。只有当工具被统一构建、验证并注册为可执行能力，Agent 才真正拥有稳定的 action space，规划、执行与学习之间的闭环才得以成立。这也使得不同来源的社区 Agent，可以共享同一批经过执行验证的工具能力，而不再各自维护脆弱、不可复现的运行环境。&lt;/p&gt;&lt;p&gt;这一方法论的意义，并不局限于科学计算。科学工具往往被视为自动化部署中最困难的一类：依赖复杂、系统耦合强、文档不完整、对环境高度敏感。如果在这样一个 &amp;ldquo;最难场景&amp;rdquo; 中，仍然可以通过以执行为中心的设计，在万级规模下稳定地产生可运行工具，那么结论已经非常清晰 &amp;mdash;&amp;mdash; &lt;strong&gt;问题不在工具类型，而在于是否建立了以执行为核心的基础设施&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一判断同样适用于更广泛的软件工具生态：工程工具、数据处理系统、专业软件乃至各类 Agent Tooling。只要工具最终需要被执行，其部署问题就无法绕开 &amp;ldquo;不完美信息&amp;rdquo; 这一现实前提。&lt;/p&gt;&lt;p&gt;Deploy-Master 并未解决所有问题。异构硬件、分布式计算、语义级 I/O 接口以及与物理实验系统的闭环集成，仍然是未来需要面对的挑战。但有一件事情已经足够清楚：&lt;strong&gt;在 Agentic Science 时代，执行不是推理之后的附属步骤，而是所有能力得以成立的前提。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当 &amp;ldquo;工具能不能跑&amp;rdquo; 不再是一个默认假设，而成为一个被系统性验证的事实，科学智能体才真正开始拥有与现实世界交互的基础。而 Deploy-Master，正是迈向这一执行现实的一次尝试。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>OpenAI for Healthcare——面向医疗保健的AI产品</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 09 Jan 2026 14:28:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-backh="309" data-backw="578" data-imgfileid="100027102" data-ratio="0.5351851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynAWZAa9Tj20Yc5ibLHQHONw6lTpjSDsrqtCuJtEhDbkDV0iauwiclnPKWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/52fced35-4237-488e-84ac-569db61a1db4/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;2026 年1 月 9 日，OpenAI 宣布推出 OpenAI for Healthcare，这是一套旨在帮助医疗机构为患者提供更一致、高质量护理的产品，而这其中也包括他们于 1 月 7 日推出的 &lt;strong&gt;ChatGPT for Healthcare&lt;/strong&gt;，它已被推广至如&amp;nbsp;AdventHealth、Baylor Scott &amp;amp; White Health 等领先机构。&lt;/p&gt;&lt;p&gt;在当今社会，关于个人健康的需求正不断上升，医疗行业的压力也随之剧增。在这种条件下，得益于模型的进步，AI 的应对能力有了明显上升。OpenAI for Healthcare 通过为组织提供安全的企业级 AI 基础，帮助缩小这一差距&amp;mdash;&amp;mdash;让团队能够使用相同工具提供更好、更可靠的护理，同时支持 HIPAA 合规。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;医疗领域的 ChatGPT 应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ChatGPT 医疗平台旨在支持真实患者护理中谨慎且基于证据的推理，同时减轻行政负担，使团队能有更多时间陪伴患者。团队可以将临床医生、管理者和研究人员带入一个安全的工作空间，配备他们所需的控制，以安全且大规模地部署 AI。&lt;/p&gt;&lt;p&gt;相关内容大致有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;为医疗工作流程构建的模型：&lt;/strong&gt;为临床、研究和运营工作提供高质量响应&amp;mdash;&amp;mdash;由为医疗领域构建的GPT-5模型驱动，并通过医生主导的测试在基准和实际工作流程中进行评估。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;证据检索并附带透明引用：&lt;/strong&gt;回答基于医学来源&amp;mdash;&amp;mdash;涵盖数百万同行评审研究、公共卫生指导和临床指南&amp;mdash;&amp;mdash;并附有清晰的引用，包括标题、期刊和出版日期，以支持快速核查来源。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynmq6C5QxH6QqREJN6urbheicfoKTib9K0bfmH4kufbJ2E3F0VgSu7VGbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1920" data-height="1080" data-backw="546" data-backh="307" data-imgfileid="100027099" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/005eac71-e443-4915-8f70-e2ae48def856/640.png" alt="图片" data-before-load-time="1767940085793" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：临床检索。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机构政策与护理路径对齐：&lt;/strong&gt;与 Microsoft SharePoint 等企业工具及其他系统集成，响应内容可纳入机构批准的政策、路径文档和运营指导，支持团队间的一致执行，确保患者获得高质量护理。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynlGI6iapvCo1ibIhHKIqicMrXD9fibezSa882YareLSveIljqrIepjSib2cQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1920" data-height="1080" data-backw="546" data-backh="307" data-imgfileid="100027100" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3b463082-d97b-4f62-93c7-48b0196406d6/640.png" alt="图片" data-before-load-time="1767940085807" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：批准的护理路径。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可重复使用的模板以自动化工作流程：&lt;/strong&gt;共享模板，用于常见任务，如出院摘要、患者指示、临床信函和事前授权支持。临床团队花在重写和搜索上的时间更少，患者拥有更清晰的下一步步骤和更顺畅的护理过渡。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;访问管理与治理：&lt;/strong&gt;一个集中式工作区，支持基于角色的访问控制，与通过 SAML SSO 和 SCIM 实现全组织用户管理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;HIPAA 合规的数据控制与支持：&lt;/strong&gt;患者数据和 PHI 仍由组织控制，提供数据驻留、审计日志、客户管理加密密钥及与 OpenAI 的业务合作伙伴协议（BAA）等选项，以支持符合 HIPAA 的使用。与 ChatGPT 分享的内容不用于训练模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在实践中，团队使用医用 ChatGPT 综合医学证据与机构指导，并将其应用于患者的具体情境、起草临床和行政文档，并调整面向患者的教育材料。这不但减少了行政工作的时间，帮助团队遵循共享的护理标准，还支持更好的患者体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;早期医院合作伙伴&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;医疗保健是增长最快的领域之一企业市场采用人工智能，医院和学术医疗中心已经在其团队中推广ChatGPT医疗服务。&lt;/p&gt;&lt;p&gt;相关链接：&lt;em&gt;https://openai.com/zh-Hans-CN/index/the-state-of-enterprise-ai-2025-report/&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;医疗领域的 OpenAI API&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;借助 OpenAI API 平台，开发者可以利用 OpenAI 最新的模型&amp;mdash;&amp;mdash;包括 GPT-5.2&amp;mdash;&amp;mdash;为工具和产品提供动力，并将 AI 直接嵌入医疗系统和工作流程中。&lt;/p&gt;&lt;p&gt;实际上，相关团队正在使用 OpenAI API 构建医疗应用，包括患者病历摘要、护理团队协调和出院工作流程。像Abridge、Ambience 和 EliseAI 这样的公司正在构建环境聆听、自动化临床文档和临床预约安排功能，服务于临床医生和患者。&lt;/p&gt;&lt;p&gt;API 平台：https://openai.com/zh-Hans-CN/api/&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为医疗保健优化的 AI 模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;所有 OpenAI for Healthcare 产品均由 GPT-5.2 模型驱动，这些模型优于早期 OpenAI 模型，并通过持续研究和真实评估开发，反映了临床医生实际使用 AI 的方式。&lt;/p&gt;&lt;p&gt;研发团队还会参考实际部署的证据。与&amp;nbsp;Penda Health&amp;nbsp;合作的一项研究发现，一个由 OpenAI 驱动的临床副驾驶在常规初级保健中使用减少了诊断和治疗错误&amp;mdash;&amp;mdash;早期证据表明，在适当的保障和临床监督下，AI 能够提升护理质量。&lt;/p&gt;&lt;p&gt;基准测试如健康台一项开放的临床医生设计评估，也强化了这一进展。在这些评估中，GPT-5.2 模型在真实临床工作流程中持续优于前几代和对比模型。在现实医疗任务中，GPT-5.2 在 GDPval 衡量的所有角色中表现优于人类基线， 超越了早期的 OpenAI 模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynxH1ZJObP6qfSpncSx9VYjAEodeUq7vgcS7dEVsH62JMeTI9qBgU3wA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5828220858895705" data-type="png" data-w="815" data-width="815" data-height="475" data-backw="546" data-backh="318" data-imgfileid="100027098" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/54a11074-520f-4866-8a07-7fd978ee02ef/640.png" alt="图片" data-before-load-time="1767940086190" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：HealthBench 共识专业人士挑战医疗专业人员工作流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一步发展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 团队表示，该公告建立在 OpenAI 在健康、生物制药和生命科学领域长期开展的工作基础上。这包括像 ChatGPT Health 这样的产品 ;与&amp;nbsp;Retro Biosciences&amp;nbsp;等公司合作，持续研究人工智能如何加速科学发现等。&lt;/p&gt;&lt;p&gt;他们坚信自己的使命是确保 AI 惠及全人类，并相信改善健康将成为 AI 的关键影响之一。相关团队将继续与使用 OpenAI for Healthcare 的医疗机构紧密合作，借鉴实际应用经验，进一步改进医疗产品。&lt;/p&gt;&lt;p&gt;原文链接：&lt;em&gt;https://openai.com/index/openai-for-healthcare/&lt;/em&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>深势科技发布Deploy-Master：一天部署5万个科学计算工具，这可能是Agentic Science真正的起点</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 09 Jan 2026 14:27:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnGculc4Prz33PHGkz398ynXAYmXG7qhEPKsUxDTbtSfia7CqXNR1P3iaz1QHHTc2eUmGvCxwJTxdIg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.5518518518518518" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="546" data-backh="301" data-imgfileid="100027095" data-aistatus="1" data-original-style="width:100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/83cf1206-a185-457d-af2b-dffd06b77bc1/640.jpeg" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;过去几十年里，科学计算领域积累了数量空前的开源软件工具。从生物信息学、化学模拟，到材料计算、物理仿真与工程设计，几乎每一个学科方向，都形成了自己的工具生态。在 GitHub 等平台上，成千上万个代码仓库声称可以被用于科研实践。&lt;/p&gt;&lt;p&gt;但一个长期存在、却始终没有被系统性解决的事实是：绝大多数科学软件，停留在「被发布过」，而不是「可以直接运行」的状态。&lt;/p&gt;&lt;p&gt;在真实科研实践中，我们往往需要花费数天甚至数周时间，反复解决编译失败、依赖冲突、系统不兼容等问题，才能在本地「勉强跑通」 一个工具。这样的运行环境高度依赖个人经验，往往是临时的、不可移植的，也很难被他人复现或复用。每个研究者、每个实验室，都在手工维护自己的运行环境，而不是在一个共享、可复现的执行基础设施之上开展工作。&lt;/p&gt;&lt;p&gt;这种模式带来的问题，并不只是效率低下。更关键的是，它在结构上限制了科学软件的三件事情：可复现性、大规模评估，以及系统性集成。即便容器化、云计算和 HPC 平台已经显著降低了算力门槛，这一「部署瓶颈」依然真实存在，并且长期制约着科学软件的可用性。&lt;/p&gt;&lt;p&gt;随着&amp;nbsp;AI for Science（AI4S）&amp;nbsp;的兴起，这一问题被进一步放大。在新的科研范式中，AI 系统不再只是输出预测结果，而是需要与真实的科学工具发生紧密交互：调用求解器、执行模拟程序、运行分析管线、处理真实数据。在这样的背景下，一个工具是否「真的能跑」，不再是工程细节，而是第一性问题。&lt;/p&gt;&lt;p&gt;这一问题在&amp;nbsp;Agentic Science&amp;nbsp;场景中表现得更加尖锐。如果工具依赖隐含环境、执行高度脆弱，那么智能体的规划将无法真正落地，执行失败也无法被结构化分析，更不可能转化为可学习的执行轨迹。从这个角度看，工具是否部署就绪，已经成为制约 AI4S 与 Agentic Science 规模化发展的结构性瓶颈。&lt;/p&gt;&lt;p&gt;基于这些观察，我们逐渐形成了一个判断：科学软件的问题，并不在于工具不够多，而在于缺乏一个能够将工具系统性转化为可执行事实的共享基础设施。Deploy-Master，正是在这一背景下被提出的。&lt;/p&gt;&lt;p&gt;在真实世界中，部署并不是一个孤立步骤，而是一条连续链路：工具能否被发现、是否被正确理解、能否构建环境，以及是否真的可以被执行。Deploy-Master 正是围绕这条链路，被设计为一个以执行为中心的一站式自动化工作流。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynfs5URBHobkyAhIzHwd8GCiaK5D74WXb4Zcefl8uicNSoOjk4AR9JicymQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5573440643863179" data-s="300,640" data-type="png" data-w="994" type="block" data-backw="546" data-backh="304" data-imgfileid="100027092" data-aistatus="1" data-original-style="width:100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/331c0e6f-ac51-48ef-8b14-4edff0446119/640.png" alt="图片" data-before-load-time="1767939985388" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Search Agent：百万级仓库搜索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大规模场景下，部署的第一个难题并不在构建，而在发现。如果候选工具集合本身存在系统性偏差，后续所有自动化都会被放大为偏差。&lt;/p&gt;&lt;p&gt;为此，我们从&amp;nbsp;91 个科学与工程领域出发，构建了一个覆盖 AI4S 实际应用场景的学科空间，并使用语言模型扩展搜索关键词，在 GitHub 与公共网络中进行大规模检索。初始召回得到的仓库，会作为「锚点」，通过依赖关系、引用关系、共享贡献者和文档链接等信号进行迭代扩展，从而避免仅依赖关键词搜索带来的盲区。&lt;/p&gt;&lt;p&gt;随后，我们通过结构启发式规则剔除明显不可执行的仓库，并由 Agent 进行语义判断，确认其是否构成一个可执行科学工具。通过这一多阶段漏斗流程，我们将最初约&amp;nbsp;50 万个仓库，收敛为&amp;nbsp;52,550 个进入自动部署流程的科学工具候选。这一步的意义，不仅在于筛选工具，更在于第一次以结构化方式刻画了真实科学工具世界的规模与边界。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="304" data-backw="546" data-imgfileid="100027093" data-ratio="0.5573440643863179" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynSrSm7TUcoKUAoqg8Y01IdYO6TARDlY8eP5mqNho1M6DFNR344tCtibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="994" type="block" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/afc7f5f6-58e5-485f-8fe2-5234e1056fd0/640.png" alt="图片" data-before-load-time="1767939985437" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Build Agent：双模型辩论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在构建阶段，我们面对的并不是一个「有明确说明书」的世界。大量科学软件仓库的构建信息是零散的、不完整的，甚至相互矛盾的。README 文件可能早已过期，已有 Dockerfile 也未必反映当前代码状态，而关键依赖往往只存在于作者本地环境中。&lt;/p&gt;&lt;p&gt;Build Agent 会系统性地遍历仓库中的构建线索，并在必要时进行补充信息检索，生成初始构建方案。早期实验表明，仅依赖单一模型生成构建规格，成功率只有&amp;nbsp;50%&amp;ndash;60%，失败主要源于构建信息中大量隐含、未被显式表达的假设。&lt;/p&gt;&lt;p&gt;为此，Deploy-Master 引入了双模型评审与辩论（debate）机制：一个模型提出构建规格，另一个模型独立审查并主动寻找潜在不一致、缺失依赖或环境假设，提出修正建议。两者通过多轮交互，不断修正方案，直到形成稳定、可执行的构建规格。这一机制将整体成功率提升到了&amp;nbsp;95% 以上。&lt;/p&gt;&lt;p&gt;每一个工具最终都会通过一个最小可执行命令进行验证。只有通过执行验证的工具，才会被视为成功部署，并被进一步结构化、注册和发布到玻尔与 SciencePedia 上，使其可以被直接使用，或被其他 Agent（例如 SciMaster）调用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLnGculc4Prz33PHGkz398ynYETESg0HKySYeW4SBJDmf30dWE0QXh7bvbCTUzwpODoSlG7z6xibIUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5291750503018109" data-s="300,640" data-type="png" data-w="994" type="block" data-backw="546" data-backh="289" data-imgfileid="100027094" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/cd5254a1-d7b1-4b38-980a-c337254bb61c/640.png" alt="图片" data-before-load-time="1767939985487" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从构建时间的分布来看，大规模部署并不是一个「均匀」的过程。尽管大多数工具可以在 7 分钟左右完成构建，但整体分布呈现出明显的长尾特征。一部分工具仅包含轻量级脚本或解释型代码，构建过程相对简单；而另一部分工具则涉及复杂的编译流程、深层依赖以及系统级库配置，其构建时间显著更长。这种差异并不会阻止整体流程的推进，但它决定了部署在规模化条件下的成本结构。&lt;/p&gt;&lt;p&gt;在成功部署的 50,112 个工具中，我们观察到一个高度异构的语言分布。工具覆盖了&amp;nbsp;170 多种编程语言，其中 Python 占据了最大比例，其次是 C/C++、Notebook 形式的工具、R、Java 等。绝大部分语言部署成功率都稳定维持在较高水平。少数成功率相对较低的语言，主要集中在依赖复杂编译链或系统级库的场景，例如 C/C++、Fortran 以及部分 R 工具。这并不意味着这些语言「天生更难部署」，而是反映了其工具链对底层环境的耦合程度更高，从而放大了构建规格中的不确定性。从部署的角度看，语言本身并不是决定性因素，环境耦合强度才是。在 2,438 次失败的构建尝试中，我们对失败原因进行了系统性统计。结果显示，失败并非均匀分布，而是高度集中在少数几类问题上。最主要的失败来源是构建流程错误，包括构建步骤与仓库当前状态不一致、关键依赖缺失、编译器或系统库不匹配等。这类失败远远多于资源不足、网络异常或权限问题。与此同时，资源相关错误在高并发阶段也确实出现过，并直接推动了我们对调度策略和隔离机制的后续改进。这进一步说明，在规模化部署中，失败不应被视为异常，而应被视为系统暴露问题、进而自我修正的信号。&lt;/p&gt;&lt;p&gt;通过统一的执行基础设施，我们得以系统性地观察科学软件在真实环境中的部署行为：哪些环节最容易失败，哪些隐含假设最常被触发，哪些工具链最容易放大不确定性。这种可观测性本身，正是 Deploy-Master 希望建立的基础之一。它让「科学软件难以部署」从一种经验判断，转化为可以被量化、被分析、被持续改进的工程对象。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从可运行工具，到 Agentic Science 的执行地基&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Deploy-Master 的直接产出，是一个由数万条执行验证工具构成的集合。但更重要的是，它为 社区 Agent 与各类 Master Agent 提供了一个长期缺失的基础前提。&lt;/p&gt;&lt;p&gt;对 Agent 而言，工具调用并不是抽象动作，而是必须在现实环境中成功落地的执行过程。只有当工具被统一构建、验证并注册为可执行能力，Agent 才真正拥有稳定的 action space，规划、执行与学习之间的闭环才得以成立。这也使得不同来源的社区 Agent，可以共享同一批经过执行验证的工具能力，而不再各自维护脆弱、不可复现的运行环境。&lt;/p&gt;&lt;p&gt;这一方法论的意义，并不局限于科学计算。科学工具往往被视为自动化部署中最困难的一类：依赖复杂、系统耦合强、文档不完整、对环境高度敏感。如果在这样一个「最难场景」中，仍然可以通过以执行为中心的设计，在万级规模下稳定地产生可运行工具，那么结论已经非常清晰 &amp;mdash;&amp;mdash;&amp;nbsp;问题不在工具类型，而在于是否建立了以执行为核心的基础设施。&lt;/p&gt;&lt;p&gt;这一判断同样适用于更广泛的软件工具生态：工程工具、数据处理系统、专业软件乃至各类 Agent Tooling。只要工具最终需要被执行，其部署问题就无法绕开「不完美信息」这一现实前提。&lt;/p&gt;&lt;p&gt;Deploy-Master 并未解决所有问题。异构硬件、分布式计算、语义级 I/O 接口以及与物理实验系统的闭环集成，仍然是未来需要面对的挑战。但有一件事情已经足够清楚：在 Agentic Science 时代，执行不是推理之后的附属步骤，而是所有能力得以成立的前提。&lt;/p&gt;&lt;p&gt;当「工具能不能跑」不再是一个默认假设，而成为一个被系统性验证的事实，科学智能体才真正开始拥有与现实世界交互的基础。而 Deploy-Master，正是迈向这一执行现实的一次尝试。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一年后，DeepSeek-R1的每token成本降到了原来的1/32</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 14:24:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e939221b-d8bb-48af-a565-0ffeb2e39054/1767939614648.png" style="width: 700%;" class="fr-fic fr-dib"&gt;几天前，DeepSeek 毫无预兆地更新了 R1 论文，将原有的 22 页增加到了现在的 86 页。&lt;/p&gt;&lt;p&gt;新版本充实了更多细节内容，包括首次公开训练全路径，即从冷启动、训练导向 RL、拒绝采样与再微调到全场景对齐 RL 的四阶段 pipeline，以及「Aha Moment」的数据化验证等等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgia4L0oLW0vZibQORT3mweJ5uB4ULjTEVHolXyqhOJl3ADn563hXpEbNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527472" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/519d86c6-5f24-4379-90e3-d0ea6b89fba3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;DeepSeek-R1 是在 2025 年 1 月 20 日发布的开源推理大模型，它拥有 6710 亿参数、单 Token 激活参数为 370 亿，并采用了 MoE 架构，训练效率得到了显著提升。&lt;/p&gt;&lt;p&gt;R1 在去年的推出震动了全球 AI 领域，其高效率的模型架构、训练方法、工程优化和蒸馏方法在之后成为了全行业的趋势。&lt;/p&gt;&lt;p&gt;没想到在不到一年之后的今天，R1 模型的每 token 成本竟已降低了到了 1/32！&lt;/p&gt;&lt;p&gt;今天，英伟达发表了一篇长文博客，展示了其如何在 Blackwell GPU 上通过软硬协同对 DeepSeek-R1 进一步降本增效。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgbNOxKnEtyh6bfBXzbxcQcgg8X87WPoZlyibZLp8cttNd7hj3clZibshA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527473" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ecc8c14c-1198-4944-af78-921531e7c2aa/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着 AI 模型智能程度的不断提升，人们开始依托 AI 处理日益复杂的任务。从普通消费者到大型企业，用户与 AI 交互的频率显著增加，这也意味着需要生成的 Token 数量呈指数级增长。为了以最低成本提供这些 Token，AI 平台必须实现极高的每瓦特 Token 吞吐量。&lt;/p&gt;&lt;p&gt;通过在 GPU、CPU、网络、软件、供电及散热方案上的深度协同设计，英伟达持续提升每瓦特 Token 吞吐量，从而有效降低了每百万 Token 的成本。此外，英伟达不断优化其软件栈，从现有平台中挖掘更强的性能潜力。&lt;/p&gt;&lt;p&gt;那么，英伟达是怎样协同利用运行在 Blackwell 架构上的推理软件栈，以实现 DeepSeek-R1 在多种应用场景中的性能增益呢？我们接着往下看。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最新 NVIDIA TensorRT-LLM 软件大幅提升推理性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA GB200 NVL72 是一个多节点液冷机架级扩展系统，适用于高度密集型的工作负载。该系统通过第五代 NVIDIA NVLink 互连技术和 NVLink Switch 芯片连接了 72 个 NVIDIA Blackwell GPU，为机架内的所有芯片提供高达 1800 GB/s 的双向带宽。&lt;/p&gt;&lt;p&gt;这种大规模的「扩展域」（Scale-up Domain）专为稀疏 MoE 架构优化，此类模型在生成 Token 时需要专家之间频繁的数据交换。&lt;/p&gt;&lt;p&gt;Blackwell 架构还加入了对 NVFP4 数据格式的硬件加速。这是英伟达设计的一种 4 位浮点格式，相比其他 FP4 格式能更好地保持精度。此外，解耦服务（Disaggregated Serving）这类优化技术也充分利用了 NVL72 架构和 NVLink Switch 技术。简单来解释一下解耦服务，即在一组 GPU 上执行 Prefill（预填充）操作，在另一组 GPU 上执行 Decode（解码）操作。&lt;/p&gt;&lt;p&gt;这些架构创新使得 NVIDIA GB200 NVL72 在运行 DeepSeek-R1 时，能够提供行业领先的性能。&lt;/p&gt;&lt;p&gt;得益于最新 NVIDIA TensorRT-LLM 软件和 GB200 NVL72 的协同，DeepSeek-R1 在 8K/1K 输入 / 输出序列长度下的 Token 吞吐量大幅提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgrlKuVthIGlS3m4jI4jrGZ48vUr2FplkaFL2aGuHyiac5Q35Cf2QqbMg/640?wx_fmt=webp&amp;from=appmsg#imgIndex=3" data-ratio="0.5305555555555556" data-s="300,640" data-type="webp" data-w="1080" type="block" data-imgfileid="503527487" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/adc0e098-93c1-40a0-8c15-b1144a0515c4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同样地，得益于最新 NVIDIA TensorRT-LLM 软件与 GB200 NVL72 的协同，在 1K/1K 序列长度下，DeepSeek-R1 Token 吞吐量同样大幅提升。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527488" data-ratio="0.5361111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg8jrvMrADDslsWiaccoqolCCJ7icgBXFazA7ThsEleX99ZySxzuYNzyAw/640?wx_fmt=webp&amp;from=appmsg#imgIndex=4" data-type="webp" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b87cce71-dbd9-4526-b0f8-f2c6eaf92feb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;另外，在 8K/1K、1K/1K 两种输入 / 输出序列长度的吞吐量与交互性曲线上，GB200 NVL72 也展现出了领先的单 GPU 吞吐能力。&lt;/p&gt;&lt;p&gt;而 TensorRT-LLM 开源库（用于优化 LLM 推理）的最新增强功能，在同一平台上再次大幅增强了性能。在过去三个月中，每个 Blackwell GPU 的吞吐量提升高达 2.8 倍（这里指的是在 8k/1k 输入 / 输出序列长度下，去年 10 月到今年 1 月的 Token 吞吐量变化）。&lt;/p&gt;&lt;p&gt;这些优化背后的核心技术包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;扩大 NVIDIA 程序化依赖启动 (PDL) 的应用：降低核函数启动延迟，有助于提升各种交互水平下的吞吐量；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;底层核函数优化：更高效地利用 NVIDIA Blackwell Tensor Core；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;优化的 All-to-all 通信原语：消除了接收端的额外中间缓冲区。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有业内人士对英伟达放出的一系列图表进行了直观的解读，用一组数据来总结就是，「通过软硬件的深度协同，自 2025 年 1 月以来，英伟达已经将 DeepSeek-R1 (671B) 的吞吐量提升了约 36 倍，这意味着单 Token 的推理成本降低到了约 1/32。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg8fdMnzibNTaG1NQpnO0oiaBgC0rqEEwvjvr6nE0nBAWficHwxbicGtOFhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.28703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527489" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/bf3123f9-4fce-4b53-ba25-d8a8df6816fe/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKggk5rm2iaGib6yP6FJibgICaXNvjNbeEIuQeG6I5uhls0lwtLicZFmRvmgw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527490" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5fbb4283-0e6e-493e-9833-cc6c9b59465c/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;利用多 token 预测和 NVFP4 技术加速 NVIDIA HGX B200 性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA HGX B200 平台由八个采用第五代 NVLink 互连和 NVLink Switch 连接的 Blackwell GPU 组成，在风冷环境下也能实现强大的 DeepSeek-R1 推理性能。&lt;/p&gt;&lt;p&gt;两项关键技术使 HGX B200 上的 DeepSeek-R1 推理性能大幅提升。第一项技术是使用多 token 预测 (MTP)，它可以显著提高各种交互级别下的吞吐量。在所有三种测试的输入 / 输出序列组合中都观察到了这一现象。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgM4ONZ4icoALek7iaBE6AnTKbiaJbFktxpLQ0FMLWAtAViaQQh3JRqDbQTw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527491" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/68cc7a08-09a8-461b-9c53-4e72b2577820/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 HGX B200 平台上，使用 1K/1K 序列长度和聚合服务模式下，FP8（不带 MTP）、FP8（带 MTP）和 NVFP4（带 MTP）的吞吐量与交互性曲线对比。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;第二种方法是使用 NVFP4，充分利用 Blackwell GPU 计算能力来提升性能，同时保持精度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg7RSDM94UibGuaicCibyvoiaNINGLqUMPINgFs6TibNG02dibrUEicxYWbefnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.524074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527492" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f3d5dcd5-d69b-4ebc-919c-ec7b07b16c29/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 HGX B200 平台上，使用 8K/1K 序列长度和聚合服务模式下，FP8（不含 MTP）、FP8（含 MTP）和 NVFP4（含 MTP）的吞吐量与交互性曲线对比。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;NVFP4 使用在完整的 NVIDIA 软件栈上（包括 TensorRT-LLM 和 NVIDIA TensorRT 模型优化器），以确保高性能并保持精度。这使得在给定交互级别下能够实现更高的吞吐量，并且在相同的 HGX B200 平台上，可以实现更高的交互级别。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgmCtSeS5liaL4nFbadtrqDWuCNADm1A0esS82FkV0ickzV92ZkibmnmiczQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5268518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527493" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/8ea1569d-fd4b-4c0b-9916-f505321cb4a7/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在 HGX B200 平台上，FP8（无 MTP）、FP8（有 MTP）和 NVFP4（有 MTP）的吞吐量与交互性曲线，序列长度分别为 1K 和 8K，并采用聚合服务模式。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;英伟达表示，其正在不断提升整个技术堆栈的性能，可以帮助用户基于现有硬件产品，持续提升大语言模型的工作负载效率，提升各种模型的 token 吞吐量。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;博客地址：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://developer.nvidia.com/blog/delivering-massive-performance-leaps-for-mixture-of-experts-inference-on-nvidia-blackwell/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Agent 2.0时代来了，首批「工业级智能体」正在核心位置上岗</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 13:36:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3053b7b0-a329-498f-a6a3-2e5c73315247/1767936811357.png" style="width: 700%;" class="fr-fic fr-dib"&gt;如果 AI 工具早一点出现，我们的很多工作会不会提前几年完成？&lt;/p&gt;&lt;p&gt;近日，整个科技圈都在感叹 AI 工具带来的效率提升。一些硅谷 AI 大厂工程师现身说法，表示在用了 AI 工具后，项目完成时长被大幅压缩。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gQx8wicEuks4jKu8YxecoePHbLW0Uu8mSOevnicquIpaNN0brXe0XJAicw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4846066134549601" data-s="300,640" data-type="png" data-w="877" type="block" data-imgfileid="503527368" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/778b6332-fea4-45ce-883a-4ad2789a8c4a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;谷歌首席工程师、Gemini API 负责人 Jaana Dogan 分享了她使用智能体的经历。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;有的人甚至认为，如果在读博的时候就有 Claude Code、Gemini 和 ChatGPT 等各类 AI 工具出现，那么也许只要一年就能毕业。&lt;/p&gt;&lt;p&gt;围绕 AI 智能体技术，一套全新的工作范式正在形成。在开发、数据分析等领域，人们的工作流程已经被 AI 彻底改变：把工作直接安排给大模型，只需要提供背景信息、元提示词，AI 就可以进行需求整理，将任务交给智能体去执行。&lt;/p&gt;&lt;p&gt;最近的一场发布，打开了智能体通向更多行业的突破口。&lt;/p&gt;&lt;p&gt;1 月 7 日，在阿里云飞天发布时刻上，阿里云百炼完成了面向智能体开发范式的一次全面升级。阿里云向行业证明：智能体「手工作坊」的时代结束了，「工业化流水线」时代正在开启。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;百炼升级了其提出的「1+2+N」的蓝图&lt;/strong&gt;：其中最底层的 1 是模型与云服务，中间层的 2 是高代码、低代码的开发范式，在最上层的 N 则是面向不同任务的开发组件。这套能力覆盖了生产级智能体构建的全生命周期。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gCiboBBuqOQT3x0pHsO0vQs6zLiaNiad7IqAlpfibI2hdskw526Bc0jV7Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527369" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/55926f9a-f278-49e5-a7ff-af92cfb67bcf/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;围绕这一框架，阿里云提供的能力，针对解决了智能体技术落地面临的一系列核心问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开发组件 &amp;nbsp;解决智能化核心挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前行业对于 AI 应用的焦点正在从验证可用性转向实际价值，为了让人们能够低门槛地快速用上智能体，百炼进行了大量应用组件的升级。&lt;/p&gt;&lt;p&gt;在百炼的应用广场上，目前已出现超过 10 类聚合主题，其中包含 146 个开箱即用模板（如子弹时间特效、会议图文纪要、AI 换装等），它们在原先支持开发者即开即用、二次开发的基础上继续升级，现在支持免登录体验、一键 API 调用，进一步降低了上手门槛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gP47ufkNdBdGZO2uO3Ik1prC5XzvvT0QR6OMRPpazic1gaZT7MaEQ3cQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6898148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527370" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2a22ecc5-ee28-4f31-b294-c0f1a45d6b1f/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大规模部署的智能体应用，必须能够整合利用多模态数据。如何将企业内部大量的多模态数据进行清洗、加工，转换为可复用、可查询的知识，是业务与 AI 结合的关键问题。&lt;/p&gt;&lt;p&gt;为了让智能体能够真正理解企业业务，把数据转化为可利用的知识，&lt;strong&gt;百炼升级了多模态知识库 RAG 能力，支持文档、图片、音频、视频等数十种文件类型的高精度解析与语义检索&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;依托通义向量模型和多模态向量模型，企业现在可以快速构建起专属 RAG 工具和高性能知识检索生成，让智能体实现多模态问答、商品图搜、视频监控检索等场景化应用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gJXcDaiadQzxia8bM3zZLK4tc3TFwPL3Aichgk27lYszshyf6fTcsViaNEQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.5374064837905237" data-s="300,640" data-type="gif" data-w="802" type="block" data-imgfileid="503527371" data-aistatus="1" data-original-style="width: 405px;height: 218px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/527098cc-0579-4ccd-9dbc-8a1c4193b2ed/640.gif" data-order="0" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 在阿里云百炼上构建多模态 RAG-音视频库。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了满足更加灵活的多模态数据处理场景，除了端到端形式的多模态知识库外，多模态处理能力也以节点的形式在工作流中提供了支持。文档、图片、音频、视频在内的全模态智能理解，都可以由用户通过画布来进行更加灵活的编排处理。&lt;/p&gt;&lt;p&gt;通过集成通义的多模态生成模型，人们可以内置包括图像生成、视频生成、音频生成能力，用于商品图制作、营销短视屏生成、智能客服、语音合成等业务场景。&lt;/p&gt;&lt;p&gt;阿里云也在打通不同平台的数据：&lt;strong&gt;百炼提供的 Connector 企业级数据连接器，现在能够一键对接钉钉、飞书、语雀等文档系统，以及 MySQL、OSS 等数据库。&lt;/strong&gt;通过数十种内置工具，智能体可直接、安全地检索并调用企业内部实时数据。&lt;/p&gt;&lt;p&gt;随着时间的推移，来自真实业务数据的不断反馈，基于百炼平台的智能体会逐渐变得懂业务流程、有专业知识、甚至懂话术，成为「企业专属员工」。&lt;/p&gt;&lt;p&gt;另外在真实场景的 AI 应用中，我们会遇到大量数据处理、信息抽取等复杂任务，它们需要长时间的运行和低成本的调用，百炼提供的能力打破了以往时间和成本的限制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69ghW23lB1EnW1O6uhl3UubpKciakCQ2sDfmicsp70XiaAzCM0WOJYTby7tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.48703703703703705" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527372" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2b52d340-ab51-4f6d-9e98-d6008482ece6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;面向大模型推理、长视频生成等耗时任务，阿里云百炼推出了异步调用 API&lt;/strong&gt;，它打破了同步接口调用 5 分钟的超时限制，可以延长到超过 24 小时，支持任务提交后轮询或回调获取结果，可以保障长周期任务稳定执行。&lt;/p&gt;&lt;p&gt;当智能体任务运行在阿里云上时，系统会自动对算力资源进行调度。&lt;strong&gt;结合实时、闲时资源请求动态调度能力，百炼的系统可以实现任务动态启停，满足不同的智能体推理需求。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;据介绍，百炼的闲时调度能让 AI 的推理成本降低 50% 以上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体开发框架 &amp;nbsp;高代码 + 低代码并行&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;应用层面之下，阿里云百炼提供方便的开发工具，可以更好地帮助人们构建智能体。&lt;/p&gt;&lt;p&gt;阿里云百炼构建了一套生产级智能体开发范式，针对真实的业务场景，在规划决策、信息管理、工具调用以及数据、服务连接等关键环节，用智能体的先进能力，重构了整个业务流程。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gcwqw228AbQ429eZO8SNxe5W7Kj3CFA3nShuqibFS1icRZPSOePVX6JvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.42314814814814816" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527374" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0faef883-d0fe-4ad9-b7c0-abd096cd4c0e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在企业内部，AI 的落地往往面临一个矛盾：懂业务的人不会开发，懂代码的人不了解业务。&lt;strong&gt;百炼平台提供的双模式开发能力，首次实现了高代码与低代码的并行。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;高低代码智能体使用了统一的开发框架和运行时，它令专业的开发者可以利用基于高代码框架灵活定制智能体逻辑，一键将代码包提交至云端托管，享受全链路的日志、网关与可观测能力；与此同时，业务人员可通过低代码界面快速配置模型、提示词、知识库与工具，可视化地搭建智能体。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gu2ibHAgGwCSibeUmq54R7zNMLOsNk7F1CVlBwykq6q1iatbNIO6nVnmdQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.5375" data-s="300,640" data-type="gif" data-w="800" type="block" data-imgfileid="503527375" data-aistatus="1" data-original-style="width: 423px;height: 227px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fb1d2ec1-ef5e-46f4-a00e-2474f6cbb1a6/640.gif" data-order="1" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 低代码构建深度搜索 Agent。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69goHVCZibC0biaBDXuoict9RXkWE5mJHx7a479IM8yOWPV03BEwJhlII2RA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.5366666666666666" data-s="300,640" data-type="gif" data-w="600" type="block" data-imgfileid="503527376" data-aistatus="1" data-original-style="width:429px;height:230px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/de94968e-a727-477c-9146-d88da474c00d/640.gif" data-order="2" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 高代码结合 Agent Identity 控制阿里云资源、钉钉文档。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;同时发布中提到，两种方式构建的智能体未来还将支持双向导出与部署 &amp;mdash;&amp;mdash; 低代码的开发成果可以转换成高代码。这种方式可以说是真正覆盖了企业内不同角色的开发需求。&lt;/p&gt;&lt;p&gt;现在，百炼平台的智能体应用能力已升级至 Agent 2.0 架构，从底层重塑了智能体的开发逻辑，完成了从「简单对话」向「目标导向的自主执行」的升级。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;升级后的「Agent 2.0」不仅具备强大的任务规划能力，更引入了「规划 - 执行 - 反思（Plan-Execute-React）」链路。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单来说，在 Agent 1.0 时代，调试智能体往就像是在「炼丹」，输入一个 Prompt，模型吐出一个结果，开发者难以理解其内部的推理逻辑；到了 Agent 2.0 时代，通过引入完整的跟踪链路，百炼把 AI 从意图理解、任务规划、工具调用、执行反馈再到自我优化的全流程实现了可视化。&lt;/p&gt;&lt;p&gt;为了构建 Agent 2.0，百炼平台的技术底座 &amp;mdash;&amp;mdash; 通义实验室的开源智能体框架 AgentScope 迎来了重大更新。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AgentScope 现在提供模型能力集成、多智能体编排、智能上下文管理和工具管理四大核心功能&lt;/strong&gt;，不仅有开箱即用的智能体，也带来了用于构建、优化、部署智能体的工具，可以真正地做到自发解决任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gnbSiankEXlBoHkjQQWozQVMzaRwbv6IZBVkfwNdPSZx43uaCsImrHyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.47685185185185186" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527377" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/232873d0-6346-4802-9e7f-ecb6f13bbebb/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在模型能力上，AgentScope 目前已经覆盖了主流大模型 API，支持了本地部署模型 API 服务，其全面支持包括文本、语音、视觉等多种模态的大模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AgentScope 支持智能体自主进行工具管理，包括 StreamableHTTP、SSE 和 STDIO 类型的 MCP，以及 Anthropic Agent Skill 的动态工具加载、卸载，让单智能体适用范围更广，能力更强。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在多智能体能力的构建上，AgentScope 采用动态图的应用编排方式，提供 MsgHub、pipeline 等语法糖，可快速实现多智能体间的信息传递、分享。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在长上下文支持方面，AgentScope 支持短期记忆自动压缩，内置 Mem0、ReMe 等长期记忆实现，支持智能体自主存储、检索向量数据库和长期记忆。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对不同行业方向，百炼还新增了通用型智能体平台 Alias，可以构建数字化助手。在 AgentZoo 上，人们可找到有关金融、数据科学、语音、问答等领域的智能体应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型与云服务 &amp;nbsp;面向真实业务&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在模型服务层面上，阿里云百炼进一步强化了企业级能力的可用性。升级后的模型广场支持结构化元数据展示与多模型对比，以及模型在线体验，能够帮助用户快速匹配业务需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g1gfqWeOz0IiaEnv9HZQGuvmcBmlNd0ZlHLBuFYShHoT55mtK6iaWYOZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527378" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/15bb11d3-628f-4abf-a7ec-b921ae659aa9/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在百炼的模型广场上目前已有 130 余款模型，最近新增的包括 Qwen-Image-Max、GLM-4.7、Wan2.6 视频生成系列、Qwen3-ASR-Flash 多语种识别等，人们还可以在其上对模型进行横向对比。&lt;/p&gt;&lt;p&gt;在生产环境中，阿里云百炼提供全链路的可观测体系，可以分别授权调用审计、推理日志，可以对模型实施全周期用量统计，多维度性能与用量指标都会被集成在业务系统中，方便统一运维管理。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于阿里自家的通义全系列模型，阿里云百炼提供了原生的训练微调能力，可以实现一站式的训练与部署&lt;/strong&gt;，帮助人们使用自己的业务数据构建定制化模型。百炼提供通义系列模型的全阶段 Checkpoint、混合数据训练与 GRPO/GSPO 强化学习算法支持，能够实现评测驱动的训练迭代。&lt;/p&gt;&lt;p&gt;值得一提的是，在通义模型和第三方模型的部署上，阿里云百炼新增了模型单元独占部署选项（模型单元），为高并发、低延迟业务提供专属算力，与此同时不需要专门管理底层资源，可以做到一键拉起部署。相比自建集群使用 vLLM、SGLang 等开源推理引擎，使用模型单元部署可以实现超过 1.3 倍的推理能力提升，以及 1.5 倍以上的并发能力提升。&lt;/p&gt;&lt;p&gt;在安全方面，百炼平台提出的机密推理服务基于 CPU/GPU TEE 可信执行环境，提供目前最高安全等级的模型推理能力。&lt;/p&gt;&lt;p&gt;从模型能力到实际的生产力，百炼为企业围绕自身业务构建智能化提供了底层支撑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 平台企业版发布&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最后，&lt;strong&gt;作为本次发布的「彩蛋」，阿里云百炼发布了 Agent 平台企业版，支持智能体在专有云、本地化与 VPC 的开发与部署&lt;/strong&gt;。人们可以基于高代码或低代码的开发方式使用不同模型、工具与数据快速构建符合自身业务需求的智能体，进而实现大模型业务流，并在落地的过程中进行全流程优化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69guqObibynCa1N9G7xOvnbicMyWfPT4s1cQ8sxtqcmEYUib9WwictTAd4fLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527379" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/abb2c724-fc08-46a7-8985-22fe946f1b67/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 91.99%;"&gt;&lt;/section&gt;&lt;p&gt;阿里云百炼的此次升级发布，一方面让智能体的构建变得严谨可靠，能够持续迭代，另一方面也让新技术可以进入更多行业，开发门槛变得更低。&lt;/p&gt;&lt;p&gt;2026 年一开年，OpenAI 的联合创始人、总裁 Greg Brockman 就对今年 AI 领域的主线剧情进行了预测，他认为这是一个「企业智能体与科研加速」年：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gbV8Wd4v0QxIYbVJH1RLYWNQ56rNnRhK8aP7C99LCCaxb9HfuXpWIiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.4151128557409225" data-s="300,640" data-type="png" data-w="1019" type="block" data-imgfileid="503527380" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/90669a93-b871-44fb-a4ca-0c64c021f91f/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;没想到业界对于大佬预测的回应如此之快。&lt;/p&gt;&lt;p&gt;随着阿里云百炼等更多 Agent 平台的发布和能力升级，当 AI 不再只是写文档、生成代码的工具，而是能够自主调用工具、分析数据并辅助决策的称职「数字化员工」时，真正的人机协同时代正在拉开帷幕。&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.aliyun.com/benefit/ai/discount?utm_content=g_1000409173"&gt;点击此链接，限时抢购 AI 焕新券，新客专享满20减10&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谁家更新日志那么长啊？Claude Code版本更新引围观，1096次提交一口气上线</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 13:30:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6ca1b9b0-64dc-49f7-88b4-8472007adc42/1767936558892.png" style="width: 700%;" class="fr-fic fr-dib"&gt;如果你是 Claude Code 的用户，你可能会注意到，它最近有个重要的版本更新，从节前的 2.0.76 更新到了 2.1.0。&lt;/p&gt;&lt;p&gt;而且，这次的日志，你得往下翻好几屏。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgZgVqp6pGhzhyAKqUFI2zvibmibcia83HnTdGf540t3FsR8AxFUVoNREQA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="0.6671875" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503527474" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6025ea99-d3e6-4675-81a4-701dd34d2eec/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;翻完这个日志，网友不淡定了，有的纳闷「是有个超级智能体在帮他们写代码吗」？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgh7FBVpShjKzcx5PqiaQ8BhHOaLibzlWUXMpicHavp4YRE8vazDw2ibbib9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.225" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527475" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/81de1f8f-1469-4bc8-8731-a94eefeed356/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有人调侃说「求求了，谁去跟他们说一下什么叫 rolling release（滚动更新）吧」「照这个速度，我们周五早上就能用上新操作系统了」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgrqRPByMuvUibKrvCrFpzbTaxZYic9zAWJaaaDfHH6BClpp34L9uEcGKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.22314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527476" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5e854515-5f46-4b9c-8ffd-6d2175d62c2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgQfbg0UKWE7t4XcdibrIica4gxGeBXgRsY2QAtcLiaf7l4hAYI5ZYlqsbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.22407407407407406" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527477" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6b56a434-2266-43ac-9ee1-4e2fc74ef798/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHNl95Dkibbfdv7tOH8M4epuIS15Iej1jXFLSoypQGbibZ4icdq2lEbZRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.24444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527478" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/7d16f305-98dd-44d9-8d28-44b3dedc7ca2/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;根据 Claude 的总结，这次更新大概包含以下类型：&amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgwAjLEiaZiaLDNaT93Auo0zVic3LgSVrNxamOCGVDBa0cm7CvZzXQD1b7g/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.436734693877551" data-s="300,640" data-type="png" data-w="980" type="block" data-imgfileid="503527479" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d5a8dda4-f79f-43db-93e4-f062b9129c4d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在官宣更新的推文中，Claude Code 创建者、负责人 Boris Cherny 提到，这个版本一共合入了 1096 个 commit。同时，他也为大家拎出了一些重点，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Shift+Enter 换行：开箱即用，无需任何配置&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;钩子支持：可直接在 agents 和 skills 的前置配置中添加钩子&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Skills 增强：支持分叉上下文、热重载、自定义代理，可用 / 调用&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Agent 行为优化：拒绝工具使用后 agent 不再停止，会尝试其他方案&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多语言响应：可配置模型以指定语言回复（如日语、西班牙语等）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;工具权限通配符：支持通配符匹配，例如 Bash (*-h*)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;会话传送：使用 /teleport 将会话转移到 claude.ai/code&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgHicnWfDCr6xEGQib7wpicB6E3xfJuX3zaSjbVT7zibXQNxzjDTlaI90Weg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.1703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527480" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/83e883c7-2be2-472a-8ec6-92396f8fd869/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从评论区来看，大家似乎对会话传送比较感兴趣。Boris 还在评论区科普了使用方法。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgX3py6AKz0oHiabEJJX2jEHn9sMFH5wxvQGmhkywnmWtKRtXEdPGX5Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.1796296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527481" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/a9edb7e5-ee88-430f-9a18-0a1820fe247a/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，还有人关心企业用户要怎么用这个功能。PyTorch 之父 Soumith Chintala 问到，很多企业都是通过 API Key 使用 Claude Code 的，Anthropic 是否也能为这类用户开放 /teleport 功能？目前，Boris 还没有给出回复。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgA7DeH8QSPUUMp1gBbttqayd1cy3WkiaRsqlRIwh3LUvE3ej1FoNWW4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6129629629629629" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527482" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/f5a681b3-e1e7-4251-8afc-a7452f8a1759/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在完成这么多更新工作后，Boris 的团队也没闲着。就在这两天，他们又推了两波更新，分别是 2.1.1 和 2.1.2，修复了一些 bug 和安全问题，还顺带加了一些小改进。这是一天一波新发布的节奏啊。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg86bmCjxXmIWFq2IvGbmuwBebtZ6NA3Wv5AcLRMr2icRWTvYObSwrU7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="1.4763705103969755" data-s="300,640" data-type="png" data-w="1058" type="block" data-imgfileid="503527483" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/fbb53e8f-8f05-48fe-a5b9-6236bdb19826/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这种发布节奏，肯定少不了 AI 工具的功劳。毕竟 Boris 曾经提到，在之前的一个月，他提交了 259 个 PR，总共包含 497 次提交，4 万行代码增加，3.8 万行删除。每一行，都是 AI 写的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgKXV9Viae77fBxCDOJorRxfDFB1RrSCQoymm6lSlk1QyBIDDTA5NTJyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="2.3366336633663365" data-s="300,640" data-type="png" data-w="606" type="block" data-imgfileid="503527484" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/c0af70a2-5d23-4b84-bb48-c02220e1e51a/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不知道在这次的更新里，AI 编码占了多大的比例。&lt;/p&gt;&lt;p&gt;在之前的采访中，Boris 也透露过他们做 Claude Code 的一些方法论。其中比较有启发性的是，他们坚持用自己的产品作为真正的生产力工具，自己公司的人（包括研发模型的）都是 Claude Code 的重度用户，这能让他们尽快发现 bug，并在产品和模型层面做出更改。2.1.0 版本那一长串更改日志，或许就是这一理念的成果。&lt;/p&gt;&lt;p&gt;元旦假期期间，Boris Cherny 还开展了一波「线上教学」，亲自示范他自己使用这个 AI 编程工具的工作流。感兴趣的读者可以点开我们之前的文章作为参考：《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651010343&amp;idx=2&amp;sn=440edc0a537b0cf8820a967f54574cb7&amp;scene=21#wechat_redirect" target="_blank"&gt;500 万人在线围观，Claude Code 创建者的 13 条独家实战秘籍爆火&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;不过，对于这次的更新，也有开发者表示不满，指出更新多但 bug 也多，而且很多新功能不够简洁。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg3SuTf6YIkHIjicj5n5icLcnEd3rNy7eOY7Qszttr7M2yP40ZYNuEm4HA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.1885245901639344" data-s="300,640" data-type="png" data-w="976" type="block" data-imgfileid="503527485" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/7cae2942-773c-4f2a-bb70-2070b30a199a/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgn79GuhmSGxShboWaia9UwQ6tz8hPncr94y2WwxxnhGZzeib42QROVzhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.712037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527486" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/8f1a48da-051a-40cd-918f-3890d5f86784/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;你觉得新版本的 Claude Code 使用体验如何？欢迎在评论区讨论。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型如何泛化出多智能体推理能力？清华提出策略游戏自博弈方案MARSHAL</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 13:26:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/0e88a2bf-b342-4e3c-92b0-57ea5863de4b/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近日，清华大学等机构的研究团队提出了 &lt;strong&gt;MARSHAL &lt;/strong&gt;框架。该框架利用强化学习，让大模型在策略游戏中进行&lt;strong&gt;自博弈（Self-Play）&lt;/strong&gt;。实验表明，这种&lt;strong&gt;多轮、多智能体&lt;/strong&gt;训练&lt;strong&gt;不仅提升了模型在游戏中的博弈决策水平，更将其推理能力有效泛化到了通用的多智能体系统&lt;/strong&gt;：在如数学竞赛和专家级问答等一般推理任务中，显著提升了多智能体系统的整体表现。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gg4O1sFaAdficJ5a0wOkXRjjh4MIn8DQbKiaMFibm0JKjmQfwtkjiaiayoNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.42962962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527177" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d2cd5b34-6c5d-425f-91b3-c1a52a799066/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：MARSHAL: Incentivizing Multi-Agent Reasoning via Self-Play with Strategic LLMs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2510.15414&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://thu-nics.github.io/MARSHAL/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码开源：https://github.com/thu-nics/MARSHAL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型仓库：https://huggingface.co/collections/nics-efc/marshal&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、 背景与挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管 DeepSeek-R1 等大模型已在数学、问答等&lt;strong&gt;单轮、单智能体&lt;/strong&gt;场景中，验证了可验证奖励强化学习（RLVR）对提升推理能力的巨大价值；但在多智能体系统（MAS）复杂的&lt;strong&gt;多轮、多智能体&lt;/strong&gt;交互场景中，这一方法的应用仍处于探索阶段。具体而言，将 RLVR 拓展至多智能体领域面临着两大核心技术挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多轮交互的信用分配&lt;/strong&gt;：现有的单轮 RLVR 方法难以精准地将最终结果回溯并分配给每一个具体的轮次或动作，进而影响了模型的有效学习。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多智能体的优势估计&lt;/strong&gt;：不同智能体通常具有高度的异构性，其在优势估计（advantage estimation）中的优势基准（baseline）存在显著差异，导致多智能体联合训练难以收敛，策略表现波动剧烈。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决上述问题，为多智能体系统训练更强的推理模型，清华大学研究团队提出了 &lt;strong&gt;MARSHAL&lt;/strong&gt;（Multi-Agent Reasoning through Self-play witH strAtegic LLMs）框架，通过策略游戏中的多智能体自博弈和端到端强化学习，激发大模型的在通用多智能体系统中的推理决策能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85iaXwMACPJCzg65KRoB3Q8jA3A70ftsQHvYiaulwvmvZpheatiaEoOqxIw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.33240740740740743" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527162" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6c1b63c3-b2d5-4563-92a6-f45d722a1a3a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1 MARSHAL 在策略游戏的表现及通用推理基准泛化性能&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心实验结果：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;策略游戏：&lt;/strong&gt;多智能体博弈决策表现显著提升，测试游戏胜率提升高达&amp;nbsp;&lt;strong&gt;28.7%&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;泛化表现：&lt;/strong&gt;将模型集成至通用多智能体系统中时，在一般推理任务中展现出显著泛化性 &amp;mdash;&amp;mdash;AIME 准确率提升&lt;strong&gt;10.0%&lt;/strong&gt;（AutoGen 框架 [1]）；GPQA-Diamond 准确率提升&lt;strong&gt; 7.6%&lt;/strong&gt;（MAD 框架 [2]）；所有基准测试平均提升 &lt;strong&gt;3.5%&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;二、MARSHAL 方法介绍&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85DBwgodQwtLgn5ToP27IeXcmDz9uR6jODjDU9RjAxjM3taTJ9Cuh8xg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.387037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527163" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4564ca07-5db4-4d48-9318-0c91639708d3/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 2 MARSHAL 框架概览&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;面向策略游戏自博弈中多轮次、多智能体训练的挑战，MARSHAL 基于 Group-Relative Policy Optimization (GRPO) 架构，提出了两项关键算法改进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;轮次级优势估计器 (Turn-level Advantage Estimator)：&lt;/strong&gt;针对多轮交互中的信用分配问题，MARSHAL 摒弃了经典单轮 GRPO 粗糙的轨迹级评估，引入精细的轮次级（Turn-level）奖励机制，并设计了 &amp;ldquo;先求累计和再归一化（Sum-then-Normalize）&amp;rdquo; 的方法进行稳定的优势计算。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分角色的优势归一化 (Agent-specific Advantage Normalization)：&lt;/strong&gt;针对角色异构性导致的回报分布差异，MARSHAL 实施了严格区分角色的归一化策略：在计算优势时，系统不再将所有智能体混为一谈，而是根据角色的不同（例如 &amp;ldquo;玩家 1&amp;rdquo; 与 &amp;ldquo;玩家 2&amp;rdquo;）将数据分组。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了培养全面的多智能体推理能力，研究团队精心挑选了六款策略游戏（其中三款用于训练，另外三款用于测试），涵盖了从简单到复杂、从竞争到合作的多种博弈类型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85tgTMfNIw5b8Biap4unS8bZdg1iciaKkOw9FF5hYgxdQ1brrBngbicghf6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.18611111111111112" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527164" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7dd4c1e8-7f86-4f24-b597-3704dca4296e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 3 MARSHAL 使用的游戏集合&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、核心实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队以 Qwen3-4B 为基线模型，在三款训练游戏（Tic-Tac-Toe、Kuhn Poker、Mini Hanabi）中训练了两种类型的智能体：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;专家智能体 (Specialist)&lt;/strong&gt;：仅在单一游戏上训练。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通用智能体 (Generalist)&lt;/strong&gt;：在所有三款游戏上混合训练。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;游戏策略能力的泛化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MARSHAL 训练出的专家智能体在各自的同类型游戏中展现出出色的泛化性；通用智能体则在所有游戏类型中的综合表现最佳，在测试游戏中取得了高达&lt;strong&gt; 28.7% &lt;/strong&gt;的胜率提升。这些结果表明，模型并非仅仅记住了特定游戏的规则，而是真正掌握了通用的博弈逻辑（如 &amp;ldquo;先手优势利用&amp;rdquo;、&amp;ldquo;信息推断&amp;rdquo; 等），并能将其灵活泛化到全新的游戏环境中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85nJfrPtFETdb6Zr6M261QiafBMYJ2fibtwTciacZYfzWqTOiaDscr7NXNlA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.362962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527165" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/9bc7457e-6520-4b48-b92f-994bae007f84/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 4 MARSHAL 专家智能体在各类策略游戏中的胜率对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通用推理能力的泛化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是本研究最核心的实验，研究团队将 MARSHAL 模型作为基座集成到主流的多智能体框架（MAD 和 AutoGen）中，测试其在 7 种数学和问答基准测试上的成绩，最终得到两个关键结论：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;在策略游戏中习得的多智能体博弈能力，能够跨域泛化到通用的多智能体系统中，提升系统在一般推理任务中的表现。&lt;/strong&gt;综合表现最强的 MARSHAL 通用智能体在数学测试 AIME 和问答测试 GPQA 中分别取得高达&lt;strong&gt; 10.0%&lt;/strong&gt;&amp;nbsp;和&lt;strong&gt; 7.6%&lt;/strong&gt;&amp;nbsp;的提升；在所有测试中的平均提升高达&amp;nbsp;&lt;strong&gt;3.5%&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;能力泛化领域高度对齐&lt;/strong&gt;：在竞争性多智能体系统 MAD 中，竞争性游戏（Tic-Tac-Toe）训练的模型表现更优；而在合作性多智能体系统 AutoGen 中，合作性游戏（Hanabi）训练的模型表现更优。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85yKGldq8y74DEhBQCicgalyxccBwyN8TeLG16j0LYCIk8icvDf4tNqRQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527166" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/f8930760-0c0d-424a-afa3-02d4545e0191/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 5 MARSHAL 智能体在数学和问答推理测试中的泛化表现&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;以上实验结果强有力地证明了自博弈是提升多智能体系统推理能力的磨刀石。此外，在扩展到 8B 模型的实验中，MARSHAL 依然保持了强劲的增长势头，验证了该方法良好的可扩展性（Scalability）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、推理模式分析：模型学到了什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了探究 MARSHAL 成功泛化的原因，研究团队从定性和定量两个维度进行了深入分析。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定性分析&lt;/strong&gt;：通过对思维链（Chain-of-Thought）的深入解读，研究发现游戏训练激发了模型两项关键的涌现能力：&lt;strong&gt;1）角色意识（Role-Awareness）&lt;/strong&gt;，根据自身角色调整决策策略；&lt;strong&gt;2）意图识别（Intent Recognition）&lt;/strong&gt;，在不确定信息场景中根据其他智能体的决策动作判断其意图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85lT7GQ4ID167Ajr6GUQHcqLjaUIibu9kkYsqicXKibumIevd3g79gR7EOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527167" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/0edc7c4b-d6d3-4021-ab60-b0f51efcdd68/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 6 推理模型定性分析&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定量分析（Quantitative Analysis）：&lt;/strong&gt;为了进一步量化 MARSHAL 带来的多智能体推理能力的提升，研究团队对多智能体系统进行了失败模式分析。结果显示，MARSHAL 将&lt;strong&gt;智能体间未对齐（Inter-Agent Misalignment）&lt;/strong&gt;的情况减少了 11.5%，显著提升了模型在跨智能体的沟通效率和理解能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q857MLIbiae7IkdB8jsdibtyIp60VICJYZic19p4NovNpCWPSNhb1FTTvRmA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.24814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527168" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/28057def-a41b-4e17-bfc0-a70629ace240/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 7 失败模式定量分析&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、消融实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自博弈 vs 固定对手&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与固定专家对手进行训练相比，自博弈展现出了不可替代的优势。实验发现，针对固定对手训练的模型容易对训练环境过拟合，在测试游戏中性能急剧下降。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gu32HUE5ZRqgF4CdY2HY70uXfxaRdj0wkougbgcWhJicUsLdJYE45TkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.21388888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527176" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2dc4fce5-134a-4afc-b148-2793b60d587e/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8 MARSHAL 自博弈和固定对手训练方式在策略游戏中的对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优势估计算法设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队通过逐步移除核心算法组件，验证了 MARSHAL 算法设计的必要性：&lt;strong&gt;1）轮次级优势估计&lt;/strong&gt;的精细信用分配是处理长序列决策的关键；2）分角色归一化在角色回报差异大的竞争性游戏中（如 Tic-Tac-Toe）影响巨大，而在角色回报分布相似的合作游戏（如 Hanabi）中影响则相对较小。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85wWGgREFMO437ricqNibLkRS8BHbicJGpCLOyDGPqqvFOIEHQPhf4dNZWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3574074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527170" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/bf288f51-9ca5-457c-81e4-cb90b98dea50/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9 MARSHAL 算法设计的消融实验&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85nt52uOKc2LmodrSOXFib4HT29qj6BicRMqL3qbNZGGUeibicU6qd7Ov55w/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.8935185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527171" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/54b4161c-20cb-41b3-a868-c1b57aa741f5/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10 角色回报分布的差异性分析&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;六、总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该项研究工作提出了 &lt;strong&gt;MARSHAL &lt;/strong&gt;框架，通过在策略游戏中进行自博弈，成功增强了大语言模型在多智能体系统中的推理能力，提高了其在一般推理任务中的表现。核心结论如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;验证了策略游戏自博弈的泛化性&lt;/strong&gt;：在简单的策略游戏中通过自博弈习得的博弈技巧（如角色意识、意图识别）能够泛化到通用多智能体系统，在一般的推理任务中取得显著的效果提升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;提出了有效的技术方案&lt;/strong&gt;：通过轮次级优势估计和分角色的归一化等算法设计，为多轮、多智能体强化学习中的稳定训练提供了有效方案。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;尽管目前主要聚焦于双人博弈，但 MARSHAL 为未来通向更复杂的 &amp;ldquo;社会沙盒&amp;rdquo;（如多智能体协作编程、搜索、科研等）指明了潜在方向：自博弈不仅是 AlphaGo 战胜人类的法宝，也能成为大模型迈向更高阶群体智能的关键引擎。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考文献&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[1] Wu, Qingyun, et al. &amp;quot;Autogen: Enabling next-gen llm applications via multi-agent conversation.&amp;quot; COLM 2024.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[2] Liang, Tian, et al. &amp;quot;Encouraging divergent thinking in large language models through multi-agent debate.&amp;quot; EMNLP 2024.&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>医疗领域DeepSeek时刻：蚂蚁 · 安诊儿医疗大模型正式开源，登顶权威榜单</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 11:10:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/56b8e8e2-7c89-4ce4-b0f8-d0dbed5fa35b/1767928041035.png" style="width: 700%;" class="fr-fic fr-dib"&gt;人们获取医疗信息的方式，正在逐渐被 AI 改变。&lt;/p&gt;&lt;p&gt;2026 刚一开年，OpenAI 发布了一份有关普通人与 AI 医疗的报告。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527395" data-ratio="0.6092592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g1myypGge8sv8CAZ1r6pTl71kn5pCzaZHuKDaCQIYvplnYV9gwWKacQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ee38e1aa-7165-43e4-b822-f508aec61af5/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;报告给出的信息令人惊讶：目前全球 ChatGPT 对话中有超过 5% 是与医疗健康有关的，每天有 4000 万人在向 ChatGPT 寻求健康问题的答案。&lt;/p&gt;&lt;p&gt;在人们向 AI 问的问题中，大模型的智能与知识储备得到了充分体现：60% 的人用 AI 探索症状，52% 的人用于理解医学术语或临床建议；越来越多的医生也在撰写医疗报告的时候应用了 AI。&lt;/p&gt;&lt;p&gt;也正是因为如此，1 月 7 日，OpenAI 正式发布了 ChatGPT 健康，通过整合人们的健康信息与大模型能力，可以帮助人们更加了解自身状况，能辅助人们进行健康方面的决策。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"uuid":"mk52r2t2jvdymrloog"},["img",{"uuid":"qy33xx","name":"image.png","size":1198404,"width":748,"height":420.7506391589079,"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5b79d6ec3e11c5f12bb3f8c8c59c0cc9d75b8339e1c4c2483045ae20e3b2f02f2a1312cc16a80de92a156a98577f418d580a91f567c7f2bd2843067fae8d9744a765b5a3d6fa47e0abab6a5c4335c25d130ef4210c2486714?tmpCode=c39fa232-3ca1-46c7-914d-91a45b7bc376","extraData":{"resourceId":"0f6c48e0-23e2-490c-b4bc-d31b522aeee4","metaData":{"size":1198404,"originWidth":3840,"originHeight":2160,"format":"png","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnV1aWQlMjIlM0ElMjJtazUycjJ0Mmp2ZHltcmxvb2clMjIlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyaW5saW5lJTIyJTJDJTIydHlwZSUyMiUzQSUyMmltYWdlJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnV1aWQlMjIlM0ElMjJxeTMzeHglMjIlMkMlMjJuYW1lJTIyJTNBJTIyaW1hZ2UucG5nJTIyJTJDJTIyc2l6ZSUyMiUzQTExOTg0MDQlMkMlMjJ3aWR0aCUyMiUzQTc0OCUyQyUyMmhlaWdodCUyMiUzQTQyMC43NTA2MzkxNTg5MDc5JTJDJTIyc3JjJTIyJTNBJTIyaHR0cHMlM0ElMkYlMkZhbGlkb2NzLmRpbmd0YWxrLmNvbSUyRmNvcmUlMkZhcGklMkZyZXNvdXJjZXMlMkZpbWclMkY1ZWVjZGFmNDg0NjBjZGU1Yjc5ZDZlYzNlMTFjNWYxMmJiM2Y4YzhjNTljMGNjOWQ3NWI4MzM5ZTFjNGMyNDgzMDQ1YWUyMGUzYjJmMDJmMmExMzEyY2MxNmE4MGRlOTJhMTU2YTk4NTc3ZjQxOGQ1ODBhOTFmNTY3YzdmMmJkMjg0MzA2N2ZhZThkOTc0NGE3NjViNWEzZDZmYTQ3ZTBhYmFiNmE1YzQzMzVjMjVkMTMwZWY0MjEwYzI0ODY3MTQlM0Z0bXBDb2RlJTNEYzM5ZmEyMzItM2NhMS00NmM3LTkxNGQtOTFhNDViN2JjMzc2JTIyJTJDJTIyZXh0cmFEYXRhJTIyJTNBJTdCJTIycmVzb3VyY2VJZCUyMiUzQSUyMjBmNmM0OGUwLTIzZTItNDkwYy1iNGJjLWQzMWI1MjJhZWVlNCUyMiUyQyUyMm1ldGFEYXRhJTIyJTNBJTdCJTIyc2l6ZSUyMiUzQTExOTg0MDQlMkMlMjJvcmlnaW5XaWR0aCUyMiUzQTM4NDAlMkMlMjJvcmlnaW5IZWlnaHQlMjIlM0EyMTYwJTJDJTIyZm9ybWF0JTIyJTNBJTIycG5nJTIyJTJDJTIycmF0aW8lMjIlM0ExJTdEJTdEJTdEJTJDJTIybm9kZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMnRleHQlMjIlMkMlMjJsZWF2ZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMmxlYWYlMjIlMkMlMjJ0ZXh0JTIyJTNBJTIyJTIyJTJDJTIybWFya3MlMjIlM0ElNUIlNUQlN0QlNUQlN0QlNUQlN0QlNUQlMkMlMjJjb250ZW50VHlwZSUyMiUzQSUyMmNhbmdqaWUtdGV4dGJsb2NrJTIyJTdEJTVEJTdE" data-identifier-application__slash__x-doc-key="oJGq75kQMgRNylAK" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gficAwvgFVG3dXw9PXDHJM1W77iaFzDCbppe5QPgBBwDzhz241rRzs1Yg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-imgfileid="503527396" data-aistatus="1" data-original-style="width: 748px;height: 420.751px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/13c5b103-b96f-42ec-b6c6-9b85225bcd04/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;大模型正在生活的很多方面给我们带来帮助，但在面向常规任务的通用大模型上寻找医疗等专业知识的建议，很多时候还是显得不够靠谱。在医疗学术界，有研究就认为 AI 提供的医疗决策必须强制披露其准确性，接受监管以保护患者的安全。&lt;/p&gt;&lt;p&gt;近日，蚂蚁集团联合浙江省卫生健康信息中心、浙江省安诊儿医学人工智能科技有限公司开源的&lt;strong&gt;蚂蚁・安诊儿医疗大模型（AntAngelMed）&lt;/strong&gt;，似乎为这些需求找到了最优解。&lt;/p&gt;&lt;p&gt;该模型总参数量达到 &lt;strong&gt;1000 亿（激活参数 61 亿），是迄今为止参数量最大的开源医疗领域专业模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;AntAngelMed 在 OpenAI 发起的 HealthBench、国家人工智能应用中试基地（医疗）的 MedAIBench 等评测基准中表现出色，其成绩超过了 GPT-oss、Qwen3、DeepSeek-R1 等通用模型，也超越了目前已有的医疗增强推理模型，达到了开源模型第一的成绩。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"jc":"center","uuid":"mk4u46irvx5y31c4ws"},["img",{"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5b79d6ec3e11c5f12bb3f8c8c59c0cc9d75b8339e1c4c2483045ae20e3b2f02f2a1312cc16a80de92a156a98577f418d548e75f0846690b3d40203800288123e3309626b4ba3cc92a6bdfa1586a00722c0fe0385e31a614ee?tmpCode=3b2b29d4-7985-4ba4-90f2-09b75320876e","width":746,"height":275.85732087227416,"uuid":"mk4u46hhn5dkia59m7g","extraData":{"resourceId":"b5c12e3e-2892-4ca6-b8df-911421db8cbc","metaData":{"size":246666,"originWidth":3210,"originHeight":1187,"format":"png","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMmpjJTIyJTNBJTIyY2VudGVyJTIyJTJDJTIydXVpZCUyMiUzQSUyMm1rNHU0Nmlydng1eTMxYzR3cyUyMiU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJpbmxpbmUlMjIlMkMlMjJ0eXBlJTIyJTNBJTIyaW1hZ2UlMjIlMkMlMjJkYXRhJTIyJTNBJTdCJTIyc3JjJTIyJTNBJTIyaHR0cHMlM0ElMkYlMkZhbGlkb2NzLmRpbmd0YWxrLmNvbSUyRmNvcmUlMkZhcGklMkZyZXNvdXJjZXMlMkZpbWclMkY1ZWVjZGFmNDg0NjBjZGU1Yjc5ZDZlYzNlMTFjNWYxMmJiM2Y4YzhjNTljMGNjOWQ3NWI4MzM5ZTFjNGMyNDgzMDQ1YWUyMGUzYjJmMDJmMmExMzEyY2MxNmE4MGRlOTJhMTU2YTk4NTc3ZjQxOGQ1NDhlNzVmMDg0NjY5MGIzZDQwMjAzODAwMjg4MTIzZTMzMDk2MjZiNGJhM2NjOTJhNmJkZmExNTg2YTAwNzIyYzBmZTAzODVlMzFhNjE0ZWUlM0Z0bXBDb2RlJTNEM2IyYjI5ZDQtNzk4NS00YmE0LTkwZjItMDliNzUzMjA4NzZlJTIyJTJDJTIyd2lkdGglMjIlM0E3NDYlMkMlMjJoZWlnaHQlMjIlM0EyNzUuODU3MzIwODcyMjc0MTYlMkMlMjJ1dWlkJTIyJTNBJTIybWs0dTQ2aGhuNWRraWE1OW03ZyUyMiUyQyUyMmV4dHJhRGF0YSUyMiUzQSU3QiUyMnJlc291cmNlSWQlMjIlM0ElMjJiNWMxMmUzZS0yODkyLTRjYTYtYjhkZi05MTE0MjFkYjhjYmMlMjIlMkMlMjJtZXRhRGF0YSUyMiUzQSU3QiUyMnNpemUlMjIlM0EyNDY2NjYlMkMlMjJvcmlnaW5XaWR0aCUyMiUzQTMyMTAlMkMlMjJvcmlnaW5IZWlnaHQlMjIlM0ExMTg3JTJDJTIyZm9ybWF0JTIyJTNBJTIycG5nJTIyJTJDJTIycmF0aW8lMjIlM0ExJTdEJTdEJTdEJTJDJTIybm9kZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMnRleHQlMjIlMkMlMjJsZWF2ZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMmxlYWYlMjIlMkMlMjJ0ZXh0JTIyJTNBJTIyJTIyJTJDJTIybWFya3MlMjIlM0ElNUIlNUQlN0QlNUQlN0QlNUQlN0QlNUQlMkMlMjJjb250ZW50VHlwZSUyMiUzQSUyMmNhbmdqaWUtdGV4dGJsb2NrJTIyJTdEJTVEJTdE" data-identifier-application__slash__x-doc-key="oJGq75kQMgRNylAK" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gLOLT5NMwZxvm8eTMeMFfTJc7sk57ticI3NL9kNfGMIP6EYic9g8NLvlA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.36944444444444446" data-type="png" data-w="1080" data-imgfileid="503527397" data-aistatus="1" data-original-style="width: 746px;height: 275.857px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6997faa1-f689-462f-99fb-8251b7c69da1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;在由国家人工智能应用中试基地（医疗）・浙江、中国医学科学院北京协和医学院、中国信息通信研究院三方共建的权威测评体系 MedAIBench 中（ https://www.medaibench.cn/ ），AntAngelMed 同样表现突出，尤其是在医疗知识问答、医疗伦理安全等多个核心维度上优势显著。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gQDTHfMaHUKXvOnqlI1shj04xbgaKe9lUf5Xb1Ounza4JP39fB925AQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.625" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527442" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c99281fb-4c2f-49d1-b006-b91a7d8ca862/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，AntAngelMed 在 &lt;strong&gt;MedBench 排行榜中位列第一&lt;/strong&gt;。MedBench 是专为评估中国医疗健康领域语言大模型（LLM）而设计的权威基准。AntAngelMed 的这一成绩进一步凸显了其在专业性、安全性以及临床应用潜力方面的领先表现。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"jc":"center","uuid":"mk4u46itsx2nmx6hxi"},["img",{"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5b79d6ec3e11c5f12bb3f8c8c59c0cc9d75b8339e1c4c2483045ae20e3b2f02f2a1312cc16a80de92a156a98577f418d528057e8420904ccfc06673914411b5047abf87519fbac5bfc9451ca1f36e876108bcbdd0401f6d3b?tmpCode=2de91cd3-326f-4d7b-9436-788f5cf55851","width":746,"height":1224.2051282051282,"uuid":"mk4u46hhayj7ujr2rse","extraData":{"resourceId":"bdbd6cdf-d2c4-471e-83e6-8f19744b8afa","metaData":{"size":324560,"originWidth":780,"originHeight":1280,"format":"png","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMmpjJTIyJTNBJTIyY2VudGVyJTIyJTJDJTIydXVpZCUyMiUzQSUyMm1rNHU0Nml0c3gybm14Nmh4aSUyMiU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJpbmxpbmUlMjIlMkMlMjJ0eXBlJTIyJTNBJTIyaW1hZ2UlMjIlMkMlMjJkYXRhJTIyJTNBJTdCJTIyc3JjJTIyJTNBJTIyaHR0cHMlM0ElMkYlMkZhbGlkb2NzLmRpbmd0YWxrLmNvbSUyRmNvcmUlMkZhcGklMkZyZXNvdXJjZXMlMkZpbWclMkY1ZWVjZGFmNDg0NjBjZGU1Yjc5ZDZlYzNlMTFjNWYxMmJiM2Y4YzhjNTljMGNjOWQ3NWI4MzM5ZTFjNGMyNDgzMDQ1YWUyMGUzYjJmMDJmMmExMzEyY2MxNmE4MGRlOTJhMTU2YTk4NTc3ZjQxOGQ1MjgwNTdlODQyMDkwNGNjZmMwNjY3MzkxNDQxMWI1MDQ3YWJmODc1MTlmYmFjNWJmYzk0NTFjYTFmMzZlODc2MTA4YmNiZGQwNDAxZjZkM2IlM0Z0bXBDb2RlJTNEMmRlOTFjZDMtMzI2Zi00ZDdiLTk0MzYtNzg4ZjVjZjU1ODUxJTIyJTJDJTIyd2lkdGglMjIlM0E3NDYlMkMlMjJoZWlnaHQlMjIlM0ExMjI0LjIwNTEyODIwNTEyODIlMkMlMjJ1dWlkJTIyJTNBJTIybWs0dTQ2aGhheWo3dWpyMnJzZSUyMiUyQyUyMmV4dHJhRGF0YSUyMiUzQSU3QiUyMnJlc291cmNlSWQlMjIlM0ElMjJiZGJkNmNkZi1kMmM0LTQ3MWUtODNlNi04ZjE5NzQ0YjhhZmElMjIlMkMlMjJtZXRhRGF0YSUyMiUzQSU3QiUyMnNpemUlMjIlM0EzMjQ1NjAlMkMlMjJvcmlnaW5XaWR0aCUyMiUzQTc4MCUyQyUyMm9yaWdpbkhlaWdodCUyMiUzQTEyODAlMkMlMjJmb3JtYXQlMjIlM0ElMjJwbmclMjIlMkMlMjJyYXRpbyUyMiUzQTElN0QlN0QlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIydGV4dCUyMiUyQyUyMmxlYXZlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIybGVhZiUyMiUyQyUyMnRleHQlMjIlM0ElMjIlMjIlMkMlMjJtYXJrcyUyMiUzQSU1QiU1RCU3RCU1RCU3RCU1RCU3RCU1RCUyQyUyMmNvbnRlbnRUeXBlJTIyJTNBJTIyY2FuZ2ppZS10ZXh0YmxvY2slMjIlN0QlNUQlN0Q=" data-identifier-application__slash__x-doc-key="oJGq75kQMgRNylAK" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gEsa68Ryzp2XiaGXfp1CCn3Gq2pVyKrAeQlfSXdkRpwSeVYHXMAfY6Zw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.641025641025641" data-type="png" data-w="780" data-imgfileid="503527398" data-aistatus="1" data-original-style="width: 746px;height: 1224.21px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5547b44d-434d-465f-a207-94c260594de1/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;目前 AntAngelMed 模型系列已在模型平台开源：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;HuggingFace：https://huggingface.co/MedAIBase/AntAngelMed&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ModelScope：https://modelscope.cn/models/MedAIBase/AntAngelMed&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github: https://github.com/MedAIBase/AntAngelMed&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;AntAngelMed 背后的技术 &amp;nbsp;专业三阶段训练&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与通用模型不同，医疗大模型面对的评价标准不仅仅是「答得多流畅」，还要强调结论的可靠性与可控性：既要在证据充分时给出严谨判断，也要在信息不足或风险较高时保持克制、明确安全边界。要满足这种要求，模型不仅需要覆盖系统化的医学知识，更需要具备稳定的推理能力与风险意识。&lt;/p&gt;&lt;p&gt;AntAngelMed 作为一款专注医疗垂直领域的开源大模型，其训练策略正是围绕上述要求展开的，形成了一套以医学能力构建为目标的&lt;strong&gt;三阶段训练流程&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一阶段是持续预训练，为模型注入医学知识。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;团队在蚂蚁百灵通用基座模型 Ling-flash-2.0-base 上系统性引入大规模、高质量医学语料，比如百科全书、网络文本、学术出版物。&lt;/p&gt;&lt;p&gt;通过这一过程，模型构建起了稳定而完整的医学知识结构，为后续的医学能力打下坚实的地基。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二阶段是面向真实医疗任务的监督微调。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AntAngelMed 引入了来自不同来源、不同形式的高质量医疗指令数据，重点微调模型如何展开和表达推理过程。这一阶段不仅提升了模型在复杂问题中的思考稳定性，也使其在医患问答、诊断分析等真实场景中，能够更好地理解问题语境并给出符合医疗交流逻辑的回应。&lt;/p&gt;&lt;p&gt;这样一来，AntAngelMed 不再仅仅停留在回答正确的表层表现上，而是在医疗语境中展现出更接近专业医生的沟通方式与思维路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三阶段是强化学习，控制 AI 医疗回答的边界与行为方式。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AntAngelMed 采用先进的 GRPO（Group Relative Policy Optimization，组相对策略优化） 强化学习算法，并通过双阶段强化学习路径对模型能力进一步优化提升。&lt;/p&gt;&lt;p&gt;首先是「推理强化学习」，确保模型面对复杂病例信息时能保持因果链条清晰、判断过程可追溯。&lt;/p&gt;&lt;p&gt;然后是「通用强化学习」，重点关注模型的行为边界，在面对不确定性、敏感性问题时学会提示风险、适度保留，体现出必要的责任意识和安全规范。&lt;/p&gt;&lt;p&gt;可以说这一阶段是通用大模型最容易「踩雷」的部分，而也是医疗 AI 最重要的「合规能力」。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"jc":"center","uuid":"mk4u46j16aw08hwfdch"},["img",{"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5b79d6ec3e11c5f12bb3f8c8c59c0cc9d75b8339e1c4c2483045ae20e3b2f02f2a1312cc16a80de92a156a98577f418d58b59135afa2b11b469b71469c51ada918b8cd1040295525ae58ab443aece068b40770ebd017fdae5?tmpCode=bab93aa5-10dc-418f-9449-7df81e04a172","width":746,"height":415.97235023041475,"uuid":"mk4u46hhs7aq82mug4k","extraData":{"resourceId":"aa623853-1947-4717-8ade-e6398adab396","metaData":{"size":341125,"originWidth":1302,"originHeight":726,"format":"png","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMmpjJTIyJTNBJTIyY2VudGVyJTIyJTJDJTIydXVpZCUyMiUzQSUyMm1rNHU0NmoxNmF3MDhod2ZkY2glMjIlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyaW5saW5lJTIyJTJDJTIydHlwZSUyMiUzQSUyMmltYWdlJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnNyYyUyMiUzQSUyMmh0dHBzJTNBJTJGJTJGYWxpZG9jcy5kaW5ndGFsay5jb20lMkZjb3JlJTJGYXBpJTJGcmVzb3VyY2VzJTJGaW1nJTJGNWVlY2RhZjQ4NDYwY2RlNWI3OWQ2ZWMzZTExYzVmMTJiYjNmOGM4YzU5YzBjYzlkNzViODMzOWUxYzRjMjQ4MzA0NWFlMjBlM2IyZjAyZjJhMTMxMmNjMTZhODBkZTkyYTE1NmE5ODU3N2Y0MThkNThiNTkxMzVhZmEyYjExYjQ2OWI3MTQ2OWM1MWFkYTkxOGI4Y2QxMDQwMjk1NTI1YWU1OGFiNDQzYWVjZTA2OGI0MDc3MGViZDAxN2ZkYWU1JTNGdG1wQ29kZSUzRGJhYjkzYWE1LTEwZGMtNDE4Zi05NDQ5LTdkZjgxZTA0YTE3MiUyMiUyQyUyMndpZHRoJTIyJTNBNzQ2JTJDJTIyaGVpZ2h0JTIyJTNBNDE1Ljk3MjM1MDIzMDQxNDc1JTJDJTIydXVpZCUyMiUzQSUyMm1rNHU0NmhoczdhcTgybXVnNGslMjIlMkMlMjJleHRyYURhdGElMjIlM0ElN0IlMjJyZXNvdXJjZUlkJTIyJTNBJTIyYWE2MjM4NTMtMTk0Ny00NzE3LThhZGUtZTYzOThhZGFiMzk2JTIyJTJDJTIybWV0YURhdGElMjIlM0ElN0IlMjJzaXplJTIyJTNBMzQxMTI1JTJDJTIyb3JpZ2luV2lkdGglMjIlM0ExMzAyJTJDJTIyb3JpZ2luSGVpZ2h0JTIyJTNBNzI2JTJDJTIyZm9ybWF0JTIyJTNBJTIycG5nJTIyJTJDJTIycmF0aW8lMjIlM0ExJTdEJTdEJTdEJTJDJTIybm9kZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMnRleHQlMjIlMkMlMjJsZWF2ZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMmxlYWYlMjIlMkMlMjJ0ZXh0JTIyJTNBJTIyJTIyJTJDJTIybWFya3MlMjIlM0ElNUIlNUQlN0QlNUQlN0QlNUQlN0QlNUQlMkMlMjJjb250ZW50VHlwZSUyMiUzQSUyMmNhbmdqaWUtdGV4dGJsb2NrJTIyJTdEJTVEJTdE" data-identifier-application__slash__x-doc-key="oJGq75kQMgRNylAK" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g8aWBKUqDQP3XZjR9HVOWjwdsmfDicgo68JVHdZTDumaicv5WibHdtNHCA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5574074074074075" data-type="png" data-w="1080" data-imgfileid="503527400" data-aistatus="1" data-original-style="width: 746px;height: 415.972px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d5e8a8e0-0bef-4e8f-a645-8af92ddef2ec/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; AntAngelMed 专业三阶段训练流程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;高效 MoE 架构，高效推理能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除了能力结构的精细建构，AntAngelMed 也在工程设计上充分考虑医疗系统的部署需求。&lt;/p&gt;&lt;p&gt;AntAngelMed 继承了&lt;strong&gt;&amp;nbsp;Ling-flash-2.0 的先进架构&lt;/strong&gt;，是一个高效的混合专家（MoE）模型。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"jc":"center","uuid":"mk4u46j3m3znfd20hxj"},["img",{"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5b79d6ec3e11c5f12bb3f8c8c59c0cc9d75b8339e1c4c2483045ae20e3b2f02f2a1312cc16a80de92a156a98577f418d551040abd8e4a5935ba45121a48dcd7b63a98377128697e3c3aec16b24d76cc498567360fec8700c4?tmpCode=4283bd3b-ee9f-4704-a231-3eba15ddc79f","width":746,"height":670.5684713375797,"uuid":"mk4u46hh0vtga8xm53be","extraData":{"resourceId":"90e0ea30-5aca-4b5d-b9ab-808e535e3fc9","metaData":{"size":633767,"originWidth":1256,"originHeight":1129,"format":"png","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMmpjJTIyJTNBJTIyY2VudGVyJTIyJTJDJTIydXVpZCUyMiUzQSUyMm1rNHU0NmozbTN6bmZkMjBoeGolMjIlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyaW5saW5lJTIyJTJDJTIydHlwZSUyMiUzQSUyMmltYWdlJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnNyYyUyMiUzQSUyMmh0dHBzJTNBJTJGJTJGYWxpZG9jcy5kaW5ndGFsay5jb20lMkZjb3JlJTJGYXBpJTJGcmVzb3VyY2VzJTJGaW1nJTJGNWVlY2RhZjQ4NDYwY2RlNWI3OWQ2ZWMzZTExYzVmMTJiYjNmOGM4YzU5YzBjYzlkNzViODMzOWUxYzRjMjQ4MzA0NWFlMjBlM2IyZjAyZjJhMTMxMmNjMTZhODBkZTkyYTE1NmE5ODU3N2Y0MThkNTUxMDQwYWJkOGU0YTU5MzViYTQ1MTIxYTQ4ZGNkN2I2M2E5ODM3NzEyODY5N2UzYzNhZWMxNmIyNGQ3NmNjNDk4NTY3MzYwZmVjODcwMGM0JTNGdG1wQ29kZSUzRDQyODNiZDNiLWVlOWYtNDcwNC1hMjMxLTNlYmExNWRkYzc5ZiUyMiUyQyUyMndpZHRoJTIyJTNBNzQ2JTJDJTIyaGVpZ2h0JTIyJTNBNjcwLjU2ODQ3MTMzNzU3OTclMkMlMjJ1dWlkJTIyJTNBJTIybWs0dTQ2aGgwdnRnYTh4bTUzYmUlMjIlMkMlMjJleHRyYURhdGElMjIlM0ElN0IlMjJyZXNvdXJjZUlkJTIyJTNBJTIyOTBlMGVhMzAtNWFjYS00YjVkLWI5YWItODA4ZTUzNWUzZmM5JTIyJTJDJTIybWV0YURhdGElMjIlM0ElN0IlMjJzaXplJTIyJTNBNjMzNzY3JTJDJTIyb3JpZ2luV2lkdGglMjIlM0ExMjU2JTJDJTIyb3JpZ2luSGVpZ2h0JTIyJTNBMTEyOSUyQyUyMmZvcm1hdCUyMiUzQSUyMnBuZyUyMiUyQyUyMnJhdGlvJTIyJTNBMSU3RCU3RCU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJ0ZXh0JTIyJTJDJTIybGVhdmVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJsZWFmJTIyJTJDJTIydGV4dCUyMiUzQSUyMiUyMiUyQyUyMm1hcmtzJTIyJTNBJTVCJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTJDJTIyY29udGVudFR5cGUlMjIlM0ElMjJjYW5namllLXRleHRibG9jayUyMiU3RCU1RCU3RA==" data-identifier-application__slash__x-doc-key="oJGq75kQMgRNylAK" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g5iahYsXz20pt0cJHsQcjRndXpeEmBFNs3fkdX6fxaicptpR3DCUFP1bA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.899074074074074" data-type="png" data-w="1080" data-imgfileid="503527401" data-aistatus="1" data-original-style="width: 746px;height: 670.568px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/8a74cd18-fa9e-4d0b-9c8c-3c46bd3511c6/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Ling-flash-2.0 模型架构&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 Ling Scaling Laws 的指导下，只激活 1/32 参数（61 亿），并在专家粒度、共享专家比例、注意力平衡、无辅助损失函数 + Sigmoid 路由、MTP 层、QK-Norm 和 Partial-RoPE 等核心组件上进行了全面优化。&lt;/p&gt;&lt;p&gt;这些优化使得小激活率的 MoE 模型相比同等规模的 Dense 架构，可以实现高达 7 倍的效率提升。&lt;/p&gt;&lt;p&gt;也就是说，AntAngelMed 仅需 6.1B 激活参数，就能实现约 40B 稠密模型的性能。这意味着模型在实际部署中对资源的占用更低、可扩展性更强，非常适合高用户需求的医疗领域。&lt;/p&gt;&lt;p&gt;由于激活参数较少，AntAngelMed 具备非常高的推理效率，在 H20 硬件环境下，可实现超过 &lt;strong&gt;200 tokens/s 的推理速度&lt;/strong&gt;，约为 36B 稠密模型的 3 倍。&lt;/p&gt;&lt;p&gt;对于医疗场景而言，这样的推理效率不仅代表响应更快，更重要的是，它提升了模型在实际系统中的可用性：在多用户同时访问的医疗平台上，能够保证稳定输出；在需要快速辅助决策的临床场景中，能在数秒内完成高质量回答，减少等待时间；甚至在资源受限的边缘部署环境中，也能以较低算力负担提供可用性能。&lt;/p&gt;&lt;p&gt;另外，医疗场景中常常伴随着篇幅较长的病历记录和结构复杂的检查报告，信息密度高、语义层级深，对模型的理解与处理能力提出了更高要求。&lt;/p&gt;&lt;p&gt;为解决这一需求，AntAngelMed 采用 YaRN 外推，将&lt;strong&gt;上下文长度扩展至 128K&lt;/strong&gt;，大幅增强了模型处理病历等长文档的能力。&lt;/p&gt;&lt;p&gt;此外，为配合进一步推理加速，团队还采用了 FP8 量化技术并结合 EAGLE3 优化方案。这种软硬结合的设计带来了实实在在性能提升。&lt;/p&gt;&lt;p&gt;在并发数为 32 的情况下，与单独使用 FP8 相比，这种方法显著提高了推理吞吐量，在 HumanEval 数据集上的提升幅度为 71%，在 GSM8K 数据集上的提升幅度为 45%，在 Math-500 数据集上的提升幅度更是高达 94%。&lt;/p&gt;&lt;p&gt;从训练流程到模型架构，我们不难看出，AntAngelMed 的设计始终围绕医疗场景展开。三阶段训练方式让模型具备了专业的医学知识，而高效的 MoE 架构，使得模型在医疗这种高频次、高要求的场景下，在大幅降低激活成本的同时，依然保持专业推理能力与长上下文处理能力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;span data-type="text"&gt;&lt;span data-type="leaf"&gt;&lt;strong&gt;AntAngelMed：领先的医学专业模型&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;最后，我们上手体验了一番，看看 AntAngelMed 真实效果如何？&lt;/p&gt;&lt;p&gt;先来个大家都忽视但又每天经历的事情，一个成年人一天到底要吃几个鸡蛋。&lt;/p&gt;&lt;p&gt;AntAngelMed 的响应速度非常快，几乎在我们输入问题后没几秒就给出了答复。&lt;/p&gt;&lt;p&gt;模型的建议并非简单罗列营养标准，而是结合了胆固醇摄入上限、个体健康状况（如有无高血脂病史）等因素，给出了一个相对灵活的建议区间：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69g9Gm1LxXLrTNNUqHk5icm2PjgcLYR2JuS6IW20tOj5icz1pm5l0JcuBHQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.7803521779425394" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503527406" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7bab1ef8-8601-4a1f-8e35-c173c1becdc1/640.gif" data-order="0" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来我们又问了一个问题：请为一个 55 岁有高血压病史的上班族男性，设计一个简洁可执行的一周饮食 + 运动建议计划。&lt;/p&gt;&lt;p&gt;AntAngelMed 的回答简直比医生还详细，还做了表格方便用户查看：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9UqS57fv5tDCzF2QFibn69gUUCwvPKqHYZzpAnT3Masic5wypw5NaOhgthfyReB6H0ono2SkUeic7gg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.7877664504170528" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503527407" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/3e3379b8-f146-4b03-ae93-c5bc4f1a69e9/640.gif" data-order="1" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AntAngelMed 的开源，对于 AI 和医疗行业而言具有重要意义。&lt;/p&gt;&lt;p&gt;在 AntAngelMed 的基础上，大量机构和研究者可以进行下游任务微调，极大地降低了前沿医疗 AI 技术的应用门槛。对于普通人来说，或许过不了多久，我们就可以从 AI 那里获得安全可信的建议了。&lt;/p&gt;&lt;p&gt;据介绍，蚂蚁集团还将依托国家平台持续推进「AI + 医疗」的开源生态与技术创新，让先进的技术能够普惠更多开发者与用户。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026 Oral | 大模型「爱你在心口难开」？深度隐藏认知让推理更可靠</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 09 Jan 2026 11:04:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-09</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-09</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/115d110d-c38e-41bd-b62b-2624ea413269/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;近年来，大语言模型在算术、逻辑、多模态理解等任务上之所以取得显著进展，很大程度上依赖于思维链（CoT）技术。所谓 CoT，就是让模型在给出最终答案前，先生成一系列类似「解题步骤」的中间推理。 这种方式可以显著提高模型在复杂推理类任务上的表现，已成为当前最主流的推理增强方法。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;但从实际使用和研究结果来看，CoT 的表现并非始终稳定。一些任务中可以明显观察到：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="7,0,0"&gt;不同推理路径之间质量差异很大。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="7,1,0"&gt;模型即使在训练或提示方式保持一致的情况下，生成的中间步骤仍可能出现偏差。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="7,2,0"&gt;推理链内部的正确性并不总能通过表面概率反映出来。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="8"&gt;那么问题来了：&lt;strong&gt;大模型有没有可能「意识到自己正在犯错」？在 Token 概率不可靠的情况下，是否有其他信号可以指导更可靠的生成？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;在这一背景下，合肥工业大学的研究团队提出了一个观点：&lt;strong&gt;大模型的内部其实存在一种「隐藏的真伪认知」。这种状态可以形象地理解为「爱你在心口难开」&amp;mdash;&amp;mdash;模型在内部激活中已隐含对推理正确性的判断，但这种判断却在基于 Token 概率的生成过程中被错误地表达。因此，模型即便「口头说错」，其内部表征中仍保留着对纠错的可能。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;这篇论文的核心，就是让模型学会用这种隐藏认知来给自己的每一步推理「打分」，进而过滤掉错误的推理链，让 CoT 更可靠。该工作已被 AAAI 2026 录用为 Oral 论文。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNsz8q1zGlwNrcX9hFOj5F2C0yib2E9EWF2szoYDbiclYdt9cpNnMfjtkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.18796296296296297" data-type="png" data-w="1080" data-width="1423" data-height="268" data-imgfileid="503527036" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6622d1bf-3eda-4a92-ad18-98f53557a22b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;论文标题：Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning&lt;/li&gt;&lt;li&gt;论文链接：https://arxiv.org/abs/2507.10007&lt;/li&gt;&lt;li&gt;GitHub 开源代码链接：https://github.com/hfutml/cog-cot&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="12"&gt;&lt;strong&gt;研究背景与问题&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="13"&gt;随着大语言模型在数学推理、逻辑推理与多模态问答等领域的应用不断扩大，人们越来越关注一个核心能力：&lt;strong&gt;模型是否能够在生成过程中保持稳定且可靠的推理质量。&lt;/strong&gt;在实际使用中，模型往往需要连续推导多个中间步骤才能得到最终答案，这使得推理链的质量对整体表现具有决定性影响。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;然而，推理链本身是通过生成式过程逐步展开的，其可靠性受到多种因素影响，例如：模型对问题理解的细微偏差、局部步骤的表达噪声、长链推理中的累积误差等。即便模型整体能力足够强，这些因素仍可能导致某些推理步骤偏离正确方向，影响最终回答的准确度。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;因此，一个自然且重要的问题是：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;在推理过程中，是否存在某种可以反映当前步骤可靠性的内部信号，从而帮助我们判断哪些推理路径值得继续扩展？&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-path-to-node="17"&gt;大语言模型在生成每一步推理时都会产生丰富的内部激活，这些表示承载了模型对输入、上下文以及当前推理状态的理解。 如果这些激活中包含区分「合理推理」与「错误推理」的信息，那么我们就有可能在生成阶段实时利用这些内部线索，从而提升推理链的整体质量。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;基于这一动机，这项研究聚焦于两个关键问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="19,0,0"&gt;模型的内部激活是否蕴含对推理步骤真伪的有效区分信息？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="19,1,0"&gt;如果存在，能否构建一个利用这些信息的机制，帮助模型在推理过程中选择更可靠的路径？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="20"&gt;论文提出的方案正是在回答这两个问题，并尝试让推理过程在模型原有能力基础上变得更稳健、更具判断力。&lt;/p&gt;&lt;p data-path-to-node="21"&gt;&lt;strong&gt;方法与创新&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;论文提出的框架，核心思想是：虽然模型表面生成的推理步骤可能不够可靠，但其内部激活在很大程度上「知道」哪些步骤是正确的。为此，作者设计了以下创新方法：&lt;/p&gt;&lt;p data-path-to-node="23"&gt;&lt;b data-index-in-node="0" data-path-to-node="23"&gt;从多层注意力头中探测「真伪敏感性」&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对模型生成的推理步骤进行真伪标注（True/False），然后在模型各层的内部表示上训练简单探针（Linear Probe），测试哪些层对推理正确性最敏感。&lt;/p&gt;&lt;p&gt;结果表明：&lt;strong&gt;中间层的特定注意力头能区分「正确步骤」和「错误步骤」，准确率可达 80% 以上。&lt;/strong&gt;这说明模型的内部确实蕴含潜在的认知信号。&lt;/p&gt;&lt;p data-path-to-node="25"&gt;&lt;b data-index-in-node="0" data-path-to-node="25"&gt;构建置信度预测器（Confidence Predictor）&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="26"&gt;作者选取最敏感的几个注意力头，将其激活拼接，作为输入训练一个轻量预测器，输出对每一步推理的可信度评分。该评分不基于 Token 概率，而基于模型内部的深层表示，更能反映推理质量。&lt;/p&gt;&lt;p data-path-to-node="27"&gt;&lt;b data-index-in-node="0" data-path-to-node="27"&gt;基于置信度的推理路径搜索（Confidence-Guided Search）&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;结合模型生成概率与可信度，设计新的推理扩展策略：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNP9OFVnS7iadU7nm0zsNrHoUMZkRXozbnIVWjibF8LlWLKPRwG7zw8Ticg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.08045977011494253" data-s="300,640" data-type="png" data-w="522" type="block" data-imgfileid="503527037" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2fd7bffb-6ea2-4bc7-9392-eef95a567667/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="30"&gt;通过此评分筛选最可信的推理路径，使生成过程能够：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="31,0,0"&gt;主动避开不可靠的步骤；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="31,1,0"&gt;优先扩展有潜力的推理方向；&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="31,2,0"&gt;从而提高整个 CoT 推理链的稳定性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN1pm6DDSmNgZC1gz10XIwibicfiaNHVkmXIKhG54fhaONib4ZzdeXgmGMhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.48703703703703705" data-type="png" data-w="1080" data-width="1526" data-height="743" data-imgfileid="503527038" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/57c785d2-8cff-4bd4-8458-244d3a2beb45/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="32"&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;论文从两个层面系统评估了所提出方法的有效性：（A）可信度预测器本身是否可靠？（B）将预测器用于推理路径选择后，整体推理是否更准确？&lt;/p&gt;&lt;p data-path-to-node="34"&gt;下面分两部分介绍。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;&lt;b data-index-in-node="0" data-path-to-node="35"&gt;A. 置信度预测器的评估&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="36"&gt;作者首先评估模型内部激活是否真的携带「推理真伪」的可判别信号，以及预测器能否有效地从激活中提取这种信号。核心实验包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;真伪区分能力&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过在模型不同层、不同注意力头上训练线性探针，研究者获得了以下发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="37,0,1,0,0"&gt;中间层的部分注意力头对推理真伪高度敏感；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="37,0,1,1,0"&gt;特定激活向量可实现 80%&amp;ndash;85% 的真伪区分准确率；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;早期层和后期层的判别能力相对较弱。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一结果表明：模型在内部表征中「隐含地知道」某一步推理是否正确。预测器正是利用这些「高敏感」注意力头，因此具有良好的理论基础。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;可信度预测的校准效果&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;论文进一步引入 ECE-Loss 进行校准，使预测的可信度分数更可解释、更稳定。实验显示置信度预测器得到的可信度分数校准性更佳，&lt;strong&gt;即得到的置信度分数更贴近真实的真伪概率值&lt;/strong&gt;，作者用 ECE、Brier 和 AUC 这三个校准指标以及多种置信度量化方法来评估，如下表：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNRBkoSXbOEfyuloI4MRUSw0cXayTiaY3mo6BlH68Q9PHdIn704oicj5Xg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5087956698240866" data-type="png" data-w="739" data-width="739" data-height="376" data-imgfileid="503527039" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/01d10642-b22c-4991-b437-5e2ecc8f8495/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这证明预测器不仅能区分真伪，还能提供更具校准性、可用于决策的连续置信度评分，适合作为搜索策略的依据。&lt;/p&gt;&lt;p data-path-to-node="38"&gt;&lt;b data-index-in-node="0" data-path-to-node="38"&gt;B. 基于预测器引导的推理性能&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="39"&gt;论文将可信度预测器应用于推理路径选择，并在多个 Benchmark 上进行验证，既包括纯文本推理任务（单模态），也包括视觉&amp;ndash;语言混合的多模态推理任务。评估数据集覆盖数学、逻辑以及常识推理。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="40,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,0,0"&gt;单模态推理任务&lt;/b&gt;：包括 GSM8K、SVAMP、StrategyQA、BoolQ 和 Boolean。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,1,0"&gt;多模态推理任务&lt;/b&gt;：包括 ScienceQA、RealWorldQA、CLEVR-Math 和 MMStar。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,2,0"&gt;Baseline&lt;/b&gt;：Few-Shot CoT、Self-Consistency、Self Evaluation Guided Beam Search、Process Reward Models Search。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNbGLTibibBPM7iahQ3TMQj9LAAYdmLDpfOHicMJuIwmyIib85n4SzH8yvoUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2916666666666667" data-type="png" data-w="1080" data-width="1573" data-height="459" data-imgfileid="503527043" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5aaa2d48-35b4-4f73-b3ae-400b6b6f688d/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="41"&gt;结果表明，方法在每种设置下均取得了优异性能。与相同设置下的少样本思维链（Few-Shot CoT）相比，该方法在大多数测试中均展现出显著提升。 例如，在单模态任务的 SVAMP 数据集上，该方法相较于少样本思维链提升了 5 个百分点（48.3 对 43.3）；在多模态任务的 RealWorldQA 数据集上，实现了 10.7 个百分点的提升。&lt;/p&gt;&lt;p data-path-to-node="41"&gt;总体而言，无论是在数学与符号推理、常识推理任务中，还是在单模态与多模态任务中，该方法在大多数情况下都优于基线模型少样本思维链以及其他 Baseline。这充分表明，从模型内部状态中提取的置信度能够有效引导生成更可靠的推理链。&lt;/p&gt;&lt;p data-path-to-node="42"&gt;消融实验表明：可信度预测器对推理提升至关重要。如下图所示：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNdc4HV4mOhEYBDQ30O4mdYcQ4yYeNopTlqQOXOQHsUSmnctay0yiamqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5006954102920723" data-type="png" data-w="719" data-width="719" data-height="360" data-imgfileid="503527044" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/2bdec123-95bf-4b1a-8e86-c153733cdbf6/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="42"&gt;若将候选推理步骤「随机选择」而非依据可信度，本方法性能显著下降。随机策略在若干任务上甚至低于 Few-Shot CoT Baseline。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;&lt;strong&gt;作者信息&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="44,0,0"&gt;一作：陈紫军，合肥工业大学博士生，主要研究方向为大模型概率可靠性，曾在 AAAI、COLING 等顶级会议上发表论文。&lt;/p&gt;&lt;p data-path-to-node="44,1,0"&gt;通讯作者：胡文波，合肥工业大学计算机与信息学院副教授，黄山青年学者。主要研究方向为机器学习，包括贝叶斯概率机器学习、人工智能安全以及科学人工智能。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>明天上市，MiniMax上市额度已经被抢疯了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 08 Jan 2026 22:40:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-08-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-08-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26e4c639-7b05-4527-a284-c3fc0d753b51/1767883209855.png" style="width: 700%;" class="fr-fic fr-dib"&gt;即将于 1 月 9 日敲钟上市的大模型公司 MiniMax，创下近年来港股 IPO 机构认购历史记录。此次参与 MiniMaxIPO 认购的机构超过 460 家，超额认购达 70 多倍。&lt;/p&gt;&lt;p&gt;此前的认购记录属于宁德时代，其在 2025 年登陆港股市场时，剔除基石后超额认购 30 倍。&lt;/p&gt;&lt;p&gt;与此同时，此次参与 MiniMax 国配订单的需求达到了 320 亿美元，最后超过 460 家机构实际下单了 190 亿美元。剔除基石部分，此次 MiniMax 的国配认购超额到 79 倍左右。&lt;/p&gt;&lt;p&gt;此次 MiniMax 备受头部基金的青睐。这些下单的机构中不乏众多的长线基金及国家主权基金。包括新加坡主权基金、南非以及中东、加拿大等多家主权基金认购金额超过 10 亿美金。与此同时，这些长线基金的认购订单总额超过 60 亿美金。&lt;/p&gt;&lt;p&gt;除了国配部分外，一些外资长线基金及国家主权基金也参与了 MiniMax 的基石认购部分。公开数据显示，MiniMax 的 14 家基石，其中包括了中东国家主权基金阿布扎比基金、韩国长线基金未来资产等。&lt;/p&gt;&lt;p&gt;1 月 8 日下午的暗盘显示，MiniMax 开盘后一路上涨，最高曾达到 211.2 港元每股，最低也曾达到 180 港元每股，最后收盘价为 205.6 港元每股，涨幅 24.6%。&lt;/p&gt;&lt;p&gt;MiniMax 的收入来源主要有两部分，AI 原生产品、开放平台及其他基于 AI 的企业服务，其中 AI 原始产品包括大语言模型、视频生成模型等于 2025 年 6 月底的收入达到 3802 万美元，占比超过 70%，而平台及企业服务部分的收入则为 1541 万美元，占比则为 28.9%。值得一提的是，截至 2025 年 9 月底，AI 原生产品累计用户达 2.12 亿，其中付费用户超过 177.1 万。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Jp34LnMTxyu2giauBhfLMKibUEFPFyd2rfTDRPIqTLBSBLuL4GQMviaTmO1oR8QE7ftKicIf6uJVxSsvbzn2ziceWJw/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=0" alt="图片" data-ratio="0.47685185185185186" data-w="1080" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/48f4877a-cee5-4239-b9e8-18585ed09e92/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;截至 2025 年 9 月底，MiniMax 的亏损为 1.8 亿美金左右，而现金还有超过 3.62 亿美金。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Jp34LnMTxyu2giauBhfLMKibUEFPFyd2rfCpGicicCSCHXoaQQxLEfdAwiaUb4sEeWDhM4xtB05libUkHbtq2Yic0efibw/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=1" alt="图片" data-ratio="0.5148148148148148" data-w="1080" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d6cc43e6-2603-4071-a54c-5a74fda08c7f/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;部分在港投资者表示，MiniMax 的商业模式相对清晰，而且逐步实现多元化的营收方式 &amp;mdash;&amp;mdash; 这给了他们对于 MiniMax 未来实现收支平衡的信心。MiniMax 的招股书显示，其下变现的方式包括多款产品的订阅及付费等。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Jp34LnMTxyu2giauBhfLMKibUEFPFyd2rfLjejiab7DyicD8ScCniaUYCME1HpP9xOrNe6h37Gicaxtu18xVDdwCe61g/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=2" alt="图片" data-ratio="1.349074074074074" data-w="1080" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/54e2027e-2fd3-4b9e-ba9c-b6f8f882e726/640.png" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
