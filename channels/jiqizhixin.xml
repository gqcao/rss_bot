<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>击败GPT、Gemini，复旦×创智孵化创业团队「模思智能」，语音模型上新了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:40:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南、杜伟&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;在语音大模型赛道上，GPT-4o、Gemini 的能力遥遥领先。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;近日，&lt;strong&gt;由复旦邱锡鹏担任首席科学家的模思智能发布了多说话人自动语音识别（ASR）模型 MOSS-Transcribe-Diarize&lt;/strong&gt;，不但可以语音转文字，还可以将音频片段与对话中不同的说话者关联起来，性能超过了 GPT-4o、Gemini、豆包等一众模型。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;多人说话场景的语音转录是语音识别领域的落地痛点问题。以往模型一旦遇到多人抢着说话就可能听不清、记不准。现在 MOSS-Transcribe-Diarize 摸透了多人说话逻辑，能够轻松应对混乱插话、频繁切话或者重叠说话等复杂场景，真正掌握了「说哪记哪、听声辩人」的技能。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;MOSS-Transcribe-Diarize 在语音识别与分析领域具有突破性意义，解决了语音领域最后的落地痛点。MOSS-Transcribe-Diarize 支持 128K 的长上下文窗口，&lt;strong&gt;可以一次性输入并处理长达 90 分钟的音频&lt;/strong&gt;，突出了复杂场景下的抗干扰能力。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;MOSS-Transcribe-Diarize 的跑分成绩同样亮眼。&lt;/strong&gt;在 AISHELL-4、Podcast、Movies 等多个语音基准测试中，模型均取得了业界最优（SOTA）的整体表现。尤其是在影视剧场景下，背景音更杂、多人同时说话、频繁插话、声音重叠，是语音转录里&lt;strong&gt;最乱、也最接近真实应用的情况。&lt;/strong&gt;即便面对这样的复杂语音条件，MOSS-Transcribe-Diarize 依然稳定跑出了当前业界最优的整体成绩：&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0nvS6kWd3rgdOY3rUwjd4x0kjHrsqvy8kyev40ziaK1MuibZT7TM7PAlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529151" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4a6a54d9-4043-4060-bb74-9834e3a8bd1a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="2 2 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 此处 GPT-4o 特指 gpt-4o-transcribe-diarize&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;再更具体一点，该模型实现了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最低的 CER（字错误率）与 cpCER（最优排列字错误率）&lt;/strong&gt;：在多说话人混合与重叠场景下取得业内领先的转录准确率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最佳的 &amp;Delta;cp 指标（说话人分离性能 ）&lt;/strong&gt;：相比于其它因为长音频切片而导致的说话人识别不一致的模型，MOSS-Transcribe-Diarize 保持了最好的说话人标签准确性和一致性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;超长音频处理&lt;/strong&gt;：在面对超长音频时，当前顶尖商业模型（如 GPT-4o Transcribe Diarize、Gemini 3 Pro）受限于输入长度或输出格式的稳定性，而 MOSS-Transcribe-Diarize 能够稳定输出完整的带有说话人以及时间戳的语音转录结果。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实战效果惊艳，经典名场面「华强买瓜」：&lt;a href="https://mp.weixin.qq.com/s/LoP4twE1X5UFSY3G7g42mQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8388af55-0fd3-4eed-a00a-ef4013e49a89/1768905487029.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Mygo 的飞鸟山公园：&lt;a href="https://mp.weixin.qq.com/s/LoP4twE1X5UFSY3G7g42mQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e991c545-34f5-43b7-bdc5-869cb019cc5f/1768905501344.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;看起来 AI 模型可以把说话人和每个人所讲的内容识别地清清楚楚，不论是嘈杂的环境音，人物的方言、俚语，还是因为情感波动表现出的喊叫、哭泣等都不会影响 AI 的判断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首个统一多模态模型，挑战 AI 语音最难题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS-Transcribe-Diarize 的特点不仅在于语音能力，它作为统一的端到端多模态语音转录模型，能够像人类一样，在「听」的过程中同时完成「听懂内容」、「识别是谁说的」以及「记录说话时间」这三件事。&lt;/p&gt;&lt;p&gt;它主要解决的是语音处理中一个经典且极具挑战的问题：SATS，即「带说话人归属和时间戳的转录」。 想象一下，在参加环境嘈杂、一堆人在场的会议时，大家你一言我一语，乱哄哄一片。这种面向多说话人的转录既要求内容准确，也要标明「何人何时发言」。&lt;/p&gt;&lt;p&gt;但是&lt;strong&gt;，传统的模块化组件拼接方案（如自动语音识别 + 说话人日志）、引入 LLM 的半级联方案（使用自动语音识别和说话人日志生成候选内容，然后利用 LLM 修正错误）&lt;/strong&gt;以及&lt;strong&gt;近期将识别与归属统一在多模态框架下的尝试（如 Sortformer、SpeakerLM、JEDIS-LLM 等）&lt;/strong&gt;都不同程度地存在着缺陷，比如级联方案对于说话人重叠的音频表现不鲁棒，其他方案对长时间多说话人对话的转录效果不佳，亟需更优的解决方案。&lt;/p&gt;&lt;p&gt;邱锡鹏团队发布的 MOSS-Transcribe-Diarize 一扫现有 SATS 方案的不足，一举解决了三大核心瓶颈，即长上下文窗口受限、长时记忆脆弱和缺乏原生时间戳。相关技术报告已在几天前发布，同时官方也开放了 &lt;strong&gt;API 接口&lt;/strong&gt;，目前为限时免费期，感兴趣的同学可自行体验：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;技术报告：https://arxiv.org/pdf/2601.01554&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型主页：https://mosi.cn/models/moss-transcribe-diarize&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;API 接入：https://studio.mosi.cn/docs/moss-transcribe-diarize&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中展示了新模型的大量技术特点：其作为一个统一的多模态大语言模型，可以通过端到端的方式同时执行语音识别（ASR）、说话人归属和时间戳预测，消除可能产生的误差传播。&lt;/p&gt;&lt;p&gt;为了达成这些效果，MOSS-Transcribe-Diarize 在模型架构、训练数据组成上形成了一套自己的解法。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在架构设计上，它采用了统一的音频 - 文本多模态架构。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;设计者将多说话人的声学表示投影到预训练文本 LLM 的特征空间中，使得该模型在单一的端到端框架内能够联合建模词汇内容、说话人归属和时间戳预测。&lt;/p&gt;&lt;p&gt;模型在一个推理过程中直接输出带有 [S01]、[S02] 标签和精确时间戳的文本。这种机制利用了语义信息来辅助说话人识别（例如，通过说话内容的连贯性来判断是否换人了），极大地提高了识别准确率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在训练数据的组成上，采用「虚实结合」的策略。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS-Transcribe-Diarize 使用大量真实世界的对话音频以及通过概率模拟器生成的合成数据进行训练，增强了对重叠语音、轮替和声学变化等性能指标的鲁棒性。该模型训练使用的真实数据包含了从公共语料库中采样的大量说话人片段，并覆盖了现实中不同类型的多说话人场景。&lt;/p&gt;&lt;p&gt;得益于架构与数据层面的一系列巧思，MOSS-Transcribe-Diarize 才能够一举攻克行业长期以来面临的长对话和多说话人转录难题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长短音频、切话叠音，多场景表现最优&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在与国内外顶级模型的较量中，MOSS-Transcribe-Diarize 在多个基准测试中拿下 SOTA 成绩。它究竟强在哪些方面呢？我们接下来进行了一番深入探究。&lt;/p&gt;&lt;p&gt;1）在&lt;strong&gt;包含近 40 分钟真实世界会议录音的 AISHELL-4 数据集&lt;/strong&gt;上，MOSS-Transcribe-Diarize 在 CER 和 cpCER 两项指标上大幅优于所有基线模型，并表现出了更低的 &amp;Delta;cp 值。这验证了相较于纯粹的 ASR 错误，由说话人归属错误引入的额外性能衰退要少得多，并由此证明了长上下文、端到端建模在长对话中维持说话人一致性方面的有效性。&lt;/p&gt;&lt;p&gt;相比之下，GPT-4o 和 Gemini 3 Pro 均无法可靠地处理 AISHELL-4 等长音频输入，前者受限于音频输入长度，无法完成完整录音转录；后者无法生成符合既定说话人归属格式的有效输出。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ03pW558PqlTxpTYhLdNUEQxMjMLziaLu7hmr4rrFsUGVhY51gayE2MUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529160" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/baa61a3f-8a29-42b6-ad4c-4038ff805a60/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2）在&lt;strong&gt;&amp;nbsp;Podcast 数据集&lt;/strong&gt;（多说话人播客访谈场景）上，MOSS-Transcribe-Diarize 再次取得所有参评模型中最低的 CER 和 cpCER。尽管其他基线模型也达到很高的 ASR 准确率，但在 &amp;Delta;cp 值这点上落败了。这表明，在频繁的话轮转换和长跨度的说话人重现场景下，MOSS-Transcribe-Diarize 能够让说话人归属更加准确。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0wAH5Eq9cd2M4EJwINa9yx0qaO59PZ9CUGqrq87PYzFjMeXZC28xjjA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529078" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cc4b02b9-d2c3-4c11-830c-4e72499cac58/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;3）在&lt;strong&gt;&amp;nbsp;Movies 数据集&lt;/strong&gt;（复杂影视剧场景）上，强调短促话语、快速说话人交替以及频繁的语音重叠场景，MOSS-Transcribe-Diarize 面对这种短语音转录任务依然优于所有基线模型。它还在 CER 和 cpCER 两项指标之间保持了相对较小的差距，这意味着不仅能听清说了什么，还能非常精准地判断出是谁说的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0nvS6kWd3rgdOY3rUwjd4x0kjHrsqvy8kyev40ziaK1MuibZT7TM7PAlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529159" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/57239345-b869-41ad-8fb6-f6ed17baeb53/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;目标：情境智能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MOSS 系列大模型的背后，是国内 AI 领域领军人物，复旦大学教授邱锡鹏带领的团队。在中国 AI 版图中，他们显得极具特色。该团队的 MOSS 模型是国内第一个对标 ChatGPT 并开源的对话式大语言模型，并提出了最早的具有内生语音能力的大模型 SpeechGPT 和原生端到端全模态大模型 AnyGPT。团队组建的模思智能（MOSI AI）则由上海创智学院与复旦大学自主孵化，是一家专注面向情境智能的多模态大模型公司。&lt;/p&gt;&lt;p&gt;他们保持了一条清晰且具有战略眼光的技术路径：&lt;strong&gt;让大模型理解复杂的真实世界情境，并以情境多模态实现通用人工智能。&lt;/strong&gt;在这条路线上，他们一直在不断探索，发布了一系列多模态领域的前沿技术成果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;去年 7 月，模思开源了革命性的对话语音合成模型&amp;nbsp;&lt;strong&gt;MOSS-TTSD&lt;/strong&gt;，能够根据完整的多人对话文本，直接生成高质量对话语音。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;去年 11 月，&lt;strong&gt;MOSS-Speech&lt;/strong&gt; 的发布展现了语音 AI 技术的突破，实现了 SOTA 性能。这是一个无文本引导的真端到端语音大模型，可以在保持模型高智商程度的前提下，解决人机低时延交互的挑战。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最近发布的&lt;strong&gt;&amp;nbsp;MOSS-Transcribe-Diarize&lt;/strong&gt;，则攻克了复杂日常多人对话场景的语音识别，对于多模态 AI 的实际落地具有重要意义。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一系列技术成果可覆盖实时对话交互、复杂场景音频生成、高鲁棒性语音理解、多模态交互等核心能力场景，在流畅度、响应速度、理解能力和可控性方面实现了行业领先表现。&lt;/p&gt;&lt;p&gt;面向未来，模思将持续深耕让 AI「理解用户所处的全局情境」的多模态智能，通过规模化物理世界的复杂真实情境，实现真正自然、连贯、可成长、可信赖的智能交互，推动多模态交互与具身智能的产业化落地。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>当黄仁勋将存储定义为「AI运行内存」，基础设施该如何实现物种进化？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:35:39 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;编辑｜Panda&amp;nbsp;&lt;/p&gt;&lt;p&gt;一根 256 GB 内存条标价 5000 美元？这个价格已经轻松超过了英伟达顶配显卡 RTX 5090 的市场溢价。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JW5fhqyibMtv1Mc4icLwgUldO4SPLvp10W5aeCGEUaN0yg6SSvGwkTPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7512755102040817" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503528866" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8ec2cd31-a8e0-4db6-b13c-ca421e7f76fc/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 此推文引发了广泛讨论，已收获超 200 万浏览，图源：X@Yuchenj_UW&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;由于 AI 算力需求引发了极端的结构性紧缺，全球内存市场正陷入一场前所未有的疯狂。报道称 OpenAI 与三星电子、SK 海力士签署了大规模 DRAM 晶圆供应协议，其预估的 DRAM 晶圆需求可能达到全球 DRAM 晶圆产能的约 40%，这一需求规模在行业内引发了对存储供应紧张的关注。与此同时，微软、谷歌等大型科技公司也派出采购团队在韩国与这些主要存储芯片供应商展开密集谈判，以争取更多 DRAM 和高带宽存储（HBM）供应资源。&lt;/p&gt;&lt;p&gt;而就在 2026 年 1 月的 CES 演讲中，英伟达 CEO 黄仁勋又更进一步为这股趋势给出了极具分量的判断。&lt;/p&gt;&lt;p&gt;他指出，围绕 AI 推理与上下文的数据存储正在形成一个「此前从未真正存在过的市场」，并预测其规模很可能成长为全球最大的存储市场之一，因为它在本质上承载着全球 AI 系统的工作内存（working memory）。黄仁勋强调，AI 的工作负载在访问模式、时延要求和数据生命周期上都与传统数据库和存储系统截然不同，因此现有存储架构难以满足需求，存储技术本身必须经历一次根本性的重构。&lt;a href="https://mp.weixin.qq.com/s/w3GRxO8EsPpZJMlhyTQFKA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3956f995-b6b7-4cd7-a15c-8899686328aa/1768905020049.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种底层架构的变革需求，正是当下 AI 基础设施面临的一大核心挑战。&lt;/p&gt;&lt;p&gt;现在，一家成立已过十周年的公司对这一挑战发起了冲锋。&lt;/p&gt;&lt;p&gt;1 月 15 日， XSKY 星辰天合在北京举办了主题为「&lt;strong&gt;数据常青 智算无界&lt;/strong&gt;」的 AIMesh 产品战略发布会，并宣布战略重心从「&lt;strong&gt;信息技术（IT）&lt;/strong&gt;」全面跨越至「&lt;strong&gt;数据智能（Data Intelligence）&lt;/strong&gt;」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qnx0oTH8RxRKYXCcZwibLWkLEzK3RJbKibDpVDvaMeZj5WZwU0q3NiaPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528868" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/07f63fe5-ffa4-4782-bf66-bdee7a9e2852/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这家成立于 2015 年 5 月的企业，已经在十年多的时间里从初创团队成长为一头独角兽，&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzAwNTc0OTM1NA==&amp;mid=2652426304&amp;idx=1&amp;sn=17daab312c04acd94feb1a5607f6d7f5&amp;scene=21#wechat_redirect" target="_blank"&gt;更是已然成为中国对象存储市场的领跑者&lt;/a&gt;，并肩负起了中国核心产业超过 &lt;strong&gt;5500 PB&lt;/strong&gt; 关键数据的安全重任。不仅如此，该公司的增长势头依然强劲：在近三年实现了超过 &lt;strong&gt;50% &lt;/strong&gt;的逆势高增长；随着业务对性能渴望的加剧，其全闪存占比已翻了三倍，达到了 &lt;strong&gt;35%&lt;/strong&gt;。大规模存储方面，XSKY 已经拥有了 &lt;strong&gt;280&lt;/strong&gt; 个 &lt;strong&gt;10 PB&lt;/strong&gt; 级以上的超级集群，甚至跨越了&lt;strong&gt;单机群百 PB&lt;/strong&gt; 的技术门槛。这每一个数字的增长，都是客户投下的一张张信任票，也构成了 XSKY 应对 AI 大爆发的底层底气。&lt;/p&gt;&lt;p&gt;从这些数字也看得出来，AI 大爆发正在催动数据中心的进化。&lt;/p&gt;&lt;p&gt;过去十年的 IT 时代，数据中心的功能类似于一座严谨的「图书馆」，价值核心在于数据的「存得进、找得到」。但在进入数据智能时代后，数据的价值正在从「被检索」进化为「被计算」，每一份文档和图片都正成为生成未来的燃料。&lt;/p&gt;&lt;p&gt;为了适应这种转变，企业的数据中心必须完成一次物种进化，从安静的图书馆演变为一座日夜轰鸣的「AI 工厂」。&lt;/p&gt;&lt;p&gt;面对大模型时代的算力博弈，XSKY 确立了清晰的战略定位：&lt;strong&gt;通过发布 AIMesh 全栈 AI 数据方案，XSKY 致力于打造开放解耦且绝对中立的数据底座，旨在破解企业私有高价值数据向智慧转化的效率瓶颈。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14EXuibnnVku5egumUibbibX6Z1T1fgCAuU7icnYWyZPCUGrkp0x7icDB4rJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528867" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f48cafe3-edd3-4fd5-8cf8-5ab3cd1d48bb/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;为什么「专有数据」是 AI 时代唯一的护城河？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大模型技术快速迭代的当下，业界逐渐达成了一个共识：算法正在走向同质化。&lt;/p&gt;&lt;p&gt;正如 AI 大牛 Andrej Karpathy 指出的那样，大模型（如 Transformer）的算法实现非常简洁，通常只有几百行代码。他提出，在大模型时代，数据不再仅仅是燃料，数据就是「源代码」。因为人类不再通过编写逻辑代码来解决问题，而是通过策划、清洗和标注特定的数据集，让模型通过学习这些数据来获得专家能力。&lt;/p&gt;&lt;p&gt;而对于企业而言，当领先的模型架构和训练方法变得透明且易于获取时，企业真正的差异化竞争优势和护城河，就在于其自身拥有的独特「&lt;strong&gt;专有数据&lt;/strong&gt;」。这些数据是企业长年累月积淀下的独有配方，也是将通用大模型转化为具备垂直领域专家能力的燃料。&lt;/p&gt;&lt;p&gt;出于安全和合规的考虑，这些高价值的核心数据不能外溢到公有云，它们必须牢牢掌握在企业自己手中。因此，构建一个私有化、安全且可控的 AI 数据底座成为了企业的刚需。&lt;/p&gt;&lt;p&gt;XSKY 的角色正是守住数据安全的底线，让企业能将私有数据在内部安全地转化为智慧。&lt;/p&gt;&lt;p&gt;这种对数据价值的深度理解，已经在行业头部的实践中得到了验证。刚刚在 1 月 9 日成功登陆港交所的 MiniMax 便是典型的例子。作为全球 AI 领域从创立到上市最快纪录的最新创造者，MiniMax 的成功证明了在算法日益透明的今天，私有数据资产才是支撑企业估值与竞争力的核心。&lt;/p&gt;&lt;p&gt;目前，MiniMax 有 PB 级的数据存放在 XSKY 的存储平台上，其中包括最核心的训练数据与推理模型数据。对于这类处于商业化爆发期的头部 AI 企业而言，存储底座的稳定性直接决定了研发的连续性。&lt;/p&gt;&lt;p&gt;这种需求的变化也预示着基础设施职能的彻底改变。正如前文所说，过去的数据中心更像是一座安静的「图书馆」，核心任务是确保数据「存得进、找得到」。但在 AI 时代，数据中心必须进化为一座日夜轰鸣的「AI 工厂」，数据不再是静止的档案，而是被不断计算、不断产生价值的动态资产。XSKY 的战略目标，就是帮助企业的专有数据完成这一物种进化，让基础设施能够支撑起从数据准备到模型训练再到推理部署的全生命周期。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AIMesh 如何推倒阻碍 AI 效率的「三堵墙」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在大模型训练与推理的实战场景中，传统的存储架构正面临严峻的挑战。这些挑战可以被总结成三堵墙：IO 墙、重力墙和内存墙。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;IO 墙&lt;/strong&gt;：当算力的吞吐速度远远超过存储的读写速度时，计算单元被迫进入空转等待状态，导致 GPU 利用率往往低至 30% 到 50%。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;重力墙&lt;/strong&gt;：随着数据体量的指数级增长，跨地域流动的高昂成本让数据逐渐沦为孤岛，形成了难以逾越的「重力墙」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;内存墙&lt;/strong&gt;：随着 AI 应用向长上下文和复杂智能体（Agent）演进，KVCache 的爆炸式增长让显存（HBM）撞上了物理极限的「内存墙」，导致硬件投入成本急剧攀升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wajnnAKlMk5IpymHrPRIGghcZx3jma1sibB5BtTOgUvS8NfNRJgrZjw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.9825517993456925" data-s="300,640" data-type="jpeg" data-w="917" type="block" data-imgfileid="503528901" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b60556c9-0193-4379-8df8-edddce1aafb1/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;典型的「内存墙」：2018 年至 2025 年期间，Transformer 模型尺寸每 2 年增长约 19 倍，而每个加速器的内存每 2 年仅增长约 1.9 倍。不仅如此，过去 20 年间，峰值计算能力增长了约 6 万倍，但 DRAM 带宽仅增长了约 100 倍，互连带宽也仅增长了约 30 倍。结果就是：处理器闲置等待数据。来源：ayarlabs.com&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;要推倒这些深层物理层面的效率障碍，不仅需要软件架构的创新，更需要与底层芯片性能的深度适配。举个例子，作为这一进程的见证者，芯片巨头英特尔与 XSKY 的合作已经跨越了第一个十年。从早期作为 Intel SPDK 技术最早的一批贡献者共同探索用户态轮询技术，到如今实现对最新硬件的 Day-0 级技术响应，这种长期的技术共创为 AIMesh 全栈 AI 数据方案的发布奠定了基础。&lt;/p&gt;&lt;p&gt;基于这种长期的软硬协同积淀，XSKY 通过 AIMesh 构建了一张面向 AI 工厂的数据与内存网，旨在打破这三堵墙，进而利用架构创新将技术参数转化为真实的业务价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshFS：打破 IO 墙，加速模型训练&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对 AI 训练中严峻的「IO 墙」挑战，XSKY 发布了专为 AI 训练而生的并行文件系统 &lt;strong&gt;MeshFS&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14jHrBMUZadPicpmkFvzL0PnlY95icA61y1zW3OwnDNAv0amkGichz4p4Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528869" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/266606c9-c20a-4462-8091-b8dec6a74916/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该系统将 XGFS 成熟的企业级协议栈与 XSEA 星飞全闪架构的 Shared-Everything 极速底座深度融合，为软件栈注入了强劲的性能心脏。&lt;/p&gt;&lt;p&gt;为了彻底破解算力在等待数据时的损耗，MeshFS 在以下三个维度实现了技术突破：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全协议兼容&lt;/strong&gt;：MeshFS 提供标准的 POSIX 语义，这意味着现有的 Python 或 TensorFlow 训练代码无需修改即可运行。更重要的是其实现了「一份数据，多协议互通」，数据清洗可以通过 HDFS 接口使用 Spark，训练过程通过 POSIX 接口使用 PyTorch，归档则使用 S3。数据在全流程中不需要搬家，原地即可被不同的业务流处理。MeshFS 也完美支持 Kubernetes CSI。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;线性的极致性能&lt;/strong&gt;：通过全分布式架构和元数据分片技术，MeshFS 的性能可以随节点数线性增长。系统引入了 Run To Completion 技术，将元数据处理延迟压低至微秒级。即使面对亿级规模的小文件数据集，依然能保持顺滑的访问体验。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;企业级管理与智能分层&lt;/strong&gt;：在提供目录 QoS、配额以及审计等完善特性的同时，MeshFS 支持智能分层能力。数据可以在全闪存层和低成本层之间透明流动，让用户能够以 Tier-2 的成本存储数据，同时享受 Tier-0 的训练速度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在性能实测中，MeshFS 凭借「一跳读」设计&lt;strong&gt;实现了顺序读带宽 30% 的提升&lt;/strong&gt;，同时&lt;strong&gt;依靠端到端 EC 写技术让顺序写带宽超出同类产品 50%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;此外，MeshFS 还针对英特尔新一代至强处理器的 AVX-512 与 AMX 指令集进行了深度优化。&lt;/p&gt;&lt;p&gt;在刚刚完成 IPO 的大模型企业 MiniMax 的生产环境中，MeshFS 提供了高吞吐、低延迟的 I/O 支持。无论是在大规模数据的 DataLoad 阶段，还是在关键的 Checkpoint 保存环节，MeshFS 都能有效保证训练效率。而在推理端，MeshFS 的高吞吐特性支撑了近万个推理服务在极短时间内上线，确保了海螺 AI 等核心产品在全球市场的竞争力。&lt;/p&gt;&lt;p&gt;在这种顶级 AI 企业的高强度实战中，XSKY 的技术架构经受住了考验，成为了支撑其走向资本市场的坚实底座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshSpace：推倒重力墙，实现全局流动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对「重力墙」，XSKY 给出的解决方案是 &lt;strong&gt;MeshSpace&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ialN0CV0cPjNBBJjwuIkSWFJcOybsiaF2kPUFv3RUyibgtgKcJRxHgWaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528870" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e33e3f1c-292a-497f-bed7-972c2994564b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为面向 EB 级数据的全局非结构化数据平台，MeshSpace 实现了从「单桶千亿」到「单桶 EB」的架构演进。&lt;/p&gt;&lt;p&gt;MeshSpace 通过三大核心能力，重新定义了大规模存储的治理模式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;平滑演进能力&lt;/strong&gt;：MeshSpace 能够直接纳管企业现有的 XEOS 集群。这意味着过去十年积累的数据资产无需经历痛苦的迁移过程，即可原地升级并融入新的 AI 训练流。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全局控制面统一&lt;/strong&gt;：这是架构设计中最具突破性的地方。通过统一的 DNS 接入，MeshSpace 将分散在不同物理机房、甚至是云端的物理集群抽象为一个逻辑整体。对于业务端而言，无论底层物理资源如何离散，都只有一个统一的入口。物理上是离散的，但在逻辑上，它们就是「一套存储」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据治理全局化&lt;/strong&gt;：MeshSpace 支持异构存储平台的统一调度。数据可以在全闪存、HDD 甚至磁带之间，根据数据温度和业务需求自由流动，确保热数据能够快速参与计算，冷数据能够自动沉降以降低成本。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在性能表现上，MeshSpace 带领对象存储正式迈入了「&lt;strong&gt;百万 OPS 单桶时代&lt;/strong&gt;」。单个对象存储桶可以每秒支持高达一百万次对象写入，以及数百万次对象读取，这一规格远超主流公有云产品的单桶性能上限。不仅如此，XSKY 还对 XScale 最底层的分布式 KV 引擎进行了彻底的优化，让 AI 训练中关键的&lt;strong&gt;大块写性能提升了近 50%&lt;/strong&gt;，同时将&lt;strong&gt;延迟降低了 30%&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种架构精准击中了 MiniMax 等混合云用户的痛点。由于采用了混合云架构，数据孤岛带来的跨域调度成本曾是其核心挑战。MeshSpace 几乎是为其量身定制的解决方案，通过统一的全局命名空间收敛数据入口，业务端不再需要感知数据的真实物理位置，从而彻底解决了数据迁移带来的低效问题，极大降低了管理成本。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MeshFusion：击穿内存墙，降低推理成本&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;至于最后的内存墙，XSKY 推出了一种面向 KVCache 的「持久化内存」方案 &lt;strong&gt;MeshFusion&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;MeshFusion 运行在 GPU 服务器内部，通过创新的软件栈将本地 NVMe SSD 资源池化，转化为可供 GPU 直接调用的 L3 级外部内存。&lt;/p&gt;&lt;p&gt;不仅如此，MeshFusion 还拥有三大必杀技：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;零拷贝&lt;/strong&gt;：数据从 SSD 直通 GPU 显存，极大降低延迟。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致并发&lt;/strong&gt;：专为 KVCache 的小 IO、高并发写入优化，支持原子提交。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;协议自适应&lt;/strong&gt;：兼容 vLLM、SGLang 等主流推理框架，代码零修改。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实测数据显示，&lt;strong&gt;该方案能以 1% 的硬件成本实现近乎无限的上下文窗口，且性能与 DRAM 的差距保持在 10% 以内。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;云计算服务商 ZStack 表示，MeshFusion 的 SSD 扩展内存能力将显著降低 AI 服务规模化部署的门槛，并计划将其与自身的 AIOS 智塔平台展开深度集成。同时，XSKY 正在与英特尔联合预研基于 CXL 技术的内存池化方案，旨在彻底打破物理内存边界，为万亿参数模型提供充裕的资源池支持。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据常青与绝对中立的战略定力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在当前「百模大战」的背景下，技术架构与算法模型正处于剧烈的变动期。对于企业决策者而言，在极高的不确定性中做出确定的选择至关重要。XSKY 给出的答案是&lt;strong&gt;坚持开放解耦，做绝对中立的数据底座&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一战略背后蕴含着深刻的时间逻辑。在 XSKY 看来，算力硬件（GPU）的生命周期通常只有&lt;strong&gt; 3 到 5 年&lt;/strong&gt;，属于快速迭代的变量。相比之下，承载着企业智慧的代码、文档与影像等数据资产，其存续周期通常长达 &lt;strong&gt;10 到 20 年&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，XSKY 提出了「&lt;strong&gt;数据常青&lt;/strong&gt;」的理念，主张用一个稳固、长周期的底座去支撑上层快速演进的算力竞争，以不变的底座应对万变的未来。&lt;/p&gt;&lt;p&gt;为了实现这种确定的支撑，&lt;strong&gt;XSKY 始终坚持不绑定任何一种特定的算力平台&lt;/strong&gt;。无论企业选择英伟达，还是昇腾、寒武纪、摩尔线程、沐曦等国产芯片，AIMesh 都能提供统一且标准的数据服务。这种中立立场赋予了客户在算力博弈中的主动权，使其能够根据业务需求自由选择最合适的硬件资源，而不必担心被特定生态锁死。&lt;/p&gt;&lt;p&gt;这种对中立与解耦的坚守，也让 XSKY 在生态构建中获得了深厚的信赖。以 ZStack 为例，双方在云计算时代便是「存算分离」建设的优选组合，彼此被称为「背靠背的战友」。进入 AI 时代，这种默契得到了延续。ZStack 认为 AIMesh 的架构设计与其 AIOS 智塔战略高度契合，双方计划在智算中心建设中继续复制云时代的成功经验，共同成为智能算力基础设施中可靠、高效的算存基石。&lt;/p&gt;&lt;p&gt;从云计算到大模型，技术浪潮几经更迭，但 XSKY 始终致力于解决大规模数据存储与利用的核心需求。正如发布会所强调的，XSKY 的使命是做企业数据资产的守门人，同时也是 AI 之路的加速器。&lt;strong&gt;通过构建高效、可控的 AI 工厂，XSKY 将持续助力企业打破算力与数据的边界，实现智算无界。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;做数据资产的守门人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年 1 月 15 日举行的这场战略发布会，标志着 XSKY 将其十年的技术积累全面导向 AI 场景。AIMesh 全栈方案的发布，是 XSKY 面对智算时代给出的一份阶段性答卷。&lt;/p&gt;&lt;p&gt;回顾这十年的进阶历程，XSKY 对 AI 浪潮的布局早在数年前就已经开始。在 2022 年，公司便预判到了 AI 对于极致性能与数据治理的迫切需求，并投入研发了 &lt;strong&gt;XSEA 全闪底座&lt;/strong&gt;与&lt;strong&gt; EasyData 数据管理平台&lt;/strong&gt;。作为 Shared-Everything 架构的极速底座，XSEA 已经通过了金融核心交易与自动驾驶算力中心等严苛场景的验证，为今天的 MeshFS 提供了澎湃的性能心脏。而 EasyData 则作为数据编排与治理的中枢，面向从采集、清洗到归档的完整链路提供全局管理，确保了 AI 数据全生命周期的有序流动。&lt;/p&gt;&lt;p&gt;正是基于这些关键技术点的长期深耕，XSKY 才能在今天完成从「单点极致」到「全局统领」的架构升维。这一战略升级的核心目标在于破解企业私有高价值数据向智慧转化的效率瓶颈。&lt;/p&gt;&lt;p&gt;在未来的竞争中，算力硬件的生命周期可能只有 3 到 5 年，但承载企业智慧的数据资产却要存续 10 到 20 年。XSKY 将继续坚守「数据常青」的理念，通过提供开放且解耦的基础设施，支撑上层快速迭代的算力竞争。作为数据资产的守门人，XSKY 同时也是企业 AI 之路的加速器。在智算中心需求爆发的未来，XSKY 将持续助力企业打破存储与计算的边界，确保私有数据资产高效转化为智能优势。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>从平面几何出发：形式化验证如何驱动MLLM的推理能力跃迁</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 18:27:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/cf61d82f-f59f-4cc9-8777-eac1eee8c7ec/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在迈向通用人工智能（AGI）的征途中，多模态大语言模型（MLLMs）虽然在视觉理解与文本生成上展现了惊人的能力，却始终面临一道难以逾越的鸿沟：如何在复杂的数学与几何推理中，克服固有的幻觉与逻辑断层？ 现有的 &amp;ldquo;结果导向&amp;rdquo; 训练往往掩盖了推理过程的脆弱性，导致模型常常 &amp;ldquo;蒙对答案&amp;rdquo; 却 &amp;ldquo;想错过程&amp;rdquo;。这种 &amp;ldquo;黑盒&amp;rdquo; 式的学习方式，使得模型难以习得真正鲁棒的推理能力。&lt;/p&gt;&lt;p&gt;面对这一挑战，来自&lt;strong&gt;上海交通大学、复旦大学、香港中文大学（深圳）、上海人工智能实验室等研究机构的团队&lt;/strong&gt;提出了一套全新的系统化解决方案：&lt;strong&gt;&amp;ldquo;Formal Enhance Informal Reasoning&amp;rdquo;（以形式化增强非形式化推理）&lt;/strong&gt;。该方案的核心洞察在于：利用领域内（In-Domain）极度严谨、可验证的形式化逻辑，可以作为一种强有力的监督信号，去规范和引导模型在非形式化场景下的推理行为。 更进一步，研究发现这种在严谨数学环境中习得的逻辑素养，不仅仅局限于几何题，更能作为一把通用的钥匙，解锁模型在通用数学乃至更广泛推理任务上的分布外（OOD）泛化能力。&lt;/p&gt;&lt;p&gt;基于这一理念，团队历经三个阶段的探索，构建了从数据底层到模型顶层的完整闭环：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;TrustGeoGen（数据基石）&lt;/strong&gt;：针对现有数据噪声大、逻辑自洽性差的问题，构建了首个形式化验证的几何数据合成引擎。通过集成多模态对齐、全路径形式化验证及 GeoExplore 探索算法，生成了 GeoTrust 数据集，确保每一条数据的逻辑链条都经过数学层面的严格验算，为后续工作提供数据和验证环境保障。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;GeoBench（深度诊断）&lt;/strong&gt;：为了精准定位模型推理短板，提出了基于分层能力评估的基准测试。它将几何推理拆解为视觉感知、目标规划、定理应用、自我反思四个层级，并引入了 &amp;ldquo;无关条件过滤&amp;rdquo; 与 &amp;ldquo;逻辑纠错&amp;rdquo; 等高阶任务，揭示了推理模型在复杂任务中的逻辑局限性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;SGVR（能力跃迁）&lt;/strong&gt;：针对 &amp;ldquo;结果监督&amp;rdquo; 的不足，提出了 Sub-Goal Verifiable Reward 训练框架。该框架将抽象证明转化为可执行的数值子目标（Milestones），利用 Skeleton Rate 提供密集奖励信号。实验证明，这种训练不仅在几何领域提升显著，更实现了向通用数学及逻辑推理任务的强力迁移。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;相关论文：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14vHoRL33VTM2TpWWNlCiaWHuaaTnzsOsZ36y0dXbHvS0PZssUfMh1ofg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.27314814814814814" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528861" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4e404214-1d5f-4bc8-b95d-1516e462b962/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2504.15780&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14yMna6c3RN9VvCZPEcau8JKlQtgTUdBc8yuD4AcGkbE4I2da1zBIPgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.35" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528862" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d105c6a5-2d18-4450-b301-13aef30181b4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：GeoBench: Rethinking Multimodal Geometric Problem-Solving via Hierarchical Evaluation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2512.24119&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14oev1MH8XvtV4WoIicI5cqogcHKdpUUONfxXia4zCld0sU8kVWfBMwdyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.412962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528864" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3fe1faf9-ef9d-4bdc-9121-e3c40b8b8e6a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.05073&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;如何构筑可信推理的基石？TrustGeoGen：形式化验证的几何数据合成引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;如何使训练数据没有逻辑漏洞？&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;连贯且准确的推理过程是可信推理的基础，每一步推理都应该由明确的前置结论和定理推导出。如图 1 所示，TrustGeoGen 用 constructor, reasoner, sampler 和 translator 四个模块来构造问题、扩充推理图谱、回溯推理路劲和转译自然表达。其中，形式化推理引擎 DDAR 被用来保证每一个结论都由预定义的定理规则得到，从而保证了推理链路的连贯性和可解释性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Xiaia5F0YicpknvhlRYias087rOuys2q4PGWMR8pTyiazYN59CjZYs9t7eQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5907407407407408" data-type="png" data-w="1080" data-width="1819" data-height="1075" data-imgfileid="503528865" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4b4d8099-7bc4-4127-a903-f19b02c1f030/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1 TrustGeoGen 可信数据构造流程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;然而，形式化引擎以遍历的方式获得每一个推理步骤，它可以保证推理步骤是正确的，但是无法解释为什么应该这样做。这样的数据仿佛解题过程被省略的参考答案，只能让大模型记住结果而无法真正掌握推理能力。如图 2 所示，connection thinking 被用来帮助构造思考过程性数据。每个推理步骤前，connection thinking 都会显式地、根据最终目标来分析当前已经拥有的结论和下一步应该得到什么结论。将推理步骤以深度思考的方式连接到一起，让模型真正掌握推理能力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD149BUibsXqUvNo1Qt0rGic43FATZupUHa5XT6P9RjPP5iaIr9dVPoEiazT2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.2638398115429919" data-type="png" data-w="849" data-width="849" data-height="1073" data-imgfileid="503528871" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d342e0ce-aa8a-41cb-9bf1-c31c738807cb/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 2 过程性思考数据构造流程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;最后，推理的魅力在于结合已有的信息向未知发起冲锋。这个过程中可能存在错误，也需要进行多次的验证。掌握更多的思维模板（而不是只会链式思考）可以帮助模型应对不同的情况。如图 3 所示，在 sampler 阶段采用不同的采样方式，可以获得具有不同思维模板的推理数据，丰富大模型的推理 &amp;ldquo;技能库&amp;rdquo;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qvX4FjyaZ8bMybIwQoT7iaSOt8KeXnm39ZEhydEUDBkHZZ9AEGSq4ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6697848456501403" data-type="png" data-w="1069" data-width="1069" data-height="716" data-imgfileid="503528876" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/84cb3565-e6ef-4d6a-bda9-d608c359af51/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 3 多解和回溯思维模板数据构造示意图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;TrustGeoGen 不仅以可验证的方式生成大量的几何推理数据，更关注到了自然语言推理与形式化推理的差异，从模型训练的角度来生成连贯可信的推理数据，为提高多模态大语言模型的推理能力奠定了基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理短板究竟在哪里？GeoBench：从感知到反思的分层诊断基准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;做对了几何题，真的意味着模型&amp;lsquo;懂&amp;rsquo;了几何吗？&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当我们为多模态大模型在 GeoQA 等基准上超越人类的表现欢呼时，一个严峻的问题被掩盖了：现有的评估往往只看最终答案，却忽视了推理过程的严谨性。模型是真正掌握了空间逻辑，还是仅仅记住了教科书里的解题套路，甚至只是为了正确答案而在作 reasoning hacking？为了刺破这层迷雾，精准定位模型能力的边界，我们提出了 GeoBench &amp;mdash;&amp;mdash; 一个基于 TrustGeoGen 数据引擎而构建的分层诊断基准。&lt;/p&gt;&lt;p&gt;GeoBench 不再满足于单一的分数，而是将复杂的几何推理能力拆解为四个层层递进的维度：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. &lt;/strong&gt;&lt;strong&gt;视觉感知（Visual Perception）&lt;/strong&gt;：模型能否从图中精准提取数值与结构信息？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 目标导向规划（Goal-Oriented Planning）&lt;/strong&gt;：模型能否将大问题拆解为可操作的子目标？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 严谨定理应用（Rigorous Theorem Application）&lt;/strong&gt;：模型能否在众多定理中精准筛选出适用的那一条？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. 自我反思回溯（Self-Reflective Backtracking）&lt;/strong&gt;：当推理误入歧途时，模型能否及时发现并修正？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14L1eYsvibkksPekicibibctblXbUEBHKKQBPOgcKiazLk7YExGBHbhlmNg8g/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5916666666666667" data-type="png" data-w="1080" data-width="1881" data-height="1113" data-imgfileid="503528877" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b6d7af22-1f7e-4c44-b141-fc01cd6a11b8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4 GeoBench 概览：利用 TrustGeoGen 引擎生成包含图像、问题及推理图的形式化验证几何题，并基于四个推理能力层级，系统化构建分层评测任务&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;基于 TrustGeoGen 引擎生成的 1021 个形式化验证样本，我们设计了六大核心任务对模型进行全方位评估。实验结果不仅揭示了推理模型的短板，更带来了一些全新的发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;能力断层&lt;/strong&gt;：即使是 OpenAI-o3 这样的顶尖推理模型，随着任务复杂度的提升，性能也呈现显著下降趋势。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键瓶颈&lt;/strong&gt;：子目标分解（Sub-Goal Decomposition）无关条件过滤（Irrelevant Premise Filtering）是决定解题成败的最关键因素。这意味着，比起单纯的计算能力，模型更缺乏 &amp;ldquo;排除干扰、规划路径&amp;rdquo; 的大局观。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CoT 的反作用&lt;/strong&gt;：思维链（Chain-of-Thought）并非万能药。在涉及 &amp;ldquo;错误定位&amp;rdquo; 的高阶反思任务中，CoT 提示甚至会产生负面干扰，导致模型在错误的路径上越走越远。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14pQIpsAz47u8yDOvBs0AqkFv7IcaeQqWnbyKDHgtqzWK17ZDcsLhaPw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.1709090909090909" data-type="png" data-w="825" data-width="825" data-height="141" data-imgfileid="503528878" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3cad1706-13ef-4bea-9d33-21a4fbfe389f/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 1 模型在 GeoBench 的 6 个任务上的表现与求解出最终正确答案的相关性（spearman 系数）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;GeoBench 的出现，不仅是一次评测标准的升级，更为未来的几何推理系统指明了进化方向：从盲目追求答案正确率，转向对推理全过程的精细化掌控。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果监督是否足够？SGVR：用可验证的 &amp;ldquo;里程碑&amp;rdquo; 引导通用推理泛化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;平面几何训练场可以实现域外泛化吗？&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GeoBench 的诊断揭示了传统训练的致命弱点：模型常因 &amp;ldquo;虚假相关性&amp;rdquo; 而 &amp;ldquo;蒙对结果&amp;rdquo;，中间过程却充满幻觉。为了打破这种 &amp;ldquo;黑盒&amp;rdquo;，我们提出 SGVR (Sub-Goal Verifiable Reward) 框架，主张 &amp;ldquo;里程碑重于结果&amp;rdquo;（Milestones over Outcome）。我们利用 TrustGeoGen 将抽象证明拆解为一连串可自动验证的数值子目标，并引入 &lt;strong&gt;Skeleton Rate (SR) &lt;/strong&gt;作为核心指标 &amp;mdash;&amp;mdash; 它不再只看最终答案，而是计算推理链条中正确 &amp;ldquo;路标&amp;rdquo; 的比例。配合 GRPO 算法，这种密集的中间奖励强迫模型 &amp;ldquo;步步为营&amp;rdquo;，只有每一步逻辑都经得起验证，才能获得高分。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HYSXicO05icKg5XwS2Vf37k6F7DiaMDGW7HzsRo47qWheATbkRNaq4fPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.637962962962963" data-type="png" data-w="1080" data-width="1265" data-height="807" data-imgfileid="503528879" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/4e3b0123-921c-4986-8c39-006616a635fc/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5 SGVR 的核心机制：利用形式化引擎将复杂的几何证明题分解为多个可验证的数值子目标（Milestones）。通过引入 Skeleton Rate (SR)，模型在每完成一个中间路标时都能获得即时的密集奖励反馈，从而纠正逻辑幻觉，确保推理路径的每一步都精准可信。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这种训练带来了意想不到的惊喜：几何逻辑的 &amp;ldquo;溢出效应&amp;rdquo;。 SGVR 不仅让模型在几何推理任务上实现了&lt;strong&gt; 9.7%&lt;/strong&gt; 的显著提升，更展现出了强大的跨域泛化能力。在完全未见过的 通用数学（AMC, MATH-500） 和 通用逻辑推理 任务中，模型在零样本（Zero-shot）条件下分别获得了 &lt;strong&gt;8.0%&lt;/strong&gt; 和&lt;strong&gt; 2.8% &lt;/strong&gt;的性能跃升。这有力地证明：在高度严谨的几何环境中习得的 &amp;ldquo;验证思维&amp;rdquo;，能够转化为通用的逻辑素养，成为解锁复杂推理难题的关键钥匙。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14KeNTF43l9MicMMEHpbQJERkR2sXicUXHLj8j6fic1uxbeBgsJYLlNz1Mg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3638888888888889" data-type="png" data-w="1080" data-width="3398" data-height="1236" data-imgfileid="503528880" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/b3bc633b-f4c7-4a30-828c-57b9548c460e/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 6 SGVR 在显著提升几何推理能力的同时，展现了卓越的 &amp;ldquo;溢出效应&amp;rdquo;：在完全未接触过的通用数学（AMC, MATH-500）和逻辑推理任务中，模型性能均实现了显著跃升&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在确定了 &amp;ldquo;过程监督&amp;rdquo; 的有效性后，一个核心问题随之而来：我们需要对推理链条进行多大程度的干预？在 SGVR 的消融实验中，我们通过调节 &lt;strong&gt;Mask Ratio&lt;/strong&gt;（即隐藏子目标的比例）探索了验证密度对模型能力的影响。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14vN0GqOqMj9LhtP75CBysjwO97vMibHwv1Rup7C0qYT3UrRO7FVZUwCw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.7675925925925926" data-type="png" data-w="1080" data-width="1237" data-height="950" data-imgfileid="503528881" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/020ecff6-dd76-4f9e-8da4-28cdabcfb9a1/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 6 验证密度对推理性能的影响 &amp;mdash;&amp;mdash; 寻找监督的 &amp;ldquo;黄金分割点&amp;rdquo;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;图 6 的实验结果揭示了一个有趣的现象：&lt;strong&gt;验证并非越密越好，而是存在一个 &amp;ldquo;黄金比例&amp;rdquo;&lt;/strong&gt;。当我们将验证颗粒度保持在适中水平时，模型不仅能获得足够的纠错信号，还能保留一定的自主推理空间。一旦验证过于稀疏，模型会退回到 &amp;ldquo;结果赌博&amp;rdquo; 的老路；而过度的干预则可能导致模型过拟合于特定的验证路径，丧失了处理复杂变体的灵活性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;形式化增强的未来：通往鲁棒性推理的新范式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对当前推理模型普遍存在的逻辑断层与过程不可控问题，团队通过构建从可信数据合成、分级能力诊断到过程监督训练的一整套系统化方案，构建了一个完整的逻辑闭环。该闭环的核心在于：利用形式化验证的严谨性来约束与增强非形式化的推理过程，并通过在特定领域内的深度训练，赋予模型跨越领域边界的广义泛化能力。&lt;/p&gt;&lt;p&gt;这一研究范式表明，平面几何不仅仅是评估模型能力的试金石，更是训练 AI 具备高阶逻辑思维的最佳演练场。未来，团队将致力于将这种 &amp;ldquo;形式化增强&amp;rdquo; 的范式拓展至通用数学、代码生成、物理模拟等更广泛的领域，旨在构建更可信、更鲁棒且具备强大泛化能力的通用推理大模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于 FrontierX Lab：&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14mpEpgx67UKuZn9yicibtZrP9LQRjTdItIbcx7icuBtPTfhIj8eChN7uVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.20833333333333334" data-type="png" data-w="1080" data-width="1330" data-height="277" data-imgfileid="503528882" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c2f31278-0444-49e6-856d-5594b1369bda/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;FrontierX Lab 由上海交通大学人工智能学院助理教授夏纫秋创立，致力于探索人工智能的前沿边界，实验室核心方向涵盖形式化增强的推理大模型、多模态文档理解以及 AI 驱动的自动化科学发现等。实验室长期招募对符号 AI、多模态推理及前沿科学探索充满热情的博士 / 硕士研究生、科研助理及实习生，欢迎发送简历至 xiarenqiu@sjtu.edu.cn，共同拓展 AI 推理的认知边界！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>具身基座模型的曙光初现？35000小时训练数据，打造全球最强跨本体VLA</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 16:06:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;ul&gt;&lt;li&gt;项目官网：https://research.beingbeyond.com/being-h05&lt;/li&gt;&lt;li&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"section","attributes":{"style":"box-sizing: border-box;font-style: normal;font-weight: 400;text-align: justify;font-size: 16px;color: rgb(62, 62, 62);","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"letter-spacing: 1px;padding: 0px 3px;line-height: 2;box-sizing: border-box;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;论文链接：https://research.beingbeyond.com/projects/being-h05/being-h05.pdf&lt;/span&gt;&lt;/li&gt;&lt;li data-pm-slice="0 0 []"&gt;&lt;span data-eleid="6"&gt;GitHub代码开源：https://github.com/BeingBeyond/Being-H&lt;/span&gt;&lt;/li&gt;&lt;li data-pm-slice="0 0 []"&gt;HuggingFace模型开源：https://huggingface.co/BeingBeyond/Being-H05-2B&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在竞争日趋白热化的具身智能领域，行业主要聚焦于有限的本体市场。本体出货量的高低，不仅决定了自身数据的积累规模，更从根本上框定了基于该本体开发的算法性能上限&amp;mdash;&amp;mdash;用户基数越大，本体在真实场景中的综合表现往往就越强，形成一种近乎&amp;ldquo;马太效应&amp;rdquo;的商业闭环。&lt;/p&gt;&lt;p&gt;如今，这一固有的行业逻辑正在被打破：&amp;nbsp;BeingBeyond团队推出的全球最强跨本体VLA模型Being-H0.5，通过整合数万小时人类视频以及当前全球几乎所有主流机器人构型的操作数据，在视觉‑语言‑动作（VLA）任务中展现出惊人的跨本体泛化能力&amp;mdash;&amp;mdash;无论硬件形态如何差异，模型皆能快速适应、稳定执行。&lt;/p&gt;&lt;p&gt;在长达40多页的技术报告中，BeingBeyond 研究团队回答了这样一个问题：&lt;/p&gt;&lt;p&gt;&amp;ldquo;诚如不同语言虽具有各自的字母、单词，但总会或多或少共享部分底层的语法和逻辑结构，我们是否能让模型像掌握一门小语种一样，在一个数据有限的机器人本体上高效地部署任务技能？&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEGfHjnNtfSbe6XWSMDHE6pSNiaO0yFYd8Fbz208AuXmxn5sZq5Soapuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7898148148148149" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEGfHjnNtfSbe6XWSMDHE6pSNiaO0yFYd8Fbz208AuXmxn5sZq5Soapuw/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="572" data-cropsely2="460" data-imgfileid="100000522" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b4b23049-51a6-4dc8-8ef8-e8ea1946340c/640.png" alt="图片" data-before-load-time="1768896114273" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;图示中在多种形态机器人上部署的任务均由同一个模型checkpoint实现&lt;/p&gt;&lt;p&gt;研究团队认为，目前的 Vision-Language-Action (VLA) 模型大多是&amp;ldquo;单语者&amp;rdquo;：在一个平台上表现优异的模型，换到另一个本体上往往难以成功部署。这种形态异构性和数据稀缺性，成为了通向通用机器人智能的最大障碍。&lt;/p&gt;&lt;p&gt;为了打破这一僵局及回答上面的问题，研究团队推出了 Being-H0.5。其核心理念在于：将人类的交互行为视为物理世界的&amp;ldquo;母语&amp;rdquo;，通过在不同机器人本体之间共享&amp;ldquo;通用语法&amp;rdquo;，来实现VLA在跨本体部署上的超强泛化能力；通过体量近乎没有上限且能够赋予模型广泛轨迹意图、物理与空间先验信息的人类视频，有效避免模型在预训练过程中坍缩到单一本体的低维流形，从而真正实现低成本、跨本体泛化，以及纯依靠实验室数据所不具备的场景泛化能力。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;UniHand-2.0:打造全球最大规模的具身预训练数据集&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;泛化能力的根源首先来自于庞大的高质量数据。为此，研究团队在前作数据集UniHand-1.0的基础上，提出了其2.0版本。该数据集总时长超过3.5万小时，囊括14,000 小时的机器人操作数据， 16,000 小时的人类视频数据，以及5000小时通用多模态数据，总训练 token 数突破 1200 亿。这是全世界首次在机器人领域进行如此大规模、跨本体的数据整合和预训练尝试。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEmV3bHdwcceEjS7QP7cVD4icJxN8PiaSkJN3p9kRbVQd6BhFo2KIWjVxg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000505" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5c070193-61ca-4b62-8ec2-7d80b0193967/640.png" alt="图片" data-before-load-time="1768896114706" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;规模相仿的人类视频、机器人操作、通用多模态数据混合构成&amp;ldquo;铁三角&amp;rdquo;&lt;/p&gt;&lt;p&gt;与以往仅基于&amp;ldquo;轮式底盘 + 双臂夹爪&amp;rdquo;范式的研究（如 &amp;pi; 系列工作）不同，UniHand2.0 第一次实现了跨本体的大规模数据融合，汇集了超过 30 种 不同硬件构型的多样化数据，涵盖了从桌面机械臂到双足机器人在内几乎所有已知的机器人形态。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEbOicdh5D0vbSe2GSp6x9nL9n4A4XiaZYexbJ5eLd5AmJhviaj4EsGQgfQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000506" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/37b780be-4ecb-4d15-923b-a7510018286c/640.png" alt="图片" data-before-load-time="1768896115123" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;UniHand与现有VLA数据集规模对比：超3.5万小时和30余本体，在规模和多样性上提升了3倍以上&lt;/p&gt;&lt;p&gt;针对人类视频普遍缺乏高质量标注的痛点，团队还设计了一套名为 UniCraftor 的便携、可扩展、低成本的人类视频采集系统：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyERlKvib2pLIFZhicAThBhiaJtaP3DgnXicDpsaZWP9KNLuboMib4kL6AXCag/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.45740740740740743" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000507" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/426da185-36b3-4539-9b56-182ca6f72d25/640.png" alt="图片" data-before-load-time="1768896115156" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;统一动作空间&lt;/strong&gt;&lt;strong&gt;（Unified Action Space）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;在 Being‑H0.5 之前，尚未有研究尝试将如此多异构本体数据统一用于训练&amp;mdash;&amp;mdash;其核心挑战在于，不同机器人的状态空间与动作空间差异巨大，直接混合训练极易引发&amp;ldquo;数据冲突&amp;rdquo;，导致模型难以收敛或泛化。&lt;/p&gt;&lt;p&gt;为解决上述难题，BeingBeyond 团队创新性地提出了统一动作空间框架，将双足人形、轮式底盘、桌面机械臂、夹爪、灵巧手等形态各异的机器人，映射到同一特征表示空间中，从而有效支撑跨本体联合训练与知识迁移。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;以人为中心的训练范式：（&lt;/strong&gt;&lt;strong&gt;Human‑Centric Learning）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;在统一动作空间的基础上，以UniHand-2.0作为数据源，Being‑H0.5 提出了一套完整的以人为中心的预训练范式，具体包括：&lt;/p&gt;&lt;p&gt;统一序列化建模：不再为人类演示、机器人轨迹和视觉文本数据设立独立的训练流水线，而是将它们转化成统一的多模态token序列。在这个序列中，视觉和文本负责提供背景信息，而统一的&amp;ldquo;状态/动作&amp;rdquo;Token 则承载物理交互信号。&lt;/p&gt;&lt;p&gt;混合监督（多目标优化）：在同一个序列上根据数据特点应用不同的损失函数。如针对文本数据（如 VQA、运动描述）的Next-token Prediction；针对离散人类动作的Masked Token Prediction，针对连续人类和机器人数据，则在统一空间内进行动作预测（Action Prediction）等。&lt;/p&gt;&lt;p&gt;这种融合的预训练方式能让模型能在从人类行为中提取高层级的、可迁移的交互逻辑（先验）的同时，从机器人数据中提炼高精度的运动控制知识。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEjdYYbhwW5086vhZyc2svkP4cAMLpHBMchWRjiaeW2ogDlfOaWY09aog/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000508" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/47691311-4023-4a37-bb36-c508c44de5d4/640.png" alt="图片" data-before-load-time="1768896115539" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;Being-H0.5模型架构和预训练示意图，MoE+MoF结合的构型&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;面向跨本体的模型架构升级&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;传统的VLA，尤其是近期流行的基于flow-matching架构的模型，其模型容量由于参数大小存在限制，这导致VLA在混合异构数据进行预训练时的性能下降，同时也阻碍了模型泛化到各种复杂下游任务的能力。为了克服这个问题， 团队针对性地进行了一系列架构创新。&lt;/p&gt;&lt;p&gt;首先，受大模型 MoE 架构启发，团队设计了 Mixture-of-Flow（MoF） 架构，将动作专家（action expert）解耦为负责学习通用的运动原语（如：物体如何运动）的共享专家，以及通过机器人感知路由，负责特定形态精准执行的特化专家。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyELq3tsgX2DycddT2npwKPq9V3HG24dbqARHabdiapQtesWuWibmXUOa0A/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.23425925925925925" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000509" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5f45eea2-fa10-4128-87e6-4b119a30e57a/640.png" alt="图片" data-before-load-time="1768896117222" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;MPG和UAC模块示意图&lt;/p&gt;&lt;p&gt;此外，针对现实部署中的抖动和延迟问题，团队引入了 流形保持门控（Manifold-Preserving Gating, MPG）以确保在感知模糊时模型能退回到鲁棒的先验分布；以及通用异步分块（Universal Async Chunking, UAC）技术，使同一个模型能完美适配不同控制频率和延迟的机器人硬件。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;海量实验验证&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEfiaRlk5bG8s1fYXwJGRibWVayq60SgYl8nuOeXnSEic7m78ySc1LTznfg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000510" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/db4e0eea-7dcf-4341-9369-bd65f13d9109/640.png" alt="图片" data-before-load-time="1768896117223" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;Being-H0.5在不同构型本体上均进行了广泛验证实验&lt;/p&gt;&lt;p&gt;跨本体部署与基准测试：为验证 Being‑H0.5 的跨本体能力，研究团队在&amp;nbsp;PND、Unitree-G1、Franka 等不同构型的人形、机械臂本体上进行了大量真机实验。得益于海量多源数据的训练，该统一模型在复杂任务上展现出卓越的跨本体执行能力。在算法基准测试中，实现了 &amp;ldquo;一个Checkpoint，多本体运行&amp;rdquo; 的工程目标，并成功完成了如 &amp;ldquo;使用按压式喷壶浇花&amp;rdquo; 等对传统夹爪极具挑战性的精细操作。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEWy2Pe05QzW6M9cMU8B7T7ZdncMhv7IklvHHNGvtpZB9icCXgKuWkJzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000511" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d37aedcc-014a-4379-a26f-bb00f866bddd/640.png" alt="图片" data-before-load-time="1768896117256" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;跨本体真机任务&lt;/p&gt;&lt;p&gt;在四组任务上展开的定量评测实验中，Being-H0.5无论是generalist（多本体数据混合训练，难度更大）还是specialist（单一本体数据分开训练，较简单），性能表现都远优于仅能依托单一本体训练的 &amp;pi;-0.5模型。同时，Being-H0.5-generalist模型在平均性能表现上和specialist持平，展现出其跨本体维度上的强大泛化能力。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEzDXl36YU3IIZLTQ43o7jfHFKYOr71MQCrc51egUJJSXriateJOUQesg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.36944444444444446" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000512" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0e4b2871-d7d2-4c91-bf24-8b9a67bb3779/640.png" alt="图片" data-before-load-time="1768896117473" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;真机实验性能对比&lt;/p&gt;&lt;p&gt;仿真评测结果对比：&lt;/p&gt;&lt;p&gt;单纯依赖真机评测，难以广泛地和现有众多VLA模型进行更标准、公平的对比，为了提升模型性能的置信度，团队在两个最常见的仿真benchmark（LIBERO，RoboCasa）上进行评测，对比结果如下：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyEUHXwkdJ5XkSPD9s7z4lGmJaKm9fWm2E2Cc8viaPeumibuVoLpxHiaBXNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.537962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000513" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/8a3440b1-8941-4b24-95fc-8583c7e3328f/640.png" alt="图片" data-before-load-time="1768896117489" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;Being-H0.5首次实现VLA基座模型98.9的平均成功率&lt;/p&gt;&lt;p&gt;在仅使用224x224像素图像（所有模型中分辨率最低），不使用任何辅助模态（比如3D）的情况下，Being-H0.5在 LIBERO和RoboCasa&amp;nbsp;上分别取得98.9% 与 54% 的成功率，不仅超越了 &amp;pi;‑0.5、GR00T 等所有已知 VLA 模型，甚至优于部分借助强化学习与 3D 模态的方案，展现出强大的SOTA性能和竞争力。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Chwic30uKYzjNk7G2TkgfiaaS2cXHLYVyE2Q60Ov58Qf0GQicKmwVfBicBY4Gxia2DmsASgz5vCQfObibXJ89jV2uHgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.33796296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100000514" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5508a50b-e86c-4ea2-ad7c-095ce0ecb908/640.png" alt="图片" data-before-load-time="1768896117523" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []" style="text-align: center;"&gt;RoboCasa对比结果，Being-H显著超过pi0.5、GR00T等先进VLA&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;深度开源造福社区&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;当前VLA领域的开源实践多局限于发布预训练参数，而关键的预训练代码与部署方案往往缺失，这极大阻碍了社区的使用、复现与创新。为推动领域的开放发展与协作，团队决定进行完整开源：不仅公开预训练与后训练的全部模型参数，更将提供完整的训练与评估代码，以及一套可复现1000+ GPU小时训练的详细配方。未来，我们还将逐步开源真机部署代码与接口，诚邀社区同仁共同参与，构建更开放的具身智能生态。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;打破数据壁垒，开启跨本体泛化新时代&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;Being-H0.5 的发布，为全球具身智能领域带来了一个范式级的启发：高质量训练数据并非必须源于自建的高成本机器人集群。它巧妙地回应了&amp;ldquo;如何适配不同本体并获取优质数据&amp;rdquo;这一行业核心挑战&amp;mdash;&amp;mdash;将视角转向人类本身这一最丰富、最自然的数据源泉。这从根本上降低了行业门槛：公司无需投入上亿资金构建数据&amp;ldquo;护城河&amp;rdquo;，即可借助以人为中心的学习范式（human-centric learning），高效开发跨本体通用算法。这也是BeingBeyond团队一直以来坚持的核心技术路线，毕竟&amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;人类本身，才是这个世界最大、最自然的数据来源，这正是 human‑centric learning 最根本的魅力所在。&lt;/p&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>EmbodiChain开源，用100%生成式数据自动训练具身智能模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 15:27:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["list",{"type":"ul","style":"list-style-type: disc","class":"list-paddingleft-1","start":null},"listitem",{"style":"color:#7b0c00"},"para",{"tagName":"p","attributes":{"style":"text-align: left; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;论文地址:&amp;nbsp;&lt;/span&gt;https://www.techrxiv.org/doi/full/10.36227/techrxiv.176153394.41323502&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源主页:https://dexforce.com/embodichain/index.html#/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库: https://github.com/DexForce/EmbodiChain&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;技术文档: https://dexforce.github.io/EmbodiChain/introduction.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大语言模型的爆发，让大家见证了 Scaling Law 的威力：只要数据够多、算力够猛，智能似乎就会自动涌现。但在机器人领域，这个公式似乎失效了。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 LLM 时代，数据是「存量」，我们只需要负责「清洗」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在具身智能时代，数据必须是「增量」，我们必须具备「创造」数据的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不同于互联网上唾手可得的万亿级文本，机器人所需的、经过 3D 标定且符合物理规律的高质量交互数据，极度稀缺且昂贵。正因如此，数据采集范式成为了近年来行业研究的绝对焦点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可以看到，整个行业正在向着更低成本、更便捷的方向全速推进：&amp;nbsp;&lt;/strong&gt;从昂贵的遥操设备，到基于动捕手套的灵巧手捕捉和更加便携式的夹爪方案，再到如今甚至不再需要佩戴手套、仅凭双手演示即可采集数据的创新方案。&lt;strong&gt;这些轻量化的数采范式正在将人类的经验数字化，这一路径不仅充满价值，更值得持续深耕，它是连接人类技能与机器人动作的桥梁。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;整个行业在将具身智能推向大模型时代的这个目标上狂奔。&lt;/p&gt;&lt;p&gt;但是，即使是最极致的采集效率，客观上仍受限于物理时间的流逝和人力成本的边界。当下没有任何现有的物理采集范式，能匹配 LLM 训练所需的「互联网级」规模。这成为了具身智能迈向更高阶智能的最大桎梏。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率定律&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了突破这一天花板，需要引入一个新的视角。在传统的 Scaling Law 中，主要关注数据集、算力和参数量。但在具身智能中，有一个被忽视的隐形变量：&lt;strong&gt;数据生成的速率（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:34px;height:23px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ce295742-ac2d-4024-a857-0c2f6da74a5f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dii" style="width: 4.32%;"&gt;）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是&lt;strong&gt;跨维智能团队在论文《GS-World》中提出的核心洞察：智能的进化存在一个「逃逸速度」。&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;瓶颈期&lt;/strong&gt;：&amp;nbsp;当数据生成太慢（依赖人工采集或低速仿真），模型参数再大也无济于事，因为模型「吃不饱」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;爆发期&lt;/strong&gt;：&amp;nbsp;只有当&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:36px;height:24px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2f4ea652-7313-489e-96b8-1950b398f2f3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 4.2%;"&gt;超过临界值&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0TwiaiaZsSVyibmRPSELzibOwhibJzhB33JjX2L46Esibt6oassQsiaYjicFd6w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6216216216216216" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503529097" data-aistatus="1" data-original-style="width:45px;height:28px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/92e1d024-db2f-4dbe-8ac8-8bfebbd17a7e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 5.6%;"&gt;，数据不再是稀缺资源，而是像自来水一样源源不断时，模型性能才会随着参数量的增加而线性释放。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0dqnsfnUGYb2GCibhqYf5ZR85vPGnHZhUichVMvbKB31ibdicjfwJFGNOrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6376811594202898" data-s="300,640" data-type="png" data-w="828" type="block" data-imgfileid="503528999" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/dcf105fb-5df5-43d6-b393-633bba1c17b0/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 效率定律 (Efficiency Law) 下模型性能与数据生成速率的关系&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;要跨越这个鸿沟，除了物理采集的持续精进，另一种极具潜力的解决方式，就是&lt;strong&gt;构建一个能够超高速、自动化生成物理现实的数字世界&lt;/strong&gt;（跨维智能团队在《GS-World》中详述了这一路径）。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0c9DibAnhSlwxiavZtwwg5iczdngQJnppRcsx0KUn7OcGl4T9EpkopD5Gw/640?wx_fmt=jpeg#imgIndex=5" data-ratio="0.3925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0icQFeqRic5svorYD3gwqf7SGD3mQAQBRqEG3ibNtfvRROqKNURS22aDSA/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy1="26.903914590747327" data-cropy2="449.67971530249105" data-imgfileid="503529002" data-aistatus="1" data-original-style="width:562px;height:220px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3e2fc684-8258-467b-984c-8e75b7144d7b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在这个基于物理引擎的生成式世界中，数据的生成速率超越了时间的限制（Efficiency Law）；机器人可以在零成本的试错中习得对物理因果的深刻理解；所有的边缘情况（Corner Cases）都可以在这里被模拟、被攻克。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GS-World 与 EmbodiChain&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，跨维智能正式开源 EmbodiChain。作为通往&lt;strong&gt;&amp;nbsp;GS-World（基于生成式仿真的世界模型）&amp;nbsp;&lt;/strong&gt;的基石，EmbodiChain 不仅仅是一个数据和模型平台，更是一次对具身智能学习范式的重构。&lt;/p&gt;&lt;p&gt;跨维团队提出并验证一个大胆的假设：&lt;strong&gt;仅凭 100% 的生成式仿真数据，只要生成速率（Rate of Generation）突破临界点，机器人就能在真实世界中涌现出超越 SOTA 的泛化能力。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这不是科幻，这就是跨维正在验证的&lt;strong&gt;效率定律（Efficiency Law）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;EmbodiChain 的本质，就是一台&lt;strong&gt;将&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:34px;height:23px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1850e3b5-3909-44ed-b0c1-8d67429646bc/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 4.11%;"&gt;拉满的数据和模型制造引擎&lt;/strong&gt;。它不再依赖对真实世界的有限采样，而是开启了具有物理真实性的数据的批量制造。&lt;/p&gt;&lt;p&gt;然而，要将 GS-World 从蓝图变为现实，绝非易事。跨维研究团队必须面对并攻克&lt;strong&gt;三个核心科学难题&lt;/strong&gt;，这也是 EmbodiChain 致力于解决的关键：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何实现数据生产自动化？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实世界极其复杂，如何仅凭少量先验（如一段视频、一句描述），就在数字世界中自动重建、生成海量且物理一致的场景与任务，而无需人工手动搭建？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何打破「虚实鸿沟」（Sim2Real Gap）？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;仿真数据再多，如果不能迁移到真机也是徒劳。如何在不依赖或尽量少依赖真实数据微调的情况下，让模型习得适应真实世界噪声与动态变化的鲁棒策略？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何突破数据生成的「IO 墙」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Scaling 需要亿级甚至十亿级的交互步数。传统的「生成 - 存储 - 读取 - 训练」模式效率极低。如何构建极致高效的数据流转机制，实现「在线数据流」？&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;EmbodiChain：一条永不停歇的「在线数据流和模型生产线」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了实现这一愿景，跨维智能构建了&lt;strong&gt;&amp;nbsp;GS-World（Generative Simulation World Model，生成式仿真世界模型）&lt;/strong&gt; 的核心基石 &amp;mdash;&amp;mdash;EmbodiChain。&lt;/p&gt;&lt;p&gt;EmbodiChain 作为一个底层的基建技术，可以把它看作&lt;strong&gt;去存储化的数字化流水线&lt;/strong&gt;。Scaling 需要亿级甚至十亿级的交互步数，传统的「生成 - 存储 - 读取 - 训练」模式在面对海量 3D 数据时，存储与传输将成为不可承受之重。&lt;/p&gt;&lt;p&gt;在 EmbodiChain 的架构中，可以彻底抛弃「先存硬盘、再读硬盘」的陈旧范式，取而代之的是在线数据流（Online Data Streaming）和模型自动生产线。&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/105066a2-86d0-4c78-bebe-8903fa14489a/1768893817074.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;EmbodiChain 的核心工作流。数据在生成的同时即被消费，橘色的数据流贯穿全场，无需落地存储。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这条流水线是如何工作的？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;世界生成（Generative Simulation）&lt;/strong&gt;：&amp;nbsp;引擎不仅是环境，更是造物主。Real2Sim 模块从极少的真实样本中提取物理先验，Gen2Sim 模块则响应语言指令，自动构建出符合牛顿力学等物理规律的 3D 场景与资产。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据扩增（Data Scaling）&lt;/strong&gt;：&amp;nbsp;数据不仅要多，还要「难」。系统自动进行视觉增强、物理参数随机化，并剔除那些机器人「够不着」的无效采样。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自我修复（Closed-loop Recovery）&lt;/strong&gt;： 真正的智能来自于从错误中学习。当仿真中的机器人抓取失败，系统会自动生成修正轨迹。这种「失败 - 修正」的闭环，比单纯的成功演示更有价值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一切都在 GPU 内部并行高速运转，数据如洪流般产生，训练完即销毁，不留下一丝冗余，只留下模型能力的增长。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;路线之争：机器人需要的是物理精确的生成式模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在通往具身智能世界模型的路上，目前存在两条截然不同的路线。&lt;/p&gt;&lt;p&gt;一条是近期火热的&lt;strong&gt;视频生成路线（Video World Model）&lt;/strong&gt;，如 Sora 或 LTX-Video，它们试图通过「画出」下一帧来模拟世界。虽然视觉效果惊艳，但一些对比实验揭示了其致命弱点：&lt;strong&gt;幻觉&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;视频模型生成的画面往往缺乏长程的时空一致性，且很难精确遵循动力学方程。用这种「做梦」产生的数据训练机器人，就像让一个飞行员在爱丽丝的仙境中学习开飞机 &amp;mdash;&amp;mdash; 看着很美，一上真机就坠毁。&lt;/p&gt;&lt;p&gt;相反，EmbodiChain 选择的是 &lt;strong&gt;GS-World 路线（基于生成式仿真的世界模型）&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物理先验（Physical Priors）：&lt;/strong&gt; 跨维智能坚持世界模型必须是 3D 的、交互式的、物理严谨的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特权信息（Privileged Information）：&lt;/strong&gt; 在 EmbodiChain 中，使用者拥有上帝视角。比如使用者能够获取物体的精确掩码、空间关系和可供性（Affordance）。通过训练模型预测这些真实世界中不可见的「特权信息」，迫使模型理解了场景背后的&lt;strong&gt;几何本质&lt;/strong&gt;，而不仅仅是表面的像素。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这正是 Yann LeCun 所倡导的理念：&lt;strong&gt;世界模型应该是对世界状态的预测与规划&lt;/strong&gt;。&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dd396cbb-f4b4-48f4-8828-758f30f822ca/1768893887934.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; EmbodiChain中可以获取的特权信息示例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;零真实数据，VLA 真的可行吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证这套「效率定律」，跨维智能做了一件极端的测试：&lt;strong&gt;不使用任何真实数据训练模型。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;跨维智能训练出的 Sim2Real-VLA 模型，在真实世界中执行任务。结果令人惊讶：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;远超基线&lt;/strong&gt;：&amp;nbsp;在没有任何真实数据微调的情况下，它在操作成功率上大幅领先 ACT、Diffusion Policy 等主流方法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无惧干扰&lt;/strong&gt;： 即使跨维智能像「捣乱者」一样更换桌布、移动物体、改变光照，模型依然稳如泰山。甚至在某些任务中，由于去除了真实数据中容易过拟合的背景噪声，模型的表现反而比用真实数据训练还要好。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b68ec599-9159-4c23-bad5-e4d31f5949b0/1768893920724.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c77d8ed0-5332-42f9-a212-65d5192f37e6/1768893933659.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0d8E8iamrJjup4bGsiaYKEj9bln7RDgf6pqtyYOlDso3Wmh6MbsiaALtKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5652173913043478" data-s="300,640" data-type="png" data-w="828" type="block" data-imgfileid="503529026" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3a27c0cd-e3dd-46f2-8832-0755bc459581/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;Sim2Real-VLA 在全生成数据训练下，不仅击败了 SOTA，更展现了惊人的鲁棒性。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;愿景：通往 GS-World 的「效率奇点」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;EmbodiChain 的开源，只是一个开始。&lt;/p&gt;&lt;p&gt;GS-World 蓝图远不止于此。在跨维智能的规划中，&lt;strong&gt;这是一个引擎驱动的闭环路径（Engine-driven Loop）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不仅环境是生成的，任务也是生成的；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不仅策略是进化的，机器人的身体结构（Morphology）也会随着任务需求协同进化。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;跨维智能希望 EmbodiChain 能成为每一位具身智能研究者的基础设施。不需要再为了几千条数据而在实验室里没日没夜地遥操作，不需要再为几十 TB 的硬盘存储发愁。&lt;/p&gt;&lt;p&gt;因为智能的未来，不应该被困在数据的匮乏中。&lt;/p&gt;&lt;p&gt;EmbodiChain 现已开源，邀请你一起见证具身智能的「效率奇点」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一周对战2500万局，这些「AI假人」让人类游戏玩家破防了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 13:32:04 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜张倩&lt;/section&gt;&lt;p&gt;谁能想到，有朝一日，人在游戏里会被 AI 耍得团团转。&lt;/p&gt;&lt;p&gt;2025 年，国产游戏跑出一匹黑马 &amp;mdash;&amp;mdash; 巨人网络的《超自然行动组》。这款微恐题材多人合作游戏玩法直接：4 人组队进入古墓「摸金」，搜宝、打怪、限时撤离。7 月，这款游戏同时在线人数突破 100 万，它还长期霸占 App Store 免费榜和畅销榜前列。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528979" data-ratio="0.4609375" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0RHJZESx2H19ia9obIDE6YiasoKWtf7VFib9esc8icTbERTuwiaibZjDq30gA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/fa55cc72-ee4d-467b-92d4-407f3c9630d8/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0B6zHN7fRrCzhY4ExRc0cpCAwFZiciawWvCKibVsJ3MsvcG9cibh4coyxEQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.4609375" data-type="gif" data-w="640" type="block" data-imgfileid="503528980" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4840fd3d-90b5-42bd-82c5-bb71d87aab2f/640.gif" data-order="1" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更有意思的是，最近它又上线了一个新玩法：游戏里的怪物「假人」，接入了 AI 大模型。&lt;a href="https://mp.weixin.qq.com/s/jC9mZNs9mEy8v7c_SJGW1g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/06477058-b287-4031-8572-5e42b6cbd885/1768886894272.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;以前的 NPC 是脚本驱动，套路固定，老玩家一眼识破。现在不一样了，AI 假人会实时语音交流，能模仿队友音色，会说「跟我走，这边有好东西」，然后把你带进埋伏圈。它们会跳舞、会帮你打怪、会假装「中国好工友」，直到关键时刻突然反水&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/jC9mZNs9mEy8v7c_SJGW1g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9b30c4a4-ef3c-48c3-8878-8ef8c4142958/1768886913334.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 玩家被 AI 假人背刺案例。视频来源：抖音号 @钦佳丕定。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;新玩法上线后，玩家社区炸了。抖音、小红书上，「被 AI 背刺」「和 AI 假人尬舞」「全程没认出队友是 AI」的视频疯传。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ077RTzjzUT5FHyISg9jicHJb2OBtdtiaF8sNTJYsLT9SywwheiaYJKzaeQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="1.799074074074074" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528981" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/58dcc44c-7aac-45a8-b5dd-4ffe49cab1be/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0rwS5PRiaJZWWgvk3UQYpolykpibJuO9HzVA9ShjA7zJ6dFOHS3pVhTPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4935822637106184" data-s="300,640" data-type="png" data-w="857" type="block" data-imgfileid="503528982" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/faec334f-78bf-4d30-a035-27fa9c4cfab8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这不是实验室 Demo。上线一周，AI 就参与了近 2500 万场对局。巨人网络联合阿里云、火山引擎、腾讯云，在模型适配、实时推理、高并发稳定性上反复打磨，让这套系统真正跑了起来。&lt;/p&gt;&lt;p&gt;这也让《超自然行动组》成为&lt;strong&gt;国内首个在大 DAU 游戏中深度融合 AI 大模型、并实现规模化落地的产品&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这次探索让我们看到，当 AI 被放在合适的位置，它完全可以走进对局，参与博弈，让游戏本身变得更好玩，而不再只是站在玩法之外、可有可无的工具。当 AI 深度参与到游戏玩法的创造，游戏的研发也在从根本上发生改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 之于游戏 &amp;nbsp;无处不在，但游走于「安全区」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要说哪个行业最欢迎 AI，游戏行业绝对可以排进前几名。从直接生成美术资产到实时匹配队友、控制游戏难度再到扮演 NPC，AI 已经无处不在。&lt;/p&gt;&lt;p&gt;但如果仔细观察，我们可以发现一个现象：&lt;strong&gt;这些应用场景，绝大多数还处于「安全区」，AI 的「工具」属性非常明显。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就拿 AI NPC 为例。其实当前大多数 AI NPC 还是以对话型 AI 助手为主，它们会给你提供游戏攻略、武器使用说明等信息服务，甚至在支线剧情里演绎一些故事，但由于不参与对局，它们的存在本质上是和核心玩法分离的。无论 AI 表现如何，都不会影响玩家在对局中的实际体验。自动匹配队友、个性化内容推荐等功能也是一样，AI 同样游离于核心玩法之外。&lt;/p&gt;&lt;p&gt;更值得关注的是，&lt;strong&gt;目前大多数 AI 与游戏结合的探索仍停留在用户量较小的产品中，或仅在测试环境下进行验证&lt;/strong&gt;。一旦进入高并发、大 DAU 的真实场景，AI 系统的稳定性便难以得到保证，这也是游戏厂商们普遍保守的重要原因。&lt;/p&gt;&lt;p&gt;在这样的背景下，《超自然行动组》对 AI 大模型的深度整合看起来非常「前沿」，因为这次，&lt;strong&gt;他们用 AI 给人类创造了一些「对手」，在核心对局里验证稳定性、体验和风险&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;《超自然行动组》让 AI 加入核心对局，创造真实博弈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在《超自然行动组》中，AI 假人被设计成一个&lt;strong&gt;你必须认真对待的博弈对象&lt;/strong&gt;，因为它们会根据你的警惕程度、和你的距离、周围有没有目击者，动态决定是继续「装队友」还是趁机动手。你以为摸清了它的套路，下一局它可能就换了策略。这让体验从「背板过关」变成了「斗智斗勇」。&lt;/p&gt;&lt;p&gt;与此同时，AI 假人也被设计成一个「&lt;strong&gt;懂分寸的队友&lt;/strong&gt;」。它知道什么时候该互动、什么时候该闭嘴 &amp;mdash;&amp;mdash; 安全时主动找你聊两句，战斗时自动消停，不会在你手忙脚乱时刷屏。偶尔来一段跳舞、一个表情、一句调侃，存在感刚刚好，不抢戏，但让你觉得「这队友还挺有意思」。&lt;/p&gt;&lt;p&gt;这套设计落到实际体验里是什么样子？从玩家反应来看，AI 假人让人又爱又恨。有的玩家会把捡到的摸金符等道具丢给它，让它帮忙携带，但后来发现一旦自己被怪物攻击，AI 假人可能会带着所有物资逃跑，让人哭笑不得。很多玩家会跟它说「带我去找大金」，AI 假人确实会带路，有时还能找到雪莲花这类稀世珍宝，但也有可能把玩家带到死胡同里，让人一无所获。甚至，它们有时会抢玩家掉在地上或刚开棺发现的东西，玩家要是抢不过它们就只能努力把它们打死。&lt;a href="https://mp.weixin.qq.com/s/jC9mZNs9mEy8v7c_SJGW1g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/11c068a9-e107-4c48-858c-9e72de3e7445/1768886994598.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; AI 假人帮助人类玩家案例。视频来源：小红书博主 @十（超自然）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;更有意思的是，由于 AI 假人可以模仿真人的语音、行为，还懂得「欺骗」，很多玩家一上来根本分不出它们是真人队友还是 AI，这就给对局带来了更大的&lt;strong&gt;不确定性和紧张感&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是《超自然行动组》与那些「安全区」AI 的本质区别：AI 假人的表现会直接影响玩家这局的胜负。它帮人背东西、找宝贝，玩家就能更快达成目标；它抢玩家物资、把人带进死胡同，这局可能就此翻车。&lt;strong&gt;这不再是一个「无论 AI 表现如何都不影响体验」的辅助模块，而是核心玩法本身。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这也对 AI 的能力提出了更高要求，因为 AI 假人必须在复杂多变的对局环境中实时做出自主判断，做不好就很容易影响体验。而更难得的是，这套系统已经面向全量玩家开放，在高并发场景下依然保持稳定 &amp;mdash;&amp;mdash; 这在 AI 深度参与核心对局的案例中几乎没有先例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;好玩、刺激背后 &amp;nbsp;让大模型在规则圈内尽情发挥&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于巨人网络来说，这是一次高难度的尝试。将 AI 放进一个高并发、大 DAU 游戏的核心对局，既要保证系统稳定，又要让 AI 不破坏体验、反而增强沉浸感，背后需要大量技术打磨。&lt;/p&gt;&lt;p&gt;这背后的核心是一套&lt;strong&gt;「规则框架 + 大模型决策」的混合架构&lt;/strong&gt;：规则层划定边界，确保 AI 不会做出离谱的事；大模型则在边界内基于实时局势做判断，让每一次反应都有临场感。&lt;/p&gt;&lt;p&gt;当你说「带我去找大金」，它不会机械回复「好的」，而是真的理解你的意图，结合当前环境决定怎么走、要不要绕路。走错了会停下确认，被打断会重新调整目标 &amp;mdash;&amp;mdash; 这种「会犯小错、也会自己改」的表现，反而更像真人。&lt;/p&gt;&lt;p&gt;更关键的是，AI 假人能保持「&lt;strong&gt;言行一致&lt;/strong&gt;」。它说的话和正在做的事是绑定的，还能记住短期对话上下文，不会前一秒答应帮你找东西、后一秒就忘了自己在干嘛。这种连贯性，是让玩家觉得「它是个队友」而不是「一个会说话的 NPC」的关键。&lt;/p&gt;&lt;p&gt;正是游戏设计与技术的双重打磨，让《超自然行动组》有底气走出「安全区」，把 AI 从旁观者变成真正的参与者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;做得了爆款，啃得了技术 &amp;nbsp;巨人多年布局终兑现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;看到这里，你可能会好奇：把 AI 扔进核心对局这么大胆的事，为什么是巨人网络先做出来了？&lt;/p&gt;&lt;p&gt;答案很简单：他们确实准备了很久。&lt;/p&gt;&lt;p&gt;在国内众多游戏厂商中，&lt;strong&gt;巨人网络是最早、最系统地把 AI 当成「核心业务」来做的一批&lt;/strong&gt;：2022 年成立 AI 实验室；2023 年把 AI 写进研发管线；2024 年拿下国内首张「游戏垂直大模型」备案；2025 年又投资了 AI 图像平台 LiblibAI 和 AI 视频生成公司爱诗科技。这种自研、投资、产业协同多线并进的做法让我们看到了巨人网络推动 AI 与核心游戏业务深度融合的决心。&lt;/p&gt;&lt;p&gt;这些布局在游戏里也开始跑通了。2024 年，他们在社交推理游戏《太空杀》中成功探索了 AI 原生玩法，陆续推出了「AI 推理小剧场」「AI 残局挑战」「AI 残局对决」等模式，相关玩法累计吸数百万玩家参与，产生了数千万对局，为 AI 在游戏中的规模化应用积累了实践经验。&lt;/p&gt;&lt;p&gt;这些积累，最终在《超自然行动组》身上开花结果。负责这款产品的是一支非常年轻的团队，2025 年暑期即冲进 iOS 畅销榜 Top 10，把小众赛道做成全民品类。如今，他们又把 AI 大模型带进了核心对局。既能做爆款，也能啃硬骨头，这支年轻团队的表现，或许正是巨人网络多年 AI 投入开始兑现的信号，也是巨人网络持续跑在游戏行业前沿的证明。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;玩家反感 AI？《超自然行动组》打消行业顾虑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回到开头的问题：为什么大多数厂商不敢把 AI 放进核心对局？除了技术难度，还有一个更现实的顾虑 &amp;mdash;&amp;mdash; 玩家可能不买账。&lt;/p&gt;&lt;p&gt;这种担忧并非没有依据。GDC 数据显示，认为「AI 会给游戏行业带来消极影响」的玩家比例，从 2024 年的 18% 上升到了 2025 年的 30%。&lt;/p&gt;&lt;p&gt;但《超自然行动组》的实践提供了另一种可能。它用真实的玩家反馈证明：&lt;strong&gt;玩家反感的并不是 AI 本身，而是被工具化、破坏体验的 AI。当 AI 真正参与博弈，成为风险和刺激的来源，它反而可能被接受，甚至被欢迎。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这也是《超自然行动组》对行业更大的价值所在。当 AI 进入胜负系统，游戏应该如何被重新设计？这款产品给出了一个已经跑通的样本。&lt;/p&gt;&lt;p&gt;这类高频、强互动、可持续运行的 AI 原生玩法，一旦验证可行，意义不止于「多了一种玩法」，而在于它打开了一条新的内容生产路径：AI 不再只是辅助工具，而是内容生成与博弈本身的一部分，每一局都能产生新的变化与体验。这或许才是游戏行业下一个真正的增长空间。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>TPAMI | DC-SAM：打破SAM交互限制，基于循环一致性的图像与视频上下文分割方法</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 13:26:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/97bf003e-0c97-44cc-9d91-9a0a47ae3832/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;上下文分割（In-Context Segmentation）旨在通过参考示例指导模型实现对特定目标的自动化分割。尽管 SAM 凭借卓越的零样本泛化能力为此提供了强大的基础，但将其应用于此仍受限于提示（如点或框）构建，这样的需求不仅制约了批量推理的自动化效率，更使得模型在处理复杂的连续视频时，难以维持时空一致性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;北京邮电大学联合南洋理工大学等&lt;/strong&gt;机构发表的 IEEE TPAMI 期刊论文《DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency》，不仅为图像和视频的上下文分割建立了统一的高效框架 &lt;strong&gt;DC-SAM&lt;/strong&gt;，还构建了首个视频上下文分割基准&lt;strong&gt; IC-VOS&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;研究团队巧妙地提出基于提示微调的 &amp;ldquo;循环一致性&amp;rdquo; 机制，通过正负双分支与循环一致性注意力的协同，配合 Mask-Tube 策略，实现了 SAM 与 SAM2 在图像及视频上下文分割任务上的统一与高效适配。&lt;/p&gt;&lt;p&gt;实验结果显示，DC-SAM 在多个基准测试中均取得了 SOTA 性能：在 COCO-20&lt;sup&gt;i&lt;/sup&gt; 上达到 55.5 mIoU，在 &amp;nbsp;Pascal-5&lt;sup&gt;i&lt;/sup&gt; 上达到 73.0 mIoU；在新建的 IC-VOS 视频基准上，J&amp;amp;F 得分高达 71.52，显著优于现有方法。该篇论文已被 &lt;strong&gt;IEEE TPAMI &lt;/strong&gt;录用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14LjibtpoKdq7r88CTaBaqEfHljJ2g1xO6pmPzgyjXjJObLIE1YvhVCdw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.19537037037037036" data-type="png" data-w="1080" data-width="1604" data-height="314" data-imgfileid="503528903" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f3ae3690-9d81-4fde-ab70-0a80440952d6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2504.12080&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/zaplm/DC-SAM&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;研究背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，以 &amp;nbsp;SAM 和 SAM2 &amp;nbsp;为代表的视觉基础模型凭借海量训练数据，展现了卓越的交互式分割能力，已成为医学影像、开放词汇分割等下游任务的强大基石。然而，尽管 SAM &amp;nbsp;在 &amp;ldquo;分割一切&amp;rdquo; 上表现出色，却缺乏 &amp;ldquo;上下文分割&amp;rdquo;（In-Context &amp;nbsp;Segmentation）的能力 &amp;mdash;&amp;mdash; 即无法仅凭一张参考示例（Support Image）及其掩码，自动在查询图像（Query Image）中分割出同类目标。&lt;/p&gt;&lt;p&gt;为了弥补这一短板，早期的少样本学习方法多依赖度量学习，但泛化能力有限。虽然 SegGPT 等通用模型通过大规模图文对训练实现了上下文分割，但其计算资源消耗巨大。相比之下，提示微调（Prompt &amp;nbsp;Tuning）提供了一条高效路径。然而，现有的 SAM 适配方法（如 VRP-SAM）主要依赖骨干网络提取的通用特征，忽略了 SAM 自身提示编码器（Prompt Encoder）的特征特性，且往往未能充分利用背景（负样本）信息来约束分割边界，导致生成的提示精度不足。&lt;/p&gt;&lt;p&gt;此外，视频领域的上下文分割研究尚处于空白阶段。现有的视频分割基准（如 DAVIS、MOSE）主要侧重于给定首帧掩码的半监督跟踪任务，缺乏评估 &amp;ldquo;基于参考示例进行视频分割&amp;rdquo; 能力的专用基准。&lt;/p&gt;&lt;p&gt;针对上述挑战，研究团队推出了&lt;strong&gt;首个视频上下文分割基准 IC-VOS&lt;/strong&gt;，并同步提出了 &lt;strong&gt;DC-SAM 框架&lt;/strong&gt;。该框架旨在通过提示微调技术，将 SAM 与 SAM2 的能力无缝迁移至这一新任务，实现了统一高效的图像与视频上下文分割。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD145SgGRkZkWVfr5zdsIKHZ2iaUNiaCbtzJeXibjzabC72YXRbQmAT10GrnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.2657407407407407" data-type="png" data-w="1080" data-width="1744" data-height="464" data-imgfileid="503528904" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8922185d-708b-4aab-9935-199813ea863f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;DC-SAM与现有方法的对比图。 a) 方法对比图，b) &amp;nbsp;预测可视化对比图，c）得分对比图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;IC-VOS：首个面向上下文视频分割的大规模基准数据集&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在研究过程中，研究团队发现该领域缺乏一个专门用于评估 &amp;ldquo;上下文视频对象分割&amp;rdquo; 的统一基准。现有的 VOS 数据集大多侧重于第一帧掩码的追踪，而传统的 Few-shot 图像数据集则完全丢失了时间维度。&lt;/p&gt;&lt;p&gt;为了填补这一空白，研究团队推出了 &lt;strong&gt;IC-VOS (In-Context Video Object Segmentation) &amp;nbsp;数据集&lt;/strong&gt;。这是首个旨在全面衡量模型在视频上下文中学习能力的数据集。IC-VOS &amp;nbsp;涵盖了极其丰富的场景，包括极小目标分割、快速运动变形以及复杂背景融合等。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wkJNOgR4aEgrNI8RYQVO1vibRkqWBDCYk7UXO6D7Bl5RMgvm0oJYBpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.2601851851851852" data-type="png" data-w="1080" data-width="1832" data-height="476" data-imgfileid="503528905" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9b60bf01-c1de-405a-b265-5ec5282aad9e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; IC-VOS 分割基准：a) 数据来源，b) 词云图，c) 类别分布，d) 示例样本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DC-SAM 框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DC-SAM 框架由三个核心部分组成：&lt;strong&gt;基于 SAM 的特征融合、正负双分支循环一致性提示生成&lt;/strong&gt;，以及&lt;strong&gt;面向视频的 Mask-tube 训练策略&lt;/strong&gt;。该框架旨在充分利用 SAM 的特征空间，通过显式的正负样本约束和循环校验，生成高精度的视觉提示。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14KSSmu9k8NVAo8dibyRatMxCiaMGUNnawpvqErLf95aaCBn9dzOApI3yw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4388888888888889" data-type="png" data-w="1080" data-width="1668" data-height="732" data-imgfileid="503528906" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/62014ff3-9976-4b2c-8eaa-73e002fe7824/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; DC-SAM方法概览图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于 SAM 的特征融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现有的上下文分割方法通常仅依赖于预训练骨干网络（如 ResNet 或 DINOv2）提取特征，这导致生成的 Prompt 与 SAM 内部的特征空间存在 &amp;ldquo;语义鸿沟&amp;rdquo;。&lt;/p&gt;&lt;p&gt;为了弥补这一差距，研究团队提出了一种&lt;strong&gt;特征融合&lt;/strong&gt;策略。在提取查询和支持图像的骨干特征（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14AThkfFr7icJfgjPtr3Ts78ga3RlDD8xrg4vXrBHqeIDdsH5vAJBYGXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.9607843137254902" data-s="300,640" data-type="png" data-w="102" type="block" data-imgfileid="503528907" data-aistatus="1" data-original-style="width: 27px;height: 26px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/48f4f8c8-8349-401a-b3d0-3a475b9bc690/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.27%;"&gt;和&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JeP2uQ6D0F0KicTyEn61V8ibJLf0261TZlA3p85txFrdgk0h0SiczzN6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.8679245283018868" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503528908" data-aistatus="1" data-original-style="width: 26px;height: 23px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1c7ecee8-ba84-40ee-bc44-77ec8ff5b1ae/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;）的同时，也提取 SAM Image Encoder 的特征 (&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14OQMXkfGejXlUIQ9fGcBevc6ibwzpJFyNxE7oODnv3PbqynnfxDG5HIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5945945945945946" data-s="300,640" data-type="png" data-w="222" type="block" data-imgfileid="503528909" data-aistatus="1" data-original-style="width: 43px;height: 26px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6eace2bc-1057-40fa-b5d2-87716279a39e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 6.22%;"&gt;和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wyE1ibwYtcve7cHria3Hq1EdHRgRDtYdG2E34GAM61aCG4IbFkUlWEpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5259259259259259" data-s="300,640" data-type="png" data-w="270" type="block" data-imgfileid="503528911" data-aistatus="1" data-original-style="width: 44px;height: 23px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f70c9f26-9dcc-4fbf-891d-005a3ce5da6b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 6.54%;"&gt;&lt;span align="" alt="" border="" data-aiimageid="" data-aiimagesource="" data-aistatus="1" data-asynid="" data-backh="" data-backw="" data-before-oversubscription-url="" data-cacheurl="" data-cardimg="" data-copyright="" data-croporisrc="" data-cropselx1="" data-cropselx2="" data-cropsely1="" data-cropsely2="" data-cropx1="" data-cropx2="" data-cropy1="" data-cropy2="" data-fileid="" data-fromlib="" data-galleryid="" data-gallerysupplier="" data-height="" data-imgfileid="503528910" data-imgid="" data-imgqrcoded="" data-oversubscription-url="" data-positionback="" data-ratio="" data-remoteid="" data-retry="" data-s="300,640" data-src="" data-type="png" data-upload="" data-w="" data-width="" height="" ismap="" sizes="" src="" title="" type="block" usemap="" width=""&gt;)。随后，将骨干特征、SAM 特征以及通过参考掩码加权的特征进行拼接与融合：&lt;/span&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14vo9bteGqcY9L56QO3XYO9CeWWaGsDiaF5Qx4aPQxDXPt9N5XzW1icY9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.175" data-type="png" data-w="1080" data-width="1430" data-height="250" data-imgfileid="503528912" data-aistatus="1" data-original-style="width: 379px;height: 66px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/03b42633-1d9c-4fa0-a85d-5bfc6d10ada2/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HG6KeCFSDRpL68rGns4iagF12Cem3kiaYLWdL3ibA1IYkknY42rQYicGgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8918918918918919" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503528967" data-aistatus="1" data-original-style="width:29px;height:26px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/a5eeed39-65d5-4255-9830-ecdacee0f6a6/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.58%;"&gt;为参考掩码，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14oKA9aq1tSwKhFibqXibNrmOLNpI0jnU4Iof4iaibI7Q0Iwoib6knybdWoUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0253164556962024" data-s="300,640" data-type="png" data-w="158" type="block" data-imgfileid="503528914" data-aistatus="1" data-original-style="width: 28px;height: 29px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3556447c-37ac-432b-83ee-55d1f1b1041f/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Zlskr3Rd3L8jaSw16kVKrpShk2wqxW3z7NdN9q2sN5Ry61fSAdv9RQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.971830985915493" data-s="300,640" data-type="png" data-w="142" type="block" data-imgfileid="503528968" data-aistatus="1" data-original-style="width:26px;height:25px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/a786f993-1062-483d-9262-4a378302dd09/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;为融合后的特征。这种设计确保了特征表示既包含通用的语义信息，又保留了 SAM 特有的视觉模式，为后续的提示生成提供了更适配 SAM 的输入。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14BjU4HLbWhrxsjFJKFYAqYENZ5qxEnn4icvWd9QSuAYwic1lpZGZknR1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5924764890282131" data-type="png" data-w="638" data-width="638" data-height="378" data-imgfileid="503528916" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/36646528-eddd-4931-a505-1b227b1f0f27/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 基于 SAM 的多源特征融合方法图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;正负双分支循环一致性提示生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;正负双分支循环一致性提示生成是 DC-SAM 的核心模块。为了解决单一前景提示带来的边界模糊问题，研究团队设计了正负双分支（Dual-Branch）结构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;正分支利用参考掩码&amp;nbsp;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HG6KeCFSDRpL68rGns4iagF12Cem3kiaYLWdL3ibA1IYkknY42rQYicGgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.8918918918918919" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503528967" data-aistatus="1" data-original-style="width:29px;height:26px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/1fa3bef8-fd55-4173-a5b2-c32a68363c3a/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dii" style="width: 4.42%;"&gt;生成正样本提示，聚焦目标主体；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;负分支利用背景掩码 1-&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HG6KeCFSDRpL68rGns4iagF12Cem3kiaYLWdL3ibA1IYkknY42rQYicGgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.8918918918918919" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503528967" data-aistatus="1" data-original-style="width:29px;height:26px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/ba016d36-b209-47ba-9ad1-d06e3ef74271/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 4.09%;"&gt;生成负样本提示，抑制背景噪声。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在每个分支内部，为了防止 &amp;ldquo;语义漂移&amp;rdquo;（即错误匹配非目标区域），研究团队引入了&lt;strong&gt;循环一致性交叉注意力（Cyclic Consistent Cross-Attention）&lt;/strong&gt;。其核心思想是：只有当支持图像中的像素 j 与查询图像中的匹配像素 j* 满足语义类别一致时，才保留该注意力权重；否则，通过偏置项 B 将其屏蔽：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14yXK5jKOv1ARoUcnW6nauDGgTompkT6zCQfCAUVILrENwWV3Hk1fTHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.24444444444444444" data-type="png" data-w="1080" data-width="1080" data-height="264" data-imgfileid="503528917" data-aistatus="1" data-original-style="width: 337px;height: 82px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/81225a0b-2cbc-4b7c-a052-b836a2b0b533/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;基于该偏置项，可以计算经过循环校验的注意力输出，确保生成的 Prompt 仅聚合高度可信的特征：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14U8g5ib70jfYcfL0kWvXPOXBZNl1fzxpDkLr8nZCY3D8v78jPZeicMxeg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.08333333333333333" data-type="png" data-w="1080" data-width="1132" data-height="94" data-imgfileid="503528918" data-aistatus="1" data-original-style="width: 391px;height: 32px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/f23eb5f4-97b4-48f6-99b3-6695be937c44/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;最终，正负分支生成的 Prompt 分别叠加 SAM 预训练的 Pos/Neg Embeddings，共同指导 Mask Decoder 生成精准掩码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Fe53GHHF7yps9HSz2vaX8YQqDzSrJLmONUBTmELNP4FxzQfMa9hiceQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.3574074074074074" data-type="png" data-w="1080" data-width="1316" data-height="470" data-imgfileid="503528919" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/3384da67-67a9-4adf-b3cb-3262726f7ed2/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 正负双分支循环一致性提示生成方法图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向视频的 Mask-tube 训练策略及模型优化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;得益于 SAM 与 SAM2 在 Prompt Encoder 上的架构一致性， DC-SAM 可以无缝迁移至视频领域。为了赋予模型处理时空动态的能力，研究团队设计了轻量级的 &lt;strong&gt;Mask-tube（掩码管道） &lt;/strong&gt;训练策略，通过数据增强将静态图像堆叠为伪视频序列，从而模拟连续帧之间的时序变化。&lt;/p&gt;&lt;p&gt;在优化阶段，无论是图像还是视频流的预测，均由二元交叉熵损失（BCE Loss）和相似度度量损失（Dice Loss） 共同约束。最终的总损失函数定义为两者的加权和，以平衡局部像素分类与整体区域重叠度的优化目标（超参数 &amp;lambda; 经验性地设置为 1）：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148vEsF9GboZIBv3ZR6PENJA2DK3JThE5y0A5Qf666HTZgIBR0VOEcnw/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.18253968253968253" data-s="300,640" data-type="png" data-w="504" type="block" data-imgfileid="503528969" data-aistatus="1" data-original-style="width:214px;height:39px;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/1867268c-686b-44c4-b09d-b268127b26fc/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;性能评估与实验分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结果方面，DC-SAM 在图像上下文分割基准 COCO-20&lt;sup&gt;i&lt;/sup&gt; 和 &lt;span data-pm-slice='2 2 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Pascal-5&lt;sup&gt;i&lt;/sup&gt; 上&lt;/span&gt;取得显著性能优势。与基础视觉模型对比，即使面对使用了海量图文对训练的通用模型 SegGPT（56.1 mIoU），基于 DINOv2 的 DC-SAM 依然在 COCO-20&lt;sup&gt;i&lt;/sup&gt; 上取得了 62.0 mIoU 的成绩，实现了近 6% 的性能反超，证明了所提出提示微调方法的泛化能力。与 基于 SAM 的方法对比，在同等骨干网络（ResNet50）下，DC-SAM 全面超越现有的 SAM 适配方法，即使对比最强的基准模型 VRP-SAM，也在COCO-20&lt;sup&gt;i&lt;/sup&gt; 超越了 1.6%，证明 SAM 特征融合方法以及 Prompt 生成的有效性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ClDClXHlcrXdia82sQaGrHd7icCpfk7ePMLPxcsdsMtDMPZcCDCJQhmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.7069351230425056" data-type="png" data-w="894" data-width="894" data-height="632" data-imgfileid="503528921" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/0c8c3e20-f824-4240-8f7d-3aef69950a31/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在团队首创的视频基准 IC-VOS 上，DC-SAM 取得了 71.52 的 J&amp;amp;F 得分，以 6.4% 的显著优势超越了 VRP-SAM，并大幅领先 PerSAM。这不仅充分验证了 Mask-tube 策略的有效性，更证明了循环一致性约束能有效抑制视频传播过程中的语义漂移，实现稳健的目标锁定。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD1485mGHAvf9Xh3dwK555mYuBdMnmovd14VZby4lAWNZ1mmtLMU6D2WVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.4111111111111111" data-type="png" data-w="1080" data-width="1630" data-height="670" data-imgfileid="503528922" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/e129a901-c1c7-46f4-bce0-d07d951e26c4/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了直观评估模型性能，研究团队对 &lt;span data-pm-slice='2 2 ["para",{"tagName":"p","attributes":{"data-pm-slice":"2 3 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"lang":"EN-US"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Pascal-5&lt;sup&gt;i&lt;/sup&gt; 和 IC-VOS 上的分割结果进行了可视化分析。在&lt;strong&gt;图像任务&lt;/strong&gt;中，DC-SAM &amp;nbsp; 展现了对复杂结构和细粒度特征的强大捕捉能力。无论是 &amp;ldquo;瓶子&amp;rdquo; 的完整轮廓，还是 &amp;ldquo;鸟类&amp;rdquo; 的细微纹理，模型均能生成高精度的掩码；特别是在处理 &amp;ldquo;自行车&amp;rdquo; 和 &amp;ldquo;飞机&amp;rdquo; 等复杂物体时，DC-SAM &amp;nbsp;有效抑制了背景区域的误检（False Positives），边缘分割清晰锐利。&lt;/span&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14BXbKlPGiaCKEDxOUQub7rF5KXibqXzfY2fnibibDUfic7RwlTjYfgnYnKBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.45092592592592595" data-type="png" data-w="1080" data-width="1534" data-height="692" data-imgfileid="503528923" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/0979fcf1-1fcc-4b3b-9bc2-b5acc860ff99/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图像上下文分割效果对比图，黄色的叉表示明显错误。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在更具挑战的&lt;strong&gt;视频任务&lt;/strong&gt;中，DC-SAM &amp;nbsp;的优势进一步凸显。以 &amp;ldquo;摩托车&amp;rdquo; 视频序列为例，基线模型 PFENet &amp;nbsp;出现了明显的语义漂移现象，不仅漏检了车轮，还错误地将骑手包含在分割目标内。相比之下，DC-SAM &amp;nbsp;能够精准区分干扰对象（如骑手）与目标主体，在连续帧中实现了稳健的语义锁定与追踪。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Psv02VZcZPRuO1DLby4cZLoWSS39gcZiaXn5AktJWpkVQxBVTm4RmRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.4203703703703704" data-type="png" data-w="1080" data-width="1412" data-height="594" data-imgfileid="503528924" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/bf00ad17-61ca-46e1-ba34-aa02aba64330/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频上下文分割效果对比图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我们相信，DC-SAM &amp;nbsp;的提出为视觉大模型的落地应用，尤其是在需要高效、自动处理海量视频数据的工业与科研领域，提供了极具竞争力的解决方案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;齐梦实，北京邮电大学计算机学院，教授、博导。博士毕业于北京航空航天大学，美国罗切斯特大学联合培养博士。曾工作于瑞士洛桑联邦理工学院CVLAB担任博士后研究员，百度研究院访问研究员等。入选2021年第七届中国科协青年人才托举工程（中国人工智能学会）、2024年小米青年学者、2025年ACM北京分会新星奖。主要研究方向为人工智能、计算机视觉和多媒体智能计算等。作为主要负责人承担国家自然科学基金（面上/青年）、北京市自然科学基金-小米创新联合基金、腾讯犀牛鸟课题、小米、阿里、微软合作项目等，并作为核心研发人员参与了国家自然科学基金重大/重点项目、科技部重点专项和港澳台科技专项等，发表国际高水平期刊会议论文50余篇，包括顶级学术会议CVPR/ICCV/ECCV/NeurIPS/ACM MM/AAAI和权威学术期刊TPAMI/TIP/TMM/TCSVT/TIFS等，担任顶级会议AAAI、IJCAI的领域主席和TMM的特邀编辑。&lt;/p&gt;&lt;p&gt;毕萧扬，北京邮电大学计算机学院，硕士研究生。主要研究方向为人工智能、计算机视觉和自动驾驶等。作为核心研究人员参与北京市自然科学基金-小米创新联合基金、腾讯犀牛鸟课题等重点科研项目。发表的国际高水平论文成果收录于权威学术期刊TPAMI和顶级学术会议UbiComp。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>MIT、哈佛等让细胞「记住」自己的基因活动历史，首次在哺乳动物细胞中记录转录组状态</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Tue, 20 Jan 2026 12:02:30 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;细胞的状态随时间而调整，若要理解细胞如何做出自己的决策，需要能够将过去的分子状态与未来的表型结果联系起来。&lt;/p&gt;&lt;p&gt;故而，来自 MIT 与哈佛大学的团队设计了一个细胞时间胶囊，能够收集和存储过去活动的记忆。这些被称为 TimeVault 的细胞储存单元，可能有助于揭开抗癌药物耐药性和干细胞生物学的秘密，揭示过去事件如何塑造细胞的未来。&lt;/p&gt;&lt;p&gt;相关研究以「&lt;em&gt;A genetically encoded device for transcriptome storage in mammalian cells&lt;/em&gt;」为题，于 2026 年 1 月 15 日发布在《Science》。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027195" data-ratio="0.24777006937561943" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkjU5iagtb5ATnoR0Gnib45uCIos5a14ibjvAwh7FP2icYK7lHlpLraeibDWtYibSXk6nGQ1gjdg7zAzJgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1009" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/fdf2c857-57c3-430e-a542-fe97d3bfb0ce/640.png" alt="图片" data-before-load-time="1768881694791" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.science.org/doi/10.1126/science.adz9353&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;细胞录音机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;细胞是不断变化的，对于这种动态过程，研究人员通常会采用两种方式进行研究。一种方法是在显微镜下观察它们的生命，通过荧光标签追踪有限数量的分子数天。另一种方法是在试管中，在实验的单一时间点（通常是实验结束时），测量 mRNA 分子，并与其他细胞中的分子进行比较。&lt;/p&gt;&lt;p&gt;在过去十年里，研究人员开发了大量「细胞记录器」&amp;mdash;&amp;mdash;许多采用 CRISPR 基因编辑技术&amp;mdash;&amp;mdash;以创建一个不可磨灭的短暂事件遗传账本，比如某一特定分子通路随时间的活动 。随后，基因组测序可以读取该账本，识别后续的编辑，从而创建细胞事件的时间线。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="431" data-backw="546" data-imgfileid="100027196" data-ratio="0.7887029288702929" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkjU5iagtb5ATnoR0Gnib45uCb0ibsqfhaRouLE5vZK9UkhWEwqV7yZNfEHI6CS1cOrfQZFaqKgsiauyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="956" type="block" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/dd155e9e-89bd-4a11-8175-90dd0e52fa83/640.png" alt="图片" data-before-load-time="1768881696313" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：TimeVault系统的概述和特征（部分）。&lt;/p&gt;&lt;p&gt;相关链接：https://www.nature.com/articles/d41586-025-03035-2&lt;/p&gt;&lt;p&gt;但这些实验也有缺点：研究人员必须提前决定要监测哪些事件，哈佛大学马萨诸塞州剑桥分校研究单细胞和基因组生物学的 Chen Fei 如此表示。&lt;/p&gt;&lt;p&gt;为了寻找一种公正记录细胞寿命的方法，Chen 和他的同事们在 YouTube 上获得了灵感。该实验室里的一名学生看到了一份关于 Leonard Rome 的资料。他是加州大学洛杉矶分校的细胞生物学家，20 世纪 80 年代，Rome 与他人共同发现了穹顶，这些穹顶在大多数哺乳动物细胞中均有数千个。然而，它们的功能自此一直未知。&lt;/p&gt;&lt;p&gt;为了将 vault 变成时间胶囊，该团队重新设计了 vault 蛋白，使其能够识别并连接 mRNA 分子的分子标志，从而捕获 vault 内的 mRNA。这种蛋白质的产生&amp;mdash;&amp;mdash;相当于按下「录音」按钮&amp;mdash;&amp;mdash;通过用药物治疗细胞触发，通过撤回药物停止。&lt;/p&gt;&lt;p&gt;团队发现，通过这些改造，时间宝库在 24 小时内捕获了人类细胞系产生的 mRNA 分子中的一小部分，并至少储存了一周。研究人员未发现携带时间宝库的细胞因货物而表现不同，桶状结构填充后也未发生变化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实际应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;关于如何应用他们的发明，团队的探索才刚刚开始。&lt;/p&gt;&lt;p&gt;在论文中，该团队利用时间宝库来理解并克服被称为顽固癌细胞的恶性癌细胞。这些细胞缺乏能躲避靶向癌症药物的基因突变，却能在药物治疗中存活下来。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="390" data-backw="546" data-imgfileid="100027197" data-ratio="0.7150368033648791" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkjU5iagtb5ATnoR0Gnib45uCExTPp15ic19ibYFmbHMJGe0APvgfZBJflICyUD3RV94G1iaSP4ibMD749Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="951" type="block" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/32451ad4-5d93-4bfc-9d10-3596934ed7b6/640.png" alt="图片" data-before-load-time="1768881696760" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：TimeVault 揭示了 PC9 细胞对奥希替尼耐药性背后的转录异质性。&lt;/p&gt;&lt;p&gt;相关链接：https://www.nature.com/articles/d41573-020-00050-y&lt;/p&gt;&lt;p&gt;一种假说是，持久细胞中活性的 mRNA 转录本解释了它们逃避药物的能力。但 Chen 表示，测试这一观点颇为棘手，因为癌症药物会引起各种其他转录变化，这些变化难以与可能导致持续性的问题区分开来。&lt;/p&gt;&lt;p&gt;利用 TimeVaults，该团队识别出数百个在持续性肺癌细胞中过度活跃的基因，这些基因在接受药物治疗前就已存在。抑制这些基因中表达最高的部分，使癌症药物杀死了更高比例的肺癌细胞。&lt;/p&gt;&lt;p&gt;这个团队还开始使用 TimeVaults 研究干细胞如何分化成多样的细胞类型。&lt;/p&gt;&lt;p&gt;华盛顿大学西雅图分校的基因组科学家杰伊&amp;middot;申杜尔说，将金库变成细胞时间胶囊需要「一些创造力和勇气」。他预计这些设备将成为 CRISPR 记录仪的有用补充，就像他团队开发的那样。他还想知道金库是否可以被设计用来储存蛋白质和其他细胞纪念物，而不仅仅是 RNA。&lt;/p&gt;&lt;p&gt;报道链接：https://www.nature.com/articles/d41586-026-00116-8&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>钉钉上线AI差旅：企业免垫资，员工免报销，AI帮比价</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 11:58:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;一趟差旅回来，员工不用再为整理发票头疼，财务无需核对上百张零散票据，而公司却能省下大笔开支——这样的场景正在钉钉上成为现实。钉钉最新推出的“AI差旅”功能，正试图改变中小企业出差的烦恼。&lt;/p&gt;&lt;p&gt;1月20日，钉钉更新8.2.5版本，由钉钉、高德、支付宝合作的“AI差旅”产品正式上线，所有企业用户在最新的钉钉内搜索“AI差旅”、“差旅用车”、“机票”、“酒店”等相关关键词，即可零门槛、免费开通这一服务，无需垫资或支付服务费。在该版本中，AI印、AI听记同声传译等能力也全量上线。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5ce959d0-6837-4852-a315-5118dcb0e12c/1768881390350.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;把中小企业的差旅成本打下来，AI差旅让企业免垫资、员工免报销&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;钉钉AI差旅专为500人以下中小企业打造，整合了高德打车、支付宝企业支付等能力，为用户提供机票、酒店、火车票及用车四大核心场景的差旅服务。与市面上其他商旅平台相比，钉钉AI差旅直连锦江、如家、东呈、亚朵、雅斯特等酒店集团系统，酒店预订更便宜。该产品还提供AI比价功能，为用户在全网自动搜索比价，实时获取多个预订平台的酒店价格，来找到最低价的选项。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f4947085-55c4-4ca0-b594-d106d6c8890d/1768881418508.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;对经常出差的员工来说，AI差旅的差旅助理让出差更简单，实现一句话规划行程，即使是复杂的多城市路线也能在30秒内给出最优方案，并自动生成出差单，无需手动填写。&lt;/p&gt;&lt;p&gt;更让员工感到便利的是，钉钉与高德合作推出的“无感报销”用车功能。员工提交外出或差旅申请后，可直接在审批单内或通过搜索“高德打车”叫车；行程结束后，发票和行程单自动关联至对应的审批单，彻底告别了手动翻找票据的繁琐。在支付环节，钉钉携手支付宝企业码提供了企业代付能力，员工出差无需垫付，企业可按需开通。&lt;/p&gt;&lt;p&gt;对企业管理层，AI差旅内置了专业的差旅管理能力，可以自定义差旅标准，设置机票预订时限、酒店价格区间、火车席别等级；产品还可生成按部门、按员工维度的明细和排行榜，让差旅成本真正做到可视、可控。&lt;/p&gt;&lt;p&gt;在杭州一家机器人企业“原力无限”，HR负责人现场对比了钉钉和其他出行平台的价格后，当场决定启用。“钉钉上的酒店资源不仅连锁品牌全覆盖，价格也非常能打。”启用一月后，员工从提交申请到完成报销的全流程周期，从过去的10天大幅压缩至3天，公司当月差旅开支直接省下约15万元。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计打印太贵太麻烦？AI印让海报设计印刷像“网购”一样方便&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;同时上线的钉钉AI印，则将企业的物料设计和印刷流程打包在钉钉里，它能够提供从AI素材设计再到物料打印、物流接收的全流程支持，让用户享受到更有保障、更低成本、更高品质的海报设计及印刷服务。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8236934-07a1-4b8f-ae30-e79230888b3e/1768881433472.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;过去设计靠外包、印刷要货比三家、物流难追踪，如今通过钉钉AI印，没有设计基础的运营、市场人员也能几分钟生成和精修出专业海报，一键下单直连全国六大印刷工厂，易拉宝、彩页、宣传册等主流品类全覆盖，价格远低于打印店等传统渠道，主要城市最快半日送达。&lt;/p&gt;&lt;p&gt;杭州扶一把网络科技有限公司CEO蒋迎安坦言：“以前打个易拉宝要多方询价、反复沟通；现在一站搞定，AI设计+平台物流，品质、效率、确定性全都有，我们省去了到处比价的繁琐，也大幅提升品质与效率。”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;外语不好没关系，AI听记为跨国开会配了AI翻译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在音视频协同方面，钉钉在8.2.5版本也进一步升级了AI翻译同传能力。在面对面沟通、跨国视频会议时，能及时听到翻译后的对话，就算外语不好，在国外旅游、开会时也不再焦虑。&lt;/p&gt;&lt;p&gt;面对面同声传译的新能力，不仅提供翻译字幕，也支持语音翻译。只要戴上一副普通的蓝牙耳机，即可实现中英日等多语种的实时互译，还可设置左右声道为不同语言，两人一人一只耳机即可顺畅沟通。钉钉视频会议则支持多语种双向同传，参会者只需设置自己的语言，即可在跨国会议中“听自己熟悉的母语”，会中还会自动生成纪要和待办，显著提升跨国协作效率。&lt;/p&gt;&lt;p&gt;“我们在国内和越南都有生产基地，在欧美都有分公司和经销商，每次开会涉及不同部门、国家和语言。AI同传让我们不再依赖专业翻译，也能实现周度月度的无障碍沟通”。杭州一家户外家居企业负责人表示。&lt;/p&gt;&lt;p&gt;从AI差旅到AI印，再到AI翻译，钉钉正把原本只有大企业才能享受的专业服务，通过AI下沉给更多中小企业，让出差不再折腾，印刷无需比价，跨国沟通不再焦虑，在降低成本的同时真正释放每一位员工的时间和精力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>零样本&amp;少样本横扫12个工业医疗数据集：西门子×腾讯优图新研究精准定位缺陷，检测精度新SOTA丨AAAI 2026</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 11:49:34 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;在工业质检与医学影像等真实场景中，&lt;strong&gt;异常检测&lt;/strong&gt;始终面临一个核心矛盾：&lt;/p&gt;&lt;p&gt;模型既要跨领域泛化，又要在几乎没有目标域数据的情况下，精确定位细微异常。&lt;/p&gt;&lt;p&gt;现实生产中，产线频繁换型，新产品刚投产，缺陷样本极少，而异常往往表现为局部、稀疏、小尺度的像素级变化。这使得大量依赖监督学习或目标域微调的方法难以真正落地。&lt;/p&gt;&lt;p&gt;近日，西门子与腾讯优图联合研究团队提出&lt;strong&gt;AdaptCLIP&lt;/strong&gt;，一种&lt;strong&gt;通用视觉异常检测框架，&lt;/strong&gt;具有以下亮点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;单一模型&lt;/li&gt;&lt;li&gt;无需目标域微调&lt;/li&gt;&lt;li&gt;同时支持&lt;strong&gt;图像级异常分类&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;像素级异常分割&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;兼容&lt;strong&gt;零样本&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;/&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;少样本&lt;/strong&gt;推理&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、为什么&amp;ldquo;通用异常检测&amp;rdquo;一直做不好？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通用异常检测要求模型在&lt;strong&gt;训练域与测试域分布显著不同&lt;/strong&gt;的前提下，仍能稳定检测异常。这一设定暴露了现有方法的结构性瓶颈：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;传统无监督&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;AD&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;方法&lt;/strong&gt;（如PaDiM、PatchCore、重建式模型）依赖大量正常样本，一旦面对未见类别或新领域，性能迅速退化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;驱动的方法&lt;/strong&gt;虽借助跨模态先验实现零样本检测，但代价并不小：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;WinCLIP 依赖密集窗口扫描，计算与显存开销巨大；&lt;/li&gt;&lt;li&gt;AnomalyCLIP、AdaCLIP 通过修改中间层或引入复杂token，削弱了 CLIP 的原始表征能力；&lt;/li&gt;&lt;li&gt;InCtrl、PromptAD 要么只支持图像级判断，要么仍需目标域重新训练。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;问题归结为一句话：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何在不破坏&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;原有泛化能力的前提下，让它真正学会&amp;ldquo;找异常&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、AdaptCLIP的答案：少即是多&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP&amp;nbsp;将&amp;nbsp;CLIP&amp;nbsp;视为一种&amp;ldquo;&lt;strong&gt;基础服务模型&lt;/strong&gt;&amp;rdquo;，不改动其主干结构，仅在输入与输出端引入&lt;strong&gt;三个轻量适配器&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视觉适配器（VisualAdapter）&lt;/li&gt;&lt;li&gt;文本适配器（TextAdapter）&lt;/li&gt;&lt;li&gt;提示-查询适配器（Prompt-QueryAdapter）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;并由两个关键洞见驱动：&lt;/p&gt;&lt;p&gt;1️⃣ &lt;strong&gt;视觉与文本表征不应联合学习，而应交替学习&lt;/strong&gt;；&lt;br&gt;2️⃣ &lt;strong&gt;少样本对比学习不能只看残差，还必须结合上下文信息&lt;/strong&gt;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/0576e23e-e1ba-451d-b881-32b0cd77a801/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图1 AdaptCLIP架构图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、交替学习：零样本异常检测的核心机制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.1 从 CLIP 的异常判别说起&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;给定查询图像，CLIP视觉编码器输出局部&amp;nbsp;patch token&amp;nbsp;与全局图像token，并与&amp;ldquo;正常&amp;nbsp;/&amp;nbsp;异常&amp;rdquo;文本嵌入进行相似度比对，即可得到图像级异常分数与像素级异常图。&lt;/p&gt;&lt;p&gt;但在工业场景中，&lt;strong&gt;原生&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;的像素级定位能力明显不足&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.2 视觉适配器：只做&amp;ldquo;微调&amp;rdquo;，不做&amp;ldquo;重塑&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视觉适配器分别作用于局部&amp;nbsp;patch token&amp;nbsp;与全局token，均采用&lt;strong&gt;残差&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;MLP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;结构&lt;/strong&gt;，对 CLIP 表征进行轻量自适应调整：&lt;img src="https://image.jiqizhixin.com/uploads/editor/3c2bdec3-e780-4ad1-b811-49bf1f99e3d1/%E5%9B%BE%E7%89%871.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;其中&lt;img src="https://image.jiqizhixin.com/uploads/editor/d854eebe-7d63-4626-950b-cc7292090166/%E5%9B%BE%E7%89%871.png" style="width: 3.58%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/2923abc3-68cd-4fef-bc16-a2e05410c4df/%E5%9B%BE%E7%89%872.png" style="width: 3.69%;" class="fr-fic fr-dii"&gt;分别表示CLIP输出的局部 patch token和全局图像token，&lt;img src="https://image.jiqizhixin.com/uploads/editor/a92f6451-becd-4365-b695-c44879420433/%E5%9B%BE%E7%89%873.png" style="width: 2.74%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/a5f99854-9f2a-45d7-a1e8-291c9f12f9af/%E5%9B%BE%E7%89%874.png" style="width: 2.85%;" class="fr-fic fr-dii"&gt;为适配器可学习参数。&lt;/p&gt;&lt;p&gt;其目标是在&lt;strong&gt;固定文本语义空间&lt;/strong&gt;的前提下，使视觉特征更贴合异常检测任务，从而显著提升像素级定位能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.3 文本适配器：抛弃 prompt 工程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;文本适配器不再依赖人工设计的模板，而是&lt;strong&gt;直接学习&amp;ldquo;正常&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;/&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;异常&amp;rdquo;两类可优化提示嵌入&lt;/strong&gt;，并输入冻结的 CLIP 文本编码器生成语义表示：&lt;img src="https://image.jiqizhixin.com/uploads/editor/db3a3687-774e-4da0-af85-766dc7d60aa6/%E5%9B%BE%E7%89%871.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;其中&lt;img src="https://image.jiqizhixin.com/uploads/editor/512bbc31-3406-4185-ab17-3ecfc668a906/%E5%9B%BE%E7%89%871.png" style="width: 3.69%;" class="fr-fic fr-dii"&gt;表示CLIP文本编码器，&lt;img src="https://image.jiqizhixin.com/uploads/editor/1322ef86-05a3-4e35-b9fd-72884f95c556/%E5%9B%BE%E7%89%872.png" style="width: 4.96%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/898d53af-a6e8-4582-8cd3-5899dfc306ff/%E5%9B%BE%E7%89%873.png" style="width: 4.85%;" class="fr-fic fr-dii"&gt;为最终用于特征比对的异常与正常文本嵌入。&lt;/p&gt;&lt;p&gt;这一设计在保留&amp;nbsp;CLIP&amp;nbsp;原有语义结构的同时，降低了对&amp;nbsp;prompt&amp;nbsp;经验的依赖。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.4为什么交替学习优于联合学习？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文通过消融实验发现，在小规模训练数据下，&lt;strong&gt;联合学习易过拟合&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此&amp;nbsp;AdaptCLIP&amp;nbsp;采用交替优化策略：&lt;/p&gt;&lt;p&gt;固定文本&amp;rarr;&amp;nbsp;优化视觉；固定视觉&amp;rarr;&amp;nbsp;优化文本，循环迭代。&lt;/p&gt;&lt;p&gt;该策略在多个工业与医学数据集上，显著优于联合学习方案，成为零样本异常检测性能提升的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、对比学习：少样本场景下的关键补强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当可获得少量正常样本时，AdaptCLIP启用&lt;strong&gt;提示-查询适配器&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.1 空间对齐：先对齐，再比较&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对查询图像的每个patch，模型在正常样本中搜索&lt;strong&gt;欧氏距离最近的&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;patch&lt;/strong&gt;作为对齐目标，从而消除旋转、平移带来的干扰，并计算对齐残差特征。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.2 残差 + 上下文：避免&amp;ldquo;只见树木，不见森林&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文发现，仅依赖残差特征虽然能突出差异，但容易引入噪声、丢失上下文信息。&lt;/p&gt;&lt;p&gt;因此&amp;nbsp;AdaptCLIP&amp;nbsp;将&lt;strong&gt;原始查询特征与对齐残差逐元素相加&lt;/strong&gt;，形成联合特征：&lt;img src="https://image.jiqizhixin.com/uploads/editor/ca6a354d-1d59-4828-8acd-ba38320b64ae/%E5%9B%BE%E7%89%874.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在 1-shot 设置下，引入上下文后，在 MVTec 数据集上的像素级 AUPR &lt;strong&gt;提升约&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;40%&lt;/strong&gt;，成为少样本性能跃迁的关键因素。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.3 从联合特征到异常预测：极简分割与分类头&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在得到融合了&lt;strong&gt;上下文与对齐残差&lt;/strong&gt;的联合特征后，AdaptCLIP 采用一套&lt;strong&gt;轻量输出头&lt;/strong&gt;完成异常预测。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;像素级分割&lt;/strong&gt;：联合特征经 &lt;strong&gt;1&amp;times;1 卷积&lt;/strong&gt;与若干 &lt;strong&gt;转置卷积模块&lt;/strong&gt;上采样至原分辨率，生成异常图；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;图像级分类&lt;/strong&gt;：对联合特征进行&lt;strong&gt;平均池化与最大池化&lt;/strong&gt;，融合后输入 &lt;strong&gt;MLP&lt;/strong&gt;输出异常分数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推理阶段根据可用信息进行结果融合：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;零样本&lt;/strong&gt;：融合视觉适配器与文本适配器预测；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;少样本&lt;/strong&gt;：在此基础上进一步融合提示-查询适配器结果。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;五、实验结果：跨工业与医疗的一致验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP 在&lt;strong&gt;12 个公开基准数据集&lt;/strong&gt;（8 个工业 + 4 个医疗）上进行了系统评估，覆盖不同成像模态与异常类型。&lt;/p&gt;&lt;p&gt;在零样本异常检测场景下，AdaptCLIP 在 MVTec、VisA、BTAD、Real-IAD 等工业数据集上，图像级 AUROC 平均达到&lt;strong&gt;86.2%&lt;/strong&gt;（SOTA），在多类未见产品与跨类别测试中依然保持稳定优势。&lt;/p&gt;&lt;p&gt;在医学影像任务中，AdaptCLIP在内窥镜数据集Kvasir与Endo的零样本像素级异常分割AUPR平均达到&lt;strong&gt;48.7%&lt;/strong&gt;，并在Br35H（MRI）、COVID-19（X-ray）等数据集的零样本图像级异常检测中取得平均&lt;strong&gt;90.7%&lt;/strong&gt;的AUROC，均显著高于其他现有方法。&lt;/p&gt;&lt;p&gt;在少样本设置下，随着正常样本数量从 1-shot 增加至 4-shot，异常区域的定位逐步细化。提示-查询适配器显著降低了误报区域，使异常边界更加清晰。&lt;/p&gt;&lt;p&gt;从模型规模与效率来看，AdaptCLIP在零样本条件下仅引入约&lt;strong&gt;0.6M&lt;/strong&gt;额外可训练参数（对比方法可高达10.7M）。在 518&amp;times;518 分辨率下，零样本条件单张图像推理时间约&amp;nbsp;&lt;strong&gt;162 ms&lt;/strong&gt;，兼顾检测精度与实际部署需求。&lt;img src="https://image.jiqizhixin.com/uploads/editor/652672e5-67c0-432a-9138-77e0e6d2a54f/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;table border="1" cellspacing="0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan="5" valign="center" width="100%"&gt;&lt;p&gt;&lt;a name="u8650227d"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign="center" width="17.158931082981717%"&gt;&lt;p&gt;&lt;a name="u320fbf43"&gt;待检图像&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="21.940928270042193%"&gt;&lt;p&gt;真实缺陷标注&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="21.09704641350211%"&gt;&lt;p&gt;0-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="20.253164556962027%"&gt;&lt;p&gt;1-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="19.549929676511955%"&gt;&lt;p&gt;4-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图2 &amp;nbsp;AdaptCLIP在工业与医疗数据上检测结果可视化&lt;img src="https://image.jiqizhixin.com/uploads/editor/222f8d35-1fea-4579-b844-df4fdef7140a/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;图3 &amp;nbsp;AdaptCLIP在工业与医疗数据上图像级AUROC分类结果与其他方法对比&lt;img src="https://image.jiqizhixin.com/uploads/editor/39d5826b-98c0-4aa9-b9dc-b77348676ed6/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图4 &amp;nbsp;AdaptCLIP在工业与医疗数据上像素级AUPR分割结果与其他方法对比&lt;img src="https://image.jiqizhixin.com/uploads/editor/7999c22a-1a03-48b1-9ebf-1dbb2e9f2024/%E5%9B%BE%E7%89%873.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图5 &amp;nbsp;AdaptCLIP与其他方法对比模型规模与效率&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP&amp;nbsp;并未试图&amp;ldquo;重造一个更大的模型&amp;rdquo;，而是通过&lt;strong&gt;交替学习&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;轻量适配&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;上下文感知对比&lt;/strong&gt;，在不破坏&amp;nbsp;CLIP&amp;nbsp;原始能力的前提下，实现了真正可迁移的异常检测。&lt;/p&gt;&lt;p&gt;它为工业与医疗等开放场景提供了一条清晰路径：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用最少的结构改动，换取最大的泛化收益。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2505.09926&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>WAIC首次“南下”：沪港握手2026“WAIC UP!全球年终盛会”，共揭AI对话新篇</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻助手</author>
      <pubDate>Tue, 20 Jan 2026 10:40:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f064dd62-3632-4097-8448-c4f8c4378c24/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20260116223441_6204_11_min.png" style="width: 700%;" class="fr-fic fr-dib"&gt;香港，2026年1月16日——作为世界人工智能大会（WAIC）的年度重磅收官活动，“WAIC UP!全球年终盛会”今日在香港科学园举行。全天数千位观众与来自国际、中国大陆和中国香港的AI专家学者、企业家、投资人及香港立法会议员等共聚一堂。&lt;/p&gt;&lt;p&gt;此次盛会意义非凡，核心主题&lt;strong&gt;“WAKE UP MORE!”&lt;/strong&gt;，象征着一次从认知到行动、从个体到生态的全面唤醒。这不仅是世界人工智能大会（WAIC）首次在港举办年度旗舰活动，更标志着&lt;strong&gt;以上海为代表的内地前沿AI产业实践，与香港的国际枢纽功能完成了一次历史性的战略握手&lt;/strong&gt;，共同激发更广阔的技术前景、更深入的产业融合与更具全球影响力的创新生态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;顶格政商学阵容，筑就国际级思想高地&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大会获得香港各界的高度重视与支持。&lt;strong&gt;香港特别行政区行政长官李家超先生&lt;/strong&gt;特别通过视频为大会揭幕致辞，他表示，今年盛会首次在香港举办，以“WAKE UP MORE!”为主题，彰显了人工智能的无限可能。要借助AI推动创新，更要用于构建具包容性的经济体系、更具韧性的社区，更可持续创造所有人的未来。并阐明香港在全球AI版图中的战略定位，释放全力支持创新科技产业发展的政策信号。&lt;strong&gt;香港特别行政区创新科技及工业局局长，JP孙东教授&lt;/strong&gt;、&lt;strong&gt;香港科技园公司行政总裁黄秉修先生&lt;/strong&gt;，以及&lt;strong&gt;香港特别行政区立法会议员、香港资讯科技联会会长邱达根先生&lt;/strong&gt;亲临现场发表致辞。引人注目的是，&lt;strong&gt;第十四届全国人民代表大会港区代表，JP，MH冼汉迪先生&lt;/strong&gt;也莅临大会并致辞，与主办方&lt;strong&gt;东浩兰生会展集团股份有限公司副总裁裘皓明女士&lt;/strong&gt;共同启动这一国际AI界年度思想盛会。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a1ac9cb7-1d37-4974-9377-b5b406525f61/%E7%89%B9%E9%A6%96.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这一阵容与会上40余位全球顶尖的AI科技产业巨擘形成“政府战略+学界前沿+产业实战”的黄金三角，标志着一个连接长三角与大湾区、贯通顶尖技术与全球市场的创新闭环正在WAIC的平台上加速形成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三幕递进式论坛，精准匹配思想价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;议程设计突破传统模式，WAIC旗下五大生态品牌首次在香港并联，以“思想觉醒—拓维跃迁—灵感迸发”为主线，打造差异化体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上午场【WAKE思想觉醒】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;聚焦新锐思想，锚定未来坐标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上午立足全球前沿，&lt;strong&gt;WAIC UP!新锐思想&lt;/strong&gt;为我们打开视野，看见未来真正的轮廓。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;硅谷人工智能研究院创始人、院长皮埃罗·斯加鲁菲（Piero Scaruffi）&lt;/strong&gt;带来开幕主题演讲，以“70·40·10——人工智能与硅谷的过去、现在与未来”为框架，全面梳理了AI七十年的技术演进、硅谷四十年的创新生态以及未来十年的未知与希望。&lt;img src="https://image.jiqizhixin.com/uploads/editor/303e10ef-422e-4958-8de7-90fa6f7c3514/Piero_Scaruffi.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中国工程院外籍院士、香港科技大学首席副校长郭毅可&lt;/strong&gt;将宏大的AI主权理念具象化为“港话通（HKChat）”等一系列深度本地化应用，展现AI技术如何扎根香港社会肌理与香港作为东西方AI枢纽的战略价值。&lt;img src="https://image.jiqizhixin.com/uploads/editor/aa41fac3-9f1a-4bf8-b523-139b4d248815/%E9%83%AD%E6%AF%85%E5%8F%AF.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;香港城市大学首席人工智能总监、香港人工智能与科学研究院院长马维英&lt;/strong&gt;阐述了“AI科学家”愿景，提出FLEX（Forward Learning From Experiences）框架配合分层记忆系统，实现智能与经验的闭环共进化，勾勒出AI重塑科学发现范式与大学研究教育体系的未来图景。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1ae09a9c-3334-41ef-b321-30058a9562e9/%E9%A9%AC%E7%BB%B4%E8%8B%B1.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下午场【UP拓维跃迁】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;WAIC矩阵并联，直击实战与生态&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下午进入高密度、分众化的实战对接环节。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC CONNECT实战案例&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Founders Space董事长兼首席执行官史蒂夫·霍夫曼（Steve Hoffman）&lt;/strong&gt;以“AI is Eating Everything（人工智能正在吞噬一切）”开场，用“吞噬”这一生动比喻与直观图示，宏观勾勒出技术爆发的全球图景与中美竞逐态势，最终引发“AI是否会取代人类工作”的紧迫且深刻思考。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b15f4abc-a96e-4d94-99fb-6b19b07fbb25/Steve_Hoffman.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;来自科研、算力、资本与市场的四方视角汇聚成&lt;strong&gt;“商业与产业圆桌”&lt;/strong&gt;，完整讨论了从技术研发到商业落地的闭环，尤其关注如何将实验室成果转化为稳定产品、如何突破规模化营收瓶颈、以及如何构建开放协同的AI生态，为AI产业化提供了清晰、务实的发展路径。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c0f89096-b685-465b-b805-d15826872233/%E4%BA%A7%E4%B8%9A%E4%B8%8E%E5%95%86%E4%B8%9A%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC YOUNG科教风向&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;香港大学、香港城市大学、香港理工大学的副校长级科学领袖聚首&lt;strong&gt;“校长圆桌”&lt;/strong&gt;，不仅剖析了教育评价体系、产学研脱节等瓶颈，更就深化粤港澳大湾区融合、构建“研究‑产业”并发式合作网络提出具体路径，为AI时代夯实科技根基提供了系统性思考与行动方向。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1d954436-ed50-4de2-a819-5f6729cba3fc/%E6%A0%A1%E9%95%BF%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;聚焦下一代的&lt;strong&gt;“青年观察家”&lt;/strong&gt;跨界对话中，宇宙学者、艺术家、教育者与生态构建者们从星际尺度、艺术本质、幼儿教育到文明价值等多重维度展开思辨，探讨AI作为“新生命形式”与人类在演化节奏、创造主体及价值定义上的根本性碰撞。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c4bcc467-c56d-4327-b3a8-22e52521758c/%E9%9D%92%E5%B9%B4%E8%A7%82%E5%AF%9F%E5%AE%B6.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC FUTURE TECH赛道机遇&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;穹彻智能联合创始人，非夕机器人联合创始人，上海交通大学人工智能学院副院长、教授，上海创智学院副院长卢策吾&lt;/strong&gt;聚焦具身智能，提出“真实基础-想象拓展-下意识学习”，首创群众采集（RoboPocket）范式，构建“数字基因”世界模型，强调力-位全信息融合，以突破Scaling Law困境。&lt;img src="https://image.jiqizhixin.com/uploads/editor/4d8560db-b30a-49f4-bc1c-6ab6b294123d/%E5%8D%A2%E7%AD%96%E5%90%BE.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“量子圆桌”&lt;/strong&gt;邀请“祖冲之号”量子计算总师朱晓波在内的多位技术路线代表与产业观察者同台交锋，话题涉及量子计算与AI的融合、不同技术路线的竞争与前景，以及量子计算从“优越性”到“实用性”的跨越，呈现了一场兼具前瞻性、批判性与建设性的前沿科技对话。&lt;img src="https://image.jiqizhixin.com/uploads/editor/88bad16b-b665-4218-a5cf-eaa010423fc9/%E9%87%8F%E5%AD%90%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AI GRAVITY链接全球&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;猎豹移动董事长兼CEO，猎户星空董事长傅盛&lt;/strong&gt;以自身“AI化”转型为实证，提出“一把手示范、全员革命、工具落地”的企业变革三部曲，用生动案例展现了一家老牌公司如何以All in姿态拥抱AI。&lt;img src="https://image.jiqizhixin.com/uploads/editor/102abbab-2880-4a92-8102-6db5a3237d8b/%E5%82%85%E7%9B%9B.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“出海战略圆桌”&lt;/strong&gt;汇集了基础模型、汽车金融、工业互联网、智慧物流领域的出海实践者，携同大湾区资源代表香港投推署与生产力促进局，积极探索通过技术赋能、生态合作与平台协同，实现从单点出海到体系化“舰队式”发展的升级路径。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b50e86b0-bcdd-4a3e-b636-42f509caf483/%E5%87%BA%E6%B5%B7%E6%88%98%E7%95%A5%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;夜晚场【灵感迸发】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;打破圈层，激发“灵感迸发”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当维港的灯火亮起，这场持续全天的思想盛宴在夜晚场达到另一种形态的高潮。&lt;/p&gt;&lt;p&gt;WAIC五大生态品牌领衔的&lt;strong&gt;Free Talk Zone&lt;/strong&gt;提供无缝交流局，让最有价值的资源、机会与灵感在非正式对谈中自然流动。&lt;strong&gt;知乎创作者、WAYtoAGI和RTE开发者社区极客、BIM青年科学家、AI头部科技博主&lt;/strong&gt;与白天登台的大咖平等对话。&lt;strong&gt;史蒂夫·霍夫曼（Steve Hoffman）&lt;/strong&gt;带来一场“模拟人生：AI缔造的未来”特别互动演讲。&lt;strong&gt;加州大学伯克利VIVE增强现实中心创始执行主任杨安（Dr. Allen Yang）&lt;/strong&gt;首次现场揭秘Physical AI的真正野心。&lt;strong&gt;香港立法会议员、港区全国政协委员、优家健康创始人和埔思学院院长&lt;/strong&gt;深入“重构生命、财富与记忆”等终极议题。&lt;strong&gt;香港城市大学&lt;/strong&gt;的&lt;strong&gt;“Tech300”菁英汇&lt;/strong&gt;为当晚注入最鲜活的创新动能。创新因子在跨代际碰撞中集中涌现。&lt;img src="https://image.jiqizhixin.com/uploads/editor/0c0ee754-27ba-40a3-939d-428bdb99fbf9/%E5%A4%9C%E5%9C%BA.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从1956年达特茅斯会议到2026“WAIC UP!全球年终盛会”，AI对话正从纯技术思辨走向“技术-产业-人文”的融合共创。&lt;/p&gt;&lt;p&gt;香港的意义，远不止资本与技术的枢纽。这座东西方文明交汇的城市，为AI注入了独特的价值维度——在这里，效率与温度并存，创新与传统对话，全球视野与本土智慧交融。WAIC选择香港作为年终思想的收官之地，正是因为这片土地能孕育出不同于硅谷的AI文明形态。&lt;/p&gt;&lt;p&gt;“WAIC UP!全球年终盛会”既是对过往技术长征的致敬，更是开启“人类与机器智能对话”的新序章。当思想从彼岸到此岸，当创新从精英走向大众，一个更加多元、包容、可持续的AI未来，正在东方初现曙光。&lt;img src="https://image.jiqizhixin.com/uploads/editor/95133668-965d-4c47-b37b-3cb8b823c84d/_6014826-opq3014263146.jpg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于WAIC和WAIC UP!&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;世界人工智能大会（WAIC）是全球人工智能领域的顶级盛会，已成功举办八届，致力于探索AI技术前沿并推动该领域的创新发展。自创办以来，大会已汇聚了来自全球的8,100多位顶尖科学家、专家、企业家投资者及行业领袖，共同交流思想、分享突破性成果并探索合作机遇。&lt;/p&gt;&lt;p&gt;2024年12月，WAIC首份刊物《WAIC UP!》正式问世，它是AI时代的进化指南，更是WAIC精神的延伸。在数字化的浪潮中，信息的碎片化、同质化、孤岛化，让我们渴望深度与连接。创办《WAIC UP!》的初衷正是为了解决这一时代难题。我们想创建的也正是这样一个多元发声阵地、智慧共鸣窗口和思想启发工具。WAIC UP! WAKE UP MORE! 旨在唤醒更多人，探究关乎技术跃迁自我边界和未来文明的无限可能。&lt;img src="https://image.jiqizhixin.com/uploads/editor/59cf355c-c198-47f7-960c-eab34a5edcbe/WAIC_UP_%E5%85%A8%E7%90%83%E5%B9%B4%E7%BB%88%E7%9B%9B%E4%BC%9A%E5%90%88%E4%BD%9C%E4%BC%99%E4%BC%B4.jpg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>“扣子”官宣2.0品牌升级：AI办公、AI创作全面更新，新增视频创作能力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 10:23:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1月19日，字节跳动旗下AI Agent平台&amp;ldquo;扣子&amp;rdquo;宣布2.0品牌升级。&lt;/p&gt;&lt;p&gt;扣子诞生于2024年2月，最初定位是新一代AI Agent平台。基于服务超1000万真实开发场景的经验，扣子2.0进行了全局重构，定位和使命是帮助更多的职场人。&lt;/p&gt;&lt;p&gt;扣子2.0集成了Agent Skill、Agent Plan、Agent Coding、Agent Office能力，让AI 真正成为用户的&amp;ldquo;工作伙伴&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/04bb453e-9e49-4fdd-b965-1c9138e9ba37/%E5%9B%BE%E7%89%871.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Skills：装上行业技能包，让通用AI变得更专业&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通用Agent已展现出强大的基础任务处理能力，在日常对话、信息整合与简单推理方面有了长足进步，但要应对高度专业化、高精度或高可控要求的复杂场景，仍需特定技能的增强。&lt;/p&gt;&lt;p&gt;通过封装领域知识、标准化操作流程或集成专用工具，&amp;ldquo;技能&amp;rdquo;（Skills）能够将通用AI的认知能力与特定任务需求相结合，更贴合实际应用场景中多元化、高标准的任务要求，保证输出稳定性。&lt;/p&gt;&lt;p&gt;扣子2.0推出的Agent Skills，本质上是「场景最佳实践 + 所需工具」的封装，旨在帮助更多用户调用专业技能，定向增强解决复杂专业问题的能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/3a04368a-21d1-493f-ae3c-13955ab7449e/%E5%9B%BE%E7%89%872.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在全新推出的技能商店中，用户可以浏览、选择并一键安装使用由扣子官方及优质开发者创建的各类专项技能模块，包括但不限于&amp;ldquo;新年绘本&amp;rdquo;&amp;ldquo;互动教学&amp;rdquo;&amp;ldquo;投资知识库&amp;rdquo;&amp;ldquo;法律类案检索&amp;rdquo;等。扣子可根据任务场景，智能调用或组合多个已安装技能，让Agent Skills提供综合性解决方案。技能库会持续更新，确保用户总能获取最前沿、最实用的能力支持。此外，用户可利用扣子提供的工具，为自己量身定制私有技能，还可以将个人经验沉淀封装为可复用的模块。&lt;/p&gt;&lt;p&gt;在Coze Skills生态中，行业专家能够把经验沉淀为&amp;ldquo;可出售的技能&amp;rdquo;，提升专业影响力；特定领域的新人即使没有行业经验，也可以一键使用他人的方法论。对于企业来说，团队能够共享专业标准作业程序（SOP）和最佳实践，新成员也能迅速掌握熟练员工的能力。&lt;/p&gt;&lt;p&gt;此外，扣子官方视频Skill也正式上线，该功能支持自动生成视频脚本、匹配视觉素材，并完成剪辑、转场、配乐等后续流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Plan：从&amp;ldquo;即时问答&amp;rdquo;到&amp;ldquo;长期计划&amp;rdquo;，AI持续执行并主动汇报&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;习惯使用AI产品提效的用户，需要的不只是即时解答问题的工具，更是一个能够理解长期目标、适应个人成长节奏、提供持续支持的智慧伙伴。&lt;/p&gt;&lt;p&gt;扣子2.0推出了Agent Plan，即&amp;ldquo;长期计划&amp;rdquo;，让AI从&amp;ldquo;即时问答工具&amp;rdquo;升级为&amp;ldquo;可持续运作的智能体&amp;rdquo;。用户只需要确定目标，规定好怎么完成、怎么实现，扣子能够持续执行，并向用户主动汇报、最终交付任务。&lt;br&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f5f1a150-e9b0-43ff-a2dd-08b7173af6d2/%E5%9B%BE%E7%89%873.png" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;长期计划实现了复杂目标的闭环管理，Agent将一个需要数小时、数天甚至更长时间才能完成的宏观目标（如&amp;ldquo;一款市场竞品分析报告&amp;rdquo;）分解为多个步骤，并持续追踪进度、管理中间状态，直至最终交付成果。这打破了传统单轮交互的局限。在执行长期任务过程中，Agent可以积累上下文信息、记忆用户偏好、总结历史经验，并动态调整后续策略。例如在长期客户服务场景中，它能基于过往互动提供越来越个性化的支持。&lt;img src="https://image.jiqizhixin.com/uploads/editor/43138986-07b1-4544-ac7b-e2984956c35a/%E5%9B%BE%E7%89%874.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;以自媒体账号运营为例，扣子能够和用户一起讨论账号定位，拆解每个阶段的运营策略，再帮用户创作内容。如果用户想写一本书，只需把写作主题和目标发给扣子，它会自己搜集资料、撰写初稿，再根据反馈自行调整，达成3周内写出10万字初稿的计划。用户还可以用长期计划来完成学习目标，比如考雅思，扣子会设定每日任务并准备学习资料。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Office：深度理解职场场景，AI办公、AI创作能力全新升级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AI通常能够针对用户的提问给到标准答案，但在真实的职场问题中，答案并不是模板化的。AI 只有理解具体场景，才能提供针对性解决方案。&lt;/p&gt;&lt;p&gt;扣子2.0面向职场类任务做了更多优化，写战略报告Word、做分析PPT、梳理数据Excel，都可以交给扣子来处理。&lt;/p&gt;&lt;p&gt;具体来说，扣子2.0增强了深度上下文理解能力，能够为用户提供洞察。用户不需要一次性把所有背景信息塞进去，扣子会通过多轮对话，逐步理解具体情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Coding：扣子编程，全栈式 Vibe Coding 开发平台&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近日，扣子开发平台正式升级为扣子编程。&lt;/p&gt;&lt;p&gt;作为一站式云端 Vibe Coding 开发平台，扣子编程实现了Vibe Agent、Vibe Workflow、Vibe Web、Vibe App几大核心功能开箱即用，用户通过连续对话，即可轻松构建智能体、工作流、网站、移动应用等，并提供 Vibe Infra 基础设施，实现一键部署上线。&lt;/p&gt;&lt;p&gt;在扣子编程平台，Agent能够自己写提示词、装知识库、开发工具，能在多轮对话过程中自我迭代。基于Vibe Workflow功能，用户彻底告别手动拖拽节点，只需要描述清楚需求即可创建工作流，还能够分节点进行调试和修改，让Vibe Coding更可控、更稳定，更好地支撑复杂业务需求。基于Vibe App功能，用户仅需输入自然语言指令即可打造一个跨端的全栈应用，扣子可以生成适配的界面和逻辑，并自动完成多端适配，帮你集成所需的组件，包括AI能力、数据库等等。&lt;/p&gt;&lt;p&gt;结合火山引擎在云计算领域强大的基础设施，扣子编程上线了Vibe Infra的能力，提供众多适合Vibe Coding用户的基础设施服务，包含服务器的资源分配、应用的版本部署，域名备案配置以及iOS和安卓的版本发布。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
