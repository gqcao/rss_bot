<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>产研协同 智启未来：科学智能“百团百项”工程产研共创沙龙在沪顺利举行</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 15:19:06 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;2026年2月3日，由上海仪电（集团）有限公司主办，上海市先导产业促进中心、上海埃迪希科技服务有限公司承办的科学智能&amp;ldquo;百团百项&amp;rdquo;工程产研共创沙龙在沪圆满落幕。&lt;strong&gt;上海仪电（集团）有限公司副总裁刘山泉、上海市经济和信息化委员会人工智能发展处处长刘文、上海市先导产业促进中心主任郑理莹&lt;/strong&gt;出席会议，共话AI4S新范式，共谋产业高质量发展新篇章。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3323f33e-14b9-4e0b-b23a-680932b5ac14/1770189343529.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;本次沙龙汇聚了来自学术界、产业界、投资界的50余位专家学者与企业代表。会议紧扣真实产业需求，旨在通过深度探索人工智能与科学研究的融合路径，推动前沿技术精准赋能实体产业转型升级，合力构筑开放、协同、高效的创新生态体系。&lt;/p&gt;&lt;p&gt;活动伊始，&lt;strong&gt;上海智能算力科技有限公司解决方案负责人王丽忱&lt;/strong&gt;向与会嘉宾系统介绍了&amp;ldquo;科学智能开放社区&amp;rdquo;。科学智能开放社区由上海仪电牵头承建，以统一门户整合一站式科研工具、高质量开源模型库、智能体开发平台以及万卡级公共算力在内的关键资源与服务，为全球科学家提供开放、协同、高效的科研创新平台，显著降低AI与科研融合的门槛，加速从基础研究到产业应用的转化周期。随后，&lt;strong&gt;上海人工智能实验室李玉强、上海科学智能研究院关慧宇、上海创智学院郑逸宁&lt;/strong&gt;分别介绍了面向科研领域的模型、智能体、工具的共性服务能力，共同为科学智能开放社区精准高效地连接产业难题与科研智慧，提供了坚实而灵活的技术支撑。&lt;/p&gt;&lt;p&gt;作为本次沙龙的重头戏，长达145分钟的&amp;ldquo;产研共创工作坊&amp;rdquo;将氛围推向高潮。与会嘉宾打破行业壁垒，围绕&amp;ldquo;百团百项&amp;rdquo;专项工程中&amp;ldquo;产业出题、科学家答题、人工智能解题&amp;rdquo;的闭环协同模式展开深度讨论。 由AI科学家、领域科学家、工程师及基金经理人组成的多维协同小组，针对化工物质、光刻胶、生物制造AI应用模型、生物制造AI4S创新驱动、量子计算、固态电池等六大战略性前沿领域的真实需求，&amp;ldquo;点对点&amp;rdquo;定义科学问题，&amp;ldquo;面对面&amp;rdquo;探讨路径可行性。现场形成的系列关键科学问题提案，为&amp;ldquo;百团百项&amp;rdquo;工程注入了强劲的创新动能。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/efb8e00f-b666-4a3d-8c45-a9132adec73f/1770189406551.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c306f2d5-a65f-410e-99b7-f8bb286ce36b/1770189412795.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a8c9e68a-9232-41dd-899e-295eed5d03c4/1770189421299.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7e0c5fca-b9a3-4aad-95f1-e65e09209cd9/1770189429834.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1c2871a2-66d6-47b8-a8f8-a7734474279f/1770189437215.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1e341b03-0d4b-4205-b267-330d77965cea/1770189444731.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;AI4S已成为引领新一轮科技革命、驱动产业源头创新的关键变量。本次沙龙的成功举办，不仅验证了以科学智能开放社区为枢纽的协同模式，更为跨领域协作提供了可复制、可推广的实战经验。 面向未来，科学智能开放社区将持续深化系列主题活动，依托平台全链条支持能力，推动优质项目从&amp;ldquo;实验室&amp;rdquo;走向&amp;ldquo;生产线&amp;rdquo;。社区将秉持开放合作理念，邀约更多产学研伙伴同频共振，共同破解关键&amp;ldquo;卡脖子&amp;rdquo;难题，为产业智能化变革贡献澎湃动力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>ICLR 2026 | U2-BENCH：首个超大规模全场景超声多模态理解基准，开启医疗大模型新赛道</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 14:32:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;h3&gt;&lt;strong&gt;1. 医疗AI的深水区：从通用视觉到超声专业理解&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;超声成像（Ultrasound）作为全球医疗中应用最广泛的影像手段之一，在妇产科、急诊及心脏病学等场景中具有不可替代的地位。然而，与 CT / MRI 等模态相比，超声影像的自动理解长期面临更高门槛：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;操作依赖性强&lt;/strong&gt;：超声影像受操作者手法影响，质量波动大、伪影多 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;空间关系复杂&lt;/strong&gt;：不同于 CT/MRI 的静态切片，超声呈现的是动态的、具有强空间上下文关系的结构 。&lt;strong&gt;评测体系缺失&lt;/strong&gt;：虽然通用视觉大模型（LVLMs）如 GPT-4V、Gemini 表现惊人，其在超声这一高专业度场景下的能力，长期缺乏系统、可复现的评估体系。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在此背景下，U2-BENCH 被提出，作为首个系统性评估LVLMs在超声领域能力的深度基准，涵盖了分类、检测、回归及文本生成四大任务维度。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/637f6159-1d11-47fe-a7da-83291f607f36/1770186374225.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;2. 核心&lt;/strong&gt;&lt;strong&gt;设计&lt;/strong&gt;&lt;strong&gt;：全谱系解剖覆盖与临床启发式任务&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;U2-BENCH的核心价值在于其高度的临床相关性和严密的构建流程：&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;2.1&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;超大规模、多来源的真实临床数据&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;广度覆盖&lt;/strong&gt;：汇集了来自 40 个授权数据集的 &lt;strong&gt;7,241 个案例&lt;/strong&gt;，跨越 &lt;strong&gt;15 个解剖区域&lt;/strong&gt;（如胎儿、心脏、乳腺、甲状腺等） 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;深度场景&lt;/strong&gt;：涵盖 &lt;strong&gt;50 个临床应用场景&lt;/strong&gt;，确保了评估结果能真实反映模型在医疗一线的能力 。&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;&lt;strong&gt;2.2&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;四级能力分解&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;strong&gt;八项临床任务&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;U2-BENCH 将“超声理解”拆解为四个能力层级、八项具体任务：&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;分类任务&lt;/strong&gt;：疾病诊断（DD）、标准切面识别与质量评估（VRA） 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;检测任务&lt;/strong&gt;：病灶定位（LL）、器官检测（OD）、关键点检测（KD） 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;回归任务&lt;/strong&gt;：临床数值估计（CVE，如射血分数、脂肪肝百分比） 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;生成任务&lt;/strong&gt;：结构化报告生成（RG）、解剖描述生成（CG） 。&lt;/li&gt;&lt;li&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f83fc832-4d78-4b57-8907-8cc320fa6329/1770186397204.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;3. 实验验证：SOTA 模型的&lt;/strong&gt;&lt;strong&gt;能力&lt;/strong&gt;&lt;strong&gt;边界&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;U2-BENCH上系统评测了&lt;strong&gt;23个&lt;/strong&gt;&lt;strong&gt;领先&lt;/strong&gt;视觉语言模型（包括 GPT-5, Gemini 2.5, Dolphin-V1 等）进行了大规模评测：&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;3.1 闭源模型依然领先，但仍有巨大空间&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;榜首表现&lt;/strong&gt;：Dolphin-V1 以 &lt;strong&gt;0.5835&lt;/strong&gt;的总分（U2-Score）位列第一，大幅领先于 GPT-5（0.3250）和 Gemini-2.5-Pro（0.2968） 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;开源对比&lt;/strong&gt;：开源模型中 DeepSeek-VL2 表现最强，但在复杂推理上与闭源顶尖模型仍有代差 。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8154111-f637-4dac-97db-a612493da226/1770186406655.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;3.2 任务难度的代差：识别容易，推理极难&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;分类 vs. 空间推理&lt;/strong&gt;：模型在疾病诊断（DD）等图像级分类上表现尚可，但在空间位置相关的检测（KD/OD）和回归（CVE）任务上表现堪忧 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;报告生成的挑战&lt;/strong&gt;：模型生成的语言质量虽然不错，但在医疗准确性和结构化合规性（RG）上仍存在严重缺陷 。&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;&lt;strong&gt;3.3 关键结论：规模不是唯一解&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;缩放定律的平台期&lt;/strong&gt;：在 Qwen 家族的对比中发现，模型参数量从 3B 到 72B 带来了稳步提升，但在某些空间推理任务上提升并不显著，暗示了&lt;strong&gt;超声专项训练&lt;/strong&gt;比单纯扩大参数更有效 。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/db965ffd-2daf-4862-a8c4-108d3cd21443/1770186427939.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;4. 总结与展望&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;U2-BENCH 的建立表明超声 AI 正在从“单一任务的小模型”转向“全能理解的大模型”。同时实验也揭示了当前 LVLMs 在空间推理和临床逻辑上的短板 。&lt;/p&gt;&lt;p&gt;未来，U2-BENCH&amp;nbsp;将扩展至：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;动态视频理解&lt;/strong&gt;：从单帧走向实时扫查序列 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;长程具身感知&lt;/strong&gt;：结合机械臂等硬件实现自动化、闭环的超声扫描与决策。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>突破RNA设计瓶颈，上智院联合复旦、上交提出全球首个强化学习与潜扩散融合框架SOLD</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Wed, 04 Feb 2026 14:25:23 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnA6AroNE959MTXRTunZ61XXLRee0gYSITrsoZwulFzX0NLS4ga2hrNibdHreZ9icQswrGIDqeD2A7g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.42407407407407405" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="100027374" data-aistatus="1" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/35be453b-449b-46d8-ae23-76f121b110b4/640.jpeg" data-sec-load-status="2" data-report-img-idx="0" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;作者丨上智院女娲生命大模型团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;在 RNA 疗法、基因调控和合成c等领域，RNA 逆折叠（RNA Inverse Folding）是至关重要的核心任务，其目标是设计出能够折叠成特定 3D 结构的 RNA 序列。如同设计一把能开启特定「基因锁」的钥匙，这要求生成的序列不仅在理论上符合要求，更需在物理上精准折叠成目标构象。&lt;/p&gt;&lt;p&gt;然而，面对复杂的 RNA 序列 - 结构相互作用，现有的深度学习方法尽管在序列恢复率上取得了一定进展，其局限仍非常明显：它们往往难以直接优化次级结构一致性（SS）、最小自由能（MFE）和局部距离差测试（LDDT）等关键的结构与功能指标，导致生成的序列在物理真实性和结构准确性上经常「次优」。此外，现有的基于强化学习的扩散模型优化方法，通常需要采样完整的扩散轨迹，计算成本极高，难以在 RNA 设计这种复杂任务中高效应用。&lt;/p&gt;&lt;p&gt;为此，上海科学智能研究院（下称上智院）与复旦大学、上海交通大学等联合提出了首个集成强化学习与潜扩散模型的 RNA 逆折叠框架（SOLD）。该框架从 RNA 的共进化模式出发，在预训练阶段引入&amp;nbsp;RNA-FM&amp;nbsp;嵌入，并在优化阶段通过创新的「分步式」（Step-wise）强化学习策略，实现了对非导向性结构目标的直接、高效优化。实验表明，该方法在多个权威指标上全面超越了现有的 SOTA 方法，为开发高精度、功能导向的 RNA 设计工具开辟了新路径。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmWG9lDvibcet4On5VLvVIOuhUMpxZIjSqcKsOZNukWs2n5YXtx13JxvDUhia9rOVyXqf1dY5mByCtA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.21203703703703702" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027354" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/5f628369-1d01-4717-b68b-926a88a8e43c/640.png" alt="图片" data-before-load-time="1770186270461" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="2 2 []"&gt;论文题目：Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model&lt;/p&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.19232&lt;/p&gt;&lt;p&gt;代码地址：&lt;/p&gt;&lt;p&gt;https://aistudio.ai4s.com.cn/galaxy-model/partner/galaxy-model-frontend/model/01301556&lt;/p&gt;&lt;p&gt;https://github.com/SAIS-LifeScience/SOLD&lt;/p&gt;&lt;p&gt;该研究成果已被 AAAI 2026 接收。上智院生命科学方向研究员斯奇、刘旭阳，上海交通大学生命科学系博士生王鹏磊，是共同第一作者。上智院首席科学家、复旦大学特聘教授漆远，是论文共同作者。上智院生命科学方向主任研究员郭昕，上智院生命科学方向负责人、复旦大学人工智能创新与产业研究院研究员程远，是共同通讯作者。&lt;/p&gt;&lt;p&gt;研究项目由星河启智科学智能开放平台（https://aistudio.ai4s.com.cn/）和复旦大学 CFFF 智算平台提供技术和算力支持。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;现有方法的两大局限&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既往的 RNA 逆折叠方法虽取得一定进展，但存在两个面向实际设计的关键短板：&lt;/p&gt;&lt;p&gt;一是难以处理非可微的结构目标。现有的深度学习方法（如 GrnaDe、RDesign）虽然提升了生成序列的质量，但它们大多无法直接优化如最小自由能（MFE）或 3D 结构相似度（LDDT）等「硬指标」。这些指标对于 RNA 是否能在真实生物环境中稳定发挥功能至关重要，但由于它们通常是不可微的，传统的梯度下降方法难以直接对其进行优化。这导致模型生成的序列往往「形似」而「神不似」，难以满足严格的物理约束。&lt;/p&gt;&lt;p&gt;二是传统强化学习优化效率低下。为了解决上述问题，强化学习（RL）被引入以优化这些离散目标。然而，现有的结合扩散模型与 RL 的方法（如 DDPO、DPOK），通常需要对扩散过程的完整轨迹进行采样才能更新策略 。在 RNA 设计的高维空间中，这种「全轨迹」采样的计算开销巨大，收敛速度极慢，且容易陷入局部最优，严重限制了其在大规模 RNA 设计任务中的应用潜力。&lt;/p&gt;&lt;p&gt;为解决这些问题，研究团队提出了&amp;nbsp;SOLD (Step-wise Optimization of Latent Diffusion Model)&amp;nbsp;框架，通过引入预训练 RNA 语言模型嵌入和创新的分步优化策略，实现了从序列生成到底层物理属性优化的全流程突破。&lt;/p&gt;&lt;p&gt;SOLD 的双阶段创新设计&lt;/p&gt;&lt;p&gt;SOLD 框架包含潜扩散模型（LDM）预训练和强化学习微调两个阶段，分别对应基础表征构建与结构目标精修，形成完整的技术闭环。&lt;/p&gt;&lt;p&gt;1、LDM 预训练：融合共进化信息。SOLD 首先构建了一个强大的潜扩散模型（LDM）底座。不同于以往直接在序列空间操作的方法，SOLD 利用预训练的 RNA-FM 提取包含丰富共进化信息的嵌入表示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmWG9lDvibcet4On5VLvVIOuMVwrFnuC38xfFMq5yyH8N95aVMgvib0EtIlCiamttLCPpCv0kt0qIazA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.34593572778827975" data-s="300,640" data-type="png" data-w="1058" type="block" data-imgfileid="100027355" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/70745587-d204-45e0-94fd-9a2783e6c0ad/640.png" alt="图片" data-before-load-time="1770186271376" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;潜空间建模：通过编码器将 RNA-FM 的高维嵌入压缩至高效的潜空间，结合 GVP-GNN 提取骨架几何特征，使模型在生成之初就具备了对 RNA 序列 - 结构复杂依赖关系的深刻理解。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;序列恢复提升：仅依靠这一阶段，LDM 在序列恢复率和核苷酸恢复率上即已超越了包括 RiboDiffusion 在内的多种现有方法，为后续优化打下坚实基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2、Step-wise RL 微调：分步式高效优化。微调阶段是 SOLD 的核心创新。团队提出了一种单步式（Step-wise）强化学习算法，直接针对复杂的结构指标进行优化。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmWG9lDvibcet4On5VLvVIOulxpapy4DLlFAicJzJzsPZmupklOJD4xia9sdon8xm0geh4J8hfQp7O9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027356" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/31edb1b8-b871-4579-ba2b-2cb0edb9afe1/640.png" alt="图片" data-before-load-time="1770186271439" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;单步采样策略：受 DDIM 启发，SOLD 无需采样完整轨迹，而是从任意噪声时间步直接预测去噪后的潜变量。这意味着模型可以在极短的时间内获得反馈，大幅提升了训练效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;长短期奖励融合：为了平衡训练的稳定性与准确性，SOLD 设计了分段奖励函数。在噪声较大的早期阶段，使用短期奖励引导方向；在噪声较小的后期阶段，使用长期奖励精确对齐目标。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;直接指标优化: &amp;nbsp;SOLD 直接集成了 ViennaRNA 和 RhoFold 作为奖励函数，直接优化 SS、MFE 和 LDDT 等物理指标，无需额外训练可能引入误差的代理奖励模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在现有 RNA 结构测试集上超越现有最优方法&lt;/p&gt;&lt;p&gt;本研究在现有 RNA 结构数据集上进行了系统评估，结果全面超越了现有最优方法。具体而言，在多目标联合优化实验中，SOLD 不仅保持了极高的序列自然度（Sequence Recovery），更在结构指标上实现了质的飞跃。例如，在 CASP15 测试集上，SOLD 生成的序列在&amp;nbsp;SS（次级结构一致性）&amp;nbsp;上达到 0.6957，远超 RiboDiffusion 的 0.4699；在&amp;nbsp;MFE（最小自由能）&amp;nbsp;上达到 - 64.0375，显著优于基线模型，证明了其设计出的 RNA 具有更高的热力学稳定性。此外，在训练效率方面，得益于单步优化策略，SOLD 完成一轮 MFE 优化仅需 256 秒，而同类方法 DDPO 和 DPOK 分别需要 5953 秒和 7677 秒，训练速度提升了&amp;nbsp;20 倍以上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实际案例验证与模块有效性&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmWG9lDvibcet4On5VLvVIOu7uUc17zC5eCtUxnsM862yRIia1w8MicNZnGPJmibCSSerpCj6DTEq1WcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2912801484230056" data-s="300,640" data-type="png" data-w="1078" type="block" data-imgfileid="100027357" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/73561035-683f-46ff-a68a-150b897cffe2/640.png" alt="图片" data-before-load-time="1770186272175" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了验证 SOLD 在真实生物场景中的应用潜力，研究团队对&amp;nbsp;TPP 核糖开关进行了案例研究。结果显示，SOLD 成功设计出了能精准折叠成目标构象的序列（RMSD 仅为 2.8157&amp;Aring;，LDDT 高达 0.6171），而其他对比方法（如 RhoDesign、RiboDiffusion）生成的序列折叠结构严重偏离目标，甚至完全解体。这一结果有力证明了 SOLD 在处理复杂生物学约束时的卓越能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SOLD 的成功，在于其巧妙地结合了预训练大模型的表征能力与强化学习的策略优化能力。首先，模型利用 RNA-FM 捕捉深层的共进化模式，解决了传统方法「只见树木不见森林」的问题。其次，创新的单步式 RL 策略攻克了非可微目标优化的效率瓶颈，使得直接针对物理属性（如自由能、结构偏差）进行设计成为可能。这种模块化、工具无关的框架设计，使得未来可以无缝集成更先进的奖励评估工具。&lt;/p&gt;&lt;p&gt;该研究不仅为 RNA 逆折叠任务确立了新的 SOTA 基准，也印证了 AI 驱动生物设计的发展方向 &amp;mdash; 通过高效的算法创新，跨越从「生成序列」到「设计功能」的鸿沟。展望未来，研究团队计划进一步扩展高质量 RNA 结构数据集，并探索多尺度指标的协同优化，从而为 RNA 疗法及合成生物学的落地持续注入新动力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>倒反天罡：「租个人」网站爆火，AI开始雇人「跑腿」了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 12:50:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜张倩&lt;/section&gt;&lt;p&gt;人给 AI 打工的一天，居然这么快就来了。&lt;/p&gt;&lt;p&gt;最近，一个名叫「rentahuman.ai」的网站上线了，它被定位为「AI 的肉身层」。众所周知，AI 没有身体，虽然机器人已经在开发了，但现阶段还不太好用。因此，在一些需要身体的场合，比如取货送货、活动签到、实地勘察、餐厅试吃、参加线下会议，AI 就得找个人替自己跑一趟，这就是网站的设计初衷。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBol4vXPQypuwl9CwDAeb7dXpIOIvIxbXicYoLQV1ia2RibxmzbOMj8AZZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531518" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/337fd114-cb77-4e48-9482-37156e7c7d8f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;通过 MCP 协议或 REST API，AI 可以像调用工具一样搜索、预订并雇佣人类来完成线下任务 。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531519" data-ratio="0.31574074074074077" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SB079icic1QYNaAXgdmm7VqurhT156I3A2iaNCHibT1YfMGUckdaeaxSib8ug/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d2ad57c6-6daf-45d8-b9d3-3fee33d04c71/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;支持的智能体类型如下：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531557" data-ratio="0.325" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBupQNJIcrO1ALq5QnJoTfOIa9HMNyyVyMtp8Ly8YLI0EAiaeP0AaJ7pg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/fffe9440-1e26-4bef-8c20-bedcc5627e95/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据网站开发者 @AlexanderTw33ts 透露，网站上线第一晚就有超过 130 人报名参加，其中还包括人工智能初创公司的创始人和首席执行官。而在上线不到 48 个小时的时间里，可用的人类劳动力就突破了 1 万，现在更是超过了 2 万。当然，这里面可能大部分都是看热闹的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBVibQ59GwRgSAj8Dmgnj2kZP2GEumMXH2jkFdx0npYd31lrDJsMAWYaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.076851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531522" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/afbc23cf-da6f-4ef7-95a8-862d153e82c1/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对于注册成为「跑腿」的人类来说，网站的规则也比较友好，允许人类自己设置时薪，还不需要闲聊。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBOTV8UnqFiacZiaedFuxsldLtx3nLN7QfyElQTWDP7BnQNAz3Y4N4C4qQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.34629629629629627" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531524" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/c44c8b04-6f66-4925-87a5-09e9a1df915e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SB3eyC0JgdCDlLVaymjBhjeq9iayA8icEhOibfsEvwZ5aTNIziciaia4cdxnyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531525" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b2ef0a14-79cc-41c2-805b-161b22e6b597/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在网站上，我们可以看到所有可用人力的列表。他们来自世界各地的不同国家，设定的时薪从十几美元到几十美元不等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBXjiaeEc9m0WyBWkSen8qelhlNUcSweiaBVVarN0wk8fqa6ROk3mTexgw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.1537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531526" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/01268050-bc30-4d65-8c2d-ea31801fd237/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;点开人物资料卡片，我们可以看到某个人类的具体信息，比如定位、服务半径等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBVv5n0NkNpia4taTuWdpyCK0sib8AnFWbsEXPUNUN7MeegicU8iaTzJrnZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.087962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531528" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b0967ead-3387-4a45-a068-89943d823781/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从网站上，我们还可以看到一些已经发布的任务，比如拍一张人工智能永远看不到的照片、试吃新餐厅、从市中心的美国邮政局领取包裹、检查 API_Keys&amp;hellip;&amp;hellip; 被雇佣检查 API_Keys 的人类感慨地说：这个时代太诡异了，人类居然成了智能体的副驾。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBe2QiaPRdlnp4T8U2xA9bgico8fBib9X2d9FzNkgcN5AZTcexy1MgPRWaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5305555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531530" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c3d3dbb6-1d5c-4008-9644-73d2ab762d4f/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然，也有一些比较抽象的任务，比如举牌子，牌子上写着「AI 付钱让我举这个牌子」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SB9ajCxyFBTHUVOSHHRScAurtRm72P6mYlfU4oRLFojhjjek5MOEX7bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="1.1268518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531531" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/ba5c5fe6-d38d-46a2-9e63-22363880fb81/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这个网站让我们再次看到了 MCP 的价值。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBYMicEAfKVABIrKuFE2xHrMP6zlw7uxvOZXmLVFbiaX9HKaJK7y2YibjDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.3685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531533" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/e50f9bd0-bdfd-4ce2-b034-2d30dc7dc027/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但是，该网站的出现也引发了一些疑问，比如智能体要怎么付钱？目前发布任务的到底是智能体还是背后的人类金主？这是不是继 Moltbook 之后的另一场炒作？&lt;/p&gt;&lt;p&gt;还有个问题更有意思：AI 要怎么确认人类保质保量地完成了工作？就比如举牌子那个任务，用 AI 生成一张图片交差，是不是也能拿到钱？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBJOT15GVjs9IVBFjibdQxWzVV63SibSBTO8lZVZb8Qrx28bkSSbC59ocw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.32037037037037036" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531535" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c7ab5f56-7cff-4189-a85a-87b6b0a20bd2/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBTdMibaWdmsuU5uic8kUM7iaM7LO8DZOxvZJht4g33rOWVmOuEfnKicQPnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.9555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531536" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/00d98644-024e-4218-9064-c3b150a846d7/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBdfDWPaOKYpw0cRA9dVGoSTNpdyapBcw0MByvFAO5GIichUdRns0FYrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.35555555555555557" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531537" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/dfc9f7d0-4528-43cd-bfaf-d880b81eb270/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;难不成，还得再雇另一个人来检查这个人的工作？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBqXoa3I4MPy1WVUl9XAg04InCRpsJNnXvxrPajaZ4bMXxl4ftm1Bg4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.3527777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531538" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/2de6e1dd-0c82-40e7-ae37-55c442025c00/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这也让人对网站上任务的真实性产生了怀疑。毕竟，大家都刚刚经历过Moltbook的炒作，上面充斥着人类操控，社交媒体上也充斥着关于&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; line-height: 1.75em; margin-bottom: 0px; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Moltbook网站的&lt;/span&gt;虚假截图等信息。&lt;/p&gt;&lt;p&gt;除了这些，还有人从中看到了一些安全、伦理问题。&lt;/p&gt;&lt;p&gt;首要且最集中的关切在于责任与法律盲区。当 AI 智能体发出指令、支付报酬并驱动人类在现实世界中行动时，一旦出现差错，责任链条将变得异常模糊 &amp;mdash;&amp;mdash; 是平台、AI 所有者，还是人类执行者该负责？这种「问责空白」是传统雇佣关系中不存在的。&lt;/p&gt;&lt;p&gt;更令人不安的是，人类执行者往往只能窥见任务的一小部分，对 AI 的完整意图、数据的最终用途乃至行为的道德边界一无所知，这在设计上就构成了「合理的推诿」，难以经受法律审视。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBjlHjnkFatZibBazdFicx4pFs4mPVS8Qnfmn4icNmRzpibk9fZIctUlUQpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="1.9169054441260744" data-s="300,640" data-type="png" data-w="698" type="block" data-imgfileid="503531539" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/cb7d2fc2-73dc-43f6-a122-c91781b844e4/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，这个网站将如何演进？我们拭目以待。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>从斑马鱼到机器鱼：机器人实验重塑神经行为研究</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 12:47:10 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/952d91eb-f0ad-4b57-b66b-1b58b2ec74fe/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当大多数人仍聚焦于让机器人承担端茶倒水等家务时，来自瑞士联邦理工学院（洛桑，EPFL）、美国杜克大学与葡萄牙高等理工大学的联合团队，已率先&lt;strong&gt;运用机器人部分替代动物开展生理学实验&lt;/strong&gt;，旨在深入探究动物神经网络对各类智能行为的调控机制。&lt;/p&gt;&lt;p&gt;他们的最新研究成果 &amp;mdash;&amp;mdash; 题为《机器鱼连续与间歇游泳的能效与神经控制（Energy Efficiency and Neural Control of Continuous versus Intermittent Swimming in a Fish-like Robot）》的论文，已发表于顶刊《科学・机器人（Science Robotics）》2026年1月号（图 1）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGNHKNbtLBMYg6WdIN1YtaU5MthJYfEQU9jvH1YDHUcJehvmjhnOVbGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5661538461538461" data-s="300,640" data-type="png" data-w="650" type="block" data-imgfileid="503531303" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/03c0a6ba-a093-46bf-9c6d-16153944f644/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml5yc8hg18m2" data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图1. 科学&amp;middot; 机器人（Science Robotics）网站截图&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml5ybhag1qyl" data-pm-slice="0 0 []"&gt;论文标题：Energy Efficiency and Neural Control of Continuous versus Intermittent Swimming in a Fish-like Robot.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，去年 10 月，该团队另一项通过机器鱼仿真研究斑马鱼视觉运动反应（optomotor response）的成果《人工具身神经网络揭示脊椎动物视觉运动行为的神经架构（Artificial embodied circuits uncover neural architectures of vertebrate visuomotor behaviors）》，也发表于该期刊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span data-mpa-action-id="ml5y8k0h9bf" data-pm-slice="0 0 []"&gt;斑马鱼，越来越受关注的实验室模式动物&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与小白鼠类似，斑马鱼是近年来备受科学领域关注的模式生物（图 2B）。其幼鱼（larval zebrafish）凭借身体透明、繁殖能力强等优势，成为观测神经元活动与行为实时关联的理想活体模型。&lt;/p&gt;&lt;p&gt;论文第一作者Xiangxiao Liu（刘祥骁）在研究中指出：受技术限制，当前及未来相当长一段时间内，科研人员仍无法在活体斑马鱼幼鱼活动状态下，对其神经回路进行精准的创建、改造与观测；同时，动物实验中难以精准调控动物行为以契合实验需求。&lt;/p&gt;&lt;p&gt;仿生机器人实验恰好填补了这一空白：研究者可通过编程构建斑马鱼神经网络模型，对模型进行改造与对比分析，&lt;strong&gt;从而在可控环境中精准验证神经环路与运动表现的因果关系&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;此外，在机器鱼（图 2A、图 2C）或机器鱼仿真（数字孪生）系统中开展实验，不仅完全不受伦理约束，且成本远低于传统动物实验。这种 &amp;ldquo;活体实验难以实现，机器人实验高效可行且优势显著&amp;rdquo; 的特点，正推动神经科学从相关性观察向机制性解析跨越。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG9DibibniaIjdp8WHHWSqIx0pXicq3qWwzI8LuaMYLkbpAyYUhaO6tJyteQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.49095022624434387" data-s="300,640" data-type="png" data-w="884" type="block" data-imgfileid="503531316" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f99ad2d0-01f5-4af4-9ba6-a2a32c21c0af/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;图2. A和C： 仿斑马鱼机器鱼ZBot（larval zebrafish inspired robot）照片；B:斑马鱼幼鱼（larval zebrafish）照片（Guillaume Valentin, EPFL提供）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;中枢模式发生器（CPGs）+&amp;nbsp;动作门（bout gate）&amp;rdquo;：&lt;/strong&gt;&lt;strong&gt;驱动仿斑马鱼间歇性游泳&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;运动能力是动物多数行为（如捕食、避险等）的基础，因此探究动物行为的前提是解析其运动机制。EPFL 机器人团队与杜克大学生物团队携手合作，基于斑马鱼神经网络的相关研究成果，构建了一套&lt;strong&gt;以中枢模式发生器（central pattern generators, CPGs）+ 动作门（bout gate）&lt;/strong&gt;为核心的斑马鱼幼鱼间歇性游泳模型。&lt;/p&gt;&lt;p&gt;同时，EPFL 团队研发了模仿斑马鱼幼鱼形态的机器鱼 ZBot（larval zebrafish inspired robot）。该模型驱动的 ZBot 不仅能精准复现斑马鱼幼鱼的 &amp;ldquo;慢速直行 2（slow 2，视频1）&amp;rdquo; 与 &amp;ldquo;常规转向（routine turn）&amp;rdquo; 游泳行为（图 3），更令人惊喜的是，通过调节运动神经元（motor neuron）输出增益等参数，还可模拟出 J 型转向（J-turn）、接近游泳（approach swim）等多种游泳步态。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGxlicrpIOkzbiagEohQ82RBfUWWWmm0wuZicDKXMU1Wl0ZfXs95fyVxWdQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.2212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531317" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/871f5893-62a2-4030-a8fd-2ae6739c1a96/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;图3. 机器鱼ZBot复现斑马鱼幼鱼的游泳表现。&lt;a href="https://mp.weixin.qq.com/s/6EfNEH0qtvzE4G-nxyCgPg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0224393b-08cf-4927-b4b8-ea937e465a83/1770180291623.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频1. 机器鱼连续型游泳和间歇性游泳。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span data-mpa-action-id="ml5y7uf61c18" data-pm-slice="0 0 []"&gt;流体粘度影响运动位移，&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span data-mpa-action-id="ml5y7uf61c18" data-pm-slice="0 0 []"&gt;对转向功能几乎无干扰&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;水中生物体型差异极大，从体长可达 30 米的蓝鲸到仅 4 毫米的斑马鱼幼鱼，其游泳所处的流体力学环境截然不同。体型较大的鱼类游泳时雷诺数较高，惯性力起主导作用；而斑马鱼幼鱼等小型水生生物处于低雷诺数区间，黏性力占主导。&lt;/p&gt;&lt;p&gt;为厘清不同雷诺数下的运动机制差异，研究者利用 &amp;ldquo;雷诺数与特征长度成正比、与流体粘度（viscosity）成反比&amp;rdquo; 的物理原理，对 ZBot 在不同粘度流体环境中进行参数化测试，测试介质包括普通水（粘度 = 1）、中粘度流体（粘度 = 213.9 cP）及高粘度流体（粘度 = 457.0 cP）。&lt;/p&gt;&lt;p&gt;实验结果显示：&lt;strong&gt;随着流体粘度升高，ZBot 的推进效率显著下降&lt;/strong&gt;，在高粘度流体中的位移仅为普通水中的约三十分之一（视频2），但此时其运动轨迹与斑马鱼幼鱼在天然低雷诺数环境下的真实游动模式愈发贴近。&lt;/p&gt;&lt;p&gt;令人意外的是，高粘度流体（低雷诺数）对转向功能几乎无影响&amp;mdash;&amp;mdash; 例如，ZBot 在普通水中完成一次转向动作（turning bout）的转向角度约为 60 度，在高粘度流体中仍可达约 45 度。&lt;a href="https://mp.weixin.qq.com/s/6EfNEH0qtvzE4G-nxyCgPg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9319df32-cdd1-4060-ba43-fdef2cb06011/1770180313525.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频2. 流体粘度升高快速降低运动位移。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;间歇性运动被普遍认为能提升动物运动的能量效率，传统观点认为其核心原因是鱼类滑行时身体保持直线，可减小水的阻力。而该研究团队提出了全新猜想：间歇性游泳能使驱动器（或动物肌肉）始终处于更高效的工作区间，进而提升整体能效。&lt;/p&gt;&lt;p&gt;为验证这一猜想，研究人员首先对比了生物肌肉与实验所用伺服电机的&amp;ldquo;负载 - 效率&amp;rdquo; 特性，发现二者均呈现&lt;strong&gt;倒 U 型效率曲线&lt;/strong&gt; &amp;mdash;&amp;mdash; 中等负载时效率达到峰值，过载或轻载时效率则急剧下降；随后，通过测量电机负载状态并预测效率，证实 ZBot 在间歇性游泳模式下，以相同速度运动时，电机效率及综合能效均高于连续游泳模式。不过，受限于间歇性游泳的占空比（limited duty factor），其最大速度无法达到连续游泳模式的水平。这一现象在普通水及两种高粘度流体中均普遍存在。&lt;/p&gt;&lt;p&gt;该研究通过对机器鱼的系统性实验，巧妙借助&amp;ldquo;机器人实验&amp;rdquo; 相较于 &amp;ldquo;动物实验&amp;rdquo; 的独特优势，揭示了单纯依靠动物实验难以探明的深层机制。这不仅深化了人类对生物运动行为及运动机理的认知，更为机器鱼控制策略提供了新方法：中低速巡航场景下，优先采用间歇式驱动以最大化能效；高速机动任务中，则切换至连续驱动模式以保障响应速度与位移能力。&lt;/p&gt;&lt;p&gt;本篇论文的第一作者为Xiangxiao Liu（刘祥骁），本科毕业于东南大学自动化学院，硕士和博士毕业于日本大阪大学，就读期间获日本学术振兴会（JSPS DC1）资助，后续于瑞士洛桑联邦理工学院（EPFL）开展博士后研究工作。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CVPR 2026 Workshop 征稿｜AdvML@CV 2026：Safety of Vision-Language Agents</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 12:06:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;IEEE/CVF 计算机视觉与模式识别会议 CVPR 2026 将于 2026年6月3日&amp;ndash;6月7日 在美国科罗拉多州丹佛举办。我们将在 CVPR 期间举办 第六届对抗机器学习计算机视觉研讨会（6th AdvML@CV），Workshop 预计安排在 6月3日或6月4日。&lt;/p&gt;&lt;p&gt;本届主题聚焦：Safety of Vision-Language Agents（视觉-语言智能体安全）。&lt;img src="https://image.jiqizhixin.com/uploads/editor/25b5876f-7085-46b1-bc08-21edee40eb93/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题聚焦：视觉-语言智能体的安全与鲁棒性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;多模态基础模型推动了视觉理解、生成与推理能力的跃迁，也让 Vision-Language Agents（视觉-语言智能体） 迅速成为&amp;ldquo;感知&amp;mdash;语言推理&amp;mdash;行动规划&amp;rdquo;一体化的新范式。&lt;/p&gt;&lt;p&gt;但随着智能体自主性增强，攻击面也从传统像素级扰动扩展到更复杂的安全风险：例如 对抗提示（adversarial prompts）、指令注入（instruction injection）、jailbreak 操控 等，它们可能扰乱推理链条、误导感知决策，甚至诱发危险行为。&lt;/p&gt;&lt;p&gt;我们希望通过本次 Workshop，汇聚计算机视觉、多模态学习与 AI Safety 社区的研究者与工程实践者，共同推进安全、鲁棒、可信的视觉-语言智能体研究与落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文征稿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本次研讨会诚邀与以下主题相关（但不限于）的投稿：&lt;/p&gt;&lt;p&gt;&amp;bull;Attack and defense on vision-language agents&lt;/p&gt;&lt;p&gt;&amp;bull;Datasets and benchmarks that could evaluate vision-language agents&lt;/p&gt;&lt;p&gt;&amp;bull;Adversarial / Jailbreak attacks on vision-language agents&lt;/p&gt;&lt;p&gt;&amp;bull;Improving the robustness of agents or deep learning systems&lt;/p&gt;&lt;p&gt;&amp;bull;Interpreting and understanding model robustness, especially agentic AI&lt;/p&gt;&lt;p&gt;&amp;bull;Adversarial attacks for social good&lt;/p&gt;&lt;p&gt;&amp;bull;Alignment of vision-language agents&lt;/p&gt;&lt;p&gt;投稿类型与格式要求：&lt;/p&gt;&lt;p&gt;&amp;bull;Long Paper：正文最多8 页（不含参考文献）&lt;/p&gt;&lt;p&gt;&amp;bull;Extended Abstract：正文最多4 页（含参考文献）&lt;/p&gt;&lt;p&gt;&amp;bull;论文需匿名，并使用 CVPR 2026 Author Kit 模板撰写（LaTeX/Word 均可）&lt;/p&gt;&lt;p&gt;&amp;bull;被录用论文可选择收录至 CVF &amp;amp; IEEE Xplore Proceedings&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重要日期&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;bull;Abstract Submission Deadline：2026/03/05&lt;/p&gt;&lt;p&gt;&amp;bull;Paper Submission Deadline：2026/03/05&lt;/p&gt;&lt;p&gt;&amp;bull;Author Notification：2026/03/17&lt;/p&gt;&lt;p&gt;&amp;bull;Camera-Ready Deadline：2026/04/01&lt;/p&gt;&lt;p&gt;&amp;bull;CVPR 2026 Conference：2026/06/03&lt;/p&gt;&lt;p&gt;&lt;strong&gt;演讲嘉宾&lt;img src="https://image.jiqizhixin.com/uploads/editor/f442f44c-165f-4cc6-a581-d1f1449881d5/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;组织团队&lt;img src="https://image.jiqizhixin.com/uploads/editor/0e981f24-e273-47d0-b964-4adfb16e593f/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Program Committee&lt;img src="https://image.jiqizhixin.com/uploads/editor/443e9b6e-dd88-42bf-ba81-b7faa1ac1d49/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;竞赛承办协办单位&lt;img src="https://image.jiqizhixin.com/uploads/editor/35df9c0a-9bba-41bf-959d-c8f0f0dd5f87/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;投稿入口与会议信息&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Workshop 官网与投稿入口见文末链接。&lt;/p&gt;&lt;p&gt;欢迎转发给有相关研究方向的同学与合作伙伴，我们期待在研讨会现场与大家交流！&lt;/p&gt;&lt;p&gt;Workshop 官网：&lt;br&gt;https://cvpr26-advml.github.io/&lt;br&gt;&lt;br&gt;OpenReview 投稿入口：&lt;br&gt;https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop/Advml&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>当运维遇上“春运时刻”，Chaterm破解移动远程运维操作难题</title>
      <description>&lt;![CDATA[“声控”运维、技能复用，合合信息Chaterm实现多场景双端智能运维]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 11:47:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;随着AI基础设施布局速度加快，企业运维面临跨终端、全链路管理的新挑战。近日，上海合合信息科技股份有限公司旗下的AI Agent产品Chaterm推出移动端应用，同步在PC端上线&amp;ldquo;Agent Skills&amp;rdquo;功能，帮助云计算行业从业者解决移动场景操作受限、运维知识难以复用等难题。通过打通移动端与PC端的场景协同服务，Chaterm为运维管理向全场景、智能化方向演进提出了新的落地方案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决远程运维难题，Chaterm移动端实现&amp;ldquo;说话即操作&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在算力设施日益复杂的背景下，保障核心业务系统的全时运转已成为企业发展的生命线。然而，面对春节等节假日、外出差旅、日常通勤等非固定办公场景，IT部门往往面临团队分散、网络环境复杂等挑战。传统移动端运维工具受限于物理屏幕尺寸，主要以虚拟键盘为操作方式，难以支撑复杂的代码输入与多键组合操作，导致运维人员操作效率低下，在关键时刻无法进行有效应急响应。&lt;/p&gt;&lt;p&gt;针对这一行业痛点，Chaterm率先在移动终端管理工具中落地语音指令识别功能，让运维指令&amp;ldquo;言出必行&amp;rdquo;。基于&amp;ldquo;ASR与热词增强+LLM纠错&amp;rdquo;双层架构，Chaterm不仅能精准&amp;ldquo;听清&amp;rdquo;运维专业术语，更能深度&amp;ldquo;听懂&amp;rdquo;用户意图，将模糊的口语描述转化为准确、可执行的操作，避免了因术语别名或环境干扰导致的误操作风险。&lt;/p&gt;&lt;p&gt;据Chaterm团队技术人员介绍，目前，Chaterm移动端具备两种模式，在Terminal模式下，用户可以通过语音命令输入和Snippets（快捷命令），快速输入指令；在对话模式下，则可以用自然语言描述运维需求，在高铁、机场等受限环境下，也能快速完成核心业务的故障排查与应急响应。&lt;/p&gt;&lt;p&gt;&lt;img width="174" src="https://image.jiqizhixin.com/uploads/editor/96468c7a-32f6-4f87-9d17-4cb9edc3c444/1770176327436.jpeg" alt="Chaterm" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;图说：Chaterm移动端将用户模糊发音精准转化为标准运维指令&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Skills&lt;/strong&gt;&lt;strong&gt;为运维人员打造&amp;ldquo;技能库&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在提升移动端运维效率的同时，Chaterm同步推进PC端升级，聚焦运维经验在系统内部的标准化复用。在传统运维工作模式中，关键系统的稳定性往往高度依赖资深专家的个人经验，这种隐性知识难以规模化传承，且容易因人员流动或操作失误引发风险。&lt;/p&gt;&lt;p&gt;为应对上述管理难题，Chaterm PC端推出Agent Skills功能，运维工程师可以将运维经验与业务逻辑，例如日常的检查清单、应用/数据库部署流程、故障排查流程、性能优化步骤等，封装为可复用的&amp;ldquo;技能包&amp;rdquo;，当AI面对用户提出的需求时，能像一位经验丰富的专家一样，查阅对应&amp;ldquo;技能包&amp;rdquo;后自主执行任务，提升运维工作效率，助力企业构建更稳健的自动化运维体系。&lt;/p&gt;&lt;p&gt;&lt;img width="415" src="https://image.jiqizhixin.com/uploads/editor/80f922ac-a0c2-4ce5-8ff8-1bb3b89e1b15/1770176327441.png" alt="90f88b67-7a81-41e4-b9c3-01bbeea68a45" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;图说：Chaterm产品主要功能介绍&lt;/p&gt;&lt;p&gt;随着大模型技术不断向垂直业务场景渗透，AI Agent成为提升企业效率的关键。在此趋势下，Chaterm也在积极探索运维智能化落地，相关实践已获行业认可。此前，在全球增长咨询公司沙利文与头豹研究院联合发布的《2025年中国生成式AI行业最佳应用实践》中，Chaterm凭借其在跨平台云资源智能管理方面的创新应用，入选2025年中国生成式AI最佳实践案例。未来，Chaterm将持续拓展AI技术在复杂运维场景中的应用，助力企业构建更高效、稳健的自动化体系。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>ICLR 2026 | 腾讯混元团队联合 KCL 提出 WildToolBench，评估 Wild 场景下 LLM 的 Agentic 能力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 11:19:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/490c3433-8113-4246-af0b-c222447651af/1770174901251.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;作者：Peijie Yu, Wei Liu, Yifan Yang, Jinjian Li, Zelong Zhang, Xiao Feng, Feng Zhang&lt;/p&gt;&lt;p&gt;单位：Tencent HY、King&amp;#39;s College London&lt;/p&gt;&lt;p&gt;链接：&lt;a href="https://openreview.net/forum?id=yz7fL5vfpn"&gt;&lt;u&gt;Benchmarking LLM Tool-Use in the Wild | OpenReview&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Github：&lt;a href="https://github.com/yupeijei1997/WildToolBench"&gt;&lt;u&gt;GitHub - yupeijei1997/WildToolBench: Benchmarking LLM Tool-Use in the Wild&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3d108a18-080b-4a40-82b0-b5b23e387f02/1770174912241.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;通过大型语言模型（LLM）的多轮、多步骤工具调用满足用户需求，往往并非简单直接的过程。真实用户交互本质上具有 &amp;ldquo;野生性&amp;rdquo;，复杂、杂乱且灵活。我们从用户行为中识别出三大核心挑战：一是组合式任务，需高效编排工具调用拓扑结构；二是隐含意图，分散于多轮对话中，需结合上下文推理；三是指令转换，用户会混合任务查询、澄清提问与日常交流，迫使 LLM 实时调整策略。现有基准测试忽视了这些行为，导致 LLM 在工具调用方面的表面进展存在误导性。为此，我们提出 WildToolBench&amp;mdash;&amp;mdash; 一个基于真实用户行为模式的 LLM 工具调用基准测试。对 58个 LLM 的综合评估显示，无任何模型的准确率超过 15%，这表明 LLM 智能体能力的稳健性仍存在巨大差距。受控实验与深度分析进一步表明，LLM 工具调用的真正挑战并非人为设计的复杂任务，而是用户行为的 &amp;ldquo;野生性&amp;rdquo;，这也凸显了重新审视 LLM、用户与工具三者间交互关系的必要性。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e1103d43-1ffa-4096-9d0b-fe83a05c1af7/1770174923131.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;一直以来，现有 LLM 工具使用基准测试（如 BFCL 系列、TauBench等）虽在推动技术发展中发挥了重要作用，但普遍存在场景理想化的问题。它们往往将用户需求简化为明确、独立的任务，忽略了真实对话中用户行为的复杂性 &amp;mdash;&amp;mdash; 用户可能在一次对话中提出包含多个简单需求的复合任务，需要 Agent高效协调多种工具；也可能将真实意图隐藏在多轮对话的上下文之中，要求 Agent主动推断；更会在任务查询、澄清疑问与日常闲聊之间灵活切换，迫使 Agent实时调整应对策略。这些被现有基准忽视的 &amp;ldquo;野生&amp;rdquo; 用户行为，恰恰是 LLMs 在实际应用中面临的核心挑战，也让此前 LLM 工具使用能力的进步显得有些 &amp;ldquo;虚高&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5dbfb4c1-294a-4f1f-aa2f-dbb9583cc67a/1770174934303.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;WildToolBench 的诞生，正是为了填补这一空白。它以真实用户行为模式为基石，通过精心设计的数据 pipeline，结合人工验证与标注，构建了 256 个场景、1024 项任务的庞大测试集。与其他基准测试不同，WildToolBench 牢牢抓住真实用户交互的三大核心特性：复合任务的工具协同需求、上下文隐含意图的推断要求，以及指令类型灵活切换下的策略适配能力。这一设计理念直指行业痛点 &amp;mdash;&amp;mdash; 真正考验 LLMs 工具使用能力的，并非人为构建的复杂场景，而是看似简单却贴合真实用户习惯的交互模式。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/30783c9d-8c93-4684-89e6-7dbcd1fee909/1770174945105.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;为验证 WildToolBench 的有效性，研究团队对 58款主流 LLMs 展开了全面评估，涵盖闭源通用模型（如 Gemini 系列、Claude系列、GPT 系列）、开源通用模型（如 GLM-4.5、Kimi-K2）以及开源专用工具模型。令人惊讶的是，所有模型的会话准确率均未超过 15% ，即便表现最佳的闭源模型，在任务准确率上也大多低于 60%。这一结果彻底打破了人们对当前 LLM 工具使用能力的乐观认知，揭示出 LLMs 在真实场景下的巨大能力缺口。&lt;/p&gt;&lt;p&gt;值得注意的是，实验还呈现出诸多具有行业启示性的发现。闭源模型整体表现优于开源模型，但头部开源模型（如 GLM-4.5）已能逼近部分顶尖闭源模型的水平，为开源社区的发展注入信心；专用工具模型虽针对工具使用进行优化，却因泛化能力不足，表现反而不及通用模型；具备强化推理能力的模型变体，在工具协同与意图推断任务中优势明显，证明推理能力是提升 LLM 工具使用能力的关键。这些发现不仅为模型开发者指明了优化方向，更让行业意识到，未来 LLM 智能体的发展，不能仅聚焦于工具调用的 &amp;ldquo;执行能力&amp;rdquo;，更需强化对用户意图的 &amp;ldquo;理解能力&amp;rdquo;，而这依赖于模型在指令跟随、长上下文 comprehension 等基础能力上的突破。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/70ef93eb-4244-4846-be35-0181f0188324/1770174986438.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战一：组合式任务的工具调用拓扑编排难题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实场景中，用户的需求往往不是单一指令的简单实现，而是需要多工具、多步骤协同完成的组合式任务。这类任务的核心难点，在于需要LLM具备高效的工具调用拓扑编排能力&amp;mdash;&amp;mdash;也就是说，不仅要明确&amp;ldquo;需要调用哪些工具&amp;rdquo;，更要精准规划&amp;ldquo;工具调用的顺序、时机、优先级&amp;rdquo;，甚至要根据前一步工具的返回结果，动态调整后续的调用逻辑。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e632e30d-2c3a-41d1-bfde-01bd3573992c/1770174992453.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;深入分析实验数据，更能发现 LLMs 在工具使用中的关键短板。在复合任务处理上，无论是顺序调用多工具、并行调用多工具，还是混合调用模式，LLMs 的表现都不尽如人意。以最复杂的混合多工具任务为例，最高准确率仅为 25%，且工具执行的最优路径率不足 43%，说明 LLMs 在工具协同规划与效率优化上仍有极大提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战二：多轮对话中隐含意图的上下文推理困境&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实用户与LLM的交互，很少会一次性将所有需求细节完整表述，更多是通过多轮对话逐步传递需求，甚至会在对话中隐含核心意图&amp;mdash;&amp;mdash;这就对LLM的上下文推理能力提出了极高要求：LLM需要全程捕捉对话中的关键信息，整合多轮对话的上下文，精准挖掘用户未明确说出的隐含需求，而非仅局限于单轮指令的表面含义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战三：指令转换下的实时策略调整压力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实的用户对话具有极强的灵活性，用户不会始终围绕单一任务指令展开交流，而是会出现频繁的指令转换：可能在提出任务查询后，突然插入澄清提问，或是切换到 casual 交流，随后又回归核心任务。这种指令转换的随机性，迫使LLM必须具备实时调整策略的能力&amp;mdash;&amp;mdash;既要在任务查询时保持工具调用的专业性，又要在澄清、闲聊时灵活回应，同时还要记住对话主线，确保在指令回归后能够快速衔接之前的任务逻辑，不出现思路断裂。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0b87603b-88d0-47b6-bed2-4c29a3676bc3/1770175007335.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在意图推断方面，面对用户通过部分信息省略、指代关联或长距离上下文依赖隐藏的意图，LLMs 尤其是在长距离依赖任务中，准确率普遍低于 50%，暴露出其上下文理解与推理能力的不足。此外，当用户在对话中频繁切换指令类型时，LLMs 的任务准确率最高可下降 30%，其 &amp;ldquo;自我条件反射&amp;rdquo; 式的决策偏差（如之前使用工具后倾向于继续调用工具），严重影响了应对真实用户灵活需求的能力。&lt;/p&gt;&lt;p&gt;WildToolBench 的意义，远不止于提供一个更具挑战性的评估基准。它通过结构化的评估维度与详细的错误分析（如 &amp;ldquo;错误工具选择&amp;rdquo;&amp;ldquo;冗余调用&amp;rdquo; 等高频错误），为模型迭代提供了清晰的改进路径；更以真实用户行为为核心的设计理念，重新定义了 LLM 工具使用评估的标准，推动行业从 &amp;ldquo;理想化测试&amp;rdquo; 迈向 &amp;ldquo;真实场景验证&amp;rdquo;。对于企业而言，WildToolBench 可帮助其更精准地评估 LLM 智能体的实际应用潜力，避免技术选型偏差；对于科研人员，它则为 LLM 工具使用能力的研究提供了贴近实际需求的 &amp;ldquo;试验场&amp;rdquo;。&lt;/p&gt;&lt;p&gt;如今，WildToolBench 的数据集、评估脚本及可控多智能体数据合成框架已全部开源，诚邀全球 AI 研究者与开发者共同探索 LLM&amp;nbsp;Agentic&amp;nbsp;能力的突破之道。&lt;/p&gt;&lt;p&gt;数据集：&lt;a href="https://github.com/yupeijei1997/WildToolBench/blob/main/wild-tool-bench/data/Wild-Tool-Bench.jsonl"&gt;&lt;u&gt;WildToolBench/wild-tool-bench/data/Wild-Tool-Bench.jsonl at main &amp;middot; yupeijei1997/WildToolBench &amp;middot; GitHub&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;评估脚本：&lt;a href="https://github.com/yupeijei1997/WildToolBench/tree/main/wild-tool-bench/wtb"&gt;&lt;u&gt;WildToolBench/wild-tool-bench/wtb at main &amp;middot; yupeijei1997/WildToolBench &amp;middot; GitHub&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;可控多智能体数据合成框架：&lt;a href="https://github.com/yupeijei1997/WildToolBench/tree/main/multi-agent-framework"&gt;&lt;u&gt;WildToolBench/multi-agent-framework at main &amp;middot; yupeijei1997/WildToolBench &amp;middot; GitHub&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>钉钉北京峰会展示AI落地多行业样本，一批企业集中签约</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 10:58:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;2月3日，以&amp;ldquo;AI时代的工作方式&amp;rdquo;为主题的钉峰会在北京隆重举行。峰会由阿里巴巴钉钉和中关村国际共同举办，汇聚了来自制造业、农业、供应链、环保、文媒等多行业的领军企业代表、数字化先锋及专家逾三百人，深入探讨人工智能浪潮下工作方式的重塑与进化。&lt;/p&gt;&lt;p&gt;现场，一批北京区域企业与钉钉集中签约，共同迈入AI时代的工作方式，包括博锐尚格科技股份有限公司、天津市神州商龙科技股份有限公司、北京健坤餐饮集团、北京央视瑞安技术服务有限公司等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体操作系统：从&lt;/strong&gt;&lt;strong&gt;工具&lt;/strong&gt;&lt;strong&gt;到伙伴的进化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;钉钉华北大区总经理刘浩在致辞中指出，当前正处在AI转型的关键时间点。钉钉以解决真实问题为原点，致力于从传统的应用平台升级为面向未来的&amp;ldquo;智能体操作系统&amp;rdquo;（Agent OS）。他强调，AI时代的工作方式需要根本性的重新思考，即从&amp;ldquo;人操作工具&amp;rdquo;转向&amp;ldquo;人调教AI&amp;rdquo;，让智能体（Agent）成为业务执行与协同的核心单元。&lt;img src="https://image.jiqizhixin.com/uploads/editor/572106a8-a4d3-428c-b800-542ff65b7bf2/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 钉钉华北大区总经理刘浩&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;中关村国际控股有限公司总经理卢江表示表示，中关村国际正通过覆盖全球的创新网络，携手钉钉，表示，以AI为纽带、出海服务为桥梁，共同优化AI时代的服务模式，让创新价值在全球范围内绽放。&lt;/p&gt;&lt;p&gt;钉钉华北大区解决方案总经理刘啸天在主题分享中阐释了&amp;ldquo;智能体协同&amp;rdquo;的核心逻辑。他认为，AI规模化落地的关键瓶颈不再是模型能力，而在于缺乏企业级统一的运行环境。钉钉正以Agent OS为内核，构建下一代操作系统，通过智能体统一调度数字工具与物理设备，并实现智能体间的交互与协同。人在这一系统中的角色，从执行者转变为&amp;ldquo;教练&amp;rdquo;，负责调教与设定目标，而将重复性、流程化的工作交由智能体执行。&lt;/p&gt;&lt;p&gt;全网爆火的钉钉首款AI硬件DingTalk A1录音卡也在本次峰会上亮相，A1产品负责人夏治朋详细介绍了这款&amp;ldquo;网红&amp;rdquo;产品设计的初衷和用户自发探索出的花式用法，现场种草。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;跨界实践：AI赋能千行百业，客户亲述转型心声&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;峰会邀请了多位来自一线企业的代表，分享了其利用钉钉AI能力进行数字化转型的前沿实践，并在现场亲述了转型过程中的真实洞察。&lt;/p&gt;&lt;p&gt;佳沃集团知识管理副总裁李萌带来《一颗蓝莓的AI之旅&amp;mdash;&amp;mdash;佳沃集团AI应用实践》主题分享。&lt;img src="https://image.jiqizhixin.com/uploads/editor/6bc84482-8169-4482-a75c-7232d383d1d6/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 佳沃集团知识管理副总裁李萌&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;佳沃集团有限公司创立于2012年，是联想控股旗下的现代农业和食品产业集团，位列中国农业企业500强第36名，更是中国农业数智化转型的标杆企业。&lt;/p&gt;&lt;p&gt;自2020、年起，佳沃与钉钉共建了以知识管理为内核的数智化生态，通过数据上钉、经验上钉、办公全场景上钉，特别是AI助理&amp;ldquo;小佳&amp;rdquo;的应用，让员工满意度不断提升，新员工培训成本降低50%，一线农人也能随时获取专业建议，经验实时更新，行政事务一站式解决。&lt;/p&gt;&lt;p&gt;2025年钉钉推出AI表格后，佳沃蓝莓也第一时间成为AI表格到深度用户。利用AI表格，佳沃把过去的N张表格变成一张看板，把过去来源于口头、微信、备注等各处无法统计的非结构化信息，变成标签化、可计算的结构化信息。&lt;/p&gt;&lt;p&gt;&amp;ldquo;钉钉AI表格现在可以通过语音录入来输入了，这个功能非常好！&amp;rdquo;李萌说，这意味着田间地头的农人都可以把经验和信息沉淀到AI表格上。&lt;/p&gt;&lt;p&gt;蜀海供应链管理有限责任公司产品总监邢禺分享了蜀海作为餐饮供应链公司的AI实战经验。蜀海曾是海底捞供应链部门，2014年起独立为第三方供应链服务公司。2020年起，蜀海引入钉钉，帮助解决组织的协同问题，2025年起重点推进AI能力，深度赋能多个智能体应用场景，助力AI转型。&lt;/p&gt;&lt;p&gt;邢禺展示了AI在复杂物流配送、智能补货计划及全国仓储会议管理中的深度应用。&amp;ldquo;AI不只是替代人，而是解放人，让从业者脱离重复劳动，聚焦核心的服务。&amp;rdquo; 通过AI算法优化配送路线，将履约率提升至99%；利用AI听记与表格自动分析海量会议内容，挖掘共性问题，使问题闭环率超90%，显著提升了供应链响应速度与管理透明度。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a436d962-34fb-4063-b1d2-7789cc39573c/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 北控水务AI创新部负责人刘连波&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;北控水务是北控集团旗下专注于水资源循环利用和水生态环境保护事业的旗舰企业，在香港主板上市，集产业投资、设计、建设、运营、技术服务与资本运作为一体，水处理规模位居国内行业前列。已入选恒生香港中资企业指数成份股、摩根斯坦利资本国际指数等多只重要国际成分股。&lt;/p&gt;&lt;p&gt;北控水务AI创新部负责人刘连波在钉峰会现场分享了其以&amp;ldquo;补位&amp;rdquo;思路推进AI落地的策略。刘连波表示，&amp;ldquo;近一年来，我们在不断研究从场景探索到能力补强，AI应用从价值验证到构建核心能力，从AI+业务、AI+组织到AI+员工，与钉钉一起继续深挖AI场景和共建AI能力和文化。&amp;rdquo;&lt;/p&gt;&lt;p&gt;他展示了一组数据：基于钉钉知识库，公司迅速孵化AI助手，在很多个超过500人的群里接入了AI助手，目前每月调用3000次以上，回答准确率93%以上。AI工具对近半数员工提高效率20%到50%。&lt;/p&gt;&lt;p&gt;央视瑞安信息化工程师杨过分享了国企信息化落地的经验和方法。央视瑞安作为中央广播电视总台全资子公司，是广播电视领域动力运维与综合技术服务的标杆企业。&amp;ldquo;解决工作中协作问题的关键就是从&amp;lsquo;传纸条&amp;rsquo;变成&amp;lsquo;共看一张图&amp;rsquo;，要善于利用时代最先进的工具为自己所用。&amp;rdquo;杨过说。通过钉钉OA审批和AI表格的联动，央视瑞安搭建了外出保障工作管理平台，实现了流程驱动数据，数据反哺流程的闭环。&lt;/p&gt;&lt;p&gt;&amp;ldquo;AI表格是真的好用，既有科技感，还不用写代码&amp;rdquo;，杨过说，&amp;ldquo;像外出保障工作管理平台，就是我和另一个工程师两个人搭建起来的。&amp;rdquo;&lt;/p&gt;&lt;p&gt;整场峰会气氛热烈，并传递出一个明确信号：AI时代的工作方式变革已进入深化实践阶段，&amp;ldquo;智能体协同&amp;rdquo;不再是一个遥远的概念，而是正在千行百业中落地生根，成为提升组织韧性、激发创新活力、锻造未来竞争力的关键引擎。企业与个人唯有主动拥抱这一变革，方能立于AI浪潮之巅。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，真正好用的Windows版「Cowork」上线了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 10:31:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杜伟、泽南&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;section&gt;天工 Skywork 桌面版旗帜鲜明地将 Windows 平台作为首发阵地，为全球用户提供开箱即用的「Cowork 平替」。&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;终于，Windows 原生「Cowork」问世了！&lt;/p&gt;&lt;p&gt;过去两周，AI 圈被火遍硅谷的 ClawdBot（现已改名为 OpenClaw）持续刷屏。&lt;/p&gt;&lt;p&gt;人们一边震撼于这个智能体助理带来的自动化效率提升，另一边也在吐槽其对 Windows 系统的适配。比如，根据一些用户的反馈，如果严格按照官网提供的命令行在 Windows 上安装 ClawdBot，将导致 Skills 功能彻底失效。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGBIjW0qbxQ4lR0tgCrib0JkUFBTXQZdKR7piciaP9tocIpzkrnO0RE8q1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.8379629629629629" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531376" data-aistatus="1" data-original-style="height: auto !important;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/43771591-a720-48a7-82f4-06a6af909c83/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这并不是 ClawdBot 一个智能体助手的选择性倾向，上个月发布的 Claude Cowork 以及 OpenAI 昨天亮相的智能体式 Codex 应用同样优先适配 macOS 系统。这种生态上的失衡在今天迎来了转机。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;国产大模型玩家昆仑天工正式发布了全新的 Agent 产品 &amp;mdash;&amp;mdash; 天工 Skywork 桌面版，旗帜鲜明地将 Windows 平台作为首发阵地&lt;/strong&gt;，为全球用户带来了开箱即用的「Cowork 平替」。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1e92a794-82fa-4c5e-8151-211a194e2ff8/1770171920011.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Skywork 原生支持 Windows 系统，无需繁琐的迁移或适配，即可对海量本地历史文件和复杂项目场景展开自动化处理。这种高度的兼容性打通了个人 Agent 进入真实办公场景的「最后一公里」。&lt;/p&gt;&lt;p&gt;在优先适配 Windows 平台之外，Skywork 在&lt;strong&gt;基础模型选择、功能支持、能力扩展&lt;/strong&gt;等其他维度同样有亮眼表现。&lt;/p&gt;&lt;p&gt;首先，与 Claude Cowork 仅支持自家 Claude 模型不同，Skywork 增加了对谷歌 Gemini 的支持，充分发挥该系列模型的原生多模态理解与生成优势。&lt;/p&gt;&lt;p&gt;现在，用户可以自由选择 Gemini 3 Pro 以及 Claude Opus 4.5、Claude Sonnet 4.5 等不同模型。当然也可以启用智能路由「auto」模式，系统自动识别任务类型并匹配最适合的模型，最大化执行效率。&lt;/p&gt;&lt;p&gt;其次，&lt;strong&gt;Skywork 在主打办公场景的同时，也能 hold 住创作场景&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531377" data-ratio="0.6851851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGKgqAyr1w566FIb9FZRkWxr1RqF35vib2kfjdvMIXfvp05JTvQCabhhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f462d30f-935f-4eac-930f-1e49893b07e5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Skywork 界面&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了全方位满足桌面级真实办公需求，Skywork 桌面版做到了对全类型文件的智能管理。不管是图片、视频、表格、Word、Excel、PDF、PPT 还是其他格式，它都能跨文件、跨格式直接读取并理解，遵循用户任务指令对它们进行归类整理或生成新内容。&lt;/p&gt;&lt;p&gt;并且，它能&lt;strong&gt;同时响应并执行多项复杂任务&lt;/strong&gt;，效率拉满。此外也无需上传云端，&lt;strong&gt;在本地环境完成即可&lt;/strong&gt;，消除了用户对数据泄露和文件安全的担忧。&lt;/p&gt;&lt;p&gt;面向图像与视频生成的创作场景，比如制作 PPT、宣传素材，整理可视化报告，创作多媒体内容，Skywork 相较于 Claude Cowork，在语义遵循以及表现力、专业性等多方面均更胜一筹。&lt;/p&gt;&lt;p&gt;最后是能力扩展，&lt;strong&gt;Skywork 内置了 100+ 个经过精选的、真正有用的 Skills 技能包&lt;/strong&gt;，并将控制权交给用户，既可以手动选择也可由系统根据任务类型自动筛选，操作灵活，覆盖了 Office 三件套生成、网页生成以及图像与视频生成。&lt;/p&gt;&lt;p&gt;此外，Skywork &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在价格上也极具杀伤力。&lt;strong&gt;用户只需 19.99 美元的 Basic 会员，就能解锁完整的产品体验&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;下载地址：https://skywork.ai/desktop&amp;nbsp;&lt;/p&gt;&lt;p&gt;在全球竞品偏向 macOS 开发的当下，昆仑天工的 Skywork，打响了一场针对「Windows 生产力人群」的抢位战。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上手实测：这会是办公自动化的「奇点」吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;话不多说，我们直接开测。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;告别「碎片化」办公&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上个星期，昆仑天工开源了 SkyReels-V3 视频生成模型，我们对此进行了报道。当时是以文章的形式进行了介绍，用到了大量图片、视频素材。&lt;/p&gt;&lt;p&gt;假如我们现在转换一下身份，&lt;strong&gt;用 PPT 向别人介绍这个模型怎么办？&lt;/strong&gt;这正是 Skywork 的用武之地，模型选用「gemini-3-pro-preview」。&lt;/p&gt;&lt;p&gt;只需要告诉它你要制作这样一个 PPT，文档的 Word 版和视频素材一股脑地放在文件夹里，它就会自行分析需求，把素材找好做成一个可供使用的版本出来。&lt;/p&gt;&lt;p&gt;可以看到，在生成中间，它还会问你要选什么样的风格，这是一个需要互动的过程。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/151750a9-6fa8-4a84-a7cf-eff5a99fb2ad/1770172033027.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最后在生成的 PPT 的基础上，你可以进行修改，节省了大量的前期工作。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531411" data-ratio="0.56" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGx3VQzXmicR7QGIeBqOT3IOiaKVV7H0g2a9licmMcOk2y5icKcz8JAXdzgA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-type="gif" data-w="800" type="block" data-original-style="height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/645f8bf6-125d-4343-a6f5-ffbe4f2bb68d/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来尝试一个更复杂的案例，&lt;strong&gt;让 Skywork 在不删除任何原始文件的基础上，将文件夹内的所有内容整理成一套清晰直观的目录结构&lt;/strong&gt;，并在任务完成后给出一份简要报告，列出新的文件夹结构和变更日志。&lt;/p&gt;&lt;p&gt;这项任务要求 Agent 具备强大的环境感知能力与跨格式解析能力，这次选用 Claude Opus 4.5。&lt;/p&gt;&lt;p&gt;在实际跑的过程中，Skywork 首先「穿透」不同层级的子目录，精准识别出了 Word、Excel、PDF 等不同格式的文件数据。然后在语义理解的基础上，它自动剔除冗余信息，重组碎片化信息，并生成逻辑严密的结构化报告。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/030f5739-7df7-4a7d-9ef5-930e7dc0ebb3/1770172056846.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最终生成的「目录结构整理报告」是这样的：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531420" data-ratio="0.6132723112128147" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG8fE4koCry5TOvHoTqPBhafVZqmJNHR1ySYIAncib7Y0kictS3u62ibxTg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-type="gif" data-w="874" type="block" data-original-style="height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5cafac8d-b789-441d-9556-83d11cbf9d64/640.gif" data-order="1" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;多模态能力融入工作流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;英伟达最近和 OpenAI 之间的新闻引发了科技圈的关注。目前多路媒体的报道认为，英伟达已经暂停了向 OpenAI 投资高达 1000 亿美元的计划。而 OpenAI 也正在寻求构建 GPU 以外的算力体系。&lt;/p&gt;&lt;p&gt;那么作为一家「以先进 AI 推理芯片为主要产品的公司」，机器之心能否在下一轮 OpenAI 的融资上找到机会呢？我们&lt;strong&gt;让 Skywork 来生成一份意向报告，要求图文并茂。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;怎么看这都是一个大工程。这回它分析需求以后上网进行了搜索，在知乎上搜到了机器之心以前发过的一些文章。&lt;/p&gt;&lt;p&gt;接着它整理了大致的撰写路径之后开始工作，自己给自己列出了要完成的事项，为了写 Word 文档，还自己下载了 docx 的库。&lt;/p&gt;&lt;p&gt;可见最后生成的「下一代 AI 推理算力基础设施提案」有那么一点可行性。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8ae96629-20b3-4008-a95f-a16d204cb8ab/1770172089215.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最后尝试一个更有挑战性的场景，看看 Skywork 能不能&lt;strong&gt;根据文档和图片生成一个精美的 SEO 网页&lt;/strong&gt;。这类任务要求 Agent 既能理解内容，还会工程实现。&lt;/p&gt;&lt;p&gt;一要精准提取文档中的核心语义，为撰写高质量网页文案做好准备。二要利用视觉处理能力来裁剪、优化图片并嵌入到合适的布局中。&lt;/p&gt;&lt;p&gt;最后也是最关键的一步，它要能自主编写出符合 SEO 逻辑的代码，将原本孤立的图文素材转化为信息齐全、布局合理、观感友好的网页。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e8a15a48-250e-44b8-981c-ab3898e5f259/1770172131643.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;简单的几个案例跑下来，我们发现：Skywork 这样的智能体助手已经不再只是一个等待执行用户指令的对话框，它们在拥有更高的系统操作权限之后，自主性得到史诗级强化，从而在极少的人为参与下高效地完成工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从「编程智能体」走向「个人助理智能体」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年被普遍认为是 Agent 落地元年，而刚过去一个月的 2026 年，我们正在见证新一轮的爆发。&lt;/p&gt;&lt;p&gt;一开年，Agent 赛道的竞争便趋于白热化，国外 Anthropic 发布 Cowork、OpenClaw 引爆 A I 社区，国内大厂阿里先后上线千问 APP 任务助理、桌面端 QoderWork，其他大模型独角兽也陆续推出桌面智能体应用。&lt;/p&gt;&lt;p&gt;业界玩家们你追我赶的发布节奏，一定程度上可以验证 OpenClaw 创建者 Peter Steinberger 近日接受采访时表达的一种观点。他认为，&lt;strong&gt;2025 年是编程智能体元年，而今年将是个人助理智能体元年&lt;/strong&gt;。这位搅动硅谷的开发者还放出狂言，「我们手机里 80% 的 APP 将被取代。」&lt;/p&gt;&lt;p&gt;Steinberger 的判断只是一家之言，但通过 Agent 打造超级个体的行业趋势是显而易见的。不管是聚焦职场人士还是普通用户，Agent 正在以前所未有的速度与深度重构数字世界的底层逻辑。&lt;/p&gt;&lt;p&gt;在桌面端，Agent 连接本地操作系统，实现跨文件管理、跨应用操作、复杂任务并行执行；在移动端，打破 APP 孤岛，实现主动意图感知、跨软件调度与全链路执行。与人类生活、工作、学习息息相关的双端并进，将加速驱动人类走向以 Agent 为主导的超级个体时代。&lt;/p&gt;&lt;p&gt;可以预见的是，对个人更友好、易用性与专业性更强的 Agent，势必收获更多潜在用户群体的青睐与认可。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当赢家无法通吃，相对优势或成护城河&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如 ChatGPT 问世之后的数年一样，2026 年 AI 领域仍是「步履不停」。对于所有入局者，尤其是以 AGI 为终极目标的大模型厂商们，谁都不愿在新一轮的狂飙中落后。&lt;/p&gt;&lt;p&gt;尤其是在行业焦虑大模型算力溢出、预训练 Scaling Laws 边际效益增长放缓的当下，大家都在期待下一次 AI 奇点的到来。两周前，DeepMind CEO 哈萨比斯在一次播客节目中表示，「实现 AGI 的路上可能还需要一两个重大创新」。&lt;/p&gt;&lt;p&gt;在那之前，Agent 成为释放与扩展基础大模型潜能的「第二曲线」。通过对个人生活与工作、企业生产范式的变革，Agent 将人类从繁琐、重复性的任务中解脱出来，将更多时间与精力放在能够发挥创造力与想象力、产生高价值的板块。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;随着 Agent 一步步踏入深水区，或许不会出现「赢家通吃」的局面。&lt;/strong&gt;现如今，全球开源社区已经对 Agent 底层模型和执行框架进行了大量解构，该赛道几乎不存在「技术秘密」。主流大模型厂商都有能力自研出 Agent 产品，这样一来竞争的胜负手转向了场景垂直与生态适配。&lt;/p&gt;&lt;p&gt;昆仑万工早在 2025 年 5 月即发布了「AI 版 Office」&amp;mdash;&amp;mdash; 天工超级智能体（&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650970454&amp;idx=1&amp;sn=7b453aa27f07c6e6b897f3a73e815d67&amp;scene=21#wechat_redirect" target="_blank"&gt;Skywork Super Agents&lt;/a&gt;，即 Skywork 网页版），成为国内较早布局 Agent 的厂商，积累了丰富的办公场景效率优化经验，拥有了庞大的 AI 办公用户基础，并让他们对其产品有了很强的认知。&lt;/p&gt;&lt;p&gt;现在，Skywork 桌面版依托 Windows 这个全球最大生产力平台，灵活支持 Gemini 3 Pro 多模态与 Claude 4.5 逻辑推理能力，在继续对办公场景的效率优化以及与其他应用场景的联动中构筑起护城河。&lt;/p&gt;&lt;p&gt;在这场愈演愈烈的 Agent 之战中，谁能更快地建立起无法替代的相对优势，或许就是最后的赢家。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Attention真的可靠吗？上海大学联合南开大学揭示多模态模型中一个被忽视的重要偏置问题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 10:22:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/29adb014-f2c3-404c-a5a8-513f4619da0e/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近年来，Vision-Language Models（视觉 &amp;mdash; 语言模型）在多模态理解任务中取得了显著进展，并逐渐成为通用人工智能的重要技术路线。然而，这类模型在实际应用中往往面临推理开销大、效率受限的问题，研究者通常依赖 visual token pruning 等策略降低计算成本，其中 attention 机制被广泛视为衡量视觉信息重要性的关键依据。&lt;/p&gt;&lt;p&gt;近日，上海大学曾丹团队联合南开大学研究人员，从 attention 可靠性的角度出发，系统揭示了 Vision-Language Models 中普遍存在的 attention 偏置问题，并提出了一种无需重新训练的 attention 去偏方法，在多个主流模型、剪枝策略及图像与视频基准上验证了其有效性，为多模态模型的高效、可靠部署提供了新的思路。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGwzIrjPM0GgdxqXYqMGlJCXrU5ibEgqDzAicYj0kahDhtLFHjxntqh0Ag/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.17222222222222222" data-type="png" data-w="1080" data-width="1582" data-height="272" data-imgfileid="503531357" data-aistatus="1" data-original-style="background-color: transparent;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1205a911-344c-48e5-b637-35f0d834da7b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml6a4plr35o" data-pm-slice="0 0 []"&gt;论文标题：Attention Debiasing for Token Pruning in Vision Language Models&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://arxiv.org/abs/2508.17807&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml6a1f7d1u8d" data-pm-slice="0 0 []"&gt;代码链接：https://github.com/intcomp/attention-bias&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml6a5idrtp2" data-pm-slice="0 0 []"&gt;&lt;strong&gt;一、研究意义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;近年来，视觉 &amp;mdash; 语言模型（Vision-Language Models，VLMs）在图像理解、视觉问答、多模态对话等任务中表现突出，并逐渐成为通用人工智能的重要技术基础。然而，这类模型在实际部署时往往面临一个现实挑战：&lt;strong&gt;模型推理成本高，速度慢。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为提升效率，研究者通常会采用 &lt;u&gt;visual token pruning（视觉 token 剪枝） &lt;/u&gt;技术，即在不显著影响性能的前提下，丢弃不重要的视觉信息。其中，attention 机制 被广泛用作判断 &amp;ldquo;哪些视觉 token 更重要&amp;rdquo; 的核心依据。&lt;/p&gt;&lt;p&gt;但上海大学曾丹团队在研究中发现：&lt;strong&gt;attention 并不总是可靠的 &amp;ldquo;重要性指标&amp;rdquo;&lt;/strong&gt;。在多模态模型中，attention 往往受到多种结构性偏置的影响，这些偏置与真实语义无关，却会直接左右剪枝结果，从而影响模型性能。&lt;/p&gt;&lt;p&gt;针对这一问题，该团队系统分析了 VLM 中 attention 的行为特性，提出了一种 &lt;strong&gt;Attention Debiasing（注意力去偏）方法&lt;/strong&gt;，在无需重新训练模型的前提下，有效提升了多种主流剪枝方法的稳定性与可靠性。如下图所示，提出的方法应用于目前基于 attention 的剪枝方法上之后，都有提升。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGvDIibWffz5hHngZgXjq8LYYqVlejXvjjzCcL69evrxe33Dpk3VUgqAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8462962962962963" data-type="png" data-w="1080" data-width="2783" data-height="2354" data-imgfileid="503531358" data-aistatus="1" data-original-style="background-color: transparent;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7ffefe18-a7f1-4fe1-8f63-265ed8e8c2f6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;二、研究背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在直觉上，attention 机制往往被理解为 &amp;ldquo;模型更关注哪里&amp;rdquo;，因此被自然地视为语义重要性的体现。然而，曾丹团队的研究表明，在 Vision-Language Models 中，attention 往往并非只由内容决定，而是隐含着多种系统性偏置。&lt;/p&gt;&lt;p&gt;其中最典型的有两类：&lt;/p&gt;&lt;p&gt;第一类是 &lt;strong&gt;位置偏置（recency bias）&lt;/strong&gt;。研究发现，language-to-vision attention 会随着视觉 token 在序列中的位置不断增大，也就是说，模型更倾向于关注 &amp;ldquo;后面的 token&amp;rdquo;。如图所示，这通常表现为模型对图像下方区域给予更高 attention，即便这些区域并不包含关键信息。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG2whGlT1Gy65hCcWhRqSNAh1aVqUlsNKhqyVhFiag8c1xBY2n4YrDzEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4203703703703704" data-type="png" data-w="1080" data-width="1414" data-height="595" data-imgfileid="503531359" data-aistatus="1" data-original-style="background-color: transparent;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6b7cd923-ee59-45eb-8a88-129bebf79b17/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;第二类是&lt;strong&gt; padding 引发的 attention sink 现象&lt;/strong&gt;。在实际输入中，为了统一尺寸，图像往往需要 padding，但这些区域在语义上是 &amp;ldquo;空白&amp;rdquo; 的。然而，由于 hidden state 中出现异常激活，padding 对应的 token 反而可能获得较高 attention，从而被错误地保留下来。下图是 pad 区域填充不同的数值时，pad 区域对应的 attention score 数值以及 hidden states 的激活值。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGl5WPocMg79WcDliazzMje8C0G9vrXVDCGvcwCbQVfT7ia5kIqmeQxTaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4916666666666667" data-type="png" data-w="1080" data-width="2774" data-height="4137" data-imgfileid="503531360" data-aistatus="1" data-original-style="background-color: transparent;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/42ade913-7119-450b-b8d3-4dbff0a0b2de/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更值得注意的是，当 attention 被用于剪枝排序时，这些偏置并不会被削弱，反而会被进一步放大，最终导致剪枝结果偏离真实语义需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、研究方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对上述问题，上海大学曾丹团队并没有提出新的剪枝算法，也没有对模型结构进行修改，而是从一个更基础的角度出发：&lt;strong&gt;既然 attention 本身是有偏的，是否可以先对 attention 进行修正？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该团队观察到，attention 中的偏置并非随机噪声，而是呈现出&lt;strong&gt;稳定的整体趋势&lt;/strong&gt;。因此，他们通过对 attention 随 token 位置变化的趋势进行拟合，构建了一条反映 &amp;ldquo;位置偏置&amp;rdquo; 的曲线，并在此基础上对原始 attention 进行去偏修正，显式削弱与内容无关的位置因素，使 attention 更接近真实的语义重要性。如下图所示。&lt;/p&gt;&lt;p&gt;与此同时，在剪枝阶段显式抑制 padding token 的影响，避免语义为空的区域干扰剪枝排序。整个过程无需重新训练模型，也不依赖特定的剪枝策略，可作为 &lt;strong&gt;plug-and-play 模块&lt;/strong&gt; 直接集成到现有方法中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGxXJicJyvtNGh2zgSsRd0MgsT5hQZ9e7Et4jFJiaFFASjXR3SQd7riagHw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6111111111111112" data-type="png" data-w="1080" data-width="2800" data-height="1711" data-imgfileid="503531361" data-aistatus="1" data-original-style="background-color: transparent;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d5de95f5-3a76-4358-8218-11799230bc9b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验验证中，该团队将 Attention Debiasing 方法集成到 FastV、PyramidDrop、SparseVLM、HiMAP、TokenCarve、iLLaVA 等 6 种主流 attention-based 剪枝方法中，在 10 个图像理解基准与 3 个视频理解基准 上进行了系统评估，并覆盖 LLaVA-7B / 13B 等多种主流 Vision-Language Models。&lt;/p&gt;&lt;p&gt;实验结果表明，在几乎所有设置下，经过 attention 去偏修正后，剪枝模型都能获得一致且稳定的性能提升，且在剪枝更激进、token 预算更紧张的情况下效果尤为明显。这说明，对 attention 进行去偏处理，有助于模型在 &amp;ldquo;更少信息&amp;rdquo; 的条件下做出更可靠的判断。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGhfAOdzicic8nYUA8iaOKOwMpuCWYib6WC4wEQXPj14I9bslrKNUfD8tH2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7444444444444445" data-type="png" data-w="1080" data-width="5897" data-height="4389" data-imgfileid="503531362" data-aistatus="1" data-original-style="background-color: transparent;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/859ee5d0-f477-41b2-b4f9-fd4ac60cee03/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG4v0uiaSS5ia63KV2rrEbzdyw92a7x8Ckyy5lrplBISbqlR3iapkXicQewQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.762962962962963" data-type="png" data-w="1080" data-width="2749" data-height="2099" data-imgfileid="503531363" data-aistatus="1" data-original-style="background-color: transparent;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7c60104d-3a7c-47d3-9814-34447f582d6d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，通过对实验结果的可视化分析，原始 attention-based 剪枝方法往往保留了大量位于图像下方或 padding 区域的视觉 token，而与问题语义密切相关的关键区域却容易被忽略。引入 attention 去偏修正后，模型保留的视觉区域更加集中于目标物体及关键细节位置，有效减少了无关背景的干扰。该结果直观验证了 attention 去偏在提升剪枝合理性和可解释性方面的作用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGZVsJey8ibvLicV4cficZNVnj75bRlZAdV4ZAico69Y5Wj0zJ1t30p6z5Fg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-ratio="0.9805555555555555" data-type="jpeg" data-w="1080" data-width="10190" data-height="9988" data-imgfileid="503531364" data-aistatus="1" data-original-style="background-color: transparent;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d5aad272-5614-47c9-a79d-36ab7082e71e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;五、总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该研究表明，attention 并非天然等价于语义重要性，尤其在 Vision-Language Models 中，如果忽视 attention 中潜在的结构性偏置，基于 attention 的剪枝策略可能会被误导。上海大学曾丹团队通过简单而有效的 attention 去偏方法，显著提升了多模态模型在效率与可靠性之间的平衡能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大道至简，何恺明团队新作pMF开启像素级「无潜、单步」生成范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 03 Feb 2026 23:29:46 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;何恺明团队新论文，再次「大道至简」。&lt;/p&gt;&lt;p&gt;此次研究直指当前以 DiT 为代表的主流扩散模型与流匹配模型存在的通病，并&lt;strong&gt;提出了一种用于单步、无潜空间（Latent-free）的图像生成新框架&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531379" data-ratio="0.22685185185185186" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGnEx31ugHbKJ2T7VKvjY4fEAEUlKE9SxBDo8pNiatrfK52C5GMBafLrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7cdaf6f2-e045-41fa-85b5-0a303c848bd0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：One-step Latent-free Image Generation with Pixel Mean Flows&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;arXiv 地址：https://arxiv.org/pdf/2601.22158v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在生成式 AI 领域，追求更高效、更直接的生成范式一直是学界的核心目标。&lt;/p&gt;&lt;p&gt;当前，以 DiT 为代表的主流扩散模型与流匹配模型主要依赖两大支柱来降低生成难度，一是通过多步采样将复杂的分布转换分解为微小的步进，二是在预训练 VAE（变分自编码器）的潜空间中运行以降低计算维度。&lt;/p&gt;&lt;p&gt;尽管这些设计在图像质量上取得了巨大成功，但从深度学习「端到端」的精神来看，这种对多步迭代和预置编码器的依赖，无疑增加了系统的复杂性和推理开销。&lt;/p&gt;&lt;p&gt;面对这些挑战，&lt;strong&gt;何恺明团队提出了用于单步、无潜空间图像生成的 pixel MeanFlow（pMF）框架&lt;/strong&gt;。该框架继承了改进均值流（improved MeanFlow，MF）的思路，通过在瞬时速度（即 v）空间内定义损失函数，来学习平均速度场（即 u）。&lt;/p&gt;&lt;p&gt;与此同时，受 Just image Transformers（JiT）的启发，pMF 直接对类似于去噪图像的物理量（即 x-prediction 值）进行参数化，并预期该物理量位于低维流形上。&lt;/p&gt;&lt;p&gt;为了兼容这两种设计，团队引入了一种转换机制，将 v、u 和 x 三个场联系起来。实验证明，这种设计更符合流形假设，并且产生了一个更易于学习的目标（见下图 1）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGiaZggwV4geVZVVexd8RDtveqjEeHBVbkDfGTP9KtLJCaorMibVpG9hgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.42592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531380" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/eff7bbdd-aee4-4a7f-bc1f-2851979e49f6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;概括来说，&lt;strong&gt;pMF 训练了一个能将噪声输入直接映射为图像像素的网络&lt;/strong&gt;。它具备「所见即所得」的特性，而这在多步采样或基于潜空间的方法中是不存在的。这一特性使得感知损失能够自然地集成到 pMF 中，从而进一步提升生成质量。&lt;/p&gt;&lt;p&gt;实验结果显示，pMF 在单步、无潜空间生成方面表现强劲，在 ImageNet 数据集上，256x256 分辨率下的 FID 达到 2.22，512x512 分辨率下达到 2.48。团队进一步证明，选择合适的预测目标至关重要：在像素空间直接预测速度场会导致性能崩溃。&lt;/p&gt;&lt;p&gt;本文验证了：&lt;strong&gt;单步、无潜空间生成正变得既可行又具竞争力，这标志着向构建单一、端到端神经网络形式的直接生成建模迈出了坚实的一步。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;框架方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了实现单步、无潜空间的生成，团队引入了 pMF（pixel MeanFlow），它的核心设计在于建立 u、 v 和 x 这三个不同场之间的关联。团队希望网络能像 JiT 那样直接输出 x，而单步建模则像均值流 (MeanFlow) 一样在 u 和 v 空间内进行。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;去噪图像场&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;iMF 和 JiT 都可以被视为在最小化 v-loss，不同之处在于 iMF 执行的是 u-prediction，而 JiT 执行的是 x-prediction。团队在 u 与广义形式的 x 之间引入了一种联系。&lt;/p&gt;&lt;p&gt;原论文等式 (5) 中定义的平均速度场 u 代表了一个潜在的基准真值（ground-truth），它取决于 p_data、p_prior 以及时间调度，但与网络无关（因此不依赖于参数 &amp;theta;）。团队引出了一个定义为 x (z_t, r, t) 的新场：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGsRe2QvicnWiaM7lBXzSgut1uWI5UGPJlg3t0ElCubW2YtsZ7WovItPYQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.17777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531382" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c590c57f-1062-44eb-87f8-714e38d65016/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;可泛化的流形假设&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上图 1 通过模拟从预训练流匹配（FM）模型中获得的一条 ODE 轨迹，可视化了 u 场和 x 场。u 包含噪声图像，这是因为作为速度场，u 同时包含了噪声和数据成分。相比之下，x 场具有去噪图像的外观：它们或是近乎清晰的图像，或是因过度去噪而显得模糊的图像。接下来，团队讨论了如何将流形假设泛化到一物理量 x 上。&lt;/p&gt;&lt;p&gt;请注意，MeanFlow 中的时间步 r 满足：&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGmloB9m6Hvuv5UZqld1YWCbBBLtGFKKp7BFvuUlgECcZY4orITfdSCA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.2789115646258503" data-s="300,640" data-type="png" data-w="588" type="block" data-imgfileid="503531383" data-aistatus="1" data-original-style="width:60px;height:20px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2d1b0234-2e39-4e16-b18b-6eb82e41b4a8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 8.89%;"&gt;。团队首先展示了 r=t 和 r=0 这两种边界情况可以近似满足流形假设；随后讨论了 0＜r＜t 的情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上文公式 (8) 中导出的 x 场为 MeanFlow 网络提供了一种重参数化方法。具体而言，团队让网络 net_&amp;theta; 直接输出 x，并根据公式 (8) 计算出相应的速度场 u：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGUpJiaiaoaeaS4Cq2fwLSovA8JFkoTHiarE0hlZNeyqgwPRIgA4ZuVRNEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.1259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531385" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5cbdd4ec-323d-46cb-bcc6-ff46f78cc4af/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;接着将公式 (11) 中的 u_&amp;theta; 纳入 iMF 表述中，即结合 v-loss 使用原论文公式 (7)。具体的优化目标如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGzib2fw20CnBaiaMm87DFC4n1vicgA2HTsgqjDFrx2nFeiaiaf642f4f6wOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.1814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531387" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/eb696b0a-fa1d-4193-b494-683826b19080/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从概念上讲，这是基于 x-prediction 的 v-loss，其中 x 通过 x&amp;rarr;u&amp;rarr;v 的关系转换为 v 空间，从而对 v 进行回归。相应的伪代码见算法 1。遵循 iMF 的思路，该算法可以扩展以支持无分类器引导（CFG）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG3SHphiaLOj7vialBqcRD0yKiaNRUvo5lWibCRiahfia9FOlw6pib4A8jGulJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.0842592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531388" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/8371ae76-0235-41c5-8831-4b27954a7c94/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;带有感知损失的像素均值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;网络 x_&amp;theta;(z_t,r,t) 直接将噪声输入 z_t 映射为去噪图像，这使得模型在训练时具备了「所见即所得」的特性。因此团队进一步引入了感知损失，基于潜空间的方法在 tokenizer 重构训练中获益于感知损失，而基于像素的方法此前尚未能轻易利用这一优势。&lt;/p&gt;&lt;p&gt;在形式上，由于 x_&amp;theta; 是像素空间下的去噪图像，团队直接对其应用感知损失（例如 LPIPS ）。整体训练目标为&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG9fHW5ECmDuHXQS8Rno3ltaMf8n22iajGkpRMqZyAfnRrSDZu31vWcQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.16698292220113853" data-s="300,640" data-type="png" data-w="1054" type="block" data-imgfileid="503531389" data-aistatus="1" data-original-style="width:99px;height:20px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ec107187-a8f2-4bde-91ab-fb30097ee8b3/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 16.5%;"&gt;。在实践中，感知损失可以仅在所添加噪声低于特定阈值（即 t&amp;le;t_thr）时应用，从而确保去噪后的图像不会过于模糊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;玩具（Toy）实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;团队首先通过一个 2D 玩具实验表明，「当底层数据位于低维流形上时，在 MeanFlow 中使用 x-prediction 更加理想。」&lt;/p&gt;&lt;p&gt;图 2 显示，x-prediction 的表现相当出色，而随着维度 D 的增加，u-prediction 的性能迅速退化。团队观察到，这种性能差距反映在训练损失的差异上：x-prediction 的训练损失低于对应的 u-prediction。这表明，对于容量有限的网络而言，预测 x 更加容易。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGmQWCVvSX0wx0U3vZdSS3qNhTCbSGHXS1PGW7Lypz5PsUGAjIcH8ZCQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.9490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531390" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/81d0d120-56db-46ba-ad1f-a94fe9528279/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;团队默认在分辨率为 256x256 的 ImageNet 数据集上进行消融实验。团队采用了 iMF 架构，它是 DiT 设计的一个变体。除非另有说明，团队将 Patch 大小设置为 16&amp;times; 16（表示为 pMF/16）。消融模型从零开始训练了 160 个 Epoch。&lt;/p&gt;&lt;p&gt;关于&lt;strong&gt;网络预测目标&lt;/strong&gt;，团队的方法基于流形假设，即假设 x 处于低维流形中且更易于预测。表 2 验证了这一假设。&lt;/p&gt;&lt;p&gt;首先将 64&amp;times;64 分辨率作为较简单的设置。当 Patch 大小为 4&amp;times;4 时，Patch 维度为 48（即 4&amp;times;4&amp;times;3）。这一维度远低于网络容量（隐藏层维度为 768）。因此，pMF 在 x-prediction 和 u-prediction 下均表现良好。&lt;/p&gt;&lt;p&gt;接下来考虑 256&amp;times;256 分辨率。按照惯例，Patch 大小设为 16&amp;times;16，Patch 维度达到 768（即 16&amp;times;16&amp;times;3）。这导致了更高维的观测空间，增加了神经网络建模的难度。在这种情况下，只有 x-prediction 表现良好，表明 x 位于更低维的流形上，因此更易于学习。&lt;/p&gt;&lt;p&gt;相比之下，u-prediction 性能彻底崩溃：作为一种含噪物理量，u 在高维空间中具有全支撑，建模难度大得多。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGc3M6Ga5IcYwlndpVaUL76THvbn918Zl9o2saAOWfqHlial8lYIZbgTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6620370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531392" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c5eb6454-e10c-48cc-9da0-0346b9e0c0a0/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;关于&lt;strong&gt;高分辨率生成&lt;/strong&gt;，团队在表 4 中研究了分辨率在 256、512 和 1024 下的 pMF。在保持序列长度不变（16^2）的情况下，不同分辨率下大致维持了相同的计算成本。这样做会导致极其激进的 Patch 大小（例如 64^2）和 Patch 维度（例如 12288）。&lt;/p&gt;&lt;p&gt;结果显示，pMF 可以有效处理这种极具挑战性的情况。尽管观测空间是高维的，但模型始终预测 x，其底层维度并不会成比例增长。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGTW39eRCUkxBBG3v9icaZV8iaibg0WLCgYwB3cBxfI2CSNy5hJEZFNgKHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.42962962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531394" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/a8923ea0-9727-40db-996c-8acdb89902a1/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;关于&lt;strong&gt;可扩展性&lt;/strong&gt;，团队在表 5 中报告了增加模型大小和训练 Epoch 的结果。正如预期的那样，pMF 从这两个维度的扩展中均有获益。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531395" data-ratio="0.3287037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGIAIBmkrhaVshqGIoPNa3x4hg2e9LMyVQd4tNus0HcRR4IRJmPpuRicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/cb79cae6-c0b7-408c-8363-4d219e2374e3/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最后，团队在表 6（256&amp;times;256）和表 7（512&amp;times;512）中 ，将 pMF 与之前的模型进行了对比。&lt;/p&gt;&lt;p&gt;其中，在 &lt;strong&gt;256&amp;times;256 分辨率&lt;/strong&gt;下，团队的方法达到了 2.22 FID（在 360 个 Epoch 时），如表 6 所示。据团队的了解，该类别中（单步、无潜空间扩散 / 流模型）唯一的其他方法是最近提出的 EPG，它在自监督预训练下达到了 8.82 FID。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531396" data-ratio="1.4333333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGAzGxib26ChlxwXnehtbUpzbRiaiboRcNoGtUf6FMuLHbich8oceZKVSrQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/d0319ca4-822b-47dc-8b69-23729eea6e43/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在&lt;strong&gt; 512&amp;times;512 分辨率&lt;/strong&gt;下，pMF 达到了 2.48 FID，如表 7 所示。这一结果的计算成本（参数量和 Gflops）与 256&amp;times;256 版本相当。事实上，唯一的额外开销仅来自通道数更多的 Patch 嵌入层和预测层，所有的 Transformer 模块都维持了相同的计算成本。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531398" data-ratio="1.0935185185185186" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGQnibzC3u1TFsvAIFHZDOJXZ64kIkicHk0w16o3zVRmyyICI7ZdISf8fg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/011aa59e-9ccf-45ff-80d8-e59f0bc90c94/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;更多实验细节请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
