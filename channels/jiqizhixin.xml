<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>黄仁勋CES放出大杀器：下一代Rubin架构推理成本降10倍</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 06 Jan 2026 10:29:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/cba512b8-400a-478d-a619-34375fdca2e9/1767666256601.png" style="width: 700%;" class="fr-fic fr-dib"&gt;「每隔 10 到 15 年，计算行业就会革新一次，每次都会催生出新形态的平台。现在，有两个转变在同时进行：应用将会构建于 AI 之上，你构建软件的方式也将改变。」&lt;/p&gt;&lt;p&gt;就在今天凌晨，在拉斯维加斯 CES 2026 展会现场，英伟达创始人黄仁勋身穿经典皮衣现身！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNbsygCawhXjoy7wtjSWMh99k7yN8eFoyoNSjwuAWhp3EPksJVbdOE1g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="0.5833333333333334" data-s="300,640" data-type="gif" data-w="600" type="block" data-imgfileid="503526871" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/cab191c0-9eab-4c0a-a455-f7a8e8e64f00/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;黄仁勋展示的第一张幻灯片是：「人工智能的发展超越了大型语言模型。」&lt;/p&gt;&lt;p&gt;随着大语言模型技术的进步，未来的物理世界 AI 将可以理解真实世界的结构，独立完成任务，并随着时间的推移进行学习。他表示，「宇宙中任何存在信息、任何存在结构的地方」都可以用来训练人工智能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNsjYLSpibnwTAmc6QP4YsiaN51NgibM7vQ6RtEd8q8f5ED3G8R6pzibWd7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5472222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526872" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d712ff59-c896-4c50-9159-e6be0f698337/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;老黄分享了下一代加速计算与人工智能将如何变革每一个行业，并一一介绍了英伟达在芯片、人工智能模型、开源开放等领域的最新进展，主要包括如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;下一代 Rubin 平台；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;全新的视觉 - 语言 - 动作模型（VLA）&amp;mdash;&amp;mdash;Alpamayo 1；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;面向物理 AI 的新开放模型、框架和 AI 基础设施。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不仅包括新一代 GPU，也有引领业界的开源 AI 模型。可见到了 2026 年，英伟达正准备以全栈的形式引领技术发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Rubin 平台问世 &amp;mdash;&amp;mdash; 六款全新芯片，一台划时代 AI 超算&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNPha14khESe4Xc7JrV0wHMeSfJib9u4ffWOjYBdRkNw6Fe4a9FPWicukg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526873" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8fdc2f2f-e9de-4b9e-8e19-c51d28603f08/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;首先，最引人关注的是下一代计算架构 &amp;mdash;&amp;mdash;NVIDIA Rubin 平台，刚刚推出的六款全新芯片，目标是构建一台在成本、性能与安全性上全面领先的 AI 超级计算机，加速 AI 在主流场景中的落地。&lt;/p&gt;&lt;p&gt;这六款芯片包括：NVIDIA Vera CPU、NVIDIA Rubin GPU、NVIDIA NVLink 6 Switch、NVIDIA ConnectX-9 SuperNIC、NVIDIA BlueField-4 DPU 和 NVIDIA Spectrum-6 Ethernet Switch，极致的协同设计，将大幅缩短训练时间，降低推理 Token 成本。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN43HibCI7IlticoXWDZF6P7xLJ1cNVsyatxMibj5ELhYAUqyF4RPGX3aZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6898148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526874" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5712c4f8-a4b5-4daf-a218-404242f83f7b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;「Rubin 的到来恰逢其时，因为训练和推理的 AI 计算需求正在激增，」黄仁勋表示，「我们以每年一代 AI 超级计算机的节奏持续前进，而 Rubin 通过六款全新芯片的极致协同设计，向 AI 的下一个前沿迈出了关键一步。」&lt;/p&gt;&lt;p&gt;据了解，Rubin 平台以美国天文学家 Vera Florence Cooper Rubin 命名，她的研究彻底改变了人类对宇宙的认知。该平台包括 NVIDIA Vera Rubin NVL72 机架级解决方案和 NVIDIA HGX Rubin NVL8 系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNVMLRFVsNvScA69Olxpe1h0micUFOnGVOLgn3v2bUTiaqsUBTMWqs4GJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526875" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5750f298-f908-449d-971b-f5bd85c854ad/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Rubin 平台引入了五项创新，包括最新一代 NVIDIA NVLink 互连技术、Transformer 引擎、机密计算和 RAS 引擎，以及 NVIDIA Vera CPU。这些突破将加速智能体 AI、高级推理和大规模混合专家（MoE）模型推理，其每 Token 成本比 NVIDIA Blackwell 平台低高达 10 倍。与前代产品相比，NVIDIA Rubin 平台训练 MoE 模型所需的 GPU 数量减少了 4 倍，从而加速了 AI 普及。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;专为扩展智能而生&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智能体 AI 和推理模型，以及最先进的视频生成工作负载，正在重新定义计算的极限。多步问题解决需要模型在长序列 Token 中处理、推理和行动。旨在满足复杂 AI 工作负载需求的 Rubin 平台包含五项突破性技术：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;第六代 NVIDIA NVLink&lt;/strong&gt;：提供当今大规模 MoE 模型所需的快速、无缝的 GPU 到 GPU 通信。每个 GPU 提供 3.6TB/s 的带宽，而 Vera Rubin NVL72 机架总带宽高达 260TB/s，比整个互联网的带宽还多。凭借用于加速集体操作的内置网内计算，以及用于增强可维护性和弹性的新功能，NVIDIA NVLink 6 switch 可实现更快、更高效的大规模 AI 训练和推理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;NVIDIA Vera CPU&lt;/strong&gt;：专为智能体推理设计的 NVIDIA Vera 是大型 AI 工厂中最节能的 CPU，采用 88 个英伟达自研 Olympus 核心，完全兼容 Armv9.2，并具有超快的 NVLink-C2C 连接。Vera 提供卓越的性能、带宽和行业领先的效率，可支持全方位的现代数据中心工作负载。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;NVIDIA Rubin GPU&lt;/strong&gt;：配备具有硬件加速自适应压缩的第三代 Transformer 引擎，Rubin GPU 可为 AI 推理提供 50 petaflops 的 NVFP4 计算能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;第三代 NVIDIA 机密计算&lt;/strong&gt;：Vera Rubin NVL72 是首个提供英伟达机密计算的机架级平台，可在 CPU、GPU 和 NVLink 域之间维护数据安全，保护全球最大的专有模型、训练和推理工作负载。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;第二代 RAS 引擎&lt;/strong&gt;：Rubin 平台涵盖 GPU、CPU 和 NVLink，具有实时健康监测、容错和主动维护功能，可最大限度地提高系统生产力。机架的模块化、无线缆设计使组装和维护速度比 Blackwell 快高达 18 倍。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;AI 原生存储和安全、软件定义基础设施&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Rubin 平台引入了 NVIDIA 推理上下文内存存储平台，这是面向千亿级推理上下文规模（gigascale） 设计的新一代 AI 原生存储架构。&lt;/p&gt;&lt;p&gt;该平台由 NVIDIA BlueField-4 驱动，可在 AI 基础设施中实现 KV Cache 数据的高效共享和重用，提高响应能力和吞吐量，同时实现可预测、能效友好的智能体 AI 扩展。&lt;/p&gt;&lt;p&gt;BlueField-4 还引入了高级安全可信资源架构（ASTRA），这是一种系统级信任架构，可为 AI 基础设施构建者提供统一、可信的控制点，以便在不影响性能的情况下安全预置、隔离和操作大规模 AI 环境。&lt;/p&gt;&lt;p&gt;随着 AI 应用向多轮智能体推理发展，AI 原生组织必须在用户、会话和服务之间管理和共享更多推理上下文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;针对不同工作负载的不同形态&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA Vera Rubin NVL72 提供了一个统一、安全的系统，集成了 72 个 NVIDIA Rubin GPU、36 个 NVIDIA Vera CPU、NVIDIA NVLink 6、NVIDIA ConnectX-9 SuperNIC 和 NVIDIA BlueField-4 DPU。&lt;/p&gt;&lt;p&gt;英伟达还将推出 NVIDIA HGX Rubin NVL8 平台，这是一款服务器主板，可通过 NVLink 连接八个 Rubin GPU，以支持基于 x86 的生成式 AI 平台。HGX Rubin NVL8 平台可加速 AI 和高性能计算工作负载的训练、推理和科学计算。&lt;/p&gt;&lt;p&gt;NVIDIA DGX SuperPOD 可作为大规模部署基于 Rubin 系统时的参考，它集成了 NVIDIA DGX Vera Rubin NVL72 或 DGX Rubin NVL8 系统，并搭配 NVIDIA BlueField-4 DPU、NVIDIA ConnectX-9 SuperNIC、NVIDIA InfiniBand 网络和 NVIDIA Mission Control 软件。&lt;/p&gt;&lt;p&gt;NVIDIA Spectrum-6 以太网是下一代 AI 网络以太网，旨在以更高的效率和更强的弹性扩展基于 Rubin 的 AI 工厂，并由 200G SerDes 通信电路、共封装光学器件和 AI 优化结构提供支持。&lt;/p&gt;&lt;p&gt;基于 Spectrum-6 架构，Spectrum-X 以太网光子共封装光交换系统可为 AI 应用提供 10 倍的可靠性和 5 倍的更长正常运行时间，同时实现 5 倍的更高能效，与传统方法相比，每瓦性能最大化。Spectrum-XGS 以太网技术是 Spectrum-X 以太网平台的一部分，可使相距数百公里甚至更远的设施作为一个统一的 AI 环境运行。&lt;/p&gt;&lt;p&gt;这些创新共同定义了下一代 NVIDIA Spectrum-X 以太网平台，该平台采用与 Rubin 极致协同设计，旨在实现大规模 AI 工厂，并为未来的百万 GPU 环境铺平道路。 Rubin 准备就绪&lt;/p&gt;&lt;p&gt;NVIDIA Rubin 已全面投产，基于 Rubin 的产品将于 2026 年下半年通过合作伙伴上市。&lt;/p&gt;&lt;p&gt;首批在 2026 年部署基于 Vera Rubin 实例的云服务提供商包括 AWS、Google Cloud、微软和 OCI，以及英伟达云合作伙伴 CoreWeave、Lambda、Nebius 和 Nscale。&lt;/p&gt;&lt;p&gt;CoreWeave 将与英伟达合作，帮助 AI 领域的先驱者充分利用 Rubin 在推理和 MoE 模型方面的进步，此外，思科、戴尔、HPE、联想和 Supermicro 预计将推出基于 Rubin 产品的服务器。&lt;/p&gt;&lt;p&gt;包括 Anthropic、Black Forest、Cohere、Cursor、Harvey、Meta、Mistral AI、OpenAI、OpenEvidence、Perplexity、Runway、Thinking Machines Lab 和 xAI 在内的 AI 实验室正在寻求利用 NVIDIA Rubin 平台来训练更大、功能更强大的模型，并以比前几代 GPU 更低的延迟和成本运行长上下文、多模态系统。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增强自动驾驶推理， Alpamayo 1 开源模型来了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;英伟达认为，下一代面向 L4 的自动驾驶方案，需要基于拥有强推理性能的 VLA 模型。&lt;/p&gt;&lt;p&gt;英伟达今日发布了 &lt;strong&gt;NVIDIA Alpamayo 系列开源 AI 模型、仿真工具及数据集&lt;/strong&gt;，旨在加速下一代安全、基于推理的自动驾驶汽车（AV）开发。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNiclzAeSGOd7MsofeUMTFguX82ModyRcdLibI6miaUNAbY2PrPrGtfDhHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526876" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/599c1ec0-5779-404b-a160-126e845aca1d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;自动驾驶汽车必须在极其广泛的驾驶条件下安全运行。那些稀少且复杂的场景（通常被称为「长尾问题」），依然是自动驾驶系统安全掌控的最严峻挑战之一。&lt;/p&gt;&lt;p&gt;传统的自动驾驶架构将感知与规划分离，当遇到全新或异常情况时，这种方式会限制系统的可扩展性。&lt;/p&gt;&lt;p&gt;虽然端到端学习在近期取得了显著进展，但要克服这些长尾极端案例，仍需要模型能够针对因果关系进行安全推理，尤其是在情况超出模型训练经验时。&lt;/p&gt;&lt;p&gt;Alpamayo 系列引入了&lt;strong&gt;基于思维链推理的视觉语言动作（VLA）模型&lt;/strong&gt;，为自动驾驶决策带来了类似人类的思考方式。&lt;/p&gt;&lt;p&gt;这些系统可以分步骤思考新颖或罕见的场景，从而提升驾驶能力和可解释性。可解释性对于增强智能汽车的信任度与安全性至关重要。此外，该系列还得到了英伟达 Halos 安全系统的底层支持。&lt;/p&gt;&lt;p&gt;黄仁勋表示：「&lt;strong&gt;物理 AI 的 ChatGPT 时刻已经到来，机器开始理解、推理并对现实世界采取行动。&lt;/strong&gt;」&lt;/p&gt;&lt;p&gt;他接着说，Alpamayo 为自动驾驶汽车带来了推理能力，使它们能够思考罕见场景，在复杂环境中安全驾驶，并解释其驾驶决策。这些都是实现安全、可扩展自主驾驶的基石。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建基于推理的自主驾驶完整开源生态&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Alpamayo 将三大支柱（开源模型、仿真框架和数据集）整合为一个内聚的开放生态系统，任何汽车开发商或研究团队都可以在此基础上进行开发。&lt;/p&gt;&lt;p&gt;不过，Alpamayo 模型并非直接在车端运行，而是作为大规模的「教师模型」。开发者可以对其进行微调和蒸馏，转化为各自完整自动驾驶技术栈的核心骨架。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Alpamayo 1：全球首个面向自动驾驶汽车的开源大规模推理视觉语言动作（VLA）模型&lt;/strong&gt;，不仅能让车辆深度理解周围环境，还能对其采取的驾驶行为给出合理解释。现已在 Hugging Face 上线。&lt;/p&gt;&lt;p&gt;Alpamayo 1 采用 100 亿参数架构，通过视频输入生成行驶轨迹及推理痕迹，展示每项决策背后的逻辑。开发者可以将 Alpamayo 1 改编为适合车辆开发的小型运行模型，或将其作为自动驾驶开发工具（如基于推理的评估器和自动标注系统）的基础。&lt;/p&gt;&lt;p&gt;Alpamayo 1 提供开放的模型权重和开源推理脚本。该系列未来的模型将具备更大的参数量、更详细的推理能力、更灵活的输入输出选项以及商业化用途。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AlpaSim：一个完全开源的端到端高保真自动驾驶开发仿真框架&lt;/strong&gt;，可在 GitHub 上获取。它提供逼真感知的传感器建模、可配置的交通动态以及可扩展的闭环测试环境，能够实现快速验证和策略优化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;物理 AI 开源数据集&lt;/strong&gt;：英伟达提供了最多样化的大规模自动驾驶开源数据集，包含超过 1700 小时的驾驶数据。这些数据采集自极其广泛的地域和环境，涵盖了对于推进推理架构至关重要的稀有且复杂的现实极端案例。这些数据集现已在 Hugging Face 上线。&lt;/p&gt;&lt;p&gt;这些工具共同构成了一个自我强化的开发闭环，助力构建基于推理的自动驾驶技术栈。&lt;/p&gt;&lt;p&gt;Alpamayo 已经得到了自动驾驶行业的广泛支持。包括 Lucid、捷豹路虎（JLR）、Uber 和 Berkeley DeepDrive 在内的出行领军者，都对利用 Alpamayo 开发基于推理的自动驾驶技术栈表示了浓厚兴趣，以实现 L4 级自动驾驶。&lt;/p&gt;&lt;p&gt;在 Keynote 上，老黄展示了奔驰新款 CLA 在旧金山市区点到点的全自动驾驶，英伟达表示，国内的一些汽车厂商如吉利和小米也会在晚些时候接入英伟达的智能驾驶模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全新物理 AI 模型，与全球合作伙伴推出新一代机器人&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNUKkM0Gp7mke4yehCJHIgKyPMmiaIHAThjyyibvU1Gb5bljceK9uA6ncw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526877" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/468429c7-d1bd-48b1-94f6-9f8138f54ca8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;英伟达宣布推出针对物理人工智能（Physical AI）的全新开源模型、框架及 AI 基础设施，并携手全球合作伙伴展示了涵盖各行各业的机器人。&lt;/p&gt;&lt;p&gt;这些新技术加速了机器人开发全生命周期的工作流，助力开启下一波机器人浪潮，其中包括构建能够快速学习多项任务的通用型专家机器人。&amp;nbsp;&lt;/p&gt;&lt;p&gt;包括波士顿动力、Caterpillar、Franka Robotics、Humanoid、LG 电子和 NEURA Robotics 在内的全球行业领军企业，正利用英伟达机器人技术栈推出全新的 AI 驱动型机器人。&lt;/p&gt;&lt;p&gt;黄仁勋表示：机器人的「ChatGPT 时刻」已经到来。物理 AI 领域的突破 &amp;mdash;&amp;mdash; 即能够理解现实世界、进行推理并规划行动的模型 &amp;mdash;&amp;mdash; 正在开启全新的应用场景。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNqvf4NIXiaibTfScGDBDguF4sWo0iaKvXh0RTibpYxgZvN02emhZvIHmj5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526878" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/db1720e1-994e-43bd-8abd-07f36775c465/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;新型开放模型推动机器人学习与推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将当今成本高昂、任务单一且编程困难的机器转变为具有推理能力的通用型专家机器人，需要巨大的资本投入和构建基础模型的专业知识。&amp;nbsp;&lt;/p&gt;&lt;p&gt;英伟达正在构建开源模型，让开发者能够绕过耗费资源的预训练阶段，专注于创造下一代 AI 机器人。这些模型均可在 Hugging Face 上获取，包括：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NVIDIA Cosmos Transfer 2.5 与 NVIDIA Cosmos Predict 2.5&lt;/strong&gt;：开源、完全可定制的世界模型，可生成符合物理定律的合成数据，并在模拟环境中对物理 AI 的机器人策略进行评估。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NVIDIA Cosmos Reason 2&lt;/strong&gt;：一款开源推理视觉语言模型（VLM），使智能机器能够像人类一样观察、理解并在物理世界中采取行动。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NVIDIA Isaac GR00T N1.6&lt;/strong&gt;：一款专为人形机器人设计的开源推理视觉语言动作（VLA）模型，可实现全身控制，并利用 NVIDIA Cosmos Reason 获得更好的推理和情境理解能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;助力机器人开发的全新开源模拟与计算框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;可扩展的模拟对于机器人的训练和评估至关重要，但当前的工作流依然零散且难以管理。基准测试通常依赖人工，难以规模化，而端到端流水线则需要在不同的计算资源之间进行复杂的协调。&amp;nbsp;&lt;/p&gt;&lt;p&gt;英伟达今日在 GitHub 上发布了全新的开源框架，简化了这些复杂的流程，加速了从研究到实际应用场景的转化。&amp;nbsp;&lt;/p&gt;&lt;p&gt;NVIDIA Isaac Lab-Arena 是一个在 GitHub 上提供的开源框架，为模拟环境中的大规模机器人策略评估和基准测试提供了一个协作系统，其评估层和任务层是与 Lightwheel 紧密合作设计的。它连接了 Libero 和 Robocasa 等行业领先的基准，实现了测试标准化，确保机器人技能在部署到物理硬件之前稳健可靠。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaNXPvRayHKHFR0VYGYJk1lriaOVN5tZlNUTvvpQBXsBicuAa4eBRtU7fAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.7657407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526879" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/4e59b171-5223-4a90-a196-4be30696da17/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Isaac Lab-Arena 框架概览&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;NVIDIA OSMO 是一款云原生编排框架，将机器人开发统一到一个易于使用的中心控制台中。OSMO 允许开发者在从工作站到混合云实例的不同计算环境中，定义并运行合成数据生成、模型训练及软件在环测试等工作流，从而缩短开发周期。&amp;nbsp;&lt;/p&gt;&lt;p&gt;OSMO 正在被 Hexagon Robotics 等开发者使用，并已集成到微软 Azure Robotics Accelerator 工具链中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicXs2As91d0ugEiarVKrDQiaN7sFUw06xWxibknbQkiahoq10RXU1wzO1a9A58684iaicibDIz0YnlxK6y2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5027777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526880" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/b592dd20-8df7-499c-8731-3aad013e7884/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; OSMO 框架概览&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;携手 Hugging Face 加速开源物理 AI 发展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;机器人目前是 Hugging Face 上增长最快的类别，英伟达的开源模型和数据集在蓬勃发展的开源社区中下载量遥遥领先。&lt;/p&gt;&lt;p&gt;为了进一步支持该社区，英伟达正与 Hugging Face 合作，将开源的 Isaac 和 GR00T 技术集成到领先的 LeRobot 开源机器人框架中，提供更便捷的软硬件工具访问，加速端到端开发。&lt;/p&gt;&lt;p&gt;此次合作将英伟达的 200 万机器人开发者与 Hugging Face 的 1300 万 AI 构建者连接在一起。 GR00T N 系列模型和 Isaac Lab-Arena 现已在 LeRobot 库中上线，方便用户进行微调和评估。&lt;/p&gt;&lt;p&gt;Hugging Face 的开源人形机器人 Reachy 2 将与 NVIDIA Jetson Thor 机器人计算机完全互操作，支持开发者运行包括 GR00T N1.6 在内的任何 VLA 模型。&lt;/p&gt;&lt;p&gt;此外，Hugging Face 的开源桌面机器人 Reachy Mini 也与 NVIDIA DGX Spark 完全互操作，可利用本地运行的英伟达大语言模型、语音及视觉模型构建自定义体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人形机器人开发者采用 NVIDIA Jetson Thor&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA Jetson Thor 能够满足人形机器人推理所需的庞大算力。在 CES 上，人形机器人开发者展示了集成 Jetson Thor 的最新顶尖机器人。&amp;nbsp;&lt;/p&gt;&lt;p&gt;其中，NEURA Robotics 推出了保时捷设计的三代人形机器人，以及一款针对灵巧控制优化的迷你人形机器人。Richtech Robotics 推出了 Dex，这是一款可在复杂工业环境中进行精细操作和导航的移动人形机器人。&lt;/p&gt;&lt;p&gt;智元机器人（AGIBOT）介绍了面向工业和消费领域的人形机器人，以及集成了 Isaac Sim 的机器人仿真平台 Genie Sim 3.0。&lt;/p&gt;&lt;p&gt;LG 电子则展示了一款旨在执行多种室内家务的新型家用机器人。 波士顿动力、Humanoid 和 RLWRLD 均已将 Jetson Thor 集成到现有人形机器人中，以增强其导航和操作能力。&lt;/p&gt;&lt;p&gt;更多细节信息请参考英伟达官方博客。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://nvidianews.nvidia.com/news/alpamayo-autonomous-vehicle-development&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://nvidianews.nvidia.com/news/nvidia-releases-new-physical-ai-models-as-global-partners-unveil-next-generation-robots?linkId=100000401170428&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.youtube.com/watch?v=0NBILspM4c4&amp;amp;t=3s&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>检索做大，生成做轻：CMU团队系统评测RAG的语料与模型权衡</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 06 Jan 2026 10:21:55 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-06</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-06</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/735cef40-a694-443c-900f-b30333bc85f7/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在检索增强生成中，扩大生成模型规模往往能提升准确率，但也会显著抬高推理成本与部署门槛。CMU 团队在固定提示模板、上下文组织方式与证据预算，并保持检索与解码设置不变的前提下，系统比较了生成模型规模与检索语料规模的联合效应，发现扩充检索语料能够稳定增强 RAG，并在多项开放域问答基准上让小中型模型在更大语料下达到甚至超过更大模型在较小语料下的表现，同时在更高语料规模处呈现清晰的边际收益递减。更进一步，研究不仅刻画了随语料扩容而变化的性能增益，也揭示了若干相对稳定的不变规律。&lt;/p&gt;&lt;p&gt;在开放域问答等知识密集型任务中，检索增强生成（RAG）已经成为主流范式之一。它通过先检索外部文档，再让大语言模型基于证据生成答案，从而缓解纯参数记忆带来的幻觉与事实错误。然而，近年来提升 RAG 的常见路径往往集中在扩大生成模型规模，准确率确实会上升，但推理成本与部署门槛也随之显著提高。对于希望在有限算力下落地的系统而言，一个更现实的问题是：在不继续扩大模型参数的前提下，是否还有同样有效的提升空间。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibRJicC4EauATIPzAicM69uEwSH2lHW6qLugM52G8zs1XMG0DVc2ekUhuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.37407407407407406" data-type="png" data-w="1080" data-width="1955" data-height="732" data-imgfileid="503526749" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/fcbc88b6-13c4-4e5a-952a-36cbde736579/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;卡内基梅隆大学计算机学院团队&lt;/strong&gt;在最新 ECIR 接收论文中给出了一个清晰的回答。他们把关注点从更大的模型转向更大的检索语料，系统评估了语料规模与生成模型规模之间的替代关系，并提出了可操作的权衡框架。核心观点为，扩大检索语料通常可以显著增强 RAG，且在不少设置下，这种增强效果可以部分替代扩大模型参数带来的收益，但在更大语料规模处会出现边际收益递减。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibxJGr8px19b2LxtGe7CxGj3jrUf46vpib7gULqC5cYa83nAnrmR3MYxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.36036036036036034" data-s="300,640" data-type="png" data-w="777" type="block" data-imgfileid="503526754" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/76a260c5-477e-42f9-8280-01683bccc45e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Less LLM, More Documents: Searching for Improved RAG&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2510.02657&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从问题出发：RAG 的另一条扩展轴&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RAG 的效果由两部分共同决定。检索模块负责把可能包含答案的证据送到模型上下文中；生成模型负责理解问题、整合证据并形成答案。扩大模型参数能够提升推理与表达能力，但检索端提供的证据质量与覆盖范围，往往直接决定模型是否有机会看到答案线索。CMU 团队指出，检索语料的规模本身就是一条独立的扩展轴，但长期以来缺少与模型规模联合控制变量的系统研究，因此语料扩容能否补偿小模型仍缺乏定量结论。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验设计：只让两个变量变化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为得到可解释的权衡曲线，研究采用了全因子设计，只让语料规模与模型规模变化，其余保持一致。检索语料选用大规模搜索引擎数据集 ClueWeb22-A 的英文子集，总计包含约 2.64 亿真实网页文档，并将其随机均衡切分为 12 个 shard。语料规模用激活 shard 的数量表示，逐步从 1 个 shard 扩展到 12 个 shard。检索端使用 MiniCPM-Embedding-Light 做稠密向量编码，后端采用 DiskANN 构建多 shard 近邻检索，固定 top 文档数、切块与重排策略，最终向生成模型提供固定数量的 top chunk 作为 LLM 答案生成证据。&lt;/p&gt;&lt;p&gt;生成端选用最新 Qwen3 同一模型家族的不同尺寸，覆盖从 0.6B 到 14B 的 Qwen3 模型，并固定提示模板与解码设置，以确保比较只反映规模变化带来的差异。评测任务覆盖三个开放域问答基准：Natural Questions、TriviaQA 与 Web Questions，指标采用最常用的 F1 与 ExactMatch。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键发现一：语料扩容可以让小模型追上大模型（变）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验结果展示了明确的补偿效应。以 Natural Questions 为例，随着语料从 1 个 shard 扩展到更大规模，较小模型的 EM 与 F1 持续提升，并在一定语料规模后达到或超过更大模型在小语料上的基线表现。研究用 n 星指标刻画补偿阈值，即小模型需要多少倍语料才能追平大模型在 1 个 shard 下的成绩。在三个数据集上，这一阈值呈现出稳定模式：中等规模模型之间的追平往往只需要把语料扩大到 2 倍或 3 倍，而最小模型想追平下一档模型则需要更高倍数的语料扩容。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaib7JekFMn2uRUfINF9YQicTee5wtY6qb2PeRyaaHHCnSunFoKmicXy1G9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.35462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526750" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8938b776-1af0-44ef-b871-e52157a7a05c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更重要的是，这种追平并非个别现象。研究在 TriviaQA 与 WebQuestions 上观察到相同趋势，并给出了跨数据集的阈值表，显示语料扩容在多数设置下都能把性能缺口缩小到一个模型档位，甚至两个档位。对部署而言，这意味着当推理预算难以支撑更大参数模型时，把资源投入到更大语料与更强检索，可能是更务实的提效方向。&lt;/p&gt;&lt;p&gt;在增长形态上，研究观察到几乎与模型规模无关的共同曲线。最显著的提升发生在从无检索到有检索的第一步，随后随着语料继续扩大，收益逐步下降，并在约 5 到 6 倍语料规模附近出现饱和趋势。这一现象对工程实践具有直接意义：检索能力的从无到有往往带来最大增益，但在较高语料规模处继续无上限扩容并不划算，应该结合吞吐、延迟与存储成本做更精细的预算分配。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键发现二：提升主要来自证据覆盖，而非模型更会用证据（不变）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;语料变大为什么能带来提升？论文给出的机制解释相对直接且符合直觉预期：语料扩容提高了检索到含答案片段的概率。当语料规模较小时，检索到的片段经常只与主题相关，但不包含关键事实；随着语料扩大，更容易检索到明确包含答案字符串的证据片段，生成模型因此获得更可靠的落脚点。&lt;/p&gt;&lt;p&gt;为把这种直觉量化，研究定义了 Gold Answer Coverage Rate，用于统计传入生成模型的 top chunk 中至少有一个包含标准答案字符串的概率。结果显示，覆盖率随语料规模增长而单调上升，并在不同数据集上体现出差异性，例如 TriviaQA 的覆盖率整体更高，反映其信息需求与网页语料的重合度更强。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibjibUZEicNfvsnKx7zq6e36SicDqTibKLxnZQlbu3Q4PUxr29df7esYXwMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5" data-type="png" data-w="1080" data-width="3000" data-height="1500" data-imgfileid="503526751" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/65d3b0c8-be7d-4cf0-8509-30a391090ee3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;进一步地，研究提出 Context Benefited Success Rate，用于衡量那些在无检索时无法答对的问题，在加入检索证据后被答对的比例，并用 Utilization Ratio 将其与覆盖率相除，以刻画模型把可用证据转化为正确答案的效率。实验显示，Utilization Ratio 在不同语料规模下整体保持稳定，且在不同模型尺寸之间差异有限。结合无检索设置下的基线表现可以看到，不同大小模型的主要差别更多来自其参数中可直接调用的内部知识储备，使其在无需外部证据时也能回答一部分问题；而对于那些无法仅凭内部知识答对的问题，一旦检索端提供了包含答案线索的证据，不同模型将证据转化为正确答案的效率整体相近。因此，语料扩容带来的关键收益主要体现在提高含答案证据进入上下文的概率，而非显著提升模型对既有上下文的利用能力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibPZCsUwHMeichict28WobRaC6EU2oqwh6icCktTiaSaON88ibAe3s1pvbVbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5" data-type="png" data-w="1080" data-width="3000" data-height="1500" data-imgfileid="503526752" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ec6de7f3-0e37-41f2-b328-8923f6467a04/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;工程启示：如何在预算约束下分配投入&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;综合实验结论，论文给出了一条可执行的系统设计建议。当推理资源受限时，优先考虑扩大检索语料与提升覆盖率，常常能让中等规模生成模型达到接近更大模型的表现。相比之下，极小模型需要更激进的语料扩容才能追平下一档，收益效率偏低；而极大模型在更大语料下的增益也相对有限，体现出利用效率并不会随着参数规模单调上升。对系统优化而言，跟踪答案覆盖率与利用率可以作为诊断指标，帮助判断瓶颈更偏检索端还是生成端，从而指导下一步应该扩语料、调检索，还是换模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项研究把 RAG 的规模讨论从单一的模型参数扩展到语料与检索能力，给出了可复现的控制变量实验与清晰的机制解释。其结论可以概括为两点：扩大语料通常有效，但收益存在边际递减；提升主要来自更高的答案证据覆盖，而非模型利用证据能力的跃迁。在面向真实部署的 RAG 系统中，这提供了一条更可控、更具性价比的提升路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者简介：&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibcdBp0xYuX7nc1ibnMjJGXvlDY3FplrhQrhm6F6IKc5srcKMia7AVJcsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1" data-type="png" data-w="1080" data-width="2730" data-height="2730" data-imgfileid="503526753" data-aistatus="1" data-original-style="width: 160px;height: 160px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/56b93f3e-781d-48d0-877a-5e8a222e7b51/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;本论文第一作者为卡内基梅隆大学计算机学院语言技术研究所硕士研究生 Jingjie Ning，研究方向聚焦信息检索、DeepResearch、Query 理解与强化、推荐系统 Benchmark 等工作。Jingjie Ning 师从 Jamie Callan 教授，后者为卡内基梅隆大学计算机学院语言技术研究所教授，曾任 SIGIR 大会主席，同时担任系博士项目主任，长期引领搜索与信息检索领域研究，在学术界与工业界具有广泛影响力。在卡内基梅隆大学前，Jingjie 曾在腾讯任职 Senior Data Scientist。个人主页：https://ethanning.github.io&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AI Shortlist上线｜研究值得关注的AI企业</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 05 Jan 2026 18:06:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/d19de98d-e2ab-4149-979c-4a0200b9c7ac/%E5%B0%B1%E5%BE%88%E9%9A%BE%E5%8A%A0%E4%B8%8D%E5%8A%A0%E7%8F%AD_jpg.jpg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7b170419-48dc-4a0e-8cdf-930a34cd03df/0.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Claude Code 一小时「复刻」谷歌一年成果，那一年能读完五年半的博士吗？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 05 Jan 2026 17:09:43 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2d0f00db-74f0-4a7e-9426-9f433b0179f8/1767604027650.png" style="width: 700%;" class="fr-fic fr-dib"&gt;近日，X 知名博主、Hyperbolic 联创 &amp;amp; CEO Yuchen Jin 发帖称，如果在他读博士的时候就有 Claude Code、Gemini 和 ChatGPT 等各类 AI 工具出现，那么也许只要一年就能毕业，而不是用了 5.5 年。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibiatqp1y35rY1vNNcjHanIx0Jx99oI6OckibrvlHXSApb0b49LrJ7NXEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5888888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526769" data-aistatus="1" data-original-style="width:508px;height:299px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ed42f2fe-50ae-46c5-9cff-ac83cde39845/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而他之所以发出这个感慨，缘由是最近一些硅谷 AI 大厂工程师表示，在用了 AI 工具后，项目完成时长被大幅压缩&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;先是谷歌首席工程师、Gemini API 负责人 Jaana Dogan 在 X 上发文称：「我不是在开玩笑，这也不好笑。从去年开始，我们就在谷歌内部尝试构建分布式 Agent 编排器。有多种选择，大家并没有完全认同&amp;hellip;&amp;hellip; &lt;strong&gt;我只是向 Claude Code 描述了问题，它就在一小时内生成了一个东西，而这几乎就是我们去年一年所做的东西。&lt;/strong&gt;」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibbibGW1z083WOBic2KRP2Mfhp6rI8NysAw98HfficiagFjry59Hz1FPCs5w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.32037037037037036" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526778" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/02bc0c99-53d8-4eae-ad7d-d793934b77ea/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;随后，她又发文补充，提示内容不算详细，也没有具体细节，只是一段三段式的描述。但由于不能分享任何东西，也不好具体展示出来，总结来说就是在现有一些想法基础上构建一个玩具版本，用以评估 Claude Code。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibDqmwBROfzYfottmYKxh7U2KwKUEib56vyauhjCa5wxic26kX3SjusfHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.31574074074074077" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526779" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/51352749-485f-435f-ba4e-f6caccd0461e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;帖子一经发布，迅速引起网友讨论，有人感慨没想到当前的 AI 编码工具已经发展到如此强大的地步，也有人惊叹，原来即便是强大如谷歌这样的 AI 大厂，也会使用 AI 编码工具，更意外的是，居然允许员工使用其他公司产品，而非强制大家使用自家旗下的 Gemini、Gemini CLI 或 Antigravity&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;其中，一位名为 Rohan Anil 的 X 网友评论道：自己以前也是谷歌工程师，在职期间一路晋升，&lt;strong&gt;但如果当时就有 Agent coding 的话，尤其是 Opus，也许就能把前六年的工作压缩在几个月内完成&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibDT39f7CdVibpkXYopzHDTUvOWXaN2y4nqnoTBgfGiamHtOocqVfC9LWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.31666666666666665" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526782" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7a480fe3-f046-4553-942b-467c3993f2b8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;随后此推文获得了上百次的浏览，而该网友也发文认真做起了自我介绍，原来 Rohan Anil 曾是前谷歌和 Meta 杰出工程师，在 Google Brain 期间从事基础研究，重点包括训练算法和基础设施方面的工作。例如谷歌 Google 内部首个 Transformer 推理系统，以及首批大规模 TPU 训练与推理系统的落地与上线。&lt;/p&gt;&lt;p&gt;之后他在 Google DeepMind 负责领导 Gemini 模型相关工作，且因在 Gemini 预训练方面的贡献，获得杰出工程师称号。去年一月，他从谷歌离职，目前在 Anthropic 工作。&lt;/p&gt;&lt;p&gt;而谈及帖文中所说的「Opus 这项技术可以把我六年的工作压缩到几个月」时，他表示，&lt;strong&gt;这主要指的是工程层面：性能优化、在真实约束条件下拼装分布式系统等&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;也正是这些内容，让 Yuchen Jin 有感而发：「这与我的亲身经历完全一致。」&lt;/p&gt;&lt;p&gt;他认为，&lt;strong&gt;当前 AI 正在显著压缩学习曲线，并以惊人的速度把初级工程师「拉升」为高级工程师&lt;/strong&gt;。在大型代码库中的新员工入职熟悉周期，已经从过去的几个月缩短到现在的几天。曾经需要花上数小时在 Google 和 Stack Overflow 上查资料的问题，如今往往只需要一个 Prompt 就能解决。同时，AI 也正在成为一位优秀的导师和结对编程伙伴。&lt;/p&gt;&lt;p&gt;「现在真正稀缺的，只剩下主动性。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibjF8apvicib4DgLaVYNX0I3Diaez3n02LLBExwgHGwwI2HSMdibzSLAHeMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.9194444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526783" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/15550f19-2c18-4883-86d4-93eb3ea0365a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;更进一步地，他认为不仅是在工作中，如果再早一些，在读博期间就会各种 AI 工具出现的话，那么，可能毕业时间也会大大缩短，也就是在文章开头所发的帖子。&lt;/p&gt;&lt;p&gt;在他看来，&lt;strong&gt;「当前的教育模式还处于人工智能出现之前，需要根本性的更新。」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不过，不同于对 AI 工具在工作中所带来影响的积极认可，关于 AI 工具在教育中的作用，大家开始出现了分歧。&lt;/p&gt;&lt;p&gt;有网友认为，就像 Yuchen Jin 所言，博士期间约有 25% 的时间是用来阅读大量论文的，但 AI 的出现让这一部分变得不一样了。「我以前需要花几个小时来解析晦涩的论文，而现在只要请 Claude 帮忙解释关键见解，并对照实际论文进行验证就可以了。」&lt;/p&gt;&lt;p&gt;当然，他也坦言，虽然现在还不能算是完美，但这只是时间的问题。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibLia0MI4K9ePVcjrZiamqQOUrhBuUlJhLZFdoeYluibkFVII9PzkjXxqBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.2712962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526775" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/19bc1802-a481-4802-9157-4b27c4e20d23/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;网友 Thierry Laurent 也持相似看法，他说自己目前正在攻读遥感硕士学位，以往需要几个月才能积累的脚本素材，现在在 Codex/CC 里只需要几天时间就可以了。「我们目前正处于一个转折点，但大学尚未准备好。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibMibG6vthTCH6TWW7sTfukor4ddLvsPyyxQTicOASGv1Xefl0akdbV7rA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.1648148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526771" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6a424ab3-4e84-44a2-9d54-a06aefa1d4f3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但一位名为 alyxya 的网友并不这样认为。在他看来，对于学生来说，仍然需要花费时间来学习批判性思维、推理行业理解能力。「AI 就像个人导师一样，我可以不断地向他提问，但 TA 不能强迫我立刻内化这些知识。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibYqH4b6Z2S4lfVYcZrlguAYoI40OkeyvD00ibRribSnwUFgJsMbiafAiaQQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.17222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526776" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8e888b24-f541-41fb-b6de-50253e011a7a/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;网友 Palmi 也有类似的看法，他认为，也许 AI 工具的接入会让毕业时间加快，但是，「你会像现在这样优秀吗？」AI 确实加快了工作、学习进程，但对于个人来说，并不会获得任何（处理过程中）的知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibOtK8SXhhJYpaIQBfE9JiariazG0P674vrXaXpEicU6tk7DDRcBHUib9xSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.12407407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526784" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6fdb0b2d-927f-45ae-8ac3-e3be85a185c1/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;网友 Burhan 甚至觉得那些曾经「浪费」的时间让自己成长了。他内心深处开始思考一个问题：这「5 年半的挣扎」是否真的在我们身上构建了一些「1 年冲刺」所无法带来的东西。换句话说，这种用「笨办法」死磕硬磨所带来的阻力，是否反而锻造出了一种更深层的专业造诣？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibjaV0fPibmXN3Su6I2F3Q3GBWVD6ZY7ejUZwqzB9nahJmwJbwA5Nic4rQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.16574074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526777" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/bf7c30d5-ca76-4c79-a4f3-cb565befb520/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有网友调侃称，&lt;strong&gt;「兄弟，不过别忘了，你不是唯一有AI工具的人，也许你的导师很快就会把研究生要求定为：需要50篇第一作者论文。」&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaiblM9pIs4ndficyict7BnQHC5IopDzn4iaDpLyGp6oxsUNbYwJflyv83nJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.13240740740740742" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526770" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/9faa2b8d-f17b-445c-80d5-dd968e222d1c/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最新信息是，Yuchen Jin 又发了一个案例，说他一位从事 AI 研究的朋友正在教自己 8 岁的孩子用 Claude Code 写 PyTorch 代码。&lt;/p&gt;&lt;p&gt;他表示，自己对这种虎妈式的做法感到震惊。但真正的信号是：当一个 8 岁的孩子能建造出需要多年学校和训练的东西时，「高等教育」就变得过时了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「经验年限现在远不如品味、好奇心、主动性，以及与人工智能合作的能力重要。」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，关于这一观点的争论还在继续，各路网友都在基于自身的经验或认知来阐述自己的立场，帖子热度也在继续高涨。&lt;/p&gt;&lt;p&gt;那么你呢，你如何看待持续快速发展的 AI 对教育带来的影响？&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/QuanquanGu/status/2007947084608246188&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2007512853625090095&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>空间智能终极挑战MMSI-Video-Bench来了，顶级大模型全军覆没</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 05 Jan 2026 17:04:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/65ff1982-f67e-4877-9013-0c5ba8f160e9/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;空间理解能力是多模态大语言模型（MLLMs）走向真实物理世界，成为 &amp;ldquo;通用型智能助手&amp;rdquo; 的关键基础。但现有的空间智能评测基准往往有两类问题：一类高度依赖模板生成，限制了问题的多样性；另一类仅聚焦于某一种空间任务与受限场景，因此很难全面检验模型在真实世界中对空间的理解与推理能力。&lt;/p&gt;&lt;p&gt;要真正走入现实世界，模型不仅需要看得见，更要看得懂空间： 它需要在复杂、多变的真实场景中理解空间布局、感知运动变化、进行时空推理，并基于这些信息做出合理决策，与环境产生有效交互。&lt;/p&gt;&lt;p&gt;为此，&lt;strong&gt;上海人工智能实验室 InternRobotics 团队&lt;/strong&gt;近日推出了一套&lt;strong&gt;全面而硬核的空间智能视频基准 &amp;mdash;&amp;mdash; MMSI-Video-Bench&lt;/strong&gt;，对当前主流多模态大模型精心打造了一场挑战系数极高的 &amp;ldquo;空间智能大考&amp;rdquo;。&lt;/p&gt;&lt;p&gt;本工作由上海人工智能实验室、上海交通大学、香港中文大学、浙江大学、香港大学、北京航空航天大学、西安交通大学、复旦大学、加州大学洛杉机分校 的研究者们共同完成。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaib3rJBXyrkemHibYYwI3UUIej2qRHtKvTY9nUSmbSTBW4ad9laWsRL6ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.32037037037037036" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526716" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/df73e168-0cf3-4ae6-a3de-5baafe2ebc63/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;项目主页： https://rbler1234.github.io/MMSI-VIdeo-Bench.github.io/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ArXiv 论文： https://arxiv.org/abs/2512.10863&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hugging Face 数据集： https://huggingface.co/datasets/rbler/MMSI-Video-Bench&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub 代码库： https://github.com/InternRobotics/MMSI-Video-Bench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/M4XBlVXjd3Alv5pH3h4tyw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8819386b-0479-410a-a2bc-43f59bb5b386/1767603661870.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;该基准具有以下显著特点：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（1）全面且系统的题型设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MMSI-Video-Bench 首先从视频本身的时空信息理解出发，对模型的基础空间感知能力进行系统考察，主要包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;空间构建（Spatial Construction）&lt;/strong&gt;：聚焦于对全局空间布局的理解，涵盖实体与场景的空间状态属性，以及 相机、实体与场景之间的两两空间位置关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;运动理解（Motion Understanding）&lt;/strong&gt;：考察模型对长时运动过程的感知与理解能力，包括实体运动、相机运动，以及多实体之间的交互运动。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在此基础上，MMSI-Video-Bench 进一步评测模型基于时空信息进行高层决策的能力，具体包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于视频信息进行推理与行动的&lt;strong&gt;规划能力（Planning）&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对未来状态进行推断与想象的&lt;strong&gt;预测想象能力（Prediction）&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;由于真实世界的观测在时间上不一定是连续的，在空间上单一视角的信息不一定是完备的，MMSI-Video-Bench 进一步扩展了任务范畴，以更真实地覆盖现实场景中的复杂情形，考察模型跨视频的推理能力，这包含了跨时间的记忆更新能力（Memory Update）；多视角信息的整合能力（Multi-View Integration）。&lt;/p&gt;&lt;p&gt;通过上述多层次、多维度的题型设计，MMSI-Video-Bench 构建了一个&lt;strong&gt;覆盖感知、推理与决策全过程的空间智能评测体系&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibS5RFP2k3DbicZv9nYBd3S0biaZqtOpttU6nLrFuqc85YeuHciaVonVlxg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.1175925925925927" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526717" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f29e4049-f1b8-4583-80f9-03016433109d/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; MMSI-Video-Bench 由五大任务类型，13 个子类问题构成&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（2）极具挑战性的问题设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MMSI-Video-Bench 基准的所有问题由 &lt;strong&gt;11 位平均研究年限超过 2.5 年的 3D 视觉研究员亲自把关精细设计&lt;/strong&gt;，严格验收打磨，确保了基准每一个问题清晰准确，具有挑战性。所有模型均表现吃力，即便是最表现最好的 Gemini 3 Pro，也只有 38% 的准确率，相比其它的空间智能基准，具有目前最高的人类&amp;ndash;AI 性能差距 (约 60%)。&lt;/p&gt;&lt;p&gt;&lt;strong&gt; (3) 丰富多样的视频数据来源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基准的视频数据来源于 25 个公开数据集 以及 1 个自建数据集，包含了机器人操作、从单房间到多层楼宇的室内场景、室外建筑与街景、自然风光、体育活动以及电影片段等多种拍摄类型，全面反映了真实世界中复杂多样、多尺度的空间场景&lt;/p&gt;&lt;p&gt;&lt;strong&gt; (4) 特定领域针对性的能力测评&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;此外，受益于场景类型的丰富以及任务类型的全面性，MMSI-Video-Bench 可以划分出&lt;strong&gt;室内场景感知&lt;/strong&gt; (Indoor Scene Perception)/ &lt;strong&gt;机器人 &lt;/strong&gt;(Robot) / &lt;strong&gt;定位&lt;/strong&gt; (Grounding) 三大子基准，方便针对性测评模型特定能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaib028sPLRgYy7ggWxMdHepE96FLh4umyrH1ibxBI7XZ7jRqnarCPuWl9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0916666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526718" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/511a55c1-0f93-4653-bfb7-d0f8f3db83cd/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; MMSI-Video-Bench 的标注流程 和 比例 / 视频时长 / 词云分布&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;空间智能大考：揭示模型能力边界与瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（1）空间智能大考模型成绩单&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队对 25 个主流多模态模型 进行了评测，整体得分普遍偏低。即便是表现最优的 Gemini 3 Pro（38.0），与人类水平 （96.4） 之间仍存在&lt;strong&gt; 接近 60%&lt;/strong&gt; 的显著差距。&lt;/p&gt;&lt;p&gt;与已有空间智能基准的结论一致，实验结果再次暴露了当前模型在空间构建能力上的不足。更为关键的是，得益于 MMSI-Video-Bench 在任务设计上的全面性，研究团队进一步发现：模型在 运动理解、规划、预测以及跨视频推理 等能力上同样存在明显瓶颈。&lt;/p&gt;&lt;p&gt;在所有任务类型中，预测（Prediction） 是最具挑战性的主任务， 相机&amp;ndash;实体之间的空间关系建模 是难度最高的细分类别。此外，研究团队发现，即便是经过专门空间任务微调的模型，其能力也未能有效泛化到 MMSI-Video-Bench。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibttWgWJH5XBebNaEuuriaXyFFrcNKaYc2OGz4fPfXjN1prCbVwdD5Paw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.837037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526720" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/519a593e-aecc-4af9-905c-34ac34111a76/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 不同模型在 MMSI-Video-Bench 上的表现&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（2）错误分析揭示模型瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为进一步定位模型性能受限的关键原因，研究团队对模型的推理结果进行了系统化复盘，并将错误归纳为五大类型:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;细致定位错误 (Detailed Grounding Error)&lt;/strong&gt;：模型在精细视觉感知层面出现失效，常见表现包括目标遗漏混淆，或 &amp;ldquo;时间点 - 事件&amp;rdquo; 对应关系感知错误。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;ID 匹配错误 (ID Mapping Error)&lt;/strong&gt;：模型在跨帧过程中难以保持一致的实体身份跟踪。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;潜在逻辑推断错误 (Latent Logical Inference Error)&lt;/strong&gt;：模型在需要依赖隐含线索或常识知识的推理任务中失败。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;提示输入对齐错误 (Prompt Alignment Error)&lt;/strong&gt;：模型未能将提示信息（如背景假设、新增条件或辅助图像）与视频信息正确结合进行推理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;几何推理错误 (Geometric Reasoning Error)&lt;/strong&gt;：模型在空间几何关系理解上存在偏差，对于相对位置或距离关系（如前后左右、远近）出现错误推断。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibx8UtMcbeYRibicfeo1OvpAjb1HyvOp5BtZ8YCNo1oWADNEMou8tqSicOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.49256505576208176" data-s="300,640" data-type="png" data-w="1076" type="block" data-imgfileid="503526721" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a3485c63-54f3-4522-9262-dc396875677e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; MMSI-Video-Bench 的五种错误类型示例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;研究团队选取 Gemini-2.5-Flash、GPT-4o、O3、QwenVL2.5-72B 四个具有代表性的模型进行了系统的错误分析和统计，结果如图所示。几何推理错误是最为普遍、影响最大的错误类型，而进一步的细分分析表明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;空间构建任务 的低表现主要源于几何推理能力不足；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;运动理解任务 中，模型难以在 快速、细微或长时间跨度的运动 中保持精确定位；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 规划与预测任务 中，除几何推理错误外，模型往往无法有效理解提示输入，并将其与视频信息进行联合推理；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;跨视频推理任务 的失败主要源于 多目标跨视频定位的复杂性，以及模型难以利用潜在线索（如持续锁定同一目标）完成推理。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibYn8ZARXYibRu4sY6jAfApRiceGlofo8GYaFWCrQxwKdth8WPnI1fX5pA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526722" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/22cd3dde-695e-40d7-827c-7089163957fb/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; MMSI-Video-Bench 的五种错误类型分布&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（3）空间线索与推理提示难以弥补核心能力不足&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队进一步探索了两种提升模型性能的策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;引入&amp;nbsp;&lt;strong&gt;3D 空间线索&lt;/strong&gt;&amp;nbsp;以辅助模型理解，如图所示，通过使用高性能的 3D 重建模型从视频帧重建 3D 场景，并多视角渲染生成 2D 全局图像作为额外输入，给予模型 3D 空间线索辅助模型的理解推理；&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibWXWc8Ju7dbkS6SiamseDCHianysfjnhZhDh4Bg6yZ4Rn7ZemLHEsTHVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.4935185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526723" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ed02a42f-2745-4bfa-b353-887b46d2b312/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3D 空间线索辅助方法&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;采用 &lt;strong&gt;思维链（Chain-of-Thought）&lt;/strong&gt;技术，提示引导模型进行更规范的推理过程。上述方法均 未能带来显著的性能提升，这些结果进一步揭示了两个关键事实：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何设计模型真正 &amp;ldquo;可理解、可利用&amp;rdquo; 的空间线索，仍是一个开放且极具挑战性的问题；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当前模型的失败 并非由于缺乏显式推理步骤，而是受限于 底层推理能力本身仍然不足。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibWqAplShSS2xicibLbJp68PufYrhibsx0PqLce3zBeHK4s6WZibrEL0eo5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5018518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526724" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/416e026e-8117-48ea-b208-5589c12ed4d0/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 3D 空间线索辅助与思维链提示下的模型性能变化&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MMSI-Video-Bench 是一个高质量、高挑战性且系统全面的视频空间智能评测基准，系统性地评估了多模态大模型在视频理解中的空间认知、推理与决策能力，评测结果清晰揭示了当前模型在多项核心任务上与人类表现之间仍存在显著差距。基于深入而细致的实验分析，研究进一步明确了现阶段模型的关键能力瓶颈，并为未来空间智能模型的技术演进指明了研究方向。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>蚂蚁、美团入局 AI 硬件， Looki 完成超 2000 万美元 A 轮融资</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Mon, 05 Jan 2026 15:53:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3029e280-c5c0-4e97-8a70-e47483cd737c/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;AI 硬件创业公司 Looki 已完成超 2000 万美元 A 轮融资，本轮融资由蚂蚁集团领投，美团龙珠、华登、中关村资本跟投，老股东 BAI 资本连续两轮超额追投，阿尔法公社、同歌创投持续加码。&lt;/p&gt;&lt;p&gt;据了解，在完成了兼具技术与产业通路的资本矩阵后，Looki 将重点加强组织人才建设、模型迭代、产品研发及供应链整合，加速公司在 AI 原生硬件赛道上的技术积累和下一代交互入口的探索。&lt;/p&gt;&lt;p&gt;在 AI 硬件百花齐放的 2025 年，这笔融资标志着资本重新聚焦于能够将多模态 AI 能力融合到硬件的头部品牌。&lt;/p&gt;&lt;p&gt;Looki 创始人兼 CEO 孙洋表示：「Looki AI 正在加速奔跑，寻找更多志同道合的伙伴，共同构建&amp;ldquo;以人为中心&amp;rdquo;的 AI，增强人，而非取代人。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;01 创造一个全新的硬件品类&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Looki 成立于 2024 年 5 月，截至目前，一年多时间已连续完成 4 轮融资。&lt;/p&gt;&lt;p&gt;公司由两位卡内基梅隆大学（CMU）的校友联合创办，CEO 孙洋曾任美团智能硬件负责人、Momenta 高级研发总监，Google Assistant 创始成员之一；CTO 刘博聪曾任美团自动驾驶算法负责人、Pony.ai 创始成员。团队成员来自清华大学、北京大学、多伦多大学、伊利诺伊大学、伦敦政经等知名院校，曾就职于 Google、Amazon、Qualcomm、字节跳动等公司，在 AI 算法、AI 产品、硬件工程等方面具备丰富经验。&lt;/p&gt;&lt;p&gt;在 2025 年 8 月，第一款产品，世界首款可穿戴的多模态 AI 硬件 Looki L1 国际版发售，在海外和国内的社交媒体平台上都引发了大量关注，数千台备货很快销售一空。随后 12 月，备货之后 Looki 在京东平台上线国内版本，截至目前全球累计销量近万台&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1a84a3ad-f94b-4eeb-80ec-162386046988/%E5%9B%BE%E7%89%872.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Looki L1 在海外社媒上走红&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;随着大模型能力的增强，AI 能够对文字、音频、图片、视频等多种模态的内容进行分析、整理、总结，通过整理用户在线上线下的 context，AI 能够向用户提供额外的价值。&lt;/p&gt;&lt;p&gt;典型的产品比如 Plaud，通过对工作会议等音频场景的收集整理，创造 AI 录音卡片这一全新品类，年收入已达到数亿美元，赛道也有出门问问、钉钉等公司入局。&lt;/p&gt;&lt;p&gt;Looki 选择了更加偏向生活的场景。不同于传统意义的运动相机，Looki L1 开创了一个全新的硬件品类，主打日常的记录和陪伴，通过视频、图片和音频等形式的记录，为用户梳理生活碎片，提供充分了解用户后的生活建议和情绪价值，在用户社区里，L1 被称为「人生回看器」。&lt;/p&gt;&lt;p&gt;除了可以回溯日常生活碎片，Looki AI 还可以洞察用户行为和情绪，为用户生成每日总结 vlog、日常片段的洞察分析、生活连载漫画等，这些具有创意和乐趣的内容被用户广泛分享到 Discord 社群和小红书等平台，已成为 Looki 最受欢迎的功能之一。&lt;img src="https://image.jiqizhixin.com/uploads/editor/e9d4877d-39b5-4bd6-9c9c-6433009f835e/%E5%9B%BE%E7%89%873.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Looki 独特的连载漫画功能&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;发售四个月以来，用户数据不断验证了 Looki 提出的假设。创始人孙洋对 Founder Park 提到，最开始用户人均使用时长是 6.2 小时，这一数据充分验证了 L1 区别于 event-based 运动相机的产品形态&amp;mdash;&amp;mdash;毕竟没有人会全天候戴着运动相机。随后数周，用户平均使用时长一路攀升到 7.9 小时，并且仍在持续增长。为了能够更长时间佩戴，用户甚至「自研」了为 Looki L1 提供额外续航的方法（如购买两台设备换着用等）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;02 新功能：主动式 AI，CES 特别版&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 CES 上，Looki 将发布全新功能，主动式 AI（Proactive AI）。&lt;/p&gt;&lt;p&gt;现阶段 Looki AI 已经能够回应用户的诸多问题，比如「我今天吃了什么？」「给我看看和家人在一起的时刻。」或者「为什么我今天这么累？」&lt;/p&gt;&lt;p&gt;对于这类问题的响应，Looki 称之为 Reactive AI（响应式 AI），它在接受用户的 prompt 之后才能被动提供价值。&lt;/p&gt;&lt;p&gt;但接下来，Looki 在充分了解用户，甚至可以实时理解用户此时此刻正在做的事情之后，它可以更加主动地给用户提供信息、提醒乃至关心。Looki 称之为「场景自适应式智能」（Scene-Adaptive Intelligence）。&lt;/p&gt;&lt;p&gt;比如：&lt;/p&gt;&lt;p&gt;当你准备拿起今天第三杯咖啡的时候，Looki 会提醒你咖啡摄入过量，可以考虑换成水。&lt;/p&gt;&lt;p&gt;当你在桌前久坐之后，Looki 会提醒你站起来走一走。&lt;img src="https://image.jiqizhixin.com/uploads/editor/ae050d0d-4edf-4c68-8c53-6d43d8d31f2e/%E5%9B%BE%E7%89%874.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;针对 CES 场景，Looki 特别开发了新的主动式 AI 功能，当 Looki 理解到你在 CES 上逛展时，它会更高频地记录你的所见所得，记录你高频的对话，分析你对哪个 booth 更感兴趣，总结参观展商的重点信息，给你接下来的逛展建议等等。&lt;/p&gt;&lt;p&gt;在 CES 上，Looki 将正式发布这一主动式 AI 的最新技术成果，通过对用户习惯和环境的持续学习，从单纯的「被动记录」，走向主动识别关键时刻并发起服务的「前瞻型伙伴」，并在不久后向全球 Looki L1 用户进行全量推送。&lt;/p&gt;&lt;p&gt;随着多模态 AI 技术的进一步成熟和用户需求的持续演进，Looki 将继续深耕「以人为中心」的产品理念。在这个充满无限可能的新时代，Looki 的故事才刚刚开始。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，蝉联Future X全球榜首的MiroMind发布全球最强搜索智能体模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 05 Jan 2026 14:47:14 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4fd9b7e5-20c2-4ea5-a4a0-4745848eb77a/1767595281555.png" style="width: 700%;" class="fr-fic fr-dib"&gt;凭借成功预测 Polymarket 题目，连续登顶 Future X 全球榜首的 MiroMind 团队，于今日（1 月 5 日）正式发布其自研旗舰搜索智能体模型 MiroThinker 1.5。&lt;/p&gt;&lt;p&gt;MiroMind 由全球知名创新企业家、慈善家陈天桥，与清华大学知名 AI 青年学者代季峰教授联合发起。去年陈天桥提出发现式智能才是真正意义上的通用人工智能这一重磅创新理念，引发全球业内人士关注。他同时提出建设发现式智能的 5 种关键能力，其中一项能力是在未知条件下重建对世界的理解，这正是 MiroMind 的使命。&lt;/p&gt;&lt;p&gt;在过去 7 个月里，当全行业都在「卷」参数规模、「卷」百万长文本的红海时，MiroMind 却在思考一个更本质的问题：&lt;strong&gt;智能的「奇点」究竟在哪里？他们给出的答案不是「把世界背进参数里」，而是押注「发现式智能」：真正的智能不靠全知，而靠会研究、会查证、会修正&lt;/strong&gt; &amp;mdash;&amp;mdash; 像顶级情报官一样对外极速取证、对内严苛去伪存真；像严谨研究员一样在不确定性里逼近真相，最终把「预测未来」从特权变成能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MiroThinker 1.5 性能评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MiroMind 团队在 AGI 竞技场上，不信奉 &amp;ldquo;大力出奇迹&amp;rdquo;，而是追求以高智效比为核心的 「巧劲」。&lt;/p&gt;&lt;p&gt;MiroThinker-v1.5-30B 仅用 1/30 的参数规模跑出了比肩众多 1T 模型的性能表现，其 235B 的版本在多个搜索智能体基准测试中跻身全球第一梯队。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实力霸榜：指标是门槛，预测是天花板&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibgsyxoGpnyKwYboRIwhPr4SHcj6QoC85rJfaAGicg5NX6iaTyVZyCkEOA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.45" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526713" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/98c7b932-1400-450c-9a9e-f2e339bc98fe/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; BrowseComp 性能对比&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9oUEwHUybwRnJPtnGzVEiaibPrfHEwjrvxsVkCpHA1DhjibuBBl6prZppuLb1jpiaIe2muc7F6jYZXrw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.1462962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526714" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5f8df5ce-97f4-48e0-9c92-41820746b98b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Agent 搜索评测基准性能对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;越级挑战：MiroThinker-v1.5-30B vs Kimi-K2-Thinking&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对参数量高达 30 倍的万亿参数巨兽 Kimi-K2-Thinking，MiroThinker-v1.5-30B 用极低的成本展示了旗鼓相当的表现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;推理成本&lt;/strong&gt;： MiroThinker-v1.5-30B 单条调用成本低至 $0.07，仅为 Kimi-K2-Thinking 的 1/20，且推理更快。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能表现&lt;/strong&gt;： 在关键评测集 BrowseComp-ZH 中实现性能超越，证明「大」 不等于 「强」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心洞察：从 「做题家模式」 转向 「科学家模式」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MiroMind 团队指出，以扩大模型内部参数量（Internal Parameters）为核心的传统 Scaling Law 已明显触及边际瓶颈；要继续提升模型性能，必须从「内部参数扩张」转向以「外部信息交互」（External Interaction）为核心的 &lt;strong&gt;Interactive Scaling&lt;/strong&gt;，将智能的增长空间从内部参数扩展到外部世界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么该模型能在大幅降低成本的同时，性能依然能打？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因为这不是「大参数碾压」，而是一次「科学家模式」对「做题家模式」的胜利。以 Scaling Law 为代表的路线，更像「做题家」：试图把全人类知识（也包括噪声与错误）尽可能背进模型里；一旦遇到生物学等领域的未知问题，就容易基于概率分布「编」出一个看似合理的答案 &amp;mdash;&amp;mdash; 幻觉往往由此产生。&lt;/p&gt;&lt;p&gt;在 &lt;strong&gt;MiroThinker 1.0&lt;/strong&gt; 中，MiroMind 团队首次系统性提出&lt;strong&gt; Interactive Scaling&lt;/strong&gt;：随着工具交互频率与深度提升，研究式推理能力也稳定增强 &amp;mdash;&amp;mdash; 这构成了与模型大小、上下文长度并列的第三个可扩展维度。v1.5 更进一步，把这套机制内化为贯穿训练与推理全流程的核心能力：将模型训练成「科学家」，核心不是死记硬背，而是勤查证。遇到难题时，它不会给出概率最高的瞎猜，而是执行慢思考的研究闭环：&lt;strong&gt;提出假设 &amp;rarr; 向外部世界查数据 / 取证 &amp;rarr; 发现对不上 &amp;rarr; 修正假设 &amp;rarr; 再查证&lt;/strong&gt;，直到证据收敛。&lt;/p&gt;&lt;p&gt;主流大模型往往盲目追求万亿参数，试图把整个互联网「背」在脑子里。而 MiroThinker 系列选择了一条反共识的路线：刻意将模型控制在 30B&amp;ndash;200B 的轻量级规模。MiroMind 团队强调，省下的不是算力，而是把算力花在了更刀刃的地方 &amp;mdash;&amp;mdash; 对外的信息获取与交互。&lt;/p&gt;&lt;p&gt;MiroMind 团队不追求让模型拥有一颗「最重的脑子」，而是培养它拥有一双「最勤的手」。当模型同时具备&lt;strong&gt;研究式确认机制&lt;/strong&gt;与&lt;strong&gt;时序因果约束&lt;/strong&gt;，这种围绕外部信息获取的交互过程才让「发现式智能」真正落地 &amp;mdash;&amp;mdash; 也正是对 Interactive Scaling 的深耕，使他们用小得多的模型，做到了大模型才能做到的事。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MiroThinker 1.5 核心技术揭秘&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的模型思维链本质上是在模型内部知识空间的线性外推，推理偏差会随路径增长而不断累积，最终导致逻辑坍塌。&lt;/p&gt;&lt;p&gt;MiroThinker 1.5 的核心发力点，在于通过 Interactive Scaling 打破孤立推理的僵局，将「推理」与「外部环境」深度耦合。通过构建「推理 - 验证 - 修正」循环，引入外部信息作为校验锚点，用确定性的证据流来对冲不确定性的推演，解决逻辑坍塌问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Training-time Interactive Scaling 技术&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当智能的 Scaling 范式不再局限于模型内部庞大的世界知识储备与缜密的长程逻辑推理，而是依托模型高频与外部世界中探索与交互并获得闭环反馈时，小而高效的探索者模型能展现比肩于甚至超出大而严谨的思考者模型的智力水平。&lt;/p&gt;&lt;p&gt;MiroThinker 1.5 正是基于这一判断，将 Interactive Scaling 从推理阶段的外挂能力，前移并内化为训练阶段的核心机制。模型并非被要求「尽量在脑中想清楚一切」，而是被系统性地训练成一个善于向外求证、敢于否定自己、能够快速修正路径的 Agent。&lt;/p&gt;&lt;p&gt;在训练过程中，MiroMind 团队刻意削弱对「单次完美推理」的奖励，转而强化以下行为模式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Evidence-Seeking（主动求证）&lt;/strong&gt;： 模型被鼓励将每一个关键判断拆解为可验证的子假设，并主动发起对外查询、检索与比对。结论本身不再是训练目标，找到可靠证据的过程才是。缺乏信源支撑的高置信输出，会在训练中被系统性地惩罚。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Iterative Verification（多轮校验与自我修正）&lt;/strong&gt;： 推理不被视为一次性路径，而是一个可反复回溯、修正的过程。模型在交互中被要求不断对已有判断进行反证测试，一旦发现证据冲突，必须显式调整假设，而非「带着错误继续推下去」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Anti-Hallucination（对捷径的系统性过滤）&lt;/strong&gt;： 对那些「看起来合理、但缺乏真实依据」的推理捷径保持零容忍。训练中不仅评估答案是否正确，更关注答案是如何得到的：任何依赖统计相关性、模式记忆或隐含先验而绕过证据验证的路径，都会被标记为低质量推理。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过这种训练方式，MiroThinker 1.5 逐步形成了一种「本能反应」：在不确定性面前，先交互、再判断；在高风险结论前，先查证、再收敛。这使得模型不再需要将庞大的世界知识全部内化为参数，而是学会在需要时，快速、精准地向外部世界「借力」。&lt;/p&gt;&lt;p&gt;最终，团队用更小的参数规模，换来了更高的智能密度：不是让模型记住更多，而是让它学会如何找到、验证并使用信息。这正是 MiroThinker 1.5 能在显著降低推理成本的同时，依然保持一线性能的根本原因。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;时序敏感训练沙盒&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;时序敏感训练沙盒，是破解「因果律」的钥匙：普通大模型训练常处在「上帝视角」&amp;mdash;&amp;mdash; 它在数据里早已「见过结果」，学到的往往是复述与「剧透」，而不是预测。MiroThinker 的训练则约束模型「只能看过去，不能看未来」，在严格的时间可见性约束下做判断、再用同样受时序约束的证据去验证与更新。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可控数据合成引擎&lt;/strong&gt;： 构建覆盖多任务类型的、难度与时间戳可控的数据合成体系。每一道题目的「正确答案」并非静态标签，而是随时间戳动态演化；模型必须在严格的信息可见性约束下，基于当时可获取的信息做出判断，而校验过程同样显式引入时间戳约束，以确保推演与评分均符合真实世界的时序逻辑。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;时序敏感训练机制&lt;/strong&gt;：采用严格的时间戳与信息可见性约束，彻底杜绝 Future Leakage；模型在训练过程中的每一步只能与发表于当前时间戳之前的信息进行交互。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在这种训练范式下，模型被迫学会在信息不完备、噪声存在、信号延迟的真实条件下进行推演与修正，而不是依赖静态数据集中的「标准答案」。时间由此从一个背景变量，转变为塑造模型行为与推理方式的核心约束，使模型更接近真实世界中的认知与决策过程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;样例展示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Case 1: A 股涨停板预测 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;据介绍，这不是 「玄学」，更不是事后诸葛亮 &amp;mdash;&amp;mdash; 而是在信息极度噪声化、情绪快速切换的盘面里，用开放世界证据 + 因果推断去赌 「次日正确答案」。（注：以下仅为技术展示，不构成投资建议）&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;12 月 10 日（周三）：&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvzaAmMvvX0bicp2RIMPibxUCfKLArickhmPtuGLIwVfdfe8gAtUUDP3XWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.649074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526674" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/dbe7d56c-e2fa-4682-b6b9-f7b704d72424/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 对话链接：https://dr.miromind.ai/share/07430808-d84d-4e40-9615-bf07d6e71365&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;跃岭股份 &lt;/strong&gt;｜ 16 只连板股，当天晋级仅 4 只，晋级率 25%，市场情绪显著退潮。MiroMind 在 8 支二板股里，精准押中唯一晋级成功的那一支。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;12 月 11 日（周四）：&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvl5WDamQO2dERMW4SAyQZqBemvqulicTbC7qBjmywjg2KLAbnw0BHJ6g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7972222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526675" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6e39aaf5-98fb-4fa3-b632-d3fa9999031e/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;对话链接：&lt;/sup&gt;&lt;/span&gt;&lt;sup&gt;https://dr.miromind.ai/share/eccc29b9-889b-43f9-b6bf-f4b2b7c8dc1e&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;再升科技&lt;/strong&gt; ｜ 9 只连板股，当天晋级仅 2 只，晋级率 22%，市场环境持续降温。MiroMind 命中 9 支连板股中高位晋级者 &amp;mdash;&amp;mdash; 退潮里选中 「活口」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;12 月 12 日（周五）：&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tv5XCDvnTMKjuBUugk33mmpHBhHlof99M1jDHuLKtyhkqnWKzE6Qn7Lw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526676" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/034b2418-8abd-42ce-8cfc-28afb5ec51e4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 对话链接：&lt;/sup&gt;&lt;/span&gt;&lt;sup&gt;https://dr.miromind.ai/share/e9db058d-3e8c-4922-b483-cf5efae2f414&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;再升科技&lt;/strong&gt; ｜13 只连板股，当天晋级 7 只，晋级率 54%，情绪强力回暖。MiroMind 不仅命中市场最高连板，还准确预判其继续晋级（后续累计涨幅高达 58%）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;12 月 15 日（周一）：&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvoMPuuQibNiaV05NAXeHYyaib8gLyPDtTUTiagQW22zgfrvO5kicCqtUCmvw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526677" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/efd4668c-b509-434b-91c9-f0d6c63dc0f0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;对话链接：&lt;/sup&gt;&lt;/span&gt;&lt;sup&gt;https://dr.miromind.ai/share/3dc7dae0-78cb-4a97-8f61-359ab2d3e1a0&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;华菱线缆 &lt;/strong&gt;｜13 只连板股，当天晋级 5 只，晋级率 38%，市场再度明显降温。MiroMind 继续命中：在情绪回落时仍能穿透噪声，给出可复盘的确定性答案。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Case 2: 下周有哪些大事件会对美股七巨头产生影响？预期的市场反应和潜在波动方向是什么 ？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TviaRxlaVgoeWIDG8u8fvPmXibTqX4icd5jVJjJSNk0747GbPSGibxQkOvGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7638888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526678" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3103c5d3-17a8-4f9f-9231-f8415e532a77/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 对话链接：&lt;/sup&gt;&lt;/span&gt;&lt;sup&gt;https://dr.miromind.ai/share/f4afae1a-21e1-4f6d-8eef-16909c2d7b79&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Case 3: GTA 6 明年能按时发布吗？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvxgS1UpruHIs9nibQBOPiauLedF5AJiaVeNiatGJE9ncQibXHsq0Eia0hTbng/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526679" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8b58b779-ce4e-4d75-8632-f0df17918f29/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 对话链接：&lt;/sup&gt;&lt;/span&gt;&lt;sup&gt;https://dr.miromind.ai/share/10e5d1fd-c6b6-4b96-a2ed-4b776a3e1dcd&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人才招募 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MiroMind 面向全球持续招募人才，简历投递：talent@miromind.ai&lt;/p&gt;&lt;p&gt;&lt;strong&gt;产品体验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;立即体验 MiroMind，免费解锁预测未来的能力&lt;/strong&gt;： https://dr.miromind.ai/&lt;/p&gt;&lt;p&gt;&lt;strong&gt;加入社群：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Discord 频道（&lt;a data-topic="1" href="javascript%3A;"&gt;#everything&lt;/a&gt;-prediction）：https://discord.gg/F7EQFnYscV&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;微信社群（MiroMind 预测未来）：微信添加小助手 miromind001&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt; 相关链接：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Hugging Face 模型下载：https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github 代码地址：https://github.com/MiroMindAI/MiroThinker&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MiroFlow 开源框架：https://github.com/MiroMindAI/MiroFlow&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>超越AlphaFold3，实现模型容量的规模化扩展，字节提出分子结构预测模型SeedFold</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 05 Jan 2026 14:41:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicLBI0hm1zLSo1Zuo21xNCz20bpvwGyH4W0KnNRNW5IRABian1rDt8qG5Q/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.5537037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="100027061" data-aistatus="1" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/3b746451-7f7d-42d0-a18f-ca687486a125/640.jpeg" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑丨coisini&lt;/span&gt;&lt;/p&gt;&lt;p&gt;高精度生物分子结构预测对于结构生物学和药物发现至关重要，而构建基础模型最核心的环节之一在于确定模型规模化的技术方案。&lt;/p&gt;&lt;p&gt;折叠模型利用先验知识，在广泛的应用中展现出多功能性，包括结构生成、结合物设计、构象采样等等。已有一些研究工作尝试探索折叠模型的规模化特性，但大多数折叠模型仍遵循 AlphaFold 的基本配置。&lt;/p&gt;&lt;p&gt;最近，来自字节跳动 Seed 的研究团队提出了种子折叠模型 &amp;mdash;&amp;mdash;SeedFold，该模型成功实现了模型容量的规模化扩展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicLmXLZ6IVOYdu8RjmK7Fnjf5UJ4mwAqUj9lyVpS85vdKviapzzXZH5ibbg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.30277777777777776" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="100027053" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/b3eb8078-6d30-495d-aa6f-747d701d90a5/640.jpeg" alt="图片" data-before-load-time="1767595210948" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.24354&lt;/p&gt;&lt;p&gt;SeedFold 通过宽度扩展和大规模数据蒸馏来提升模型容量。该研究还推出了 SeedFold-Linear&amp;mdash;&amp;mdash; 一种采用线性三角注意力机制的高效变体。两种模型在 FoldBench 基准测试中均取得 SOTA 结果，在多数蛋白质相关任务上超越了 AlphaFold3。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SeedFold&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SeedFold 采用 AlphaFold3 的架构，并针对大规模扩展进行了关键改进。SeedFold 的创新主要体现在三个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;首先，针对 Pairformer 提出有效的宽度扩展策略，以提升其表征能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其次，引入一种创新的线性三角注意力机制，通过降低计算复杂度实现了高效规模化；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后，构建了大规模蒸馏数据集，显著扩充了训练样本规模。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;模型规模化&amp;nbsp;该研究从三个选项（加深 Pairformer 模块深度 [48 层&amp;rarr;96 层]、加深 Structure 模块深度 [24 层&amp;rarr;48 层]、拓宽 Pairformer 模块宽度 [128 维&amp;rarr;256 维&amp;rarr;384 维&amp;rarr;512 维]）中，确定了控制模型规模扩展的关键因素。实验表明，折叠模型中的模块深度已足以支持潜在空间推理，而模型容量主要受限于配对表征的隐藏维度（128 维）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicLe28JToPsFiaINcs7IqpAhvQVa42ibeFH34ZR3SkQjvS0khamDpJSFkmw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.8787037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027054" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/0ccddfff-da5b-4663-9d70-590b30dce842/640.jpeg" alt="图片" data-before-load-time="1767595210979" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicLmk026OItfNObicevjQ2wmrLTE3lDUB3Us1LrbrbiauRnMtibiclE19icibEg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.3111111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027055" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/88bc0b1f-5414-4188-9dcb-777d2c7448d3/640.jpeg" alt="图片" data-before-load-time="1767595211013" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;线性三角注意力&amp;nbsp;通过检查 AlphaFold3 的各个组成部分，该研究识别出计算瓶颈 &amp;mdash;&amp;mdash;Pairformer 中的三角运算。三角运算的计算复杂度随蛋白质序列长度呈三次方增长，消耗大量时间和内存。研究团队因此提出用线性注意力替代基于 softmax 的三角注意力，从而将复杂度从三次方降至二次方。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicLG3zpjl1pDEBiaPJ6JTy80ic52icQqHjb5RysQTfMM38Cy6icYLhAibyicRtA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.45092592592592595" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027056" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f06d03d2-6f7f-4e2d-8294-d5541409cac9/640.jpeg" alt="图片" data-before-load-time="1767595211029" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大规模数据蒸馏&amp;nbsp;具有高质量和多样性的大规模数据集是深度学习模型成功的关键要素。然而，实验确定的蛋白质结构数量仍然有限。该研究构建了一个源自 AlphaFold2 的大规模数据集，包含 2650 万个样本，相比实验结构数据，训练数据规模扩大了 147 倍。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicL16vf6GGYa1GVnr6YzFeZNkpL3C7lE68f5puLvq7gvINqOiaq2lwNfOw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.19722222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027057" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7afde98b-fe84-4270-aff2-f458f135f460/640.jpeg" alt="图片" data-before-load-time="1767595211037" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了评估 SeedFold 的性能，该研究在 FoldBench 上进行了综合评估，将 SeedFold 与 AlphaFold 3、Boltz-1、Protenix 和 Chai-1 等最新方法进行了比较。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicLZ3auwjHpjpkAJ3pR14qwTUKdu3x4J4f1GHUbINForSe4H39jFSNPEg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-ratio="0.5333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027058" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4d39fc84-cc15-4b69-83e3-dfead240b129/640.jpeg" alt="图片" data-before-load-time="1767595211037" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;结果显示，在所有评估指标上，SeedFold 均超越了现有开源模型。值得注意的是，SeedFold 和 SeedFold-Linear 展现出不同的学习特性：尽管两者在单体蛋白质和蛋白质 - 蛋白质复合物任务上都超越了 AlphaFold3，但它们的优势表现具有任务特异性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicLKHv0OibsmClKcq2Cj4RXmAL9IwVSpLoia0qly437yWs70fPKNOxiaxLow/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-ratio="0.37222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027059" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c3056701-ce41-45c9-8624-a757519f137e/640.jpeg" alt="图片" data-before-load-time="1767595211048" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SeedFold 在抗体 - 抗原相互作用预测中表现优于 AlphaFold3，而 SeedFold-Linear 则在蛋白质 - 配体相互作用预测中表现突出。这一发现凸显了结合异构注意力机制对于优化特定应用场景模型性能的重要价值。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLnCSMmdNd2SibwlfRL5r0jicL6Elj9rAenneYa2gcdicOAR8dF5Gicq8Fr7GqQI1yrjBk0soItibKGHqKA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=9" data-ratio="0.4166666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027060" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/b2fc216d-4402-46f2-a849-f879914a220f/640.jpeg" alt="图片" data-before-load-time="1767595211065" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;感兴趣的读者可以阅读论文原文，了解更多研究内容。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CES 2026超前瞻：空间智能来势汹汹！从实验室奢侈品到消费级刚需，如何重塑 AI 具身时代？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 05 Jan 2026 14:38:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4c27c171-0bdd-49ed-b7e0-52a360e0857c/1767594959077.png" style="width: 700%;" class="fr-fic fr-dib"&gt;明天，一年一度的 CES 即将在美国拉斯维加斯璀璨开幕。作为全球科技产业最重要的风向标之一，笔者在超前探访之后欣喜发现，在今年机器人「后厨翻炒」与 AI 眼镜「同声传译」的热闹之外，行业终于开始直面核心命题：无法理解三维空间的 AI，终究只是缺乏行动力的 「语言巨人」。&lt;/p&gt;&lt;p&gt;如何解题？空间智能（Spatial Intelligence），这一被李飞飞定义为 「AI 下一个十年」 的关键赛道，正在本届 CES 上完成从学术概念到产业实践的突破性跨越。从巨头的算力竞赛到中国初创企业的端侧破局，一场关于 「空间智商」 的全球竞速已悄然开幕，让我们一探究竟 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;今年 CES 2026 展馆，具身智能（Embodied AI）仍旧是各大厂商的展示重点，但在这背后一种冷静的共识正在行业底层悄然凝聚：如果 AI 不能像生物一样理解三维空间，那么它将永远被困在屏幕或昂贵的遥控器里。&lt;/p&gt;&lt;p&gt;今年，当大众还在讨论大语言模型（LLM）的逻辑能力时，一批专注于「空间智能」的公司已经开始在端侧重构 AI 的感知边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;感知困局：万亿参数为何敌不过一只苍蝇的空间直觉？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CES 2026 的展台前，一个矛盾现象引发行业深思：一边是参数规模突破万亿、逻辑推理能力逼近人类的大语言模型（LLM）；另一边是依赖激光雷达或人工远程操控才能勉强运行的智能设备。多数 AI 眼镜仍停留在 「2D 提词器」 的初级阶段，而号称 「自主决策」 的机器人，在复杂物理环境中甚至难以完成简单的避障动作。&lt;/p&gt;&lt;p&gt;「一只苍蝇没有万亿级参数，却能在杂乱空间中极速避障、精准着陆。」 一位资深 AI 投资人的感叹，点出了当前具身智能的核心痛点。&lt;/p&gt;&lt;p&gt;正如 OpenAI 前首席科学家 Ilya Sutskever 与 Meta AI 负责人 Yann LeCun 共同指出的：物理世界的常识无法通过文字完全习得。猫与苍蝇不识字，却凭借与生俱来的空间直觉，在 3D 环境中展现出远超超级计算机的感知与决策能力。&lt;/p&gt;&lt;p&gt;这种「语言强、手脚笨」的困境，本质上便是「空间智能」的缺失。&lt;/p&gt;&lt;p&gt;李飞飞曾定义「空间智能」为 AI 的下一个十年：若 AI 无法理解物体的深度、距离、遮挡与重力，就永远无法真正 「具身」。在语言智能趋于饱和的今天，AI 行业的竞争焦点正从 「参数竞赛」 转向 「感知革命」&amp;mdash;&amp;mdash; 谁能以更低成本实现更快的空间直觉，谁就掌握了下一轮技术浪潮的主动权。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;空间智能：AI 理解世界的「认知革命」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为何整个行业将破解具身困境的希望押注于「空间智能」？其根本原因在于，这并非一次寻常的技术迭代，而是一场让 AI 获得「人类理解世界」底层能力的认知革命。&lt;/p&gt;&lt;p&gt;李飞飞在其论述中深刻指出，空间智能是人类认知的「脚手架」。从婴儿通过抓握与爬行来探索环境，到消防员在浓烟中凭借直觉判断建筑坍塌的风险，我们无时无刻不依赖着对深度、距离、遮挡和物理关系的瞬间理解。这种能力在文字诞生之前便已存在，它根植于进化之中，是连接感知与行动、驱动智能涌现的核心循环。&lt;/p&gt;&lt;p&gt;然而，当前最被人熟知的 AI 工具却似乎尚未具备这种思维方式。它们能处理海量文本与图像，却在理解物体间空间关系、预测物理动态等根本任务上表现薄弱，与它们所试图交互的物理现实严重脱节。&lt;/p&gt;&lt;p&gt;要弥合这一鸿沟，李飞飞提出需要为 AI 构建全新的认知基础 &amp;mdash;&amp;mdash; 即能够理解、推理并与复杂世界交互的「世界模型」。这要求模型具备三种核心能力：生成性，能创造在视觉、几何与物理层面皆一致的世界；多模态性，可融合处理文本、图像、动作等多种信号；交互性，能预测动作对世界状态的影响。这远超越了对语言序列的建模，是对高维、动态物理规律的统一表征，其挑战规模空前。&lt;/p&gt;&lt;p&gt;一旦攻克空间智能，意味着 AI 将首次获得类似生物的空间直觉与物理常识。&lt;/p&gt;&lt;p&gt;这将不再是让机器「看到」更多像素，而是让其「理解」场景中物体为何存在、如何关联，以及将如何变化。由此，AI 才能从被动的信息处理器，蜕变为能在真实世界中主动规划、安全交互的智能体。&lt;/p&gt;&lt;p&gt;这场认知革命的产业价值不言而喻。一旦 AI 掌握了空间智能，自动驾驶将拥有媲美人类的场景理解与预判能力；机器人能在复杂环境中实现真正自主的导航与灵巧操作；智能制造、医疗手术辅助等领域也将获得颠覆性的可靠「伙伴」。&lt;/p&gt;&lt;p&gt;这不仅是技术的升级，更是 AI 融入并赋能物理世界的「通行证」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526685" data-ratio="0.8944444444444445" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvMJbfuFPswa8nXlCsVOwlMstRGCtBLT8A3BsMvjibNI3h3cQz3Zqudvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/853c10bc-4095-4c50-96c7-a604d9be18aa/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;全球竞速：「世界生成」与「空间决策」技术路径分野&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前，空间智能的技术革命催生了两大核心路径的分化：世界生成派与空间决策派。&lt;/p&gt;&lt;p&gt;一条致力于构建与生成逼真的 3D 世界，为 AI 提供学习和训练的无限场景；另一条则专注于在现实环境中实现实时的空间理解与动作决策，让 AI 能真正「动手操作」、像人一样融入真实物理世界。&lt;/p&gt;&lt;p&gt;本届 CES 清晰地展现了这两种路径的平行竞赛与互补可能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;路径一：世界生成 &amp;mdash;&amp;mdash; 创造 AI 的「无限模拟场」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该路径的核心在于，通过生成式模型构建高保真、可交互的虚拟环境，为机器人训练、游戏娱乐、影视创作等提供「数字孪生」基础。&lt;/p&gt;&lt;p&gt;META 凭借 SAM 3 (3D）项目，致力于为物理世界中的万物进行 3D 标记与重建，旨在建立最庞大的视觉词典。由李飞飞领衔的 World Labs 则走得更远，其「Marble」模型不仅能够理解 3D 场景，更能像造物主一样生成并与之交互，是目前空间建模的「科研天花板」。来自中国的 GIGA 同样聚焦于此，专注于利用神经渲染等技术，从 2D 图像或视频中高效生成高质量的 3D 场景资产。&amp;zwnj;&lt;/p&gt;&lt;p&gt;这条路径的价值在于，它能为缺乏真实交互数据的机器人训练，以及需要大量 3D 内容的创意产业，提供一个成本可控、规模无限的「练兵场」和「素材库」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;路径二：空间决策 &amp;mdash;&amp;mdash; 赋予机器「实时行动力」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与「造世界」的宏大叙事并行，另一批公司正攻坚更具即时挑战的命题：如何让机器基于当下的视觉输入，在毫秒间理解空间关系并做出安全、精准的决策。&lt;/p&gt;&lt;p&gt;NVIDIA 的 NitroGen 项目通过建立视觉到动作的端到端模型，减少传统规划环节的延迟。自动驾驶领域的小鹏汽车等其城市级智能驾驶系统本质上是在复杂开放的世界中完成持续的空间决策。银河通用（Galbot） 研发的 VLA 模型，试图将视觉感知、语言指令与动作生成紧密耦合，让机器人「看到即思考，思考即行动」。联汇科技 OmAI 则更侧重于通过普通 RGB 摄像头和有限的端侧算力下，实现极高精度的 3D 开放空间感知，为无人装备和可穿戴设备提供视觉决策核心。&lt;/p&gt;&lt;p&gt;这条路径的竞争，围绕着实时性、精度、功耗与成本展开，直接决定了具身智能能否走出实验室，走进动态变化的真实生活与普通消费场景。&lt;/p&gt;&lt;p&gt;当然，两条路径并非割裂，而是共同构成空间智能的完整闭环。&lt;/p&gt;&lt;p&gt;「世界生成」为「空间决策」提供了海量、安全的训练与仿真环境；而「空间决策」中带来的真实数据与挑战，又不断反哺和修正「世界生成」的模型，使其更贴近物理规律。&lt;/p&gt;&lt;p&gt;这场竞速的本质，是 AI 在「虚拟」与「现实」之间构建双向通道的能力比拼，其终点则是创造出真正具备空间常识、能与人类世界无缝交互的智能体。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行业拐点：当空间感知进入「百元时代」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;但比终点更早来临的将是行业「拐点」。&lt;/p&gt;&lt;p&gt;不论何种技术路径的演进，都将指向一个清晰的产业目标：将曾经成本高昂的空间感知能力变成一项可大规模普及的基础服务。&lt;/p&gt;&lt;p&gt;在本届 CES 现场，我们还看到了关于纯视觉路径打破空间感知 「昂贵魔咒」的更多可能。&lt;/p&gt;&lt;p&gt;长期以来，3D 空间感知被昂贵的硬件设备所垄断：多摄像头 BEV 架构或数千美元的激光雷达，让具身智能只能局限于高端实验室和工业场景。但在 2026 年的展台上，一种 「视觉优先」 的技术路径正在改写游戏规则。&lt;/p&gt;&lt;p&gt;美国 AI 顶级大厂率先吹响了范式转型的号角 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;META SAM 3 (3D）：试图把全世界的物体在 3D 空间中「标记」出来，为 AI 提供最全的视觉词典。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;META 谢赛宁 (SuperSensing）：追求超越像素的物理洞察力，让 AI 能「看透」运动物体的物理惯性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;NVIDIA NitroGen：建立 Vision-Action（视觉－动作）的直连通路，让机器人不再通过语言大脑转译，而是凭视觉直觉直接做出反应。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;顶级厂商不计成本地利用算力优势打造的「大」模型，对端侧的硬件也有极高的要求，「堆料」成为主流美式机器人厂商和可穿戴设备厂商的唯一选择。&lt;/p&gt;&lt;p&gt;不过，笔者也在 CES 现场看到了另一类产业化技术破局者 &amp;mdash;&amp;mdash; 著名的消费电子品牌韶音（Shokz）与 AI 空间智能厂商联汇科技（OmAI）联合推出的 AI 眼镜，它展示了一种极具破局性思路的技术路径。&lt;/p&gt;&lt;p&gt;这款搭载了联汇科技 OmAI 核心空间智能技术的 AI 眼镜：彻底抛弃了昂贵的传感器，仅通过普通的 RGB 摄像头 + 端侧的 OmModel 模型，即实现了实时的 3D 开放空间感知。对于用户而言，这副轻便的眼镜能将物理世界即时转化为清晰的避障指令；而对于行业而言，可轻便搭载的高性能低成本的空间感知能力，意味着：模型优势可以将 3D 空间感知的成本降到单目摄像头的水平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvOxEliawwI8MPfdlXrZ19HBKm48G74qlHtQQdVxMRwyw5oj3A979ictRA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8351851851851851" data-type="gif" data-w="1080" type="block" data-imgfileid="503526703" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/530350e4-241f-4498-bff9-7a7328be8c03/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;过去，实现可靠的 3D 感知往往意味着高昂的硬件成本 &amp;mdash;&amp;mdash; 多摄像头 BEV（鸟瞰图）架构或者是数千美元的激光雷达。这使得具身智能被禁锢在昂贵的工业场景或高端实验室中。&lt;/p&gt;&lt;p&gt;如今，算法重构让高精度空间感知能力得以嵌入低功耗端侧芯片 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;其一，脱离激光雷达的纯视觉方案，让 AI 眼镜、家用机器人等设备真正进入消费级价格区间；&lt;/p&gt;&lt;p&gt;其二，端侧实时处理能力，为盲人导航、具身机器人等场景筑牢安全底线；&lt;/p&gt;&lt;p&gt;其三，从 「看到物体」 到 「理解空间」 的跨越，让具身智能完成了从感知到决策的关键进化。&lt;/p&gt;&lt;p&gt;当底层算法重构取代了硬件堆砌，具身智能也将迎来走出实验室的可能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;投资人观察：寻找具身智能领域的「Intel Inside」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在提前看展的过程中，一位同行的硅谷投资人坦言：「过去我们看参数规模，现在我们看空间智能的落地效率。谁能让 AI 在物理世界中实现&amp;lsquo;仿生灵动&amp;rsquo;，谁就赢得了下一个十年。」&lt;/p&gt;&lt;p&gt;具身智能和可穿戴设备的「iPhone 时刻」，或许将始于这次 CES 展释放的空间感知成本革命信号 &amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;从「实验室」到「消费级」：当 3D 空间感知的成本从数万元（激光雷达方案）降至数百元（纯视觉算法方案）时，市场容量将发生指数级扩张。不仅是盲人眼镜，扫地机器人、低空无人机乃至消费级具身机器人的大规模落地将不再受困于硬件整机成本门槛。&lt;/p&gt;&lt;p&gt;数据的入口效应：谁能让 AI 在各类复杂室内外场景中实现「视觉闭环」，谁就掌握了物理世界最真实的数据流。这种数据的护城河，远比单纯的文本爬取深得多。&lt;/p&gt;&lt;p&gt;投资人的集体共识指向了一个清晰趋势：未来 3-5 年，具备端侧、实时、高精度 3D 空间感知与决策能力的企业，将成为具身智能生态中不可或缺的 「视觉芯片级」 供应商，其行业地位也将堪比 PC 时代的 Intel、移动时代的 ARM，因为这些厂商会让具身智能和可穿戴设备真正走入千家万户，成为新的消费级市场。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvcib9t5SuDgNdgJzrMVDrGKuEPbvEP7d8PaQfDENOpEHQctPcrd94BGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8342592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526690" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2b504692-7041-4df9-b01a-f26672890f6a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从 CES 2026 的现场来看，这场从「语言智能」到「空间智能」的跃进已经不可逆转。而这场革命的想象力远不止于此：在消费端，百元级 3D 感知方案将催生智能穿戴、智能家居的新品类爆发，让 AI 设备成为像手机一样的生活必需品。在工业端，低成本空间智能将推动智能制造、物流仓储的效率革命，为企业降本增效提供核心动力。在社会价值层面，它将为残障人士、老年人等各类刚需群体带来更便捷的生活方式，加速 AI 普惠。&lt;/p&gt;&lt;p&gt;如果说过去两年，LLM 以「博学」令人震撼。那么，未来三年，AI 将以其在物理世界中的「仿生灵动」与「自主」重新定义智能边界，而我们正在见证 AI 从「语言智能」向「空间智能」的范式跃进。在这场全球竞速中，技术范式的重构、成本门槛的突破、应用场景的落地，正共同推动具身智能迎来真正的「iPhone 时刻」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026 Oral｜InfiGUI-G1模型来了，刷新GUI Grounding SOTA</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 05 Jan 2026 14:33:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-05</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-05</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/a8453d26-d857-485a-9277-fa5bd904b237/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着多模态大语言模型（MLLM）的飞速发展，能够像人类一样通过视觉输入操作图形用户界面（GUI）的智能体（Agent）正逐渐成为现实。然而，在通往通用计算机控制的道路上，如何让模型精准地将自然语言指令对应到屏幕上的具体元素 &amp;mdash;&amp;mdash; 即 GUI Grounding 任务，依然是一大难题。&lt;/p&gt;&lt;p&gt;现有的方法，特别是基于验证奖励的强化学习（RLVR），虽然在提升 &amp;ldquo;指得准&amp;rdquo;（空间对齐）方面表现出色，却往往在 &amp;ldquo;指得对&amp;rdquo;（语义对齐）上遭遇瓶颈。模型常常陷入 &amp;ldquo;自信陷阱&amp;rdquo;，在复杂的语义场景下无法通过有效探索找到正确的功能图标。&lt;/p&gt;&lt;p&gt;针对这一痛点，来自浙江大学、香港理工大学及 InfiX.ai 的研究团队提出了一种全新的&lt;strong&gt;自适应探索策略优化框架（AEPO）&lt;/strong&gt;，并推出了&lt;strong&gt;&amp;nbsp;InfiGUI-G1&amp;nbsp;&lt;/strong&gt;系列模型。该模型通过多答案生成与自适应奖励机制，彻底打破了传统 RLVR 的探索瓶颈。仅凭 3B 和 7B 的参数量，InfiGUI-G1 便在多个高难度 GUI 基准测试中刷新了 SOTA，部分指标甚至大幅超越了闭源模型。&lt;/p&gt;&lt;p&gt;本文将深入介绍这项被 AAAI 2026 接收为 Oral 的工作，解读其如何通过 &amp;ldquo;学会探索&amp;rdquo; 来实现更精准的 GUI 语义理解。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LsDpXzzCsVoefGyvR5nP6s26Ur5YV6aMVhVrgpqLplJNwNWWdEHI1Eg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.26481481481481484" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526422" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a38e844c-011f-422d-a7fa-bf3e0b62a368/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2508.05731&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/InfiXAI/InfiGUI-G1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从 &amp;ldquo;空间对齐&amp;rdquo; 到 &amp;ldquo;语义对齐&amp;rdquo;：被忽视的探索瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GUI Grounding 任务的核心是将自然语言指令（如 &amp;ldquo;打开相机&amp;rdquo;）映射到屏幕上的特定元素坐标。研究团队指出，这一任务可以解构为两个正交的维度：&lt;/p&gt;&lt;p&gt;1. 空间对齐（Spatial Alignment）：能否精确地定位到元素（即 &amp;ldquo;指得准&amp;rdquo;）。&lt;/p&gt;&lt;p&gt;2. 语义对齐（Semantic Alignment）：能否识别出功能正确的元素（即 &amp;ldquo;指得对&amp;rdquo;）。&lt;/p&gt;&lt;p&gt;现有的 RLVR 方法（如 Naive RLVR）虽然能通过优化坐标生成来提升定位精度，但在面对语义模糊或复杂的指令时却显得力不从心。&lt;/p&gt;&lt;p&gt;例如，当指令是 &amp;ldquo;使用相机搜索物体&amp;rdquo; 时，屏幕上可能同时存在普通的 &amp;ldquo;相机应用&amp;rdquo; 和具有视觉搜索功能的 &amp;ldquo;Google Lens&amp;rdquo;。缺乏深度语义理解的模型往往会自信地死磕 &amp;ldquo;相机应用&amp;rdquo; 图标。由于传统 RL 依赖当前策略采样，模型会不断重复这个高置信度的错误，陷入&amp;ldquo;自信陷阱&amp;rdquo;（Confidence Trap），从而无法发现真正正确的 &amp;ldquo;Google Lens&amp;rdquo; 图标，导致无法获得修正语义误解所需的学习信号。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LWvjXB0DibMlJIG9y5svCdszoug57NV0NqV3HvGlHBuiagnOnQNDiaUL0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.7481481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526418" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/86e65a0c-5263-4b5d-863d-40bf37bc1c50/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; GUI Grounding 的主要失败模式： (a) 空间对齐失败，(b) 语义对齐失败&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;InfiGUI-G1：自适应探索策略优化（AEPO）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决这一探索效率低下的问题，InfiGUI-G1 引入了 &lt;strong&gt;AEPO（Adaptive Exploration Policy Optimization）&lt;/strong&gt; 框架。与传统的单次回答生成不同，AEPO 旨在通过更广泛且高效的探索来捕捉低概率但正确的选项。&lt;/p&gt;&lt;p&gt;AEPO 框架由三个协同工作的核心组件构成：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 多答案生成机制（Multi-Answer Generation）&lt;/strong&gt; 传统的 RL 方法通常只采样一个动作，一旦模型 &amp;ldquo;固执己见&amp;rdquo; 地选错，梯度的学习信号就会消失。AEPO 强制模型在一次前向传递中生成 N 个候选坐标点。这一机制迫使模型跳出单一的高置信度预测，去探索策略分布长尾中的可能性，从而大幅增加了发现正确答案（如上述例子中的 Google Lens）的概率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 自适应探索奖励（Adaptive Exploration Reward, AER）&lt;/strong&gt; 仅仅生成多个答案是不够的，如何评价这些答案的质量至关重要。研究团队基于效率第一性原理（效率 = 效用 / 成本）设计了 AER 函数。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;动态激励&lt;/strong&gt;：如果模型在靠前的排名（Rank k）就找到了正确答案，给予高额奖励；如果失败，则给予较小的惩罚以鼓励继续探索。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这种非线性的奖励设计在失败时鼓励模型 &amp;ldquo;广撒网&amp;rdquo;，在成功时引导模型追求 &amp;ldquo;快准狠&amp;rdquo;，实现了探索与利用的动态平衡。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 共线惩罚（Collinear Penalty）&lt;/strong&gt; 为了防止模型通过生成近似直线的点来 &amp;ldquo;作弊&amp;rdquo;（简单的线性扫描策略），研究引入了共线惩罚。如果生成的多个候选点在几何上近似共线，将被视为低质量探索并受到严厉惩罚。这强制模型在语义空间而非单纯的几何空间中进行多样化探索。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LiaKjYTG0saXiaNFibOXUL1wzMfv6wqib3g2sibUnicCUKugicZN7C4uHTiaic6w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.38333333333333336" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526423" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/60ebbd40-2acc-4b72-ba7d-12107ab150ea/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AEPO 与 Naive 强化学习基准方法的对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：小参数量实现性能越级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 MMBench-GUI、ScreenSpot-Pro、UI-Vision 等五个极具挑战性的基准上对 InfiGUI-G1（3B 和 7B 版本）进行了全面评估。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 综合性能全面领先&lt;/strong&gt;：在 MMBench-GUI 基准测试中，InfiGUI-G1-7B 在 Windows、iOS、Android 等多个平台上的表现均刷新了开源模型的最佳成绩。值得注意的是，InfiGUI-G1-7B 在部分指标上甚至优于参数量大得多的 Qwen2.5-VL-72B 和闭源模型 GPT-4o。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 攻克高难度语义理解任务&lt;/strong&gt; ScreenSpot-Pro 基准专门区分了文本类（Text）和图标类（Icon）任务。结果显示，InfiGUI-G1 在更依赖语义理解的 &amp;ldquo;图标&amp;rdquo; 任务上提升尤为明显。这直接证明了 AEPO 策略有效解决了语义对齐的瓶颈，让模型真正 &amp;ldquo;看懂&amp;rdquo; 了抽象图标背后的功能含义，而不仅仅是进行简单的文本匹配。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 让 &amp;ldquo;不可学习&amp;rdquo; 变得 &amp;ldquo;可学习&amp;rdquo;&lt;/strong&gt; 为了验证 AEPO 是否真的解决了探索难题，研究团队将样本按难度分为简单、中等和困难。实验发现，InfiGUI-G1 在 &amp;ldquo;困难&amp;rdquo; 样本（即基座模型几乎无法答对的样本）上的提升最为巨大，相对 Naive RLVR 基线提升了超过 &lt;strong&gt;60%&lt;/strong&gt;。这意味着 AEPO 成功挖掘出了那些以往因缺乏探索而被模型 &amp;ldquo;放弃&amp;rdquo; 的长尾知识。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526425" data-ratio="0.4351851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LzHpov1xzeJcqdqLxrjdFWAicCiaoicgNLVbAO7qYo8Fibl2SE5O1SEJ1GQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/ef7109c8-b171-4428-b33b-b7d5492f473d/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ScreenSpot-Pro 基准测试的性能对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;InfiGUI-G1 的成功表明，GUI 智能体的性能瓶颈不仅仅在于视觉识别能力，更在于如何通过有效的强化学习策略来解决语义对齐问题。通过引入自适应探索机制，InfiGUI-G1 以极高的数据效率和较小的模型规模，实现了超越大模型的 GUI Grounding 能力。这项工作为未来开发更通用、更智能的 GUI 交互助手提供了坚实的技术基础。&lt;/p&gt;&lt;p&gt;目前，InfiGUI-G1 的代码、模型权重及相关资源已在 GitHub 开源，欢迎社区进一步研究与使用。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>田渊栋2025年终总结：救火Llama4但被裁，现任神秘初创公司联创</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 16:34:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8424773e-17cc-41e0-990d-fa02d4896204/1767514913138.png" style="width: 700%;" class="fr-fic fr-dib"&gt;去年 10 月，Meta 人工智能部门的裁员波及到了一大波人，其中包括了知名华人科学家田渊栋及其团队成员。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526647" data-ratio="0.35833333333333334" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvec6g9tXXabibQOzlY0JvibauE7ejbf0UT0bZyqTBp5YTISsOp6CR5REQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d3dca246-b4cf-400b-bf92-1645e61105ea/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;就在这两天，田渊栋分享了自己的 2025 年终总结。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526634" data-ratio="0.36666666666666664" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvUeu6A4XtFHXTBVpwI9UquicAm3k67UzWOnyOb1zC4XI52GJicDPwG7gQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/3e3c2d98-dd58-4e9b-893e-76cd72540370/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526635" data-ratio="0.36203703703703705" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvuD2txxHZzC9uE00XlaqESdqUy2WRB5anPBD6HxCTXaibuc49dJM8hvw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cd2e5b79-8119-4a83-890f-377fa506a7af/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;他首先透露了自己「救火」Llama 4 项目的经历以及之后被裁、未来的工作规划；接着回顾了 2025 年的主要研究方向，包括大模型推理和打开模型的黑箱；最后探讨了 AI 驱动下的社会变革、生产力重构以及个人价值的存续逻辑。&lt;/p&gt;&lt;p&gt;接下来为田渊栋知乎原文内容。&lt;/p&gt;&lt;h3&gt;2025年终总结（一）&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;关于被裁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 2025 年 1 月底被要求加入 Llama4 救火的时候，作为一直以来做强化学习的人，我事先画了一个 2x2 的回报矩阵（reward matrix），计算了一下以下四种可能（虽然在那时，因为来自上面的巨大压力，不同意是几乎不可能的）：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526636" data-ratio="0.14907407407407408" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvEOFaib9lToC1ibZdQgTsQ6TMEGXVgicFDF5Wgv2LtuLvg15fgK7grjqzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/092daf5d-2084-440f-9d66-a67617b3596a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当时想的是我们去帮忙的话，即便最后项目未能成功，也至少尽力而为，问心无愧。不过遗憾的是，最后发生的是没在计算之内的第五种可能，这也让我对这社会的复杂性有了更为深刻的认识。&lt;/p&gt;&lt;p&gt;尽管如此，在这几个月的努力过程中，我们还是在强化学习训练的核心问题上有一些探索，比如说训练稳定性，训推互动，模型架构设计，和预训练 / 中期训练的互动，长思维链的算法，数据生成的方式，后训练框架的设计等等。这个经验本身是很重要的，对我的研究思路也带来了不小的转变。&lt;/p&gt;&lt;p&gt;另外其实我也想过在公司十年多了，总有一天要离开，总不见得老死在公司里吧，但总是因为各种经济上和家庭上的原因还是要待下去。最近一两年的说话和做事方式，都是抱着一种 &amp;ldquo;公司快把我开了吧&amp;rdquo; 的心态，反而越来越放开。2023 年年末我休第一个长假的时候，其实几乎差点要走了，但最后没签字还是选择待在公司继续，所以说真要做出离开的决定也不容易。现在 Meta 帮我做了也挺好。&lt;/p&gt;&lt;p&gt;这次波折和今年一年的起起落落，也为接下来的小说创作提供了非常多的新素材。所谓 &amp;ldquo;仕途不幸诗家幸，赋到沧桑句便工&amp;rdquo;，生活太平淡，人生就不一定有乐趣了。还记得 2021 年年头上的时候，因为在年末工作总结里面写了几句关于&amp;rdquo; 为啥 paper 都没中 &amp;ldquo;的反思，喜提 Meet Most，有一种突然不及格的懵逼感。但想了想与其到处抱怨世道不公，不如就在大家面前装成自己刚刚升职吧，结果半年后果然升了职，而那篇 21 年头上无人问津的工作，在 21 年 7 月份中了 ICML Best paper honorable mention，成为一篇表征学习中还比较有名的文章。&lt;/p&gt;&lt;p&gt;10 月 22 号之后的一段时间，基本上我的各种通信方式都处于挤爆的状态，每天无数的消息和邮件，还有各种远程会议或者见面的邀请，实在是忙不过来了。一直到几周之后才渐渐恢复正常。这两个月非常感谢大家的关心和热情。如果那时有什么消息我没有及时回复，请见谅。&lt;/p&gt;&lt;p&gt;虽然最后有不少 offer，大家能想到的知名公司也都联系过我，但最后还是决定乘自己还年轻，去当一家新初创公司的联合创始人，细节暂时不公开，先安静地忙活一阵吧。根据 Linkedin 信息显示，他已经于去年 12 月在这家公司上任。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526637" data-ratio="0.18518518518518517" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvcupzicP87od5baiapaoriaDUg3lrlnnHrISLqqbTUuSibrwS4EUQfEiatuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/c7586d1e-5f84-48d2-880b-795415e766cc/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;一些研究的方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的主要方向，一个是大模型推理，另一个是打开模型的黑箱。&lt;/p&gt;&lt;p&gt;自从 2024 年末我们的连续隐空间推理（coconut，COLM&amp;rsquo;25）工作公开之后，25 年在这个研究方向上掀起了一股热潮。大家探索如何在强化学习和预训练中使用这个想法，如何提高它的训练和计算的效率，等等。虽然我们组随后就被拉去 llama 干活，没能再继续花很大力气往下挖，但这个让我觉得非常欣慰。尽管如此，我们还是在上半年发了一篇理论分析（Reasoning by Superposition，NeurIPS&amp;lsquo;25）的文章，展示连续隐空间推理有优势的地方究竟在哪里，获得了不少关注。&lt;/p&gt;&lt;p&gt;另外是如何提高大模型的推理效率。我们的 Token Assorted（ICLR&amp;rsquo;25）的工作，先通过 VQVAE 学出隐空间的离散 token，再将所得的离散 token 和 text token 混在一起进行后训练，减少了推理代价的同时提高了性能。我们的 DeepConf 通过检测每个生成 token 的自信程度，来决定某条推理路径是否要被提前终止，这样推理所用的 token 减少了很多，但在 majority vote 的场景下性能反而更好。ThreadWeaver 则是通过制造并行推理的思维链，并在其上做后训练，来加快推理速度。另外我们也在 dLLM 上用 RL 训练推理模型（Sandwiched Policy Gradient），也有在小模型上学习推理的尝试（MobileLLM-R1）。&lt;/p&gt;&lt;p&gt;在可解释性方面，Grokking（顿悟）这个方向我大概两年前就在关注了。因为之前我做表征学习（representation learning）的分析，虽然能分析出学习的动力学过程，看到模型出现表征塌缩的原因，但究竟学出什么样的表征，它们和输入数据的结构有什么关系，能达到什么样的泛化能力，还是个谜团，而通过分析 Grokking 这个特征涌现的现象，从记忆到泛化的突变过程，正好能解开这个谜团。一开始确实非常难做没有头绪，2024 年先做了一篇 COGS（NeurIPS&amp;lsquo;25，见求道之人，不问寒暑（十）），但只能在特例上进行分析，我不是很满意。在一年多的迷茫之后，在和 GPT5 大量互动之后，最近的这篇 Provable Scaling Laws 的文章应该说有比较大的突破，能分析出之前的线性结构（NTK）看不到的东西，并把特征涌现的训练动力学大概讲清楚了。虽然说分析的样例还是比较特殊，但至少打开了一扇新的窗口。详细解释请看田渊栋的想法。&lt;/p&gt;&lt;p&gt;年末的这篇 The path not taken 我很喜欢，对于 RL 和 SFT 的行为为何会如此不一致，在权重的层面给出了一个初步的答案。SFT 造成过拟合和灾难性遗忘（catastrophic forgetting），其表层原因是训练数据不够 on-policy，而深层原因是权重的主分量直接被外来数据大幅修改，导致 &amp;ldquo;根基&amp;rdquo; 不稳，模型效果大降。而 RL 则因为用 on-policy 的数据进行训练，权重的主分量不变，改变的只是次要分量，反而能避免灾难性遗忘的问题，而改变的权重其分布也会较为稀疏（特别在 bf16 的量化下）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于可解释性的信念&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很多人觉得可解释性，或者 &amp;ldquo;AI 如何工作得那么好&amp;rdquo; 这个问题不重要，但我却觉得很重要。试想之后的两种场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;场景一：如果我们仅仅通过 Scaling 就达到了 AGI 乃至 ASI，全体人类的劳动价值都降为零，AI 作为一个巨大的黑盒子帮我们解决了所有问题，那如何让 AI 作为一个超级智能，一直行善，不欺骗不以隐秘的方式作恶，就是当务之急，要解决这个问题就要做可解释性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;场景二：如果 Scaling 这条路最终失效，人类在指数增长的资源需求面前败下阵来，必须得要寻求其它的方案，那我们就不得不去思考 &amp;ldquo;模型为什么有效，什么东西会让它失效&amp;rdquo;，在这样的思考链条之下，我们就必须回归研究，可解释性就是目所能及的另一条路了。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在这两种情况下，最终都需要可解释性来救场。就算最终 AI 是个全知全能全善的神，以人类好奇和探索的天性，必然还是会去研究 AI 为什么能做得好。毕竟 &amp;ldquo;黑盒&amp;rdquo; 就意味着猜疑链的诞生，在大模型技术爆炸，开始达到甚至超过人类平均水平的今天，《三体》中 &amp;ldquo;黑暗森林&amp;rdquo; 的规则，也许会以另一种方式呈现出来。&lt;/p&gt;&lt;p&gt;目前打开训练好模型的黑箱，去找到电路（circuit），还是处于比较初步的阶段。可解释性真正的难点，在于从第一性原理，即从模型架构、梯度下降及数据本身的固有结构出发，解释为什么模型会收敛出这些解耦、稀疏、低秩、模块化、可组合的特征与回路，为什么会有大量不同的解释，这些涌现出来的结构和模型训练的哪些超参数相关，如何相关，等等。等到我们能从梯度下降的方程里，直接推导出大模型特征涌现的必然性，可解释性才算真正从生物式的证据收集走向物理式的原理推导，最终反过来指导实践，为下一代人工智能的模型设计开辟道路。对比四百年前的物理学，我们现在有很多 AI 版的第谷（收集数据），一些 AI 版的开普勒（提出假说），但还没有 AI 版的牛顿（发现原理）。&lt;/p&gt;&lt;p&gt;等到那一天来临的时候，我相信，世界一定会天翻地覆。&lt;/p&gt;&lt;h3&gt;2025年终总结（二）&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;未来会是什么样子&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;抛开前公司里每三个月一次的组织架构重组不谈，2025 年一年的变化本身已经很大。25 年年初的 Deepseek-R1 的发布，现在想来几乎已经算是上个世纪的事情了。带思维链的推理模型的巨大成功，让强化学习（RL）又回到了 AI 的主流视野之中，也带动了 AI4Coding 及 AI Agent 的发展，而后两者让大模型有了大规模落地，大幅度提高生产力的切实可能。&lt;/p&gt;&lt;p&gt;以前做项目，招人是很重要的一环，但现在脑中的第一个问题是 &amp;ldquo;还需不需要人？&amp;rdquo; 几个 Codex 进程一开，给它们下各种指令，它们就可以 24 小时不间断干活，速度远超任何人类，而且随便 PUA 永远听话毫无怨言。和 AI 工作，我最担心的是工作量有没有给够，有没有用完每天的剩余 token 数目。这也是为什么各家都在试验让 AI Agent 做几个小时连续不断的工作，看 AI 的能力上界在哪里。因为人的注意力永远是最昂贵的，人要休息，要度假，要允许有走神、睡觉和做其它事情的时间。减少人的介入，让 AI 自己找到答案，干几个小时活之后再回来看看最好。&lt;/p&gt;&lt;p&gt;这每个月交给 OpenAI 的 20 块钱，一定要榨干它的价值啊。&lt;/p&gt;&lt;p&gt;我突然意识到，就因为这区区 20 块钱，我已经成为了 &amp;ldquo;每个毛孔里都滴着血&amp;rdquo; 的肮脏资本家。我能这么想，全世界最聪明和最富有的头脑，也一定会这么想。&lt;/p&gt;&lt;p&gt;所以请大家丢掉幻想，准备战斗吧。&lt;/p&gt;&lt;p&gt;在帮忙赶工 Llama4 期间，我经常在加州时区晚上 12 点接到东部时区的组员消息，在伦敦的朋友们更是永不下线，熬夜折腾到凌晨四五点是寻常事，但大模型越来越强，辛勤劳动最终达到的结果，是看到大模型达到甚至超越我们日常作事的水准。&lt;/p&gt;&lt;p&gt;这应该说是一种陷入囚徒困境之后的无奈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人类社会的 &amp;ldquo;费米能级&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果以后以 AI 为中心，那还需要人么？&lt;/p&gt;&lt;p&gt;如果考虑劳动力的投入 - 回报模型，传统思维会告诉你，工作经验积累越多，人的能力越强，回报也越大，是个单调上升的曲线。这就是为什么大厂有职级，职级随年限晋升，越老越香。但现在的情况已经不同了。职级已经没有意义，过去的经验也没有意义，人的价值从按照 &amp;ldquo;本人产出的劳动数量及质量&amp;rdquo; 来评估，变成了是否能提高 AI 的能力，人加 AI 要大于 AI 本身的产出，这样才行。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526638" data-ratio="0.5458984375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tvb9ibc7SiaZpCfsGhFicrTEY8H8kCQiblaYCGFXl0e2wFJSiagY8hZclqvCA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-type="jpeg" data-w="1024" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d7c742da-0c94-4a67-b660-15dd5bf39df2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这样就让投入 - 回报曲线从一个单调递增曲线变成了一个先是全零，再在一定阈值之后增长的曲线（也即是 soft-thresholding 的曲线）。一开始人的能力是比不过 AI 的，而 AI 的供给只会越来越便宜，所以在很长一段成长期内，人本身是没有价值的。只有在人的能力强到一定程度之后，能够做到辅助 AI 变强，才开始变得有价值起来。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526640" data-ratio="0.5458984375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tv5rB3QyfiaGc32cj9PSGsNP7fMssxjN0icPib5Z6AKqrtibH1X073Ehof8Q/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-type="jpeg" data-w="1024" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f869485b-aac9-4bfd-8c98-8be837f32414/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;并且，在跨越阈值之后，厉害人对 AI 的加成，会高于普通人很多很多，因为普通人只会对 AI 的一两条具体产出花时间修修补补，而厉害的人在看了一些 AI 存在的问题之后，能提出较为系统性和普遍性的解决方案，结合手上的各类资源（GPU 和数据等），可以进一步让 AI 变得更强，而这种效应随着 AI 的广泛部署，会被几何级数地放大。&amp;ldquo;一骑当千&amp;rdquo; 这种小说笔法，将很快变成现实。&lt;/p&gt;&lt;p&gt;在这样一个非常两级分化的投入 - 回报模型之下，如果把人 + 所有个人能获取的 AI 当成一个智能体，整体来看，它的能力分布会和电子能级在材料里的分布很像：低于或达到某个水准线的智能体遍地都是，求着客户给它活干，以证明自己还是有用的；而高于这个水准线的智能体则指数级地变少，获取和使用它非常花钱，还常常排不到。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526642" data-ratio="0.5458984375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic5UPZUVKVAgo73uyMial9TvZTNib5hrO7ea0ZRql7zvclvkLLeddUau7EBKdWQD8QEX2DpicDG6IvDA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-type="jpeg" data-w="1024" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/10fe7ea3-b46b-4a0c-81ca-1566a4c9902c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这个水准线，就是 AI 洪水的高度，就是人类社会的 &amp;ldquo;费米能级&amp;rdquo;。低于费米能级的职业，可能在一夜之间就被颠覆掉，就像一场洪水或者地震一样，前一天还是岁月静好，后一天整个行业被端掉了。&lt;/p&gt;&lt;p&gt;随着时间变化，这条水准线还会一直往上走。其进展的速度，和它能获取到的，比它更强的数据量成正比。如果大模型的训练过程没有特别大的进展，那和自动驾驶无人车一样，越往上走，有用的数据是越来越少的，进展也会越慢，最顶尖的那部分人，还能在很长时间内保有自己的护城河。如果训练过程有突破，比如说找到新的合成数据手段，乃至新的训练算法，那就不好说了。&lt;/p&gt;&lt;p&gt;当然以上的判断是假设有无限的 GPU 和能源的供给，并没有考虑到各种资源短缺的情况。能源短缺，芯片产能短缺，内存短缺，整个地球能否满足人类日益疯狂增长的 AI 需求还是个未知数，这方面深究下去，或许可以做一篇论文出来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;遍地神灯时代的独立和主动思考&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么，接下来会怎么样呢？&lt;/p&gt;&lt;p&gt;未来的世界，或许不再是传统故事里描绘的那样 &amp;mdash;&amp;mdash; 人们为了争夺稀缺的武功秘籍，或是千辛万苦寻找唯一的阿拉丁神灯、集齐七颗龙珠而展开冒险。相反，这将是一个 &amp;ldquo;遍地神灯&amp;rdquo; 的时代。每一个 AI 智能体都像是一个神灯，它们能力超群，渴望着实现别人的愿望，以此来证明自己的价值。&lt;/p&gt;&lt;p&gt;在这种环境下，真正稀缺的不再是实现愿望的能力，而是 &amp;ldquo;愿望&amp;rdquo; 本身，以及将愿望化为现实的那份坚持。&lt;/p&gt;&lt;p&gt;然而，在这个 AI 能力极其充沛的时代，巨大的便利往往伴随着巨大的陷阱。大模型提供了极其廉价的思考结果，在当前信息交互尚不充分的市场中，这些结果甚至可以直接用来交差并获取经济价值（例如那些一眼就能看出的 &amp;ldquo;AI 味&amp;rdquo; 文案）。这种唾手可得的便利，会让许多人逐渐失去思考的动力，久而久之丧失原创能力，思想被生成式内容和推荐系统所绑架和同化。这就是新时代对 &amp;ldquo;懒人&amp;rdquo; 的定义：不再是因为体力上的懒惰，而是精神上没有空闲去思考，没有能力去构思独特的东西。&lt;/p&gt;&lt;p&gt;最终，变成一具空壳，连许愿的能力都失去了。&lt;/p&gt;&lt;p&gt;那我们该如何保持独立思考？如何不被 AI 同化？战术上来说，我们需要学会不停地审视 AI 的答案，挑它的毛病，并找到它无法解决的新问题。未来的新价值将来源于三个方面：（1）新的数据发现；（2）对问题全新的深入理解；（3）新的路径，包括可行的创新方案及其结果。利用信息不对称来套利只是暂时的。随着模型越来越强，社会对 AI 的认知越来越清晰，这种机会将迅速消失。如果仅仅满足于完成上级交代的任务，陷入 &amp;ldquo;应付完就行&amp;rdquo; 的状态，那么在 AI 泛滥的今天，这种职位极易被取代。&lt;/p&gt;&lt;p&gt;就拿 AI Coding 来说，用多了，我会觉得它虽然可以很快弄出一个可以跑的代码库满足需求，但随着代码越来越长，屎山也越来越高，它贡献的代码也就越来越不如人意，还是需要人来做大的设计规划。如何调教它让它更快达成自己的长远目的，这个会成为人类独有价值的一部分。如果只是盲目地命令它做这个做那个，而不自己去思考如何做才能和它配合做得更好，那就会和大部分人一样停留在应用层面，而无法理解得更深入，就更不用说独一无二了。&lt;/p&gt;&lt;p&gt;战略上来说，无论主动还是被动，每个人都将面临从 &amp;ldquo;员工&amp;rdquo; 角色向 &amp;ldquo;老板&amp;rdquo; 或 &amp;ldquo;创始人&amp;rdquo; 角色的转变。这种转变的核心在于 &amp;ldquo;目标感&amp;rdquo;。如果心中有一个坚定的目标，并愿意动用一切手段（包括将大模型作为核心工具）去达成它，那么主动思考就是自然而然的结果。目标越远大，触发的主动思考就越多，激发的潜力就越大。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526643" data-ratio="0.5458984375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic5UPZUVKVAgo73uyMial9Tv6ficvOKY8P71oQHhS2DJI7ScOwuZVlTEIxgzqDDPicO6ssibDSTDwrOdQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=9" data-type="jpeg" data-w="1024" type="block" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/9db6b922-93d6-45cf-8c62-a31a1b08034d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;因此，如果将来的孩子立志要去土卫六开演唱会，或者想在黑洞边缘探险，千万不要打压这样看似荒诞的志向。因为这份宏大的愿望，或许正是他们一辈子充满前进动力，主动思考的根本源泉，也是让他们始终屹立于 &amp;ldquo;费米能级&amp;rdquo; 之上的关键。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;知乎原文链接 1：&lt;a href="https://zhuanlan.zhihu.com/p/1990809161458540818"&gt;https://zhuanlan.zhihu.com/p/1990809161458540818&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;知乎原文链接 2：&lt;a href="https://zhuanlan.zhihu.com/p/1991073922217709984"&gt;https://zhuanlan.zhihu.com/p/1991073922217709984&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>科研人福音！一键生成PPT和科研绘图，北大开源Paper2Any，全流程可编辑</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 04 Jan 2026 16:21:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-04-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-04-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/97cd12ca-73af-4e95-b58f-b71b385d4176/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;你是否经历过这样的至暗时刻： 明明实验数据已经跑通，核心逻辑也已梳理完毕，却在面对空白的 PPT 页面时陷入停滞； 明明脑海里有清晰的系统架构，却要在 Visio 或 Illustrator 里跟一根歪歪扭扭的线条较劲半小时； 好不容易用 AI 生成了一张精美的流程图，却发现上面的文字是乱码，或者为了改一个配色不得不重新生成几十次&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;在内容生产的过程中，&amp;ldquo;写&amp;rdquo; 往往只占了一半，而将文字转化为结构图、流程图，再整理成演示用的 PPT，这个过程繁琐、耗时，且极度考验设计感。为什么我们不能让 AI 像理解文字一样，理解我们的逻辑，并自动帮我们要展示的 &amp;ldquo;视觉物料&amp;rdquo; 准备好？&lt;/p&gt;&lt;p&gt;为了解决这一痛点，北京大学 DCAI 课题组 基于自动化数据治理 Agent 框架 DataFlow-Agent，推出了全新的多模态辅助平台 &amp;mdash;&amp;mdash; Paper2Any。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibekqYWo7JUbFwicgaf1YCxOb28LdzzK8k7B9eqjeLb7op5L5VbQkRiaicqw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6138888888888889" data-type="png" data-w="1080" data-width="2216" data-height="1361" data-imgfileid="503526157" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3d7fda9a-ad08-4238-a004-39a7c44b906e/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiaHXY1wcnjklMH07NIcVRRrj9P3XIEibpK7xCsvchCaziaoJHJ2pqjRCA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5925925925925926" data-type="png" data-w="1080" data-width="2869" data-height="1699" data-imgfileid="503526158" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c9974b03-f1e5-4e70-a993-934d6797a68d/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;它不再是一个简单的 &amp;ldquo;文生图&amp;rdquo; 工具，而是一整套自动化的内容视觉化 Workflow。从阅读资料、理解逻辑，到生成图像、切割元素，最终输出完全可编辑的 PPT 和 SVG 文件，Paper2Any 正在试图重塑我们准备 Presentation 的方式。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;本地部署方式：&lt;a href="https://github.com/OpenDCAI/Paper2Any?tab=readme-ov-file#-linux-% E5% AE%89% E8% A3%85"&gt;https://github.com/OpenDCAI/Paper2Any?tab=readme-ov-file#-linux-% E5% AE%89% E8% A3%85&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;网页体验地址：&lt;a href="http://dcai-paper2any.nas.cpolar.cn/"&gt;http://dcai-paper2any.nas.cpolar.cn/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;文章多模态工作流 Paper2Any：&lt;a href="https://github.com/OpenDCAI/Paper2Any"&gt;https://github.com/OpenDCAI/Paper2Any&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;一、 核心突破：打破 &amp;ldquo;不可编辑&amp;rdquo; 的魔咒&lt;/h4&gt;&lt;p&gt;目前市面上的 AI 绘图工具虽然效果不错，但在科研与办公等场景下有一个致命缺陷：生成的图片是 &amp;ldquo;死&amp;rdquo; 的。 文字无法修改，模块无法拖拽，风格难以统一。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;span class="fr-img-caption fr-fic fr-dib" style="width: 820.328px;"&gt;&lt;span class="fr-img-wrap"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibek6G1ZNCvJetcmtYmkobtQDsmJiaibqKAAzmdRtloCcO7CWOSVzoqxMWg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5453703703703704" data-type="png" data-w="1080" data-width="1408" data-height="768" data-imgfileid="503526160" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8fed86ca-3701-4ba8-98cc-2f906be2c82f/640.png" alt="图片" data-report-img-idx="7" data-fail="0"&gt;&lt;span class="fr-inner"&gt;&lt;p data-pm-slice="0 0 []"&gt;工作流实现逻辑&lt;/p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;span class="fr-img-caption fr-fic fr-dib" style="width: 820.328px;"&gt;&lt;span class="fr-img-wrap"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeTJy3OIML1Mt5ZxFw9nN8AbhONlzDf1NSTwLibmSkSq9CC4Ao38WWa5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7481481481481481" data-type="png" data-w="1080" data-width="1287" data-height="963" data-imgfileid="503526161" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/9c3940bb-95ca-429b-9d53-29b3a931fe3a/640.png" alt="图片" data-report-img-idx="6" data-fail="0"&gt;&lt;span class="fr-inner"&gt;&lt;p data-pm-slice="0 0 []"&gt;生成示例PPT绘图&lt;/p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;Paper2Any 的核心差异在于它实现了从逻辑到结构化元素的映射。&lt;/p&gt;&lt;p&gt;系统内置的智能体首先对输入的文章或文本进行语义分析，提取核心贡献与思路。接着，它不仅生成视觉图像，更进一步对草稿图进行图文内容分割 &amp;mdash;&amp;mdash; 自动识别其中的文字、图表、结构模块、图标，并记录每个元素的元数据。&lt;/p&gt;&lt;p&gt;这意味着，你拿到的不再是一张不可直接修改的 PNG，而是一组独立、分层、可操作的图文块。用户可以在 PPT 中自由移动、编辑、替换、重新布局。（Paper2PPT 和 PPTPolish 功能暂时仅支持输出 PDF，可通过 PDF2PPT 功能将其结果转为可编辑 PPTX）。&lt;/p&gt;&lt;h4&gt;二、 功能全景：从草稿到演示的自动化闭环&lt;/h4&gt;&lt;p&gt;Paper2Any 目前支持的功能主要涵盖以下四大核心场景，旨在解决从 &amp;ldquo;输入素材&amp;rdquo; 到 &amp;ldquo;最终汇报&amp;rdquo; 的最后一公里问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Paper2Figure：智能科研绘图，草图变精图&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/qQqIZeYhMiOrzi1qeez93g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/525c2410-0254-4c12-88cd-c3e4f344f29a/1767514539478.png" style="width: 700px;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9EricQXXByphb4tN0ha6mibeQy9roDYibpt78xU56za926nhg1yZkDM8Hibuiadr59gsk2UG6ISGfo8qg%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4319948465079271432" data-ratio="1.6127110228401191" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4319948465079271432" data-vh="371.8125" data-vidtype="2" data-vw="661" data-w="3248" height="384" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4319948465079271432"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;用户无需从零学习复杂的矢量绘图软件。Paper2Figure 支持多模态输入（PDF、文本、甚至随手画的草图截图），系统便能自动识别你的意图。&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;模型架构图： 上传论文或描述，系统自动梳理模块连接关系，生成清晰的架构图。支持生成 SVG 和 可编辑 PPTX，图里的方框、线条都能动。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;技术路线图： 无论是中文还是英文，系统能根据方法论自动绘制流程与逻辑步骤。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;实验数据图： 扔给它一堆实验数据文本或表格，它能自动转化为可视化的对比柱状图或折线图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Paper2PPT：文章结构化解析与 PPT 生成&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9EricQXXByphb4tN0ha6mibexcEJZEicZGs8EbmLMyNutvLWZBRxWNz5GzPOTichKd3topVwM1pjCs0w%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4319955297046839314" data-ratio="1.5932560590094837" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4319955297046839314" data-vh="371.8125" data-vidtype="2" data-vw="661" data-w="3024" height="384" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4319955297046839314"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;a href="https://mp.weixin.qq.com/s/qQqIZeYhMiOrzi1qeez93g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/15321460-455c-44b0-ba90-192c69e1c712/1767514581652.png" style="width: 700px;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;这是为 &amp;ldquo;赶进度&amp;rdquo; 的研究者和职场人准备的救星。Paper2PPT 不仅仅是简单的摘要生成，它利用算法对文档结构进行深度语义分析，提取背景、方法论、关键图表。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;三种输入模式： 直接上传 PDF 论文、粘贴长文本、或者仅仅输入一个研究 Topic（系统会自动深度搜索）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;自定义设置： 支持用户自定义幻灯片页数、风格及自由选择中英文语言；支持逐页生成 PPT，用户可自由调整每页 PPT 的大纲。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;超长 PPT 支持：首次支持制作超过 40 页的超长 ppt，无论是综述的演示还是深入研究某个主题都能一次满足！&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中文适配与呈现： 可解决大模型生成 PPT 字体怪异及表达僵硬问题。输出结果采用标准中文字体与规范的排版，文案逻辑自然流畅，可减少 &amp;ldquo;AI 痕迹&amp;rdquo;，满足正式场合演示需求。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiaV0PgTzmEjvZRPTtAttRWoc8s1uC5v51IO3TVanzib2wOXO3SZibUMBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5074074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526167" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/53841032-2a3b-4b5b-bd78-a774a1b3fda7/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;PDF2PPT：让静态文档可编辑&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibenF0Wa8acjiasy7lOOyF08OEZOQp9XacOQ4kVZuoZe395a11fibYWuqsQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5666666666666667" data-type="png" data-w="1080" data-width="2217" data-height="1257" data-imgfileid="503526168" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/afe35107-01c2-4e21-a173-d8771df35162/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;你是否遇到过这种情况：手里只有一份 PDF 格式的讲义或报告，却需要对其进行修改和汇报？&lt;/p&gt;&lt;p&gt;PDF2PPT 模块利用 MinerU 与 SAM (Segment Anything Model) 模型，像 &amp;ldquo;拆积木&amp;rdquo; 一样对版面进行高精度解析，将原本锁死的 PDF 页面还原为可编辑的 PPTX。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;黑科技加持： 系统集成了 Gemini Nano 模型进行图像内补（Inpainting）。当系统将文字提取出来后，会自动修复文字覆盖区域的背景，实现 &amp;ldquo;去字留影&amp;rdquo;，最大程度还原原始底图的视觉效果。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;PPTPolish：交互式美化专家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你的 PPT 内容已经写好，但排版却有些简陋，PPTPolish 可以接手后续的美化工作。系统会自动分析页面并生成美化提示词，用户可以逐页修改提示词来微调美化方向。&lt;/p&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9EricQXXByphb4tN0ha6mibeCkAgXJDGJBfLNysAKJ9vqE5LOA4qwwiaoQ4wialRicmBXX1IKrD3FjEdA%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4319954344587476999" data-ratio="1.5932560590094837" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4319954344587476999" data-vh="371.8125" data-vidtype="2" data-vw="661" data-w="3024" height="384" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4319954344587476999"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;a href="https://mp.weixin.qq.com/s/qQqIZeYhMiOrzi1qeez93g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9bc1bf83-7a25-4158-b5f4-ebc4771800c4/1767514615797.png" style="width: 700px;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;h4&gt;三、 示例高能时刻：从输入到输出的 &amp;ldquo;视觉魔法&amp;rdquo;&lt;/h4&gt;&lt;p&gt;空口无凭，我们来看看 Paper2Any 的实际表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;科研绘图：拯救手残党&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;模型架构图生成：&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;1. 论文 PDF &amp;rarr; 符合论文主题的架构图&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeMAsVicBialuE1wL5NhyWdQnGIClQZICHhGsUSUmvyNTerWBDljo5Yxpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.825925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526181" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/cccafe73-059f-46fe-8f66-e131b3d29883/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;2. 科研配图 / 示意图截图 &amp;rarr; 可编辑 PPTX&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiaWicRia3icQWaDYbSRgCvEXpU1jLLe1FO90ewXERH7nKJp9F0IPkgCqpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.3435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526182" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/c75a9988-42f6-4d50-8298-16eef07816ae/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;3. 论文摘要文本 &amp;rarr; 可编辑架构图&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeBZejS9unQfL4Ky1lv5jtHVicQTH6JiaL4X1bjk3BS0XTszlJkcsa1JNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526183" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/999d5657-33c0-4f34-9b90-b92afd2d9880/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;技术路线图智能梳理：&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;1. 论文 PDF &amp;rarr; 符合论文主题的技术路线图&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe5shmB1lG8StmVz91wN75gLQlnzicFGeb97fGvKqNFTSJiblYeiawqaxJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.41203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526184" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/87bd1869-dd32-4b31-80e4-dcae48914da7/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2. 论文摘要文本 &amp;rarr; 符合论文主题的技术路线图&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeRKORp3dh0UXHgLXjVVicdvia0QiatrlRkrY9hbgoCjYeYVw8drzeJKyNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.3824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526188" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/f1f91047-7555-4408-a963-2c26180cbbfa/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;实验数据可视化：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;1. 论文 PDF &amp;rarr; 自动提取实验数据绘制 PPT&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibedpDjicNHBkhVbiav9ibRwSZdc99vaPQSGLWibDoftygJUtL0rlkhTVJLvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.46944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526189" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/32749ffb-9389-435a-87f3-f8416a212456/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;span class="fr-img-caption fr-fic fr-dib" style="width: 820.328px;"&gt;&lt;span class="fr-img-wrap"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeJ4xGjzmXo1GID9uMj4tE3VUyED8gCOF29rtdY4lyZiaSVgkBQCFnDyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526190" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/a686c2bd-2794-49e6-be20-b882edde47f4/640.png" alt="图片" data-report-img-idx="11" data-fail="0"&gt;&lt;span class="fr-inner"&gt;&lt;p data-pm-slice="0 0 []"&gt;不同类型与不同风格的生成图示例&lt;/p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;2. 论文实验表格文本 &amp;rarr; 自动整理实验数据绘制 PPT&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibem5ZexxicLTBibxRdoeOX36xsEf9LBtcP9ds0gb9NJY2AvPicUibaXxiclVw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.3138888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526191" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/1b9e2c26-402d-4efa-a520-5cb388c46284/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;PPT 智能生成与美化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从文档到演示，Paper2Any 提供了全链路的解决方案。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Paper2PPT：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiclpZYib91jPfhtrhdmapHmT7knBEUtibOToian0MdNAyo6T1ibnWoEvttA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.9416666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526194" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/60288f0e-0dac-4410-9655-8f88f3558ef2/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibevHe42BSTA3McV42QpewCeAa9V3aKf3LUpsic4AyGt8ojmWbDcmbyISg/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.9027777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526195" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/e791743f-9419-4d65-9540-97d60342c64d/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibethPnmyiaHcWk1uTp6N4w0iapGtOA0ESDJDiayvibnPGLAP3gecjbzsU2icg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6768518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526196" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/991b84d5-bcad-4508-a204-6069c4a98d28/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeQln2FsMgs9BvVdwa1gbzCYWqVwUD5CNia0fGF5sxRavCz9picfT0muZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.4064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526197" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/f7ee70ac-afba-4651-abb4-b98389e00494/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibejqlE3Qtgov3EBB7yygalrEldBs6kdK2tZV5aXGFw92xTO61SXibJObg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.9675925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526198" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/f8f44938-7af8-4e6c-8df0-1a8470a6597d/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeCZzsh7H6WmzocFrqG6XLNzDFurqznlk6hckjiaNIZ6L3tFmXDgbL0IA/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.9842592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526225" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/b37c9bc1-4171-4c52-b2a3-e5acc56bc71f/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeVXQVStROBfyLJTgcgfQW653Naj2Y4vgLmzI0OBic2lPOYRWwOjgPOmQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.5638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526256" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/6f1721c0-6dab-4750-81a1-5f4978c27ae3/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeicsmuM2DkWX6Z1nlDmABrZqMLibzOwJJG7HXj37X96jiceBGweS52WW8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526206" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/5d59735f-94c0-478e-8dc7-7fb91b9a4087/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeDSrRcCG9zT5khovqVqZ724nDvU16qTaSdKibCMnh5oslIczsia79eib1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526207" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/ff587460-3034-44f3-9bfe-c01da602d033/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;与 Gemini 3 Pro、NotebookLM 相比，Paper2Any 生成的 PPT 有以下优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;结构化图表生成能力强&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中文文字表达与字体呈现效果更自然&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;可读性更好，干货更多，排版布局更具专业感与人工感&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;PDF2PPT：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe15E244WJgBLZyD4OJlczsPYf2ecEWviagmrA2hDuubkwFOdyRe8CCew/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="0.3453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526211" data-aistatus="1" data-original-style="null" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/126de627-eeaa-4cbc-a67a-b9bb3faab6a5/640.png" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;PPTPolish：&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;1. PPT 增色美化&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibezUxPd9ALjfdAOgzoiaibsCzkkw6lj24U9BD4G1hA5bBwiaqvzV07BOsTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=25" data-ratio="0.6324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526213" data-aistatus="1" data-original-style="null" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/db8e31cc-38ab-4d23-8c30-17536cabb490/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2. PPT 润色拓展&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiaz8ER9cT0kXb1Qk1z47y07Tic6KOBKgXVicJH2xW00l63YymIWKX3a2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.6370370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526214" data-aistatus="1" data-original-style="null" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/f558ae90-6d6e-4627-aa09-67ca8316b254/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;原始 PPT 只是简单的文字罗列；润色后，系统自动添加了科技感背景、可视化图标、以及逻辑图示，瞬间提升汇报档次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、 如何使用与部署&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Paper2Any 提供两种使用方式：&lt;/p&gt;&lt;p&gt;1. 本地部署（开发者推荐）&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果你希望深入研究、二次开发或本地运行，可以基于 Github 仓库进行本地部署。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Github 仓库：&lt;a href="https://github.com/OpenDCAI/Paper2Any"&gt;&amp;nbsp;https://github.com/OpenDCAI/Paper2Any&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;快速开始指引： &lt;a href="https://github.com/OpenDCAI/Paper2Any?tab=readme-ov-file#-linux-% E5% AE%89% E8% A3%85"&gt;https://github.com/OpenDCAI/Paper2Any?tab=readme-ov-file#-linux-% E5% AE%89% E8% A3%85&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;参考 Readme 文档启动 Web 前端即可。&lt;/p&gt;&lt;p&gt;2. 网页版快速体验&amp;nbsp;&lt;/p&gt;&lt;p&gt;团队已推出可视化的 Web 前端，支持拖拽上传与实时进度展示。新用户可免费注册，登录后可查看历史使用记录。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;访问地址： &lt;a href="http://dcai-paper2any.nas.cpolar.cn/"&gt;http://dcai-paper2any.nas.cpolar.cn/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;结语：让配图成为一种「自动获得的附加值」&lt;/p&gt;&lt;p&gt;Paper2Any 的愿景，是希望建立一条新的科研与工作惯例：写文章 + 一键配图 + 一键生成 PPT + 一键展示。&lt;/p&gt;&lt;p&gt;在未来，课题组计划陆续支持 Paper2Rebuttal（论文返修）、Paper2Idea（创新点生成）和 Paper2Poster（文章海报生成）等更多的多模态功能。我们相信，工具的价值在于释放人类的创造力，让你从繁琐的格式调整中解脱出来，将宝贵的时间投入到那些真正闪光的 Idea 之中。&lt;/p&gt;&lt;p&gt;欢迎大家关注使用 DCAI 的开源项目并与我们进行技术交流，如果觉得好用也请在 GitHub 仓库点一个 star ~&lt;/p&gt;&lt;p&gt;Data-centric AI 开源项目：&lt;/p&gt;&lt;p&gt;文章多模态工作流 Paper2Any:&lt;a href="https://github.com/OpenDCAI/Paper2Any"&gt; https://github.com/OpenDCAI/Paper2Any&lt;/a&gt;&lt;/p&gt;&lt;p&gt;自动化数据治理 Agent 框架 DataFlow-Agent: &lt;a href="https://github.com/OpenDCAI/DataFlow-Agent"&gt;https://github.com/OpenDCAI/DataFlow-Agent&lt;/a&gt;&lt;/p&gt;&lt;p&gt;LLM 数据准备系统 DataFlow (1.9k star): &lt;a href="https://github.com/OpenDCAI/DataFlow"&gt;https://github.com/OpenDCAI/DataFlow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;DataFlow 技术报告（&lt;a data-topic="1" href="javascript%3A;"&gt;#1&lt;/a&gt; of the Hugging Face daily paper）: &lt;a href="https://arxiv.org/abs/2512.16676"&gt;https://arxiv.org/abs/2512.16676&lt;/a&gt;&lt;/p&gt;&lt;p&gt;LLM 数据训练系统 DataFlex (基于 LLaMA-Factory): &lt;a href="https://github.com/OpenDCAI/DataFlex"&gt;https://github.com/OpenDCAI/DataFlex&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
