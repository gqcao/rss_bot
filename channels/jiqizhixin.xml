<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>Nature丨清华等团队揭示AI科研双重效应：个人效率亦或是科学边界</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Thu, 15 Jan 2026 14:02:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNIANKJ2VGB5Gkx2ndnV3O4rypxOUxzOQqY3YJBD0UBkiaWiaXlzXIibPLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5778894472361809" data-s="300,640" data-type="png" data-w="995" type="block" data-backw="578" data-backh="334" data-imgfileid="100027161" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/6947648e-ca36-4274-b7be-d06fe32f6dfe/640.png" data-sec-load-status="2" data-report-img-idx="0" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;在过去十年里，人工智能几乎渗透进所有自然科学领域：从蛋白结构预测，到材料筛选，再到自动化实验与论文写作。AI 被反复证明能「加速发现」，但一个更深层的问题长期被忽略&amp;mdash;&amp;mdash;&lt;strong&gt;当越来越多科学家依赖 AI，科学整体究竟发生了什么变化？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了突破这一局限，来自清华大学等的徐丰力、李勇教授团队最终推出了「全流程、跨学科的科研智能体系统」&amp;mdash;OmniScientist。他们通过对跨越 45 年、覆盖 4100 余万篇科研论文的分析，首次全景式揭示了 AI 工具融入科学研究后所带来的复杂图景。&lt;/p&gt;&lt;p&gt;相关研究内容以「&lt;em&gt;Artificial intelligence tools expand scientists&amp;rsquo; impact but contract science&amp;rsquo;s focus&lt;/em&gt;」为题，于2026 年 1 月 14 日发布在《&lt;em&gt;Nature&lt;/em&gt;》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNpqnMOeJ8osOsurjnkGzniaWPSDzVzia0NibuhEBfWo0pkOCiaUlZkqY08A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3402854006586169" data-type="png" data-w="911" data-width="911" data-height="310" data-imgfileid="100027157" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/68ad18d2-e9d2-4e49-ba20-4801739a81e5/640.png" alt="图片" data-before-load-time="1768456914451" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41586-025-09922-y&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;个人扩张与集体收缩&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队构建了一个基于&amp;nbsp;&lt;strong&gt;BERT 的语言模型&lt;/strong&gt;，用于识别「AI 增强型科研论文」。不同于关键词匹配，他们直接让模型学习论文标题与摘要中的语义特征，判断研究是否在方法层面实质性使用了 AI。&lt;/p&gt;&lt;p&gt;最终研究覆盖了&amp;nbsp;&lt;strong&gt;1980&amp;ndash;2025 年间的 41,298,433 篇论文&lt;/strong&gt;，横跨生物、医学、化学、物理、材料与地质六大自然科学领域，并按 AI 发展阶段划分为：&lt;strong&gt;传统机器学习 &amp;rarr; 深度学习 &amp;rarr; 生成式 AI&lt;/strong&gt; 三个时代。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNicp20lxYJxzxu4MWvw4lPEulVO1RMpjpP7yK0icwBXoWNVugPq3QpxRg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5703125" data-type="png" data-w="1024" data-width="1024" data-height="584" data-imgfileid="100027160" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e4524c82-bc4a-4435-a7f7-9ac4a68407bc/640.png" alt="图片" data-before-load-time="1768456914942" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：AI 在科学领域应用普及率的提升。&lt;/p&gt;&lt;p&gt;在此谨将研究结果分为个人与学术界两个层级进行解读。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对于研究者个人而言：&lt;/strong&gt;与未使用 AI 的同行相比，采用 AI 的研究者年均发表论文数量高出 3.02 倍，获得的引用量高出 4.84 倍。他们的职业发展也明显提速，从「初级研究者」晋升为「资深研究者」的平均时间缩短 1.37 年。AI论文本身也更具影响力，年均引用量高出 98.70%，且更多发表于高影响力期刊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;但对于学术界可能不算什么好事：&lt;/strong&gt;尽管个体论文影响力增强，但 AI 驱动的科学研究，其集体关注的科学主体空间收缩了 4.63%。这意味着 AI 研究倾向于更集中地围绕已有热门主题展开，而非开拓新的知识疆域。在超过 70% 的细分研究领域中，都观察到了这种知识范围的收缩现象。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNmEIUMqZ23CboxWz25f715HxPuB5arz3GoqQWPic1OaDJkic0YubXTa5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7282608695652174" data-type="png" data-w="920" data-width="920" data-height="670" data-imgfileid="100027159" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ae0f9973-8f04-45a2-b730-61dd63e2bc91/640.png" alt="图片" data-before-load-time="1768456915308" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：AI 的采用与自然科学领域知识广度的收缩相关。&lt;/p&gt;&lt;p&gt;究其原因，并非是 AI 不善于创新，而是它更容易&lt;strong&gt;在数据充足、问题定义清晰、评价标准明确的领域发挥优势。&lt;/strong&gt;这使得研究资源、注意力与后续工作，持续向「已有数据密集区」聚集&amp;mdash;&amp;mdash;例如成熟学科、热门问题、已有大规模数据集的方向，而冷门问题、新领域、缺乏标准数据的问题则进一步边缘化。&lt;/p&gt;&lt;p&gt;除此之外，AI 研究催生的后续科学互动模式也发生了变化。单篇 AI 论文能启发较广的知识衍生范围，但后续引用该原始工作的论文之间，彼此相互引用的「后续互动」程度降低了 22%。&lt;/p&gt;&lt;p&gt;这种「孤星」结构，与 AI 领域的学术认可分配不均现象，加剧了科学研究的选择偏颇。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率与探索之间的张力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项研究触及了科学发展的一个根本性张力：在追求研究效率、产出速度和个体成功的激励下，AI 工具正将科研资源引向那些最容易通过数据驱动模型取得快速进展的领域。这固然能加速解决现有范式内的核心问题，提升效率，但可能同时削弱了对数据匮乏、高风险、高不确定性的原创性、颠覆性问题的探索动力。&lt;/p&gt;&lt;p&gt;研究团队指出，这种趋势可能导致科学界困于现有认知的「局部最优解」，而减少了在更广阔、更多元的未知领域进行「分散搜索」的机会。长此以往，科学发现的内涵可能从「提出新问题」向「优化旧方案的答案」倾斜。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNPLC8vNA2KmI5lIC9bmiaezy4qLlOuh5BibYDdjNdGQ9vHULQNAwib2b6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6666666666666666" data-type="png" data-w="915" data-width="915" data-height="610" data-imgfileid="100027158" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/488bb1b6-da1a-4a44-ba50-aa74d6167ebd/640.png" alt="图片" data-before-load-time="1768456915534" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 3：AI 领域后续参与度降低且重叠研究更多。&lt;/p&gt;&lt;p&gt;该研究实质上是在呼吁一种更全面、更平衡的 AI 赋能科学愿景。研究者建议，未来的 AI 系统不应仅仅作为认知能力的放大器，更应发展为感知与实验能力的拓展器。&lt;/p&gt;&lt;p&gt;这意味着 AI 需要帮助科学家去探索、选择并收集来自此前难以触及领域的新型数据，例如设计新型实验、操控机器人实验室、或模拟极端条件，从而主动创造知识探索的新前沿，而非仅仅在现有数据上精耕细作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;笔者小结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为科技前沿的参与者与旁观者，笔者在日常中也常能看到 AI 闪烁的发光点。遍历内容，却发现这些发光点大都依托在已有的实验基础之上，算是站在了巨人的肩膀上更进一层。&lt;/p&gt;&lt;p&gt;AI 带来的学术突破似乎已经将重点从学术转变为了 AI，各类大模型、智能框架的产生，都是为了方便研究者快速完成实验、达到理想中的结果。这并非不是 AI 所带来的时代红利，但人类总要保持对探索未知的热忱。&lt;/p&gt;&lt;p&gt;论文中表示，分析的局限，包括识别方法可能遗漏未明确提及的 AI 使用、主要聚焦自然科学而未涵盖人文社科等。生成式 AI 的影响也尚数据来充分评估。但在&amp;nbsp;AlphaFold、自动化实验室和大模型辅助写作不断加速科研的当下，这种张力，可能正是未来科学必须正视的问题。&lt;/p&gt;&lt;p&gt;相关报道：&lt;em&gt;https://www.science.org/content/article/ai-has-supercharged-scientists-may-have-shrunk-science&lt;/em&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，喝到了千问APP给我点的奶茶</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 13:23:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/403bc2e2-1837-4c41-99d5-9b540bfad168/1768454199805.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2026 一开年，智能体的发展立马进入狂奔状态。&lt;/p&gt;&lt;p&gt;本周二，Anthropic 发布 Cowork 掀起了打工人的革命。它不再像 Claude Code 一样专门面向程序员，而是把大模型与智能体能力推进到电脑桌面上，可以解决大部分人的工作问题。&lt;/p&gt;&lt;p&gt;同一时间，谷歌联合 Walmart 等零售商推出了一项专为智能体购物场景设计的开放标准 &amp;mdash;&amp;mdash; 通用商务协议（UCP）。此举旨在推动智能体购物全流程的标准化，实现从商品推荐、购买决策到支付结算的无缝衔接。&lt;/p&gt;&lt;p&gt;1 月 15 日上午，千问又前进了一大步，已经准备让智能体全面接管我们的日常生活了。&lt;/p&gt;&lt;p&gt;这一次，&lt;strong&gt;千问 App 上线了全新 AI Agent 能力「任务助理」，同时全面打通阿里生态，一次开启了 400 多项新功能&lt;/strong&gt;，邀请测试与灰度上线已经同步开启，全都是免费可用的。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528421" data-ratio="0.5564814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDpTYZvbIZoLJGkNGjYxeE7zibEicKqk4ItZAViaJ9ibGTdbwdhPQxibxxiazA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/66817256-da70-4ccb-8c82-d441010c7335/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 千问 C 端事业群总裁吴嘉&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;国内最强的 AI 模型，与最全的应用生态，现在合而为一了。&lt;/p&gt;&lt;p&gt;现在，你只需要对 AI 说「我要两杯奶茶」，千问就可自动找到相应的店铺，选好你的地址、选好商品、下好订单，你只需要点击最终的支付即可。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528423" data-ratio="2.062222222222222" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDbORxXCibZXrQOqJazsARXlqTyTVib1DVSmtySEHDhBBtBuCcAlZYBoHQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-type="gif" data-w="450" type="block" data-original-style="width:404px;height:833px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/449fd024-d31d-4afd-b95d-d034c0d90a90/640.gif" data-order="0" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;如果你想买点什么东西拿不定主意，也可以和千问「任务助理」商量一下，它不仅可以讨论出个符合需求的结果，而且可以直通商店的付款链接。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgnSNwY2fIZaEkgxe4M68LyWWrFd3pvg0hlR6FChzDYMjHn0xfWcfuQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="2.0625" data-s="300,640" data-type="gif" data-w="400" type="block" data-imgfileid="503528424" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a7b1ad6b-b72c-47db-a9f8-5496a3c5e07f/640.gif" data-order="1" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;可以看到，千问能够接入的应用包括淘宝、闪购、飞猪、高德地图和支付宝。如果你有需要，千问还能帮你打电话。在发布会现场，千问就展示了 AI 帮人订餐，看起来餐厅老板没有认出与他交谈的是千问。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528425" data-ratio="0.3527777777777778" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDYfzLEV6hibXQKPHEabsLpjqKqRSh7ZXNMiceXPicE0siaWt1JO0o5aIU7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a888f7df-8072-4808-b391-3149cd7b1d61/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了各种有意思的功能，我们也初步体验到了 AI 智能体带来的交互革命 &amp;mdash;&amp;mdash; 强大的千问模型，正在把阿里独有的生态优势全部并联起来。不论生活还是工作，以后通行的方法，或许都会被 AI 重新整理一遍。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528428" data-ratio="0.6666666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD1aQ5QwIjsqMJ8zicTdyjyNIiaTKMNLiahHjpWXdggk1dxUBV1l8AQhlCQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/0760db6c-ab57-4215-93a6-7d1f8fdbed8b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;一手实测 &amp;nbsp;触角已经碰到了物理世界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;刚过去的 2025 年被普遍视为智能体元年，智能体在人工智能领域的热度一直没有断过。从 Manus、ChatGPT Agent 到更多国产 Agent 大模型与应用，几乎每一次发布都会引起轰动。&lt;/p&gt;&lt;p&gt;智能体的出现，让大模型从拥有智能「大脑」进化出灵活的「手」和「脚」，对复杂任务的自动分析、拆解、执行能力与日俱增。有了智能体的参与，人们可以从繁冗的流程性工作中解放出来，大大节省了工作量与时间成本。&lt;/p&gt;&lt;p&gt;在全面接入一众阿里生态业务之后，千问 App 上的这个智能体新面孔能带来哪些不一样的东西呢？带着这个疑问，我们在拿到内测资格之后，马上对它来了一次摸底测验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多品牌团购不在话下&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在上文，我们已经见识到千问「任务助理」点奶茶的便利。接下来的实测中，我们给它上上难度，看能不能搞定多品牌、跨店铺的团购任务。&lt;/p&gt;&lt;p&gt;团购不同牌子的奶茶通常需要我们进入购物 App 并一一查找、浏览对应牌子的奶茶店，还要确认店中有没有自己想要的口味，这会浪费不少时间。在将类似的任务交给千问「任务助理」后，一切的麻烦都没有了。&lt;/p&gt;&lt;p&gt;我们输入指令「帮我点 3 杯霸王茶姬，5 杯瑞幸，8 杯茶百道」，它在确认你的收货地址之后会首先询问你的口味需求。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528435" data-ratio="1.776470588235294" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDVsULfyDOe1ia18IlUDCSka7gcPtq7hUiaufGq9FtZUTocDkibskT4tctg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-type="gif" data-w="340" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e930a75d-168f-4b72-beb6-2cecf4ba2512/640.gif" data-order="2" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在确认你有无特殊的口味需求之后，它便开始马不停地自动跑完接下来的所有流程，包括&lt;strong&gt;分析用户点单需求、核对点单数量、以及搜索并获取购物平台（这里是淘宝闪购）商品信息&lt;/strong&gt;。随着一系列内外部信息被它吸收消化，紧接着会进入到制定最佳点单方案的环节。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528433" data-ratio="1.776470588235294" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD5OERstLwydwoj6ibjaTnHXtFk3dTjiaQJUHcpS1rEmzqEGibicPzS9k5TA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-type="gif" data-w="340" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f7d769c0-246c-4ed4-a917-9d61b454e0d3/640.gif" data-order="3" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在制定点单方案时，它会根据距离的远近等因素自动为你匹配合适的商家，并初步完成满足你需求的商品筛选与推荐。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528436" data-ratio="1.0212962962962964" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD46Wawc1oqia4baP8Z47ke1AkCP7n92lj060GvUrTPQKKE85nGwpRCXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/c71f9e2d-7af9-43a8-8ce7-ee01a73c14d3/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;一套丝滑连招下来，它为我们推荐了&lt;strong&gt;三种差异化的方案&lt;/strong&gt;，或想更快收到货、或是选择评分高销量高的门店、或想要订单中包含更多样的饮品种类。这些潜在的用户意图被它精准地捕捉并考虑进来，转化为对应的优先级推荐方案。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528434" data-ratio="1.7377049180327868" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDxlelEqQJ1xt38aaEhJo6qBbypa2ZUJ7QlyiclibLrib2LaGwe76gdBfLw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-type="gif" data-w="366" type="block" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/e7f66bba-15ce-4b73-9662-2e99948340f9/640.gif" data-order="4" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;最后一步，凭自己的喜好下单付款即可。整个操作过程中，除了在有特殊口味需求时需要你的手动介入，其他时候全权交给千问「任务助理」就行了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定制旅游计划一气呵成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前几天，「威海暴雪」的新闻登上了微博热搜，让这座滨海城市闯入了人们的视线。提起山东，大家可能更多地想到青岛。相比之下，威海的名气没有那么大。但从网上的口碑来看，威海以「小而美」著称。&lt;/p&gt;&lt;p&gt;带着对这座城市的好奇，我们让千问「任务助理」制定一份 1 月 16 日（这周五）北京出发的威海两日游计划。&lt;/p&gt;&lt;p&gt;在接收到任务之后，它便自动进入到了任务规划以及逐步的任务执行流程。首先会对我们的需求进行一个整体分析，将威海的景点、美食、住宿等因素统统考虑进来，并启动&lt;strong&gt;搜索子任务&lt;/strong&gt;，即调用搜索工具查询相关的背景知识。&lt;/p&gt;&lt;p&gt;通过不间断地搜索、查询多类型网络来源（包括门户网站新闻、旅行社区热帖等）的威海旅游攻略，尽可能地确保信息准确可靠。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528430" data-ratio="1.7868852459016393" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDmhkiaXoAibooZkvicNx0cw5btgGLmhsudEA0ypich8nfEgYEKXG2IVMsaA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-type="gif" data-w="366" type="block" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/706050e0-5f0c-43e8-933a-ed9deb7fc905/640.gif" data-order="5" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;紧接着，根据筛选后的优质搜索结果，它为我们规划详细的两日游行程，这里全程对&lt;strong&gt;高德&lt;/strong&gt;和&lt;strong&gt;飞猪&lt;/strong&gt;进行了调用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDicIRyRMJfdiaB0g8A28oYw7IPfJicgCrhTbk5XxvIQwzSkw6uk2aeqFxQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.5944444444444444" data-type="gif" data-w="1080" type="block" data-imgfileid="503528431" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/52019515-e9e5-42c9-a1d7-231215af99ae/640.gif" data-order="6" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最终在整合所有行程信息之后，它在高德地图上呈现出了两条交互式路线图。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDBVt8lYxNRn2G3aHYPS875VEWc2IcUzpbibcbrDWq8wxEkWr72YDVObw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.4444444444444444" data-type="gif" data-w="1080" type="block" data-imgfileid="503528427" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/afdfc4b7-0880-4eb0-b717-4074fd6d9c05/640.gif" data-order="7" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;完整的威海两日游计划出来之后，我们发现，不仅囊括了威海热门景点，还兼顾自然风光与历史文化，并综合考虑了预算成本与游玩体验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDic6TkNZ0Ez4d5116aNqleK2b8A4AKwneL2h8AIuwo42ib7jpeXOmKpPQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.6370370370370371" data-type="gif" data-w="1080" type="block" data-imgfileid="503528432" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/7682f914-ac05-49fa-badb-a073c8646ddb/640.gif" data-order="8" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在生成的行程计划中，你既可以一键跳转高德来导航去某处景点的路线并一键打车，也能跳转飞猪去订景区门票和酒店。&lt;/p&gt;&lt;p&gt;在日常购物、旅游规划之外，千问「任务助理」擅长的事情还有很多，比如&lt;strong&gt;政务场景&lt;/strong&gt;，在接入支付宝政务服务之后，只需用户一句话就能快速完成政策解读、材料清单梳理等步骤，覆盖办签证、查社保等等场景，并直达办理入口，效率高得惊人。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDzm7qdasXjU8iag2qzxdq1pmgpNZzduq3SnkrLPkrficlPZW7qiaO2XjrA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-ratio="1.9095477386934674" data-type="gif" data-w="398" type="block" data-imgfileid="503528429" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/7af25a5d-5bb2-4a38-bc8b-9700352dfc7f/640.gif" data-order="9" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;简单的几个任务测下来，我们感受颇深的一点是：在交互方式上，以前我们是与大模型「对话」，现在是给智能体「派单」。只需要给出任务，然后等待结果即可。该说不说，这才是智能体真正的定义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;千问 AI 助手 &amp;nbsp;有一套「拟人化」思考架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;千问不仅是能点外卖这么简单，千问「任务助理」已经完成了一套基于通用 Agent 体系的底层重构。&lt;/p&gt;&lt;p&gt;首先，&lt;strong&gt;千问 App 采用了一套全新的通用 Agent 体系&lt;/strong&gt;。它基于 MCP 和 A2A 协议，在其中，主 Agent 作为指挥者，它基于千问最强模型拆解和规划任务；子 Agent 作为执行者，它们是多个具有反思能力的智能体，在其领域具有完全决策执行的权限，可以根据任务情况动态纠偏。&lt;/p&gt;&lt;p&gt;这套范式实现了高效的分层规划，在特定任务领域上也可以保证正确的决策，大幅提升了跨领域、长链路的复杂任务执行效率和准确率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;千问深度重构了 Agent 的原生能力栈&lt;/strong&gt;。不同于目前流行的基于视觉识别（GUI）的 Agent 路线，千问选择了更加直接的协议打通，提升了 Agent 在执行任务时的精度和效率，在隐私安全上也更有保障。为了进一步提升效率，千问还专门为 AI 进行了工具栈的重构。&lt;/p&gt;&lt;p&gt;比如在搜索时，Agent 能够自主选择不同的搜索方式，或是进行并发搜索；操作浏览器的 Agent 经过了专门训练，结合阿里自研浏览器内核，具备毫秒级响应和极高的交互精度；在处理可视化、写小程序或复杂表格时，智能体会检索、对齐经过验证的成熟代码范式，确保产出结果具备「工程级」稳定性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「任务助理」多层 Agent 的系统，深度集成了阿里自家生态的各种应用、工具&lt;/strong&gt;，大量的应用会被拆解成原子化的指令级，确保了工具调用的准确。在跨场景任务上，系统能够正确地感知实时的位置、价格等时效信息，减少了大模型常见的幻觉问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;千问的 Agent 系统还具备可以持续演进的能力。&lt;/strong&gt;在完成任务之后，Agent 并不是就结束工作了，而是会像人一样进行「反思」并沉淀经验，让 Agent 可以持续进化。实践的经验会被转化为结构化经验库，作为先验知识在后续任务中动态加载。&lt;/p&gt;&lt;p&gt;这样，AI Agent 就可以逐渐具备人类的工作直觉。&lt;/p&gt;&lt;p&gt;最后，&lt;strong&gt;通过 AI Coding 的能力，千问现在可以在执行任务时发动 AI 生成代码能力现写工具&lt;/strong&gt;。前面说到在大量任务上，Agent 可以实现精准的识别与操作。而在比较少见的任务上，千问的 Agent 可以启动 Agentic Learning 机制，自主编写、测试并封装新的原子工具。随着人们的使用，千问「任务助理」的能力会持续增强。&lt;/p&gt;&lt;p&gt;前天 Anthropic 发布的 Cowork，据说是十天之内用 AI 生成代码能力写出来的。看起来现在千问把类似的能力已经给你集成在智能体上了。千问表示，目前在数百个常用工具中，有超过一半是由 AI Coding 编程自主生成的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体的 AI 革命 &amp;nbsp;已经开始了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今年，AI 领域正在进入产品爆发的阶段。&lt;/p&gt;&lt;p&gt;仅在 1 月份，业界就出现了 Anthropic 的 Cowork，OpenAI 的 ChatGPT Health 等一系列新产品。各家科技公司正在快速兑现 OpenAI 总裁 Greg Brockman 对于智能体在企业、专业领域落地的预言。&lt;/p&gt;&lt;p&gt;刚刚千问的新发布，更是把智能体拉近到了我们身边：它能用快速精准的方式连接最常用的 App，让 Agent 进入到你生活的每一步。在国内，能做到覆盖如此全面的生活场景的公司，还真的只有阿里，其生态囊括了购物、出行、支付、办公等方方面面。&lt;/p&gt;&lt;p&gt;我们能够看出，目前这些 Agent 能力还显得比较简单 &amp;mdash;&amp;mdash; 正如第一代 iPhone 功能的简单并没有掩盖其划时代的意义一样，千问 APP 今日的推出，也许就像是智能体的 iPhone 时刻。从鼠标点击到手指触控，再到自然语言对话的交互方式升级，从这场发布开始打响了第一枪，人与机器的关系也进入到了第三次革命的关口。&lt;/p&gt;&lt;p&gt;当 AI 开始帮你整理发票、规划行程、甚至下单买咖啡时，它不再是云端那个高冷的「先知」，而变成了身边能干活的「助理」，这是 AI 从「言」到「行」的分水岭。&lt;/p&gt;&lt;p&gt;千问，会像淘宝开启移动互联网时代那样，开启一个全新的 AI 时代吗？我们拭目以待。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>人脸机器人登上Science Robotics封面：用AI教会仿生人脸机器人「开口说话」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 13:13:46 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3db839cc-d9a6-4a2c-844b-6c2b943df2b3/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;胡宇航（网名 &amp;ldquo;U 航&amp;rdquo;），毕业于美国哥伦比亚大学，博士学位，首形科技创始人。长期专注于机器人自主学习的研究工作。研究成果发表于《Nature Machine Intelligence》，《Science Robotics》等国际顶级期刊。致力于赋予机器人 &amp;ldquo;自我模型&amp;rdquo; 能力，即构建对自身物理结构与运动的内部表征，使机器人能够更好地理解自身，并适应多变的形态、环境与任务。在仿生人机交互方向，他提出融合语音、视觉与动作的情绪理解与表达一体化系统，为机器人提供更加自然的交互能力。通过自监督学习机制，他的方法使机器人在无需人工干预的情况下不断提升人机互动质量，朝着具备终身学习能力的智能体不断迈进。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528356" data-ratio="0.38055555555555554" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDnxq8JDb1txO71452AibDTYrw4upDGtiaQb7FcuyuCJkFXBAL8nB7LGxg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/960fdfdc-fae0-4db7-887e-403f7e494a29/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文地址：https://www.science.org/doi/10.1126/scirobotics.adx3017&lt;/p&gt;&lt;p&gt;曾发表论文：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Hu, Yuhang, et al. &amp;quot;Human-robot facial coexpression.&amp;quot; Science Robotics 9.88 (2024): eadi4724.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hu, Yuhang, Jiong Lin, and Hod Lipson. &amp;quot;Teaching robots to build simulations of themselves.&amp;quot; Nature Machine Intelligence (2025): 1-11.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://mp.weixin.qq.com/s/HdnbBweZseTjMedyWHDLSg&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2026 年 1 月 15 日，一项来自美国哥伦比亚大学工程学院的突破性研究正式发表于《Science Robotics》，并登上期刊封面。该研究展示了一项全新的机器人技术：一台具备仿生面部结构的人形机器人，通过深度学习实现与语音和歌曲同步的真实唇部运动。它能跟着人类的语言精准张合嘴唇，甚至，能跟着音乐唱歌。标志着人形机器人在人类最丰富的交流通道之一&lt;strong&gt;唇部表达&lt;/strong&gt;上，迈出了突破性一步。&lt;a href="https://mp.weixin.qq.com/s/BySG2N_jsBf8XsB7v4-SOg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e6fd90e9-df68-431b-b850-b7ec4041c5fd/1768453840414.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;为什么 &amp;ldquo;嘴唇&amp;rdquo; 如此重要？&lt;/p&gt;&lt;p&gt;研究显示，在面对面的交流中，人类将近一半的注意力集中在唇部运动上。我们或许能容忍机器人走路笨拙、手部动作僵硬，但&lt;strong&gt;哪怕极其轻微的不自然面部表情，都会立刻引发本能的不适&lt;/strong&gt;。这正是著名的 &amp;ldquo;恐怖谷&amp;rdquo;。&lt;/p&gt;&lt;p&gt;长期以来，即便是最先进的人形机器人，在 &amp;ldquo;说话&amp;rdquo; 时也只能做出类似木偶的张合动作 &amp;mdash;&amp;mdash; 如果它们有脸的话。但这一次，情况正在发生改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一个会自主学习表情的机器人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这项研究中，研究团队打造了一张高度仿生的机器人面孔：&lt;/p&gt;&lt;p&gt;在一层柔性硅胶皮肤之下，隐藏着&lt;strong&gt;&amp;nbsp;20 余个微型电机&lt;/strong&gt;，能够快速、安静且协同地驱动唇部形变。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528352" data-ratio="0.6361111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDsCy3zFQRicRlLxHZS47dkecA9f9KCk2qXeuJmGYpiaAOZIumc9JSZQZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/38af39e9-41cf-4096-afb4-4866494297f3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2. 机器人唇形硬件结构。（A）面部机器人设计概览，重点展示了人机交互关键组件：包括扬声器、麦克风、高清摄像模块，以及用于固定柔软硅胶面皮的磁吸式快拆连接器。该连接器能实现面皮的精准定位，并通过推拉双向运动驱动硅胶面皮，完成说话时所需的复杂唇部动作。（B）搭载柔软硅胶面皮的人形机器人外观展示。其底座内部集成有边缘计算设备。（C）唇部驱动系统特写，展示上唇、下唇与唇角连接器分别对应固定于相应唇部支架。柔软可替换的面皮通过磁吸连接器固定，可便捷拆卸以进行维护或个性化调整。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;随后，机器人被 &amp;ldquo;带到镜子前&amp;rdquo;&amp;hellip;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就像一个第一次对着镜子学做表情的孩子，机器人通过观察自己面部在不同电机驱动下的变化，构建 Facial Action Transformer (FAT) 模型，逐渐学会如何控制自己的脸（机器人自我建模 Robotic Self-modeling)。研究团队将这一过程称为一种 &lt;strong&gt;&amp;ldquo;视觉 &amp;mdash; 动作&amp;rdquo; 的自监督学习&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528353" data-ratio="0.45740740740740743" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDvxzRJ7S84CvoUy65ibZ9lyBIhicQlqh3CiaoLN1tm1xMUjSRgXG1Zc75w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1baf7b37-25b4-4960-a1f1-94ec0738725a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3. 机器人能实现的口型及其对应音标展示。该机器人展示了再现关键英语音标的能力，例如爆破音（/p/ 和 /b/）、双唇音（/m/）以及圆唇元音（/u/ 和 /o/）。通过独立控制上唇、下唇及嘴角，每帧图像均捕捉到其实现的典型唇部运动效果。这些数据为机器人在说话时实现正确的唇形匹配奠定了基础。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依靠纯声音驱动嘴形动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;接着，机器人通过观看合成的机器人视频（通过 Wav2Lip）在不同语音语料（由 TTS 和 ChatGPT 生成）的真实唇部变化，进一步学习&lt;strong&gt;声音与唇部运动之间的对应关系&lt;/strong&gt;。最终，这两种能力被整合在一起 &amp;mdash;&amp;mdash; 机器人得以将收到的声音信号，直接转化为连续、自然的唇部运动。无需理解语义，机器人已经能 &amp;ldquo;对得上口型&amp;rdquo;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528354" data-ratio="0.4601851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgmZPRIx2vjsQwRiagZgIeehaz5XsfiaDDQMNtlVyJTJl8D2JibZkDOkaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/bea0b7dd-4325-44ac-bb20-def2f2f4f14b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4. 机器人唇形同步的自监督学习框架。 (A) 数据收集阶段：机器人通过与语音相关的随机指令自主生成数据集，利用 RGB 摄像头捕捉广泛的唇部运动，以获取 3D 唇形数据。(B) 部署过程：始于来自 ChatGPT 的文本输入，文本被转换为音频，随后利用 Wav2Lip 技术合成机器人视频。利用真实机器人视频及其对应指令，训练由编码器和解码器（VAE）组成的机器人逆向变换器，以生成平滑、准确、可供真实机器人执行的电机指令。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多语言能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队测试了机器人在多种语言、不同语音环境甚至歌曲中的表现。结果显示，即使在复杂的语音节奏下，机器人也能完成连贯的唇部同步，甚至演唱来自其 AI 生成的曲目。&lt;a href="https://mp.weixin.qq.com/s/BySG2N_jsBf8XsB7v4-SOg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9d830db5-e21b-4894-b2f2-4c5fa7efcbdc/1768453913455.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 机器人多语言口型对齐能力&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528355" data-ratio="0.375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDiaATHafTyLYwmdkhRdwWM7uibKKev13w8AE0LBlcj1JrcbH6feTH8gOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/77feb593-4b24-4d72-afa3-6d52fbc72995/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5. 多语言唇语同步性能量化表现。x 轴标签下方标注的样本量 n 对应每种语言的测试句子视频帧数。结果表明，所有非英语语言的同步误差均保持在英语误差范围内，显示出稳健的跨语言泛化能力。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;当然，这还不是终点。研究者坦言，像 &amp;ldquo;B&amp;rdquo; 这类需要完全闭唇的音，以及 &amp;ldquo;W&amp;rdquo; 这类涉及明显撮唇的发音，仍然存在挑战。但关键在于 &amp;mdash;&amp;mdash; &lt;strong&gt;这是一种可以随着学习持续进化的能力，而不是写死的规则。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;跨越恐怖谷的 &amp;ldquo;缺失环节&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在研究者看来，面部表情 &amp;mdash;&amp;mdash; 尤其是唇部的自然运动，正是长期以来机器人能力中的 &amp;ldquo;缺失环节&amp;rdquo;。&amp;ldquo;当前的人形机器人更多关注行走和抓取，但凡是需要与人面对面交流的场景，面部表达同样关键。&amp;rdquo;&lt;/p&gt;&lt;p&gt;随着人形机器人逐渐进入娱乐、教育、医疗、陪护等高度依赖情感沟通的领域，一张温暖、自然、可信的&amp;lsquo;脸&amp;rsquo;将不再是加分项，而是入场券。经济学家预测，未来十年全球或将制造超过十亿台人形机器人进入人们的生活场景。而几乎可以确定的是 &amp;mdash;&amp;mdash; 它们不可能都没有脸。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从实验室走向现实&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项封面研究，不仅是一次学术突破，也展示了中国学者在国际人形机器人领域具备独特的创新能力。&lt;/p&gt;&lt;p&gt;第一作者胡宇航博士表示，当唇部同步能力与对话型大模型结合时，机器人与人类之间的连接将发生质变。&amp;ldquo;我们交流中有大量情感信息并不在语言本身，而在面部和身体语言中。机器人正在开始触碰这条通道。&amp;rdquo;&lt;/p&gt;&lt;p&gt;当机器人真正学会像人一样 &amp;ldquo;说话&amp;rdquo; 和 &amp;ldquo;表达&amp;rdquo;，&lt;/p&gt;&lt;p&gt;恐怖谷，正在被一步步填平。&lt;/p&gt;&lt;p&gt;人类与机器人的信任和情感，将会迎来新的篇章。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>实测夸克「千问划词快捷指令」，这7个邪修Prompt，建议收藏</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 12:11:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/110f143e-0454-429b-b66b-6597f05f6ef0/1768449877316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;新年第一天，DeepSeek 发布了一篇艰深晦涩的技术论文，不少网友直呼「看不懂」。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"jc":"center","uuid":"mk2gmj7aweyieukbrpn"},["img",{"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5168d798d8b874f4f0f3eb7ebad2f178375b8339e1c4c24833998745b666af745115b5d1153adab25a156a98577f418d5b7c4b67b1ed0eaebdfca5b38285a1f63ec564bff80fdc5574f77387d2e13df021f0ef096c4d55c51?tmpCode=f00bcf97-2b0f-4aad-8d0e-776a3b6d2398","width":746,"height":523.275657336726,"uuid":"mkdfb33mb664v67jyo9","extraData":{"resourceId":"7f12b51b-0f64-4a2f-bbbf-ce8ad418a0e6","metaData":{"size":168183,"originWidth":1179,"originHeight":827,"format":"jpg","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMmpjJTIyJTNBJTIyY2VudGVyJTIyJTJDJTIydXVpZCUyMiUzQSUyMm1rMmdtajdhd2V5aWV1a2JycG4lMjIlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyaW5saW5lJTIyJTJDJTIydHlwZSUyMiUzQSUyMmltYWdlJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnNyYyUyMiUzQSUyMmh0dHBzJTNBJTJGJTJGYWxpZG9jcy5kaW5ndGFsay5jb20lMkZjb3JlJTJGYXBpJTJGcmVzb3VyY2VzJTJGaW1nJTJGNWVlY2RhZjQ4NDYwY2RlNTE2OGQ3OThkOGI4NzRmNGYwZjNlYjdlYmFkMmYxNzgzNzViODMzOWUxYzRjMjQ4MzM5OTg3NDViNjY2YWY3NDUxMTViNWQxMTUzYWRhYjI1YTE1NmE5ODU3N2Y0MThkNWI3YzRiNjdiMWVkMGVhZWJkZmNhNWIzODI4NWExZjYzZWM1NjRiZmY4MGZkYzU1NzRmNzczODdkMmUxM2RmMDIxZjBlZjA5NmM0ZDU1YzUxJTNGdG1wQ29kZSUzRGYwMGJjZjk3LTJiMGYtNGFhZC04ZDBlLTc3NmEzYjZkMjM5OCUyMiUyQyUyMndpZHRoJTIyJTNBNzQ2JTJDJTIyaGVpZ2h0JTIyJTNBNTIzLjI3NTY1NzMzNjcyNiUyQyUyMnV1aWQlMjIlM0ElMjJta2RmYjMzbWI2NjR2NjdqeW85JTIyJTJDJTIyZXh0cmFEYXRhJTIyJTNBJTdCJTIycmVzb3VyY2VJZCUyMiUzQSUyMjdmMTJiNTFiLTBmNjQtNGEyZi1iYmJmLWNlOGFkNDE4YTBlNiUyMiUyQyUyMm1ldGFEYXRhJTIyJTNBJTdCJTIyc2l6ZSUyMiUzQTE2ODE4MyUyQyUyMm9yaWdpbldpZHRoJTIyJTNBMTE3OSUyQyUyMm9yaWdpbkhlaWdodCUyMiUzQTgyNyUyQyUyMmZvcm1hdCUyMiUzQSUyMmpwZyUyMiUyQyUyMnJhdGlvJTIyJTNBMSU3RCU3RCU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJ0ZXh0JTIyJTJDJTIybGVhdmVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJsZWFmJTIyJTJDJTIydGV4dCUyMiUzQSUyMiUyMiUyQyUyMm1hcmtzJTIyJTNBJTVCJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTJDJTIyY29udGVudFR5cGUlMjIlM0ElMjJjYW5namllLXRleHRibG9jayUyMiU3RCU1RCU3RA==" data-identifier-application__slash__x-doc-key="8K4nyeZ46Y2Y5nLb" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicF8hyA8EDOLbjWjcIehg1cMAwlX2qlOiak8p7ibxI4an9j2rOn8mboPzQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.7018518518518518" data-type="jpeg" data-w="1080" data-imgfileid="503528201" data-aistatus="1" data-original-style="width:358px;height:251px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b7d9feb4-53a6-4273-8029-325883d11eca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;于是，机器之心评论区出现了集体求助 AI 的一幕：有人让 AI 用八十岁老太太能听懂的方式解释，有人要求用大白话翻译，还有人直接说「当我是幼儿园小朋友，给我讲明白」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicfj7xcdHvpLyIEkg9ib4ICl8slDbQKymmbP4ZN6P6fqdQ82mLibJZw0vw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.39814814814814814" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="230" data-imgfileid="503528219" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2f74b96e-3ce9-4df9-a2e6-1423991a420f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这场景既搞笑又真实。如今，我们面对复杂信息时，第一反应已经是向 AI 求援，而非硬啃。但问题来了，同样是使用 AI，有些人总能得到精准、高质量的回答，而有些人却总在和 AI「鸡同鸭讲」。&lt;/p&gt;&lt;p&gt;这样的体验让不少人对 AI 的智能程度产生怀疑，抱怨 AI 不够聪明、听不懂人话、是个「智障」。可事实并非如此，问题可能出在我们的提问方式上。&lt;/p&gt;&lt;p&gt;一个完美的指令，关键在于让 AI 确认它是否真正理解我们的需求，这就是为什么网上会流传各种提示词模板，这些经过反复打磨的指令，往往能让 AI 输出质量提升好几个 level。&lt;/p&gt;&lt;p&gt;不过，新的痛点也随之而来，这些高频使用的指令，每次都要从头输入一遍，不仅浪费时间，还容易因为表述不同导致效果不稳定。&lt;/p&gt;&lt;p&gt;如果有一个方法，能把这些指令变成一键调用的快捷键，会怎样？&lt;/p&gt;&lt;p&gt;最近，夸克 AI 浏览器功能更新，&lt;strong&gt;「千问划词」支持自定义快捷指令&lt;/strong&gt;。如果你常常需要对文稿进行内容润色、检查、优化，只需提前设置好常用的提示词，就能开启更精准、更快捷的划词体验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicia7EfnD7yZ00rYibhZuYv3uKN1k7daSjl0h8MVwqmayaKFvgx2uhM2RA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6407407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="370" data-imgfileid="503528328" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d9116190-27e1-4528-9524-bbf1c4655d2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;简单来说，就是把那些已经验证过、效果很好的提示词固定下来，需要时一键调用。&lt;/p&gt;&lt;p&gt;用法也很简单，我们只需&lt;strong&gt;在设置里找到「划词工具栏」，点击「添加自定义指令」，输入常用指令&lt;/strong&gt;，比如「请将以下内容翻译成中文：{selection} 要求翻译准确流畅，符合中文表达习惯，避免生硬直译」，再给指令起个名字，专属指令就设置成功了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicOoZKZW1mXSpzOSPUgiaSwXAYXicmLic1bcM6Z0AQvnbJThwQeg2bibqBCw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.6404077849860983" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="370" data-imgfileid="503528302" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cbdbce4e-a6bd-451c-9be0-3d21ea6a5d88/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;这里提一嘴，输入常用指令时系统有一套规则：需使用 {selection} 来表示划词选中的文字。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;后续在浏览网页或文档时，遇到需要协助翻译、润色、检查的段落，只需轻轻划选，指令即可一键使用，告别复制粘贴、重复手动输入的麻烦。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测：用夸克 AI 浏览器玩转 100 个指令&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说实话，很多人觉得 AI 难用，就是被那些长到记不住的提示词给劝退的。既然如此，不妨交给浏览器来记。&lt;/p&gt;&lt;p&gt;最近，我们对着夸克 AI 浏览器疯狂实测了一波，从中精选出 7 类最实用指令，接下来全是干货。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;邪修提示词&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最近，博主「张咋啦 zara」分享了一个超好用的邪修 Prompt：tell me what you need from me to do this well。翻译过来就是「为了执行好这个任务，你需要我给你提供什么？」&lt;/p&gt;&lt;p&gt;她表示，AI 背后的人格是个助手，而助手的第一要务是满足用户需求，很多时候 AI 不好意思跟我们提需求，这就导致当我们给 AI 的上下文不够完整时，它就瞎干，最终交付的结果自然无法达到我们的预期。&lt;/p&gt;&lt;p&gt;所以，我们可以主动询问 AI 的需求，然后再想方设法满足，执行效果会好很多。&lt;/p&gt;&lt;p&gt;我们索性用夸克 AI 浏览器的「千问划词 - 快捷指令」试试。当然 Prompt 也根据具体使用场景，改得稍微具体了些：&lt;/p&gt;&lt;p&gt;「我需要你帮我润色以下内容：{selection} ，为了执行好这个任务，你需要我提供什么额外信息？请列出你需要了解的关键要素，以便给出最优质的回答。」&lt;/p&gt;&lt;p&gt;设置好后，我们拿《马斯克的「移动客厅」又火了：20 人座无方向盘，每公里才 3 毛钱》这篇文章进行测试。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiclViaOmBdayvU8pDibGaHaNqvvyUGpQ8jXasLk10xkvtKtqPicA313IPnA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.64" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="370" data-imgfileid="503528301" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1f827b59-5120-46b6-b29d-fa43f6b087f2/640.gif" data-order="1" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;AI 终于大大方方提出疑问：目标受众、发布平台、侧重表达的观点以及语言风格分别是什么，还贴心地举了例子。得到回答后，刷刷几下子润色版本就出来了，在保留核心信息基础上，语言更具网感。&lt;/p&gt;&lt;p&gt;有一说一，&lt;strong&gt;让 AI 先问清需求，再精准输出，比直接让它润色效果好太多&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;毒舌大师&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;国外一博主也摸索出 AI 的一些骚操作。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/61201ac8-2369-4b3e-a202-c434ecaa8f27/1768449983247.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;一般来说，AI 总爱跟我们假客气，说啥它都顺毛捋，所以该博主给 AI 立了个毒舌导师的人设，我们反手就将这个提示词设置为夸克 AI 浏览器的划词指令：&lt;/p&gt;&lt;p&gt;「你是我冷酷无情的导师，别跟我绕弯子。请严格批评以下内容：{selection}，要求是如果想法烂透了，就直接说这是垃圾。你的工作就是把所有问题都挑出来，直到我说无懈可击为止。批评完后，用一句话告诉我改进方向，然后帮我修改，能更吸引人。」&lt;/p&gt;&lt;p&gt;题好一半文。扒出之前写的一篇流量堪忧的文章，点击「毒舌大师」快捷指令搞个更吸引人的标题。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaichW5H4pPOfDS1ZgYkhfL5P1tq9hNUtRfahapdMOlRYTymLSDibavxPHg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.6425" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="371" data-imgfileid="503528244" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/264621b6-4024-416c-9cba-5b4e2a6c9ed3/640.gif" data-order="2" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;AI 毫不留情地开喷「主题不明确、信息陈旧、用词情绪化，更像是社交媒体的几句牢骚」。骂完就给出改进方向，并直接甩出修改版本。&lt;/p&gt;&lt;p&gt;AI 终于不跟我们装熟了，给的建议也更靠谱。以后编辑部谁写的东西自我感觉良好，就让这个毒舌模式喷一遍。&lt;/p&gt;&lt;p&gt;讲完邪修用法，我们再来看看工作学习具体场景。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人话翻译器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于很多机器之心读者来说，最头疼的场景之一，就是读那些不明觉厉的专业论文。&lt;/p&gt;&lt;p&gt;以上文提到的 DeepSeek 技术论文为例，网友求助 AI 的表述五花八门，但核心需求其实是一致的，那就是把复杂的学术内容转化为通俗易懂的表达。&lt;/p&gt;&lt;p&gt;我们可以用夸克整个「人话翻译器」划词指令：&lt;/p&gt;&lt;p&gt;「你是一位擅长科普的教育工作者，请用费曼学习法解释以下内容： {selection}，要求先用一个生活化的类比引入概念，再拆解核心逻辑，最后用一句话总结。语言要生动，避免术语堆砌。」&lt;/p&gt;&lt;p&gt;打开一篇论文，遇到看不懂的段落，划词选中，夸克 AI 浏览器&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;几秒钟就能给出通俗解读。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic18pZjzexMFlAr5A7A5GKYgCiaf3lsxpBbUq8o5v0YTWLZ9WqnNFrh2w/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.6275" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="363" data-imgfileid="503528232" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f4e8a0e0-9aa3-485d-8f45-52adf905bac7/640.gif" data-order="3" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这比每次都要输入「用大白话解释」要精准得多，因为 AI 已经知道要用什么结构、什么风格来回答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文引用查找器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文党基本绕不过翻译、写作、修改、引用查询等环节，有了 AI 后，干这些活的效率直线上升，但用到的提示词来来回回也就那几个。这时，夸克的划词指令就派上用场。&lt;/p&gt;&lt;p&gt;举个例子。我们搞了个「引用来源查询」的划词指令：&lt;/p&gt;&lt;p&gt;「你是一位学术研究助手，精通文献检索。请针对以下观点或数据进行分析：{selection}，1）判断这可能属于哪个研究领域的哪个分支；2）推测可能的引用来源类型（奠基性理论文献、实证研究、综述文章、方法论文献）；3）提供搜索关键词建议；4）如果这是经典理论或常见观点，告诉我通常会引用哪些代表性文献或学者。注意：不需要提供具体论文链接，只需给我检索方向即可。」&lt;/p&gt;&lt;p&gt;想想以前核查引用来源，我们需要打开 Google Scholar，用各种关键词搜索，翻阅十几篇论文的摘要，判断哪些可能相关，再去下载 PDF 查看全文，最后才能确认是不是要找的那篇。一个引用来源，可能要花半小时甚至更久。&lt;/p&gt;&lt;p&gt;现在我们只需划词选中 DeepSeek 论文中一句话，点击「引用来源查询」，AI 不仅给出研究领域、来源类型、搜索关键词建议，甚至连代表性文献和学者也清晰罗列出来。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicibTKdpy4Ve5I2SI2CLd6wFMRRkACHHbkXKeRhfLpT8RdtArV5uYcNUA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.6275" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="363" data-imgfileid="503528233" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/5571c13b-cf46-4974-9380-49c21c0cebc7/640.gif" data-order="4" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;后续我们沿着这个方向，再去 Google Scholar 检索，效率飙升。&lt;/p&gt;&lt;p&gt;AI 在提升效率的同时，还会提醒我们这个观点属于什么研究脉络、应该引用什么类型的文献，这对于学术新手来说特别有价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;爆款生成器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;至于内容创作者，千问划词 - 快捷指令就更有用武之地了。&lt;/p&gt;&lt;p&gt;以机器之心编辑部为例，同一个话题要在 X、小红书、微博等多个平台发布，但每个平台的调性和用户偏好完全不同。&lt;/p&gt;&lt;p&gt;以前的做法是，编辑写好原稿后，再手动改写成各种版本，每个版本都要重新调整语气、结构、表述方式。现在，我们用夸克的「千问划词 - 快捷指令」，就能针对不同平台定制不同的改写指令。&lt;/p&gt;&lt;p&gt;比如同样是「特斯拉 FSD 首次横穿美国，Model3 实现 1 万英里零干预」这一话题，小红书爆款生成器的生成结果更生活化、更有共鸣感。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicYHSdYEdXZp0CddIJyia1PiaptViaKPGG96zDMTB8B6SCV6cYdRlvFe3nQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.6425" data-type="gif" data-w="800" type="block" data-imgfileid="503528239" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/bb0f71ff-3034-4f38-86fb-db067c8a2aef/640.gif" data-order="5" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「小红书爆款生成器」的指令是：你是一位小红书爆款内容创作者，请把以下内容改写成小红书风格：{selection}，要求：1）开头用 emoji 和惊叹式标题吸引注意力；2）把专业内容转化为「对用户有什么用」的实用角度；3）多用短句和段落，每段不超过两句话；4）结尾加上互动引导（如「你会用吗？」「评论区聊聊」）；5）适当加入网络热词但不要过度；6）控制在 500 字以内。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;微博热搜体的表达则是短平快抓眼球。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-backh="358" data-backw="562" data-imgfileid="503528234" data-ratio="0.6376274328081557" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic1rtHcqcYL1gBUjvjUVWp3jtN0DJIYWTORAGSliavzFVpMy2MElic5doQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-type="gif" data-w="1079" type="block" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/102376eb-4dc4-4dcb-89c7-2aa400cbaa1b/640.gif" data-order="6" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「微博热搜体」的指令是：你是一个专业的爆款微博大师，要求：1）用中括号【】先提炼最核心的信息做成一个标题；2）整体控制在 140 字以内；3）突出话题性和新闻感；4）加上 2-3 个相关话题标签；5）可以适当制造悬念引导点击链接。请把以下内容浓缩成一条微博：{selection}&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;X 平台则更偏向专业简洁。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicprqy0Bmh1Qic0dyFjZrEJp2ASc8hHU6G4YKSOQyLP7jd4L9eSjtX3sQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.6422613531047267" data-type="gif" data-w="1079" type="block" data-backw="562" data-backh="361" data-imgfileid="503528240" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/2868e7e3-c890-4ba9-a436-a3190717a7db/640.gif" data-order="7" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「X 平台国际化表达」的指令是：请把以下中文内容翻译成英文并调整为国际用户的阅读习惯：{selection}，要求：1）语言简洁直白，避免中式思维的复杂从句；2）突出核心事实，少用形容词和情绪化表达；3）如果涉及中国特有的概念或梗，要加简单解释；4）保持科技媒体的专业度但不要过于学术化；5）控制在 280 字符以内。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;通过千问划词 - 快捷指令，一篇内容快速适配多个平台，大大节省了编辑和运营同事反复思考和修改的时间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不止于指令：一个更强大的 AI 浏览器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;千问划词 - 快捷指令只是夸克 AI 浏览器能力升级的一部分。&lt;strong&gt;在这次更新中，夸克表现出更大野望，即成为一个真正意义上的超级应用。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;夸克 AI 浏览器除了全面融合千问 AI 助手，实现全局桌面唤起 AI 的创新交互形态；在阿里 Qwen 大模型加持下，&lt;strong&gt;近期更是一口气上线了十多种模型，供用户自由选择&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicAD3IRlCumGzjjaKWhibhRSBZPjHt4vLMbDrfWYib6ic7p9Yoqt3ZevZsQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.6413345690454124" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="371" data-imgfileid="503528235" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/3b591fa0-955d-482d-9ff4-75d65e5d02e0/640.gif" data-order="8" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时它也支持语音、图片、文件等多模态输入。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicPiafzybyE6FVtick7ZOcop4oBMgJdqDXTz7et2IOE2MiaTdF2T0pW7wfA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.6413345690454124" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="371" data-imgfileid="503528236" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/adaf9836-6974-4b82-b21c-4e79083a08cd/640.gif" data-order="9" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 首页、侧边栏、快捷框等均可实现语音输入。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，&lt;strong&gt;夸克 AI 浏览器还内置一系列实用的 AI 工具&lt;/strong&gt;。这些工具组合起来，可以构建起一套完整的一站式工作流。&lt;/p&gt;&lt;p&gt;比如我们要准备一份马斯克 SpaceX 的介绍 PPT，可以先使用夸克 AI 浏览器中的「超级播放器」，5 倍速观看相关视频，AI 实时生成字幕、翻译，并自动总结视频摘要和脑图，半小时的视频几分钟就能掌握。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/252a5045-5e98-4217-9ce1-9cead9bab461/1768450218858.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;然后调用夸克 PPT 工具生成汇报材料，将上述 AI 视频摘要输入进去，就能一键生成图文并茂的 PPT。海量模板任选，大纲随时调整。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dad953b6-7509-4ecd-bb49-bd1bcb89f453/1768450231667.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;夸克 AI 浏览器仍在以极快的速度持续进化，不断挖掘并满足用户更精细化的需求。&lt;/strong&gt;我们有理由相信，随着 AI 交互方式的持续创新优化、与工作流的深度整合，一个更强大的 AI 浏览器背后，是让个人真正实现「一个人即能活成一支队伍」的能力底座，所谓的「超级个体」也将不再是一句空话。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>已证实！清华姚班陈立杰全职加入OpenAI，保留伯克利教职</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 12:01:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/acc03329-ca2f-46fe-8152-ae7d24244959/1768449717057.png" style="width: 700%;" class="fr-fic fr-dib"&gt;据机器之心求证，清华大学「姚班」校友、加州大学伯克利分校（UC Berkeley）助理教授&lt;strong&gt;陈立杰（Lijie Chen）已正式加入 OpenAI&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="5"&gt;知情人士透露，陈立杰此次是以&lt;strong&gt;全职&lt;/strong&gt;身份加入 OpenAI 开展研究工作。与此同时，他目前在伯克利的状态为 On Leave（停薪留职），即他保留了在大学的教职，并未离职。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;陈立杰是理论计算机科学领域的顶尖青年学者，本科毕业于清华姚班，博士毕业于麻省理工学院（MIT），在计算复杂性理论等领域拥有卓越的学术成就。&lt;/p&gt;&lt;p data-path-to-node="7"&gt;截至目前，其个人主页和 LinkedIn 页面尚未更新。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDaqKWkZeGtANwZg9y9zUV0Jk9td0YvwfjDtlJ1pmpR5PdhMhDqjibeiag/640?wx_fmt=jpeg#imgIndex=1" data-ratio="0.9305555555555556" data-type="png" data-w="1080" data-width="1521" data-height="1761" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDOHYFqQZhfcFNPmnJCG9pjEbgqejTeX5iaBClKRE3IjbvmTwFa2A9e8A/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy2="1005.0533807829181" data-imgfileid="503528407" data-aistatus="1" data-original-style="width:562px;height:523px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8c483a01-1c51-441c-9ed4-617ffd1c7cd0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDNjqD1ITGUvZzuC01n8abQnrVG4hXosNK5SiaA1woDBfJFu1Yrx4sjMQ/640?wx_fmt=jpeg#imgIndex=2" data-ratio="1.2916666666666667" data-type="png" data-w="1080" data-width="1194" data-height="1704" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDvQxBeWxeTXHms5QL1zvPCm1Z74pzmEp0nLjs1c1D4QMYwEuSSS2jrQ/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy1="92.24199288256227" data-cropy2="1487.4021352313168" data-imgfileid="503528402" data-aistatus="1" data-original-style="width:562px;height:726px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1e527d87-4420-4124-94fd-2cd33c56a834/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="8"&gt;&lt;strong&gt;从 IOI 金牌到伯克利助理教授&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;陈立杰高中就读于杭州外国语学校。他在信息学竞赛（OI）领域表现突出，是当时知名的竞赛选手。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;2011 年，他获得全国青少年信息学奥林匹克竞赛（NOI）金牌；2013 年，他代表中国队出征第 25 届国际信息学奥林匹克竞赛（IOI），不仅夺得金牌，更取得了全球第一名的成绩。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDNeZqJ8KUyicvsibXAylhNXAVIhxRfZoFTYWguibcKvD6ISsKliafuPMGicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5433333333333333" data-type="png" data-w="600" data-imgfileid="503528413" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8062465f-5d24-4da8-a1ad-7055eaf3ae30/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="11"&gt;进入清华大学姚班后，陈立杰逐渐将重心从程序设计竞赛转向计算机科学理论研究。2016 年，他获得清华大学本科生特等奖学金。在特等奖学金答辩会上，陈立杰曾立下宏愿：「&lt;strong&gt;有生之年，希望能看到 P vs NP 问题被解决。&lt;/strong&gt;」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgjkLv9SWDs8jXPeaNs1QHLATcFogMWXzkkoictumhkv3EAkDcbWvsow/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6366666666666667" data-type="png" data-w="600" data-imgfileid="503528412" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/71f41604-8e2b-4fd3-821d-05347c1117fb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;大三时期，他曾赴 MIT 进行科研交换，师从著名量子信息科学家 Scott Aaronson 教授。2017 年，作为大四本科生的他在 FOCS（IEEE 计算机科学基础年会）上发表了论文，&lt;strong&gt;成为首位在该顶级会议上发文的中国本科生&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDz1Fte6DQa9OLZ4VQhPz7iaicnQI5AhsaVSwXQgTZPRuzfgtgUyxOKjHQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.7583333333333333" data-type="jpeg" data-w="600" data-imgfileid="503528409" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3267e0c9-a55b-4552-9253-5478b8d4cf15/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="13"&gt;该论文是他在 MIT 访问期间与 4 名博士研究生及博士后合作完成的，解决了 John Watrous 于 2002 年提出的关于「量子统计零知识证明」（QSZK）的开放性问题，引入了「量子区分复杂度」这一新概念，证明了其与 QSZK 查询复杂度的关系，解释了传统分析方法的局限性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="14"&gt;&lt;b data-index-in-node="0" data-path-to-node="14"&gt;论文地址：&lt;/b&gt;https://arxiv.org/pdf/1609.02888&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="15"&gt;本科毕业后，陈立杰赴 MIT 攻读博士学位，师从计算复杂性权威 Ryan Williams 教授。这一时期，他在&lt;strong&gt;计算复杂性、电路复杂度、伪随机性&lt;/strong&gt;等领域取得了实质性突破，主要贡献包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="16,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,0,0"&gt;硬度放大：&lt;/b&gt; 他与合作者发现了一条绕过「自然证明」壁垒的潜在路径：证明某些问题在极弱的电路模型下是困难的，可以自动「放大」推导出它们在极强电路模型下也是困难的（即推导出 P &amp;ne; NP）。严谨的是，他也提出了「局部性壁垒」，客观指出了目前技术在利用这一发现时面临的实际困难。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,1,0"&gt;非黑盒去随机化：&lt;/b&gt; 他提出了一种新框架，证明在比传统要求更弱的假设下，可以去除算法中的随机性。他还证明了在特定条件下，随机性对于计算可能是「无用」的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,2,0"&gt;量子霸权的理论基石：&lt;/b&gt; 他参与证明了存在一个 Oracle，使得量子多项式时间（BQP）不包含在多项式层级（PH）中。这为量子计算机在理论上超越经典计算机提供了坚实的数学支撑。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="17"&gt;他在博士期间多次获得理论计算机顶级会议的最佳学生论文奖，包括 STOC 2019（Danny Lewin Award）和 FOCS 2019（Machtey Award）。2022 年，他的博士论文获得 ACM 博士论文奖荣誉提名以及 MIT George M. Sprowls 最佳博士论文奖。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDFtg8HUndFooTiaxvn4jyP3B1ayDCre1mwYIYelUwFVn6lw8icoZ5NV4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6714285714285714" data-type="png" data-w="980" data-width="980" data-height="658" data-imgfileid="503528419" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c432f97a-faaf-42f7-ab70-86543e799aba/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="18"&gt;2022 年博士毕业后，陈立杰获得了 UC Berkeley 米勒基础科学研究所的 &lt;strong&gt;Miller Fellowship&lt;/strong&gt;。这是一项面向全球杰出青年科学家的全额资助计划，历史上曾诞生过多位诺贝尔奖和菲尔兹奖得主。作为米勒研究员，他拥有完全的学术自由，在三年内专注于自己感兴趣的前沿课题。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;他于 2025 年 7 月入职 UC Berkeley 电气工程与计算机科学系（EECS）担任助理教授，继续从事教学与科研工作。&lt;/p&gt;&lt;section&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/section&gt;&lt;section&gt;&lt;sup&gt;https://www.tsinghua.org.cn/info/1953/13913.htm&lt;/sup&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>解锁任意步数文生图，港大&amp;Adobe全新Self-E框架学会自我评估</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 11:58:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/404ea3bf-7d73-4b10-9055-d81ed68eadc3/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管扩散模型（Diffusion Model）与流匹配（Flow Matching）已经把文本到图像生成（Text-to-Image, T2I）推向了更高的视觉质量与可控性，但他们通常在推理时需要数十步网络迭代，限制了其对于一些需要低延迟，Real-Time 的应用。&lt;/p&gt;&lt;p&gt;为了把推理步数降下来，现有路线通常依赖知识蒸馏（Distillation）：先训练一个多步教师模型，再把能力迁移到少步学生模型。但这条路的代价同样明显 &amp;mdash;&amp;mdash; 既依赖预训练教师，又引入了额外的训练开销，并在「从零训练（from scratch）」与「极少步高质量」之间留下了长期空白。&lt;/p&gt;&lt;p&gt;近日，香港大学（The University of Hong Kong）与 Adobe Research 联合发布 Self-E（Self-Evaluating Model）：一种&lt;strong&gt;无需预训练教师蒸馏、从零开始训练的任意步数文生图框架&lt;/strong&gt;。其目标非常直接：让同一个模型在极少步数也能生成语义清晰、结构稳定的图像，同时在 50 步等常规设置下保持顶级质量，并且随着步数增加呈现单调提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAvlRwkoKg4F7DFOOm16JzLj2F0t3WyRSicfDL1ibHjIzokI51iaS1UueSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.27037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528045" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/03427976-4849-4dc5-a278-d8adaa8d6bb8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Self-Evaluation Unlocks Any-Step Text-to-Image Generation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://xinyu-andy.github.io/SelfE-project/&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文 PDF：https://www.arxiv.org/pdf/2512.22374&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsuBcsLgMO3SOAXfTrUQ8Kqp1L4oc9YCLSM4xrSn2WE5FUDrDtf15eQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5342592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528044" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c7250837-2b24-40bd-b3c7-bfa9bea307bb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;引言：从「轨迹匹配」到「落点评估」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;扩散 / 流匹配范式本质上是在学习一张「局部向量场」：给定噪声状态，预测下一步该往哪里走。这个监督信号在「小步、密集积分」时非常有效，但一旦尝试「大步跳跃」，误差会被轨迹曲率放大，生成往往滑向平均解、语义漂移或结构坍塌。&lt;/p&gt;&lt;p&gt;Self-E 的切入点是一个根本上的范式改变：&lt;strong&gt;我们能否不再执着于「每一步走得对不对」，而是把训练重心转向「落点好不好」？&lt;/strong&gt;也就是把目标从「轨迹匹配（trajectory matching）」转变为「落点评估（destination/landing evaluation）」。&lt;/p&gt;&lt;p&gt;换句话说，传统 Diffusion Model 训练强调「在起点对齐局部方向」；Self-E 强调「在落点评估结果并给出纠偏方向」。监督位置的改变，带来了训练信号性质的改变：从静态监督变成动态反馈。&lt;/p&gt;&lt;p&gt;作者在项目主页用动图展示了这两者的区别：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAe6xwicALoYz3p73XBzZwIkVnQ7zzDsCraQlplYa4H0Bo7AqYbW6p5xw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.5829471733086191" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503528046" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/fb315588-387f-4e02-a7a4-55865bdf0f5c/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA7nHJfx8zhw61HDVt6V5WhIuqglibu4JyKBKASImLa606R3YZmyMm5Dg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.5829471733086191" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503528047" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7e7fb9e8-6e51-476b-8c23-59effe360bc5/640.gif" data-order="1" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这也是为什么模型在测试阶段有少步推理能力：扩散模型在测试时只能逐步跟随当前点预测的最好局部路径，最终走到全局最优；而 Self-E 在训练阶段就逐步学会了走向全局最优的落点。&lt;/p&gt;&lt;p&gt;这也不同于目前多数少步生成模型所采用的学习轨迹的积分，如 Consistency Model, Mean Flow; Self-E不局限于沿着预定义的轨迹走，而是直接关心每步结果好不好，对不对。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Self-E 的核心：两条互补训练信号（Two Complementary Signals）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 用同一个网络在两种「模式」下工作：一方面像 Flow Matching 一样从真实数据学习分布的局部结构；另一方面用「模型自身正在学到的局部估计」去评估自生成样本，形成自反馈闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1）从数据学习：Learning from Data&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;学什么&lt;/strong&gt;：分布的局部结构（local score /velocity 的期望形式），即「在邻域内密度如何变化」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;怎么学&lt;/strong&gt;：采样真实图像与文本条件，加噪得到噪声输入，用条件流匹配式目标训练模型去预测干净样本（或等价参数化），提供稳定的局部监督。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2）自我评估学习：Learning by Self-Evaluation&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;学什么&lt;/strong&gt;：分布层面的正确性（distribution-level correctness）&amp;mdash;&amp;mdash;&amp;nbsp;生成样本是否与真实分布一致、是否与描述的文本对齐。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键机制&lt;/strong&gt;：模型先做一次「长距离跳跃」（从起始时间步跳到落点时间步），然后在落点处用自己当前学到的局部估计产生一个「方向信号」，告诉生成样本应如何移动才能进入更高质量、更符合文本的概率分布区域。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最大差异&lt;/strong&gt;：评估信号不来自外部教师（pretrained diffusion teacher），而是来自模型自身的在训估计（dynamic self-teacher）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAb6e5QriaPUVibjetLXLCOkO5a4r60gibVAUAgSiaIialNvIfQHqwUKuicp1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528048" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/8d0e1028-1471-4428-a999-f7773fb6950a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;训练细节：把「自我评估」做成可反传的学习信号&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 在理论上把评估写成分布级目标（例如以反向 KL 为代表的分布匹配视角），但真正落地的难点在于：真实分布与生成分布的 score 都不可得。&lt;/p&gt;&lt;p&gt;Self-E 的关键观察是：&lt;strong&gt;模型在「从数据学习」阶段会逐步学到某种条件期望形式，而该量与 score 通过 Tweedie&amp;rsquo;s formula 存在联系&lt;/strong&gt;，因此可以用「正在训练的模型」去近似提供评估方向。&lt;/p&gt;&lt;p&gt;在实现上，作者发现理论目标中包含「classifier score term」等项，并实证发现仅使用 classifier score 项就足够有效，甚至更利于收敛，从而避免早期还要额外训练一个用于 fake score 的模型分支。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA5p4gj4vOpXFrMHbiaVbHYiaS6MlETMShJ9Xr1vZEXcgkfrAeNOXCVmFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3074074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528049" data-aistatus="1" data-original-style="width:374px;height:115px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c51c4cff-042f-40a8-b873-879557485033/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了把这种「评估方向」变成可训练的损失，Self-E 采用 stop-gradient 的双前向构造 pseudo-target，通过最小化 MSE 诱导出与所需方向一致的梯度；并在最终目标中将数据驱动损失与自评估损失进行混合加权。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGVx9h55OaXTDXHvkOIh12xKEibpuHX49QLYoOugmfQzwLKnz8qa3nZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.20462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528050" data-aistatus="1" data-original-style="width:347px;height:71px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/547d8dac-fa19-43fc-83a2-5543e4546836/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最终，我们可以用一个统一的形式来训练：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuo01tTMfxTSRAgbLFyObmTO431CcULicSNEWkFR74fXfLfn63qicj1Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.11481481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528051" data-aistatus="1" data-original-style="width:320px;height:37px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/19efea39-1e2a-4e2b-b666-2f56a04b9d26/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中，等式右边第一项正是 Learning-from-data 的目标，而第二项对应 Self-Evaluation。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理：任意步数（Any-Step Inference），并随步数单调变好&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在推理阶段，Self-E 与扩散 / 流匹配一样进行迭代去噪，但不同之处在于：由于训练中已经显式学习「长距离落点」的质量与纠偏方向，它可以在非常少的步数下保持可用的语义与结构，同时在增加步数时继续提升细节与真实感。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;性能：GenEval 全步数段 SOTA，少步优势尤其显著&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 GenEval 基准上，Self-E 对比其他方法取得全面领先，并且随着步数增加呈现单调提升。更关键的是少步区间的「断层式」优势：在 2-step 设置下，Self-E 相比当时最佳对比方法的提升约为&lt;strong&gt; +0.12&lt;/strong&gt;（0.7531 相比 0.6338），而多种传统扩散 / 流匹配模型在 2-step 下几乎无法生成可用结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAK3VzR2O3ILOtbJyxwS39UOU4pmBKovEKWlLsZ3wtnEDcezwicJvg2bw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528052" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/699a30fc-1c99-4433-add6-b98868d536a3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAI75P0LtKlz5R16L9ICeSHtRSqDpuDV6Dib9oTIU9v9XW51o0jYQc7bA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.8518518518518519" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528053" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c6d9e0ab-7a49-4e5e-9a61-ca451b520943/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;另一角度解读：把「预训练」与「反馈学习」拉到同一条线上&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从更宏观的视角看，Self-E 把训练过程组织成一个类似强化学习中的「环境 &amp;mdash; 智能体（environment&amp;ndash;agent）闭环」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Phase&lt;/strong&gt;：模型从真实数据学习分布的局部结构，得到越来越可靠的局部估计（可视作学习环境，并给出评估）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Self-Evaluation Phase&lt;/strong&gt;：模型提出长距离跳跃方案（可视作智能体执行动作），在落点处用内部估计产生反馈方向并更新参数（可视作获得环境的反馈）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Closed Loop&lt;/strong&gt;：评估器随训练变强，反馈信号质量随之提升，反过来又进一步强化少步生成能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者在项目主页指出：这种内部评估器在角色上接近「可查询的学习型奖励模型」，为后续把强化学习（RL）更系统地引入视觉生成训练提供了新的接口与想象空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 的价值不只是在「少步生成」这一条指标上跑得更快，而在于它把文生图训练范式从「沿着既定轨迹走」推进到「学会评估落点并自我纠偏」：在不依赖预训练教师蒸馏的前提下，让单一模型同时覆盖极低时延与高质量长轨迹两种需求，并在不同推理预算下保持可扩展的性能曲线。&lt;/p&gt;&lt;p&gt;对内容创作与生成式系统落地而言，「one model, any compute」的工程意义非常直接：同一个 checkpoint 可以按场景动态选择步数 &amp;mdash;&amp;mdash; 交互式场景用 1～4 步追求即时反馈，高质量离线渲染用 50 步追求细节上限；而训练侧则绕开了教师蒸馏链路，把「从零训练 + 少步推理」真正拉回到可讨论、可复现、可扩展的主流路径上。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>5分钟定制一个AI采购专家：讯飞发布“招采智能体工厂”，重新定义行业开发范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 15 Jan 2026 11:35:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;大模型落地，正从&amp;ldquo;聊天与创作&amp;rdquo;走向&amp;ldquo;规划与执行&amp;rdquo;的深水区。1月13日，科大讯飞将这一趋势押注在一个极其垂直且复杂的领域&amp;mdash;&amp;mdash;招标采购，并发布了其全新的&amp;ldquo;招采智能体平台&amp;rdquo;。与其说这是一个产品，不如说它是一个&amp;ldquo;专为招采场景打造的智能体操作系统与开发工厂&amp;rdquo;，其核心主张令人振奋：零代码，5分钟，让企业构建属于自己的AI采购专家。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c97a3f6d-6b0e-45c7-8526-841c8dc20a2d/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;要理解这场发布的意义，首先要看清AI赋能招采的技术演进之路。1.0时代是&amp;ldquo;工具辅助&amp;rdquo;，核心是&amp;ldquo;小模型+结构化&amp;rdquo;，解决了&amp;ldquo;人工翻页&amp;rdquo;痛点，但AI不理解业务；2.0时代进入&amp;ldquo;单点智能&amp;rdquo;，大模型带来了认知突破，能深度理解评审规则，但无法解决流程割裂问题；3.0时代即&amp;ldquo;智能体（Agent）时代&amp;rdquo;，智能体具备自主规划、跨域协同、持续进化能力，成为能够推进全流程的&amp;ldquo;专业伙伴&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/d04571c4-3b69-4e8d-8f47-fa5d4d8ea648/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&amp;ldquo;招采智能体平台&amp;rdquo;的架构基于三大核心技术支柱：首先是&amp;ldquo;星辰Agent底座&amp;rdquo;，这是平台的&amp;ldquo;决策大脑&amp;rdquo;，是国内首批融合大模型决策规划与RPA执行能力的智能体平台；其次是&amp;ldquo;星辰RPA&amp;rdquo;，作为智能体的&amp;ldquo;自动化双手&amp;rdquo;，能够稳定执行跨软件操作；第三是&amp;ldquo;MaaS模型精调平台&amp;rdquo;，允许企业上传自身数据精调模型，平均40分钟即可完成一个细分场景模型的优化。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a074e41d-0134-449c-aeb4-9dc9a9e78372/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;发布会的体验区成为了技术理念的最佳秀场。参会者可以亲历两大亮点：在&amp;ldquo;智能体搭建工坊&amp;rdquo;，即使毫无编程基础的业务人员，通过简单的拖拽、连线，就能快速构建一个可运行的智能体；作为发布会的技术彩蛋，讯飞透露正在跟进国际领先的智能体&amp;ldquo;技能&amp;rdquo;（Skills）标准，该标准旨在为AI编写结构化的&amp;ldquo;工作手册&amp;rdquo;，预示着未来智能体将具备更强大的跨平台任务执行能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/95987983-18ad-422c-b022-7906f026f867/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;讯飞深知，招采业务场景千变万化，仅靠自身无法穷尽。因此，平台的终极目标是构建生态。它不仅内置了覆盖招标、投标、评标核心流程的数十个专业Agent，更将底层能力开放。未来，第三方开发者、行业专家可以基于此平台，开发并上架更丰富的垂直场景智能体，共同打造招采领域的&amp;ldquo;智能应用商店&amp;rdquo;。&lt;/p&gt;&lt;p&gt;从单一AI应用到开放的能力基座，科大讯飞此次发布标志着其AI to B战略进入了以&amp;ldquo;平台+生态&amp;rdquo;驱动的新阶段。在行业聚焦于真实价值创造的当下，招采智能体平台能否以其鲜明的技术路径和清晰的落地场景，成为垂直领域大模型应用的新范式，值得所有技术观察者持续关注。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Agent时代，为什么多模态数据湖是必选项？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 09:55:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/357eea47-54fc-4a65-9090-96dbe74862e5/1768441988644.png" style="width: 700%;" class="fr-fic fr-dib"&gt;「2025 年，注定被铭记为 AI 工业时代的黎明。」&lt;/section&gt;&lt;p&gt;回望这一年，吴恩达教授曾这样感慨。&lt;/p&gt;&lt;p&gt;这一年，大量企业你追我赶，投身于 AI 应用及 Agent 建设。然而，许多企业或许尚未意识到：如果 AI 竞速只停在应用层，可能连这场竞争的「起跑线」都尚未站上。&lt;/p&gt;&lt;p&gt;AI 时代，数智化表面是模型的狂欢，底层是基建的深耕。&lt;/p&gt;&lt;p&gt;唯有能支撑 AI 应用规模化落地的数据基座，才能构筑企业真正的竞争力。&lt;/p&gt;&lt;p&gt;近来， AI 行业普遍认为我们正在进入所谓的「AI 下半场」，而此时行业面临的一大关键问题是「究竟应该让 AI 去做什么？又该如何衡量真正的进展？」&lt;/p&gt;&lt;p&gt;而这个问题的答案也基本已有共识：要想在这下半场脱颖而出，我们需要及时转变思维方式，应当用 AI 的思维，把该做的事情重新做一遍。&lt;/p&gt;&lt;p&gt;与上一阶段不同，这一阶段的企业数据，不再等待人来解读，而是被模型直接「消费」。&lt;/p&gt;&lt;p&gt;以音频数据应用为例，AI 时代，音频数据不应只是一份录音数据存档，还应成为可查询和交互的信息源，比如应该支持查找「录音中的人是客户 A ，上周在另一业务有投诉记录」这类关联信息。这种跨模态的关联性，是实现模型复杂推理的基础。&lt;/p&gt;&lt;p&gt;推及其他行业：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在智能驾驶中，道路视频、点云与传感器数据需要被实时送入智能体，支撑感知、规划与异常检索；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在游戏行业，需要将对话、行为与世界观等多模态数据沉淀为长期记忆，用于沉浸式 NPC 与自动化资产生成；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在传媒行业，需要使用视频、音频与用户互动数据来驱动内容生成与精准分发；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在电商领域，商品图文与交易数据直接喂给模型，实现智能选品与个性化推荐。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，&lt;strong&gt;对多种模态数据的处理与使用的能力，正在影响各行业商业竞争的形态与上限&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;接下来的风口要踏在哪里？我们关注到了火山引擎近期发布的《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzkwMzMwOTQwMg==&amp;mid=2247521304&amp;idx=1&amp;sn=dc367120edc88b47f8ed7f4f168e2c4c&amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;strong&gt;AI 时代企业数据基建升级路线图&lt;/strong&gt;&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;它在开篇写到：&lt;strong&gt;AI 时代，数据基建已经成为决定企业竞争高度的战略资产&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;笔者深以为然。&lt;/p&gt;&lt;p&gt;企业要发展可以处理多模态数据的底层基建。因为 AI 时代最深的红利，并不在于「拥有」SOTA 的模型，而在于能否持续「驾驭」并「滋养」它。更进一步，可以说构建多模态数据湖已经成为企业参与这场 Agent 竞赛的必选项。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicEgLkymO8MMCrLiavX0ql8FiaIic9vG0qu0TCo74T5VGbKcuyO8iaLNWeAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528308" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a7f325e4-217e-4dce-9d6a-511b35d4d756/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 传统数据湖与多模态数据湖对比，图像由 AI 生成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 时代，这是你不能错过的风口&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智能的涌现扎根于坚实、鲜活且可进化的数据土壤。&lt;/p&gt;&lt;p&gt;尤其在 Agent 时代的到来之际，企业竞速也正由数据基建分野：领先者正将沉睡的非结构化数据转化为可用的竞争力，而落后者由于非结构化数据资产仍处于休眠状态，而只得徘徊在 Agent 应用的起点。&lt;/p&gt;&lt;p&gt;当行业的聚光灯都投向大模型或智能体本身时，真正的竞争已转入水下，&lt;strong&gt;即底层的、支撑多模态数据的数据工程。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;唤醒数据，化「沉睡库存」为核心资产&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;IDC 预测，2025 年企业超过 80% 的数据将是非结构化的。&lt;/p&gt;&lt;p&gt;这些长期堆积的视频、音频、图像和传感器数据，曾被视为「数字负债」。然而，多模态与大模型技术的成熟，正让它们焕发前所未有的价值。&lt;/p&gt;&lt;p&gt;以制造业为例，以往无人问津的历史故障录像，经大模型解析与标注，即可成为「智能知识库」。新员工用自然语言提问，便能精准调取同类故障的处理记录 &amp;mdash;&amp;mdash; 沉寂数据瞬间转化为实战生产力。&lt;/p&gt;&lt;p&gt;本质上，AI 时代的数据基建，正通过向量化等处理能力，让非结构化数据真正「活」起来，使其从被动存储的负担，变为可随时调用、持续学习的战略资源。&lt;/p&gt;&lt;p&gt;唤醒这 80% 的数据，是在 Agent 时代构建竞争力的工程前提。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让数据资产驱动业务，启动飞轮&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;强大的数据基建能构建数据、模型与业务深度耦合的闭环，真正「让模型自主成长」，为 Agent 赋予更多智能。&lt;/p&gt;&lt;p&gt;一个优秀的数据架构，需在企业数据平台、MaaS（模型即服务）平台、Agent 开发工具与应用之间建立高效的数据流通管道，否则数据会停留于「孤岛」，智能难以落地。&lt;/p&gt;&lt;p&gt;典型的例子是传统智能客服：尽管不断采集用户的语音、文本、截图与操作轨迹，却因模型与业务间数据不通，导致客服模型始终重复犯错、体验停滞，陷入「千人一面」的困境。&lt;/p&gt;&lt;p&gt;我们发现，火山引擎通过多模态数据湖与 AgentKit、火山方舟等产品的联动，已验证了数据、模型、业务打通的可行性。在零售行业中，完善的多模态数据湖不仅能分析销售报表，还可实时捕捉顾客行为、评论与画像。这些鲜活数据持续回流，使企业 AI 能力能随业务不断演进。&lt;/p&gt;&lt;p&gt;这种「业务滋养模型、模型反哺业务」的闭环，使企业 AI 能力可伴随业务持续进化，这正因为此，多模态数据湖成为了 Agent 时代构建智能护城河的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让业务拥有锚点，获得未来的确定性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;新一代数据基建通过统一的数据与计算底座，以同一平台支撑多模态数据，并持续适配技术演进。&lt;/p&gt;&lt;p&gt;以某安防企业为例，传统数据管理体系下，如果从视频监控扩展至智能识别，往往需为不同算法供应商重建独立的计算平台与数据库，导致内部数据不互通、烟囱林立。巨大的管理和技术成本，会拖累企业创新动力。&lt;/p&gt;&lt;p&gt;而统一的多模态数据湖体系，能以统一元数据管理结构化和非结构化数据，提供面向 AI 的灵活数据集能力，支持数据快速探查与调用。通过标准化存储与可扩展接口，系统能在上层屏蔽底层模型的频繁迭代，使数据始终以对模型友好的形态稳定输入。&lt;/p&gt;&lt;p&gt;这意味着，当该企业未来业务从「视频监控」拓展至「自动巡检」、「人流预测」等领域时，可低成本接入新算法模块，无需颠覆底层架构。&lt;/p&gt;&lt;p&gt;「基建不动，技术常新」，在追求敏捷响应速度的 Agent 时代，这种具备工程确定性的多模态基座正在成为架构的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;升级三部曲：积累，重构，融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;火山的这份「数据基建升级路线图」之所以值得展开聊聊，是因为它在行业内率先为企业提供了一套从「拥有模型」到「驾驭智能」的数据基建进化蓝图。在 Agent 时代，它为企业提供一套实现多模态数据湖的清晰演进路径。&lt;/p&gt;&lt;p&gt;这个蓝图可作为重要的参考框架，企业可结合业务特点与发展阶段，衍生出适合自身的基建升级路径，进而在 Agent 时代构筑自己的核心竞争力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528305" data-ratio="1.0444444444444445" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiciaapBNl8MSNCEIsQNResw6sdN9fdh5YF9NrTPrseSomrXiabvRibCotAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a388d8f5-e4e3-4cd0-a29a-73ad318413a7/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;具体而言，火山引擎将企业数据基建的演进分为了三步渐进式过程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;异构算力与分布式引擎阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一阶段的核心是突破算力瓶颈。为应对大规模数据处理与大模型训练的需求，传统仅依赖 CPU 的架构已难以满足 AI 时代对存储与计算的高实时性要求。企业需转向为 AI 任务量身打造的 CPU+GPU 异构架构，实现灵活调度。&lt;/p&gt;&lt;p&gt;这一阶段的核心目标是：数据「进得来，跑得快」，并原生支持 AI 服务。在异构算力的支撑下，企业能在技术快速迭代中平衡性能与成本，真正让算力服务于业务与模型增长。整体来说，这一阶段可为多模态数据湖这一必选项提供坚实的物理支撑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型即引擎与多模态重构阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在算力基础就绪后，需进一步推动数据基建与 AI 的深度融合。本阶段的关键在于将预训练大模型嵌入数据流水线，实现文本、图像、音频等多模态数据向统一语义向量与高价值知识标签的自动转换。&lt;/p&gt;&lt;p&gt;Agent 时代，数据价值不在于「存量」，而在于能被 AI 调用的「流量」。通过&lt;strong&gt;向量化&lt;/strong&gt;处理，企业的多模态资产第一次真正实现通用「可读、可感、可交互」。该过程直接发生于数据基建层，从源头确保企业数据对大模型友好，使其可随时被检索、推理与学习，赋能全感官业务洞察。&lt;/p&gt;&lt;p&gt;因此，这一阶段可使多模态数据湖成为 Agent 识别与推理的逻辑重心，进一步确立了其作为基建必选项的地位。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全域数据治理与平台融合阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目标是在管理层面对数据资产进行统一管控，推动全域数据的治理、价值激活与安全合规。&lt;/p&gt;&lt;p&gt;这意味着 AI 能力可深度融入每一条业务流程，激活分散在不同系统与形态中的数据资产，并将其持续转化为增长动能。统一的数据治理体系不仅能显著降低安全与合规风险，还可大幅提升数据复用效率，助力企业将技术优势系统化、可持续地转化为长期竞争力。&lt;/p&gt;&lt;p&gt;这一阶段标志着多模态数据湖从单一的技术底座演变为全域的智能中枢，完成了其作为 Agent 时代必选项的最后拼图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 时代数据基建的选型指南&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;国内云厂商都在积极拥抱 Agent 时代的技术升级，从各大厂商的进度来看，对多模态数据的「存、算、管」重视度在持续提升。其中，我们观察到火山引擎「多模态数据湖」在行业内的进展最快，能够提供数据统一入湖与治理能力，在算子体系、性能优化、异构算力调度以及与大模型生态的无缝协同方面形成了更完整的一体化方案。&lt;/p&gt;&lt;p&gt;同时通过观察行业内其他厂商面向多模态数据的方案方向，我们也在思考：AI 和 Agent 时代的企业需要的数据基建，到底应该是什么样的？&lt;/p&gt;&lt;p&gt;综合起来，我们认为企业应将&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;以下特质列为&lt;/span&gt; AI 数据基建的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从「存储中心」到「价值中心」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 AI 浪潮下，企业首先撞上的，是数据体系的根本性变革。&lt;/p&gt;&lt;p&gt;一方面，数据规模动辄 PB 级，非结构化格式复杂，处理流程高度碎片化，还要同时承载 CPU + GPU 混合负载与复杂作业调度；另一方面，大量数据分散存储、难以统一检索，无法被模型高效消费，数据准备周期越来越长，成本却持续上升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真正有价值的数据，是能被快速获取、被模型理解、能转化为 Token 并直接参与推理与训练的数据。&lt;/strong&gt;而那些无法被向量化、无法进入模型工作流的数据，正在从资产变成沉重的存储负担。&lt;/p&gt;&lt;p&gt;AI 时代的数据底座，是从「存储中心」转向「价值中心」的底座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;业务优先，回归实用主义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在技术变革快速的当下，除去技术复杂性之外，企业更大的挑战是：数据基建与业务脱节。&lt;/p&gt;&lt;p&gt;当前很多企业同时面临多模态数据分散、训练与生产割裂、血缘与版本缺失、质量评估与数据反馈闭环不足的问题。结果是数据冗余高、问题排查难、准备周期长，而业务决策却越来越依赖实时与精准。&lt;/p&gt;&lt;p&gt;在这种背景下，盲目堆算力、追求极限性能，反而成了负担。AI 时代最昂贵的基建，是那些无法转化为业务价值的闲置能力。&lt;/p&gt;&lt;p&gt;衡量一套数据基建是否先进，在于它是否能以最低成本、最快速度完成从数据输入到业务决策的闭环，并持续驱动数据飞轮运转。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开放解耦，对冲未来不确定性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着模型与技术路线持续快速更迭，企业面临的另一项长期风险正在显现：如果数据基建随模型变化不断重构，系统将永远处于迁移与动荡之中。&lt;/p&gt;&lt;p&gt;在多模态数据规模持续膨胀、合规与安全要求不断提高的背景下，这种反复重构的代价几乎不可承受。&lt;/p&gt;&lt;p&gt;因此，解耦与开放的能力决定了成为企业的「生存能力」。通过模块化、可替换的数据与 AI 基础设施，企业才能在模型更替、技术跃迁时实现平滑升级，既保持系统稳定，又持续吸收新能力，将技术不确定性转化为长期竞争力。&lt;/p&gt;&lt;p&gt;在 AI 时代，模型会不断过时，真正具有长期价值的，只有数据资产与承载它的基础设施弹性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaictYQCpliak2DZbxFh5zJDsxEEZpjicLm7EyXopeXeygEoAD9NibJPndkFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528306" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4b6d51d4-f1a3-4864-a3a6-b614609e3925/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这使得多模态数据管理必须从「存得全、存得久」升级为「取得快、读得懂」的针对业务模式的系统性工程。&lt;/p&gt;&lt;p&gt;我们观察到火山引擎多模态数据湖有一个非常有意思的理念。&lt;/p&gt;&lt;p&gt;其提出了&lt;strong&gt;「乐高式」可组合底座&lt;/strong&gt;的观点，与其他云厂商的解决方案大相径庭。这种方式支撑企业以乐高积木般灵活、高效的方式，自主构建上层应用与智能体。&lt;/p&gt;&lt;p&gt;在这种框架下，企业可以根据现有的技术情况，选择渐进式的解决方案，同时可以模块化设计数据与智能架构，结合自身业务来进行组合式的升级，方案完全「量身定做」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicib7SIKbm4ZkDISKe6wUy1RCoEtgL0X1UTEerliaRmnGI6dPvzKdKfNWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528307" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/768e01dd-7c95-4144-9c3c-312338cd6d3f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从行业视角看，这一设计理念呼应了企业长期的 AI 战略 &amp;mdash;&amp;mdash; 让数据基础设施具备持续演进的能力，使企业在快速迭代的技术环境中，始终拥有自主调整与进化的空间。&lt;/p&gt;&lt;p&gt;目前火山的多模态数据湖，已经在智驾、游戏、传媒等多个行业落地。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在某智驾企业的模型训练中，该方案可在 150&amp;ndash;200 毫秒内完成 12 亿级别数据的「以图搜图」，性能提升&amp;nbsp;&lt;strong&gt;20 倍&lt;/strong&gt;以上；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;某游戏企业在 AI NPC 模型训练过程中，音视频数据加工效率提升&amp;nbsp;&lt;strong&gt;50%&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;应用于某头部传媒企业的媒资平台后，其内容生产与运营效率提升 &lt;strong&gt;90%&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些实践表明了采用多模态数据湖的必要性，同时也揭示出：AI 和 Agent 时代，用好多模态数据，可以激发出推动企业智能化跃迁的潜能。千行百业，都值得以此为起点，探索数据基建的更多可能，拥抱智能时代的风口。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当下，企业正站在一场深刻技术变革的洪流之中。&lt;/p&gt;&lt;p&gt;AI 落地的前提，是多模态数据处理走向标准化与智能化。对坚定投身于 AI 浪潮的企业来说，在见证大模型所带来的能力飞跃的同时，更应关注到多模态数据管理作为基础设施的必要性。&lt;/p&gt;&lt;p&gt;构建能够支撑未来十年 AI 发展的数据基座，是这场变革中最应锚定的重心。&lt;/p&gt;&lt;p&gt;对企业而言，多模态数据湖的意义远不止步于一套数据架构。它是承载 AI 应用持续演进的土壤，是企业在技术红利窗口期建立确定性的基础。&lt;/p&gt;&lt;p&gt;是的，正如我们已经在文中多次强调的那样：多模态数据湖已经不再只是可有可无的优化项，而是企业进入智能赛道的必选项。&lt;/p&gt;&lt;p&gt;它赋予企业的，是在 Agent 时代中「以静制动」的底气，也是在变革中持续进化的能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型长脑子了？研究发现LLM中层会自发模拟人脑进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 09:50:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b219daeb-2948-457a-9eb5-94ef85713a83/1768441601006.png" style="width: 700%;" class="fr-fic fr-dib"&gt;生物智能与人工智能的演化路径截然不同，但它们是否遵循某些共同的计算原理？&lt;/p&gt;&lt;p&gt;最近，来自帝国理工学院、华为诺亚方舟实验室等机构的研究人员发表了一篇新论文。该研究指出，大型语言模型（LLM）在学习过程中会自发演化出一种&lt;strong&gt;协同核心（Synergistic Core）&lt;/strong&gt;结构，有些类似于生物的大脑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaDEA4U9DcSVav4UW7TjxlMDPVHrqulibN7OMysqaKAwdlY4gyx13NltQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5138888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528163" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c18b58cd-4b2b-41e6-8e6d-b2de38e46668/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.06851&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYQ7ONWxVbgAo3t1P0569iaJorTz0GAU0KhicicFKo0dCbSw16uqXS2fUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.841995841995842" data-s="300,640" data-type="png" data-w="962" type="block" data-imgfileid="503528161" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a60aba40-7a5b-4c8a-b4b8-f8ee43d60ff5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队利用&lt;strong&gt;部分信息分解（Partial Information Decomposition, PID）&lt;/strong&gt;框架，对 Gemma、Llama、Qwen 和 DeepSeek 等模型进行了深度剖析。&lt;/p&gt;&lt;p&gt;他们发现，这些模型的中层表现出极强的协同处理能力，而底层和顶层则更偏向于冗余处理。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协同与冗余：LLM 的内部架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队将大型语言模型视为分布式信息处理系统，其核心实验设计旨在量化模型内部组件之间交互的本质。为了实现这一目标，研究者选取了 Gemma 3、Llama 3、Qwen 3 8B 以及 DeepSeek V2 Lite Chat 等多种具有代表性的模型系列进行对比分析。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验方法与量化指标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验过程中，研究者向模型输入了涵盖语法纠错、逻辑推理、常识问答等 6 个类别的认知任务提示词。&lt;/p&gt;&lt;p&gt;针对每一个提示词，模型会生成一段 100 个 Token 的回答，实验设备则同步记录下每一层中所有注意力头或专家模块的激活值。&lt;/p&gt;&lt;p&gt;具体而言，研究人员计算了这些输出向量的 L2 范数，以此作为该单元在特定时间步的激活强度数据。&lt;/p&gt;&lt;p&gt;基于这些时间序列数据，研究团队应用了&lt;strong&gt;整合信息分解（Integrated Information Decomposition, ID）&lt;/strong&gt;框架。&lt;/p&gt;&lt;p&gt;这一框架能够将注意力头对之间的交互分解为「持续性协同」和「持续性冗余」等不同原子项。&lt;/p&gt;&lt;p&gt;通过对所有注意力头对的协同值和冗余值进行排名并求差，研究者得到了一个关键指标：&lt;strong&gt;协同-冗余秩（Synergy-Redundancy Rank）&lt;/strong&gt;。该指标能够清晰地标示出模型组件在处理信息时，究竟是倾向于进行独立的信号聚合，还是在进行跨单元的深度集成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;跨模型的空间分布规律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验数据揭示了一个在不同架构模型中高度一致的空间组织规律。在归一化后的模型层深图中，协同分布呈现出显著的「倒 U 型」曲线 ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaTPhh9z3Alm9dSFwo6lYYRBAPddsHoOPqyPJFfCmYDibxd4G7iasJEbAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8357588357588358" data-s="300,640" data-type="png" data-w="962" type="block" data-imgfileid="503528162" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/10673250-d9c8-46d7-8ffd-c92ebb7dc50a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;冗余外周（Redundant Periphery）&lt;/strong&gt;：模型的早期层（靠近输入端）和末期层（靠近输出端）表现出极低的协同秩，信息处理以冗余模式为主。在早期层，这反映了模型在进行基本的解词元化（Detokenization）和局部特征提取；而在末期层，则对应着 Token 预测和输出格式化的过程。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;协同核心（Synergistic Core）&lt;/strong&gt;：模型的中层则展现出极高的协同秩，形成了核心处理区。例如，在对 Gemma 3 4B 的热图分析中，中间层的注意力头之间表现出密集且强烈的协同交互，这正是模型进行高级语义集成和抽象推理的区域。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;架构差异与一致性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，这种「协同核心」的涌现并不依赖于特定的技术实现。&lt;/p&gt;&lt;p&gt;在 DeepSeek V2 Lite 模型中，研究者即使是以「专家模块」而非「注意力头」作为分析单位，依然观察到了相同的空间分布特征。&lt;/p&gt;&lt;p&gt;这种跨架构的收敛性表明，&lt;strong&gt;协同处理可能是实现高级智能的一种计算必然&lt;/strong&gt;，而非单纯的工程巧合。&lt;/p&gt;&lt;p&gt;这种组织模式与人脑的生理结构形成了精确的映射：&lt;strong&gt;人脑的感官和运动区域同样表现出高冗余性，而负责复杂认知功能的联合皮层则处于高协同的「全局工作空间」中心。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能的涌现：学习驱动而非架构使然&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个关键的问题在于：这种结构是 Transformer 架构自带的，还是通过学习习得的？&lt;/p&gt;&lt;p&gt;研究人员通过分析 Pythia 1B 模型的训练过程发现，在随机初始化的网络中，这种「倒 U 型」的协同分布并不存在。随着训练步数的增加，这种组织架构才逐渐稳定形成。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaZO93YoRoCFrUysSX6dr975lEGm4ZBY9r3nDpKxeYokWNHMYRTHuibGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528164" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f6fe5bb0-ab9f-473d-9848-a274a9a812fe/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着，&lt;strong&gt;协同核心是大模型获得能力的标志性产物&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在拓扑性质上，协同核心具有极高的「全局效率」，有利于信息的快速集成；而冗余外周则表现出更强的「模块化」，适用于专门化处理。这种特征再次与人类大脑的网络架构形成了精确的平行关系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协同核心的功能验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证协同核心是否真的驱动了模型行为，研究团队进行了两类干预实验：消融实验和微调实验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;消融实验&lt;/strong&gt;：研究发现，消融那些高协同性的节点，会导致模型出现灾难性的性能下降和行为背离，其影响远超随机消融或消融冗余节点。这证明协同核心是模型智能的核心驱动力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaNVn394A9Tibic2UUF4Dsc3GULWFE2bJ9XfichATbjdeX6sEibOKso9uiaxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5768518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528165" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/01e62eda-ea60-4eef-811f-0d3eda786661/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;微调实验&lt;/strong&gt;：在强化学习微调（RL FT）场景下，仅针对协同核心进行训练，获得的性能提升显著优于针对冗余核心或随机子集的训练。有趣的是，在监督微调（SFT）中这种差异并不明显。研究者认为，这反映了 RL 促进通用化而 SFT 更多倾向于记忆的特性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsajfmJSoD0RbpSliaWiaUZQeqvrrgcia2FHmvjiaXg380QdqR4bX3QeCNicqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.674074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528166" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/72dc4178-af5b-42ba-a834-fa76d570b62a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项研究为大模型的可解释性开辟了新路径。它表明，我们可以从「自上而下」的信息论视角来理解模型，而不仅仅是「自下而上」地寻找特定的电路。&lt;/p&gt;&lt;p&gt;对于 AI 领域，识别协同核心有助于设计更高效的压缩算法，或者通过更有针对性的参数更新来加速训练。对于神经科学，这提供了一种计算上的验证，预示着协同回路在强化学习和知识迁移中可能扮演着至关重要的角色。&lt;/p&gt;&lt;p&gt;大模型虽然基于硅基芯片和反向传播算法，但在追求智能的过程中，它们似乎不约而同地走向了与生物大脑相似的组织模式。这种智能演化的趋同性，或许正是我们揭开通用智能奥秘的关键线索。&lt;/p&gt;&lt;p&gt;更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>性能提升60%，英特尔Ultra3这次带来了巨大提升</title>
      <description>&lt;![CDATA[Intel 18A 工艺来了。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Wed, 14 Jan 2026 16:33:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;上周，英特尔在 CES 2026 上正式发布了代号为 Panther Lake 的 Core Ultra Series 3 处理器，成为了本次展会的绝对主角。它终于让 PC 芯片摆脱了多年挤牙膏的困境，在 CPU、GPU 和 NPU 架构上均带来了显著的「代际」升级。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6f39a96a-2809-4c8e-91bb-2e03b5a1dc15/image__7_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这是首款基于英特尔自家 18A 工艺（等效 1.8 纳米级别）大规模量产的消费级芯片，桌面端和移动端版本同期推出。对英特尔来说，新制程与新芯片具有重大意义，标志着该公司重新引领芯片性能与方向的开始。&lt;/p&gt;&lt;p&gt;CES 之后，英特尔对下一代酷睿 Ultra 平台作了完整的技术概述。&lt;/p&gt;&lt;p&gt;在新一代 Panther Lake 产品上，能效核 Darkmont 与性能核 Cougar Cove，GPU（升级版 Xe3）都是新架构，引入了第五代 NPU 用于 AI 加速，缓存、图像处理单元都是新的，芯片整体采用了基于 chiplet 的封装，使用 Foveros-S 堆叠技术。&lt;/p&gt;&lt;p&gt;具体来说，每颗 Panther Lake 主要由三种小芯片组成：基于 Intel 18A 的计算芯片、基于 Intel 3 或台积电 N3E 工艺的图形芯片，以及基于台积电 N6E 的平台控制器芯片。每个配置都采用了 Foveros-S 封装，安装在同一个基板上，CPU、GPU、I/O 芯片会被集成到一个紧凑的 SoC 布局中。&lt;/p&gt;&lt;p&gt;英特尔表示，Panther Lake 会具备 Lunar Lake 的能效与 Arrow Lake 的性能，CPU 最多拥有 16 个核心，性能相比上代提升 60%（比之前宣称的 50% 又有提升），低功率情况下，单核性能较上一代提升 40%。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f8892235-e355-44a5-b018-7781dea64214/0bd098b364420f3591649e3d7592997d.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在 CPU 上，Panther Lake 集成了三种类型的核心，Cougar Cove P 核心在 Lion Cove 的基础上进行了改进，增加了 TLB 的容量，配备了更精确的多级分支预测器。每个 P 核心包含 3MB 的 L2 缓存和 256K 的 L1 缓存。Darkmont E 是上一代 Skymont 的升级版，支持 9 路解码，更大的乱序执行窗口和 26 个调度端口。&lt;/p&gt;&lt;p&gt;Panther Lake 还新增了一个四核低功耗集群，它基于 Darkmont 架构，直接位于计算单元上，用于处理后台或轻量级负载。&lt;/p&gt;&lt;p&gt;英特尔表示，重新设计的内存子系统支持 DDR5-7200 与 LPDDR5X-9600，相比前几代产品带宽和容量更高，计算单元可在核心集群上共享 18MB 的 L3 缓存，并连接到 8MB 的内存端缓存，从而减少 DRAM 流量和延迟。&lt;/p&gt;&lt;p&gt;GPU 方面，新一代芯片搭载了全新的 Xe3 架构核显，拥有最多 12 个 Xe 核心，官方宣称游戏性能相比上一代（Lunar Lake）提升高达 77%，同功耗水平性能提升 50%，其性能甚至超越了部分独立显卡（如部分 RTX 4050 移动版）。当然，这一代核显的性能相较 AMD 的同档产品也有巨大的优势。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4ac70684-fa6c-4f23-b65c-1326c49cfa9f/32802905bd061663d7b9a28bfd85de03.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;可见在魔兽世界、群星等游戏上，以后我们基本可以用集显玩了。我们甚至可以展望 Ultra 3 发布会，会有搭载集显的全能笔记本出现。&lt;/p&gt;&lt;p&gt;12 核心的 Xe3 版本使用台积电 N3E 工艺打造，提升了 L1、L2 缓存容量，改进了各向异性过滤和模板渲染速率，并配备了增强型光线追踪单元和动态光线管理功能。&lt;/p&gt;&lt;p&gt;Panther Lake 还首次搭载了 XeSS 3 多帧生成技术，可以通过生成多个插帧的方法实现更加流畅的游戏体验。英特尔计划在其图形软件中增加帧生成覆盖控制功能，从而让用户可以强制指定特定的帧生成模式。&lt;/p&gt;&lt;p&gt;在 AI 计算方面，Panther Lake 采用了更加均衡的 XPU 设计，可实现更高水平的 AI 计算加速，总平台算力超过了 180TOPS。其中 NPU 算力提升至 50 TOPS，支持 FP8、INT8 等量化格式，MAC 吞吐量翻倍，功耗降低 40% 以上。&lt;/p&gt;&lt;p&gt;利用新的线程管理器，Panther Lake 能够适应不断变化的工作负载，在游戏时提升约 10% 的帧率。通过优化 Windows 电源模式，新的芯片在相同的功耗限制下可以把性能提升大约 20%。&lt;/p&gt;&lt;p&gt;Panther Lake CPU 预计将提供八核心 + 两个十六核心的版本，命名为英特尔酷睿 Ultra 处理器第三代（3xx）。另外在连接方面，这一代芯片支持最多 20 条 PCIe 通道，集成雷电 4；无线连接方面则支持 Wi-Fi 7 Revison 2 和蓝牙 6.0Core。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fe0d6dd0-ce58-40ed-bc0f-3b4de9d5463d/image__8_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;除了个人电脑领域之外，Panther Lake 的应用范围还扩展到了包括机器人在内的边缘应用领域。英特尔提供了 AI 软件套件与参考板卡，能够帮助复杂 AI 应用的客户快速上手，利用新一代 AI 芯片实现控制和 AI 感知，并快速开发机器人。&lt;/p&gt;&lt;p&gt;英特尔表示，得益于 18A 工艺，Panther Lake 芯片的能效比进一步优化，官方宣称部分机型续航可达 27 小时。再加上性能的提升，新一代芯片在轻薄笔记本和游戏本上都会带来更好的体验。&lt;/p&gt;&lt;p&gt;预计搭载 Panther Lake 的笔记本电脑在今年 1 月就会大批量上市。&lt;/p&gt;&lt;p&gt;英特尔还预告了 30W 功率掌机版本的 Panther Lake 的信息，不过更多信息有待公布。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8255694f-7971-44f0-919c-b7c4137e0cae/image__9_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;随着 Ultra 第三代产品的推出，AI PC 距离实用化更近了一步。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>继宇树后，唯一获得三家大厂押注的自变量：具身模型不是把DeepSeek塞进机器人</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:45:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/169694b5-8cac-4291-8aa4-aae419d72237/1768373003246.png" style="width: 700%;" class="fr-fic fr-dib"&gt;国内具身智能，接下来可能是「大脑」的战场了。&lt;/p&gt;&lt;p&gt;2026 开年，&lt;strong&gt;自变量机器人传出融资消息，字节、红杉出手，融资额达到 10 亿。&lt;/strong&gt;虽然自变量是一家软硬一体的公司，但这场融资背后，真正说服投资人的可能是他们对于机器人「大脑」的思考。&lt;/p&gt;&lt;p&gt;和之前的 locomotion（移动）、navigation（导航）战场不同，&lt;strong&gt;「大脑」所主导的 manipulation（操作）涉及频繁的物理世界交互，随机性、不确定性充斥着每一个看似简单的任务&lt;/strong&gt;。这也是为什么，在我们看了多年的机器人跳舞、跑酷、玩杂技之后，机器人在自主操作上依然没有拿出一个技惊四座的 demo。而这个「自主操作」，才是决定机器人能否大规模走入人类世界的关键。&lt;/p&gt;&lt;p&gt;在自变量看来，「操作」这类任务的复杂性决定了，机器人必须有一个由「物理世界基础模型」所支撑的「大脑」。这个「大脑」不是像很多人想的「把 DeepSeek 塞进宇树」那么简单，它不是 AI 模型的「应用层」，而是独立、平行于语言大模型、多模态模型等虚拟世界模型的新范式。&lt;/p&gt;&lt;p&gt;对于这个新范式应该是什么样子、如何去打造，自变量已经有了一套体系化的方法论，并且自研出了一些成果。这些大胆的尝试，或许会为具身智能领域带来新的变量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;具身智能 &amp;ne; AI 模型下游应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们知道，最近几年机器人「大脑」的进化主要还是依赖语言模型和多模态模型。于是很多人就认为，具身智能是 AI 模型的一个应用方向。但自变量 CEO 王潜曾在多个场合强调，这个定位存在偏差。&lt;/p&gt;&lt;p&gt;举例来说，图中有两个矿泉水瓶，一个瓶盖拧紧，一个没有完全拧紧。只靠视觉去看，它们在图像里差别很小，但一旦把它们拿起来、翻转或倾倒，结果却完全不同 &amp;mdash;&amp;mdash; 一个会漏水，一个不会。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicoUZK5tD2uzpKljicRrS1td1mupIF4No3N72L7vKoib51BuUbtDBktT1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528184" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/0969c240-aa4d-4d28-b79c-025910ff56b8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;物理世界里真正关键的信息，往往就藏在这些「看不出来但会影响行为」的细节中。&lt;/strong&gt;这些差异只有在与世界发生真实交互时才会暴露出来，而不是静态观察就能轻易判断。&lt;/p&gt;&lt;p&gt;更重要的是，这类信息往往并不会在当下立刻给出反馈。比如拧瓶盖这个动作本身，并不会产生任何可见变化，真正的差异要等到下一步、甚至再下一步操作时才显现出来。对模型来说，这意味着它必须能够把一连串感知、动作和结果在时间上串联起来理解，而不是只处理某一帧画面、某一个瞬间的输入输出。&lt;/p&gt;&lt;p&gt;这正是物理世界对智能提出的一个隐性要求：&lt;strong&gt;模型不仅要能感知，还要能处理足够长的行为序列，理解因果是如何在时间中逐步展开的。&lt;/strong&gt;否则，它就永远学不会那些「现在看不出来、但之后会出问题」的物理规律。&lt;/p&gt;&lt;p&gt;而在很多真实任务中，问题甚至不只是时间跨度变长这么简单。机器人往往需要在行动之前，对未来进行某种形式的推演。比如在倒水之前，它需要判断瓶子会不会漏；在整理桌面之前，它需要决定先拿走什么、再放回什么。这类判断并不是对当前状态的直接反应，而是对「接下来会发生什么」的内部演算。&lt;/p&gt;&lt;p&gt;也正因为如此，单纯依赖静态信息训练出的语言模型或多模态模型，在物理世界里往往显得力不从心。它们并不真正理解「拧紧」和「没拧紧」在物理后果上的差别，也难以应对充满连续变化、随机扰动和部分不可观测的现实环境。&lt;/p&gt;&lt;p&gt;在自变量看来，这并不是靠给现有模型打补丁就能解决的问题，而是指向了一个更底层的结论：&lt;strong&gt;我们需要一种「生于物理世界、用于物理世界」的基础模型。这种模型应当与语言模型、多模态模型平行存在，而不是作为它们的下游应用。&lt;/strong&gt;自变量的目标，正是要打造这样一个基础模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建物理世界基础模型&amp;mdash;&amp;mdash;要端到端、要做通才模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要打造这个模型，自变量认为有两点非常重要：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一是要有一个统一的架构，因为真正的物理智能需要的是整体性的、具身的理解，而不是模块化的知识拼接。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;举个例子，人类在使用锤子时，注意力不在「这是一个锤子」「锤子有多重」，而是在木头、钉子和要完成的目标上。锤子作为一种工具，会被纳入行动本身，在认知中「隐退」。但对于现在很多机器人来说，情况恰恰相反，每一次使用工具，它们都要重新经历一整套流程：看见这是锤子，理解锤子的用途，规划怎么用，再执行动作。自变量认为，这种方式永远无法达到人类那种直觉的工具使用境界。&lt;/p&gt;&lt;p&gt;归根结底，这种局面是把模型拼接起来的分层架构所带来的 &amp;mdash;&amp;mdash; 视觉模块先把世界压缩成向量，语言模块再接手理解，规划模块再根据语言输出动作。一套流程下来，模块之间彼此「看不见」「听不见」对方真正关心的东西。每跨一次模块，细节、关联和物理直觉都会被削掉一层。这就像把一幅油画描述给盲人，再让盲人转述给聋人。&lt;/p&gt;&lt;p&gt;这就不难解释，为什么自变量从成立第一天就是「端到端」路线的坚定信徒。他们看到的是这一路线的底层逻辑：信息必须在一个统一的空间里流动，系统才能发现不同东西之间深层的关联。早期，这一选择饱受质疑，但如今，Google Robotics、Physical Intelligence 等头部具身智能团队也都走到了这条路上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二是模型要足够通用，因为只有这样才能学到物理世界的共性结构。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这条路已经被语言模型走过一遍。大家发现，相比于最初针对单一任务分别做专用模型，把翻译、问答、写作、推理等任务放进同一个模型里，反而能让模型学到更底层的逻辑和常识。物理世界也是一样，当模型同时学习足够多、足够杂的任务，它会被迫去发现这些任务背后的共性结构 &amp;mdash;&amp;mdash; 物理规律、物体属性、因果关系。一旦掌握了这些共性，模型学新任务所需的数据量就会骤降，甚至出现「涌现」。&lt;/p&gt;&lt;p&gt;提到语言模型，它的成功其实还有一个常被忽视的关键：它找到了一个极好的损失函数 &amp;mdash;&amp;mdash; 预测下一个词。这个看似简单的目标，能够把海量文本中的结构、逻辑、常识全部压缩进模型里。&lt;/p&gt;&lt;p&gt;但机器人面对的是一个更复杂的局面，&lt;strong&gt;它的损失函数应该预测什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;自变量认为，不能只停留在「预测动作」。如果只预测动作，模型很容易沦为一个「模仿者」，它只学会了手势的形状，却不懂得背后的原因。真正的突破口在于：将损失函数从「动作预测」升级为「多模态状态的预测」。&lt;/p&gt;&lt;p&gt;当模型试图预测「如果我推倒这个杯子，下一秒视觉画面会如何变化、指尖的触感会如何消失」时，它实际上是在强迫自己理解因果律，把物理世界的复杂性压缩进模型里。&lt;/p&gt;&lt;p&gt;这也解释了为什么自变量的 WALL-A 模型不只输出动作。它还能用语言和人对话，能根据图片重建三维环境，能像世界模型一样预测未来。这些能力看似五花八门，但背后的逻辑是一致的：如果一个模型真正理解了物理世界，它就应该能用各种方式表达这种理解，无论是控制机械臂，还是描述它在做什么，还是预测物体会怎么滚动。在这个模型身上，我们已经能够看到自变量所追求的物理世界基础模型的雏形。&lt;a href="https://mp.weixin.qq.com/s/22w4L3Edq0rkp8A-MV-wHg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4691a136-e40b-4b35-bc70-0e6d574f0178/1768373097434.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;以外卖即时配送任务为例，自变量的机器人在完全开放的室外及室内环境中执行移动操作任务，应对人流、环境变化、突发干扰等不确定因素，从外卖柜取箱、拆箱、回收、室内导航、电梯交互到最终交付，机器人基于统一的端到端具身智能模型完成超长序列操作，体现了自变量的具身智能模型具备极强的泛化能力，标志着具身智能首次具备在真实商业场景中稳定运行的能力。该场景首次让VLA模型在高频、强约束、强时效的真实环境中长期运行，完成从实验室验证到商业级部署的关键跨越。&lt;/section&gt;&lt;p&gt;&lt;strong&gt;开源有得选 &amp;nbsp;但依然要坚持「自研」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除了对于「机器人大脑」这个问题的独特思考，自变量这家公司在业内其实还有一个非常罕见的特质：坚持自研，尤其是基础模型的自研。&lt;/p&gt;&lt;p&gt;在很多公司看来，这点可能暂时还没有那么必要或者说「紧迫」，毕竟 Physical Intelligence 开源的 Pi0 和 Pi0.5、英伟达开源的 GRoot 等都是不错的选择，也是很多具身智能厂商的主流选择。&lt;/p&gt;&lt;p&gt;但自变量对「自研」的坚持，更多来自一个底层判断：具身智能的下一阶段竞争，本质上还是数据闭环构建的基础模型与模型进化能力的竞争。模型不掌握在自己手里，竞争无从谈起。&lt;/p&gt;&lt;p&gt;一路目睹语言模型演进的从业者应该对此有着深刻的感受 &amp;mdash;&amp;mdash; 这个行业最大的变量，往往藏在基础模型的内核里。过去两年，Cursor 等应用层产品风头无两，但它们的「智能」几乎完全依赖 Claude 或 GPT 的能力边界。上游模型一次升级，下游应用被动重构；API 定价一旦调整，成本结构随之改变。&lt;/p&gt;&lt;p&gt;对于机器人而言，这个问题还要更深一层：真实物理世界的重量、阻力、空间关系，无法从互联网文本中习得，必须从数据采集到模型架构建立一套完整的自研体系。选择在基础层投入，看似是一条更慢的路，但历史反复证明：&lt;strong&gt;原始创新者定义规则，跟随者只能适应规则。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，自变量共有两款核心模型：主模型 WALL-A 和轻量化模型 WALL-OSS，均为自研成果。这个系列模型的核心架构首创了 VLA 与世界模型深度融合的系统范式，而且率先实现了具身多模态思维链。&lt;/p&gt;&lt;p&gt;值得注意的是，自变量还将 WALL-OSS 开源了出来，并围绕&amp;nbsp;WALL-OSS 等全球具身开源项目组织了一个名为「&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzkzOTc1NjE3Nw==&amp;mid=2247484684&amp;idx=1&amp;sn=319ed37b206dc726e20604c44b029a59&amp;scene=21&amp;click_id=52#wechat_redirect" target="_blank"&gt;具亮计划&lt;/a&gt;」的黑客松。该计划鼓励开发者利用具身基础开源模型，从数据采集、策略训练到真机部署跑通完整链路，最终让机器人在真实场景里动手完成任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicO5cf2dNtjwtcPicFptXA7KSyLgJmPQSekBBhqXF5m5UcXM2YEhs1wuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4083333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528272" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6d1054a7-fae4-477d-a76d-4e7cdc380dba/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在国内，这种活动也是非常有益的尝试，因为从语言模型发展来看，整个技术社区的发展离不开开源文化，具身智能领域也需要自己的 DeepSeek。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重走婴儿的路 &amp;nbsp;物理世界没有捷径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;看到语言模型的蓬勃发展，很多人可能都会思考一个问题，为什么机器人迟迟等不来它们的涌现时刻？&lt;/p&gt;&lt;p&gt;一个可能的答案是：语言本身就是一种高度压缩的符号系统，人类已经用几千年的时间把世界的复杂性「预处理」成了文字。模型要做的，只是学会这套现成的编码规则。但物理世界没有这样的捷径。重力、摩擦、碰撞、形变，这些规律从未被谁显式地写下来，它们散落在每一次交互的细节里。&lt;/p&gt;&lt;p&gt;这也意味着，物理世界基础模型的构建，某种程度上是在重走人类婴儿的路。物理世界基础模型要学的，是那些人类「做得出但说不清」的东西，这可能才是智能更本源的形态。&lt;/p&gt;&lt;p&gt;这条路注定漫长，也足够迷人。而自变量正走在这条路上。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Sebastian Raschka 2026预测：Transformer统治依旧，但扩散模型正悄然崛起</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:41:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="2" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/79d32e9f-5d40-430d-9bc0-ccba6a68bdc2/1768372696097.png" style="width: 700%;" class="fr-fic fr-dib"&gt;站在 2026 年的开端回望，LLM 的架构之争似乎进入了一个新的微妙阶段。过去几年，Transformer 架构以绝对的统治力横扫了人工智能领域，但随着算力成本的博弈和对推理效率的极致追求，挑战者们从未停止过脚步。&lt;/p&gt;&lt;p data-path-to-node="3"&gt;知名 AI 研究员 Sebastian Raschka 的最新洞察中，他不仅回应了关于「Transformer 是否会被取代」的年度终极之问，更敏锐地捕捉到了近期业界的一个重要转向：从单纯追求模型参数的「大力出奇迹」，转向了混合架构与效率微调的精细化战争。&lt;/p&gt;&lt;p data-path-to-node="4"&gt;同时，文章还探讨了一个极具潜力的变量：扩散语言模型。这类模型在 Google 等巨头的布局下会有怎样的表现？它们在「工具调用」上的天然缺陷是否会成为阿喀琉斯之踵？而在高质量数据日益枯竭的今天，扩散模型又是否能凭借「超级数据学习者」的特性，成为打破数据墙的关键？&lt;/p&gt;&lt;p data-path-to-node="5"&gt;以下内容编译自 Sebastian Raschka 的最新博文，并结合文中提及的前沿论文及往期深度分析进行了系统性拓展，以便读者获取更完整的上下文视角。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="953" data-imgfileid="503527971" data-ratio="0.4" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkABcAaiaj7tMDQEx3dM7KF4Jrw0mFgSpRaT6lfyDicxWYtOGCN5Bh7DK4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="2382" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/29f304a9-fc0f-4360-8fab-0d3b641f93a9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="6"&gt;博客地址：https://x.com/rasbt/status/2010376305720594810&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="8"&gt;最近几周，我经常被问到的一个问题是：&lt;strong&gt;在 2026 年，我们是否会看到自回归 Transformer 架构（即标准的 LLM）的替代方案。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;就目前而言，我坚信 &lt;strong&gt;Transformer 在未来（至少一到几年内）仍将保持其在 SOTA 性能方面的地位。&lt;/strong&gt;它是当前 AI 生态系统的基石，拥有最成熟的工具链和优化方案。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;但是，情况确实会发生一些微调。这并不是说架构会一成不变，而是这种变化更多体现在「效率」和「混合」上，而非彻底的推倒重来。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;效率战争：混合架构与线性注意力的崛起&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;临近去年年底，我们看到业界更加关注&lt;strong&gt;混合架构&lt;/strong&gt;以及如何提高其效率。当然，这并不是什么新想法，但近期来自顶尖实验室的发布表明，目前的侧重点已明显向此倾斜。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;我们回顾一下 DeepSeek V3 以及随后的 R1，它们展示了&lt;strong&gt;混合专家模型（MoE）和多头潜在注意力（MLA）&lt;/strong&gt;的强大之处。DeepSeek V3 通过 MLA 显著减少了推理时的 KV Cache 占用，而 MoE 架构则允许模型在拥有 6710 亿参数的同时，每次推理仅激活 370 亿参数。这种在保持模型巨大容量的同时极致压缩推理成本的设计思路，正是 2025 年末到 2026 年的主旋律。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;但这还不是全部。除了 MoE，我们看到了更激进的效率尝试，例如&lt;strong&gt;&amp;nbsp;Qwen3-Next、Kimi Linear、Nvidia Nemotron 3&lt;/strong&gt;，以及采用了稀疏注意力机制的 DeepSeek V3.2。（如果您对更多细节感兴趣，我在之前的《Big LLM Architecture Comparison》一文中对此进行了报道。）&lt;img data-aistatus="1" data-height="1530" data-imgfileid="503527972" data-ratio="0.6222222222222222" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA7oZuANMs0u5wsmYEwKXUzWj441D8szMn1tI5Hv79Og9eD2fia7O1ibxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="2460" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a2c82762-e812-4600-8f43-5e78767de977/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 带有这类效率调整的 Transformer 架构示意图。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;相关链接：https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="16"&gt;&lt;b data-index-in-node="0" data-path-to-node="16"&gt;为什么大家都在卷「线性注意力」或「稀疏注意力」？&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;标准的 Transformer 注意力机制（Scaled Dot-Product Attention）具有 O(N^2) 的复杂度，这意味着随着上下文长度的增加，计算成本呈二次方爆炸式增长。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="18,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,0,0"&gt;Qwen3-Next&lt;/b&gt; 和 &lt;b data-index-in-node="13" data-path-to-node="18,0,0"&gt;Kimi Linear&lt;/b&gt; 采用了一种混合策略：它们并非完全抛弃标准注意力，而是将高效的线性层（如 Gated DeltaNet）与全注意力层以一定比例（如 3:1）混合。这种设计试图在捕捉长距离依赖（全注意力的强项）和推理速度（线性层的强项）之间找到最佳平衡点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="18,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,1,0"&gt;DeepSeek V3.2&lt;/b&gt; 则引入了稀疏注意力，通过只计算最重要的 Token 之间的相互作用，进一步降低了计算开销。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19"&gt;这些「微调」表明，2026 年的竞争不再仅仅是看谁的模型更聪明，而是看谁能在更长的上下文、更低的延迟下提供同等的智能。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;strong&gt;扩散语言模型：速度与代价的博弈&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;话说回来，除了 Transformer 的变体，&lt;strong&gt;扩散语言模型&lt;/strong&gt;怎么样？&lt;/p&gt;&lt;p data-path-to-node="22"&gt;扩散语言模型之所以具有吸引力，是因为它们能够以相对快速且低廉的成本生成 Token。与自回归模型（AR）那种「一个字接一个字」的串行生成不同，&lt;strong&gt;扩散模型采用的是并行生成&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="23"&gt;想象一下，自回归模型像是一个人在打字，必须打完上一个字才能打下一个；而扩散模型更像是在冲洗一张照片，整段文字从模糊的噪声中同时显现，经过数次「去噪」迭代后变得清晰。&lt;/p&gt;&lt;p data-path-to-node="24"&gt;我前阵子在《Beyond Standard LLMs》一文中对此多写了一些。简而言之，我认为 2026 年我们会看到更多相关内容，Google 可能会推出 &lt;strong&gt;Gemini Diffusion&lt;/strong&gt; 作为其更便宜的 Flash 模型的替代品。Google 已经在其技术博客中暗示了这一点，强调其生成速度「明显快于我们目前最快的模型」。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24"&gt;相关链接：https://magazine.sebastianraschka.com/p/beyond-standard-llms&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;然而，虽然扩散语言模型的优势在于它们可以并行生成 Token，但这同时也是一个巨大的缺点。因为由于并行生成的特性，&lt;strong&gt;它们无法在响应链中原生地整合工具调用&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;在自回归模型中，模型可以生成「调用计算器」的指令，暂停，等待结果，然后再继续生成。而在扩散模型中，整个响应是同时生成的，很难在中间插入一个外部工具的交互步骤。这使得它们在作为智能体使用时面临巨大挑战。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527973" data-ratio="0.5625" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuulUiadnlby61pcX7bDQBmb6pENqfFF0ibzaGCRNFa8fQB6yTnUCX2Tw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7326952b-8424-4118-9941-74e762097b73/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27,0"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 文本扩散过程示例。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;此外，虽然众所周知文本扩散推理效率更高，但最近的研究也表明，如果你为了提升质量而增加去噪步数以匹配自回归模型的性能，那么最终的计算预算其实是相差无几的。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;&lt;strong&gt;数据枯竭时代的「超级学习者」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="30"&gt;那么，我想表达什么呢？既然扩散模型有这些缺陷，为什么我还认为它值得关注？&lt;/p&gt;&lt;p data-path-to-node="31"&gt;我原本计划讨论一月份发布的近期一系列有趣的研究，但我还是想简要重点介绍一篇我在「待读论文」清单上的、2025 年 11 月的有趣论文，它强调了扩散语言模型的一个有趣优势：《Diffusion Language Models are Super Data Learners》。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2511.03276&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1760" data-imgfileid="503527974" data-ratio="1.049074074074074" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAwXOt5dibyF6Lx8pia0JTDF4hAQj1kWnYic5p9w2LkUPTlO688RRLYzE8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" data-width="1678" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f51d529a-149b-4dba-9da1-16643d5e78e8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;来自论文《Diffusion Language Models are Super Data Learners》的带注释图表。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;这篇论文提出了一个在 2026 年至关重要的观点：&lt;b data-index-in-node="25" data-path-to-node="33"&gt;当高质量数据变得稀缺时，扩散模型可能是更好的学习者。&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;众所周知，互联网上的高质量文本数据正在接近枯竭。对于自回归（AR）模型来说，通常我们只让模型把数据「看」一遍（1 Epoch）。如果让 AR 模型反复在同一份数据上训练，它们很容易&lt;strong&gt;过拟合&lt;/strong&gt;，即死记硬背训练数据，导致在未见过的新任务上表现下降。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;然而，上述论文表明，当进行多 Epoch 训练时，文本扩散模型的表现可能优于标准的自回归（AR）大语言模型。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;根据论文的研究结果，在严格控制的预训练设置下，当唯一数据量有限时，通过增加训练轮数，扩散语言模型的表现持续超越了自回归模型。&lt;/p&gt;&lt;p data-path-to-node="37"&gt;这一现象被称为「Crossover（交叉点）」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="38,0,0"&gt;当数据量充足时，AR 模型学得更快。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="38,1,0"&gt;但当数据受限时，DLM 是最终的赢家。例如，一个 10 亿参数的 DLM 模型，仅仅通过反复训练 10 亿个 Token（这在今天看是非常小的数据量），在 HellaSwag 和 MMLU 基准测试上分别达到了 &amp;gt;56% 和 &amp;gt;33% 的准确率，且没有使用任何特殊技巧。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="39"&gt;为什么会这样？ 论文归结为三个因素：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="40,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,0,0"&gt;任意顺序建模&lt;/b&gt;：AR 模型被迫只能从左到右学习，而扩散模型可以学习文本中任意位置之间的依赖关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,1,0"&gt;超高密度计算&lt;/b&gt;：通过迭代的双向去噪，DLM 在训练时实际上对每个样本进行了更深度的压榨。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,2,0"&gt;内置的蒙特卡洛增强&lt;/b&gt;：扩散过程本身就是一种数据增强。同一个句子，每次加噪的方式都不一样，相当于把一条数据变成了无数条变体。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="41"&gt;更有趣的是，论文发现，对于 DLM 来说，&lt;strong&gt;验证集损失的上升并不意味着下游能力的下降&lt;/strong&gt;。即便模型在验证集上看起来「过拟合」了，它在实际任务（如代码生成、推理）上的表现仍在提升。&lt;/p&gt;&lt;p data-path-to-node="42"&gt;由于成本原因，过去没有人会在多个 Epoch 上训练大语言模型。但在数据枯竭的今天，如果我们不得不进行多 Epoch 训练，扩散模型似乎提供了一条新出路。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;这确实是有趣的结果！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
