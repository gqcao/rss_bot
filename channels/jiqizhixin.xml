<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>面向临床的心电图AI，上智院、复旦等提出CLEAR-HUG框架实现诊断性能与可解释性双突破</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 16 Jan 2026 14:04:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwky9JXa63Km3fpBgbQIDE2c8r18iazKcU9TnVp6MCzD8HKYMULrqrMcw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.55" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="318" data-imgfileid="100027171" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/9ca6db6f-e88e-41d4-9bb7-17127975abe0/640.png" data-sec-load-status="2" data-report-img-idx="0" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;作者团队丨上海科学智能研究院、复旦大学团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;在心血管疾病诊断中，心电图（Electrocardiogram, ECG）是无可替代的基础工具，其中 12 导联心电图是临床使用的金标准。作为观察心脏电活动的&amp;ldquo;视角&amp;rdquo;，导联是由一正一负两个电极构成的一个记录电路，12 导联心电图即是通过体表 10 个电极组合构建出 12 个独特的电信号&amp;ldquo;视角&amp;rdquo;，同步捕捉心脏的电活动，形成一套多维度的波形图谱。&lt;/p&gt;&lt;p&gt;然而，面对海量的心电图数据，现有基于自监督学习的分析方法尽管提供了无需大规模标注数据的解决方案，其局限仍非常明显：它们往往未能充分建模心脏传导过程中细微的个体心搏差异，也缺乏与临床&amp;ldquo;从心搏到导联，再从导联到整体&amp;rdquo;的递进诊断逻辑相对齐的推理结构，导致在复杂病例诊断中表现受限。&lt;/p&gt;&lt;p&gt;为此，上海科学智能研究院（下称上智院）与复旦大学联合提出了&amp;nbsp;CLEAR-HUG&amp;nbsp;双阶段框架。该框架从心电图信号的生理本质出发，在预训练阶段显式建模心脏传导特征，并在诊断阶段紧密贴合临床判读的层级思维，实现了从信号表征到诊断推理的全流程优化。实验表明，该方法在六个权威公开数据集上平均性能提升达 6.84%，为开发高性能、可解释的 AI 辅助心电图诊断工具开辟了新路径。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwbq3I3xMYn2EEdMvYDHosYd9icVCcwicvRTNoTm5Unqmibh3tTIftjcibBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3507246376811594" data-s="300,640" data-type="png" data-w="690" type="block" data-imgfileid="100027166" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ca340fbd-0641-4440-92d0-a210c54acfbb/640.png" alt="图片" data-before-load-time="1768543434374" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.24002&lt;/p&gt;&lt;p&gt;该研究成果已被 AAAI 2026 接收。研究项目由星河启智科学智能开放平台和复旦大学 CFFF 智算平台提供技术和算力支持。&lt;/p&gt;&lt;p&gt;星河启智平台链接：https://aistudio.ai4s.com.cn&lt;/p&gt;&lt;p&gt;&lt;strong&gt;现有方法的两大局限&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既往的心电图自监督学习（electrocardiogram self-supervised learning, eSSL）方法虽取得一定进展，但存在两个面向临床的关键短板：&lt;/p&gt;&lt;p&gt;一是忽视个体差异。&lt;/p&gt;&lt;p&gt;现有方法学会了看&amp;ldquo;大概&amp;rdquo;和&amp;ldquo;通常&amp;rdquo;，却难以识别那些&amp;ldquo;例外&amp;rdquo;与&amp;ldquo;异常&amp;rdquo;，而后者往往是临床诊断中更需要关注的信号。具体来说，现有方法主要让模型学习心电图信号中重复出现和普遍存在的模式&amp;mdash;&amp;mdash;比如不同导联之间波形的同步性，或连续心搏间的形态相似性，却忽略了一个生理事实：每个心搏的传导路径存在自然的细微差异，而不同导联观察的解剖角度也本就不同。这些细节往往承载着重要的生理与病理信息，例如，一个偶发的、形态异常的室性早搏，在标准心电图中看起来就&amp;ldquo;很不合群&amp;rdquo;，但这恰恰是临床诊断需要捕捉的关键线索。&lt;/p&gt;&lt;p&gt;二是脱离临床逻辑。&lt;/p&gt;&lt;p&gt;为确保诊断的精确性和全面性，心电图临床诊断通常遵循&amp;ldquo;心搏&amp;rarr;单导联&amp;rarr;多导联组合&amp;rdquo;的层级流程：医生首先观察单个心搏的形态细节，判断其是否异常；然后在一个特定的导联上，分析连续心搏的节律和模式，确认异常是否持续存在；最后，综合所有 12 个导联的信息，像拼图一样将不同导联的发现进行组合与空间对应，从而精确定位心脏的病变部位并做出最终诊断。但是，现有模型在下游任务中常忽视这一递进式诊断逻辑，导致特征提取与诊断需求脱节。&lt;/p&gt;&lt;p&gt;为解决这些问题，研究团队从心脏传导机制和临床诊断规范双重视角出发，构建了 CLEAR-HUG 框架，实现从信号表征到诊断推理的全流程优化。该框架与人类专家的知识体系对齐，使得医生不仅能够获知&amp;ldquo;诊断结果是什么&amp;rdquo;，更能理解&amp;ldquo;模型为何做出该诊断&amp;rdquo;，从而推动心电图AI分析更加可解释。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwRicPy0zOAOoPf4CDVQVceOgMqK7tUwnuGnHyWsZZnXXH3bwicgqdQClw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3898550724637681" data-s="300,640" data-type="png" data-w="690" type="block" data-imgfileid="100027167" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5524a1bb-927d-44a8-91d3-ab922c221416/640.png" alt="图片" data-before-load-time="1768543434426" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：心脏传导机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLEAR-HUG 的双阶段创新设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CLEAR-HUG 框架包含预训练和微调两个阶段，分别对应特征学习与诊断适配，形成完整的技术闭环。&lt;/p&gt;&lt;p&gt;第一阶段，团队设计了名为&amp;ldquo;传导-导联重构器&amp;rdquo;（Conduction-LEAd&amp;nbsp;Reconstructor, CLEAR）的自监督模型，该模型能同时捕捉心跳的特异性变异与普遍共性。通过将每个心搏视为独特实体，该模型采用简洁高效的稀疏注意力机制，在排除其他心搏干扰的情况下重构信号。&lt;/p&gt;&lt;p&gt;第二阶段，团队构建了&amp;ldquo;分层导联统一分组头&amp;rdquo;（Hierarchical lead-Unified&amp;nbsp;Group head,&amp;nbsp;HUG头）诊断模块，模拟临床诊断流程。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwNf0uia802TYFBZlyoQdFCCrSt4KfiaZO3vCzGJwjpKBTsibcqmpxGunlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4608695652173913" data-s="300,640" data-type="png" data-w="690" type="block" data-imgfileid="100027168" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ca8a9df8-69dc-42ec-be49-7980b6057463/640.png" alt="图片" data-before-load-time="1768543434443" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：双阶段训练&lt;/p&gt;&lt;p&gt;1.CLEAR 预训练，捕捉传导级细微特征&lt;/p&gt;&lt;p&gt;预训练阶段的核心是 CLEAR 模型，通过传导引导和视角引导的双重信息学习，精准重建心电图信号：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;双重视角建模：将心电图信号分解为传导引导信息（同一心搏在各导联的时间同步特征）和视角引导信息（同一导联的空间异质性特征），全面捕捉信号本质。&lt;/li&gt;&lt;li&gt;稀疏注意力机制：设计专属注意力掩码，确保心搏重建仅依赖对应的心搏传导信息和导联全局上下文，避免其他心搏干扰，高效提取特异性特征。&lt;/li&gt;&lt;li&gt;掩码重建训练：采用 80% 的高掩码率，通过重建被掩盖的心搏 token，迫使模型学习深层生理特征而非表面模式，提升表征鲁棒性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2.HUG 微调 ，模拟临床诊断流程&lt;/p&gt;&lt;p&gt;微调阶段引入 HUG 头，完全贴合临床心电图诊断的层级逻辑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;导联分组：按临床标准将 12 导联分为 3 组（双极肢体导联、加压单极肢体导联、胸前导联），每组通过独立线性层学习特征并平均。&lt;/li&gt;&lt;li&gt;成对组合：将三组特征进行两两组合，进一步捕捉导联间的互补信息。&lt;/li&gt;&lt;li&gt;全局聚合：整合所有组合特征，形成完整的多导联全局表征，作为最终诊断依据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种层级设计不仅提升了模型的可解释性，更让特征提取过程与医生诊断思维高度一致，实现从数据驱动到临床驱动的转变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在六大数据集上超越现有最优方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本研究在 MIMIC-IV-ECG 数据集上完成预训练后，于 PTB-XL、CPSC2018 及 CSN 三个公开数据集的六个下游任务上进行了系统评估，结果全面超越了现有最优方法（SOTA）。&lt;/p&gt;&lt;p&gt;具体而言，模型在平均性能上较当前 SOTA 提升了 6.84%，其中 CLEAR 单模型在预训练阶段贡献了 3.94% 的提升，而加入 HUG 诊断头后性能得到进一步改善，充分验证了双阶段设计的有效性。在低数据场景下，该方法展现出卓越的少样本迁移能力，例如，在仅使用 1% 训练数据的 PTBXL-Rhythm 任务中，CLEAR-HUG 较 SOTA 提升超 17%。&lt;/p&gt;&lt;p&gt;同时，在细粒度疾病分类任务上，层级分组策略的价值尤为凸显&amp;mdash;&amp;mdash;在 CSN 数据集的 38 类疾病分类中，使用 1%、10% 与 100% 训练数据时，HUG 头相较基础模型分别带来 9.21%、5.81% 与 3.18% 的性能增益。&lt;/p&gt;&lt;p&gt;此外，该方法在关键特性上也表现出显著优势。其一，模型具有更强的稳健性，即使在部分导联缺失、仅保留两个核心导联的极端情况下，其性能仍优于现有 SOTA，能够很好地适应临床中数据不完整的实际场景。其二，模型展现出高度的临床适配性，通过激活可视化，HUG 头对不同疾病所激活的导联组合模式，与临床诊断标准高度一致，显著提升了模型的可解释性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心模块的必要性验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为验证 CLEAR-HUG 框架中各核心组件的贡献，本研究进行了系统的消融实验。该方法遵循控制变量原则，通过逐步移除或调整模型中的特定设计，量化评估每个创新模块的实际价值。主要实验结果与发现如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;传导建模的有效性验证：对比基础掩码自编码器，CLEAR 预训练通过传导引导稀疏注意力，在心律分析任务中提升 17.4%，证明了传导机制建模的重要性。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwQ72U1DKyK2Nrpxw9ZeGONMq7jxibAcwUgibm9BicWODBxG2y7UOb7vOkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.8040201005025126" data-s="300,640" data-type="png" data-w="398" type="block" data-imgfileid="100027169" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7c793868-6b77-4442-b38d-b6588dc02ef6/640.png" alt="图片" data-before-load-time="1768543434802" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/li&gt;&lt;li&gt;层级诊断结构的作用分析：移除 HUG 头后，模型在细分类任务中性能明显下降，验证了层级分组策略对复杂疾病诊断的关键作用。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwwqZUPMb8eibzghJOt0R8GccKxB8iazArLuNWegPdiavtVCyMkbnpCibefQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7106481481481481" data-s="300,640" data-type="png" data-w="432" type="block" data-imgfileid="100027170" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1f3e4794-2bf2-40f6-9953-0a2647ed45f9/640.png" alt="图片" data-before-load-time="1768543434942" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/li&gt;&lt;li&gt;预训练掩码策略的优化验证：不同掩码率实验表明，80% 的掩码率能平衡特征学习深度与训练稳定性，是最优选择。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些实验从多个维度证实，CLEAR 与 HUG 两个核心模块均不可或缺，其设计共同支撑了模型在各项任务中的性能提升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CLEAR-HUG 的成功，并不依赖于复杂的模型架构，而是根植于对医学本质的深刻洞察与巧妙融合。&lt;/p&gt;&lt;p&gt;首先，模型从生理机制出发，紧扣心脏传导这一心电信号的核心生成原理，使特征学习过程更贴合生理本质。其次，通过将模型流程与医生诊断逻辑深度对齐，在提升性能的同时也显著增强了结果的可解释性。此外，其轻量化设计与对缺失导联的适应能力，兼顾了效率与临床实用性，为实际部署扫除了障碍。&lt;/p&gt;&lt;p&gt;该研究不仅为心电分析提供了新的技术路径，也印证了 AI 医疗发展的关键方向&amp;mdash;&amp;mdash;唯有将领域知识与人工智能技术深度融合，才能开发出真正赋能临床的实用工具。&lt;/p&gt;&lt;p&gt;展望未来，研究团队计划将本框架扩展至更多心血管疾病诊断场景，并探索与多模态医疗数据的融合应用，从而为智能医疗的落地持续注入新动力。&lt;/p&gt;&lt;p&gt;作者信息：&lt;/p&gt;&lt;p&gt;上智院实习生、复旦大学人工智能创新与产业研究院博士生潘覃和孙翊轩，为共同第一作者。&lt;/p&gt;&lt;p&gt;代码地址：&lt;/p&gt;&lt;p&gt;https://aistudio.ai4s.com.cn/galaxy-model/partner/galaxy-model-frontend/model/CLEAR-HUG&lt;a data-topic="1" href="javascript%3A;"&gt;#heading&lt;/a&gt;-1&lt;/p&gt;&lt;p&gt;https://github.com/Ashespt/CLEAR-HUG&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>神同步OpenAI！中国团队Deep Principle领衔发布LLMs for Science评测，引爆外网</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Fri, 16 Jan 2026 14:03:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027153" data-ratio="0.5027777777777778" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6Tx9kRhLkibK8AmtCkqcBWhERjONB2OxY14EzBJWicpIKJkIICmFQ8UazQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/027856d8-92d4-4464-8564-9fcadca1f957/640.jpeg" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;最近，一篇由中国团队领衔全球 24 所 TOP 高校机构发布，用于评测 LLMs for Science 能力高低的论文，在外网炸了！&lt;/p&gt;&lt;p&gt;当晚，Keras （最高效易用的深度学习框架之一）缔造者 Fran&amp;ccedil;ois Chollet 转发论文链接，并喊出：「我们迫切需要新思路来推动人工智能走向科学创新。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6T07oR3O8SToy6MOcEdaCia3MFibcqNpJn09ZfERm9oTKF1y8BD2cBklpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6963087248322147" data-s="300,640" data-type="png" data-w="596" type="block" data-imgfileid="100027148" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/42dae098-8008-456b-b948-ab8794d333ee/640.png" alt="图片" data-before-load-time="1768543355556" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;AI 领域 KOL Alex Prompter 分享论文核心摘要后，NBA 独行侠队老板 Mark Cuban 跟帖转发，硅谷投资人、欧洲家族办公室、体育媒体同时涌进评论区。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TEqsW5RwicCMFdr2pMGHCAptN835wBptmNlKIiam8Fl6TEmXfESZdOZbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.6446850393700787" data-s="300,640" data-type="png" data-w="1016" type="block" data-imgfileid="100027149" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/99212310-ea85-4c65-8425-672c41048151/640.png" alt="图片" data-before-load-time="1768543355562" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;仅一夜，累计阅读量逼近 200 万。&lt;/p&gt;&lt;p&gt;值得一提的是，同一时间窗里，OpenAI 也发布了对于 AI 在科学发现领域能力评测的论文《FrontierScience: Evaluating Al&amp;#39;s Ability to Perform Scientific Research Tasks》概述，指出现有评测标准在 AI for Science 领域失灵。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TKUNcXnKX4X5P4lialI0hzJcO4VJRYW2z06d3Nx3g8X7wGHMlg6raKow/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.1327731092436975" data-s="300,640" data-type="png" data-w="595" type="block" data-imgfileid="100027150" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2de8dc8d-f04b-4938-9839-bdce91aa4dcd/640.png" alt="图片" data-before-load-time="1768543355562" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;神同步 OpenAI、海外讨论出圈，究竟是什么样的一份工作成果，搅动了全球 AI 舆论场？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 距离可以助力科学发现还有多远？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前段时间，美国推出「创世纪计划」，号称要调动「自阿波罗计划以来最大规模的联邦科研资源」，目标是在十年内将美国科研的生产力和影响力翻倍。&lt;/p&gt;&lt;p&gt;但在人工智能估值泡沫隐现、能耗与产出比饱受质疑的当下，一面是资本的狂欢，另一面却是 AI 能力困于「文生图」等表层应用的尴尬；一面是各类大语言模型频繁霸榜 GPQA、MMMU 等题库式 Benchmark 的层出不穷，另一面却是现有 LLMs 还无法准确解析简单核磁图谱的尴尬现状。&lt;/p&gt;&lt;p&gt;人们不禁要问：能在题库拿高分，就能助力科学发现吗？现在的模型距离科学发现还有多远？究竟什么样的 AI 模型可以胜任，拓宽人类的生存边界？这些讨论，在中美 AI 竞争白热化的当下变得愈发浓烈。&lt;/p&gt;&lt;p&gt;在此背景下，由中国 AI for Science 领域的初创企业「深度原理&amp;nbsp;Deep Principle」领衔麻省理工学院、哈佛、普林斯顿、斯坦福、剑桥、牛津等全球 24 所科研院校共同发布的《Evaluating LLMs in Scientific Discovery》论文，正式回答该时代之问。&lt;/p&gt;&lt;p&gt;论文推出了 LLM for Science 首套评测体系&amp;nbsp;SDE（Scientific Discovery Evaluation），从科学问题到研究项目，对 GPT-5、Claude-4.5、DeepSeek-R1、Grok-4 等全球主流大语言模型在生物、化学、材料、物理领域的科学研究与发现能力完成摸底。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TIBotoxAD2nzVI4EUpCfb92oCE7RAK9ztkTIQPCE2VfjTeC96IDddDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027151" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/88674268-ed99-48c6-ad30-303eeb250907/640.png" alt="图片" data-before-load-time="1768543355622" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同以往评测体系不同的是，SDE 对模型能力的考量，从简单的问答式，引向了具体的「假设 -&amp;gt; 实验 -&amp;gt; 分析」实验场景。&lt;/p&gt;&lt;p&gt;研究发现，GPT-5、Claude-4.5、DeepSeek-R1、Grok-4 平均准确率 50&amp;ndash;70%，远低于它们在 GPQA、MMMU 等题库上的 80&amp;ndash;90%；在 86 道「SDE-Hard」难题中，最高分不足 12%，共同暴露出多步推理、不确定性量化和实验与理论闭环的短板。&lt;/p&gt;&lt;p&gt;更值得警惕的是，模型规模与推理能力的提升已呈现明显的「边际效益递减」。&lt;/p&gt;&lt;p&gt;GPT-5 相较于前一代模型，参数规模和推理算力显著增加，但在 SDE 基准的四大科学领域中，平均准确率仅提升 3%-5%，部分场景（如 NMR 结构解析）甚至出现性能下滑。&lt;/p&gt;&lt;p&gt;换句话说，当前大语言模型在推动科学发现方面的表现，还不如一个普通的本科生。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;能领衔 24 所顶尖科研院校发布的背后团队是谁？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;《Evaluating LLMs in Scientific Discovery》论文通讯作者段辰儒，是「深度原理 Deep Principle」创始人兼 CTO。早在 2021 年，在 MIT 攻读化学博士期间，他就已在图灵奖得主 Yoshua Bengio 的支持下，发起了 AI for Science 社区的建立，并在 NeurIPS 上举办 AI for Science workshop。&lt;/p&gt;&lt;p&gt;2024 年初，他与 MIT 物理化学博士贾皓钧回国，共同创立「深度原理 Deep Principle」。贾皓钧任 CEO，段辰儒任 CTO，两人虽为 95 后，但已在全球 AI for Science 创业领域小有名气。&lt;/p&gt;&lt;p&gt;创业一年半以来，其已获得线性资本、高瓴创投、蚂蚁集团等多家知名机构的投资，且与晶泰科技、深势科技等 AI for Science 领域的知名企业建立战略合作关系。&lt;/p&gt;&lt;p&gt;「深度原理 Deep Principle」从创立之初，就带着全球 AI for Science 头部研究者们的期待。目前「深度原理 Deep Principle」已深入全球材料研发中的第一线，将生成式人工智能同量子化学结合起来，致力于推动材料发现等领域进入新纪元。&lt;/p&gt;&lt;p&gt;在过去的一年中，他们在 Nature 大子刊和 JACS 等顶级期刊上不断扔出重磅成果，宣告着他们的技术领先和开放交流的「95 后创业公司」心态。从开拓扩散生成模型（Diffusion Models）在化学反应的生成，证明「不止要生成材料，更需要生成材料的合成路径」，到机器学习势（Machine Learning Potentials, MLPs）和扩散生成模型的直接对比，证明传统的机器学习势不是「万能」的，再到现在组织各大顶级学者和高校推出 SDE，证明传统一问一答的 Benchmark 不能带领我们走向科学超级智能，精准切入 AI for Science 领域的核心冲突。&lt;/p&gt;&lt;p&gt;但同时，对于所有的 AI4S 公司而言，在商业真金白银的检验中，AI 能否真正解决新产品研发问题、满足客户期待，是日复一日必须面对的拷问。&lt;/p&gt;&lt;p&gt;随着与行业头部客户的商业化合作落地，「深度原理 Deep Principle」的数据库中已经汇聚了来源于客户与自己实验室、大量来自第一线的真实工业研发场景数据和模型应用经验。&lt;/p&gt;&lt;p&gt;学术圈的深耕与在 AI for Science 商业化第一线的积累，让「深度原理 Deep Principle」在提出要构建一把新尺子评测 LLMs for Science 能力时，一呼百应，摇来了 23 家全球 TOP 科学发现机构的 50 余位科学家，成立了制定 SDE 的「梦之队」。&lt;/p&gt;&lt;p&gt;这其中，不乏活跃在 LLM 领域的大牛学者们，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;孙欢（Huan Sun），MMMU 发起人，俄亥俄州立教授&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;杜沅岂（Yuanqi Du），康奈尔博士，AI4Science 社区「运营大管家」&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;王梦迪，普林斯顿最年轻教授，AI+Bio Safety 先驱者&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Philippe Schwaller，IBM RXN&amp;nbsp;之父，EPFL 教授&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而「深度原理 Deep Principle」前期积累的科学发现场景，成为了后来 SDE 评测体系的前身。&lt;/p&gt;&lt;p&gt;在经历近 9 个月的跨高校跨学科跨时区的协作后，《Evaluating LLMs in Scientific Discovery》论文正式发布，通讯单位赫然写着：深度原理，杭州，中国。 &amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TZ9Bm2yttmJFP3pDLWM7byticdciah5xjfw72YVdibVFibYKLUINKWaC5RA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.2836601307189544" data-s="300,640" data-type="png" data-w="765" type="block" data-imgfileid="100027152" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d3809a4e-b413-4edc-a284-f3928d5b7b14/640.png" alt="图片" data-before-load-time="1768543355960" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;自此，汇聚着全球顶级科学发现机构的集体智慧，来自中国的创业团队「深度原理 Deep Principle」，和大洋彼岸的 OpenAI，同时站在了向 AI for Science&amp;mdash;&amp;mdash; 这一人类通往终极 AGI 顶峰攀登的起跑线。&lt;/p&gt;&lt;p&gt;或许千百年后，当人类回望 AGI 时代，在 21 世纪的四分之一结束的当口，这场由中美团队共同呼应的，对于 AI for Science 的严肃讨论，把 LLMs 在各类问答式榜单上的内卷，向真正科学发现的星辰大海推近了一步。&lt;/p&gt;&lt;p&gt;至于怎么通往彼岸，段辰儒表示：「当大语言模型在各种科学问答榜单表现饱和，但还不能有效支持科学发现时，就像『考试成绩好』不等于『顶级研究者』，说明我们需要新的评测体系与训练路径。」&lt;/p&gt;&lt;p&gt;「深度原理 Deep Principle」与 20 多所机构的 50 多位合作者的研究证明了，目前 LLM 的发展路径并不能「顺便攻克」科学发现。&lt;/p&gt;&lt;p&gt;这条通往科学超级智能之路，需要更多有识之士共同并肩而行。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>美团又上新模型，8个Thinker齐开工，能顶个诸葛亮？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 13:27:37 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c6beaf52-8c20-4450-b38a-104cc1677e8b/1768540889264.png" style="width: 700%;" class="fr-fic fr-dib"&gt;临近春节，各家 AI 厂商进入冲刺阶段，纷纷亮出最新大模型成果。&lt;/p&gt;&lt;p&gt;1 月 15 日，美团也重磅更新自家模型 &amp;mdash;&amp;mdash;&lt;strong&gt;LongCat-Flash-Thinking-2601&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这是一款强大高效的大规模推理模型，拥有 5600 亿个参数，基于创新的 MoE 架构构建。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="577" data-backw="578" data-height="790" data-imgfileid="503528594" data-ratio="0.9974747474747475" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFQiaIPufWNEx5nXFtOFwKd4OicLiboTvab6kPuaMT4NYcNIjSnoMviaD8SA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="792" data-width="792" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/275c3b6b-dcec-48ac-8b3c-9c130905a63b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该模型引入了强大的&lt;strong&gt;重思考模式（Heavy Thinking Mode）&lt;/strong&gt;，能够同时启动 8 路思考并最终总结出一个更全面、更可靠的结论。目前重思考模式已在 LongCat AI 平台正式上线，人人均可体验。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFmqZPpibEj5OYFVcN288Mp0XrgjzSq1p38TKhVDVFyDjS2MZicA4icYZJg/640?wx_fmt=jpeg#imgIndex=2" data-ratio="0.2175925925925926" data-type="png" data-w="1080" data-width="1936" data-height="622" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFNDqkW8A2TgiaGuB6n8ZAib2jqzS17sIFMhEtAcLNZMZuJ4sS5Cp3Uk3g/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1932.5551601423488" data-cropy1="55.11743772241993" data-cropy2="475.38790035587186" data-backw="578" data-backh="186" data-imgfileid="503528596" data-aistatus="1" data-original-style="width:561px;height:122px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ae0abd23-88b6-46c3-8223-bfbb4e6ba50c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 仅选择「深度思考」时才会触发重思考模式。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;体验链接：https://longcat.ai&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址：https://huggingface.co/meituan-longcat/LongCat-Flash-Thinking-2601&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;GitHub：&lt;/span&gt;https://github.com/meituan-longcat/LongCat-Flash-Thinking-2601&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不仅如此，该模型的&lt;strong&gt;智能体能力&lt;/strong&gt;还获得了重大提升：在智能体工具调用、智能体搜索和工具集成推理等基准测试中达到顶尖性能，而且在任意的 OOD（分布外）真实智能体场景中实现了泛化能力的显著提升。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="331" data-backw="578" data-height="1668" data-imgfileid="503528603" data-ratio="0.5731481481481482" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFGBdBP9ZcnNaOuicRldOwIK2icNjA6mNlpMoPaDe5Iez6B9ibk1k5NIb3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" data-width="2910" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9e441ac3-653d-4d99-bc5f-be25c5da21a1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队还专门提出了一种全新的智能体模型泛化能力评测方法。&lt;/p&gt;&lt;p&gt;通过构建自动化的环境和任务合成流程，基于给定关键词，随机生成任意的复杂任务。每个生成的任务都配备对应的工具集与可执行环境。&lt;/p&gt;&lt;p&gt;这种高度随机化的评测方式，能够更真实地检验模型在未知场景下的适应能力。&lt;/p&gt;&lt;p&gt;实验结果表明，LongCat-Flash-Thinking-2601 在该评测中始终保持领先性能。&lt;a href="https://mp.weixin.qq.com/s/4CWGglF95Knyrc-ERzgI2w"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/cf151250-3fbc-4395-bb13-ec52c4b3cb93/1768540936715.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;接下来，我们就把模型拉到真实场景里实测一番。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测：这只龙猫有点强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们先来试试数理逻辑推理，顺便看看这个&lt;strong&gt;重思考模式&lt;/strong&gt;到底是怎么一回事。&lt;/p&gt;&lt;p&gt;「运动会招募志愿者，第一次招募了不到 100 人，其中男女比例为 11:7；补招若干女性志愿者后，男女比例为 4:3。问最多可能补招了多少名女性志愿者？」&lt;/p&gt;&lt;p&gt;在 longcat.ai 上开启「深度思考」后，便进入了重思考模式，此时 8 个 Thinker 同时开工，每个都表现出不同的思考风格。有的按常规解题，有的则直接写了个 Python 脚本。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="372" data-backw="578" data-imgfileid="503528624" data-ratio="0.6435185185185185" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFgA3zzbayLGicGbib66o51opoLcwDE1BWib9S6n8pu1lOoqr65gELibicIzg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-type="gif" data-w="1080" type="block" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f70f27a1-5a0f-4bc9-9e28-e0be32c60b08/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大部分 Thinker 给出了答案 5，其中 3 号和 6 号 Thinker 还写出详细的推导过程。待 8 个 Thinker 执行完任务后，模型再验证不同 Thinker 的思考过程，形成最终答案。&lt;/p&gt;&lt;p&gt;整个过程就像一个团队开会讨论问题，最后达成共识，最终给出的解答也更靠谱得多。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="407" data-backw="578" data-imgfileid="503528628" data-ratio="0.7034291010194624" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFKibNFTmdwC7kw3SRavgr5DhjN0PiciavksQUibAhewBvhfZXB26Onnlq8A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-type="gif" data-w="1079" type="block" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/13872103-c641-4b0c-9169-8e9087998aa7/640.gif" data-order="1" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;下面是道逻辑推理题。「A 的手机号码最后 5 位，由五个不同的数字组成。B 说：我猜它是 84261。C 说：我猜它是 26048。D 说：我猜它是 49280。A 说：巧了，你们每人都猜对了位置不相邻的两个数。你知道这五位号码是多少？」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFcaMqlbS1gelqhBicMR0ycIxD7ghkr3GvUFmcFmjbuib1hib9hEVhs7WGw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.7025" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="406" data-imgfileid="503528630" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/791ad904-7aff-4ecb-ace1-faa978567054/640.gif" data-order="2" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;8 个 Thinker 再次启动，各自从不同角度切入。&lt;/p&gt;&lt;p&gt;模型没有简单地按照「少数服从多数」的原则采纳意见，而是调用一段代码，系统验证答案是否满足所有约束条件，并穷举所有可能的组合，确认 86240 是唯一解。&lt;/p&gt;&lt;p&gt;这种将单个模型调用八次的模型编排方式，在技术实现上虽直接，却在实际效果上发挥出「三个臭皮匠顶过诸葛亮」的优势。&lt;/p&gt;&lt;p&gt;实测过程中，我们还发现了重思考模式的一种有趣玩法：投票。&lt;/p&gt;&lt;p&gt;举个例子，我们可以开启「深度思考」模式，然后让模型选出 2000 年代最优秀的华语流行歌手。&lt;/p&gt;&lt;p&gt;我们发现不同的 Thinker 会给出很不一样的答案，比如有一个仅选出了周杰伦、蔡依林、孙燕姿、王菲、陈奕迅五位代表，而另一个则直接列出了一长串名单。&lt;/p&gt;&lt;p&gt;最终，经过模型在总结阶段的汇总整理，LongCat-Flash-Thinking-2601 给出了一份涵盖多维度评估的名单，颇具参考性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="518" data-backw="578" data-height="758" data-imgfileid="503528629" data-ratio="0.8970414201183432" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFmv58OTa4YRSHqagiagSAXpPrHbhQVMDlUv0WvN38nznupcOFUOHaqsA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="845" data-width="845" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3a7b1b3d-03ea-4415-8e49-c31f14a73a4a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们又试了下该模型的编程能力。先让它生成一个 Flappy Bird 小游戏，效果很不错。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="743" data-backw="578" data-imgfileid="503528626" data-ratio="1.2854291417165669" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFt9PPiboKmSX8FgicAUt9AlEqia55ZEly1ThrVEU0C7A1VMiawLrJPKFTRg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-type="gif" data-w="1002" type="block" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d9f0fef8-0e95-4abe-bf88-97a246b252da/640.gif" data-order="3" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; Prompt：Make a game like flappy bird using HTML/CSS/JS in a single HTML file.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;接下来我们又试了试让其编写一个康威生命游戏：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="642" data-backw="578" data-imgfileid="503528632" data-ratio="1.1106666666666667" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFNH8wpOb6icSnWu12s2yp081G8BbQsC3zNZ1AybHoJ2o6WIuFtLCrEqg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-type="gif" data-w="750" type="block" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/a35afce7-5e91-43fc-bcd4-2cbdbebb4694/640.gif" data-order="4" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;Prompt：用 Python 写一个 Conway 生命游戏，提供可视化网格、暂停、单步和参数调节功能。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但实事求是地说，使用 8 个 Thinker 来完成编程任务的计算成本应当是比较高的，可能并不适合大规模应用（尽管目前该模型对普通用户免费），但是我们认为这种模式却非常适合医疗、金融、法律等可能需要多次深度思考来保证准确性的场景。&lt;/p&gt;&lt;p&gt;最后，我们再来测试一下 LongCat-Flash-Thinking-2601 模型主打的 &lt;strong&gt;Agent 能力&lt;/strong&gt;，其中的核心便是工具调用。&lt;/p&gt;&lt;p&gt;为了方便用户测试，美团专门构建了一个「大模型工具使用测试」平台。该平台能基于关键词随机生成复杂的 OOD（分布外）任务，专门用来试探模型在陌生环境下的行动能力。&lt;/p&gt;&lt;p&gt;我们随机生成了一个「营养补给方案」任务。平台瞬间拉起了一个包含近 30 个工具的复杂图谱。从页面右侧的依赖关系可以看出，这并非简单的线性调用，模型需要像经验丰富的营养学家，理清儿童营养需求分析、食物营养成分计算、过敏食物筛选等工具之间环环相扣的逻辑。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="321" data-backw="578" data-height="1055" data-imgfileid="503528634" data-ratio="0.5555555555555556" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFunpDTtaVUv3KYcUINP40dszjA9vVqHaYSicv3DiaEHp2iaEAcdndia3ybA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" data-width="1899" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/de029fc0-a874-4628-8ba2-280ba2efdde5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更有趣的是，该平台还支持模型对比，让用户可以轻松地将 LongCat-Flash-Thinking 与其它模型放在同一起跑线上进行对比。&lt;/p&gt;&lt;p&gt;这里我们将其与当前大模型界的顶级选手 Claude 4.5 Opus 放在了同一个赛道上，进行同步竞技。&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/4CWGglF95Knyrc-ERzgI2w"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/04f8acb8-c2cd-471d-ad49-0c9987b48d7a/1768541012889.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 8 倍速视频&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;视频展示了两个模型在高频调用工具时的思考流。在任务完成后，系统会调用 AI 评估员，从执行速度与任务达成度两个维度进行复盘。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="167" data-backw="578" data-height="532" data-imgfileid="503528635" data-ratio="0.2898148148148148" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFNjBhgan3o2TBV69fTh6JO4hkFoZEicXXGLviaLEsEgbl56B1tBWhn6Aw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="1080" data-width="1838" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/77f9b14a-03c2-49f6-8bc5-f8e97b47fb19/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在这个具体案例中，两个模型都交出了高分答卷，但 LongCat 成功达到了 100% 的标准覆盖率，而 Claude 4.5 Opus 却未能成功为用户创建健康档案，仅达到了 80% 的覆盖率。整体而言，LongCat 在处理工具依赖关系的响应节奏上展现出了更强的稳定性。&lt;/p&gt;&lt;p&gt;深入细节，我们可以看到这些工具的调用和输出都采用了标准的 JSON 格式，这也是当前大量的 MCP 或 API 工具采用的主流格式。这也意味着，我们可以非常轻松地将 LongCat-Flash-Thinking-2601 整合进到现有的工作流程中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="465" data-backw="578" data-height="583" data-imgfileid="503528636" data-ratio="0.8041379310344827" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFULhPyN2ibjE5J7mQmicPuMvaXkczKwE03aVeYKYrbNxQsEibae0n4PHEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="725" data-width="725" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/25bda444-9071-4d07-8911-efacd54d0c0a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;强大实力的根基：重思考 + 智能体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么，表现如此亮眼的 LongCat-Flash-Thinking-2601 究竟是如何炼成的？&lt;/p&gt;&lt;p&gt;正如其推文总结的那样，我们先给出几个关键词：&lt;strong&gt;并行思考、迭代式总结、环境规模扩展（Environment Scaling）、多环境大规模强化学习（Multi-Environment RL Scaling）、课程学习（Curriculum Learning）&lt;/strong&gt;。另外，还有即将发布的 &lt;strong&gt;ZigZag Attention&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;作为 LongCat-Flash-Thinking 的最新版本，2601 版本继承了上一版本的领域并行训练方案，而技术底座同样是参数总量达 560B 的高性能混合专家（MoE）架构模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFGt3yXoJlsOQwCribsLqRxGJq8MA9qT2YkOeG72se7YMaB2f3Ow3EaAQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4074074074074074" data-type="png" data-w="1080" data-width="1322" data-height="539" data-backw="578" data-backh="236" data-imgfileid="503528650" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/6994cebf-0049-4b2a-bc0a-3737fcf0e9a5/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 来自 LongCat-Flash-Thinking 技术报告&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在此基础上，如上文评测所示，除了一些细节上的优化，这个新版本重点引入了两大改进：&lt;strong&gt;重思考模式&lt;/strong&gt;和&lt;strong&gt;智能体能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;该模型新引入的重思考模式别具一格，我们目前还未见其它任何模型显式或开源地提供类似模式。&lt;/p&gt;&lt;p&gt;而在智能体能力方面，美团引入了一套精心设计的流程。该流程结合了环境规模扩展与后续任务合成，并会在此之上进行可靠且高效的大规模、多环境强化学习。为更好地适应真实世界智能体任务中固有的噪声与不确定性，美团 LongCat 团队还对多种类型和不同强度的环境噪声进行了系统分析，并采用课程式训练，使模型在非理想条件下依然保持稳健表现。&lt;/p&gt;&lt;p&gt;下面我们就来更具体地看看美团的这些核心技术。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重思考模式：推理广度与深度的协同扩展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;打开 longcat.ai 「深度思考」后开始体验，你第一时间就会被同时冒出的 8 个 Thinker 吸引注意。这正是 LongCat 团队提出的 &lt;strong&gt;Heavy Thinking Mode（重思考模式）&lt;/strong&gt;的外在表现。它不仅看起来炫酷，更重要的是将推理能力推向了新的边界。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFMt6tPrwNo6BKPIssY1k6uxThenV8ibuxunclUDc4wF5XFBal0T9qtWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.1347222222222222" data-type="png" data-w="720" data-width="720" data-height="817" data-backw="578" data-backh="656" data-imgfileid="503528652" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/04195b9d-a1b0-4087-93ea-2801532ac7ef/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大致来看，其与 AI 大牛 Andrej Karpathy 实验性的&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651003281&amp;idx=1&amp;sn=3d21baa1164c2afbbfc15c7b2fb5c847&amp;scene=21#wechat_redirect" target="_blank"&gt;大模型议会&lt;/a&gt;项目有相似之处，但不同的是，Karpathy 的大模型议会是通过模型编排方式来向不同模型构成的集体提出问题，让它们各自发言并讨论后给出最终解答，而 LongCat-Flash-Thinking-2601 新引入的重思考模式则是&lt;strong&gt;并行地调用一个模型 8 次&lt;/strong&gt;来实现高强度的并行思考。&lt;/p&gt;&lt;p&gt;如此一来，便可以同时获得多条相互独立的推理路径并进行交叉验证，从而显著降低偶然性错误，提升在复杂问题上的稳定性、可靠性与最终答案质量。如此一来，可以进一步提升模型在极具挑战性任务上的表现。&lt;/p&gt;&lt;p&gt;具体来说，该模式会将高难度问题求解分解为两个互补阶段：&lt;strong&gt;并行思考&lt;/strong&gt;与&lt;strong&gt;总结&lt;/strong&gt;，从而同时扩展推理的深度与宽度。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在&lt;strong&gt;推理宽度&lt;/strong&gt;方面，重思考模式会并行生成多条独立轨迹，以广泛探索不同推理路径，并采用相对较高的推理温度以保证多样性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在&lt;strong&gt;推理深度&lt;/strong&gt;方面，总结阶段生成的精炼轨迹可以递归反馈给总结模型，形成支持逐步加深推理的迭代推理回路。LongCat 团队还专门设计了额外的强化学习阶段来训练总结能力，进一步释放该模式的潜力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;智能体能力提升：环境规模扩展与多环境强化学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体能力&lt;/strong&gt;方面，LongCat 团队精心设计了一套自动化环境规模扩展链路，并构建了一组多样且高质量的环境，作为工具调用类任务强化学习的训练场，使模型能够习得高层次、可泛化的智能体能力。&lt;/p&gt;&lt;p&gt;每个环境包含多达 60 余种工具，并以高密度依赖图的形式组织，提供了足够的复杂度以支持多样化任务构建与大规模探索。实验表明，随着训练环境数量的增加，模型在分布外（OOD）任务中的表现会持续提升（&lt;strong&gt;Environment Scaling&lt;/strong&gt;）。&lt;/p&gt;&lt;p&gt;高质量任务构建&lt;/p&gt;&lt;p&gt;为确保训练任务集的质量，LongCat 团队对任务复杂度和多样性进行显式控制。每个任务都定义在从高质量环境中采样得到的连通子图之上，任务复杂度通过要求在该子图内尽可能多地协同使用工具来调节。为促进任务多样性，已选工具的再次采样概率会逐步降低。&lt;/p&gt;&lt;p&gt;LongCat 团队还构建了配套数据库以确保任务的可执行性，并验证每个任务至少存在一种可执行解。然而，当环境中包含大量工具时，跨数据库的一致性维护会变得困难，可能导致部分任务无法验证。针对这一问题，LongCat 团队设计了专门的应对策略，使训练的稳定性和有效性得到了充分保障。&lt;/p&gt;&lt;p&gt;多环境强化学习&lt;/p&gt;&lt;p&gt;在保持高效异步训练和流式 rollout 特性的同时，LongCat 团队进一步扩展了其强化学习基础设施 DORA（异步弹性共卡系统），以支持环境规模扩展下的大规模多环境智能体训练（&lt;strong&gt;Multi-Environment RL Scaling&lt;/strong&gt;）。&lt;/p&gt;&lt;p&gt;具体而言，来自多个环境的任务会在每个训练批次中以平衡的方式混合，并根据任务复杂度和当前训练状态分配不同的 rollout 预算。&lt;/p&gt;&lt;p&gt;下图展示了该模型的多环境混合强化学习训练曲线，可以看到上涨的趋势非常稳定，这表明美团构建的基础设施和算法可以有效保证训练的稳定性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFcfza8FKCIxF5pFjSBiaqqj1Klu2KX7d3B4VWNWtH7yUyibFswMFHIcbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5907407407407408" data-type="png" data-w="1080" data-width="1695" data-height="1002" data-backw="578" data-backh="342" data-imgfileid="503528658" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/96191e0a-3f35-4e6e-aee4-dc3f72d1c536/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;下图则展示了多环境强化学习训练下，模型在不同 OOD 测试集上的 RL Scaling 表现，效果非常明显。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFtmlLrjVLYTfEVt8D8lcKOUYIcviae0EKibc17Nc6PWudENq3sxzbDm4A/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.8333333333333334" data-type="png" data-w="1080" data-width="1940" data-height="1616" data-backw="578" data-backh="481" data-imgfileid="503528660" data-aistatus="1" data-original-style="width:100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/31d7c3b1-93da-4c8a-bf77-550a5b21d359/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;面向噪声环境的稳健训练&lt;/p&gt;&lt;p&gt;真实世界的智能体环境天然存在噪声和缺陷，仅在理想化环境中训练模型往往难以获得足够的稳健性。为此，LongCat 团队在训练过程中显式引入环境不完美因素，以提升模型的稳健性。&lt;/p&gt;&lt;p&gt;具体而言，LongCat 团队系统分析了智能体场景中真实世界噪声的主要来源，并设计了一套自动化流程，将这些噪声注入训练环境。在强化学习阶段，LongCat 团队采用课程式策略，随着训练推进逐步增加噪声的类型和强度。&lt;/p&gt;&lt;p&gt;下图展示了模型是否采取面向噪声环境的稳健训练，在带噪声 / 无噪声评测集下的表现对比，其中不同的评测集上依据特性添加了不同类型的噪声。可以看到，带噪声环境下未经过稳健训练的模型的表现会出现大幅衰减，Claude 也无法适应全部的噪声类型。而经过稳健训练后，LongCat-Flash-Thinking-2601（Training w/ Noise 组） 对环境的噪声和不确定性展现出了强大的适应能力，并在各类非理想条件下取得更优表现。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFsRiassxnzUsn2Q7UIRf9ib8GqTcibL65UqhPZPFXjicc6uvuaC6ZHAoyIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.7583333333333333" data-type="png" data-w="1080" data-width="2586" data-height="1960" data-backw="578" data-backh="438" data-imgfileid="503528661" data-aistatus="1" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/8b458c58-2f92-4f01-978e-e49888b68429/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;得益于这些改进与创新，LongCat-Flash-Thinking-2601 不仅在智能体工具使用、智能体搜索以及工具融合推理等基准测试中达到顶尖水平，还在任意的 OOD（分布外）真实世界智能体场景中展现出显著提升的泛化能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LongCat ZigZag Attention：实现超长上下文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LongCat ZigZag Attention&lt;/strong&gt;，顾名思义，是一种注意力机制，根据其官方推文描述，其一大核心亮点是能「实现 100 万 token 上下文」。据悉，LongCat ZigZag Attention 已被成功用于训练当前 LongCat-Flash-Thinking 模型的一个分支，我们也将很快见证这个分支版本面世。细节详见论文：https://arxiv.org/abs/2512.23966&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFhJjqx1o17x61wJVVk9gEGFxxMBfH4ZH0nZTzhsp2VuWPMA4Dk3FjGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.3638888888888889" data-type="png" data-w="1080" data-width="1340" data-height="487" data-backw="562" data-backh="204" data-imgfileid="503528662" data-aistatus="1" data-original-style="width:100%;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/7b5a15ff-c5bc-4a8b-b184-a49818137abd/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;One More Thing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回头来看，美团大模型站到台前时间并不算长但节奏清晰，首次亮相在 2025 年 9 月，此后保持了每月一更的开源节奏，不断扩容自己的能力库：从强调响应速度的 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650988704&amp;idx=1&amp;sn=da107de5f4054028060a334398147912&amp;scene=21#wechat_redirect" target="_blank"&gt;LongCat-Flash-Chat&lt;/a&gt; 到专注逻辑的 Thinking 版本，再到图像和视频模型以及覆盖多模态的 Omni 版本，每一步迭代都在让这只龙猫能够更好地理解这个世界，并让复杂的现实生活变得更加可计算。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFfOYSu1DWxHx5a4s1ibcsZ7t8T4tQOvRpPiaSseITGBZlk5jIoZfW1Qibg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=19" data-ratio="0.6433041301627034" data-type="gif" data-w="799" type="block" data-backw="578" data-backh="372" data-imgfileid="503528665" data-aistatus="1" data-original-style="width: 100%;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/023ad478-89cf-43a1-a59b-63a47a6699ca/640.gif" data-order="5" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;美团在 Hugging Face 上的论文页面&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一次，龙猫聚焦 Agent 与 Thinking 能力进行全面提升，也是实现了一次从理解到融入真实世界的跃迁。&lt;/p&gt;&lt;p&gt;或许，美团现在追求的，就是一种确定性：能够用技术在真实世界中又好又快地解决问题，终有一天让「模型即服务」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>失去三个联创后，Mira公司危机持续：又有两人要出走</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 13:18:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e4439142-1c0b-4536-88cd-be03099ac0be/1768540593329.png" style="width: 700%;" class="fr-fic fr-dib"&gt;继奥特曼在 OpenAI 的「宫斗」大戏后，他的老搭档 Mira 这周的经历也够拍一部电视剧了。&lt;/section&gt;&lt;section&gt;&lt;img alt="OpenAI's Sam Altman and Mira Murati on the Future of AI and ChatGPT" data-aistatus="1" data-imgfileid="503528655" data-ratio="0.562962962962963" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFeyI6giaqyQvkGsBUv8nEKCiaeibDqKOtUeuicxR3nVVpUWG7RcSja5CMvw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/eb4a2a3d-96ab-443b-bdcd-3ec32e2dd608/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;昨天，我们报道了前 OpenAI CTO Mira Murati 创办的 Thinking Machines Lab 出现&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651012179&amp;idx=2&amp;sn=23abb8c02371b8b774e9ac9a77264f2f&amp;scene=21#wechat_redirect" target="_blank"&gt;重大人事变动&lt;/a&gt;的消息：&lt;strong&gt;联合创始人兼 CTO Barret Zoph 被解雇，另一位联创 Luke Metz 以及创始团队成员 Sam Schoenholz 也一起离开，三人一起回归 OpenAI。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果再加上之前离开的 PyTorch 大神 Andrew Tulloch，Thinking Machines Lab 目前已失去了三位联创，可谓创业未半，核心团队就散了。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528639" data-ratio="1.4796296296296296" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFjXRaYfBPGUnbzD975WbOFlIiaRufqd4gKvtkYw039AdgDsaaRFGfialA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/890e8ada-59b1-4717-8746-e0a84c2e4c89/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;今天，事件还在继续发酵，该实验室的另外两位技术骨干 &amp;mdash;&amp;mdash; 基础设施工程师 Ian O&amp;rsquo;Connell 和研究模型架构的研究员 Lia Guy 也被爆出将要离开，后者明确也要回 OpenAI。&lt;/p&gt;&lt;p&gt;多家媒体将此事件描述为「OpenAI 对 Thinking Machines Lab 的人才突袭（raid）」。据《连线》报道，这次挖人行动已在 OpenAI 内部筹备数周。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFeAE3wCWx5EribIdFasoxiaSmf4ng7uGE2w76zYvchUzda8DQPicB5g5lg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528643" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/54be764f-12df-46d1-b4ad-e5a985dcc95e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而且，这里面还有一些难辨真假的纠葛。知情人士透露，Mira 是在本周三解雇 Zoph 的，当时她还不知道 Zoph 即将重返 OpenAI ，解雇理由是公司宣称的、在公司任职期间曾出现严重不当行为并引发一系列问题。大约在得知 Zoph 将回归 OpenAI 的同一时间，Thinking Machines Lab 内部开始质疑，Zoph 是否曾向竞争对手泄露公司机密信息。&lt;/p&gt;&lt;p&gt;与此同时，OpenAI 应用业务首席执行官 Fidji Simo 在本周三发给员工的一份备忘录中称，Zoph 早在周一就告知 Mira Murati，自己正考虑离开 Thinking Machines Lab&amp;mdash;&amp;mdash; 这一时间点早于他被解雇的日期。Fidji Simo 还向员工表示，OpenAI 并不认同 Thinking Machines Lab 对 Zoph 职业道德方面的质疑。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528645" data-ratio="0.6111111111111112" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFLccAYR8gkob58bJfb9INFm85nDtObAk6d9ibz6tv7077hbB8q7icUMoQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/85a3956e-33de-4be8-85d8-286cd3a26c61/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;至于其他人集体出走的原因，《连线》所联系的知情人士表示，这是 Thinking Machines Lab 内部长期讨论的结果。公司团队在产品定位、技术路线与未来发展方向上存在分歧，这才是核心原因。目前他们需要理清的问题包括：要开发什么产品，是否应专注于研究或部署，如何证明筹集资金的规模合理性以及领导层信任与治理。&lt;/p&gt;&lt;p&gt;无论真相如何，这次事件都将给 Thinking Machines Lab 带来一些打击。甚至有悲观的网友认为，这家公司「已经完了」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFibAB60jDPT9rxNRwXNvOYPrM64vibHOlDmxicZJUfGZjhrvE9jT8VlKEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.32407407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528646" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/fcd4d54c-6ec3-43de-a649-856fae3d89fd/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;公司长期以来面临的质疑也被再次拿出来讨论，其中被提及最多的一点是没有「产品」。不过，这么说也不准确，因为公司前段时间推出过一个名叫「Tinker」的产品，专注于解决后训练 Infra 的复杂性。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528647" data-ratio="0.35648148148148145" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF5iawtwnoE7xHsx1Lm6jMI9TUb9lxsCh6ic2g84xMSBicc9LlXhwzHNRVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/26099e8d-8810-4233-9e3c-638eacbf738f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但显然，这样的成果是承载不起顶级人才当时从大厂出走时所怀揣的技术理想的。因为除此之外，他们没有旗舰模型，没有明确的商业平台，似乎也没有一份与投资规模相匹配的公开路线图。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFFVs6r7dHrDgUu8KfpkBvDsQCBp3Zbmv8Wopyqa5E0de8bFrn7Qiaq1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.39351851851851855" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528648" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/337d4bef-cfb0-4028-855d-25a248146dd1/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不过，在失去「联创」这件事上，Thinking Machines Lab 倒也并不孤独，有人统计了最近几年头部 AI 公司的人员流动情况，发现联创出走比大家印象中还要频繁。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528649" data-ratio="0.7768518518518519" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFU3XfNa2IF2asw0snruyiadKphvKfsaEjryjJMskWbTTC3KrKlCBeGNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d7f7d18f-9c26-4925-bd2c-362386ffb863/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;行业分析师表示，此类快速行动，如招聘、离职和迅速回归，现在已成为 AI 劳动力市场的一个常见特征，并可能改变项目路线图和时间表。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://www.wired.com/story/inside-openai-raid-on-thinking-machines-lab/?utm_brand=wired-science&amp;amp;utm_campaign=aud-dev&amp;amp;utm_medium=social&amp;amp;utm_social-type=owned&amp;amp;utm_source=twitter-science&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>不止于量化：最新综述用「时-空-构」三维视角解构KV Cache系统级优化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 13:14:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/729151fc-a59c-4e5c-af2a-fa81bea22a47/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着 LLM 向 1M 上下文演进，&lt;strong&gt;KV cache（键值缓存）&lt;/strong&gt;已成为制约推理服务效率的核心瓶颈。自回归生成的特性使得模型必须存储历史 token 的 key-value 状态（即 KV cache）以避免重复计算，但 KV cache 的显存占用随着上下文长度的增长而膨胀，带来显著的内存瓶颈。&lt;/p&gt;&lt;p&gt;过去两年，关于 KV cache 的优化工作爆炸式增长，包括调度、迁移、压缩等策略层出不穷。然而，现有综述主要聚焦于 LLM 推理或服务的整体效率，大多仅将 KV cache 作为其中一个子模块作简要讨论。&lt;/p&gt;&lt;p&gt;近期，来自&lt;strong&gt;墨尔本大学和华中科技大学的研究者们&lt;/strong&gt;发布了一篇深度综述，从 &lt;strong&gt;MLSys 的思维&lt;/strong&gt;出发，用一套新颖的&lt;strong&gt;「时间 - 空间 - 结构」系统行为视角&lt;/strong&gt;对 KV cache 优化方法进行了系统性梳理与深入分析，并将相关资源整理成了&lt;strong&gt;持续维护的 Awesome 资源库&lt;/strong&gt;，方便研究者与从业人员快速定位与落地。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDHKaMlzv9lZKLGiaib9DfV7K5nSc12167J5BJh4Mla6IPsLwDh7FJ29Yg/640?wx_fmt=jpeg#imgIndex=1" data-ratio="0.2943361188486537" data-s="300,640" data-type="png" data-w="1077" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDcIBA66Koljsyewp5ico3M4PdVLt5Z0M8KiaYAKD0Bfx7ua2qBQsjocFQ/640?wx_fmt=png&amp;from=appmsg" data-cropx1="3.8434163701067616" data-cropx2="1080" data-cropy1="57.65124555160142" data-cropy2="374.7330960854092" data-imgfileid="503528360" data-aistatus="1" data-original-style="width:560px;height:165px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/fcef86b2-5504-4708-afa1-bd66e468821a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址: https://doi.org/10.36227/techrxiv.176046306.66521015/v3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址: https://github.com/jjiantong/Awesome-KV-Cache-Optimization&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;什么是「 sKis」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了提供更聚焦的视角和理解，作者们首先在综述中定义了 &lt;strong&gt;sKis &lt;/strong&gt;的边界：在推理服务阶段，以 KV cache 为核心优化对象，在不依赖模型重训或结构修改的前提下，提升吞吐、延迟等核心系统指标。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDAAezaGmgRW1Gb7L1RWkYSLJOgiaNEchBsUhFyPvxgHia8cVLBPAFnBvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.46296296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528362" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2616ff8a-e1b9-4c84-9712-bb29014351be/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;从「系统行为」看 KV Cache&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;聚焦于 sKis，该综述创新性地提出以&lt;strong&gt;系统行为的视角&lt;/strong&gt;来组织 KV cache 优化技术：不是按具体流程、框架、算法来划分，而是按优化策略在系统中发生的&lt;strong&gt;时间、空间、结构三个维度&lt;/strong&gt;的行为来划分，从而更容易对齐工程实现与组合策略。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;执行与调度（时间维度）&lt;/strong&gt;：&lt;strong&gt;KV 什么时候被访问和计算？&lt;/strong&gt;该分类关注执行过程与调度。例如设计以 KV 为中心的调度策略，采用流水线来掩盖延迟，或者根据不同硬件的特性适配操作等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;放置与迁移（空间维度）&lt;/strong&gt;：&lt;strong&gt;KV 放在哪里、如何迁移？&lt;/strong&gt;该分类关注数据的存储。例如在 GPU、CPU、SSD 构成的存储层级中如何使热点 KV 留在 GPU 显存中，或者在分布式或异构的计算设备中设计迁移策略等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;表示与留存（结构维度）&lt;/strong&gt;：&lt;strong&gt;KV 长什么样？&lt;/strong&gt;该分类关注数据表示。这是目前最拥挤的赛道，包括量化、驱逐等论文密集的子领域，旨在直接减少 KV cache 的物理体积。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDiamrDOmybkHkkLQUlMwnIVuapumNnf6GLE8lcVXAnPicbqkf8LcMicpiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6187363834422658" data-s="300,640" data-type="png" data-w="918" type="block" data-imgfileid="503528363" data-aistatus="1" data-original-style="width: 389px;height: 241px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c1e7b8d9-b03e-44d2-b822-b394c1cfdc06/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;基于上述三个维度，该综述将现有工作归纳为 7 个二级类别，具体包括：以 KV 为中心的调度（KVS）、流水线与重叠（OVLP）、硬件感知的执行（HAE）、跨内存层级的 KV 编排（MHO）、跨计算设备的 KV 编排（CDO）、KV cache 压缩（KVCC）、KV cache 留存管理（KVRM）。&lt;/p&gt;&lt;p&gt;该论文不仅详细梳理了每个维度下的不同类型和技术方法，&lt;strong&gt;还为每一类提炼了关键要点、局限与权衡，给出了可落地的实用指导&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDhpYEibiccdS0GybwUBPgsSh8HEGcb7Hj4SiaaM7EyIztAKAHjVFat0icMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8351851851851851" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528364" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a2654293-b89b-42b1-91a2-bf89a25e8d2a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;深度洞察与开放挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇综述最有价值的部分之一，在于作者们对百余篇论文进行了&lt;strong&gt;全局交叉分析&lt;/strong&gt;，从而归纳了 &lt;strong&gt;7 大关键观察&lt;/strong&gt;，并引发了 &lt;strong&gt;6 大开放挑战&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;首先，作者们对文献进行了&lt;strong&gt;跨行为共现分析&lt;/strong&gt;，以揭示不同维度的 KV 行为之间的内在联系和协同模式；此外，作者们深入分析了&lt;strong&gt; KV 行为和优化目标的作用关系&lt;/strong&gt;，并统计了文献中对相关优化指标的实际关注情况。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDVqFScswT3vrgxwysKcaRJrX7kcXlicwKiboggW8ibss8nzlG0huZA10dg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5046296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528365" data-aistatus="1" data-original-style="width: 379px;height: 191px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/92306560-f5cc-4e5b-825d-5a07ed7758db/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDpLvYw2O0ZlfWxaczhh9HOvFXOdNBEeC86jZzG18juZYIIWFhAsAWFA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.31203703703703706" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528366" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9878c8cc-ef93-493c-9e00-1191ca5f123c/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;基于以上两类交叉分析，作者们揭示了当前领域的&lt;strong&gt; 7 大关键观察&lt;/strong&gt;，例如什么组合是最常见的协同模式？结构维度（如量化）虽然论文最多，为什么往往沦为系统中的「孤岛」？&lt;/p&gt;&lt;p&gt;基于关键观察，作者们进一步提炼了 &lt;strong&gt;6 大开放挑战&lt;/strong&gt;，例如在追求效率的同时，我们虽然常常会关注到对其质量的影响，但是否往往忽视了可信度（trustworthiness）的隐形崩塌？该综述中对每一个观察和挑战都给出了具体的分析和思路，期待能激发社区向着更加高效与可信的 LLM 服务系统的持续探索！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;资源分享：Awesome-KV-Cache-Optimization 资源库&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了方便社区追踪这一飞速发展的领域的最新进展，论文作者同步维护了一个 Awesome 风格的资源库，收录并持续更新 sKis 领域的最新论文和代码实现。希望这个资源库能让你少走弯路！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;地址：https://github.com/jjiantong/Awesome-KV-Cache-Optimization&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你正在做 LLM Infra、模型压缩或者高性能计算等相关方向，欢迎在 GitHub 上 star 支持，或者来仓库一起补全与更新！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>支付宝携手千问App、淘宝闪购等发布中国首个AI商业协议ACT</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Fri, 16 Jan 2026 11:15:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1月16日，支付宝联合千问App、淘宝闪购、Rokid、大麦、阿里云百炼等伙伴，正式发布ACT协议（Agentic Commerce Trust Protocol，智能体商业信任协议）。这是中国首个面向 Agent 商业需求设计的开放技术协议框架，为 AI 与电商、外卖等服务平台的协同打造一套 &amp;ldquo;通用语言&amp;rdquo;，让跨终端、跨系统、跨平台的 AI 任务执行，变得更便捷、更高效。&lt;img src="https://image.jiqizhixin.com/uploads/editor/d3a457f1-d771-461f-88af-95c56c05c4ed/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;以千问App为例，依托 ACT协议 ，千问App成功打通淘宝闪购与支付宝 AI 付：用户只需向千问发出指令 &amp;ldquo;帮我点杯珍珠奶茶&amp;rdquo;，千问基于用户地理位置，智能推荐附近符合需求的商品，同步完成比价与优惠券自动核销。用户仅需点击 &amp;ldquo;选它&amp;rdquo;，确认支付宝付款，即可一键完成结账。整个购物流程以对话式、自动化、不跳端的方式推进，千问化身专属 &amp;ldquo;购物助手&amp;rdquo;，包办繁琐操作。&lt;/p&gt;&lt;p&gt;当 AI 的能力边界不断拓展，从&amp;ldquo;聊天对话&amp;rdquo;延伸至购物付款等&amp;ldquo;办事时代&amp;rdquo;，新的问题也随之浮现：AI 操作是否获得用户明确授权？资金交易过程是否足够安全？更换设备或应用后，服务体验能否保持连贯？&lt;/p&gt;&lt;p&gt;ACT 协议的诞生正是为破解这些问题而来。支付宝为其搭建了 &amp;ldquo;委托授权域&amp;rdquo;&amp;ldquo;商业交互域&amp;rdquo;&amp;ldquo;支付服务域&amp;rdquo;&amp;ldquo;信任服务域&amp;rdquo; 四大核心基础设施标准，实现 AI 操作全流程可追溯、可验证，让人更放心；支持自动化交易流程，减少不必要的人工干预，提升服务效率；统一多平台服务标准，避免体验的割裂。&lt;img src="https://image.jiqizhixin.com/uploads/editor/03bad643-d16e-484c-9044-2e39c5b03076/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;与传统付款模式不同，在 ACT协议的规则框架下，AI 仅承担下单操作的执行角色，付款环节始终由用户主导或自主授权。在保障资金安全的前提下，为用户大幅节省时间成本。而对商家而言，未来接入 AI 原生应用时，只需按照协议标准配置统一接口，即可对接全渠道入口，无需单独进行复杂的 API 开发，大幅降低对接成本。&lt;/p&gt;&lt;p&gt;目前，ACT 协议可使用在AI 代买、企业自动化采购等多元场景，并提供两种付款模式：一是即时付款，用户与 AI 实时对话，基于推荐列表自主决策，确认后完成付款授权与身份验证，适用于 AI 点外卖、日常购物等高频场景；二是委托授权，用户可提前设定时间窗口、金额上限、商家范围等条件，即便离线无指令，AI 也能自动监测商品动态并完成下单结算，适用于机票、酒店预订等场景。&lt;/p&gt;&lt;p&gt;该协议最大限度遵循兼容性、隐私性、开放性三大原则，全面适配现有商业与支付系统，并将伴随 AI 行业技术发展持续优化。支付宝同时表示，正积极推动更多支付服务商、商家与平台、AI 开发者、智能终端生态厂商加入，共同完善协议内容，共建 AI 商业信任新生态。&lt;/p&gt;&lt;p&gt;随着 AI 原生应用能力的持续升级，&amp;ldquo;AI 代办&amp;rdquo; 服务日渐普及，支付作为其中特殊且关键的环节，正成为全球科技企业的布局焦点。此前，OpenAI 联合 Stripe 推出协议以支持 ChatGPT 结账功能；近期，谷歌也发布 AI 购物全流程通用商务协议（Universal Commerce Protocol，简称 UCP），将实现用户在 Gemini 内直接下单。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，Geoffrey Hinton成为第二位引用量破百万的科学家</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 10:32:37 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/da65f910-b4cb-4a55-b5d3-2ab1ec2ded1e/1768530536279.png" style="width: 700%;" class="fr-fic fr-dib"&gt;刚刚，Geoffrey Hinton 正式成为历史上第二位 Google Scholar 引用量突破 100 万大关的计算机科学家。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD7a3jciaMpwmMUB2VPS8Y9VZnO7RuRt3WIM3OIbTDjDkOyicJUeW0WXqQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.5814814814814815" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528480" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d8b5fcfd-47a4-4f5a-90bd-ad01d61db6e1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在他之前，只有他的老搭档、另一位「深度学习教父」&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650997783&amp;idx=1&amp;sn=0f796e9cbaf70b81378e4cb06ba7ea90&amp;scene=21#wechat_redirect" target="_blank"&gt;Yoshua Bengio&lt;/a&gt; 达成了这一成就。目前，Hinton 的引用量仍在以惊人的速度增长，每一次引用都代表着他对人工智能领域不可磨灭的贡献。从反向传播算法的推广到 AlexNet 的惊艳问世，从获得图灵奖到斩获 2024 年诺贝尔物理学奖，Hinton 的职业生涯几乎就是一部现代 AI 的发展史。&lt;/p&gt;&lt;p&gt;这一数字不仅是学术影响力的量化，更是对这位 78 岁长者一生执着探索的最高致敬。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Geoffrey Hinton：来自学术世家的「教父」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;童年&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Geoffrey Everest Hinton，1947 年 12 月 6 日出生于英国伦敦的一个学术世家。他的中间名「Everest」来自他的叔祖父，也就是以其名字命名珠穆朗玛峰英文名的 George Everest。他的家族星光熠熠，曾祖父是布尔逻辑的创始人 George Boole，表姑是参与曼哈顿计划的核物理学家 Joan Hinton（寒春）。&lt;/p&gt;&lt;p&gt;生在这样的家庭，压力与荣耀并存。Hinton 的母亲曾给他下过一道温和却严厉的「最后通牒」：「要么做个学者，要么就是个失败者（Be an academic or be a failure）」。这种高期待或许解释了他日后对学术的极致追求。&lt;/p&gt;&lt;p&gt;他的童年充满了像电影《天才一族》般古怪而硬核的色彩。家里养过猫鼬，车库的坑里甚至养着毒蛇。8 岁那年，Hinton 曾挥舞着手帕逗弄坑里的毒蛇，结果一条蛇猛地扑向他的手，仅差一英寸就咬中了他，差点让他丧命。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibpJ08gskIzfop6hz3Fal6PHEe3x1PyBmnqibQbQNCuRUu87ekPehShtIaatlqoQJfts4HUb3ukJTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503523890" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/61f3390a-4ba3-4e20-b44d-61c45a1411d5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 8 岁的 Hinton 搂着一条蟒蛇&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;家族的轶事甚至还涉及到了加拿大政坛。1961 年，他的父亲访华时带回了一打中国乌龟。在旅途中，老 Hinton 与未来的加拿大总理皮埃尔・特鲁多（Pierre Trudeau）住同一间酒店房间。据说老 Hinton 把乌龟都养在了浴缸里，导致特鲁多根本没法洗澡。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;求学之路&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;然而，这位天才的学术之路并非一片坦途，但他对世界本质的好奇心早在 4 岁时就已萌芽。&lt;/p&gt;&lt;p&gt;那时，他在一辆乡村巴士上发现了一个奇怪的现象：当巴士急刹车时，座位上的硬币并没有顺着惯性向前滑，而是反直觉地向后移动。这个违反物理常识的现象困扰了他整整十年，直到后来他才明白这是座位绒毛角度与振动共同作用的结果。对此，他曾说道：「有些人可以接受自己不理解的事物，但我不行。我无法接受有什么东西违反了我对世界的认知模型。」&lt;/p&gt;&lt;p&gt;这种对「理解世界运作方式」的执念贯穿了他的求学生涯。在剑桥大学国王学院期间，他曾在物理学、哲学和心理学之间反复横跳。毕业后，在迷茫中他甚至曾短暂地做过一段时间的木匠。在攻读博士学位期间，由于神经网络在当时不被看好，他一度陷入抑郁和自我怀疑。&lt;/p&gt;&lt;p&gt;在一个类似心理治疗的研讨会上，当其他人都在大喊「我想要被爱」来释放情感时，Hinton 憋了半天，最终吼出了心底最深层的渴望：「我真正想要的是一个博士学位！（What I really want is a PhD!）」。带着这股执拗，他在爱丁堡大学获得了人工智能博士学位，正式开启了他在神经网络荒原上的长征。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibpJ08gskIzfop6hz3Fal6Pzib4NjmVLwTH6jMurebiafQovIpVXiafzHYlwEoua5OAvUwWuoZJVNc2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7111111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503523892" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1af9f84d-96bb-400f-814d-186482e88862/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 31 岁的 Hinton 与他的博士后同学 Chris Riesbeck&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;北上加拿大&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 70 年代和 80 年代，当 AI 领域被符号主义主导时，Hinton 就像一个孤独的异类。由于对罗纳德・里根时代美国国防部主导的军事资助感到失望，他做出了一个改变人生轨迹的决定：离开美国，北上加拿大。&lt;/p&gt;&lt;p&gt;除了政治原因，这背后还有一个鲜为人知的温情理由：当时他和妻子计划收养一对来自南美洲的儿女。他不希望在一个当时正暴力干涉拉美事务的国家抚养这些孩子。于是，他在多伦多大学扎根，在那里数十年如一日地在神经网络的「荒原」上耕耘，这也为后来加拿大成为全球 AI 重镇埋下了伏笔。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;学术成就&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Geoffrey Hinton 最著名的成就之一是与 David Rumelhart 和 Ronald Williams 共同发表了关于&lt;strong&gt;反向传播（Backpropagation）&lt;/strong&gt;的论文，解决了多层神经网络的训练难题，为后来深度学习的爆发埋下了伏笔。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibpJ08gskIzfop6hz3Fal6PALqLcHkpiab79b7gQzzHDrcb3qvRJTmfJ4T5kic1Rl359KBf5N0LxWLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7936962750716332" data-s="300,640" data-type="png" data-w="1047" type="block" data-imgfileid="503523888" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/94d0cf8d-b626-4df4-bd29-4b7583edf5bb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;但他的贡献远不止于此：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;玻尔兹曼机&lt;/strong&gt;（Boltzmann Machine）与&lt;strong&gt;受限玻尔兹曼机&lt;/strong&gt;（RBM）：为无监督学习和特征表示学习奠定了基础，可用于生成模型和预训练神经网络。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;深度信念网络&lt;/strong&gt;（DBN）：在 2006 年提出，通过逐层贪心训练方法有效训练深度神经网络，点燃了深度学习复兴的火种。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dropout&lt;/strong&gt;：一种简单而高效的正则化技术，通过随机「丢弃」神经元防止过拟合，成为大型神经网络训练的标准做法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;t-SNE&lt;/strong&gt;：一种高维数据可视化技术，用于将复杂数据嵌入低维空间，广泛用于理解深度学习特征表示。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分布式表示&lt;/strong&gt;（Distributed Representations）：强调分布式特征编码在学习系统中的重要性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;胶囊网络&lt;/strong&gt;（Capsule Networks）：提出对卷积神经网络中空间关系处理不足的问题的一种改进，通过「胶囊」表示和动态路由机制增强特征层次感知。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;混合专家模型&lt;/strong&gt;（MoE）：通过多个子网络（专家）协同工作并由路由器选择性激活，提高模型容量与计算效率，成为大规模模型的重要设计思路。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;知识蒸馏&lt;/strong&gt;（Knowledge Distillation）：提出将大型复杂模型（教师模型）的知识迁移到小型模型（学生模型），在保证性能的同时降低计算成本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;层归一化&lt;/strong&gt;（Layer Normalization）：改进深度网络训练稳定性和收敛速度的技术，对自然语言处理模型尤其重要。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;深度生成模型与概率图模型&lt;/strong&gt;：在生成模型领域提出了多种创新方法，为后续的变分自编码器（VAE）和生成对抗网络（GAN）奠定了理论基础。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;AlexNet 与 ImageNet 变革&lt;/strong&gt;： 他与学生 Alex Krizhevsky、Ilya Sutskever 共同推出了 AlexNet，在 ImageNet 竞赛中以绝对优势夺冠。这被公认为深度学习时代的「大爆炸」时刻，证明了深层卷积神经网络在海量数据和 GPU 算力下的统治力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Forward-Forward Algorithm&lt;/strong&gt;（前向 - 前向算法，2022）： 这是他在职业生涯后期对反向传播生物学合理性的反思与挑战，提出了一种更接近人脑运作机制的学习替代方案。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2018 年，他与 Yoshua Bengio 和 Yann LeCun 共同获得了计算机领域的最高荣誉：&lt;strong&gt;图灵奖&lt;/strong&gt;。这三人也常被称为「深度学习三巨头」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibpJ08gskIzfop6hz3Fal6Pnn1gWc8dU2wFqDDLjI9vKyhwDe0gapndm7wdNpm8QMicz9QAIvj889g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.54375" data-s="300,640" data-type="png" data-w="800" type="block" data-imgfileid="503523889" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/9209ee35-71c3-4a04-91b4-7fdc3129c0b7/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;值得注意的是，这三位图灵奖得主也是 Hinton 引用量第二高的论文《&lt;strong&gt;Deep learning&lt;/strong&gt;》的共同作者。该论文于 2015 年 5 月发表于 Nature，十年时间已经收获了超过 10 万引用量。其中系统总结了深度学习的发展历程、基本原理、关键算法（例如多层表征学习、反向传播、卷积神经网络和循环神经网络）以及其在语音识别、视觉识别、目标检测、基因组学等领域的广泛应用，标志着深度学习从学术探索迈向应用驱动的成熟阶段，被公认为推动该领域走向主流的里程碑性工作。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibpJ08gskIzfop6hz3Fal6P4EbLtUBsj1icjWjYdrZiam6RfqsgLTbCRQTliaWXefwoQQIezmaVgm6LA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.37222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503523891" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d76d0579-b8e6-4dbe-a390-7f0077f341d7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2024 年，Hinton 与 John Hopfield 共同获得了诺贝尔物理学奖，以表彰他们「实现了利用人工神经网络进行机器学习的奠基性发现和发明」。参阅报道《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650937189&amp;idx=1&amp;sn=0dd0e673b6ecbe994bed94c30b0a0035&amp;scene=21#wechat_redirect" target="_blank"&gt;刚刚，2024 诺贝尔物理学奖授予 Geoffrey Hinton、John Hopfield&lt;/a&gt;》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibpJ08gskIzfop6hz3Fal6PvucWg8AFPFtq9Gp1g6vrmRuhJIJQdkSKUNWuFz4gLyicwLQeqFtCADQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9790697674418605" data-s="300,640" data-type="png" data-w="860" type="block" data-imgfileid="503523894" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9945f443-870f-4f6e-9b15-a900a3e76bab/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;冷静的警示者&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;然而，这位「AI 教父」在晚年却不仅是一位技术布道者，更成为了一位冷静的警示者。&lt;/p&gt;&lt;p&gt;2023 年 5 月，他从工作了十年的谷歌离职，只为能「自由地谈论 AI 的风险」。他曾表示：「我想我现在对自己毕生的工作有一部分感到后悔。」他担忧数字智能可能会演变成一种比人类更优越的智能形式，并可能因缺乏控制而对人类构成生存威胁。他警告说：「如果你想知道不再是处于食物链顶端的智慧生物是什么感觉，去问问鸡就知道了。」&lt;img src="https://image.jiqizhixin.com/uploads/editor/d3d401b8-d9a5-48ce-bec9-197e06c0490e/1768530659519.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Alex Krizhevsky 与 Ilya Sutskever&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Hinton 浩如烟海的著作中，引用量最高的一篇无疑是 2012 年发表在 NeurIPS 上的奠基之作：《ImageNet classification with deep convolutional neural networks》。这篇论文目前的引用量已超过 18 万次（可能仅次于引用量近 30 万的 ResNet 论文和引用量超过 20 万的 Transformer 论文），它不仅标志着深度学习时代的正式开启，也让两位共同作者的名字响彻云霄：&lt;strong&gt;Alex Krizhevsky&lt;/strong&gt; 和 &lt;strong&gt;Ilya Sutskever&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;作为 Hinton 的两名得意门生，他们在那间多伦多大学的实验室里，共同推开了 AI 新世界的大门。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibpJ08gskIzfop6hz3Fal6PTtYT7rjb3foxvVsjR1P9SOVT7WsJHMazwZHia2RcxUzfQSsyicqia6rMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6602941176470588" data-s="300,640" data-type="png" data-w="680" type="block" data-imgfileid="503523893" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/457ba80b-4a1a-4702-8a69-51dfc5e342e4/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; Alex Krizhevsky 与 Ilya Sutskever 是 Geoffrey Hinton 引用量最高的论文的第一和第二作者。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Alex Krizhevsky：低调的隐士天才&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为那篇传奇论文的第一作者，Alex Krizhevsky 是 AlexNet 的主要构建者。正是他编写了关键的 CUDA 代码，让神经网络得以在两块 GeForce GPU 上高效训练，从而在 2012 年的 ImageNet 挑战赛上以惊人的 10.8% 优势碾压第二名，一举震惊世界。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibpJ08gskIzfop6hz3Fal6PtPicpia3UwvlAIWMNAjf4ic4NDzmoszTmic3vO39MfVv4YwgMXyoROsS9Q/640?wx_fmt=webp&amp;from=appmsg#imgIndex=9" data-ratio="0.5615696887686062" data-s="300,640" data-type="webp" data-w="739" type="block" data-imgfileid="503523898" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/f9e0959f-abe1-4f36-a6d0-a024f262c7d3/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;然而，与他在学术界的赫赫声名形成鲜明对比的是他极度低调的性格。Alex 出生于乌克兰，成长于加拿大。他被很多同行描述为一位「纯粹的工程师」，拥有极深的技术洞察力。在谷歌工作了数年后，他于 2017 年离职，理由是「对工作失去了兴趣」。&lt;/p&gt;&lt;p&gt;此后，他加入了初创公司 Dessa，随后又逐渐淡出公众视野。据悉，他目前可能已处于半退休状态，享受着徒步旅行的乐趣。在科技圈追逐名利的热潮中，Alex Krizhevsky 就像一位事了拂衣去的隐士。尽管 AlexNet 如今在技术上已被更新的模型取代，但正如一位评论者所言：「没有他，就没有今天的 ChatGPT，没有便捷的 3A 大作，也没有先进的医学影像分析。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Ilya Sutskever：执着的 AI 愿景者&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 Alex 是低调的技术天才，那么该论文的第二作者 Ilya Sutskever 则是充满使命感的 AI 领袖。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibpJ08gskIzfop6hz3Fal6P7LePveljFibC5RwGpqtnibHW9EX7VicWHAdWgquogOCZsCAmBWhXdb2sA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.5626822157434402" data-s="300,640" data-type="jpeg" data-w="686" type="block" data-imgfileid="503523899" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/bca6a09e-9f65-445f-a53d-95f1c52894ca/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Ilya 同样出生于前苏联（俄罗斯），并在以色列和加拿大长大。在多伦多大学期间，他与 Hinton 和 Alex 共同缔造了 AlexNet 的辉煌。随后，他在 Google Brain 参与了序列到序列（Seq2Seq）学习算法和 TensorFlow 的开发，并是 AlphaGo 论文的众多作者之一。&lt;/p&gt;&lt;p&gt;2015 年，Ilya 离开谷歌，作为联合创始人兼首席科学家创办了 OpenAI。他是 ChatGPT 和 GPT-4 诞生的关键人物，被誉为能够「通过直觉看到深度学习未来」的人。然而，他对 AI 安全的关注也日益加深。2023 年，他曾主导了 OpenAI 董事会罢免 Sam Altman 的风波，理由是「沟通不坦诚」，尽管后来 Altman 复职，Ilya 对 AI 对齐（Alignment）和安全超级智能（SSI）的执着从未改变。&lt;/p&gt;&lt;p&gt;2024 年，Ilya 成立了新公司 Safe Superintelligence Inc. (SSI)，并为其筹集了 10 亿美元资金。与商业化气息浓厚的硅谷公司不同，SSI 宣称其「第一个产品将是安全的超级智能，在此之前不会做任何其他事情」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Geoffrey Hinton 引用量突破百万，不仅是他个人学术生涯的高光时刻，也是 Alex Krizhevsky 和 Ilya Sutskever 等一代 AI 杰出人才共同奋斗的缩影。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibpJ08gskIzfop6hz3Fal6PhROFKPPyeT2Tv1hiaibaZON9xok21Hpw7JfD5tS5dQ0n0EFfyLiaF59kQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.6564814814814814" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503523895" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/022a446f-6c3a-4bd3-98b2-8bb8d6847885/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从 Alex 编写的那行 CUDA 代码，到 Ilya 对通用人工智能（AGI）的深邃构想，再到 Hinton 对神经网络半个世纪的坚守与晚年的忧思，这一里程碑背后，是人类探索智能本质的波澜壮阔的历史。&lt;/p&gt;&lt;p&gt;今天，我们致敬 Hinton，也致敬所有为这一刻铺路的研究者。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://scholar.google.com/citations?user=JicYPdAAAAAJ&amp;amp;hl=en&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.youtube.com/watch?v=giT0ytynSqg&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.britannica.com/biography/Geoffrey-Hinton&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.nobelprize.org/prizes/physics/2024/hinton/podcast/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>腾讯AngelSlim升级，首个集LLM、VLM及语音多模态为一体的投机采样训练框架，推理速度飙升1.8倍</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 10:24:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/fdb3895e-e15b-4dbd-9468-5d71ad7fa81a/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着大模型步入规模化应用深水区，日益高昂的推理成本与延迟已成为掣肘产业落地的核心瓶颈。在 &amp;ldquo;降本增效&amp;rdquo; 的行业共识下，从量化、剪枝到模型蒸馏，各类压缩技术竞相涌现，但往往难以兼顾性能损耗与通用性。&lt;/p&gt;&lt;p&gt;在此背景下，&lt;strong&gt;投机采样&lt;/strong&gt;作为一种 &amp;ldquo;另辟蹊径&amp;rdquo; 的推理加速范式，正凭借其近乎无损的加速效果成为业界新宠。腾讯混元近日升级的 &lt;strong&gt;AngelSlim 训练框架&lt;/strong&gt;，首次将这一技术的潜力拓展至 LLM、VLM 及语音的全模态场景，实现了从 &amp;ldquo;可加速&amp;rdquo; 到 &amp;ldquo;善加速&amp;rdquo; 的关键跃迁。其核心在于独创的 &lt;strong&gt;Eagle3 训练架构&lt;/strong&gt;，通过让小模型学会 &amp;ldquo;前瞻性&amp;rdquo; 地为大模型起草多步候选 token，再由大模型并行验证，一举将大模型解码阶段的算力冗余转化为提速动能，实测最高可带来 &lt;strong&gt;1.9 倍的推理速度飙升&lt;/strong&gt;。这不仅是一次技术升级，更是对下一代高效推理基础设施的重要定义，为多模态 AI 应用的实时化、普惠化铺平了道路。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、AngelSlim + 投机采样&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;投机采样是一种通过&lt;strong&gt;小模型多步预测 + 大模型一步验证&lt;/strong&gt;的推理加速技术，其核心思想是：使用一个轻量级的草稿模型生成多个候选 token，由目标模型对候选结果进行并行验证是否接受，以此来并行解码加速，在有效利用大模型解码阶段的算力冗余，提升推理吞吐并降低单请求延迟。&lt;/p&gt;&lt;p&gt;AngelSlim 是一款集成了包括量化、投机采样等压缩算法，面向全模态的大模型压缩算法工具包。此次对投机采样训练进行了重磅升级，支持了大语言、多模态理解、语音等不同模态大模型投机采样草稿模型训练能力。&lt;/p&gt;&lt;p&gt;AngelSlim 以 &amp;ldquo;&lt;strong&gt;Eagle3 训练即部署&lt;/strong&gt;&amp;rdquo; 为设计核心，提供从数据处理、模型封装到投机采样算法训练的完整链路，帮助开发在不侵入现有模型结构的前提下，显著降低推理时延与计算成本，各模态、各类大模型加速可达 1.4-1.9 倍。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsadVQBnZ1l3jNnmIpyaycSsfWzOAiaZILtlZ8OiastP5UkxHUYGKpAFDUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.562037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528170" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/79ab0608-0ef6-4a81-8661-20a743402ee9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Github 开源地址：https://github.com/Tencent/AngelSlim&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、核心亮点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 覆盖从文生文、多模态理解到语音的全模态投机采样训练&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AngelSlim 是一个从设计之初就支持全模态的投机采样训练框架，通过统一的训练接口，不同模态之间共享核心算法与工程能力，避免重复造轮子。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 面向部署&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AngelSlim 并不止步于 &amp;ldquo;能训&amp;rdquo;，而是强调训出来就能用。AngelSlim 训练产出的模型可以无缝用于 vLLM/Sglang 等框架进行部署。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、核心训练组件解析 &lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAvPGN0Qq82V8jGSeNlNKh5GIw4Ll2RWA3DBySly9j5sNwx5faABDQmQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.2601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528020" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8704ff60-c4f7-4f48-b690-ca84584d17a9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;1. 数据处理模块&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaibibRfrda8FurLlibnKt4TVhh2NedCwDiaKJFqMOVshFOPpLPAA58YpOhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4027777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528158" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ac37f7ab-656d-4e8c-8c20-7fea0ac01b4a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;数据处理模块为投机采样训练多个模态提供稳定、可复用的数据基础，主要包括：&lt;/p&gt;&lt;p&gt;a. 数据重采样：针对分布外数据集重新采样，生成分布内数据集用以训练。&lt;/p&gt;&lt;p&gt;b. 数据预处理：&lt;/p&gt;&lt;p&gt;i. 统一不同模态的数据格式，将文本、图像、音频等输入标准化处理成 token ids 和 loss mask。&lt;/p&gt;&lt;p&gt;ii. 草稿模型裁剪词表的映射。&lt;/p&gt;&lt;p&gt;c. 隐藏特征提取：根据处理好的 token ids 获取对应的隐藏特征。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsax2X7SsjNjwJAicbX6zTzJM1Zj2whwcvgB7YapLmkiaLwPPEfrQtChyPw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8527777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528171" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a301352c-5d1c-4ba5-a57e-709c7d9b9d9f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. 模型模块&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;模型模块是 AngelSlim 实现高度扩展性的关键。&lt;/p&gt;&lt;p&gt;a. 统一的 TargetModel 接口&lt;/p&gt;&lt;p&gt;i.AngelSlim 提供统一的 TargetModel 接口，包括模型加载与权重管理、前向计算、中间层 / 隐状态特征提取等抽象方法；&lt;/p&gt;&lt;p&gt;b. 低成本扩展新的模型后端&lt;/p&gt;&lt;p&gt;ii. 对于新的模型架构或后端，用户只需实现 TargetModel 中定义的抽象方法即可完成模型注册并接入训练流程，无需修改训练器或核心算法代码。这一设计极大降低了对新模型、新模态的适配成本。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAIS1SpUTy6jlfcaur8ianvaIzPtC9v8AiaNpOCLD1OwS8tS0Mu4hia1R7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.48055555555555557" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528028" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f4f5cae1-59cb-4d25-ac7f-711ada7decae/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 训练器模块&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;a. 训练器针对 Eagle3 算法特点设计了两种训练模式：在线训练和离线训练。在线与离线训练的区别在于是否预先生成并存好全量数据的 hidden states。在线训练适合小尺寸模型或显存足够的场景，离线训练适合大尺寸模型、低显存高磁盘空间机器。&lt;/p&gt;&lt;p&gt;b. 训练器实现封装了 Eagle3 等投机采样算法训练的关键逻辑：&lt;/p&gt;&lt;p&gt;i. 训练时测试（training-time-test）：训练时模拟 Eagle3 模型多步生成过程，让 Eagle3 模型看到并学习使用自己的预测。&lt;/p&gt;&lt;p&gt;c. 训练器原生支持断点续训能力，完整保存并恢复：&lt;/p&gt;&lt;p&gt;i. 草稿模型参数&lt;/p&gt;&lt;p&gt;ii.Optimizer/ LR Scheduler 状态以及训练进度&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、实践与部署&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 快速开始&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当安装好 AngelSlim 后，进入 AngelSlim 根目录按照如下命令可以快速开始 Eagle3 的训练：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="bash"&gt;&lt;code&gt;# 启动vLLM 服务&lt;/code&gt;
&lt;code&gt;bash scripts/speculative/run_vllm_server.sh&lt;/code&gt;
&lt;code&gt;# 生成训练数据&lt;/code&gt;
&lt;code&gt;bash scripts/speculative/generate_data_for_target_model.sh&lt;/code&gt;
&lt;code&gt;# 开始在线训练&lt;/code&gt;
&lt;code&gt;bash scripts/speculative/train_eagle3_online.sh&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;其中前两条命令是准备数据，对训练数据进行重采样，生成目标模型分布内的数据。这一步是可选项，如果训练数据已经是来自目标模型的 SFT 数据或自身生成的数据，这一步可跳过。对 Eagle3 模型进行训练直接执行最后一条命令即可，更多进阶的使用指南可以参见我们的文档。&lt;/p&gt;&lt;p&gt;我们提供了全面的多模态模型 Eagle3 训练与部署指南，支持 LLM / VLM / Audio (ASR &amp;amp; TTS) 模型。&lt;/p&gt;&lt;p&gt;详见：https://angelslim.readthedocs.io/zh-cn/latest/features/speculative_decoding/eagle/eagle.html&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.AngelSlim 训练模型的加速表现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们使用 vLLM 在代码、数学、指令跟随、文本生成、多模态理解等任务上评测了 AngelSlim 所训练的 Eagle3 模型，设置 num_speculative_tokens=2 or 4 下我们所训的模型接收长度可达 1.8-3.5，最高加速可达 1.4-1.9 倍。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaXdAQ10m2nGj1gYJcodovzsH8jGibLgduQwymYHZ7YawrGkOqiauz92vg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5953703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528159" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5939823f-d258-4a6f-83e2-a3e27521fcfb/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 代码和模型链接&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AngelSlim 代码 Github 开源仓库：https://github.com/Tencent/AngelSlim&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hugging-Face Eagle3 模型与权重：https://huggingface.co/collections/AngelSlim/eagle3&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;五、未来计划&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在未来规划中，我们将从工具与算法两个层面持续推进投机采样能力演进：工具方面，计划支持基于 vLLM 的离线 hidden states 生成，以进一步降低数据构建与训练成本，并通过系统性的训练加速优化提升整体训练效率；算法创新方面，将探索多模态理解与语音输入信息在 Eagle3 模型中的深度融合，统一建模文本、视觉与语音特征，拓展投机采样在全模态场景下的适用性与加速潜力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>DeepSeek连发两篇论文背后，原来藏着一场学术接力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 10:19:55 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4dc25181-b5e0-4d5f-a42e-139036252ddd/1768529804267.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2026 年 1 月过半，我们依然没有等来 DeepSeek V4，但它的模样已经愈发清晰。&lt;/p&gt;&lt;p&gt;最近，DeepSeek 连发了两篇论文，一篇解决信息如何稳定流动，另一篇聚焦知识如何高效检索。&lt;/p&gt;&lt;p&gt;第一篇论文（&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651010187&amp;idx=1&amp;sn=cc9ae88f676873468dcfc98d54e98aa9&amp;scene=21#wechat_redirect" target="_blank"&gt;mHC&lt;/a&gt;）出来的时候，打开论文的人都表示很懵，直呼看不懂，让 AI 助手用各种方式讲给自己听。我们也翻了翻网友的讨论，发现理解起来比较透彻的办法其实还是要回到研究脉络，看看这些年研究者们是怎么接力的。要理解第二篇论文（&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651011743&amp;idx=1&amp;sn=34e666de69c7ad8166d2d46a4f8938fc&amp;scene=21#wechat_redirect" target="_blank"&gt;Conditional Memory&lt;/a&gt;）也是如此。&lt;/p&gt;&lt;p&gt;于是，我们就去翻各路研究者的分析。这个时候，我们发现了一个有意思的现象：DeepSeek 和字节 Seed 团队的很多工作其实是存在「接力」的 &amp;mdash;&amp;mdash;&lt;strong&gt;mHC 在字节 Seed 团队 HC（Hyper-Connections）的基础上进行了重大改进；Conditional Memory 则引用了字节 Seed 的 OverEncoding、UltraMem 等多项工作&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;如果把这些工作之间的关系搞清楚，相信我们不仅可以加深对 DeepSeek 论文的理解，还能看清大模型架构创新正在往哪些方向突破。&lt;/p&gt;&lt;p&gt;在这篇文章中，我们结合自己的观察和学界专家的点评，尝试为大家梳理了一下。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;残差连接的十年接力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要理解 mHC，得先回到 2015 年。&lt;/p&gt;&lt;p&gt;那一年，AI 大牛何恺明等人提出了 ResNet，用残差连接解决了深度神经网络训练中的老大难问题：网络层数一多，信息从前往后传递时会逐渐失真，到最后几层几乎学不到东西。残差连接的思路很简单，每一层不光接收上一层处理过的结果，还同时保留一份原始输入，两者加在一起再往下传。&lt;/p&gt;&lt;p&gt;这个设计堪称深度学习的基石，十年来几乎所有主流深度网络架构都以残差连接为默认配置。从视觉领域的各类 CNN，到自然语言处理领域的 Transformer，再到如今的大语言模型，无一例外。&lt;/p&gt;&lt;p&gt;期间，研究者们大多在注意力机制、归一化方法、激活函数等方面做了大量改进，但残差连接的基本形式几乎没有根本性变化。&lt;/p&gt;&lt;p&gt;直到 2024 年 9 月，字节 Seed 提出了 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650941988&amp;idx=2&amp;sn=1b35f2af9982c529a1c9217bfab24a02&amp;scene=21#wechat_redirect" target="_blank"&gt;HC&lt;/a&gt;，论文后来被 ICLR 2025 接收。&lt;/p&gt;&lt;p&gt;HC 的核心创新在于显著提升了网络的拓扑复杂度，同时不改变单个计算单元的 FLOPs 开销。这意味着在相同的计算预算下，模型可以探索更丰富的特征组合方式。&lt;/p&gt;&lt;p&gt;中国人民大学长聘副教授、博士生导师刘勇认为：&lt;strong&gt;HC 打破了由 ResNet 统治的恒等映射残差连接传统，提出了多路并发连接的新范式。&lt;/strong&gt;它通过引入宽度动态性和跨层特征聚合，证明了通过增加残差路径的特征维（Expansion）和引入可学习的 Dynamic Hyper Connections 可以有效缓解 Representation Collapse 的问题并提升大语言模型的预训练效率，提供了一个超越传统残差网络的全新架构底座，即不再局限于单路径的特征叠加，而是通过超连接构建一个更高维、更灵活的特征流动空间。&lt;/p&gt;&lt;p&gt;DeepSeek 在 mHC 论文中表示：近年来，以 Hyper-Connections（HC）（Zhu et al., 2024） 为代表的研究，为残差连接引入了一个新的维度，并在实验上验证了其显著的性能潜力。HC 的单层结构如图 1 (b) 所示。通过扩展残差流的宽度并提升连接结构的复杂性，HC 在不改变单个计算单元 FLOPs 开销的前提下，显著提升了网络的拓扑复杂度。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDPYzibK7O47ktlVpGcV2SM8HpJeWJtx92Kk2JX0XgthUVgicgpRj9BYCQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.687962962962963" data-type="png" data-w="1080" data-width="1160" data-height="798" data-imgfileid="503528535" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2a29df81-262a-42a4-936e-bd3e5e7781d3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可以看出：字节 Seed 提出的「扩展残差流宽度 + 可学习连接矩阵」这一新的架构范式，构成了其后续方法设计的重要基础，相关工作正是在这一范式框架内进一步展开的。&lt;/p&gt;&lt;p&gt;但 HC 在走向大规模训练的过程中遇到了瓶颈，导致训练不稳定和受限的可扩展性。尽管如此，但其为后续研究指明了方向。刘勇认为，HC 论文为 mHC 研究提供了三个核心思路：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;首先是&lt;strong&gt;宽度扩展（Stream Expansion）&lt;/strong&gt;，即通过将残差流维度扩大（如扩大至 4 倍或更多），能够显著增强模型的容量和学习能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其次是&lt;strong&gt;多尺度连接的权重化&lt;/strong&gt;，通过引入可学习矩阵来分配不同层级特征的贡献，启示了连接权重管理（mHC 中的&amp;nbsp;Sinkhorn-Knopp&amp;nbsp;算法）的重要性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后是&lt;strong&gt;动态拓扑的潜力&lt;/strong&gt;，论文展示了模型可以根据深度动态调整特征流向，这种软拓扑结构为解决深层网络训练难点提供了新视角。这些探索让 mHC 意识到，虽然拓扑结构的复杂化能带来增益，但也必须解决随之而来的训练稳定性与工程效率问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;正是基于这些探索，DeepSeek 团队得以明确 mHC 的研究方向：在继承 HC 架构优势的同时，针对性地解决其规模化瓶颈。&lt;/p&gt;&lt;p&gt;刘勇指出：mHC 针对 HC 在大规模部署时暴露的稳定性风险和内存访问开销进行了针对性改进。在&lt;strong&gt;研究思路上&lt;/strong&gt;，mHC 延续了 HC 的宽度扩展与多路径聚合，并进一步通过 Sinkhorn-Knopp 等技术手段，施加流形约束，将 HC 的广义空间投影回特定流形，从而在保留 HC 性能优势的同时，重新找回了残差网络至关重要的恒等映射特性，解决了 HC 在超大规模训练时的不稳定性。在&lt;strong&gt;工程层面&lt;/strong&gt;，mHC 中提出了更高效的内核优化（Infrastructure Optimization），使该范式从理论实验走向了万亿级参数规模的工业级应用。&lt;/p&gt;&lt;p&gt;基于这些改进，mHC 不仅解决了稳定性问题，且在大规模训练中（如 27B 模型）表现出卓越的可扩展性。&lt;/p&gt;&lt;p&gt;我们不难发现，mHC 解决了 HC 在大规模训练中的工程瓶颈。通过引入流形约束，mHC 在保留 HC 架构优势的同时恢复了训练稳定性，使得这一新范式真正具备了在主流大模型训练中应用的条件。&lt;/p&gt;&lt;p&gt;有网友认为：DeepSeek 提出的 mHC 是对字节 Seed HC 训练架构技巧的一次颇具说服力的推进。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDUr1PuE81VotNDvvRpib8yc0Z2KfWXAg0c84LWY5Dzmvbjco3Iibu7CJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6844221105527638" data-type="png" data-w="995" data-width="995" data-height="681" data-imgfileid="503528536" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f470e310-03a6-47e3-a4c3-19143c3e795d/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从 2015 年残差连接问世，到 2024 年字节 Seed 提出 HC，再到 2026 年 DeepSeek 提出 mHC，我们清楚地看到残差连接在算法上的演进，是不同机构、研究者持续接力和优化的结果。&lt;/p&gt;&lt;p&gt;而在 DeepSeek 发布的另一篇论文中，我们看到了几乎相同的模式再次上演。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;都用 N-gram，字节 Seed、DeepSeek 接连导出新结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;和 mHC 论文的「抽象」感不同，「Conditional Memory」论文解决的问题比较好理解：大模型被问到的很多问题是可以直接查表解决的，比如「法国的首都是哪里」，但由于标准 Transformer 缺乏原生的知识查找原语，即使这样简单的问题，模型也得去计算，就像你上了考场还要自己推导公式，这无疑是一种浪费。&lt;/p&gt;&lt;p&gt;对此，「Conditional Memory」论文提出的解决方案是给模型装一个「小抄本」（Engram），常见的词组直接查表，省下来的算力用来做更复杂的推理。&lt;/p&gt;&lt;p&gt;具体来说，Engram 的做法是：给模型配一个巨大的「词组词典」，当模型读到某个词（比如「Great」时，就把它前面几个词拼成 N-gram（比如「the Great」或「Alexander the Great」），然后用哈希函数把这个 N-gram 变成一个数字，直接去词典里查对应的向量。&lt;/p&gt;&lt;p&gt;这个「N-gram 哈希查表」的做法，字节 Seed 之前也用过。在提出&amp;nbsp;&lt;strong&gt;OverEncoding 方法&lt;/strong&gt;的论文（题为「Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling」）中，他们发现：给模型配一个巨大的 N-gram 词典，几乎是「白捡」的性能提升。为什么说白捡？刘勇分析说，因为&lt;strong&gt;这&lt;/strong&gt;&lt;strong&gt;些海量的嵌入参数是稀疏激活的，每次推理只查其中极少数，所以既不怎么吃显存，也不怎么费算力。&lt;/strong&gt;更重要的是，论文发现词典越大、性能越好，而且提升幅度是可预测的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDG1Gw1ohKRqQdHDBHKp8bY7ltngtf1ChrEN0qZtp8KcfTAiaQKuEGE9g/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7305555555555555" data-type="png" data-w="1080" data-width="1776" data-height="1298" data-imgfileid="503528537" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c3545c1a-01a6-488c-a31d-69e5462d76f9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文地址：https://arxiv.org/pdf/2501.16975&lt;/p&gt;&lt;p&gt;如果说字节 Seed 论文用实验告诉我们「把输入词表加大就能涨分」，DeepSeek 论文则另开一条赛道：把 N-gram 做成外挂存储 Engram，与 MoE 分工，正式提出「条件存储」这条新轴线，并告诉我们该怎么分参数才最划算。&lt;/p&gt;&lt;p&gt;还是回到考场的比喻：字节 Seed 发现给学生发公式手册成绩会提高，于是得出结论 &amp;mdash;&amp;mdash;「大词表是更好的输入表示」。DeepSeek 则进一步追问：这种做法还能以什么方式提高成绩？他们通过 LogitLens 等工具进行机制分析，发现这种 lookup 机制能将模型从繁重的局部静态模式重建中解放出来，使早期层直接获得高阶语义，从而增加了模型的有效推理深度。&lt;/p&gt;&lt;p&gt;基于这个洞察，DeepSeek 不再仅仅将 N-gram 视为简单的词表扩展，而是将这一实验性结论升华为「条件存储」（Conditional Memory），这是一条与条件计算（MoE）并列的 scaling law 新轴线。在此基础上，他们提出了「稀疏分配」（Sparsity Allocation）问题：在固定参数预算下，如何在 MoE 专家与静态存储模块之间分配参数？实验揭示了一条 U 型缩放规律 &amp;mdash;&amp;mdash; 全押 MoE 并非最优解，将约 20%-25% 的参数分配给 Engram 反而效果更好。&lt;/p&gt;&lt;p&gt;刘勇表示，在工程实现上，DeepSeek 也进行了系统性的技术改良。架构层面，它改进了前作仅在输入层（Layer 0）注入信息的局限，将 Engram 模块注入到模型的中间层，使存储访问与深度计算实现并行与融合。交互机制上，它放弃了简单的嵌入加和，引入了「上下文感知门控」，利用隐状态动态调节检索结果。系统优化上，它通过分词器压缩提高存储效率，并利用硬件层面的预取技术（Prefetching）解决海量参数导致的延迟问题，使该技术真正具备了大规模工业落地的能力。&lt;/p&gt;&lt;p&gt;在论文的 3.2 章节，我们发现，DeepSeek 把自己的 Engram 与字节 Seed 的 OverEncoding 方法进行了对比，指出虽然两者都能从更大的嵌入表中获益，但在相同的参数预算下，Engram 的缩放效率明显更高。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDRgicuxvDYLLG5rcicO3pMLVfNicWw5ZicNKH01E0zgFKZibb2GOUSAP4XTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5212962962962963" data-type="png" data-w="1080" data-width="1568" data-height="818" data-imgfileid="503528541" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c2e6d714-3ed5-4ecd-81dd-8622ab2df3b3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;一起上分、互相启发 &amp;nbsp;研究发表的意义具象化了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;每次 DeepSeek 一发论文，推特上都能引发不小的轰动，有位博主甚至提到他搭乘的飞机上有 30% 的人都在看 DeepSeek 刚发的论文。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDuiaA53s7ehhXFKf4ZYLgcsHziaILAZnDV6ayb3jElWXhRbNHDoIcrEBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0944444444444446" data-type="png" data-w="1080" data-width="1186" data-height="1298" data-imgfileid="503528539" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f940bdf1-5b1d-4bf8-a22a-96279f4e7c43/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;归根结底，这反映出一个问题 &amp;mdash;&amp;mdash; 目前还愿意公开自己研究成果、带着大家一起「上分」的头部大模型厂商已经越来越少了。DeepSeek 和字节 Seed 在研究上的接力让我们看到了公开研究成果的价值。&lt;/p&gt;&lt;p&gt;同时，DeepSeek 对于社区内优秀成果的挖掘也给了我们一些启发，类似字节 Seed 这样的国内头部大模型团队其实有很多想法值得继续探索。&lt;/p&gt;&lt;p&gt;比如，在架构层面，除了前面提到的 OverEncoding，DeepSeek 论文中还提到了几篇字节 Seed 的相关研究，包括稀疏模型架构 UltraMem 和它的新版本 Ultramemv2。这个全新的模型架构通过分布式多层级联内存结构、Tucker 分解检索与隐式参数扩展优化，有效解决了传统 MoE 架构在推理阶段的高额访存问题，同时验证了其优于传统架构的 Scaling Law 扩展特性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD4DoXCPEO9rd4KDf0BgGQLLcaX5WUwEQ5DBgsibvJLG26yUeAib5EEYQQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.2361111111111111" data-type="png" data-w="1080" data-width="1346" data-height="318" data-imgfileid="503528540" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c1069c3a-9cd9-41d3-aae7-6555b851b1d1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，字节 Seed 在基础研究上还发表过很多大胆探索全新范式的尝试，比如&lt;strong&gt; Seed Diffusion Preview&lt;/strong&gt;，系统性地验证离散扩散技术路线作为下一代语言模型基础框架的可行性；&lt;strong&gt;SuperClass&lt;/strong&gt;，首次舍弃了文本编码器，直接用原始文本的分词作为多分类标签，在视觉任务上效果优于传统的 CLIP 方法；甚至提出了新型神经网络架构 &lt;strong&gt;FAN&lt;/strong&gt;，通过引入傅里叶原理思想，弥补了 Transformer 等主流模型在周期性建模方面的缺陷。&lt;/p&gt;&lt;p&gt;这些底层技术的研究，虽然在短期内无法用于商业模型的训练，但是科技行业的进步，正是在无数研究者对未知领域的探索中发生的。&lt;/p&gt;&lt;p&gt;毕竟，真正推动技术进步的，从来不是单一的突破，而是持续的积累与相互启发。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>仅需一个混频器的无线射频机器学习推理，登上Science Advances！</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 16 Jan 2026 10:15:03 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-16</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-16</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/252567e8-dbe4-482f-b630-8808af1866e3/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="2" data-pm-slice="0 0 []"&gt;&lt;strong&gt;本文作者包括来自杜克大学的高智辉、陈廷钧教授和 MIT 的 Dirk Englund 教授团队。&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"data-path-to-node":"26","style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;高智辉，杜克大学电子与计算机工程系博士生。本科毕业于复旦大学电子工程系。研究兴趣于下一代网络系统，包括信息物理系统、机器学习加速等。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicZgK0FZiaiapjhMWLHYdoBX0aoezPry02VS3TNYibEQ2ibzWR4K3dJOjKXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2111111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528311" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3af36de2-b64a-4ae0-80bc-3547ef1783f7/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Disaggregated machine learning via in-physics computing at radio frequency&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://www.science.org/doi/10.1126/sciadv.adz0817&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["list",{"type":"ul","style":"list-style-type: disc;margin-left: 8px;margin-right: 8px;","class":"list-paddingleft-1","start":null},"listitem",{"style":""},"para",{"tagName":"p","attributes":{"style":"text-align: left;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;开源代码：https://github.com/functions-lab/WISE&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;模型-数据的分解式计算&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="5"&gt;机器学习部署在边端设备的时候，模型总是存储在云端服务器上（5G 基站），而模型输入输出总是在边端设备上（例如用照相机拍摄照片然后识别其中的目标）。在这种场景下，传统有以下两种方案完成机器学习的推理：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;方案一：上传模型输入到云端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种方案需要每个用户分别把自己的模型输入上传到云端，然后在云端完成推理，最后把模型输出下载到各个用户。&lt;/p&gt;&lt;p&gt;这种方案需要消耗大量的带宽资源，尤其是在大用户规模的情形下；其次，这种上传用户模型输出的方案会涉及用户隐私泄露的问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;方案二：广播模型下载到边端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种方案要求是云端服务器把模型广播给所有的用户，每个用户各自存储模型，并且在边缘端进行计算。&lt;/p&gt;&lt;p&gt;这种方案极大挑战了边缘用户的算力，并且在模型存储的过程中还有边端存储读写的开销。&lt;/p&gt;&lt;p&gt;在我们的工作里，我们提出了第三种分离式计算（disaggregated computing）的方案：&lt;strong&gt;广播模型并在射频上完成计算&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD9mVdhV4Vu1bphrp9woiceSia8enELUIOQEuKBxhiaPwXc9icU4LSQTJPDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.32685185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528371" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b87ad115-d623-4dc1-a5be-a28ac29700dd/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;在这种方案里，模型存储在云端并且在射频上广播，用户也把模型输入调制到射频上。所有的计算都在边缘端的混频器（frequency mixer）的模拟计算中完成，混频器输出直接就是模型的输出。&lt;/p&gt;&lt;p&gt;这种方案成功解决了上述两种方案的问题：模型不需要存储在边缘端，所以没有存储读写的开销；混频器是所有带网络连接功能的边缘设备的必备元件，并且是无源的，所以功耗极低。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicWaicoQuHpsLKCPuWuoYmicjzdUguva7iaRiacExeJWCKEhibYde3gPBDE7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3138888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528298" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d30475e3-6501-44ee-b106-8d117387c92a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="9"&gt;&lt;b data-index-in-node="0" data-path-to-node="9"&gt;利用混频器进行矩阵向量乘&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;混频器的本质是一个时域上乘法器。它把收到的射频信号和本地震荡器产生的信号相乘，输出就是解调后的基带信号。在我们的工作中，我们把射频信号换成了广播的模型，本地震荡器的信号换成了模型输入，于是混频器的输出就成了模型的输出。&lt;/p&gt;&lt;p&gt;在数字信号处理中，时域上的乘法就是频域上的卷积。当我们把模型推理过程抽象成矩阵向量乘 y = Wx 的时候，我们就可以用卷积来完成这个矩阵向量乘。&lt;/p&gt;&lt;p&gt;另外，我们还需要提前在云端测量无线信道 H。在发送的时候就预调制一个无线信道的逆变成 V，这样通过无线信道后在边缘端接收到的信号就变成了我们希望得到的 W。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDvorJfNiazjOutFLU4MtmCHvict0kWicHfrlmTTJgQcCzwUJXydicic5Kib5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.42685185185185187" data-type="png" data-w="1080" data-width="5591" data-height="2387" data-imgfileid="503528376" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6d241582-6729-4738-88d5-335e69a48067/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;&lt;b data-index-in-node="0" data-path-to-node="12"&gt;在测试平台上的实验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们实现了一台云端服务器广播给三个边缘设备的机器学习推理。我们在软件定义测试平台（software-defined radio testbed）上进行实验验证，其中我们使用 USRP X310 作为主要的无线收发机，外接 ZEM-4300+ 作为主要的混频器。&lt;/p&gt;&lt;p&gt;我们使用了 915 MHz 的频率和 25 MHz 的带宽来无线广播模型。&lt;/p&gt;&lt;p&gt;我们先考虑了通用复数域的 4096 点的向量内积进行计算精度的测试，实验上得到的最高计算精度能达到 5.5 bit，对于大部分机器学习推理已经足够。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicUd5KxPSeWHcaMA3p8j2A078x7BLTUMgI0EFOcOPibiawGuWAmaQzVL5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3675925925925926" data-type="png" data-w="1080" data-width="6045" data-height="2222" data-imgfileid="503528312" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a5bb65c8-17e6-47cc-8a03-7020497c98a2/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="14"&gt;&lt;b data-index-in-node="0" data-path-to-node="14"&gt;计算能耗分析&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="15"&gt;考虑一个输入维度是 N，输出维度是 M 的矩阵向量乘，我们的模拟计算架构能耗来源于三个部分：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="16,0,0"&gt;数模转换器（DAC）：用于产生模型输入的信号 x，复杂度是 O(kMN)。这里的 k 取决于整个系统的能量效率（例如混频器的插入损失、接收器的噪声系数等），且远小于 1。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,1,0"&gt;模数转换器（ADC）：用于采样模型输出的信号 y，复杂度是 O(N)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,2,0"&gt;解码器：使用 FFT 把输出的信号 y转到频域，并且提取出最终的模型输出 y，复杂度是 O(N)。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上所述，整个系统的能量消耗是 O(M + kMN) 对整个矩阵向量乘；均摊到一个乘累加（MAC）上就是 O(1/N + k)。也就是说，计算的矩阵向量乘规模越大，单个乘累加的能耗越低。&lt;/p&gt;&lt;p&gt;在我们的实验平台上，我们实现了最高到 32768 点的向量内积，能耗可以达到飞焦级，比传统的数字计算（皮焦级）低了 2~3 个数量级。&lt;a href="https://mp.weixin.qq.com/s/II5PcGZG5fk-NumDiD4Spg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/cc3b44b5-f7aa-44dc-892c-0ae745057b3a/1768529582938.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDF9YYkx0c6ko5rcpvPMUUqicm1muEpwOIEQz4mkM19EICiadiaTHauLunA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.2833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528368" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/cc28bf41-85f9-4673-b818-8419279722f0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="18"&gt;&lt;b data-index-in-node="0" data-path-to-node="18"&gt;机器学习推理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 MNIST 数据集上，我们训练了一个单全连接层的机器学习模型（等价于逻辑回归），我们展示了一个视频样例。&lt;/p&gt;&lt;p&gt;此外，我们也考虑了三个全连接层的模型，传统的数字计算可以达到 98.1% 的精确度。在用我们的框架时，精确度可以达到 95.7%，但是能耗仅需 6.03 fJ/MAC，也就是一次推理共计6.42 fJ。&lt;/p&gt;&lt;p&gt;我们也考虑了其他机器学习任务，例如 AudioMNIST 数据集上的语音识别，精确度达到了 97.2%，而能耗下降到了 2.8 fJ/MAC。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;b data-index-in-node="0" data-path-to-node="20"&gt;论文总结&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;我们的核心创新包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;模型无线广播，多终端同时推理&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;神经网络模型被编码为无线射频信号，由中心无线节点统一广播，覆盖范围内的任意数量边缘设备都可同步完成推理，实现真正的「计算即广播」的多终端 AI 推理范式。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;无需改硬件，把「算力」直接搬进无线射频&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;利用边缘设备中本就存在的射频频率混频器，该方法无需任何专用 AI 芯片或电路改动，就能在射频信号域完成乘加运算，实现真正「零额外能耗」的模拟计算。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;单个射频器件即可支持规模化维度的神经网络计算&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过频域编码，一个频率混频器即可完成高达 32,768 维的内积运算，突破了传统模拟计算在规模上的限制，能够支撑现代深度学习模型的推理需求。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>国内首个可复现！萝博派对公开人形机器人 “从 0 到跑” 全开源方案</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 15 Jan 2026 21:37:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;2026 年 1 月 15 日，萝博派对（Roboparty）在官方 GitHub 仓库正式完整开源双足人形机器人 &amp;ldquo;萝博头原型机（Roboto_Original）&amp;rdquo;，并同步启动全球开发者共创计划。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5cd0eb52-5cf5-4e3d-936c-f2dedf0aa6a3/1768483880892.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这款搭载&lt;strong&gt;拟人步态的 AMP 运控算法&lt;/strong&gt;、跑步速度达 3m/s 的原型机，凭借全栈透明的技术开放模式，成为目前全球范围内技术成熟度领先的全开源人形机器人。&lt;/p&gt;&lt;p&gt;不同于&amp;ldquo;只开源代码或只开源结构图&amp;rdquo;的碎片式开放，本次开源以&amp;ldquo;可复现、可二开、可验证&amp;rdquo;为目标，覆盖参考硬件、控制/训练栈、工程化调试与验证方法，以及长期维护的行业 Know-how 共创知识库。&lt;/p&gt;&lt;p&gt;萝博派对希望把&amp;ldquo;从 0 到跑&amp;rdquo;做成行业共享的具身 Infra 底座：把路径标准化、把经验工具化、把验证流程公开化，推动行业把时间用在真正的场景与能力突破上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全栈开源，直击人形机器人开发痛点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人形机器人真正的门槛，往往不在某一个算法点，而在&amp;ldquo;从设计&amp;mdash;装配&amp;mdash;标定&amp;mdash;训练&amp;mdash;验证&amp;mdash;迭代&amp;rdquo;的系统工程。基于此，萝博派对针对行业长期存在的三大核心痛点&amp;mdash;&amp;mdash;闭源导致开发壁垒高、设计规范缺失、架构标准不统一&amp;mdash;&amp;mdash;以&amp;ldquo;可复现、可二开、可验证&amp;rdquo;为目标，正式发布双足人形机器人&amp;ldquo;萝博头原型机&amp;rdquo;的全栈开源方案，并同步推出&amp;ldquo;动手学人形机器人问题清单&amp;rdquo;Know-how 共创文档，推动行业经验从&amp;ldquo;各自积累&amp;rdquo;走向&amp;ldquo;公开共享&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e065a1fa-a367-425d-a7d1-59487d761c42/1768483905745.jpeg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在硬件层面，萝博头原型机公开 1.2m 身高、30kg 重量级本体的全套结构图纸，覆盖关节排布、线束收束方案以及金属结构件选型标准等关键设计细节。同时，项目同步开放关节模组核心参数、选型指南与拆机报告，并提供国内优质供应商清单，配套完整 EBOM 物料清单与 SOP 组装流程，从采购、装配到复现路径形成闭环，显著降低硬件研发与复刻门槛。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/505751f8-3523-4602-81c3-23ab790688ca/1768483942763.gif" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1a5bd777-4415-4e02-8596-f868b0c8fb80/%E5%8E%9F%E5%9E%8B%E6%9C%BA%E8%B7%91%E6%AD%A502_406x232.gif" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在软件与控制层面，项目开放底层控制全量代码，涵盖模仿运动、感知运动与导航运动三大核心模块，并支持 SMPL-X 人体模型适配，使开发者能够直接复用海量人体动捕数据，减少新任务开发中的微调成本，提升能力迁移效率，缓解传统控制方案在泛化性与工程落地上的不足。同时，萝博头原型机同步开源拟人步态的 AMP 运控算法代码，为步态自然度与运动稳定性的进一步迭代提供可直接复用的技术基础。&lt;/p&gt;&lt;p&gt;在工程化落地层面，萝博派对将研发过程中形成的 sim2real gap 弥补方案、样机测试矩阵与调试经验总结系统化公开，并同步沉淀关键避坑要点与流程规范，帮助开发者与合作团队减少重复试错、提升调试效率，让&amp;ldquo;跑起来&amp;rdquo;不再依赖隐性经验，而是可以被复现、被验证、被持续迭代的工程流程。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/583269a9-b11b-4a57-b0ef-669d87976e4d/1768484102694.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;与此同时，萝博派对长期建设并持续维护&amp;ldquo;动手学人形机器人问题清单&amp;rdquo;共创知识库，覆盖行业发展、硬件研发、软件研发与生产制造等关键环节，旨在将行业讨论从&amp;ldquo;表演型炫技&amp;rdquo;拉回&amp;ldquo;实用落地&amp;rdquo;。该知识库主张人形机器人优先解决行走稳定性、抗摔性等基础能力，并围绕尺寸、重量、散热、成本等量产关键问题展开共建，以&amp;ldquo;全员编辑、按紧急度排序&amp;rdquo;的开放机制，将单一团队的经验沉淀升级为&amp;ldquo;全行业共建的落地指南&amp;rdquo;，推动行业从&amp;ldquo;各自试错&amp;rdquo;走向&amp;ldquo;协同突破&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心突破：性能与步态双达标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/86e01880-18d4-452f-a057-5817dadbf79d/1768483952840.gif" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;萝博头原型机的关键优势，在于&amp;ldquo;硬件性能&amp;rdquo;与&amp;ldquo;控制体验&amp;rdquo;的同步提升。&lt;/p&gt;&lt;p&gt;在运动能力上，原型机跑步速度达到 3m/s 级别，跻身全球全开源人形机器人第一梯队，回应了行业长期存在的&amp;ldquo;开源性能滞后于闭源&amp;rdquo;的刻板印象。为支撑高速与稳定运行，硬件端采用类车规级本体结构与高刚性金属材料，提升力传递效率与整体结构稳定性；同时通过模块化关节模组实现更高的扭矩密度与更快的动态响应，为跑步与复杂动作提供可靠的执行基础。&lt;/p&gt;&lt;p&gt;在控制体验上，萝博头原型机搭载拟人步态的 AMP 运控算法，作为其核心控制能力底座。该算法基于数据驱动范式，并深度适配 Behavior Foundation Model（BFM）预训练框架，通过学习人体动捕数据，使机器人的行走与跑步更贴近人类生物力学特征，在提升动作自然度的同时兼顾稳定性表现，能够在复杂路况中保持更可靠的姿态控制。同时，这一范式显著降低新步态与新任务的微调成本，使步态扩展从&amp;ldquo;重研发&amp;rdquo;转向&amp;ldquo;可迁移、可复用&amp;rdquo;的工程流程。&lt;/p&gt;&lt;p&gt;对开发者而言，这意味着在不额外承担高昂研发投入的前提下，即可获得兼具高性能与自然步态的人形机器人参考方案，并在此基础上更高效地进行二次开发与场景适配，加速具身能力向真实应用落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生态共建：以开源推动协同创新&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a0150afe-b8b1-4ac5-a9b6-cc94ffcdb3dc/1768484141606.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;此次开源是萝博派对推进人形机器人行业协同生态建设的关键一步。在开发者生态层面，团队已搭建面向行业的技术交流与共创网络，吸引上市公司技术负责人、高校科研人员及创业公司核心成员等专业群体加入，形成更高效率的技术交流与资源共享平台，持续推动经验沉淀与问题协作解决。&lt;/p&gt;&lt;p&gt;在商业与产业层面，该项目已获得经纬创投、小米战投、光源资本等机构的千万美元种子轮融资。萝博派对认为，这不仅是对团队技术路线与工程能力的认可，更是对&amp;ldquo;具身智能 Infra 化&amp;rdquo;路径的验证：通过开源与标准化，把开发所需的关键链路沉淀为可复用的基础设施，让行业将更多精力投入到真实场景与能力创新之中。&lt;/p&gt;&lt;p&gt;&amp;ldquo;我们的目标是让具身智能的开发成本降低 80%。&amp;rdquo;萝博派对团队表示，当硬件不再成为门槛、算法不再是黑盒，具身智能才能真正进入&amp;ldquo;千行百业&amp;rdquo;的应用阶段，形成规模化的产业价值。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b138010f-b7e5-4aa2-9daf-2ff98eb9b4bb/1768484153705.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;除开源共创外，萝博派对也为产业伙伴提供 JDM（联合定义制造）设计与联合开发，加速从参考样机到工程化交付的全流程，覆盖结构/电气/控制集成、BOM 与供应链、试产与测试矩阵等关键工作。&lt;/p&gt;&lt;p&gt;目前，全球开发者可通过官方渠道获取核心资源与参与共创：&lt;/p&gt;&lt;p&gt;萝博头原型机开源仓库已在 GitHub 上线，作为从硬件到软件的汇总入口，保持持续更新。&lt;/p&gt;&lt;p&gt;萝博派对 Github ：&lt;a href="https://github.com/Roboparty/roboto_origin"&gt;https://github.com/Roboparty/roboto_origin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;同时，团队长期维护&amp;ldquo;动手学人形机器人问题清单&amp;rdquo;Know-how 文档，鼓励开发者通过社区参与编辑、提交行业痛点与复现经验，共同建设可持续迭代的落地知识库。&lt;/p&gt;&lt;p&gt;&amp;ldquo;动手学人形机器人问题清单&amp;rdquo; Know-How 文档：roboparty.com/roboto_origin/doc&lt;/p&gt;&lt;p&gt;萝博派对将持续基于社区反馈优化技术方案，推动行业从&amp;ldquo;各自为战&amp;rdquo;走向&amp;ldquo;协同共赢&amp;rdquo;，并欢迎全球开发者加入共创，探索人形机器人技术在真实场景中的实用化落地路径。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>联发科天玑9500s、8500发布：GPU、光追拉满，红米Turbo 5Max将搭载</title>
      <description>&lt;![CDATA[支持硬件级光线追踪技术。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Thu, 15 Jan 2026 18:48:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1 月 15 日，联发科（MediaTek）正式发布了天玑 9500s 和天玑 8500 移动芯片。&lt;/p&gt;&lt;p&gt;作为天玑家族的新成员，两款新品承袭了天玑旗舰芯片的诸多先进技术，在性能、能效、AI、影像、游戏和无线连接等方面表现强大，为旗舰细分市场注入了新动力。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/646b7712-6fe8-489a-aa6e-41f290d2154f/QQ20260115-181348.png" style="width: 59.67%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;天玑 9500s 采用 3nm 制程工艺和全大核架构（拥有超过 290 亿晶体管），八核 CPU 包含 1 个主频 3.73GHz 的 Cortex-X925 超大核、3 个 Cortex-X4 超大核和 4 个 Cortex-A720 大核，配备同档次出众的大容量高速缓存（二级缓存、三级缓存+系统缓存共 29m），结合第二代天玑调度引擎，可为手机等终端带来强大性能和能效表现。&lt;img src="https://image.jiqizhixin.com/uploads/editor/d2e2574e-f4c9-4894-9923-d9a57039e491/QQ20260115-181722.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;GPU 方面，天玑 9500s 搭载 Immortalis-G925 GPU ，提供重载硬核手游满帧、沉浸式的畅游体验，能够满足游戏发烧友、电竞选手对性能的期待。天玑 9500s 支持先进的光线追踪技术，天玑 OMM 追光引擎能够高效渲染图形，大幅提升游戏画面的真实感和精细度，带来主机级的环境光照和反射效果。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2ee4cf4f-04c6-445c-99bc-bfc0d0173632/QQ20260115-181925.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;此外，借助天玑星速引擎的自适应技术 3.0（MAGT 3.0）和天玑倍帧技术 3.0（MFRC 3.0），天玑 9500s 可显著提高主流游戏的能效表现，延长终端的续航时间。该芯片还支持 165 超高帧游戏，助力玩家体验快人一步。&lt;/p&gt;&lt;p&gt;在 AI 性能方面，天玑 9500s 集成了旗舰级 NPU，拥有强大的端侧 AI 推理能力，面向生成式推理、多模态模型进行了优化，以构建强大的旗舰端侧影像、内容生成等多元能力。该芯片支持端侧 AI 实况照片美化、AI 照片编辑（扩图、抠图、消除），AI 内容摘要（通话、会议和文件）等日常高频功能，能够助力终端厂商打造用户的个人随身 AI 设备，满足日益增长的社交、生产力场景需求。&lt;/p&gt;&lt;p&gt;联发科表示，其正在持续与大量应用端厂商合作，致力于打造更多新形态的 AI 体验。&lt;/p&gt;&lt;p&gt;影像方面，天玑 9500s 搭载先进的 MediaTek Imagiq 影像处理器，支持实时 30 帧运动追焦和 8K 全焦段杜比视界 HDR 视频录制，视频创作者可轻松捕捉清晰、生动的视频画面。此外，该芯片还支持杰出的抓拍和降噪技术，带来既快又清晰的旗舰拍照体验。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6a7e02ad-98bf-4006-8d04-10882c83eac4/QQ20260115-182809.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;今天推出的另一款芯片天玑 8500 采用台积电 4nm 制程打造，全大核架构 CPU 包含 8 个主频至高可达 3.4GHz 的 Cortex-A725 大核，带来性能和能效的进一步提升。天玑 8500 支持精准的调度技术，支持传输速率更高的 LPDDR5X 9600Mbps 内存，用户在日常应用、游戏和多任务处理等使用场景中能够享受丝滑流畅、持久续航。&lt;/p&gt;&lt;p&gt;天玑 8500 搭载性能更强的八核 Mali-G720 GPU，峰值性能相较上一代提升 25%，功耗相较上一代峰值性能下降低 20%。得益于全面升规的计算核心、天玑调度和星速双引擎，天玑 8500 可为玩家带来兼具游戏满帧稳帧、疾速加载和冰峰高能效的劲爽体验。据介绍，在流行开放世界手游的高画质设置上，搭载该芯片的手机可以保持 60 帧满帧的效果。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5c118ad0-80d7-448c-8274-26f667762031/QQ20260115-183705.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;此外，天玑 8500 还将光线追踪技术落地于主流移动游戏，提供更加逼真的画质效果，显著提升玩家的沉浸感。&lt;/p&gt;&lt;p&gt;联发科表示，基于天玑新一代次旗舰芯片，通过与腾讯语音团队的合作，目前双方已在王者荣耀游戏中落地了 AI 语音转文字的功能。&lt;/p&gt;&lt;p&gt;至于搭载新一代芯片的手机，联发科介绍了与小米（REDMI）vivo，OPPO 等厂商的深度合作。&lt;/p&gt;&lt;p&gt;小米集团手机部副总裁李俊也来到了发布会现场，介绍了即将搭载联发科新一代芯片的手机。他表示，即将在本月发布的红米 Turbo 5 Max（天玑 9500s 版）的安兔兔跑分达到了 361 万分，在 2500 元价位上实现了前所未有的性能。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8bc2160d-3391-46d7-b63b-43ab0b276fdb/QQ20260115-183809.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;除了天玑 9500s 与 8500 芯片，红米 Turbo 5 Max 预计还将拥有大屏幕及超大容量电池。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
