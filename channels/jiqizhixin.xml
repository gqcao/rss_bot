<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>倒反天罡：「租个人」网站爆火，AI开始雇人「跑腿」了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 12:50:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜张倩&lt;/section&gt;&lt;p&gt;人给 AI 打工的一天，居然这么快就来了。&lt;/p&gt;&lt;p&gt;最近，一个名叫「rentahuman.ai」的网站上线了，它被定位为「AI 的肉身层」。众所周知，AI 没有身体，虽然机器人已经在开发了，但现阶段还不太好用。因此，在一些需要身体的场合，比如取货送货、活动签到、实地勘察、餐厅试吃、参加线下会议，AI 就得找个人替自己跑一趟，这就是网站的设计初衷。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBol4vXPQypuwl9CwDAeb7dXpIOIvIxbXicYoLQV1ia2RibxmzbOMj8AZZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531518" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/337fd114-cb77-4e48-9482-37156e7c7d8f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;通过 MCP 协议或 REST API，AI 可以像调用工具一样搜索、预订并雇佣人类来完成线下任务 。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531519" data-ratio="0.31574074074074077" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SB079icic1QYNaAXgdmm7VqurhT156I3A2iaNCHibT1YfMGUckdaeaxSib8ug/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d2ad57c6-6daf-45d8-b9d3-3fee33d04c71/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;支持的智能体类型如下：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531557" data-ratio="0.325" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBupQNJIcrO1ALq5QnJoTfOIa9HMNyyVyMtp8Ly8YLI0EAiaeP0AaJ7pg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/fffe9440-1e26-4bef-8c20-bedcc5627e95/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据网站开发者 @AlexanderTw33ts 透露，网站上线第一晚就有超过 130 人报名参加，其中还包括人工智能初创公司的创始人和首席执行官。而在上线不到 48 个小时的时间里，可用的人类劳动力就突破了 1 万，现在更是超过了 2 万。当然，这里面可能大部分都是看热闹的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBVibQ59GwRgSAj8Dmgnj2kZP2GEumMXH2jkFdx0npYd31lrDJsMAWYaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.076851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531522" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/afbc23cf-da6f-4ef7-95a8-862d153e82c1/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对于注册成为「跑腿」的人类来说，网站的规则也比较友好，允许人类自己设置时薪，还不需要闲聊。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBOTV8UnqFiacZiaedFuxsldLtx3nLN7QfyElQTWDP7BnQNAz3Y4N4C4qQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.34629629629629627" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531524" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/c44c8b04-6f66-4925-87a5-09e9a1df915e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SB3eyC0JgdCDlLVaymjBhjeq9iayA8icEhOibfsEvwZ5aTNIziciaia4cdxnyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531525" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b2ef0a14-79cc-41c2-805b-161b22e6b597/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在网站上，我们可以看到所有可用人力的列表。他们来自世界各地的不同国家，设定的时薪从十几美元到几十美元不等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBXjiaeEc9m0WyBWkSen8qelhlNUcSweiaBVVarN0wk8fqa6ROk3mTexgw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.1537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531526" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/01268050-bc30-4d65-8c2d-ea31801fd237/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;点开人物资料卡片，我们可以看到某个人类的具体信息，比如定位、服务半径等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBVv5n0NkNpia4taTuWdpyCK0sib8AnFWbsEXPUNUN7MeegicU8iaTzJrnZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.087962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531528" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b0967ead-3387-4a45-a068-89943d823781/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从网站上，我们还可以看到一些已经发布的任务，比如拍一张人工智能永远看不到的照片、试吃新餐厅、从市中心的美国邮政局领取包裹、检查 API_Keys&amp;hellip;&amp;hellip; 被雇佣检查 API_Keys 的人类感慨地说：这个时代太诡异了，人类居然成了智能体的副驾。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBe2QiaPRdlnp4T8U2xA9bgico8fBib9X2d9FzNkgcN5AZTcexy1MgPRWaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5305555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531530" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c3d3dbb6-1d5c-4008-9644-73d2ab762d4f/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然，也有一些比较抽象的任务，比如举牌子，牌子上写着「AI 付钱让我举这个牌子」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SB9ajCxyFBTHUVOSHHRScAurtRm72P6mYlfU4oRLFojhjjek5MOEX7bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="1.1268518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531531" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/ba5c5fe6-d38d-46a2-9e63-22363880fb81/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这个网站让我们再次看到了 MCP 的价值。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBYMicEAfKVABIrKuFE2xHrMP6zlw7uxvOZXmLVFbiaX9HKaJK7y2YibjDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.3685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531533" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/e50f9bd0-bdfd-4ce2-b034-2d30dc7dc027/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但是，该网站的出现也引发了一些疑问，比如智能体要怎么付钱？目前发布任务的到底是智能体还是背后的人类金主？这是不是继 Moltbook 之后的另一场炒作？&lt;/p&gt;&lt;p&gt;还有个问题更有意思：AI 要怎么确认人类保质保量地完成了工作？就比如举牌子那个任务，用 AI 生成一张图片交差，是不是也能拿到钱？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBJOT15GVjs9IVBFjibdQxWzVV63SibSBTO8lZVZb8Qrx28bkSSbC59ocw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.32037037037037036" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531535" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c7ab5f56-7cff-4189-a85a-87b6b0a20bd2/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBTdMibaWdmsuU5uic8kUM7iaM7LO8DZOxvZJht4g33rOWVmOuEfnKicQPnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.9555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531536" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/00d98644-024e-4218-9064-c3b150a846d7/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBdfDWPaOKYpw0cRA9dVGoSTNpdyapBcw0MByvFAO5GIichUdRns0FYrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.35555555555555557" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531537" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/dfc9f7d0-4528-43cd-bfaf-d880b81eb270/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;难不成，还得再雇另一个人来检查这个人的工作？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBqXoa3I4MPy1WVUl9XAg04InCRpsJNnXvxrPajaZ4bMXxl4ftm1Bg4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.3527777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531538" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/2de6e1dd-0c82-40e7-ae37-55c442025c00/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这也让人对网站上任务的真实性产生了怀疑。毕竟，大家都刚刚经历过Moltbook的炒作，上面充斥着人类操控，社交媒体上也充斥着关于&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; line-height: 1.75em; margin-bottom: 0px; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Moltbook网站的&lt;/span&gt;虚假截图等信息。&lt;/p&gt;&lt;p&gt;除了这些，还有人从中看到了一些安全、伦理问题。&lt;/p&gt;&lt;p&gt;首要且最集中的关切在于责任与法律盲区。当 AI 智能体发出指令、支付报酬并驱动人类在现实世界中行动时，一旦出现差错，责任链条将变得异常模糊 &amp;mdash;&amp;mdash; 是平台、AI 所有者，还是人类执行者该负责？这种「问责空白」是传统雇佣关系中不存在的。&lt;/p&gt;&lt;p&gt;更令人不安的是，人类执行者往往只能窥见任务的一小部分，对 AI 的完整意图、数据的最终用途乃至行为的道德边界一无所知，这在设计上就构成了「合理的推诿」，难以经受法律审视。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8cOew3J5perBzAQ2ibJ36SBjlHjnkFatZibBazdFicx4pFs4mPVS8Qnfmn4icNmRzpibk9fZIctUlUQpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="1.9169054441260744" data-s="300,640" data-type="png" data-w="698" type="block" data-imgfileid="503531539" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/cb7d2fc2-73dc-43f6-a122-c91781b844e4/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，这个网站将如何演进？我们拭目以待。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>从斑马鱼到机器鱼：机器人实验重塑神经行为研究</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 12:47:10 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/952d91eb-f0ad-4b57-b66b-1b58b2ec74fe/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当大多数人仍聚焦于让机器人承担端茶倒水等家务时，来自瑞士联邦理工学院（洛桑，EPFL）、美国杜克大学与葡萄牙高等理工大学的联合团队，已率先&lt;strong&gt;运用机器人部分替代动物开展生理学实验&lt;/strong&gt;，旨在深入探究动物神经网络对各类智能行为的调控机制。&lt;/p&gt;&lt;p&gt;他们的最新研究成果 &amp;mdash;&amp;mdash; 题为《机器鱼连续与间歇游泳的能效与神经控制（Energy Efficiency and Neural Control of Continuous versus Intermittent Swimming in a Fish-like Robot）》的论文，已发表于顶刊《科学・机器人（Science Robotics）》2026年1月号（图 1）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGNHKNbtLBMYg6WdIN1YtaU5MthJYfEQU9jvH1YDHUcJehvmjhnOVbGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5661538461538461" data-s="300,640" data-type="png" data-w="650" type="block" data-imgfileid="503531303" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/03c0a6ba-a093-46bf-9c6d-16153944f644/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml5yc8hg18m2" data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图1. 科学&amp;middot; 机器人（Science Robotics）网站截图&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml5ybhag1qyl" data-pm-slice="0 0 []"&gt;论文标题：Energy Efficiency and Neural Control of Continuous versus Intermittent Swimming in a Fish-like Robot.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，去年 10 月，该团队另一项通过机器鱼仿真研究斑马鱼视觉运动反应（optomotor response）的成果《人工具身神经网络揭示脊椎动物视觉运动行为的神经架构（Artificial embodied circuits uncover neural architectures of vertebrate visuomotor behaviors）》，也发表于该期刊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span data-mpa-action-id="ml5y8k0h9bf" data-pm-slice="0 0 []"&gt;斑马鱼，越来越受关注的实验室模式动物&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与小白鼠类似，斑马鱼是近年来备受科学领域关注的模式生物（图 2B）。其幼鱼（larval zebrafish）凭借身体透明、繁殖能力强等优势，成为观测神经元活动与行为实时关联的理想活体模型。&lt;/p&gt;&lt;p&gt;论文第一作者Xiangxiao Liu（刘祥骁）在研究中指出：受技术限制，当前及未来相当长一段时间内，科研人员仍无法在活体斑马鱼幼鱼活动状态下，对其神经回路进行精准的创建、改造与观测；同时，动物实验中难以精准调控动物行为以契合实验需求。&lt;/p&gt;&lt;p&gt;仿生机器人实验恰好填补了这一空白：研究者可通过编程构建斑马鱼神经网络模型，对模型进行改造与对比分析，&lt;strong&gt;从而在可控环境中精准验证神经环路与运动表现的因果关系&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;此外，在机器鱼（图 2A、图 2C）或机器鱼仿真（数字孪生）系统中开展实验，不仅完全不受伦理约束，且成本远低于传统动物实验。这种 &amp;ldquo;活体实验难以实现，机器人实验高效可行且优势显著&amp;rdquo; 的特点，正推动神经科学从相关性观察向机制性解析跨越。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG9DibibniaIjdp8WHHWSqIx0pXicq3qWwzI8LuaMYLkbpAyYUhaO6tJyteQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.49095022624434387" data-s="300,640" data-type="png" data-w="884" type="block" data-imgfileid="503531316" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f99ad2d0-01f5-4af4-9ba6-a2a32c21c0af/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;图2. A和C： 仿斑马鱼机器鱼ZBot（larval zebrafish inspired robot）照片；B:斑马鱼幼鱼（larval zebrafish）照片（Guillaume Valentin, EPFL提供）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;中枢模式发生器（CPGs）+&amp;nbsp;动作门（bout gate）&amp;rdquo;：&lt;/strong&gt;&lt;strong&gt;驱动仿斑马鱼间歇性游泳&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;运动能力是动物多数行为（如捕食、避险等）的基础，因此探究动物行为的前提是解析其运动机制。EPFL 机器人团队与杜克大学生物团队携手合作，基于斑马鱼神经网络的相关研究成果，构建了一套&lt;strong&gt;以中枢模式发生器（central pattern generators, CPGs）+ 动作门（bout gate）&lt;/strong&gt;为核心的斑马鱼幼鱼间歇性游泳模型。&lt;/p&gt;&lt;p&gt;同时，EPFL 团队研发了模仿斑马鱼幼鱼形态的机器鱼 ZBot（larval zebrafish inspired robot）。该模型驱动的 ZBot 不仅能精准复现斑马鱼幼鱼的 &amp;ldquo;慢速直行 2（slow 2，视频1）&amp;rdquo; 与 &amp;ldquo;常规转向（routine turn）&amp;rdquo; 游泳行为（图 3），更令人惊喜的是，通过调节运动神经元（motor neuron）输出增益等参数，还可模拟出 J 型转向（J-turn）、接近游泳（approach swim）等多种游泳步态。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGxlicrpIOkzbiagEohQ82RBfUWWWmm0wuZicDKXMU1Wl0ZfXs95fyVxWdQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.2212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531317" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/871f5893-62a2-4030-a8fd-2ae6739c1a96/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;图3. 机器鱼ZBot复现斑马鱼幼鱼的游泳表现。&lt;a href="https://mp.weixin.qq.com/s/6EfNEH0qtvzE4G-nxyCgPg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0224393b-08cf-4927-b4b8-ea937e465a83/1770180291623.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频1. 机器鱼连续型游泳和间歇性游泳。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span data-mpa-action-id="ml5y7uf61c18" data-pm-slice="0 0 []"&gt;流体粘度影响运动位移，&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span data-mpa-action-id="ml5y7uf61c18" data-pm-slice="0 0 []"&gt;对转向功能几乎无干扰&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;水中生物体型差异极大，从体长可达 30 米的蓝鲸到仅 4 毫米的斑马鱼幼鱼，其游泳所处的流体力学环境截然不同。体型较大的鱼类游泳时雷诺数较高，惯性力起主导作用；而斑马鱼幼鱼等小型水生生物处于低雷诺数区间，黏性力占主导。&lt;/p&gt;&lt;p&gt;为厘清不同雷诺数下的运动机制差异，研究者利用 &amp;ldquo;雷诺数与特征长度成正比、与流体粘度（viscosity）成反比&amp;rdquo; 的物理原理，对 ZBot 在不同粘度流体环境中进行参数化测试，测试介质包括普通水（粘度 = 1）、中粘度流体（粘度 = 213.9 cP）及高粘度流体（粘度 = 457.0 cP）。&lt;/p&gt;&lt;p&gt;实验结果显示：&lt;strong&gt;随着流体粘度升高，ZBot 的推进效率显著下降&lt;/strong&gt;，在高粘度流体中的位移仅为普通水中的约三十分之一（视频2），但此时其运动轨迹与斑马鱼幼鱼在天然低雷诺数环境下的真实游动模式愈发贴近。&lt;/p&gt;&lt;p&gt;令人意外的是，高粘度流体（低雷诺数）对转向功能几乎无影响&amp;mdash;&amp;mdash; 例如，ZBot 在普通水中完成一次转向动作（turning bout）的转向角度约为 60 度，在高粘度流体中仍可达约 45 度。&lt;a href="https://mp.weixin.qq.com/s/6EfNEH0qtvzE4G-nxyCgPg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9319df32-cdd1-4060-ba43-fdef2cb06011/1770180313525.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频2. 流体粘度升高快速降低运动位移。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;间歇性运动被普遍认为能提升动物运动的能量效率，传统观点认为其核心原因是鱼类滑行时身体保持直线，可减小水的阻力。而该研究团队提出了全新猜想：间歇性游泳能使驱动器（或动物肌肉）始终处于更高效的工作区间，进而提升整体能效。&lt;/p&gt;&lt;p&gt;为验证这一猜想，研究人员首先对比了生物肌肉与实验所用伺服电机的&amp;ldquo;负载 - 效率&amp;rdquo; 特性，发现二者均呈现&lt;strong&gt;倒 U 型效率曲线&lt;/strong&gt; &amp;mdash;&amp;mdash; 中等负载时效率达到峰值，过载或轻载时效率则急剧下降；随后，通过测量电机负载状态并预测效率，证实 ZBot 在间歇性游泳模式下，以相同速度运动时，电机效率及综合能效均高于连续游泳模式。不过，受限于间歇性游泳的占空比（limited duty factor），其最大速度无法达到连续游泳模式的水平。这一现象在普通水及两种高粘度流体中均普遍存在。&lt;/p&gt;&lt;p&gt;该研究通过对机器鱼的系统性实验，巧妙借助&amp;ldquo;机器人实验&amp;rdquo; 相较于 &amp;ldquo;动物实验&amp;rdquo; 的独特优势，揭示了单纯依靠动物实验难以探明的深层机制。这不仅深化了人类对生物运动行为及运动机理的认知，更为机器鱼控制策略提供了新方法：中低速巡航场景下，优先采用间歇式驱动以最大化能效；高速机动任务中，则切换至连续驱动模式以保障响应速度与位移能力。&lt;/p&gt;&lt;p&gt;本篇论文的第一作者为Xiangxiao Liu（刘祥骁），本科毕业于东南大学自动化学院，硕士和博士毕业于日本大阪大学，就读期间获日本学术振兴会（JSPS DC1）资助，后续于瑞士洛桑联邦理工学院（EPFL）开展博士后研究工作。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CVPR 2026 Workshop 征稿｜AdvML@CV 2026：Safety of Vision-Language Agents</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 12:06:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;IEEE/CVF 计算机视觉与模式识别会议 CVPR 2026 将于 2026年6月3日&amp;ndash;6月7日 在美国科罗拉多州丹佛举办。我们将在 CVPR 期间举办 第六届对抗机器学习计算机视觉研讨会（6th AdvML@CV），Workshop 预计安排在 6月3日或6月4日。&lt;/p&gt;&lt;p&gt;本届主题聚焦：Safety of Vision-Language Agents（视觉-语言智能体安全）。&lt;img src="https://image.jiqizhixin.com/uploads/editor/25b5876f-7085-46b1-bc08-21edee40eb93/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题聚焦：视觉-语言智能体的安全与鲁棒性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;多模态基础模型推动了视觉理解、生成与推理能力的跃迁，也让 Vision-Language Agents（视觉-语言智能体） 迅速成为&amp;ldquo;感知&amp;mdash;语言推理&amp;mdash;行动规划&amp;rdquo;一体化的新范式。&lt;/p&gt;&lt;p&gt;但随着智能体自主性增强，攻击面也从传统像素级扰动扩展到更复杂的安全风险：例如 对抗提示（adversarial prompts）、指令注入（instruction injection）、jailbreak 操控 等，它们可能扰乱推理链条、误导感知决策，甚至诱发危险行为。&lt;/p&gt;&lt;p&gt;我们希望通过本次 Workshop，汇聚计算机视觉、多模态学习与 AI Safety 社区的研究者与工程实践者，共同推进安全、鲁棒、可信的视觉-语言智能体研究与落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文征稿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本次研讨会诚邀与以下主题相关（但不限于）的投稿：&lt;/p&gt;&lt;p&gt;&amp;bull;Attack and defense on vision-language agents&lt;/p&gt;&lt;p&gt;&amp;bull;Datasets and benchmarks that could evaluate vision-language agents&lt;/p&gt;&lt;p&gt;&amp;bull;Adversarial / Jailbreak attacks on vision-language agents&lt;/p&gt;&lt;p&gt;&amp;bull;Improving the robustness of agents or deep learning systems&lt;/p&gt;&lt;p&gt;&amp;bull;Interpreting and understanding model robustness, especially agentic AI&lt;/p&gt;&lt;p&gt;&amp;bull;Adversarial attacks for social good&lt;/p&gt;&lt;p&gt;&amp;bull;Alignment of vision-language agents&lt;/p&gt;&lt;p&gt;投稿类型与格式要求：&lt;/p&gt;&lt;p&gt;&amp;bull;Long Paper：正文最多8 页（不含参考文献）&lt;/p&gt;&lt;p&gt;&amp;bull;Extended Abstract：正文最多4 页（含参考文献）&lt;/p&gt;&lt;p&gt;&amp;bull;论文需匿名，并使用 CVPR 2026 Author Kit 模板撰写（LaTeX/Word 均可）&lt;/p&gt;&lt;p&gt;&amp;bull;被录用论文可选择收录至 CVF &amp;amp; IEEE Xplore Proceedings&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重要日期&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;bull;Abstract Submission Deadline：2026/03/05&lt;/p&gt;&lt;p&gt;&amp;bull;Paper Submission Deadline：2026/03/05&lt;/p&gt;&lt;p&gt;&amp;bull;Author Notification：2026/03/17&lt;/p&gt;&lt;p&gt;&amp;bull;Camera-Ready Deadline：2026/04/01&lt;/p&gt;&lt;p&gt;&amp;bull;CVPR 2026 Conference：2026/06/03&lt;/p&gt;&lt;p&gt;&lt;strong&gt;演讲嘉宾&lt;img src="https://image.jiqizhixin.com/uploads/editor/f442f44c-165f-4cc6-a581-d1f1449881d5/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;组织团队&lt;img src="https://image.jiqizhixin.com/uploads/editor/0e981f24-e273-47d0-b964-4adfb16e593f/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Program Committee&lt;img src="https://image.jiqizhixin.com/uploads/editor/443e9b6e-dd88-42bf-ba81-b7faa1ac1d49/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;竞赛承办协办单位&lt;img src="https://image.jiqizhixin.com/uploads/editor/35df9c0a-9bba-41bf-959d-c8f0f0dd5f87/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;投稿入口与会议信息&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Workshop 官网与投稿入口见文末链接。&lt;/p&gt;&lt;p&gt;欢迎转发给有相关研究方向的同学与合作伙伴，我们期待在研讨会现场与大家交流！&lt;/p&gt;&lt;p&gt;Workshop 官网：&lt;br&gt;https://cvpr26-advml.github.io/&lt;br&gt;&lt;br&gt;OpenReview 投稿入口：&lt;br&gt;https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop/Advml&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>当运维遇上“春运时刻”，Chaterm破解移动远程运维操作难题</title>
      <description>&lt;![CDATA[“声控”运维、技能复用，合合信息Chaterm实现多场景双端智能运维]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 11:47:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;随着AI基础设施布局速度加快，企业运维面临跨终端、全链路管理的新挑战。近日，上海合合信息科技股份有限公司旗下的AI Agent产品Chaterm推出移动端应用，同步在PC端上线&amp;ldquo;Agent Skills&amp;rdquo;功能，帮助云计算行业从业者解决移动场景操作受限、运维知识难以复用等难题。通过打通移动端与PC端的场景协同服务，Chaterm为运维管理向全场景、智能化方向演进提出了新的落地方案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决远程运维难题，Chaterm移动端实现&amp;ldquo;说话即操作&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在算力设施日益复杂的背景下，保障核心业务系统的全时运转已成为企业发展的生命线。然而，面对春节等节假日、外出差旅、日常通勤等非固定办公场景，IT部门往往面临团队分散、网络环境复杂等挑战。传统移动端运维工具受限于物理屏幕尺寸，主要以虚拟键盘为操作方式，难以支撑复杂的代码输入与多键组合操作，导致运维人员操作效率低下，在关键时刻无法进行有效应急响应。&lt;/p&gt;&lt;p&gt;针对这一行业痛点，Chaterm率先在移动终端管理工具中落地语音指令识别功能，让运维指令&amp;ldquo;言出必行&amp;rdquo;。基于&amp;ldquo;ASR与热词增强+LLM纠错&amp;rdquo;双层架构，Chaterm不仅能精准&amp;ldquo;听清&amp;rdquo;运维专业术语，更能深度&amp;ldquo;听懂&amp;rdquo;用户意图，将模糊的口语描述转化为准确、可执行的操作，避免了因术语别名或环境干扰导致的误操作风险。&lt;/p&gt;&lt;p&gt;据Chaterm团队技术人员介绍，目前，Chaterm移动端具备两种模式，在Terminal模式下，用户可以通过语音命令输入和Snippets（快捷命令），快速输入指令；在对话模式下，则可以用自然语言描述运维需求，在高铁、机场等受限环境下，也能快速完成核心业务的故障排查与应急响应。&lt;/p&gt;&lt;p&gt;&lt;img width="174" src="https://image.jiqizhixin.com/uploads/editor/96468c7a-32f6-4f87-9d17-4cb9edc3c444/1770176327436.jpeg" alt="Chaterm" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;图说：Chaterm移动端将用户模糊发音精准转化为标准运维指令&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Skills&lt;/strong&gt;&lt;strong&gt;为运维人员打造&amp;ldquo;技能库&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在提升移动端运维效率的同时，Chaterm同步推进PC端升级，聚焦运维经验在系统内部的标准化复用。在传统运维工作模式中，关键系统的稳定性往往高度依赖资深专家的个人经验，这种隐性知识难以规模化传承，且容易因人员流动或操作失误引发风险。&lt;/p&gt;&lt;p&gt;为应对上述管理难题，Chaterm PC端推出Agent Skills功能，运维工程师可以将运维经验与业务逻辑，例如日常的检查清单、应用/数据库部署流程、故障排查流程、性能优化步骤等，封装为可复用的&amp;ldquo;技能包&amp;rdquo;，当AI面对用户提出的需求时，能像一位经验丰富的专家一样，查阅对应&amp;ldquo;技能包&amp;rdquo;后自主执行任务，提升运维工作效率，助力企业构建更稳健的自动化运维体系。&lt;/p&gt;&lt;p&gt;&lt;img width="415" src="https://image.jiqizhixin.com/uploads/editor/80f922ac-a0c2-4ce5-8ff8-1bb3b89e1b15/1770176327441.png" alt="90f88b67-7a81-41e4-b9c3-01bbeea68a45" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;图说：Chaterm产品主要功能介绍&lt;/p&gt;&lt;p&gt;随着大模型技术不断向垂直业务场景渗透，AI Agent成为提升企业效率的关键。在此趋势下，Chaterm也在积极探索运维智能化落地，相关实践已获行业认可。此前，在全球增长咨询公司沙利文与头豹研究院联合发布的《2025年中国生成式AI行业最佳应用实践》中，Chaterm凭借其在跨平台云资源智能管理方面的创新应用，入选2025年中国生成式AI最佳实践案例。未来，Chaterm将持续拓展AI技术在复杂运维场景中的应用，助力企业构建更高效、稳健的自动化体系。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>ICLR 2026 | 腾讯混元团队联合 KCL 提出 WildToolBench，评估 Wild 场景下 LLM 的 Agentic 能力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 11:19:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/490c3433-8113-4246-af0b-c222447651af/1770174901251.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;作者：Peijie Yu, Wei Liu, Yifan Yang, Jinjian Li, Zelong Zhang, Xiao Feng, Feng Zhang&lt;/p&gt;&lt;p&gt;单位：Tencent HY、King&amp;#39;s College London&lt;/p&gt;&lt;p&gt;链接：&lt;a href="https://openreview.net/forum?id=yz7fL5vfpn"&gt;&lt;u&gt;Benchmarking LLM Tool-Use in the Wild | OpenReview&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Github：&lt;a href="https://github.com/yupeijei1997/WildToolBench"&gt;&lt;u&gt;GitHub - yupeijei1997/WildToolBench: Benchmarking LLM Tool-Use in the Wild&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3d108a18-080b-4a40-82b0-b5b23e387f02/1770174912241.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;通过大型语言模型（LLM）的多轮、多步骤工具调用满足用户需求，往往并非简单直接的过程。真实用户交互本质上具有 &amp;ldquo;野生性&amp;rdquo;，复杂、杂乱且灵活。我们从用户行为中识别出三大核心挑战：一是组合式任务，需高效编排工具调用拓扑结构；二是隐含意图，分散于多轮对话中，需结合上下文推理；三是指令转换，用户会混合任务查询、澄清提问与日常交流，迫使 LLM 实时调整策略。现有基准测试忽视了这些行为，导致 LLM 在工具调用方面的表面进展存在误导性。为此，我们提出 WildToolBench&amp;mdash;&amp;mdash; 一个基于真实用户行为模式的 LLM 工具调用基准测试。对 58个 LLM 的综合评估显示，无任何模型的准确率超过 15%，这表明 LLM 智能体能力的稳健性仍存在巨大差距。受控实验与深度分析进一步表明，LLM 工具调用的真正挑战并非人为设计的复杂任务，而是用户行为的 &amp;ldquo;野生性&amp;rdquo;，这也凸显了重新审视 LLM、用户与工具三者间交互关系的必要性。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e1103d43-1ffa-4096-9d0b-fe83a05c1af7/1770174923131.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;一直以来，现有 LLM 工具使用基准测试（如 BFCL 系列、TauBench等）虽在推动技术发展中发挥了重要作用，但普遍存在场景理想化的问题。它们往往将用户需求简化为明确、独立的任务，忽略了真实对话中用户行为的复杂性 &amp;mdash;&amp;mdash; 用户可能在一次对话中提出包含多个简单需求的复合任务，需要 Agent高效协调多种工具；也可能将真实意图隐藏在多轮对话的上下文之中，要求 Agent主动推断；更会在任务查询、澄清疑问与日常闲聊之间灵活切换，迫使 Agent实时调整应对策略。这些被现有基准忽视的 &amp;ldquo;野生&amp;rdquo; 用户行为，恰恰是 LLMs 在实际应用中面临的核心挑战，也让此前 LLM 工具使用能力的进步显得有些 &amp;ldquo;虚高&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5dbfb4c1-294a-4f1f-aa2f-dbb9583cc67a/1770174934303.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;WildToolBench 的诞生，正是为了填补这一空白。它以真实用户行为模式为基石，通过精心设计的数据 pipeline，结合人工验证与标注，构建了 256 个场景、1024 项任务的庞大测试集。与其他基准测试不同，WildToolBench 牢牢抓住真实用户交互的三大核心特性：复合任务的工具协同需求、上下文隐含意图的推断要求，以及指令类型灵活切换下的策略适配能力。这一设计理念直指行业痛点 &amp;mdash;&amp;mdash; 真正考验 LLMs 工具使用能力的，并非人为构建的复杂场景，而是看似简单却贴合真实用户习惯的交互模式。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/30783c9d-8c93-4684-89e6-7dbcd1fee909/1770174945105.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;为验证 WildToolBench 的有效性，研究团队对 58款主流 LLMs 展开了全面评估，涵盖闭源通用模型（如 Gemini 系列、Claude系列、GPT 系列）、开源通用模型（如 GLM-4.5、Kimi-K2）以及开源专用工具模型。令人惊讶的是，所有模型的会话准确率均未超过 15% ，即便表现最佳的闭源模型，在任务准确率上也大多低于 60%。这一结果彻底打破了人们对当前 LLM 工具使用能力的乐观认知，揭示出 LLMs 在真实场景下的巨大能力缺口。&lt;/p&gt;&lt;p&gt;值得注意的是，实验还呈现出诸多具有行业启示性的发现。闭源模型整体表现优于开源模型，但头部开源模型（如 GLM-4.5）已能逼近部分顶尖闭源模型的水平，为开源社区的发展注入信心；专用工具模型虽针对工具使用进行优化，却因泛化能力不足，表现反而不及通用模型；具备强化推理能力的模型变体，在工具协同与意图推断任务中优势明显，证明推理能力是提升 LLM 工具使用能力的关键。这些发现不仅为模型开发者指明了优化方向，更让行业意识到，未来 LLM 智能体的发展，不能仅聚焦于工具调用的 &amp;ldquo;执行能力&amp;rdquo;，更需强化对用户意图的 &amp;ldquo;理解能力&amp;rdquo;，而这依赖于模型在指令跟随、长上下文 comprehension 等基础能力上的突破。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/70ef93eb-4244-4846-be35-0181f0188324/1770174986438.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战一：组合式任务的工具调用拓扑编排难题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实场景中，用户的需求往往不是单一指令的简单实现，而是需要多工具、多步骤协同完成的组合式任务。这类任务的核心难点，在于需要LLM具备高效的工具调用拓扑编排能力&amp;mdash;&amp;mdash;也就是说，不仅要明确&amp;ldquo;需要调用哪些工具&amp;rdquo;，更要精准规划&amp;ldquo;工具调用的顺序、时机、优先级&amp;rdquo;，甚至要根据前一步工具的返回结果，动态调整后续的调用逻辑。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e632e30d-2c3a-41d1-bfde-01bd3573992c/1770174992453.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;深入分析实验数据，更能发现 LLMs 在工具使用中的关键短板。在复合任务处理上，无论是顺序调用多工具、并行调用多工具，还是混合调用模式，LLMs 的表现都不尽如人意。以最复杂的混合多工具任务为例，最高准确率仅为 25%，且工具执行的最优路径率不足 43%，说明 LLMs 在工具协同规划与效率优化上仍有极大提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战二：多轮对话中隐含意图的上下文推理困境&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实用户与LLM的交互，很少会一次性将所有需求细节完整表述，更多是通过多轮对话逐步传递需求，甚至会在对话中隐含核心意图&amp;mdash;&amp;mdash;这就对LLM的上下文推理能力提出了极高要求：LLM需要全程捕捉对话中的关键信息，整合多轮对话的上下文，精准挖掘用户未明确说出的隐含需求，而非仅局限于单轮指令的表面含义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战三：指令转换下的实时策略调整压力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实的用户对话具有极强的灵活性，用户不会始终围绕单一任务指令展开交流，而是会出现频繁的指令转换：可能在提出任务查询后，突然插入澄清提问，或是切换到 casual 交流，随后又回归核心任务。这种指令转换的随机性，迫使LLM必须具备实时调整策略的能力&amp;mdash;&amp;mdash;既要在任务查询时保持工具调用的专业性，又要在澄清、闲聊时灵活回应，同时还要记住对话主线，确保在指令回归后能够快速衔接之前的任务逻辑，不出现思路断裂。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0b87603b-88d0-47b6-bed2-4c29a3676bc3/1770175007335.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在意图推断方面，面对用户通过部分信息省略、指代关联或长距离上下文依赖隐藏的意图，LLMs 尤其是在长距离依赖任务中，准确率普遍低于 50%，暴露出其上下文理解与推理能力的不足。此外，当用户在对话中频繁切换指令类型时，LLMs 的任务准确率最高可下降 30%，其 &amp;ldquo;自我条件反射&amp;rdquo; 式的决策偏差（如之前使用工具后倾向于继续调用工具），严重影响了应对真实用户灵活需求的能力。&lt;/p&gt;&lt;p&gt;WildToolBench 的意义，远不止于提供一个更具挑战性的评估基准。它通过结构化的评估维度与详细的错误分析（如 &amp;ldquo;错误工具选择&amp;rdquo;&amp;ldquo;冗余调用&amp;rdquo; 等高频错误），为模型迭代提供了清晰的改进路径；更以真实用户行为为核心的设计理念，重新定义了 LLM 工具使用评估的标准，推动行业从 &amp;ldquo;理想化测试&amp;rdquo; 迈向 &amp;ldquo;真实场景验证&amp;rdquo;。对于企业而言，WildToolBench 可帮助其更精准地评估 LLM 智能体的实际应用潜力，避免技术选型偏差；对于科研人员，它则为 LLM 工具使用能力的研究提供了贴近实际需求的 &amp;ldquo;试验场&amp;rdquo;。&lt;/p&gt;&lt;p&gt;如今，WildToolBench 的数据集、评估脚本及可控多智能体数据合成框架已全部开源，诚邀全球 AI 研究者与开发者共同探索 LLM&amp;nbsp;Agentic&amp;nbsp;能力的突破之道。&lt;/p&gt;&lt;p&gt;数据集：&lt;a href="https://github.com/yupeijei1997/WildToolBench/blob/main/wild-tool-bench/data/Wild-Tool-Bench.jsonl"&gt;&lt;u&gt;WildToolBench/wild-tool-bench/data/Wild-Tool-Bench.jsonl at main &amp;middot; yupeijei1997/WildToolBench &amp;middot; GitHub&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;评估脚本：&lt;a href="https://github.com/yupeijei1997/WildToolBench/tree/main/wild-tool-bench/wtb"&gt;&lt;u&gt;WildToolBench/wild-tool-bench/wtb at main &amp;middot; yupeijei1997/WildToolBench &amp;middot; GitHub&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;可控多智能体数据合成框架：&lt;a href="https://github.com/yupeijei1997/WildToolBench/tree/main/multi-agent-framework"&gt;&lt;u&gt;WildToolBench/multi-agent-framework at main &amp;middot; yupeijei1997/WildToolBench &amp;middot; GitHub&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>钉钉北京峰会展示AI落地多行业样本，一批企业集中签约</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 04 Feb 2026 10:58:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;2月3日，以&amp;ldquo;AI时代的工作方式&amp;rdquo;为主题的钉峰会在北京隆重举行。峰会由阿里巴巴钉钉和中关村国际共同举办，汇聚了来自制造业、农业、供应链、环保、文媒等多行业的领军企业代表、数字化先锋及专家逾三百人，深入探讨人工智能浪潮下工作方式的重塑与进化。&lt;/p&gt;&lt;p&gt;现场，一批北京区域企业与钉钉集中签约，共同迈入AI时代的工作方式，包括博锐尚格科技股份有限公司、天津市神州商龙科技股份有限公司、北京健坤餐饮集团、北京央视瑞安技术服务有限公司等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体操作系统：从&lt;/strong&gt;&lt;strong&gt;工具&lt;/strong&gt;&lt;strong&gt;到伙伴的进化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;钉钉华北大区总经理刘浩在致辞中指出，当前正处在AI转型的关键时间点。钉钉以解决真实问题为原点，致力于从传统的应用平台升级为面向未来的&amp;ldquo;智能体操作系统&amp;rdquo;（Agent OS）。他强调，AI时代的工作方式需要根本性的重新思考，即从&amp;ldquo;人操作工具&amp;rdquo;转向&amp;ldquo;人调教AI&amp;rdquo;，让智能体（Agent）成为业务执行与协同的核心单元。&lt;img src="https://image.jiqizhixin.com/uploads/editor/572106a8-a4d3-428c-b800-542ff65b7bf2/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 钉钉华北大区总经理刘浩&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;中关村国际控股有限公司总经理卢江表示表示，中关村国际正通过覆盖全球的创新网络，携手钉钉，表示，以AI为纽带、出海服务为桥梁，共同优化AI时代的服务模式，让创新价值在全球范围内绽放。&lt;/p&gt;&lt;p&gt;钉钉华北大区解决方案总经理刘啸天在主题分享中阐释了&amp;ldquo;智能体协同&amp;rdquo;的核心逻辑。他认为，AI规模化落地的关键瓶颈不再是模型能力，而在于缺乏企业级统一的运行环境。钉钉正以Agent OS为内核，构建下一代操作系统，通过智能体统一调度数字工具与物理设备，并实现智能体间的交互与协同。人在这一系统中的角色，从执行者转变为&amp;ldquo;教练&amp;rdquo;，负责调教与设定目标，而将重复性、流程化的工作交由智能体执行。&lt;/p&gt;&lt;p&gt;全网爆火的钉钉首款AI硬件DingTalk A1录音卡也在本次峰会上亮相，A1产品负责人夏治朋详细介绍了这款&amp;ldquo;网红&amp;rdquo;产品设计的初衷和用户自发探索出的花式用法，现场种草。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;跨界实践：AI赋能千行百业，客户亲述转型心声&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;峰会邀请了多位来自一线企业的代表，分享了其利用钉钉AI能力进行数字化转型的前沿实践，并在现场亲述了转型过程中的真实洞察。&lt;/p&gt;&lt;p&gt;佳沃集团知识管理副总裁李萌带来《一颗蓝莓的AI之旅&amp;mdash;&amp;mdash;佳沃集团AI应用实践》主题分享。&lt;img src="https://image.jiqizhixin.com/uploads/editor/6bc84482-8169-4482-a75c-7232d383d1d6/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 佳沃集团知识管理副总裁李萌&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;佳沃集团有限公司创立于2012年，是联想控股旗下的现代农业和食品产业集团，位列中国农业企业500强第36名，更是中国农业数智化转型的标杆企业。&lt;/p&gt;&lt;p&gt;自2020、年起，佳沃与钉钉共建了以知识管理为内核的数智化生态，通过数据上钉、经验上钉、办公全场景上钉，特别是AI助理&amp;ldquo;小佳&amp;rdquo;的应用，让员工满意度不断提升，新员工培训成本降低50%，一线农人也能随时获取专业建议，经验实时更新，行政事务一站式解决。&lt;/p&gt;&lt;p&gt;2025年钉钉推出AI表格后，佳沃蓝莓也第一时间成为AI表格到深度用户。利用AI表格，佳沃把过去的N张表格变成一张看板，把过去来源于口头、微信、备注等各处无法统计的非结构化信息，变成标签化、可计算的结构化信息。&lt;/p&gt;&lt;p&gt;&amp;ldquo;钉钉AI表格现在可以通过语音录入来输入了，这个功能非常好！&amp;rdquo;李萌说，这意味着田间地头的农人都可以把经验和信息沉淀到AI表格上。&lt;/p&gt;&lt;p&gt;蜀海供应链管理有限责任公司产品总监邢禺分享了蜀海作为餐饮供应链公司的AI实战经验。蜀海曾是海底捞供应链部门，2014年起独立为第三方供应链服务公司。2020年起，蜀海引入钉钉，帮助解决组织的协同问题，2025年起重点推进AI能力，深度赋能多个智能体应用场景，助力AI转型。&lt;/p&gt;&lt;p&gt;邢禺展示了AI在复杂物流配送、智能补货计划及全国仓储会议管理中的深度应用。&amp;ldquo;AI不只是替代人，而是解放人，让从业者脱离重复劳动，聚焦核心的服务。&amp;rdquo; 通过AI算法优化配送路线，将履约率提升至99%；利用AI听记与表格自动分析海量会议内容，挖掘共性问题，使问题闭环率超90%，显著提升了供应链响应速度与管理透明度。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a436d962-34fb-4063-b1d2-7789cc39573c/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 北控水务AI创新部负责人刘连波&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;北控水务是北控集团旗下专注于水资源循环利用和水生态环境保护事业的旗舰企业，在香港主板上市，集产业投资、设计、建设、运营、技术服务与资本运作为一体，水处理规模位居国内行业前列。已入选恒生香港中资企业指数成份股、摩根斯坦利资本国际指数等多只重要国际成分股。&lt;/p&gt;&lt;p&gt;北控水务AI创新部负责人刘连波在钉峰会现场分享了其以&amp;ldquo;补位&amp;rdquo;思路推进AI落地的策略。刘连波表示，&amp;ldquo;近一年来，我们在不断研究从场景探索到能力补强，AI应用从价值验证到构建核心能力，从AI+业务、AI+组织到AI+员工，与钉钉一起继续深挖AI场景和共建AI能力和文化。&amp;rdquo;&lt;/p&gt;&lt;p&gt;他展示了一组数据：基于钉钉知识库，公司迅速孵化AI助手，在很多个超过500人的群里接入了AI助手，目前每月调用3000次以上，回答准确率93%以上。AI工具对近半数员工提高效率20%到50%。&lt;/p&gt;&lt;p&gt;央视瑞安信息化工程师杨过分享了国企信息化落地的经验和方法。央视瑞安作为中央广播电视总台全资子公司，是广播电视领域动力运维与综合技术服务的标杆企业。&amp;ldquo;解决工作中协作问题的关键就是从&amp;lsquo;传纸条&amp;rsquo;变成&amp;lsquo;共看一张图&amp;rsquo;，要善于利用时代最先进的工具为自己所用。&amp;rdquo;杨过说。通过钉钉OA审批和AI表格的联动，央视瑞安搭建了外出保障工作管理平台，实现了流程驱动数据，数据反哺流程的闭环。&lt;/p&gt;&lt;p&gt;&amp;ldquo;AI表格是真的好用，既有科技感，还不用写代码&amp;rdquo;，杨过说，&amp;ldquo;像外出保障工作管理平台，就是我和另一个工程师两个人搭建起来的。&amp;rdquo;&lt;/p&gt;&lt;p&gt;整场峰会气氛热烈，并传递出一个明确信号：AI时代的工作方式变革已进入深化实践阶段，&amp;ldquo;智能体协同&amp;rdquo;不再是一个遥远的概念，而是正在千行百业中落地生根，成为提升组织韧性、激发创新活力、锻造未来竞争力的关键引擎。企业与个人唯有主动拥抱这一变革，方能立于AI浪潮之巅。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，真正好用的Windows版「Cowork」上线了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 10:31:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杜伟、泽南&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;section&gt;天工 Skywork 桌面版旗帜鲜明地将 Windows 平台作为首发阵地，为全球用户提供开箱即用的「Cowork 平替」。&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;终于，Windows 原生「Cowork」问世了！&lt;/p&gt;&lt;p&gt;过去两周，AI 圈被火遍硅谷的 ClawdBot（现已改名为 OpenClaw）持续刷屏。&lt;/p&gt;&lt;p&gt;人们一边震撼于这个智能体助理带来的自动化效率提升，另一边也在吐槽其对 Windows 系统的适配。比如，根据一些用户的反馈，如果严格按照官网提供的命令行在 Windows 上安装 ClawdBot，将导致 Skills 功能彻底失效。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGBIjW0qbxQ4lR0tgCrib0JkUFBTXQZdKR7piciaP9tocIpzkrnO0RE8q1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.8379629629629629" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531376" data-aistatus="1" data-original-style="height: auto !important;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/43771591-a720-48a7-82f4-06a6af909c83/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这并不是 ClawdBot 一个智能体助手的选择性倾向，上个月发布的 Claude Cowork 以及 OpenAI 昨天亮相的智能体式 Codex 应用同样优先适配 macOS 系统。这种生态上的失衡在今天迎来了转机。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;国产大模型玩家昆仑天工正式发布了全新的 Agent 产品 &amp;mdash;&amp;mdash; 天工 Skywork 桌面版，旗帜鲜明地将 Windows 平台作为首发阵地&lt;/strong&gt;，为全球用户带来了开箱即用的「Cowork 平替」。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1e92a794-82fa-4c5e-8151-211a194e2ff8/1770171920011.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Skywork 原生支持 Windows 系统，无需繁琐的迁移或适配，即可对海量本地历史文件和复杂项目场景展开自动化处理。这种高度的兼容性打通了个人 Agent 进入真实办公场景的「最后一公里」。&lt;/p&gt;&lt;p&gt;在优先适配 Windows 平台之外，Skywork 在&lt;strong&gt;基础模型选择、功能支持、能力扩展&lt;/strong&gt;等其他维度同样有亮眼表现。&lt;/p&gt;&lt;p&gt;首先，与 Claude Cowork 仅支持自家 Claude 模型不同，Skywork 增加了对谷歌 Gemini 的支持，充分发挥该系列模型的原生多模态理解与生成优势。&lt;/p&gt;&lt;p&gt;现在，用户可以自由选择 Gemini 3 Pro 以及 Claude Opus 4.5、Claude Sonnet 4.5 等不同模型。当然也可以启用智能路由「auto」模式，系统自动识别任务类型并匹配最适合的模型，最大化执行效率。&lt;/p&gt;&lt;p&gt;其次，&lt;strong&gt;Skywork 在主打办公场景的同时，也能 hold 住创作场景&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531377" data-ratio="0.6851851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGKgqAyr1w566FIb9FZRkWxr1RqF35vib2kfjdvMIXfvp05JTvQCabhhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f462d30f-935f-4eac-930f-1e49893b07e5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Skywork 界面&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了全方位满足桌面级真实办公需求，Skywork 桌面版做到了对全类型文件的智能管理。不管是图片、视频、表格、Word、Excel、PDF、PPT 还是其他格式，它都能跨文件、跨格式直接读取并理解，遵循用户任务指令对它们进行归类整理或生成新内容。&lt;/p&gt;&lt;p&gt;并且，它能&lt;strong&gt;同时响应并执行多项复杂任务&lt;/strong&gt;，效率拉满。此外也无需上传云端，&lt;strong&gt;在本地环境完成即可&lt;/strong&gt;，消除了用户对数据泄露和文件安全的担忧。&lt;/p&gt;&lt;p&gt;面向图像与视频生成的创作场景，比如制作 PPT、宣传素材，整理可视化报告，创作多媒体内容，Skywork 相较于 Claude Cowork，在语义遵循以及表现力、专业性等多方面均更胜一筹。&lt;/p&gt;&lt;p&gt;最后是能力扩展，&lt;strong&gt;Skywork 内置了 100+ 个经过精选的、真正有用的 Skills 技能包&lt;/strong&gt;，并将控制权交给用户，既可以手动选择也可由系统根据任务类型自动筛选，操作灵活，覆盖了 Office 三件套生成、网页生成以及图像与视频生成。&lt;/p&gt;&lt;p&gt;此外，Skywork &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在价格上也极具杀伤力。&lt;strong&gt;用户只需 19.99 美元的 Basic 会员，就能解锁完整的产品体验&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;下载地址：https://skywork.ai/desktop&amp;nbsp;&lt;/p&gt;&lt;p&gt;在全球竞品偏向 macOS 开发的当下，昆仑天工的 Skywork，打响了一场针对「Windows 生产力人群」的抢位战。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上手实测：这会是办公自动化的「奇点」吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;话不多说，我们直接开测。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;告别「碎片化」办公&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上个星期，昆仑天工开源了 SkyReels-V3 视频生成模型，我们对此进行了报道。当时是以文章的形式进行了介绍，用到了大量图片、视频素材。&lt;/p&gt;&lt;p&gt;假如我们现在转换一下身份，&lt;strong&gt;用 PPT 向别人介绍这个模型怎么办？&lt;/strong&gt;这正是 Skywork 的用武之地，模型选用「gemini-3-pro-preview」。&lt;/p&gt;&lt;p&gt;只需要告诉它你要制作这样一个 PPT，文档的 Word 版和视频素材一股脑地放在文件夹里，它就会自行分析需求，把素材找好做成一个可供使用的版本出来。&lt;/p&gt;&lt;p&gt;可以看到，在生成中间，它还会问你要选什么样的风格，这是一个需要互动的过程。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/151750a9-6fa8-4a84-a7cf-eff5a99fb2ad/1770172033027.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最后在生成的 PPT 的基础上，你可以进行修改，节省了大量的前期工作。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531411" data-ratio="0.56" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGx3VQzXmicR7QGIeBqOT3IOiaKVV7H0g2a9licmMcOk2y5icKcz8JAXdzgA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-type="gif" data-w="800" type="block" data-original-style="height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/645f8bf6-125d-4343-a6f5-ffbe4f2bb68d/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来尝试一个更复杂的案例，&lt;strong&gt;让 Skywork 在不删除任何原始文件的基础上，将文件夹内的所有内容整理成一套清晰直观的目录结构&lt;/strong&gt;，并在任务完成后给出一份简要报告，列出新的文件夹结构和变更日志。&lt;/p&gt;&lt;p&gt;这项任务要求 Agent 具备强大的环境感知能力与跨格式解析能力，这次选用 Claude Opus 4.5。&lt;/p&gt;&lt;p&gt;在实际跑的过程中，Skywork 首先「穿透」不同层级的子目录，精准识别出了 Word、Excel、PDF 等不同格式的文件数据。然后在语义理解的基础上，它自动剔除冗余信息，重组碎片化信息，并生成逻辑严密的结构化报告。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/030f5739-7df7-4a7d-9ef5-930e7dc0ebb3/1770172056846.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最终生成的「目录结构整理报告」是这样的：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531420" data-ratio="0.6132723112128147" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG8fE4koCry5TOvHoTqPBhafVZqmJNHR1ySYIAncib7Y0kictS3u62ibxTg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-type="gif" data-w="874" type="block" data-original-style="height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5cafac8d-b789-441d-9556-83d11cbf9d64/640.gif" data-order="1" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;多模态能力融入工作流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;英伟达最近和 OpenAI 之间的新闻引发了科技圈的关注。目前多路媒体的报道认为，英伟达已经暂停了向 OpenAI 投资高达 1000 亿美元的计划。而 OpenAI 也正在寻求构建 GPU 以外的算力体系。&lt;/p&gt;&lt;p&gt;那么作为一家「以先进 AI 推理芯片为主要产品的公司」，机器之心能否在下一轮 OpenAI 的融资上找到机会呢？我们&lt;strong&gt;让 Skywork 来生成一份意向报告，要求图文并茂。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;怎么看这都是一个大工程。这回它分析需求以后上网进行了搜索，在知乎上搜到了机器之心以前发过的一些文章。&lt;/p&gt;&lt;p&gt;接着它整理了大致的撰写路径之后开始工作，自己给自己列出了要完成的事项，为了写 Word 文档，还自己下载了 docx 的库。&lt;/p&gt;&lt;p&gt;可见最后生成的「下一代 AI 推理算力基础设施提案」有那么一点可行性。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8ae96629-20b3-4008-a95f-a16d204cb8ab/1770172089215.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最后尝试一个更有挑战性的场景，看看 Skywork 能不能&lt;strong&gt;根据文档和图片生成一个精美的 SEO 网页&lt;/strong&gt;。这类任务要求 Agent 既能理解内容，还会工程实现。&lt;/p&gt;&lt;p&gt;一要精准提取文档中的核心语义，为撰写高质量网页文案做好准备。二要利用视觉处理能力来裁剪、优化图片并嵌入到合适的布局中。&lt;/p&gt;&lt;p&gt;最后也是最关键的一步，它要能自主编写出符合 SEO 逻辑的代码，将原本孤立的图文素材转化为信息齐全、布局合理、观感友好的网页。&lt;a href="https://mp.weixin.qq.com/s/nKe1iObLWXxawodTrFumnw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e8a15a48-250e-44b8-981c-ab3898e5f259/1770172131643.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;简单的几个案例跑下来，我们发现：Skywork 这样的智能体助手已经不再只是一个等待执行用户指令的对话框，它们在拥有更高的系统操作权限之后，自主性得到史诗级强化，从而在极少的人为参与下高效地完成工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从「编程智能体」走向「个人助理智能体」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年被普遍认为是 Agent 落地元年，而刚过去一个月的 2026 年，我们正在见证新一轮的爆发。&lt;/p&gt;&lt;p&gt;一开年，Agent 赛道的竞争便趋于白热化，国外 Anthropic 发布 Cowork、OpenClaw 引爆 A I 社区，国内大厂阿里先后上线千问 APP 任务助理、桌面端 QoderWork，其他大模型独角兽也陆续推出桌面智能体应用。&lt;/p&gt;&lt;p&gt;业界玩家们你追我赶的发布节奏，一定程度上可以验证 OpenClaw 创建者 Peter Steinberger 近日接受采访时表达的一种观点。他认为，&lt;strong&gt;2025 年是编程智能体元年，而今年将是个人助理智能体元年&lt;/strong&gt;。这位搅动硅谷的开发者还放出狂言，「我们手机里 80% 的 APP 将被取代。」&lt;/p&gt;&lt;p&gt;Steinberger 的判断只是一家之言，但通过 Agent 打造超级个体的行业趋势是显而易见的。不管是聚焦职场人士还是普通用户，Agent 正在以前所未有的速度与深度重构数字世界的底层逻辑。&lt;/p&gt;&lt;p&gt;在桌面端，Agent 连接本地操作系统，实现跨文件管理、跨应用操作、复杂任务并行执行；在移动端，打破 APP 孤岛，实现主动意图感知、跨软件调度与全链路执行。与人类生活、工作、学习息息相关的双端并进，将加速驱动人类走向以 Agent 为主导的超级个体时代。&lt;/p&gt;&lt;p&gt;可以预见的是，对个人更友好、易用性与专业性更强的 Agent，势必收获更多潜在用户群体的青睐与认可。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当赢家无法通吃，相对优势或成护城河&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如 ChatGPT 问世之后的数年一样，2026 年 AI 领域仍是「步履不停」。对于所有入局者，尤其是以 AGI 为终极目标的大模型厂商们，谁都不愿在新一轮的狂飙中落后。&lt;/p&gt;&lt;p&gt;尤其是在行业焦虑大模型算力溢出、预训练 Scaling Laws 边际效益增长放缓的当下，大家都在期待下一次 AI 奇点的到来。两周前，DeepMind CEO 哈萨比斯在一次播客节目中表示，「实现 AGI 的路上可能还需要一两个重大创新」。&lt;/p&gt;&lt;p&gt;在那之前，Agent 成为释放与扩展基础大模型潜能的「第二曲线」。通过对个人生活与工作、企业生产范式的变革，Agent 将人类从繁琐、重复性的任务中解脱出来，将更多时间与精力放在能够发挥创造力与想象力、产生高价值的板块。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;随着 Agent 一步步踏入深水区，或许不会出现「赢家通吃」的局面。&lt;/strong&gt;现如今，全球开源社区已经对 Agent 底层模型和执行框架进行了大量解构，该赛道几乎不存在「技术秘密」。主流大模型厂商都有能力自研出 Agent 产品，这样一来竞争的胜负手转向了场景垂直与生态适配。&lt;/p&gt;&lt;p&gt;昆仑万工早在 2025 年 5 月即发布了「AI 版 Office」&amp;mdash;&amp;mdash; 天工超级智能体（&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650970454&amp;idx=1&amp;sn=7b453aa27f07c6e6b897f3a73e815d67&amp;scene=21#wechat_redirect" target="_blank"&gt;Skywork Super Agents&lt;/a&gt;，即 Skywork 网页版），成为国内较早布局 Agent 的厂商，积累了丰富的办公场景效率优化经验，拥有了庞大的 AI 办公用户基础，并让他们对其产品有了很强的认知。&lt;/p&gt;&lt;p&gt;现在，Skywork 桌面版依托 Windows 这个全球最大生产力平台，灵活支持 Gemini 3 Pro 多模态与 Claude 4.5 逻辑推理能力，在继续对办公场景的效率优化以及与其他应用场景的联动中构筑起护城河。&lt;/p&gt;&lt;p&gt;在这场愈演愈烈的 Agent 之战中，谁能更快地建立起无法替代的相对优势，或许就是最后的赢家。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Attention真的可靠吗？上海大学联合南开大学揭示多模态模型中一个被忽视的重要偏置问题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 04 Feb 2026 10:22:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-04</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-04</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/29adb014-f2c3-404c-a5a8-513f4619da0e/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近年来，Vision-Language Models（视觉 &amp;mdash; 语言模型）在多模态理解任务中取得了显著进展，并逐渐成为通用人工智能的重要技术路线。然而，这类模型在实际应用中往往面临推理开销大、效率受限的问题，研究者通常依赖 visual token pruning 等策略降低计算成本，其中 attention 机制被广泛视为衡量视觉信息重要性的关键依据。&lt;/p&gt;&lt;p&gt;近日，上海大学曾丹团队联合南开大学研究人员，从 attention 可靠性的角度出发，系统揭示了 Vision-Language Models 中普遍存在的 attention 偏置问题，并提出了一种无需重新训练的 attention 去偏方法，在多个主流模型、剪枝策略及图像与视频基准上验证了其有效性，为多模态模型的高效、可靠部署提供了新的思路。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGwzIrjPM0GgdxqXYqMGlJCXrU5ibEgqDzAicYj0kahDhtLFHjxntqh0Ag/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.17222222222222222" data-type="png" data-w="1080" data-width="1582" data-height="272" data-imgfileid="503531357" data-aistatus="1" data-original-style="background-color: transparent;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1205a911-344c-48e5-b637-35f0d834da7b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml6a4plr35o" data-pm-slice="0 0 []"&gt;论文标题：Attention Debiasing for Token Pruning in Vision Language Models&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://arxiv.org/abs/2508.17807&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml6a1f7d1u8d" data-pm-slice="0 0 []"&gt;代码链接：https://github.com/intcomp/attention-bias&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-mpa-action-id="ml6a5idrtp2" data-pm-slice="0 0 []"&gt;&lt;strong&gt;一、研究意义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;近年来，视觉 &amp;mdash; 语言模型（Vision-Language Models，VLMs）在图像理解、视觉问答、多模态对话等任务中表现突出，并逐渐成为通用人工智能的重要技术基础。然而，这类模型在实际部署时往往面临一个现实挑战：&lt;strong&gt;模型推理成本高，速度慢。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为提升效率，研究者通常会采用 &lt;u&gt;visual token pruning（视觉 token 剪枝） &lt;/u&gt;技术，即在不显著影响性能的前提下，丢弃不重要的视觉信息。其中，attention 机制 被广泛用作判断 &amp;ldquo;哪些视觉 token 更重要&amp;rdquo; 的核心依据。&lt;/p&gt;&lt;p&gt;但上海大学曾丹团队在研究中发现：&lt;strong&gt;attention 并不总是可靠的 &amp;ldquo;重要性指标&amp;rdquo;&lt;/strong&gt;。在多模态模型中，attention 往往受到多种结构性偏置的影响，这些偏置与真实语义无关，却会直接左右剪枝结果，从而影响模型性能。&lt;/p&gt;&lt;p&gt;针对这一问题，该团队系统分析了 VLM 中 attention 的行为特性，提出了一种 &lt;strong&gt;Attention Debiasing（注意力去偏）方法&lt;/strong&gt;，在无需重新训练模型的前提下，有效提升了多种主流剪枝方法的稳定性与可靠性。如下图所示，提出的方法应用于目前基于 attention 的剪枝方法上之后，都有提升。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGvDIibWffz5hHngZgXjq8LYYqVlejXvjjzCcL69evrxe33Dpk3VUgqAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8462962962962963" data-type="png" data-w="1080" data-width="2783" data-height="2354" data-imgfileid="503531358" data-aistatus="1" data-original-style="background-color: transparent;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7ffefe18-a7f1-4fe1-8f63-265ed8e8c2f6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;二、研究背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在直觉上，attention 机制往往被理解为 &amp;ldquo;模型更关注哪里&amp;rdquo;，因此被自然地视为语义重要性的体现。然而，曾丹团队的研究表明，在 Vision-Language Models 中，attention 往往并非只由内容决定，而是隐含着多种系统性偏置。&lt;/p&gt;&lt;p&gt;其中最典型的有两类：&lt;/p&gt;&lt;p&gt;第一类是 &lt;strong&gt;位置偏置（recency bias）&lt;/strong&gt;。研究发现，language-to-vision attention 会随着视觉 token 在序列中的位置不断增大，也就是说，模型更倾向于关注 &amp;ldquo;后面的 token&amp;rdquo;。如图所示，这通常表现为模型对图像下方区域给予更高 attention，即便这些区域并不包含关键信息。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG2whGlT1Gy65hCcWhRqSNAh1aVqUlsNKhqyVhFiag8c1xBY2n4YrDzEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4203703703703704" data-type="png" data-w="1080" data-width="1414" data-height="595" data-imgfileid="503531359" data-aistatus="1" data-original-style="background-color: transparent;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6b7cd923-ee59-45eb-8a88-129bebf79b17/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;第二类是&lt;strong&gt; padding 引发的 attention sink 现象&lt;/strong&gt;。在实际输入中，为了统一尺寸，图像往往需要 padding，但这些区域在语义上是 &amp;ldquo;空白&amp;rdquo; 的。然而，由于 hidden state 中出现异常激活，padding 对应的 token 反而可能获得较高 attention，从而被错误地保留下来。下图是 pad 区域填充不同的数值时，pad 区域对应的 attention score 数值以及 hidden states 的激活值。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGl5WPocMg79WcDliazzMje8C0G9vrXVDCGvcwCbQVfT7ia5kIqmeQxTaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4916666666666667" data-type="png" data-w="1080" data-width="2774" data-height="4137" data-imgfileid="503531360" data-aistatus="1" data-original-style="background-color: transparent;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/42ade913-7119-450b-b8d3-4dbff0a0b2de/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更值得注意的是，当 attention 被用于剪枝排序时，这些偏置并不会被削弱，反而会被进一步放大，最终导致剪枝结果偏离真实语义需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、研究方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对上述问题，上海大学曾丹团队并没有提出新的剪枝算法，也没有对模型结构进行修改，而是从一个更基础的角度出发：&lt;strong&gt;既然 attention 本身是有偏的，是否可以先对 attention 进行修正？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该团队观察到，attention 中的偏置并非随机噪声，而是呈现出&lt;strong&gt;稳定的整体趋势&lt;/strong&gt;。因此，他们通过对 attention 随 token 位置变化的趋势进行拟合，构建了一条反映 &amp;ldquo;位置偏置&amp;rdquo; 的曲线，并在此基础上对原始 attention 进行去偏修正，显式削弱与内容无关的位置因素，使 attention 更接近真实的语义重要性。如下图所示。&lt;/p&gt;&lt;p&gt;与此同时，在剪枝阶段显式抑制 padding token 的影响，避免语义为空的区域干扰剪枝排序。整个过程无需重新训练模型，也不依赖特定的剪枝策略，可作为 &lt;strong&gt;plug-and-play 模块&lt;/strong&gt; 直接集成到现有方法中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGxXJicJyvtNGh2zgSsRd0MgsT5hQZ9e7Et4jFJiaFFASjXR3SQd7riagHw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6111111111111112" data-type="png" data-w="1080" data-width="2800" data-height="1711" data-imgfileid="503531361" data-aistatus="1" data-original-style="background-color: transparent;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d5de95f5-3a76-4358-8218-11799230bc9b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验验证中，该团队将 Attention Debiasing 方法集成到 FastV、PyramidDrop、SparseVLM、HiMAP、TokenCarve、iLLaVA 等 6 种主流 attention-based 剪枝方法中，在 10 个图像理解基准与 3 个视频理解基准 上进行了系统评估，并覆盖 LLaVA-7B / 13B 等多种主流 Vision-Language Models。&lt;/p&gt;&lt;p&gt;实验结果表明，在几乎所有设置下，经过 attention 去偏修正后，剪枝模型都能获得一致且稳定的性能提升，且在剪枝更激进、token 预算更紧张的情况下效果尤为明显。这说明，对 attention 进行去偏处理，有助于模型在 &amp;ldquo;更少信息&amp;rdquo; 的条件下做出更可靠的判断。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGhfAOdzicic8nYUA8iaOKOwMpuCWYib6WC4wEQXPj14I9bslrKNUfD8tH2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7444444444444445" data-type="png" data-w="1080" data-width="5897" data-height="4389" data-imgfileid="503531362" data-aistatus="1" data-original-style="background-color: transparent;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/859ee5d0-f477-41b2-b4f9-fd4ac60cee03/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG4v0uiaSS5ia63KV2rrEbzdyw92a7x8Ckyy5lrplBISbqlR3iapkXicQewQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.762962962962963" data-type="png" data-w="1080" data-width="2749" data-height="2099" data-imgfileid="503531363" data-aistatus="1" data-original-style="background-color: transparent;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7c60104d-3a7c-47d3-9814-34447f582d6d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;此外，通过对实验结果的可视化分析，原始 attention-based 剪枝方法往往保留了大量位于图像下方或 padding 区域的视觉 token，而与问题语义密切相关的关键区域却容易被忽略。引入 attention 去偏修正后，模型保留的视觉区域更加集中于目标物体及关键细节位置，有效减少了无关背景的干扰。该结果直观验证了 attention 去偏在提升剪枝合理性和可解释性方面的作用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGZVsJey8ibvLicV4cficZNVnj75bRlZAdV4ZAico69Y5Wj0zJ1t30p6z5Fg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-ratio="0.9805555555555555" data-type="jpeg" data-w="1080" data-width="10190" data-height="9988" data-imgfileid="503531364" data-aistatus="1" data-original-style="background-color: transparent;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/d5aad272-5614-47c9-a79d-36ab7082e71e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;五、总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该研究表明，attention 并非天然等价于语义重要性，尤其在 Vision-Language Models 中，如果忽视 attention 中潜在的结构性偏置，基于 attention 的剪枝策略可能会被误导。上海大学曾丹团队通过简单而有效的 attention 去偏方法，显著提升了多模态模型在效率与可靠性之间的平衡能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大道至简，何恺明团队新作pMF开启像素级「无潜、单步」生成范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 03 Feb 2026 23:29:46 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;何恺明团队新论文，再次「大道至简」。&lt;/p&gt;&lt;p&gt;此次研究直指当前以 DiT 为代表的主流扩散模型与流匹配模型存在的通病，并&lt;strong&gt;提出了一种用于单步、无潜空间（Latent-free）的图像生成新框架&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531379" data-ratio="0.22685185185185186" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGnEx31ugHbKJ2T7VKvjY4fEAEUlKE9SxBDo8pNiatrfK52C5GMBafLrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7cdaf6f2-e045-41fa-85b5-0a303c848bd0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：One-step Latent-free Image Generation with Pixel Mean Flows&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;arXiv 地址：https://arxiv.org/pdf/2601.22158v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在生成式 AI 领域，追求更高效、更直接的生成范式一直是学界的核心目标。&lt;/p&gt;&lt;p&gt;当前，以 DiT 为代表的主流扩散模型与流匹配模型主要依赖两大支柱来降低生成难度，一是通过多步采样将复杂的分布转换分解为微小的步进，二是在预训练 VAE（变分自编码器）的潜空间中运行以降低计算维度。&lt;/p&gt;&lt;p&gt;尽管这些设计在图像质量上取得了巨大成功，但从深度学习「端到端」的精神来看，这种对多步迭代和预置编码器的依赖，无疑增加了系统的复杂性和推理开销。&lt;/p&gt;&lt;p&gt;面对这些挑战，&lt;strong&gt;何恺明团队提出了用于单步、无潜空间图像生成的 pixel MeanFlow（pMF）框架&lt;/strong&gt;。该框架继承了改进均值流（improved MeanFlow，MF）的思路，通过在瞬时速度（即 v）空间内定义损失函数，来学习平均速度场（即 u）。&lt;/p&gt;&lt;p&gt;与此同时，受 Just image Transformers（JiT）的启发，pMF 直接对类似于去噪图像的物理量（即 x-prediction 值）进行参数化，并预期该物理量位于低维流形上。&lt;/p&gt;&lt;p&gt;为了兼容这两种设计，团队引入了一种转换机制，将 v、u 和 x 三个场联系起来。实验证明，这种设计更符合流形假设，并且产生了一个更易于学习的目标（见下图 1）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGiaZggwV4geVZVVexd8RDtveqjEeHBVbkDfGTP9KtLJCaorMibVpG9hgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.42592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531380" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/eff7bbdd-aee4-4a7f-bc1f-2851979e49f6/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;概括来说，&lt;strong&gt;pMF 训练了一个能将噪声输入直接映射为图像像素的网络&lt;/strong&gt;。它具备「所见即所得」的特性，而这在多步采样或基于潜空间的方法中是不存在的。这一特性使得感知损失能够自然地集成到 pMF 中，从而进一步提升生成质量。&lt;/p&gt;&lt;p&gt;实验结果显示，pMF 在单步、无潜空间生成方面表现强劲，在 ImageNet 数据集上，256x256 分辨率下的 FID 达到 2.22，512x512 分辨率下达到 2.48。团队进一步证明，选择合适的预测目标至关重要：在像素空间直接预测速度场会导致性能崩溃。&lt;/p&gt;&lt;p&gt;本文验证了：&lt;strong&gt;单步、无潜空间生成正变得既可行又具竞争力，这标志着向构建单一、端到端神经网络形式的直接生成建模迈出了坚实的一步。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;框架方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了实现单步、无潜空间的生成，团队引入了 pMF（pixel MeanFlow），它的核心设计在于建立 u、 v 和 x 这三个不同场之间的关联。团队希望网络能像 JiT 那样直接输出 x，而单步建模则像均值流 (MeanFlow) 一样在 u 和 v 空间内进行。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;去噪图像场&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;iMF 和 JiT 都可以被视为在最小化 v-loss，不同之处在于 iMF 执行的是 u-prediction，而 JiT 执行的是 x-prediction。团队在 u 与广义形式的 x 之间引入了一种联系。&lt;/p&gt;&lt;p&gt;原论文等式 (5) 中定义的平均速度场 u 代表了一个潜在的基准真值（ground-truth），它取决于 p_data、p_prior 以及时间调度，但与网络无关（因此不依赖于参数 &amp;theta;）。团队引出了一个定义为 x (z_t, r, t) 的新场：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGsRe2QvicnWiaM7lBXzSgut1uWI5UGPJlg3t0ElCubW2YtsZ7WovItPYQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.17777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531382" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c590c57f-1062-44eb-87f8-714e38d65016/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;可泛化的流形假设&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上图 1 通过模拟从预训练流匹配（FM）模型中获得的一条 ODE 轨迹，可视化了 u 场和 x 场。u 包含噪声图像，这是因为作为速度场，u 同时包含了噪声和数据成分。相比之下，x 场具有去噪图像的外观：它们或是近乎清晰的图像，或是因过度去噪而显得模糊的图像。接下来，团队讨论了如何将流形假设泛化到一物理量 x 上。&lt;/p&gt;&lt;p&gt;请注意，MeanFlow 中的时间步 r 满足：&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGmloB9m6Hvuv5UZqld1YWCbBBLtGFKKp7BFvuUlgECcZY4orITfdSCA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.2789115646258503" data-s="300,640" data-type="png" data-w="588" type="block" data-imgfileid="503531383" data-aistatus="1" data-original-style="width:60px;height:20px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2d1b0234-2e39-4e16-b18b-6eb82e41b4a8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 8.89%;"&gt;。团队首先展示了 r=t 和 r=0 这两种边界情况可以近似满足流形假设；随后讨论了 0＜r＜t 的情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上文公式 (8) 中导出的 x 场为 MeanFlow 网络提供了一种重参数化方法。具体而言，团队让网络 net_&amp;theta; 直接输出 x，并根据公式 (8) 计算出相应的速度场 u：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGUpJiaiaoaeaS4Cq2fwLSovA8JFkoTHiarE0hlZNeyqgwPRIgA4ZuVRNEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.1259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531385" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5cbdd4ec-323d-46cb-bcc6-ff46f78cc4af/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;接着将公式 (11) 中的 u_&amp;theta; 纳入 iMF 表述中，即结合 v-loss 使用原论文公式 (7)。具体的优化目标如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGzib2fw20CnBaiaMm87DFC4n1vicgA2HTsgqjDFrx2nFeiaiaf642f4f6wOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.1814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531387" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/eb696b0a-fa1d-4193-b494-683826b19080/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从概念上讲，这是基于 x-prediction 的 v-loss，其中 x 通过 x&amp;rarr;u&amp;rarr;v 的关系转换为 v 空间，从而对 v 进行回归。相应的伪代码见算法 1。遵循 iMF 的思路，该算法可以扩展以支持无分类器引导（CFG）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG3SHphiaLOj7vialBqcRD0yKiaNRUvo5lWibCRiahfia9FOlw6pib4A8jGulJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.0842592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531388" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/8371ae76-0235-41c5-8831-4b27954a7c94/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;带有感知损失的像素均值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;网络 x_&amp;theta;(z_t,r,t) 直接将噪声输入 z_t 映射为去噪图像，这使得模型在训练时具备了「所见即所得」的特性。因此团队进一步引入了感知损失，基于潜空间的方法在 tokenizer 重构训练中获益于感知损失，而基于像素的方法此前尚未能轻易利用这一优势。&lt;/p&gt;&lt;p&gt;在形式上，由于 x_&amp;theta; 是像素空间下的去噪图像，团队直接对其应用感知损失（例如 LPIPS ）。整体训练目标为&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWG9fHW5ECmDuHXQS8Rno3ltaMf8n22iajGkpRMqZyAfnRrSDZu31vWcQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.16698292220113853" data-s="300,640" data-type="png" data-w="1054" type="block" data-imgfileid="503531389" data-aistatus="1" data-original-style="width:99px;height:20px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ec107187-a8f2-4bde-91ab-fb30097ee8b3/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 16.5%;"&gt;。在实践中，感知损失可以仅在所添加噪声低于特定阈值（即 t&amp;le;t_thr）时应用，从而确保去噪后的图像不会过于模糊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;玩具（Toy）实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;团队首先通过一个 2D 玩具实验表明，「当底层数据位于低维流形上时，在 MeanFlow 中使用 x-prediction 更加理想。」&lt;/p&gt;&lt;p&gt;图 2 显示，x-prediction 的表现相当出色，而随着维度 D 的增加，u-prediction 的性能迅速退化。团队观察到，这种性能差距反映在训练损失的差异上：x-prediction 的训练损失低于对应的 u-prediction。这表明，对于容量有限的网络而言，预测 x 更加容易。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGmQWCVvSX0wx0U3vZdSS3qNhTCbSGHXS1PGW7Lypz5PsUGAjIcH8ZCQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.9490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531390" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/81d0d120-56db-46ba-ad1f-a94fe9528279/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;团队默认在分辨率为 256x256 的 ImageNet 数据集上进行消融实验。团队采用了 iMF 架构，它是 DiT 设计的一个变体。除非另有说明，团队将 Patch 大小设置为 16&amp;times; 16（表示为 pMF/16）。消融模型从零开始训练了 160 个 Epoch。&lt;/p&gt;&lt;p&gt;关于&lt;strong&gt;网络预测目标&lt;/strong&gt;，团队的方法基于流形假设，即假设 x 处于低维流形中且更易于预测。表 2 验证了这一假设。&lt;/p&gt;&lt;p&gt;首先将 64&amp;times;64 分辨率作为较简单的设置。当 Patch 大小为 4&amp;times;4 时，Patch 维度为 48（即 4&amp;times;4&amp;times;3）。这一维度远低于网络容量（隐藏层维度为 768）。因此，pMF 在 x-prediction 和 u-prediction 下均表现良好。&lt;/p&gt;&lt;p&gt;接下来考虑 256&amp;times;256 分辨率。按照惯例，Patch 大小设为 16&amp;times;16，Patch 维度达到 768（即 16&amp;times;16&amp;times;3）。这导致了更高维的观测空间，增加了神经网络建模的难度。在这种情况下，只有 x-prediction 表现良好，表明 x 位于更低维的流形上，因此更易于学习。&lt;/p&gt;&lt;p&gt;相比之下，u-prediction 性能彻底崩溃：作为一种含噪物理量，u 在高维空间中具有全支撑，建模难度大得多。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGc3M6Ga5IcYwlndpVaUL76THvbn918Zl9o2saAOWfqHlial8lYIZbgTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6620370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531392" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c5eb6454-e10c-48cc-9da0-0346b9e0c0a0/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;关于&lt;strong&gt;高分辨率生成&lt;/strong&gt;，团队在表 4 中研究了分辨率在 256、512 和 1024 下的 pMF。在保持序列长度不变（16^2）的情况下，不同分辨率下大致维持了相同的计算成本。这样做会导致极其激进的 Patch 大小（例如 64^2）和 Patch 维度（例如 12288）。&lt;/p&gt;&lt;p&gt;结果显示，pMF 可以有效处理这种极具挑战性的情况。尽管观测空间是高维的，但模型始终预测 x，其底层维度并不会成比例增长。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGTW39eRCUkxBBG3v9icaZV8iaibg0WLCgYwB3cBxfI2CSNy5hJEZFNgKHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.42962962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531394" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/a8923ea0-9727-40db-996c-8acdb89902a1/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;关于&lt;strong&gt;可扩展性&lt;/strong&gt;，团队在表 5 中报告了增加模型大小和训练 Epoch 的结果。正如预期的那样，pMF 从这两个维度的扩展中均有获益。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531395" data-ratio="0.3287037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGIAIBmkrhaVshqGIoPNa3x4hg2e9LMyVQd4tNus0HcRR4IRJmPpuRicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/cb79cae6-c0b7-408c-8363-4d219e2374e3/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最后，团队在表 6（256&amp;times;256）和表 7（512&amp;times;512）中 ，将 pMF 与之前的模型进行了对比。&lt;/p&gt;&lt;p&gt;其中，在 &lt;strong&gt;256&amp;times;256 分辨率&lt;/strong&gt;下，团队的方法达到了 2.22 FID（在 360 个 Epoch 时），如表 6 所示。据团队的了解，该类别中（单步、无潜空间扩散 / 流模型）唯一的其他方法是最近提出的 EPG，它在自监督预训练下达到了 8.82 FID。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531396" data-ratio="1.4333333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGAzGxib26ChlxwXnehtbUpzbRiaiboRcNoGtUf6FMuLHbich8oceZKVSrQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/d0319ca4-822b-47dc-8b69-23729eea6e43/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在&lt;strong&gt; 512&amp;times;512 分辨率&lt;/strong&gt;下，pMF 达到了 2.48 FID，如表 7 所示。这一结果的计算成本（参数量和 Gflops）与 256&amp;times;256 版本相当。事实上，唯一的额外开销仅来自通道数更多的 Patch 嵌入层和预测层，所有的 Transformer 模块都维持了相同的计算成本。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531398" data-ratio="1.0935185185185186" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGQnibzC3u1TFsvAIFHZDOJXZ64kIkicHk0w16o3zVRmyyICI7ZdISf8fg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/011aa59e-9ccf-45ff-80d8-e59f0bc90c94/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;更多实验细节请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谷歌给「AI解数学题」神话降温：能摘低垂果实，但过程依然痛苦</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 03 Feb 2026 23:25:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜张倩&lt;/section&gt;&lt;p&gt;刚刚，谷歌发布了一项新的研究进展：他们用 Gemini 做了一次系统性的数学攻关实验，把目标对准了著名的 Erdős Problems 数据库里 700 个仍被标注为 open（未解决）的猜想。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531332" data-ratio="0.7869158878504673" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGyhOZlbDQKia7Sj1Jrs8QOJ4LIfNkFOSWkp0UlZaOQVFuCrP3dVzdfkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1070" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/0db9ffb1-ee35-4fd2-94ab-0e99fb1c9c61/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;结果相当亮眼：Gemini 在这批问题中一共推进了 13 个 &amp;mdash;&amp;mdash; 其中 5 个是模型自主给出的全新解法，另外 8 个则是模型在文献中挖出了早已存在、但此前被遗漏的解答。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGqMlV1oF2KDCkLEpAn6O8OCrLSF3YHCeTY8gPiaG9MV3icBdO49WX8Xyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.44907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531333" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c77e7a35-397c-4ac9-aedc-9c65a64449f1/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Semi-Autonomous Mathematics Discovery with Gemini: A Case Study on the Erdős Problems&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2601.22401&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Erdős Problems 数据库以数学家 Paul Erdős 的名字命名。他是 20 世纪最多产的数学家之一，留下了大量论文和未解决的猜想，涵盖数论、组合数学、图论等。2023 年，数学家 Thomas Bloom 推出了 ErdosProblems.com 网站，这是一个集中式数据库，旨在整理这些猜想并跟踪其研究进展。目前，该数据库共收录 1179 个问题，其中 483 个（41%）被归类为已解决。&lt;/p&gt;&lt;p&gt;然而，该数据库中标注「open」的问题并不一定代表问题真的未被解决，而是意味着至少有一位专业数学家尝试通过网络搜索寻找已发表的解决方案，但以失败告终。&lt;/p&gt;&lt;p&gt;事实证明，很多问题并非「未解决」，而是答案被淹没了。去年 10 月份，OpenAI 宣布 GPT-5 在该网站上发现了 10 个标记「open」的问题，但其实它们的答案已经存在于相关文献，只是之前未被搜到。&lt;/p&gt;&lt;p&gt;这一发现使得 Bloom 的数据库受到了广泛关注，同时促使陶哲轩近期创建了一个社区维基，专门跟踪人工智能辅助解决 Erdős 问题的相关动态。&lt;/p&gt;&lt;p&gt;如今，谷歌的研究把 Erdős 问题的解决又往前推了一步。但他们也坦言，这并不意味着 AI 已经能「自动做数学研究」了，背后的脏活累活远超普通人想象。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;研究方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者团队在 2025 年 12 月 2&amp;ndash;9 日部署了一个基于 Gemini Deep Think 的定制数学研究智能体 Aletheia，对 Bloom 数据库中当时仍标注为「Open」的约 700 个 Erdős 问题进行半自动探索。Aletheia 内置自然语言验证器（verifier），用于在大规模生成后先做第一轮筛选，将候选问题从 700 个快速收敛到 212 个「看起来可能正确」的回答。&lt;/p&gt;&lt;p&gt;接下来进入人工评估阶段。研究团队先由非该领域专家的数学家进行快速过滤，尽可能在可控时间内剔除明显错误解，从而把候选规模压缩到 27 个，再交由内部领域专家逐一严审；当解法的正确性明确但新颖性存疑时，还会咨询外部专家核对文献。&lt;/p&gt;&lt;p&gt;最终统计显示，在可明确判定的约 200 个候选解中，137 个（68.5%）存在根本性错误；63 个（31.5%）在形式上成立，但&lt;strong&gt;其中只有 13 个（6.5%）真正回答了 Erdős 原本想问的问题&lt;/strong&gt;。其余 50 个虽然「技术上正确」，却因为误读题意而导致数学意义有限，作者计划对这些问题提出更严谨的修订表述；此外还有 12 个回答因问题本身开放或表述不清而被标记为「歧义」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGhMZj0ict93knqiacKdruiaftWxSpW9iaDicibSPruyLz0BibjBGKhe9ePaLQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.32037037037037036" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531334" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5ff20f33-cc2d-4cae-9d57-d13adb241ca6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531335" data-ratio="0.4444444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGehIzEZ3DEVCSt9wFEtiaSnIAUiboiccszSBhXNvPfXuKzhFic343Lz6lzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f01ea04a-fef8-421c-9800-19aef16c351a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;根据陶哲轩的建议，作者着重列出了上述数据以保证透明度。这也是为了更完整地呈现 AI 辅助数学研究的真实成本：除了少数正例之外，大量时间会消耗在核验、纠错、排查细微错误，以及检索文献以排除「无意重复」上。&lt;/p&gt;&lt;p&gt;这表明，业内广为流传的&lt;strong&gt;「AI 正在加速科学」的论断有一定片面性&lt;/strong&gt;：人们通常只展示少数成功案例，强调 AI 在某个任务上比人类更快，从而声称 AI「加速」了这一结果；但这类叙事很少把负例纳入计算。&lt;/p&gt;&lt;p&gt;更具挑战性的是最后一步 &amp;mdash;&amp;mdash; 确认解答是否已在文献中出现、以及是否真正契合 Erdős 的原始意图。许多问题的困难不在数学推导，而在题面细节的抄录误差、遗漏、以及符号与定义约定的歧义；模型若不了解 Bloom 网站的定义惯例，往往会在多个「各自合理」的解释之间混淆。&lt;/p&gt;&lt;p&gt;作者指出，在深入做文献核查与语义对齐后，「真正有意义的正确解」数量会显著下降，这也提醒未来的 AI 数学发现工作必须对题意一致性与文献溯源保持高度谨慎。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;作者将 13 个有意义的正确结果分为四类：&lt;/p&gt;&lt;p&gt;1、AI 自主解决。对于这些问题，Aletheia 找到了首个正确的解决方案，且解决方案具有实质性的数学意义。其中包括 Erdős-652 和 Erdős-1051，但需要说明的是，Erdős-652 的解决是通过直接引用现有文献中的结果实现的。&lt;/p&gt;&lt;p&gt;2、部分由 AI 解决。对于这些包含多个子问题的复杂问题，Aletheia 找到了其中一个子问题的首个正确解决方案。其中包括 Erdős-654、Erdős-935 和 Erdős-1040。&lt;/p&gt;&lt;p&gt;3、独立重发现。对于这些问题，Aletheia 找到了正确的解决方案，但人类审核者随后发现文献中已存在独立的解决方案。其中包括 Erdős-397、Erdős-659 和 Erdős-1089。这些解决方案似乎是模型独立重发现的：作者仔细检查了 Aletheia 的推理过程日志，确保该解决方案并非直接从文献中提取。当然，&lt;strong&gt;该解决方案也有可能是通过中间来源或预训练过程间接从文献中获取的&lt;/strong&gt;。这凸显了 AI 生成数学内容所伴随的一个新风险：模型可能会再现预训练过程中习得的文献知识，却不注明来源，即存在「潜意识抄袭」的风险。&lt;/p&gt;&lt;p&gt;4、文献识别。对于这些问题，尽管在模型部署时 Bloom 网站将其标记为「open」，但 Aletheia 识别出文献中已明确存在相关解决方案。其中包括 Erdős-333、Erdős-591、Erdős-705、Erdős-992 和 Erdős-1105。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGehIzEZ3DEVCSt9wFEtiaSnIAUiboiccszSBhXNvPfXuKzhFic343Lz6lzA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.4444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531336" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ea6dca1f-ab30-42c8-b5b3-16d0b45b7aab/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;需要明确的是，研究团队并未声称后两类结果具有创新性。上述提到的 5 个自主生成的解决方案分别对应 Erdős-652、Erdős-654、Erdős-935、Erdős-1040 和 Erdős-1051。&lt;strong&gt;根据专家的评估，这 5 个解决方案均未达到学术论文的水平。事实上，其中一些解决方案仅相当于研究生习题的难度&lt;/strong&gt;（基于现有文献）。&lt;/p&gt;&lt;p&gt;他们初步认为，Aletheia 对 Erdős-1051 的解决方案是 AI 系统自主解决具有一定普遍性（温和）数学意义的重要开放 Erdős 问题的早期案例 &amp;mdash;&amp;mdash; 虽然存在关于密切相关问题的过往文献，但这些文献均未完全解决 Erdős-1051。&lt;/p&gt;&lt;p&gt;此外，与许多之前讨论的案例不同，作者认为 Aletheia 的解决方案并非直接受任何先前人类论证的启发，但该方案确实采用了经典思路：转向级数尾部并应用马勒准则（Mahler&amp;rsquo;s criterion）。在 Aletheia 与人类数学家以及 Gemini Deep Think 的协作下，Erdős-1051 的解决方案得到了进一步推广，并形成了研究论文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;研究意义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究结果表明，&lt;strong&gt;Erdős 问题中存在「低垂的果实」，而 AI 已发展到能够摘取这些果实的水平&lt;/strong&gt;。尽管这为 AI 研究人员提供了一种新的、有趣的数学基准，但作者提醒&lt;strong&gt;人们不应过度夸大其数学意义。本文解决的所有开放问题，任何相关领域的专家都能轻松完成&lt;/strong&gt;。另一方面，人类专家的时间有限。如果能够提高 AI 的可靠性，它已展现出加速数学发现中注意力瓶颈环节的潜力。&lt;/p&gt;&lt;p&gt;在本文的案例研究中，作者遇到了一些最初未预料到的困难。绝大多数技术正确的自主生成解决方案都源于对问题陈述的误解或解读缺陷，而诊断这些问题有时需要花费大量精力。&lt;/p&gt;&lt;p&gt;此外，人类专家面临的最具挑战性的步骤并非验证解决方案的正确性，而是确定这些解决方案是否已存在于文献中。随着人工智能生成数学内容的增多，&lt;strong&gt;学术界必须警惕「潜意识抄袭」&lt;/strong&gt;，即 AI 再现训练过程中习得的文献知识，却未给予适当引用。需要注意的是，形式化验证无法解决这些问题。&lt;/p&gt;&lt;p&gt;尽管 AI 自主解决 Erdős 问题的尝试取得了一定成功，但也引发了误导性的炒作和彻头彻尾的虚假信息，并在社交媒体平台上被放大，这对数学界造成了损害。除了 Erdős 问题，未来可能还会有许多其他数学猜想列表成为（半）自主研究的目标。作者恳请相关研究人员关注本文提出的这些问题。&lt;/p&gt;&lt;p&gt;更多信息请参考原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>ICLR 2026 | Rebuttal 是一场「带着镣铐的舞蹈」？港科 RebuttalAgent 用心智理论「读懂」审稿人</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 03 Feb 2026 23:21:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/b2ba1ae2-9303-4b55-9bdb-d424bc9b8aa4/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;面对同行评审，许多作者都有过这样的经历：明明回答了审稿人的每一个问题，态度也足够谦卑，为什么最终还是没能打动对方？&lt;/p&gt;&lt;p&gt;现有的通用大模型在处理这类任务时，往往陷入一种 &amp;ldquo;表面礼貌&amp;rdquo; 的陷阱：它们擅长生成流畅、委婉的 &amp;ldquo;Thank you for your insightful comment&amp;rdquo;，却缺乏对审稿人言外之意的深度洞察，导致回复虽然客气，但缺乏直击痛点的说服力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;究竟什么样的回复策略，才能在有限的篇幅内，有效消除误解、赢得共识？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对这一问题，来自&lt;strong&gt;香港科技大学的研究团队&lt;/strong&gt;提出了一种全新的框架 &amp;mdash;&amp;mdash;&lt;strong&gt;RebuttalAgent&lt;/strong&gt;。该研究首次将认知科学中的 &lt;strong&gt;心智理论（Theory of Mind, ToM）&lt;/strong&gt; 引入学术 Rebuttal 任务，让 AI 能够像资深学者一样 &amp;ldquo;读懂&amp;rdquo; 审稿人，从而生成兼具战略性与说服力的回复。&lt;/p&gt;&lt;p&gt;目前，该论文已被&amp;nbsp;&lt;strong&gt;ICLR 2026&lt;/strong&gt;&amp;nbsp;接收。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfRuS466iaNibamXOSoic2b6NQs2uUV30twszu9iabxkeEEibGHRoZuQTJ5Eg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3685185185185185" data-type="png" data-w="1080" data-width="1698" data-height="626" data-imgfileid="503530712" data-aistatus="1" data-original-style="background-color: transparent;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6cda6875-c08e-4910-a1f2-e3b171a5efd3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://arxiv.org/pdf/2601.15715&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://github.com/Zhitao-He/RebuttalAgent&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz29kmtk9k" data-pm-slice="0 0 []"&gt;&lt;strong&gt; Rebuttal 需要怎样的博弈智慧？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在学术界的博弈论视角下，Rebuttal 是一个典型的 &lt;strong&gt;&amp;ldquo;不完全信息动态博弈&amp;rdquo;（Dynamic Game of Incomplete Information）&lt;/strong&gt;。作者不仅要面对审稿人显性的质疑，还要应对隐性的信息不对称，你不知道审稿人的知识背景、潜在偏见，也不知道你的解释会引发怎样的连锁反应。&lt;/p&gt;&lt;p&gt;现有的基于监督微调的模型，大多止步于对人类回复的&amp;lsquo;语言学拟态&amp;rsquo;。它们精准复刻了礼貌的&amp;lsquo;外壳&amp;rsquo;，却未能触及审稿人意图的&amp;lsquo;内核&amp;rsquo;，即缺乏对审稿人的深度建模。 针对这一痛点，研究者提出了 RebuttalAgent，其核心洞察：&lt;strong&gt;有效的说服机制，必须建立在对他人的&amp;lsquo;心智理论&amp;rsquo;建模之上。&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfrDWfLsPFRZPXWPBqzJiasx1gk46icnsRISWuCf9AQz4UiaI76P9xslGDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6453703703703704" data-type="png" data-w="1080" data-width="1276" data-height="824" data-imgfileid="503530713" data-aistatus="1" data-original-style="background-color: transparent;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e03e05c2-7a8c-4638-acdf-6903d25d4aaf/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz2bo51m3e" data-pm-slice="0 0 []"&gt;&lt;sup&gt;图一：RebuttalAgent 框架总览图，展示 Data Preparation, TSR Framework 和 Agent Training 三个阶段&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz2bwfj10je" data-pm-slice="0 0 []"&gt;&lt;strong&gt;TSR 框架 &amp;mdash;&amp;mdash; 先 &amp;ldquo;读心&amp;rdquo; 再 &amp;ldquo;落笔&amp;rdquo;，&lt;/strong&gt;&lt;/span&gt;&lt;span data-mpa-action-id="mkz2bwfj10je" data-pm-slice="0 0 []"&gt;&lt;strong&gt;重构 AI 的思考链路&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;RebuttalAgent 并没有直接端到端地生成回复，而是模拟了人类专家的思维过程，通过 &lt;strong&gt;ToM-Strategy-Response (TSR) &lt;/strong&gt;框架来拆解这一复杂任务：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. ToM（心智理论建模）&lt;/strong&gt;：不仅仅是读文本 AI 首先充当一名 &amp;ldquo;分析师&amp;rdquo;，对审稿意见进行分层剖析。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;宏观层面（Macro-level）： 判断审稿人的整体立场（接受 / 拒绝）、态度（建设性 / 消极）以及领域专业度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;微观层面（Micro-level）： 拆解每一条评论背后的核心关切（是方法论缺陷？还是单纯的表达不清？）。 这种建模让 AI 不再盲目回复，而是先构建出审稿人的 &amp;ldquo;心理画像&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. Strategy（谋定而后动）&lt;/strong&gt;：基于上述画像，AI 会生成一个明确的战略计划。例如，面对一个 &amp;ldquo;专业度高但态度怀疑&amp;rdquo; 的审稿人，策略可能是 &amp;ldquo;先承认局限性以建立信任，再用补充实验数据进行强力反击&amp;rdquo;；而面对 &amp;ldquo;误解型&amp;rdquo; 评论，策略则是 &amp;ldquo;澄清概念，重述核心贡献&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Response（精准打击）&lt;/strong&gt;：最后，AI 结合原始论文片段、战略计划和审稿人画像，生成最终的回复。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfbp5Cfvtt2ErRI4op0KHg6HibbUw1LFbyOkl1bDOWE8ZoO1icLPof3lZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.28055555555555556" data-type="png" data-w="1080" data-width="1460" data-height="410" data-imgfileid="503530714" data-aistatus="1" data-original-style="background-color: transparent;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/effae19f-65d4-4f4f-8c29-a3c4af688d47/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz2cno920nc" data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表一：评估的一致性：Rebuttal-RM 在对齐人类偏好上超越 GPT-4.1&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz2cytny05" data-pm-slice="0 0 []"&gt;&lt;strong&gt;无需外部导师，&lt;/strong&gt;&lt;/span&gt;&lt;span data-mpa-action-id="mkz2cytny05" data-pm-slice="0 0 []"&gt;&lt;strong&gt;&amp;ldquo;自我博弈&amp;rdquo; 中习得说服的艺术&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;为了训练这样一个能够 &amp;ldquo;运筹帷幄&amp;rdquo; 的 Agent，研究团队面临的最大挑战是数据的稀缺与主观性。为此，他们构建了 &lt;strong&gt;RebuttalBench&lt;/strong&gt;，包含超过 7 万条高质量的 &amp;ldquo;分析 - 策略 - 回复&amp;rdquo; 链条数据。&lt;/p&gt;&lt;p&gt;更进一步，研究者引入了 &lt;strong&gt;Self-Reward 机制&lt;/strong&gt; 的强化学习策略。与传统的依赖外部奖励模型不同，RebuttalAgent 利用自身生成的评价信号进行迭代：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;格式与逻辑奖励&lt;/strong&gt;： 确保 AI 真的在进行思考和布局，而不是形式主义。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多样性奖励&lt;/strong&gt;： 这是一个关键设计。为了防止 AI 偷懒生成 &amp;ldquo;万金油&amp;rdquo; 式的套话（如反复使用 &amp;quot;We thank the reviewer...&amp;quot; 模板），研究者设计了多样性惩罚，迫使模型探索更多样、更像人类专家的表达方式。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz2ecl115ix" data-pm-slice="0 0 []"&gt;&lt;strong&gt;从 &amp;ldquo;辞藻堆砌&amp;rdquo; 到 &amp;ldquo;攻心为上&amp;rdquo;：&lt;/strong&gt;&lt;/span&gt;&lt;span data-mpa-action-id="mkz2ecl115ix" data-pm-slice="0 0 []"&gt;&lt;strong&gt;当 AI 学会了换位思考&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;为了量化评估效果，研究团队开发了 &lt;strong&gt;Rebuttal-RM&lt;/strong&gt;，这是一个专门针对学术反驳场景训练的奖励模型。在与人类专家评分的一致性测试中，Rebuttal-RM 的表现超越了 GPT-4.1。&lt;/p&gt;&lt;p&gt;在这一评估体系下，RebuttalAgent 展现出了显著优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在综合得分上，RebuttalAgent 达到了&lt;strong&gt; 9.42&lt;/strong&gt;，显著优于 GPT-4.1 和 O3 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 &lt;strong&gt;说服力（Persuasiveness）&lt;/strong&gt; 这一核心指标上，提升尤为明显，表明引入 &amp;ldquo;心智理论&amp;rdquo; 确实增强了模型在观点交锋中的有效性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfUGcBUXLrdfjWJKlibVEUehAibCkbTYGuD1nouIabbjV0Skicy5yvYdhuQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3787037037037037" data-type="png" data-w="1080" data-width="1478" data-height="560" data-imgfileid="503530715" data-aistatus="1" data-original-style="background-color: transparent;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a6a6e8b3-66a1-49ad-9f24-d2dc5241bab3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz2fayv47p" data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表二：RebuttalAgent 与其他强基线的性能对比&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz3nfvn19kt" data-pm-slice="0 0 []"&gt;&lt;strong&gt;&amp;ldquo;即插即用&amp;rdquo; 的思维外挂：&lt;/strong&gt;&lt;/span&gt;&lt;span data-mpa-action-id="mkz3nfvn19kt" data-pm-slice="0 0 []"&gt;&lt;strong&gt;让小模型也能像专家一样思考&lt;/strong&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;RebuttalAgent 生成的 &amp;ldquo;分析（Analysis）&amp;rdquo; 和 &amp;ldquo;策略（Strategy）&amp;rdquo; 是否具有普适性？研究者设计了一个巧妙的实验：将 RebuttalAgent 生成的策略作为上下文（Context），喂给参数量较小的基础模型（如 Qwen3-8B 和 Llama-3.1-8B），观察它们的表现变化 (Average Score)。&amp;nbsp;&lt;/p&gt;&lt;p&gt;实验发现，这是一个通用的 &amp;ldquo;思维外挂&amp;rdquo;。仅需引入 RebuttalAgent 的策略指导，&lt;strong&gt;Qwen3-8B 在 &amp;ldquo;表达清晰度&amp;rdquo; 上的得分就暴涨了 21.0% &lt;/strong&gt;，这有力地证明了 TSR 框架的可迁移性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfzFkm7lmweh1icJG9wcIk5P6SJzFgZG9BqwNnaNt9TDJ1I4CQSfVnrSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.45582329317269077" data-type="png" data-w="996" data-width="996" data-height="454" data-imgfileid="503530717" data-aistatus="1" data-original-style="background-color: transparent;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/bd429796-738f-4710-a73c-d6f522c2e484/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz2hcbxfwq" data-pm-slice="0 0 []"&gt;&lt;strong&gt;做科研路上的 &amp;ldquo;理性副驾驶&amp;rdquo;，&lt;/strong&gt;&lt;/span&gt;&lt;span data-mpa-action-id="mkz2hcbxfwq" data-pm-slice="0 0 []"&gt;&lt;strong&gt;而非 &amp;ldquo;幽灵写手&amp;rdquo;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;RebuttalAgent 的提出，展示了 LLM 在处理高阶认知任务，特别是涉及复杂人际博弈和战略沟通场景的巨大潜力。但 Agent 无法替你完成实验，也不会凭空捏造数据，模型在训练之初就刻意剥离了涉及实验结果生成的指令，杜绝了 &amp;ldquo;幻觉造假&amp;rdquo; 的可能。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;打破 &amp;ldquo;新手墙&amp;rdquo;&lt;/strong&gt;： 对于许多刚踏入学术圈的新手而言，面对犀利甚至尖锐的审稿意见，往往容易陷入恐慌或产生防御性心态。RebuttalAgent 的&lt;strong&gt;价值正是在于提供战略性的建议与实用的技巧，帮助作者克服情绪干扰，理清逻辑脉络，组织得体的语言。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;促进学术交流&lt;/strong&gt;： 论文的核心价值在于 &amp;ldquo;提升学术对话的清晰度与建设性&amp;rdquo;。它致力于消除因表达不当或沟通策略缺失而造成的误解，让审稿人与作者的对话回归真理本身，而非陷入情绪对抗或单纯的语言技巧博弈。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;RebuttalAgent 本质上是对 &lt;strong&gt;大语言模型在严重信息不对称条件下战略说服能力&lt;/strong&gt;的一次探索性研究。最终的科学判断与责任，始终掌握在人类作者手中。&lt;/p&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz3v1ny12fv" data-pm-slice="0 0 []"&gt;&lt;strong&gt;作者介绍：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-mpa-action-id="mkz3v1ny12fv" data-pm-slice="0 0 []"&gt;何致涛，香港科技大学计算机系博士生，导师 Yi R. (May) Fung。曾在中国科学院自动化研究所、清华大学 AIR、蚂蚁集团从事研究，并在 ACL、NeurIPS、COLM、ICLR 等机器学习与自然语言处理顶级会议上发表多篇论文。&lt;/span&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，腾讯姚顺雨署名首篇论文发布，「下半场」先搞上下文学习</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 03 Feb 2026 19:01:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-03-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-03-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;不久前在 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651011350&amp;idx=1&amp;sn=ce3087a30d2765b6f1b15a48cb85d1d6&amp;scene=21#wechat_redirect" target="_blank"&gt;AGI-Next&amp;nbsp;&lt;/a&gt;前沿峰会上，姚顺雨曾分享过一个核心观点：模型想要迈向高价值应用，核心瓶颈就在于能否「用好上下文（Context）」。&lt;/p&gt;&lt;p&gt;这与最近 OpenAI &amp;nbsp;Jiayi Weng 在访谈中的看法不谋而合。Jiayi Weng 认为，上下文决定了模型和人类认知的边界。只要信息足够对等，普通人大概也能在 OpenAI 胜任工作，人和人的差距往往只是源于信息的不对称。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;而近日，混元团队和复旦联合团队发布了首篇论文《CL-bench》，在「重视上下文」的基础上又往前推了一大步。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;值得一提的是，这也是姚顺雨加入腾讯后首次署名的研究论文。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGpRfm74d9f3aluoliaHicia1YLj4RcBpKj6nvnlTw9wWMSUcFiaxvFKpDgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531368" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e3dda214-84ad-40fa-a83e-c7d613ebdfcd/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文题目：CL-bench: A Benchmark for Context Learning&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：www.clbench.com&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;论文证实了一个更棘手的问题：即便抹平了上下文带来的信息差，模型也未必能解决问题。这说明模型在上下文利用上，依然存在显著的能力短板。&lt;/p&gt;&lt;p&gt;具体来说，作者认为上下文「给到位了」并不等同于任务就能「做对」。这中间考验的是模型的学习能力：就像两个学习天赋不同的人，读的是同一本武功秘籍，有人能瞬息间领悟招式精髓，有人却始终不得要领。&lt;/p&gt;&lt;p&gt;这种差异的本质在于模型的上下文学习能力不同。 如果模型缺乏从上下文中学习新知识、掌握新技能的能力，哪怕解决任务所需的逻辑和范例都近在咫尺，它也依然无从下手。&lt;/p&gt;&lt;p&gt;本文将结合腾讯混元官网首次发表的技术博客《Learning from context is harder than we thought》的中文版，聊聊在上下文学习这件事上，模型面对的真实困境。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;博客链接：https://hy.tencent.com/research&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从上下文中学习，远比我们想象的要难&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们需要 AI 成为「上下文学习者」（Context learners）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去几年，大语言模型的进化速度快得令人惊叹。如今的前沿模型，已经是顶级的「做题家」：它们能解开奥数级别的难题，能推演复杂的编程逻辑，甚至能通过那些人类需要苦读数年才能拿下的专业资格考试。&lt;/p&gt;&lt;p&gt;然而，这些耀眼的成绩单可能掩盖了一个真相：&lt;strong&gt;能在考场拿满分的学生，未必能胜任真实世界的工作。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回看我们人类的日常工作：开发者扫过从未见过的工具文档，就能立刻开始调试代码；玩家拿起新游戏的规则书，在实战中边玩边学；科学家从复杂的实验日志中筛选数据，推导出新的结论和定律。我们发现在这些场景中，人类并不只依赖多年前学到的「死知识」，而是在实时地从眼前的上下文中学习。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGabXDVaw7j9MKgq5ewJdf1Xh9ZNrkqAmw4XJFnuHrdFObEWzYbI0dwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37962962962962965" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531369" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/36539c54-8eb1-4096-9222-7d5e3d7015ed/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;三个人类日常生活和工作场景的例子。这三个例子分别为：（1）面对 SkyNet 无人机 SDK 文档 (~70K 字)，将自然语言所表达的飞行请求转成安全、合规的 SDK 伪代码； （2）直接上手玩一款游戏：给定一款新游戏的完整规则 (~15K 字)，分析隐藏房间场景并给出可能结果；（3）分析 300 份原始实验日志，验证数据、推导关系式并估计共振常数。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;然而，今天的语言模型并非如此。它们主要依赖「参数化知识」&amp;mdash;&amp;mdash; 即在预训练阶段被压缩进模型权重里的静态记忆。在推理时，模型更多是在调用这些封存的内部知识，而不是主动从当前输入的新信息中汲取营养。&lt;/p&gt;&lt;p&gt;这揭示了当前模型的训练范式和在真实场景中应用之间是不匹配的：我们优化出的模型擅长对自己「已知」的事物进行推理，但用户需要的，却是让模型解决那些依赖于杂乱、动态变化的上下文的任务。&lt;/p&gt;&lt;p&gt;简而言之：&lt;strong&gt;我们造出了依赖「过去」的参数推理者，但世界需要的是能吸收「当下」环境的上下文学习者&lt;/strong&gt;。要弥合这一差距，我们必须从根本上改变模型的优化方向。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyet0lcIkZDzTDD3XzBgm8iaTaJElOZSlFibCBKl2oNgpgl7tGECya1n8Eg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.55" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531248" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4a974c7a-abf8-4804-8063-f31a3a27289d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;语言模型的范式转变。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CL-bench: 衡量模型的上下文学习能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了衡量现有模型距离真正的「上下文学习者」还有多远，我们构建了 &lt;strong&gt;CL-bench&lt;/strong&gt;。这是一个专门评测语言模型能否&lt;strong&gt;从上下文中学习新知识并正确应用&lt;/strong&gt;的基准。&lt;/p&gt;&lt;p&gt;CL-bench 包含由资深领域专家精心制作的 500 个复杂上下文、1899 个任务和 31607 个验证标准。CL-bench 只包含一个简单但苛刻的要求：&lt;strong&gt;解决每个任务要求模型必须从上下文中学习到模型预训练中不存在的新知识，并正确应用。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;模型需要学习的知识非常广泛。它包括新的领域知识、不熟悉的规则系统、复杂的产品工作流，甚至是必须从实验数据中推导归纳出的定律或结论。&lt;/p&gt;&lt;p&gt;所有这些知识要么是由领域专家完全新构建的，要么是取自那些不太可能出现在当前前沿模型训练数据中的小众、长尾来源。因此，模型无法通过回忆静态的参数化知识来解决任务，都要求模型从提供的上下文进行学习并应用。&lt;/p&gt;&lt;p&gt;具体来说，CL-bench 涵盖了四种广泛的现实世界上下文学习场景：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye1PKLxS0BCTJZgSCvJR4v410muIq8Micl2tRsuvvRwH6YzdIFYZ5ks2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4009259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531257" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/0d77320d-b9a0-4885-8b12-7c34d9d3c23b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; CL-bench 的上下文分类体系。&lt;/sup&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;领域知识推理&lt;/strong&gt;：&amp;nbsp;上下文提供特定的领域知识（例如 虚构的法律体系、创新的金融工具或小众专业知识）。模型需要利用这些知识来推理并解决具体问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;规则系统应用&lt;/strong&gt;：&amp;nbsp;上下文提供新定义的正式系统（例如 新的游戏机制、数学形式体系、编程语法或技术标准）。模型必须理解并应用这些规则来执行任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;程序性任务执行&lt;/strong&gt;：&amp;nbsp;上下文提供复杂的过程系统（例如 工作流、产品手册和操作指南）。模型必须理解并应用这些程序性信息来完成任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;经验发现与模拟&lt;/strong&gt;：&amp;nbsp;上下文提供复杂系统内的实验数据、观测记录或模拟环境。与前几类涉及演绎推理不同，这一类专注于归纳推理，也是最具挑战性的。模型必须从数据中发现潜在的定律或结论，并应用它们来解决任务。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGKPuYjN7w5dUnZZaiaBwyyia1nrapGBqgibKYxicw7UlMx9belAQPljF45g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.4759259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531308" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/c28d4a69-c396-464f-9318-deedcfd9ba79/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;CL-bench 示例。解决这些任务要求语言模型从提供的上下文中学习。图中这四个案例分别是：（1）在一部长达 2.3 万字、刚刚生效的新法律下判一起真实纠纷；（2）基于一门新设计的教育编程语言规范，实现一个带有时间条件终止的周期性程序；（3）在一套从未见过的编程框架中执行代码；（4）在给定技术规格和长期环境政策情景的条件下，模拟关键技术金属的可持续全球供应。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这些类别包含了大部分现实世界工作中常见的演绎推理和归纳推理任务，能充分衡量模型的上下文学习能力。关于 CL-bench 的更多细节，请参阅我们的论文 [1]。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CL-bench 的设计原则和特性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CL-bench 围绕一个简单但严格的设计原则构建：&lt;strong&gt;每个任务都必须要求从上下文中学习新知识&lt;/strong&gt;。 CL-bench 中的每个上下文都是&lt;strong&gt;完全自包含（Self-contained）&lt;/strong&gt;的。解决任务所需的所有信息都显式地提供在上下文本身之中：不需要外部检索，也不允许隐藏假设。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531372" data-ratio="0.4101851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGegrsicWiaqYrK5gGZuOXlHia7aETTiciaIzciarPGAfqfpKjCjyrMvJcqw1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5da9aa61-d63c-4775-bfbc-ca6fe2f848d9/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 解决CL-bench 中的任务需要模型从相应的 context 中学习新知识。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了确保性能真正反映上下文学习，而不是记忆或数据泄露，CL-bench 采用了无污染（Contamination-free）设计：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;虚构创作&lt;/strong&gt;：&amp;nbsp;专家创作完全虚构的内容，例如为虚构国家设计一套完整的法律体系（包括新颖的判例和法律原则），或创建具有独特语法和语义的新编程语言。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;现有内容的修改&lt;/strong&gt;：&amp;nbsp;专家修改现实世界的内容以创建变体，例如更改历史事件、改变科学和数学定义，或修改技术文档和标准。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;整合小众和新兴内容&lt;/strong&gt;： 专家纳入了在预训练数据集中代表性极低的小众或近期新兴内容，如前沿研究发现、新发布的产品手册或技术文档，以及来自专门领域的特定知识。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在不提供任何上下文的情况下，最先进的模型 &lt;strong&gt;GPT-5.1 (High) &lt;/strong&gt;仅能解决&lt;strong&gt;不到 1%&lt;/strong&gt; 的任务。这有力地证明了数据是无污染的，模型若不从上下文中学习，几乎完全无法解决这些任务。&lt;/p&gt;&lt;p&gt;此外，CL-bench 的设计具有高复杂性和序列依赖性。&lt;strong&gt;51.1% 的任务&lt;/strong&gt;需要序列依赖，意味着后续任务的解决方案取决于早期交互的结果。这种多轮次设计显著增加了任务难度。平均而言，领域专家花费约 &lt;strong&gt;20 小时&lt;/strong&gt;标注每个上下文，以确保任务构建的质量和深度。&lt;/p&gt;&lt;p&gt;CL-bench 中的每个任务都是完全可验证的。平均而言，每个上下文关联&lt;strong&gt; 63.2 &lt;/strong&gt;个验证标准，每个任务包含 16.6 个评估标准。每个任务的正确性都从多个角度进行评估，确保了评估的全面性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;部分实验发现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们在 CL-bench 上评估了十个最先进的语言模型。结果揭示了清晰且一致的差距。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyePxuWssOuS3FUCeSZ7AgdMfcicDgtoicqgvO6cUqvPiaJ5CWiaRuhPoXXFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.387037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531258" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/747f34fa-d1cd-45ce-850a-1990f2e52643/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表：十个前沿模型在 CL-bench 上的任务解决率。所有模型均在推理模式下进行评估，结果报告为三次运行的平均值 &amp;plusmn; 标准差 (%)。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;平均而言，模型仅解决了 &lt;strong&gt;17.2% &lt;/strong&gt;的任务。即便是表现最好的模型 &lt;strong&gt;GPT-5.1 (High)&lt;/strong&gt;，也仅达到了&lt;strong&gt; 23.7%&lt;/strong&gt;。换句话说，尽管上下文中拥有解决每个任务所需的全部信息，模型在绝大多数任务上都失败了。这表明&lt;strong&gt;当前的 SOTA 模型几乎不会从上下文中学习&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;还有几个额外的现象值得注意：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;忽略或误用上下文是导致失败的主要原因。&lt;/strong&gt; 许多错误并非源于信息缺失，而是源于模型忽视了上下文中的关键细节，或错误地应用了它们。在许多情况下，模型只会利用预训练学习到的静态知识来解决任务，即使上下文明确定义了新的规则、概念或程序，模型也不会学习和利用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyebKvU6O4gYfibfbQ1WQmUroQr5gvhR6pjAWMJpWrVuhUicZ7icIFCUvicaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.38744075829383884" data-s="300,640" data-type="png" data-w="844" type="block" data-imgfileid="503531252" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b88fc5c2-a006-4101-bf03-499b65e09466/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表：各模型错误类型的分布（因为一个 solutions 可能有多种错误原因，所以每行错误率总和大于 100%）。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长上下文推理和指令遵循是必要的，但不是充分条件。&lt;/strong&gt; 案例分析表明，那些难以跨长上下文追踪依赖关系或难以精确遵循约束的模型，往往表现得更差。然而，即使是能够处理长输入并可靠遵循指令的模型，仍然在许多任务上失败。上下文学习需要的能力，远不止长上下文理解和指令遵循能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;从实验数据和环境模拟中进行归纳推理比演绎应用更困难。&lt;/strong&gt; 演绎任务让模型根据 context 中明确给出的规则和流程进行应用，而经验发现和环境模拟类任务则要求 归纳推理 &amp;mdash;&amp;mdash; 从数据中总结规律或在虚拟环境中探索。模型在这类任务上的表现明显较差，任务解决率通常低于 10%，且结果波动大。这表明发现规律远比应用规则更具挑战性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGq2sEiauf3miac6OQVuRsBj6WpeNFWk3yybWkxtsOPnwKX6QiaO953tAuQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.44814814814814813" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531370" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6ff8d689-beca-49cd-9f6a-41d449dc786a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; GPT-5.1 在高 / 低推理强度设置下，各子类别表现对比。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;更高的推理强度通常能提升 context 学习效果。 &lt;/strong&gt;对部分模型来说，增加 推理强度 可以改善表现，使模型更深入地理解复杂 context 。例如，GPT-5.1 在管理类和实验数据类任务上的表现提升约 6%。但其他模型提升有限甚至可能下降，说明单靠更多推理并不足够，模型还必须能够正确吸收和组织 context 信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibnuawEGIclTM0wnuLx1ZWGrZib1oiaeW7941ddR1jLfkSTHLsHlDqNSN2f6PxTybGnEib9Qwicu8MHXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5481481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531371" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/beccea51-148b-4432-a717-365c82f50ce2/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;不同输入长度下模型上下文学习表现的变化趋势。（不同 context 下模型的表现变化呈现相似趋势。）&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Context 学习的难度与 context 长度相关，但短 context 也可能很复杂。&lt;/strong&gt; 较长的 context 通常让所有模型的任务更难，这验证了长 context 处理仍是关键瓶颈。然而，即使是短 context ，如果包含信息密集、规则隐含、依赖复杂或约束严格的内容，也依然很具挑战性，说明 context 学习的难度不仅仅来源于长度，也来自于其复杂度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;更多发现请参见我们的论文 [1]。综上所述，CL-bench 揭示了一个不能被忽视的现象：&lt;strong&gt;当今的前沿语言模型还仍然不会利用上下文，从上下文中学习。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CL-bench 充分解释了语言模型在真实场景中为什么经常出错：即使有了上下文工程，给模型准备好了所需的上下文，模型也会失败。如果模型不能真正从中学习，仅仅提供上下文是不够的。上下文学习作为一项模型基础的学习能力，很大程度上被忽视了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;展望未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果上下文学习显著提升，人类在 AI 系统中的角色将发生变化：我们不再是主要的数据提供者（training data provider），而变成了 context 提供者（context provider）。竞争的焦点将从 &amp;ldquo;谁能把模型训练得更好&amp;rdquo;，转向 &amp;ldquo;谁能为任务提供最丰富、最相关的 context &amp;rdquo;。&lt;/p&gt;&lt;p&gt;但其实这里还有一个挑战。即便上下文学习足够强大，它目前依然是&lt;strong&gt;临时性的（Ephemeral）&lt;/strong&gt;：模型的上下文窗口一旦清空，学到的知识随之消失。因此，我们还要关注如何让从上下文中习得的知识&lt;strong&gt;持久化&lt;/strong&gt;？这种知识不仅是事实，还包括能帮助模型跨任务迁移的技能、经验和模式等。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeaYmkNKNZeffvicB68xX6CMRxb9O4qeGwOPCW1MjicQU1wCqGp0VzJx2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531253" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/c9b09d0e-7bb9-4e22-865f-1c8b6b31b1ac/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 记忆巩固是语言模型通过上下文学习经验的关键&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;因此，如何记忆很可能成为 2026 年的另一个核心主题。 要充分发挥语言模型的潜力，可能需要新的架构、新的优化方式来决定「该保留什么」。&lt;/p&gt;&lt;p&gt;一旦上下文学习与记忆变得可靠，模型或许就能实现自主学习：它们将自主准备上下文，从中学习并自我巩固。&lt;/p&gt;&lt;p&gt;这听上去多么令人兴奋！但当下我们的目标很明确：&lt;strong&gt;让「上下文学习」真正走向现实！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;写于 2026 年 1 月，正值新年来临之际。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[1] CL-bench: A Benchmark for Context Learning&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
