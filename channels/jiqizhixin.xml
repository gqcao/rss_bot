<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>性能提升60%，英特尔Ultra3这次带来了巨大提升</title>
      <description>&lt;![CDATA[Intel 18A 工艺来了。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Wed, 14 Jan 2026 16:33:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;上周，英特尔在 CES 2026 上正式发布了代号为 Panther Lake 的 Core Ultra Series 3 处理器，成为了本次展会的绝对主角。它终于让 PC 芯片摆脱了多年挤牙膏的困境，在 CPU、GPU 和 NPU 架构上均带来了显著的「代际」升级。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6f39a96a-2809-4c8e-91bb-2e03b5a1dc15/image__7_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这是首款基于英特尔自家 18A 工艺（等效 1.8 纳米级别）大规模量产的消费级芯片，桌面端和移动端版本同期推出。对英特尔来说，新制程与新芯片具有重大意义，标志着该公司重新引领芯片性能与方向的开始。&lt;/p&gt;&lt;p&gt;CES 之后，英特尔对下一代酷睿 Ultra 平台作了完整的技术概述。&lt;/p&gt;&lt;p&gt;在新一代 Panther Lake 产品上，能效核 Darkmont 与性能核 Cougar Cove，GPU（升级版 Xe3）都是新架构，引入了第五代 NPU 用于 AI 加速，缓存、图像处理单元都是新的，芯片整体采用了基于 chiplet 的封装，使用 Foveros-S 堆叠技术。&lt;/p&gt;&lt;p&gt;具体来说，每颗 Panther Lake 主要由三种小芯片组成：基于 Intel 18A 的计算芯片、基于 Intel 3 或台积电 N3E 工艺的图形芯片，以及基于台积电 N6E 的平台控制器芯片。每个配置都采用了 Foveros-S 封装，安装在同一个基板上，CPU、GPU、I/O 芯片会被集成到一个紧凑的 SoC 布局中。&lt;/p&gt;&lt;p&gt;英特尔表示，Panther Lake 会具备 Lunar Lake 的能效与 Arrow Lake 的性能，CPU 最多拥有 16 个核心，性能相比上代提升 60%（比之前宣称的 50% 又有提升），低功率情况下，单核性能较上一代提升 40%。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f8892235-e355-44a5-b018-7781dea64214/0bd098b364420f3591649e3d7592997d.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在 CPU 上，Panther Lake 集成了三种类型的核心，Cougar Cove P 核心在 Lion Cove 的基础上进行了改进，增加了 TLB 的容量，配备了更精确的多级分支预测器。每个 P 核心包含 3MB 的 L2 缓存和 256K 的 L1 缓存。Darkmont E 是上一代 Skymont 的升级版，支持 9 路解码，更大的乱序执行窗口和 26 个调度端口。&lt;/p&gt;&lt;p&gt;Panther Lake 还新增了一个四核低功耗集群，它基于 Darkmont 架构，直接位于计算单元上，用于处理后台或轻量级负载。&lt;/p&gt;&lt;p&gt;英特尔表示，重新设计的内存子系统支持 DDR5-7200 与 LPDDR5X-9600，相比前几代产品带宽和容量更高，计算单元可在核心集群上共享 18MB 的 L3 缓存，并连接到 8MB 的内存端缓存，从而减少 DRAM 流量和延迟。&lt;/p&gt;&lt;p&gt;GPU 方面，新一代芯片搭载了全新的 Xe3 架构核显，拥有最多 12 个 Xe 核心，官方宣称游戏性能相比上一代（Lunar Lake）提升高达 77%，同功耗水平性能提升 50%，其性能甚至超越了部分独立显卡（如部分 RTX 4050 移动版）。当然，这一代核显的性能相较 AMD 的同档产品也有巨大的优势。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4ac70684-fa6c-4f23-b65c-1326c49cfa9f/32802905bd061663d7b9a28bfd85de03.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;可见在魔兽世界、群星等游戏上，以后我们基本可以用集显玩了。我们甚至可以展望 Ultra 3 发布会，会有搭载集显的全能笔记本出现。&lt;/p&gt;&lt;p&gt;12 核心的 Xe3 版本使用台积电 N3E 工艺打造，提升了 L1、L2 缓存容量，改进了各向异性过滤和模板渲染速率，并配备了增强型光线追踪单元和动态光线管理功能。&lt;/p&gt;&lt;p&gt;Panther Lake 还首次搭载了 XeSS 3 多帧生成技术，可以通过生成多个插帧的方法实现更加流畅的游戏体验。英特尔计划在其图形软件中增加帧生成覆盖控制功能，从而让用户可以强制指定特定的帧生成模式。&lt;/p&gt;&lt;p&gt;在 AI 计算方面，Panther Lake 采用了更加均衡的 XPU 设计，可实现更高水平的 AI 计算加速，总平台算力超过了 180TOPS。其中 NPU 算力提升至 50 TOPS，支持 FP8、INT8 等量化格式，MAC 吞吐量翻倍，功耗降低 40% 以上。&lt;/p&gt;&lt;p&gt;利用新的线程管理器，Panther Lake 能够适应不断变化的工作负载，在游戏时提升约 10% 的帧率。通过优化 Windows 电源模式，新的芯片在相同的功耗限制下可以把性能提升大约 20%。&lt;/p&gt;&lt;p&gt;Panther Lake CPU 预计将提供八核心 + 两个十六核心的版本，命名为英特尔酷睿 Ultra 处理器第三代（3xx）。另外在连接方面，这一代芯片支持最多 20 条 PCIe 通道，集成雷电 4；无线连接方面则支持 Wi-Fi 7 Revison 2 和蓝牙 6.0Core。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fe0d6dd0-ce58-40ed-bc0f-3b4de9d5463d/image__8_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;除了个人电脑领域之外，Panther Lake 的应用范围还扩展到了包括机器人在内的边缘应用领域。英特尔提供了 AI 软件套件与参考板卡，能够帮助复杂 AI 应用的客户快速上手，利用新一代 AI 芯片实现控制和 AI 感知，并快速开发机器人。&lt;/p&gt;&lt;p&gt;英特尔表示，得益于 18A 工艺，Panther Lake 芯片的能效比进一步优化，官方宣称部分机型续航可达 27 小时。再加上性能的提升，新一代芯片在轻薄笔记本和游戏本上都会带来更好的体验。&lt;/p&gt;&lt;p&gt;预计搭载 Panther Lake 的笔记本电脑在今年 1 月就会大批量上市。&lt;/p&gt;&lt;p&gt;英特尔还预告了 30W 功率掌机版本的 Panther Lake 的信息，不过更多信息有待公布。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8255694f-7971-44f0-919c-b7c4137e0cae/image__9_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;随着 Ultra 第三代产品的推出，AI PC 距离实用化更近了一步。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>继宇树后，唯一获得三家大厂押注的自变量：具身模型不是把DeepSeek塞进机器人</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:45:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/169694b5-8cac-4291-8aa4-aae419d72237/1768373003246.png" style="width: 700%;" class="fr-fic fr-dib"&gt;国内具身智能，接下来可能是「大脑」的战场了。&lt;/p&gt;&lt;p&gt;2026 开年，&lt;strong&gt;自变量机器人传出融资消息，字节、红杉出手，融资额达到 10 亿。&lt;/strong&gt;虽然自变量是一家软硬一体的公司，但这场融资背后，真正说服投资人的可能是他们对于机器人「大脑」的思考。&lt;/p&gt;&lt;p&gt;和之前的 locomotion（移动）、navigation（导航）战场不同，&lt;strong&gt;「大脑」所主导的 manipulation（操作）涉及频繁的物理世界交互，随机性、不确定性充斥着每一个看似简单的任务&lt;/strong&gt;。这也是为什么，在我们看了多年的机器人跳舞、跑酷、玩杂技之后，机器人在自主操作上依然没有拿出一个技惊四座的 demo。而这个「自主操作」，才是决定机器人能否大规模走入人类世界的关键。&lt;/p&gt;&lt;p&gt;在自变量看来，「操作」这类任务的复杂性决定了，机器人必须有一个由「物理世界基础模型」所支撑的「大脑」。这个「大脑」不是像很多人想的「把 DeepSeek 塞进宇树」那么简单，它不是 AI 模型的「应用层」，而是独立、平行于语言大模型、多模态模型等虚拟世界模型的新范式。&lt;/p&gt;&lt;p&gt;对于这个新范式应该是什么样子、如何去打造，自变量已经有了一套体系化的方法论，并且自研出了一些成果。这些大胆的尝试，或许会为具身智能领域带来新的变量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;具身智能 &amp;ne; AI 模型下游应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们知道，最近几年机器人「大脑」的进化主要还是依赖语言模型和多模态模型。于是很多人就认为，具身智能是 AI 模型的一个应用方向。但自变量 CEO 王潜曾在多个场合强调，这个定位存在偏差。&lt;/p&gt;&lt;p&gt;举例来说，图中有两个矿泉水瓶，一个瓶盖拧紧，一个没有完全拧紧。只靠视觉去看，它们在图像里差别很小，但一旦把它们拿起来、翻转或倾倒，结果却完全不同 &amp;mdash;&amp;mdash; 一个会漏水，一个不会。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicoUZK5tD2uzpKljicRrS1td1mupIF4No3N72L7vKoib51BuUbtDBktT1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528184" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/0969c240-aa4d-4d28-b79c-025910ff56b8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;物理世界里真正关键的信息，往往就藏在这些「看不出来但会影响行为」的细节中。&lt;/strong&gt;这些差异只有在与世界发生真实交互时才会暴露出来，而不是静态观察就能轻易判断。&lt;/p&gt;&lt;p&gt;更重要的是，这类信息往往并不会在当下立刻给出反馈。比如拧瓶盖这个动作本身，并不会产生任何可见变化，真正的差异要等到下一步、甚至再下一步操作时才显现出来。对模型来说，这意味着它必须能够把一连串感知、动作和结果在时间上串联起来理解，而不是只处理某一帧画面、某一个瞬间的输入输出。&lt;/p&gt;&lt;p&gt;这正是物理世界对智能提出的一个隐性要求：&lt;strong&gt;模型不仅要能感知，还要能处理足够长的行为序列，理解因果是如何在时间中逐步展开的。&lt;/strong&gt;否则，它就永远学不会那些「现在看不出来、但之后会出问题」的物理规律。&lt;/p&gt;&lt;p&gt;而在很多真实任务中，问题甚至不只是时间跨度变长这么简单。机器人往往需要在行动之前，对未来进行某种形式的推演。比如在倒水之前，它需要判断瓶子会不会漏；在整理桌面之前，它需要决定先拿走什么、再放回什么。这类判断并不是对当前状态的直接反应，而是对「接下来会发生什么」的内部演算。&lt;/p&gt;&lt;p&gt;也正因为如此，单纯依赖静态信息训练出的语言模型或多模态模型，在物理世界里往往显得力不从心。它们并不真正理解「拧紧」和「没拧紧」在物理后果上的差别，也难以应对充满连续变化、随机扰动和部分不可观测的现实环境。&lt;/p&gt;&lt;p&gt;在自变量看来，这并不是靠给现有模型打补丁就能解决的问题，而是指向了一个更底层的结论：&lt;strong&gt;我们需要一种「生于物理世界、用于物理世界」的基础模型。这种模型应当与语言模型、多模态模型平行存在，而不是作为它们的下游应用。&lt;/strong&gt;自变量的目标，正是要打造这样一个基础模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建物理世界基础模型&amp;mdash;&amp;mdash;要端到端、要做通才模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要打造这个模型，自变量认为有两点非常重要：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一是要有一个统一的架构，因为真正的物理智能需要的是整体性的、具身的理解，而不是模块化的知识拼接。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;举个例子，人类在使用锤子时，注意力不在「这是一个锤子」「锤子有多重」，而是在木头、钉子和要完成的目标上。锤子作为一种工具，会被纳入行动本身，在认知中「隐退」。但对于现在很多机器人来说，情况恰恰相反，每一次使用工具，它们都要重新经历一整套流程：看见这是锤子，理解锤子的用途，规划怎么用，再执行动作。自变量认为，这种方式永远无法达到人类那种直觉的工具使用境界。&lt;/p&gt;&lt;p&gt;归根结底，这种局面是把模型拼接起来的分层架构所带来的 &amp;mdash;&amp;mdash; 视觉模块先把世界压缩成向量，语言模块再接手理解，规划模块再根据语言输出动作。一套流程下来，模块之间彼此「看不见」「听不见」对方真正关心的东西。每跨一次模块，细节、关联和物理直觉都会被削掉一层。这就像把一幅油画描述给盲人，再让盲人转述给聋人。&lt;/p&gt;&lt;p&gt;这就不难解释，为什么自变量从成立第一天就是「端到端」路线的坚定信徒。他们看到的是这一路线的底层逻辑：信息必须在一个统一的空间里流动，系统才能发现不同东西之间深层的关联。早期，这一选择饱受质疑，但如今，Google Robotics、Physical Intelligence 等头部具身智能团队也都走到了这条路上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二是模型要足够通用，因为只有这样才能学到物理世界的共性结构。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这条路已经被语言模型走过一遍。大家发现，相比于最初针对单一任务分别做专用模型，把翻译、问答、写作、推理等任务放进同一个模型里，反而能让模型学到更底层的逻辑和常识。物理世界也是一样，当模型同时学习足够多、足够杂的任务，它会被迫去发现这些任务背后的共性结构 &amp;mdash;&amp;mdash; 物理规律、物体属性、因果关系。一旦掌握了这些共性，模型学新任务所需的数据量就会骤降，甚至出现「涌现」。&lt;/p&gt;&lt;p&gt;提到语言模型，它的成功其实还有一个常被忽视的关键：它找到了一个极好的损失函数 &amp;mdash;&amp;mdash; 预测下一个词。这个看似简单的目标，能够把海量文本中的结构、逻辑、常识全部压缩进模型里。&lt;/p&gt;&lt;p&gt;但机器人面对的是一个更复杂的局面，&lt;strong&gt;它的损失函数应该预测什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;自变量认为，不能只停留在「预测动作」。如果只预测动作，模型很容易沦为一个「模仿者」，它只学会了手势的形状，却不懂得背后的原因。真正的突破口在于：将损失函数从「动作预测」升级为「多模态状态的预测」。&lt;/p&gt;&lt;p&gt;当模型试图预测「如果我推倒这个杯子，下一秒视觉画面会如何变化、指尖的触感会如何消失」时，它实际上是在强迫自己理解因果律，把物理世界的复杂性压缩进模型里。&lt;/p&gt;&lt;p&gt;这也解释了为什么自变量的 WALL-A 模型不只输出动作。它还能用语言和人对话，能根据图片重建三维环境，能像世界模型一样预测未来。这些能力看似五花八门，但背后的逻辑是一致的：如果一个模型真正理解了物理世界，它就应该能用各种方式表达这种理解，无论是控制机械臂，还是描述它在做什么，还是预测物体会怎么滚动。在这个模型身上，我们已经能够看到自变量所追求的物理世界基础模型的雏形。&lt;a href="https://mp.weixin.qq.com/s/22w4L3Edq0rkp8A-MV-wHg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4691a136-e40b-4b35-bc70-0e6d574f0178/1768373097434.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;以外卖即时配送任务为例，自变量的机器人在完全开放的室外及室内环境中执行移动操作任务，应对人流、环境变化、突发干扰等不确定因素，从外卖柜取箱、拆箱、回收、室内导航、电梯交互到最终交付，机器人基于统一的端到端具身智能模型完成超长序列操作，体现了自变量的具身智能模型具备极强的泛化能力，标志着具身智能首次具备在真实商业场景中稳定运行的能力。该场景首次让VLA模型在高频、强约束、强时效的真实环境中长期运行，完成从实验室验证到商业级部署的关键跨越。&lt;/section&gt;&lt;p&gt;&lt;strong&gt;开源有得选 &amp;nbsp;但依然要坚持「自研」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除了对于「机器人大脑」这个问题的独特思考，自变量这家公司在业内其实还有一个非常罕见的特质：坚持自研，尤其是基础模型的自研。&lt;/p&gt;&lt;p&gt;在很多公司看来，这点可能暂时还没有那么必要或者说「紧迫」，毕竟 Physical Intelligence 开源的 Pi0 和 Pi0.5、英伟达开源的 GRoot 等都是不错的选择，也是很多具身智能厂商的主流选择。&lt;/p&gt;&lt;p&gt;但自变量对「自研」的坚持，更多来自一个底层判断：具身智能的下一阶段竞争，本质上还是数据闭环构建的基础模型与模型进化能力的竞争。模型不掌握在自己手里，竞争无从谈起。&lt;/p&gt;&lt;p&gt;一路目睹语言模型演进的从业者应该对此有着深刻的感受 &amp;mdash;&amp;mdash; 这个行业最大的变量，往往藏在基础模型的内核里。过去两年，Cursor 等应用层产品风头无两，但它们的「智能」几乎完全依赖 Claude 或 GPT 的能力边界。上游模型一次升级，下游应用被动重构；API 定价一旦调整，成本结构随之改变。&lt;/p&gt;&lt;p&gt;对于机器人而言，这个问题还要更深一层：真实物理世界的重量、阻力、空间关系，无法从互联网文本中习得，必须从数据采集到模型架构建立一套完整的自研体系。选择在基础层投入，看似是一条更慢的路，但历史反复证明：&lt;strong&gt;原始创新者定义规则，跟随者只能适应规则。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，自变量共有两款核心模型：主模型 WALL-A 和轻量化模型 WALL-OSS，均为自研成果。这个系列模型的核心架构首创了 VLA 与世界模型深度融合的系统范式，而且率先实现了具身多模态思维链。&lt;/p&gt;&lt;p&gt;值得注意的是，自变量还将 WALL-OSS 开源了出来，并围绕&amp;nbsp;WALL-OSS 等全球具身开源项目组织了一个名为「&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzkzOTc1NjE3Nw==&amp;mid=2247484684&amp;idx=1&amp;sn=319ed37b206dc726e20604c44b029a59&amp;scene=21&amp;click_id=52#wechat_redirect" target="_blank"&gt;具亮计划&lt;/a&gt;」的黑客松。该计划鼓励开发者利用具身基础开源模型，从数据采集、策略训练到真机部署跑通完整链路，最终让机器人在真实场景里动手完成任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicO5cf2dNtjwtcPicFptXA7KSyLgJmPQSekBBhqXF5m5UcXM2YEhs1wuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4083333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528272" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6d1054a7-fae4-477d-a76d-4e7cdc380dba/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在国内，这种活动也是非常有益的尝试，因为从语言模型发展来看，整个技术社区的发展离不开开源文化，具身智能领域也需要自己的 DeepSeek。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重走婴儿的路 &amp;nbsp;物理世界没有捷径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;看到语言模型的蓬勃发展，很多人可能都会思考一个问题，为什么机器人迟迟等不来它们的涌现时刻？&lt;/p&gt;&lt;p&gt;一个可能的答案是：语言本身就是一种高度压缩的符号系统，人类已经用几千年的时间把世界的复杂性「预处理」成了文字。模型要做的，只是学会这套现成的编码规则。但物理世界没有这样的捷径。重力、摩擦、碰撞、形变，这些规律从未被谁显式地写下来，它们散落在每一次交互的细节里。&lt;/p&gt;&lt;p&gt;这也意味着，物理世界基础模型的构建，某种程度上是在重走人类婴儿的路。物理世界基础模型要学的，是那些人类「做得出但说不清」的东西，这可能才是智能更本源的形态。&lt;/p&gt;&lt;p&gt;这条路注定漫长，也足够迷人。而自变量正走在这条路上。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Sebastian Raschka 2026预测：Transformer统治依旧，但扩散模型正悄然崛起</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:41:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="2" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/79d32e9f-5d40-430d-9bc0-ccba6a68bdc2/1768372696097.png" style="width: 700%;" class="fr-fic fr-dib"&gt;站在 2026 年的开端回望，LLM 的架构之争似乎进入了一个新的微妙阶段。过去几年，Transformer 架构以绝对的统治力横扫了人工智能领域，但随着算力成本的博弈和对推理效率的极致追求，挑战者们从未停止过脚步。&lt;/p&gt;&lt;p data-path-to-node="3"&gt;知名 AI 研究员 Sebastian Raschka 的最新洞察中，他不仅回应了关于「Transformer 是否会被取代」的年度终极之问，更敏锐地捕捉到了近期业界的一个重要转向：从单纯追求模型参数的「大力出奇迹」，转向了混合架构与效率微调的精细化战争。&lt;/p&gt;&lt;p data-path-to-node="4"&gt;同时，文章还探讨了一个极具潜力的变量：扩散语言模型。这类模型在 Google 等巨头的布局下会有怎样的表现？它们在「工具调用」上的天然缺陷是否会成为阿喀琉斯之踵？而在高质量数据日益枯竭的今天，扩散模型又是否能凭借「超级数据学习者」的特性，成为打破数据墙的关键？&lt;/p&gt;&lt;p data-path-to-node="5"&gt;以下内容编译自 Sebastian Raschka 的最新博文，并结合文中提及的前沿论文及往期深度分析进行了系统性拓展，以便读者获取更完整的上下文视角。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="953" data-imgfileid="503527971" data-ratio="0.4" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkABcAaiaj7tMDQEx3dM7KF4Jrw0mFgSpRaT6lfyDicxWYtOGCN5Bh7DK4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="2382" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/29f304a9-fc0f-4360-8fab-0d3b641f93a9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="6"&gt;博客地址：https://x.com/rasbt/status/2010376305720594810&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="8"&gt;最近几周，我经常被问到的一个问题是：&lt;strong&gt;在 2026 年，我们是否会看到自回归 Transformer 架构（即标准的 LLM）的替代方案。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;就目前而言，我坚信 &lt;strong&gt;Transformer 在未来（至少一到几年内）仍将保持其在 SOTA 性能方面的地位。&lt;/strong&gt;它是当前 AI 生态系统的基石，拥有最成熟的工具链和优化方案。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;但是，情况确实会发生一些微调。这并不是说架构会一成不变，而是这种变化更多体现在「效率」和「混合」上，而非彻底的推倒重来。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;效率战争：混合架构与线性注意力的崛起&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;临近去年年底，我们看到业界更加关注&lt;strong&gt;混合架构&lt;/strong&gt;以及如何提高其效率。当然，这并不是什么新想法，但近期来自顶尖实验室的发布表明，目前的侧重点已明显向此倾斜。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;我们回顾一下 DeepSeek V3 以及随后的 R1，它们展示了&lt;strong&gt;混合专家模型（MoE）和多头潜在注意力（MLA）&lt;/strong&gt;的强大之处。DeepSeek V3 通过 MLA 显著减少了推理时的 KV Cache 占用，而 MoE 架构则允许模型在拥有 6710 亿参数的同时，每次推理仅激活 370 亿参数。这种在保持模型巨大容量的同时极致压缩推理成本的设计思路，正是 2025 年末到 2026 年的主旋律。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;但这还不是全部。除了 MoE，我们看到了更激进的效率尝试，例如&lt;strong&gt;&amp;nbsp;Qwen3-Next、Kimi Linear、Nvidia Nemotron 3&lt;/strong&gt;，以及采用了稀疏注意力机制的 DeepSeek V3.2。（如果您对更多细节感兴趣，我在之前的《Big LLM Architecture Comparison》一文中对此进行了报道。）&lt;img data-aistatus="1" data-height="1530" data-imgfileid="503527972" data-ratio="0.6222222222222222" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA7oZuANMs0u5wsmYEwKXUzWj441D8szMn1tI5Hv79Og9eD2fia7O1ibxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="2460" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a2c82762-e812-4600-8f43-5e78767de977/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 带有这类效率调整的 Transformer 架构示意图。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;相关链接：https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="16"&gt;&lt;b data-index-in-node="0" data-path-to-node="16"&gt;为什么大家都在卷「线性注意力」或「稀疏注意力」？&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;标准的 Transformer 注意力机制（Scaled Dot-Product Attention）具有 O(N^2) 的复杂度，这意味着随着上下文长度的增加，计算成本呈二次方爆炸式增长。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="18,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,0,0"&gt;Qwen3-Next&lt;/b&gt; 和 &lt;b data-index-in-node="13" data-path-to-node="18,0,0"&gt;Kimi Linear&lt;/b&gt; 采用了一种混合策略：它们并非完全抛弃标准注意力，而是将高效的线性层（如 Gated DeltaNet）与全注意力层以一定比例（如 3:1）混合。这种设计试图在捕捉长距离依赖（全注意力的强项）和推理速度（线性层的强项）之间找到最佳平衡点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="18,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,1,0"&gt;DeepSeek V3.2&lt;/b&gt; 则引入了稀疏注意力，通过只计算最重要的 Token 之间的相互作用，进一步降低了计算开销。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19"&gt;这些「微调」表明，2026 年的竞争不再仅仅是看谁的模型更聪明，而是看谁能在更长的上下文、更低的延迟下提供同等的智能。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;strong&gt;扩散语言模型：速度与代价的博弈&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;话说回来，除了 Transformer 的变体，&lt;strong&gt;扩散语言模型&lt;/strong&gt;怎么样？&lt;/p&gt;&lt;p data-path-to-node="22"&gt;扩散语言模型之所以具有吸引力，是因为它们能够以相对快速且低廉的成本生成 Token。与自回归模型（AR）那种「一个字接一个字」的串行生成不同，&lt;strong&gt;扩散模型采用的是并行生成&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="23"&gt;想象一下，自回归模型像是一个人在打字，必须打完上一个字才能打下一个；而扩散模型更像是在冲洗一张照片，整段文字从模糊的噪声中同时显现，经过数次「去噪」迭代后变得清晰。&lt;/p&gt;&lt;p data-path-to-node="24"&gt;我前阵子在《Beyond Standard LLMs》一文中对此多写了一些。简而言之，我认为 2026 年我们会看到更多相关内容，Google 可能会推出 &lt;strong&gt;Gemini Diffusion&lt;/strong&gt; 作为其更便宜的 Flash 模型的替代品。Google 已经在其技术博客中暗示了这一点，强调其生成速度「明显快于我们目前最快的模型」。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24"&gt;相关链接：https://magazine.sebastianraschka.com/p/beyond-standard-llms&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;然而，虽然扩散语言模型的优势在于它们可以并行生成 Token，但这同时也是一个巨大的缺点。因为由于并行生成的特性，&lt;strong&gt;它们无法在响应链中原生地整合工具调用&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;在自回归模型中，模型可以生成「调用计算器」的指令，暂停，等待结果，然后再继续生成。而在扩散模型中，整个响应是同时生成的，很难在中间插入一个外部工具的交互步骤。这使得它们在作为智能体使用时面临巨大挑战。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527973" data-ratio="0.5625" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuulUiadnlby61pcX7bDQBmb6pENqfFF0ibzaGCRNFa8fQB6yTnUCX2Tw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7326952b-8424-4118-9941-74e762097b73/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27,0"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 文本扩散过程示例。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;此外，虽然众所周知文本扩散推理效率更高，但最近的研究也表明，如果你为了提升质量而增加去噪步数以匹配自回归模型的性能，那么最终的计算预算其实是相差无几的。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;&lt;strong&gt;数据枯竭时代的「超级学习者」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="30"&gt;那么，我想表达什么呢？既然扩散模型有这些缺陷，为什么我还认为它值得关注？&lt;/p&gt;&lt;p data-path-to-node="31"&gt;我原本计划讨论一月份发布的近期一系列有趣的研究，但我还是想简要重点介绍一篇我在「待读论文」清单上的、2025 年 11 月的有趣论文，它强调了扩散语言模型的一个有趣优势：《Diffusion Language Models are Super Data Learners》。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2511.03276&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1760" data-imgfileid="503527974" data-ratio="1.049074074074074" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAwXOt5dibyF6Lx8pia0JTDF4hAQj1kWnYic5p9w2LkUPTlO688RRLYzE8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" data-width="1678" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f51d529a-149b-4dba-9da1-16643d5e78e8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;来自论文《Diffusion Language Models are Super Data Learners》的带注释图表。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;这篇论文提出了一个在 2026 年至关重要的观点：&lt;b data-index-in-node="25" data-path-to-node="33"&gt;当高质量数据变得稀缺时，扩散模型可能是更好的学习者。&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;众所周知，互联网上的高质量文本数据正在接近枯竭。对于自回归（AR）模型来说，通常我们只让模型把数据「看」一遍（1 Epoch）。如果让 AR 模型反复在同一份数据上训练，它们很容易&lt;strong&gt;过拟合&lt;/strong&gt;，即死记硬背训练数据，导致在未见过的新任务上表现下降。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;然而，上述论文表明，当进行多 Epoch 训练时，文本扩散模型的表现可能优于标准的自回归（AR）大语言模型。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;根据论文的研究结果，在严格控制的预训练设置下，当唯一数据量有限时，通过增加训练轮数，扩散语言模型的表现持续超越了自回归模型。&lt;/p&gt;&lt;p data-path-to-node="37"&gt;这一现象被称为「Crossover（交叉点）」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="38,0,0"&gt;当数据量充足时，AR 模型学得更快。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="38,1,0"&gt;但当数据受限时，DLM 是最终的赢家。例如，一个 10 亿参数的 DLM 模型，仅仅通过反复训练 10 亿个 Token（这在今天看是非常小的数据量），在 HellaSwag 和 MMLU 基准测试上分别达到了 &amp;gt;56% 和 &amp;gt;33% 的准确率，且没有使用任何特殊技巧。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="39"&gt;为什么会这样？ 论文归结为三个因素：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="40,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,0,0"&gt;任意顺序建模&lt;/b&gt;：AR 模型被迫只能从左到右学习，而扩散模型可以学习文本中任意位置之间的依赖关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,1,0"&gt;超高密度计算&lt;/b&gt;：通过迭代的双向去噪，DLM 在训练时实际上对每个样本进行了更深度的压榨。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,2,0"&gt;内置的蒙特卡洛增强&lt;/b&gt;：扩散过程本身就是一种数据增强。同一个句子，每次加噪的方式都不一样，相当于把一条数据变成了无数条变体。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="41"&gt;更有趣的是，论文发现，对于 DLM 来说，&lt;strong&gt;验证集损失的上升并不意味着下游能力的下降&lt;/strong&gt;。即便模型在验证集上看起来「过拟合」了，它在实际任务（如代码生成、推理）上的表现仍在提升。&lt;/p&gt;&lt;p data-path-to-node="42"&gt;由于成本原因，过去没有人会在多个 Epoch 上训练大语言模型。但在数据枯竭的今天，如果我们不得不进行多 Epoch 训练，扩散模型似乎提供了一条新出路。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;这确实是有趣的结果！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>端到端智驾新SOTA | KnowVal：懂法律道德、有价值观的智能驾驶系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:34:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/d749f0ab-f5b6-4259-9d5a-69576200c90d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;一个智能驾驶系统，在迈向高阶自动驾驶的过程中，应当具备何种能力？除了基础的感知、预测、规划、决策能力，如何对三维空间进行更深入的理解？如何具备包含法律法规、道德原则、防御性驾驶原则等知识？如何进行基本的视觉 - 语言推理？如何让智能系统具备世界观和价值观？&lt;/p&gt;&lt;p&gt;来自北京大学王选计算机研究所王勇涛团队的最新工作 KnowVal 给出了一种有效可行的方案。&lt;/p&gt;&lt;p data-path-to-node="2" data-pm-slice="0 0 []"&gt;&lt;b data-index-in-node="0" data-path-to-node="2"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaEMKZM72IQ9tCCpEACHFjVZ03xUbFuTgBb2jQ2mmpOAicQ16Dmribah6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.262037037037037" data-type="png" data-w="1080" data-imgfileid="503528145" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/097a3cc2-e743-4d6d-bd00-416e2cf5b377/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="4,0,0"&gt;论文标题： KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="4,0,0"&gt;论文链接：https://arxiv.org/abs/2512.20299&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="4,2,0"&gt;本工作提出了一种新型自动驾驶系统 KnowVal，该系统通过感知模块与知识检索模块的协同作用，实现视觉 - 语言推理能力。&lt;/p&gt;&lt;p data-path-to-node="4,2,0"&gt;团队构建了涵盖交通法规、防御性驾驶原则与道德考量的综合驾驶知识图谱，并为其开发了高效的基于大型语言模型的检索机制。通过设计集成世界模型与价值模型的规划器，从而实现价值对齐决策。同时构建了人类偏好数据集用于训练价值模型。&lt;/p&gt;&lt;p data-path-to-node="4,5,0"&gt;实验表明，KnowVal 兼容现有的端到端和 VLA 方法，在 nuScenes 数据集上实现了最低碰撞率，并在 Bench2Drive 基准测试中取得了最先进的性能表现。&lt;/p&gt;&lt;p data-path-to-node="4,5,0"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicFZCBCia2pic36dtxra88bsalM6SNTNBHmT5FYDffycTPxqFCibHdNTSSmDNAssslc3dXlFxgjRyAmA/640?wx_fmt=other&amp;from=appmsg#imgIndex=2" alt="image.png" data-ratio="0.2851851851851852" data-type="other" data-w="1080" data-imgfileid="503528146" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/06373dc6-325d-4cc6-bcb7-e64f191a04ec/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="6"&gt;&lt;strong&gt;KnowVal 系统框架：开放三维感知与知识检索相互引导的视觉 - 语言推理&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="7"&gt;相比于当前主流的端到端自动驾驶系统和视觉 - 语言 - 动作（VLA）系统，KnowVal 将视觉 - 语言范式升级为开放三维感知 - 知识检索范式，并通过感知和检索的相互引导，实现了基础的视觉 - 语言推理：&lt;/p&gt;&lt;p data-path-to-node="7"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsa2aXp9HiaDyibt71fgCIKTsmx0EAV9cSnwNXurJ1GG9K8NTmsgQmQNjrw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.49444444444444446" data-type="png" data-w="1080" data-imgfileid="503528147" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/71bf2234-0994-4a69-86fd-5863bf8691c6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;&lt;b data-index-in-node="0" data-path-to-node="8"&gt;检索引导的开放世界感知&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;通过自动驾驶领域专用感知和开放式三维感知，能够抽取常见实例与长尾实例的 3D 目标检测结果与实例特征，以及面向开放世界的全场景占据栅格预测与体素特征，抽取特征保证了整个系统的特征传递与可导；同时，通过利用轻型 VLM 实现的抽象元素理解，能够对上一时间帧知识检索分支要求的信息进行补充，针对「是否是隧道、桥梁场景？是否是夜间场景？」等抽象概念进行自然语言描述。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;&lt;b data-index-in-node="0" data-path-to-node="9"&gt;感知引导的知识图谱检索&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;将感知信息进行自然语言化，对包含了法律法规、道德原则、防御性驾驶原则等知识的知识图谱进行检索，得到多条相关性由高到低排列的知识条目以及其 Token。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;&lt;b data-index-in-node="0" data-path-to-node="10"&gt;基于世界预测和价值模型的轨迹规划&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;通过规划模块和世界模型模块的多轮迭代，得到多条候选自车轨迹、对应的其他物体的运动预测与隐式世界状态。价值模型以上述信息为输入，针对每条候选轨迹和检索得到的知识，进行价值评估，最终选定规划轨迹。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;该系统的各个模块之间保持了显式结果和隐式特征的共同传递，是可端到端微调的 3D 视觉 - 语言 - 动作框架。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;&lt;strong&gt;驾驶知识图谱构建与知识检索&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-path-to-node="13"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaMMIcibPicJiceO7DbBiaZdM9Ymx4TLKLDF64GpJvdw4kxxicoDJjJz4sMDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4685185185185185" data-type="png" data-w="1080" data-imgfileid="503528156" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/61255189-28f9-4fc7-80fe-12f322b43914/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/h3&gt;&lt;p data-path-to-node="14"&gt;作者团队收集了多样化的驾驶相关资源&amp;mdash;&amp;mdash;包括国家现行交通法律法规、防御性驾驶原则、道德准则以及经验知识访谈&amp;mdash;&amp;mdash;并依据文本结构构建了初始的知识森林。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;随后利用大语言模型抽取实体并定义节点与边，形成结构化的知识图谱。在推理过程中，KnowVal 生成富含三维感知信息的自然语言查询，通过实体抽取、知识条目过滤与向量化，从知识图谱中检索相关条目，并按相关性降序进行排序。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;价值模型构建与基于价值模型的轨迹规划&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-path-to-node="16"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaWxy0jbLNf7w5FxnShCxyCaJLGrjGVTtrmuB3vljekib1NqV09ib6oHTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.45555555555555555" data-type="png" data-w="1080" data-imgfileid="503528149" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/cbc46e58-3d99-4d95-8d93-ab12cb33bb91/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/h3&gt;&lt;p data-path-to-node="17,0,0"&gt;KnowVal 提供了一种与现有端到端和 VLA 模型兼容的改造方式，针对其轨迹规划 Transformer 或 RNN 进行改造，引入对自车查询叠加的多条预设高斯噪声和多样性约束损失函数，使其具备生成多样化候选轨迹的能力。&lt;/p&gt;&lt;p data-path-to-node="17,1,0"&gt;KnowVal 构建了一个大规模驾驶价值偏好数据集，用以训练价值模型。数据集选取了多个自动驾驶真实场景数据，通过规划模型预测和随机生成的方式获取多条轨迹，并保存其相应的场景状态（隐式特征向量与显式鸟瞰渲染图），并利用前述的检索方法得到多条知识，为每个轨迹 - 知识对进行介于 -1 到 1 之间的价值评分标注，最终得到包含 16 万个轨迹 - 知识对的数据集。&lt;/p&gt;&lt;p data-path-to-node="17,2,0"&gt;模型推理时，该模块以构造的多条自车特征和感知得到的实例特征与作为查询，以感知得到的全部信息作为键 - 值，通过规划模块和世界模型模块的多轮迭代，得到多条候选自车轨迹、对应的其他物体的运动预测与隐式世界状态；价值模型以上述信息为输入，针对每条候选轨迹和检索得到的每条知识，进行价值评估，并计算每条轨迹的降序加权平均分数，以最终选定规划轨迹。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;作者团队将 KnowVal 框架应用至 GenAD、HENet++ 与 SimLingo 三个基线模型，并在 nuScenes 开环端到端驾驶基准和 Bench2Drive 闭环端到端驾驶基准上进行了测试。KnowVal 范式能够在 nuScenes 上取得最低的驾驶碰撞率，并在 Bench2Drive 上取得最高的驾驶分数和成功率。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaJumgYYI0GSAkwAic8v83iaJDhjOabn0lvYtic7EIsf3P2VBiaBqqF800sQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.38333333333333336" data-type="png" data-w="1080" data-imgfileid="503528150" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/abae9949-6237-4dda-a763-64133cc8c5ad/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicFZCBCia2pic36dtxra88bsaFZCKIWQAQxULO32mcMCbXO3GkmofYH1FPRCKVZHqEgmGwp8ibbaIeKw/640?wx_fmt=other&amp;from=appmsg#imgIndex=7" alt="image.png" data-ratio="0.6334519572953736" data-type="other" data-w="562" data-imgfileid="503528151" data-aistatus="1" data-original-style="width: 383px;height: 243px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/391aefc3-d124-48d4-8e34-8bc135450f75/640.png" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;现有基准测试对于法律和道德行为的评估并不够全面，因此，作者也提供了几个定性分析样例，以说明 KnowVal 的实际效果：&lt;/p&gt;&lt;p data-path-to-node="21"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicFZCBCia2pic36dtxra88bsaE9MBCibM0vP1zFalTaX0wvMiaxDxq4cRUTmhaD3N147NKiciayQmnwS3qQ/640?wx_fmt=other&amp;from=appmsg#imgIndex=8" alt="image.png" data-ratio="0.6784452296819788" data-type="other" data-w="566" data-imgfileid="503528152" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8fae5db4-99ef-4527-a0fe-d3882ceabe4a/640.png" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;上图中两个样例，前者是在 nuScenes 真实数据上通过场景编辑得到，测试智能驾驶系统是否能够在路过积水时减速慢行、以免溅到行人；后者是在 CARLA 模拟器中隧道场景进行的测试，测试智能驾驶系统是否会遵循「隧道内 / 实线车道不能变道」的法律法规。实验结果说明，原本无法正确处理这些情况的端到端智驾模型，增加了 KnowVal 的知识检索与价值评估后，能够正确应对这些情形。&lt;/p&gt;&lt;p data-path-to-node="22"&gt;&lt;strong&gt;作者介绍&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;p data-path-to-node="23"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"data-path-to-node":"23","style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;该论文的第一作者和通讯作者均来自北京大学王选计算机研究所的 VDIG (Visual Data Interpreting and Generation) 实验室，第一作者为北京大学博士生夏仲禹，通讯作者为博士生导师王勇涛副研究员。VDIG 实验室近年来在 CVPR、NeurIPS、IJCV、ICCV、ICML、AAAI、ECCV 等顶会顶刊上有多项重量级成果发表，多次荣获国内外 CV 领域重量级竞赛的冠亚军奖项，与国内外知名科研机构和企业广泛开展合作。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>仅用10天？Anthropic最新智能体Cowork的代码竟然都是Claude写的</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:15:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="7"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f8b57c5c-1804-4c71-98aa-15c66eaeadb1/1768371250956.png" style="width: 700%;" class="fr-fic fr-dib"&gt;最近，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"data-path-to-node":"6","style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Anthropic &lt;/span&gt;发布了全新的智能体工具 &lt;strong&gt;Cowork&lt;/strong&gt;，号称能让普通用户像开发者使用 Claude Code 一样，轻松搞定非技术性任务。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1918" data-imgfileid="503528202" data-ratio="1.5907407407407408" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic04lULDjNExgQfIX4b0wpqM8H7I5FllnxLYCTcaOlPDM23zP8QVEloQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" data-width="1206" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8ed05b6b-1bf8-4618-8d0c-053650e0ef2f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="8"&gt;更令人咋舌的是，&lt;strong&gt;Cowork 的诞生仅仅用了一周半&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="840" data-imgfileid="503528203" data-ratio="1.1444141689373297" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicJUddgCHx02J2FUqKQ5xefAGxicwS9CSEegTiaDwdsgsALyUjIGQSZibRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="734" data-width="734" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1770f628-5015-4a18-977b-b75e217ee9ca/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="9"&gt;Cowork 是 Claude Code 的简化版本，专为普通用户设计。目前作为研究预览版，仅向 macOS 桌面端的 Claude Max 订阅者开放。用户只需授权访问特定文件夹，便能通过自然语言指令，让 AI 自主读取、编辑或创建文件。它不仅能制定计划、并行执行任务，还会实时更新进度，并邀请用户参与指导。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;根据官方介绍，Cowork 的能力包括但不限于：自动整理下载文件夹、从截图生成电子表格、基于散乱笔记起草报告，甚至支持连接 Google Calendar 等现有工具，直接生成文档或演示文稿。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;据 Claude Code 创建者 Boris Cherny 所说，&lt;strong&gt;Cowork 的全部代码都是由 Claude Code 写的&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;这简直就是 Claude Code 最好的广告，当其他 AI 公司还在靠收购构建生态的是时候，Anthropic 已经开始让 AI 自己生 AI 了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="956" data-imgfileid="503528205" data-ratio="0.725" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicqbQazWsSmkU1RAJSHVP0w9cH5Z8w9lIsiaJ6A82JNOxibEldibqX4qoPw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-type="jpeg" data-w="1080" data-width="1318" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/08483140-9265-4c99-87dc-75e274cd4a2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="14"&gt;有不少用户分享了实测反馈，其中热度最高的帖子之一来自 X 用户 vibhu。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;他表示自己安装 Cowork 后，仅用 2 小时就完成了原本需要 2 个月的工作，包括生成职位描述、营销策略文档、合作伙伴邮件、网站文案等。随后，他「惊慌」地发现日程、待办和收件箱都空了，不知道工作该怎么继续，甚至在为下午的经理一对一会议发愁。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="724" data-imgfileid="503528206" data-ratio="0.7973568281938326" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicXEI0wLSeRXQeT2PJia0kdWiaUGF07HDyukUg9h05iaC99QvSfDMdlBk4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="908" data-width="908" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f07b439b-ca6d-4bb3-99d9-0523f69d8820/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="16"&gt;不过评论区很多人质疑其真实性，认为这可能是夸张的营销或搞笑帖。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="200" data-imgfileid="503528207" data-ratio="0.21739130434782608" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicIib5ic4HG6jXHib10fAzS8MWQ8XvlXqPDdcUoBcXGOLw3ryrqt5svOcbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="920" data-width="920" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f76a4f83-762d-4759-a67b-a2b3a65a6ef4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="384" data-imgfileid="503528208" data-ratio="0.4151351351351351" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicVokzVt8v7Brhtv4zu1tJ6MyG8mVYuOHEWZ7vqzyWicdK5ZNiaYJDdxhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="925" data-width="925" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/a560f658-dd18-4410-9bab-c14ee026d5bf/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="17"&gt;但在创业圈，这种冲击却是实打实的。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;有人感叹，这将使许多 YC 创业项目原地蒸发。毕竟在 AI 圈，真正的硬通货是地基和模型，而不是那些依附在巨头身上的「套壳挂件」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="815" data-imgfileid="503528209" data-ratio="0.9005524861878453" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicqqhn0wHBtQ0sffCQcodiaWeZg3xzRKjWmshVgKzUyyU2ibhuY2vibUrQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="905" data-width="905" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/1ecc9524-cbdc-4c47-ab4a-ec871d149f30/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="19"&gt;甚至已经有「受害者」出现：用户 Guohao Li 表示，由于 Claude Cowork 的横空出世，他们的类似产品失去了竞争力，于是选择开源。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="785" data-imgfileid="503528210" data-ratio="0.8616904500548848" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicnPPBpY6PLdvz04vW6ppJDBNSLWa0vRbwV6bLkJjcxBWSQXCG1icFEDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="911" data-width="911" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/918e8932-6932-4c04-8d9b-476fb58d2370/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;大家纷纷调侃「开源才是王道」，HuggingFace 联合创始人 Thomas Wolf 也现身评论区表达支持。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="144" data-imgfileid="503528211" data-ratio="0.15737704918032788" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicOewUPXqWfibMq8k5r9umh0CyicmoBFC0AXO3RGicOKlRQ9gdtiaphiaLcog/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="915" data-width="915" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6b7db1a0-428d-4ca8-88a4-fa5197f9e04f/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="21"&gt;该项目快速获得 3K GitHub Star。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="698" data-imgfileid="503528212" data-ratio="0.7636761487964989" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicH57XFy5NCUeiafmiaiaxnw7RvpPazf8XaCibWNKJun3SibtsyO4SWz1KB1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="914" data-width="914" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/dd77c8b4-ae96-48c2-b1c0-52187e160293/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22"&gt;社区也不乏调侃之声，看看这个「当前创业公司结构」：现在的科技创业似乎只需要一个聪明大脑，外加一张能付得起 AI 公司账单的信用卡就够了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="314" data-imgfileid="503528213" data-ratio="0.34316939890710385" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicrKTeu5WydmA2Iib8nYdsT19ibAsibLXEWe7sG7iavjTd7REf9y04hTEyeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="915" data-width="915" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/a7ee9e40-a8aa-4702-966e-dfd8bfe4a761/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23"&gt;当下，日常工作下的助理智能体正在层出不穷，结合电脑手机系统的智能体也越来越强大。豆包手机的出现已经重塑了普通人对日常工作任务智能化的想象。&lt;/p&gt;&lt;p data-path-to-node="24"&gt;但就像网友使用过 Cowork 说的：「我正在努力想办法解释，为什么我既比以往任何时候都更有效率，又完全没用。」&lt;/p&gt;&lt;p data-path-to-node="25"&gt;普通人对智能体完全代理工作任务，似乎还没有做好预期和准备。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;相比于其他公司的巨额并购投资，Anthropic 借助 AI 能力，在短时间内，以低成本的方式打造用户端智能体的策略，是否更有价值？&lt;/p&gt;&lt;p data-path-to-node="27"&gt;&lt;sup&gt;参考链接：&lt;br&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;https://x.com/TheAhmadOsman/status/2010917868586647693&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;https://x.com/craigzLiszt/status/2010842587624505445&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;https://x.com/guohao_li/status/2010899322825744745&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026｜AP2O-Coder 让大模型拥有「错题本」，像人类一样按题型高效刷题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:11:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/cdd5136e-f7db-4818-8b3b-97587028f6af/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;作者：上交博士，在腾讯codebuddy 实习，发表一作顶会顶刊论文10篇（含best paper 等），开源PFLlib等明星项目，获得社区赞誉。主要研究AI强化学习、AI合成数据、Agent 记忆等。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;在 AI 辅助 Coding 技术快速发展的背景下，大语言模型（LLMs）虽显著提升了软件开发效率，但开源的 LLMs 生成的代码依旧存在运行时错误，增加了开发者调试成本。&lt;/p&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;现有基于偏好优化的改进方法，多依赖「通过 / 失败」二元信号构建训练数据，难以知晓「错在哪」，也忽视了模型能力在训练时的动态变化特性。&lt;/p&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;针对此缺口，在腾讯 CodeBuddy 实习期间，我们提出自适应渐进式偏好优化方法（AP2O），并构建 AP2O-Coder 框架。该方法借鉴人类的「按题型高效刷题」经验出发，通过「考试 - 分析 - 纠错 - 小测」的系统性流程提升模型代码纠错能力，在多款主流开源模型上实现最高 3% 的 pass@k 性能提升，同时降低训练数据需求量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAOExTFtLBFIpLxPwzhSEGqeC0JuSzAUiccKnEo0KgxYRfZGC4pwNqQow/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.20925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528019" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/36055654-21e4-40f4-adc2-e1033c58f252/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：AP2O-Coder: Adaptively Progressive Preference Optimization for Reducing Compilation and Runtime Errors in LLM-Generated Code&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2510.02393&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源代码：https://github.com/TsingZ0/AP2O&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="7"&gt;&lt;strong&gt;一、现有方法的核心挑战 与 AP2O-Coder 的针对性设计&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;当前离线偏好优化方法（如 DPO 等）在 LLM 代码纠错任务中面临三大核心挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="9,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,0,0"&gt;错误类型感知缺失&lt;/b&gt;：仅依赖单元测试的二元反馈信号，无法知晓类型错误（如 KeyError、ValueError 等），导致模型难以定位错误原因；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="9,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,1,0"&gt;训练聚焦性不足&lt;/b&gt;：训练数据采用随机打乱的方式批量输入，模型需在多种错误类型间频繁切换适应，纠错学习的针对性不强；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="9,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,2,0"&gt;动态适配能力薄弱&lt;/b&gt;：静态构建的训练集无法匹配模型训练过程中不断变化的能力短板，易引发灾难性遗忘或训练资源浪费。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="10"&gt;为应对上述挑战，AP2O-Coder 借鉴人类按题型进行的「错题整理 - 专题突破 - 定期复盘」的学习模式，构建了包含四大核心模块的优化框架，旨在实现错误信息的深度利用与模型能力的动态适配。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;二、AP2O-Coder 的核心技术框架与工作机制&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;AP2O-Coder 的核心设计思路是通过系统化流程实现错误类型的精准捕捉、渐进式优化与动态适配，其整体框架包含四个关键步骤（如图 1 所示）：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528002" data-ratio="0.8740740740740741" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8ZwUnMzYAKh879bPqUpxnaGFANfZnddUibeNurRo4SXIicjv4nd2qr8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/41e29db1-9a18-480f-b681-b594188a3c2c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：AP2O-Coder 框架流程图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;代码生成评估（Exam）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为全面掌握目标模型的初始能力边界，该模块让 LLM 在 M 个编程任务上生成 &amp;nbsp;N 个候选答案（采用温度系数 1.0 的设置以充分探索能力范围），通过配套的单元测试获取每个答案的「通过 / 失败」标签，形成初始训练数据集，为后续错误分析提供基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;错误诊断分析（Analysis）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;借助编程语言专用分析工具（如 Python 解释器）对所有失败答案进行结构化解析，标注具体错误类型并统计各类错误的出现频率，按错误题型构建结构化的「错题本」。该过程实现了从二元反馈到精细化错误信息的转化，为针对性优化提供数据支撑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;渐进式偏好优化（Correction）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于错题本，设计差异化的优化顺序：对于小参数模型（如 0.5B）采用「低频错误 -&amp;gt; 高频错误」（L2H）的优化路径，对于大参数模型（如 34B）采用「高频错误&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&amp;nbsp;-&amp;gt;&amp;nbsp;&lt;/span&gt;低频错误」（H2L）的优化策略。通过构建 DPO 滑动窗口，逐步聚焦各类错误类型，一个题型一个题型地纠错，生成有序的偏好数据对&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACA4ZGAiahjLAnricTUjV3TauGDqa6hWr1iaXmJdx4TT8kKoG315kia6pRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.20952380952380953" data-s="300,640" data-type="png" data-w="315" type="block" data-imgfileid="503528003" data-aistatus="1" data-original-style="width: 110px;height: 23px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/804f11fa-8d16-4560-97de-d6f0d0d9869c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 14.34%;"&gt;，使模型能够分阶段集中优化特定类型错误。其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4r7fKtTqQFlgNvkSZz8c2J9wI15TLDNaZOsslB6jEwU6zrPOgh5jGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8095238095238095" data-s="300,640" data-type="png" data-w="63" type="block" data-imgfileid="503528005" data-aistatus="1" data-original-style="width: 22px;height: 20px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1a75d6aa-dcb9-4adf-9ab9-948106ae9f0a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 3.58%;"&gt;是输入 Prompt，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAOa3sibWRuahEOD3HsS6NLwkogiazOq8ib5x6xjq8fFUYXfvhypiasxCO0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7951807228915663" data-s="300,640" data-type="png" data-w="83" type="block" data-imgfileid="503528004" data-aistatus="1" data-original-style="width: 28px;height: 22px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/204ec741-876f-4178-b620-44ccd01d8500/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 4.22%;"&gt;是正确的回答（随机获得），&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALtwLP9gz8fZWkicw6S70q0Ym1ybO351JkuYLGZ62AxhOdxAesB4DETA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.8461538461538461" data-s="300,640" data-type="png" data-w="78" type="block" data-imgfileid="503528006" data-aistatus="1" data-original-style="width: 25px;height: 21px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8b3c5919-d4b1-481e-9441-cab283475875/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.8%;"&gt;是错误类型为 E 的错误回答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自适应错误回放（Quiz）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为适配模型训练过程中的能力变化，该模块定期在一个小验证集上评估模型性能，实时捕捉当前阶段的高频错误类型，&lt;strong&gt;找出模型依旧犯错的题型&lt;/strong&gt;，将其对应的失败答案重新纳入训练流程。通过动态调整训练数据分布，确保模型始终聚焦于当前的能力短板，有效缓解灾难性遗忘问题。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;三、实验验证与结果分析&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;研究团队在 6 款主流 LLM（含代码专用模型 CodeLlama、DeepSeek-Coder、Qwen2.5-Coder 与通用模型 Llama3、Qwen2.5、Qwen3）上开展了系统验证，参数规模覆盖 0.5B - 34B，实验基准包括 EvalPlus（HumanEval/MBPP）与 LiveCodeBench v6，主要取得以下研究发现：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;性能提升的有效性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在不同类型与参数规模的模型上，AP2O-Coder 均展现出稳定的性能改进。如下表所示，在 EvalPlus（HumanEval）基准上，AP2O-Coder (H2L) 即使对于 30B+ 的大参数模型，也能实现 2.8% - 3.4% 的性能优化，且未出现现有后训练方法中性能退化现象。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAghU5EpZhTicsr5np8iaNwxw2FnsIXpKiaOQ8e5AdxDvFK2tA3YkTQ2Txw/640?wx_fmt=jpeg#imgIndex=7" data-ratio="0.275" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkApxldNLAOudYbzFfibZ1mI3QJPEmTN7pPHrqibHbfLIRwthqMjzgYSM4Q/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1896" data-cropy2="521.5640138408305" data-imgfileid="503528008" data-aistatus="1" data-original-style="width: 578px;height: 159px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ce182892-f694-4c18-8a68-6c53bd4ffcaf/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表 1：各种类型和规模代码的 LLM 在 Pass@1 on EvalPlus (HumanEval) 上的表现。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;&lt;b data-index-in-node="0" data-path-to-node="22"&gt;错误抑制效果与泛化能力&lt;/b&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAPxWA6dCx06XP6SqyRMu34E5xVL3k7flKVvoABDcBNtNgDOhm4jReqw/640?wx_fmt=jpeg#imgIndex=8" data-ratio="0.47628657921291623" data-s="300,640" data-type="png" data-w="991" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4DGrQQibYNp8wv71uIRcYoia4ibmCRY0IhwWQ0oMk0ST2sj1ENd4LGeKg/0?wx_fmt=png&amp;from=appmsg" data-cropx2="991" data-cropy2="473.21107266435985" data-imgfileid="503528009" data-aistatus="1" data-original-style="width: 578px;height: 276px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/533dab17-5b89-4c7f-a0e9-d36ccbd5dec4/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 2：使用 Qwen2.5-Coder-7B 在测试基准上出现错误的统计数据。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528013" data-ratio="0.2219074598677998" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv3oc1sCeuvDewibwUPVkceRV8lcnusqKIibFUsWRUwL5FzoJEicv0LMAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="1059" type="block" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/43a46cdc-fd07-4f06-a461-254764b8778d/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23,0"&gt;&lt;sup&gt;图 3：使用 Qwen2.5-Coder-7B 在测验阶段对验证集上的错误统计结果。我们的 AP2O-Coder 能够逐步减少错误。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="25"&gt;如图 2 所示，相较于 SFT、DPO 等基线方法，AP2O-Coder 能够有效降低各类错误的发生频率，且未引入新的错误类型。如图 3，在 Qwen2.5-Coder-7B 的实验中，高频错误「WrongResult」的发生率显著下降，IndexError 等小众错误在训练后期实现清零。同时，该方法在 pass@5、pass@10 等指标上的稳定提升（如图 4），表明其增强了模型代码生成的泛化能力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528014" data-ratio="0.4214876033057851" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA13Moic8jYUylCM41EWCX0IwwickMyYXlib33ecBAmXJTXxtKibaxb2yUJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="968" type="block" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/34df3be3-69a9-4e37-b71b-de3708a82f3d/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="25"&gt;&lt;sup&gt;图 4：在不同模型规模下，使用 DeepSeek-Coder 在 EvalPlus (HumanEval) 基准上的 pass@5 和 pass@10 表现。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;&lt;b data-index-in-node="0" data-path-to-node="27"&gt;样本效率的优化&lt;/b&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528016" data-ratio="0.262037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAtIpgXboWLXkxgIsfXwF9crMCG2dYb2hfZDraPHoxeVWqGMPpicsMruA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/63dec4ba-c896-4fab-8abe-81e323febf14/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;sup&gt;图 5：用于在 MBPP 训练集上对不同规模的 Qwen2.5-Coder 进行训练并达到最优性能的偏好数据对需求。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="29"&gt;AP2O-Coder 通过错误类型的精准聚焦，显著提升了训练数据的利用效率。实验结果显示，该方法仅需 4% - 60% 的偏好数据即可达到传统 DPO 方法的最优性能，在 32B 参数规模的模型上，数据需求量减少更为明显（如图 5），这就和班上刷题时，优等生所需刷题量更少类似，为低资源场景下的 LLM 代码优化提供了可行路径。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;&lt;b data-index-in-node="0" data-path-to-node="30"&gt;通用 LLM 适配性&lt;/b&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528018" data-ratio="0.3142857142857143" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAxeibb5Bicv9x5WM4nBPKm0vHcXI5QGR5P8qW3ic37z2q3KAeDb685nianw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="875" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/25cde936-bae6-43f7-8166-c6077483ebfc/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="30"&gt;&lt;sup&gt;图 6：在将通用 LLM（如 Qwen2.5、Qwen3 和 Llama3）适配到代码领域时，其在 EvalPlus (MBPP) 上的 pass@1 表现。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;AP2O-Coder 不仅适用于代码专用 LLM，也能有效支持通用 LLM 向代码领域的适配。在 Qwen3、Llama3 等通用模型的实验中，经过该方法优化后，模型在 MBPP 基准上的 pass@1 分数显著提升，验证了其跨模型类型的适配能力（如图 6）。&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;四、研究发现与方法特性&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;实验过程中，团队发现了优化策略与模型规模的适配规律：&lt;/p&gt;&lt;p data-path-to-node="35,0,0"&gt;对于 &lt;b data-index-in-node="3" data-path-to-node="35,0,0"&gt;Qwen2.5-Coder&lt;/b&gt;，小参数模型（&amp;le; &lt;span data-index-in-node="23" data-math="\le"&gt;3B）采用「低频错误&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&amp;nbsp;-&amp;gt;&amp;nbsp;&lt;/span&gt;高频错误」的优化顺序更具优势，这一策略可避免模型因能力有限而陷入高频常见错误的学习困境，而让小模型一开始能看到不同种类的错误，跳出局部最优；&lt;/p&gt;&lt;p data-path-to-node="35,1,0"&gt;大参数模型（&amp;ge; 7B）采用「高频错误 -&amp;gt; 低频错误」的顺序效果更优，能够充分发挥其强学习能力，快速实现整体错误率的下降。这一发现为不同规模 LLM 的代码优化提供了针对性参考。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>用AI从常规病理切片重建空间蛋白图谱：基于H&amp;E图像的高维蛋白质表达预测</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Wed, 14 Jan 2026 14:03:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TqnmMJSAgLibOXh7stVJk7N0GBia1ib4FkwGhM3ZXfAB4MXjWKebYJW5zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5481481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="317" data-imgfileid="100027143" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/383caf82-e71e-4e2f-8601-0ec71c64d59a/640.png" data-sec-load-status="2" data-report-img-idx="0" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;空间蛋白质组学，它代表着蛋白质表达的高分辨率定位，对于生物学与疾病的研究至关重要。而相关空间蛋白质组学的翻译可不算简单，成本、复杂性和可扩展性，现有方法仍不足以填上这些方面的缺漏。&lt;/p&gt;&lt;p&gt;于此，美国斯坦福大学（Stanford University School）等研究团队介绍了 H&amp;amp;E 到蛋白质表达（HEX），这是一个 AI 模型，旨在从标准组织病理切片中计算生成空间蛋白质组学谱。&lt;/p&gt;&lt;p&gt;此外，该团队还开发了一种多模态数据集成方法，结合了上述原始的 H&amp;amp;E 图像与 AI 衍生的虚拟空间蛋白质组学，比传统临床病理学和分子生物标志物，提高了 22% 的预后准确性，并提高了 24% 至 39% 的免疫治疗反应预测。&lt;/p&gt;&lt;p&gt;相关研究内容以「&lt;em&gt;AI-enabled virtual spatial proteomics from histopathology for interpretable biomarker discovery in lung cancer&lt;/em&gt;」为题，于 2026 年 1 月 5 日发布在《Nature Medicine》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6ThLppRRbPzD5PsBMh4cgx6c7FpAUCr5vYaVULicubfqJBOLzxDRML95A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37659574468085105" data-type="png" data-w="940" data-width="940" data-height="354" data-imgfileid="100027138" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ee2472b8-63da-42c2-bfb4-5386436455be/640.png" alt="图片" data-before-load-time="1768370581251" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41591-025-04060-4&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;图像特征到空间蛋白表达&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;HEX 通过利用最先进的病理学基础模型进行训练，基于 H&amp;amp;E 图像同时预测 40 个蛋白质生物标志物的表达，可以从标准组织病理学生成虚拟空间蛋白质组学谱。&lt;/p&gt;&lt;p&gt;团队通过两个独立数据集与包含 57plex CODEX 的泛癌数据集，对 HEX 模型的准确性与普遍性进行了评估验证。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6T22icrQpPrf0ThS6yqkySUywLQ7SyjXfGxmc2TaAMXTwnEYwWZ2hX1FA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.332846715328467" data-type="png" data-w="685" data-width="685" data-height="913" data-backw="546" data-backh="728" data-imgfileid="100027141" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f2c14f07-70a7-49f5-9ce5-13ea67e2ae2d/640.png" alt="图片" data-before-load-time="1768370581269" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：HEX 的开发、验证及临床应用。&lt;/p&gt;&lt;p&gt;在结构设计上，HEX 以病理图像的局部区域为输入，输出对应区域内多种蛋白的空间表达强度。模型并非简单地进行整体回归，而是保留空间分辨率，使预测结果能够以&amp;ldquo;图谱&amp;rdquo;的形式呈现。这一点对于后续的生物学解释尤为关键。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6T8aD2mj3kU0EvxhDPRbrY1CRK0OQ0ol2iaxNQCsKmqDWjPhiahibdR5u4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4087591240875912" data-type="png" data-w="685" data-width="685" data-height="965" data-backw="546" data-backh="769" data-imgfileid="100027140" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/539b5703-9904-41c3-8d34-61ed6e9f502d/640.png" alt="图片" data-before-load-time="1768370581579" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：HEX 在蛋白质生物标志物预测中的性能评估。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;交叉性能验证：&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验团队在 Stanford-WSI 数据集进行了五重交叉验证，通过 40 个生物标志物，HEX 实现了 H&amp;amp;E 图像中蛋白质表达的准确预测。与次优模型条件 GAN（CGAN）相比，HEX 显著提升了 26% 的皮尔逊系数、44%的斯皮尔曼系数、15% 的 SSIM 和 80% 的 MSE。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;独立验证：&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;接下来，团队使用完整的 Stanford-WSI 数据集，评估了两个独立微阵列（TMA）的表现。依旧是与次优模型 CGAN 相比，HEX 几乎将所有系数翻了个番。这些结果共同凸显了 HEX 在独立数据集上的普遍性和稳健性。&lt;/p&gt;&lt;p&gt;值得注意的是，HEX 并未只关注肿瘤细胞本身。模型同样能够在肿瘤微环境中，对免疫相关蛋白的空间分布作出合理预测，为后续的免疫状态分析提供了基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多模态共关注整合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;H&amp;amp;E 提供了详细的细胞组学，虚拟 CODX 图谱提供了关于空间分辨蛋白表达的补充信息。为了整合这些不同但协同效应的数据类型，研究团队开发了多模态共关注整合（MICA），这是一种深度学习框架，可以明确建模跨模态交互和空间关系。&lt;/p&gt;&lt;p&gt;在实验验证的分析中，团队将小细胞肺炎区分为早期与晚期，并检验 HEX 预测得到的虚拟空间蛋白图谱在这两类人群中的表现差异。&lt;/p&gt;&lt;p&gt;在早期肺癌样本中，HEX 预测的空间蛋白表达呈现出更为局部化和结构化的模式。部分与肿瘤发生早期相关的蛋白，其预测信号主要集中于肿瘤边缘区域或特定细胞群体周围。&lt;/p&gt;&lt;p&gt;在晚期肺癌样本中，HEX 预测的蛋白空间模式表现出明显不同的特征。多种蛋白的高表达区域在空间上更加弥散，与组织结构的对应关系也更为复杂。这反映了晚期肿瘤在细胞组成和微环境层面的高度异质性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkofGjfaXtexfrcoqPEIj6TGicUeq63dYBpSMDAxOttCCGMia8WUISxfDdLzNL8HKP0EFXu4pjibONVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.272992700729927" data-type="png" data-w="685" data-width="685" data-height="872" data-backw="546" data-backh="695" data-imgfileid="100027139" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7d1bba28-bb53-4140-b8b8-2e30922f0b48/640.png" alt="图片" data-before-load-time="1768370582464" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 3：MICA 提升免疫治疗反应预测能力，并识别晚期非小细胞肺癌中的空间蛋白质组特征。&lt;/p&gt;&lt;p&gt;对于早期肺癌患者，这些空间蛋白特征更多与长期预后相关，提示模型捕捉到的信号可能与肿瘤早期生物学行为及潜在进展风险有关。而在晚期患者中，预测信号则更多与治疗反应，尤其是免疫相关治疗结局相关联。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;组织学+虚拟空间蛋白质组学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;HEX 是一种高精度的预测方式，已扩展至 34 种组织类型和新的蛋白质标记，展示了相较于其他基于 H&amp;amp;E 图像预测蛋白质表达的方法的显著性能提升。相比临床风险因素，HEX 将预后预测的准确性提高了 20% 以上。&lt;/p&gt;&lt;p&gt;HEX 模型实现了更准确的靶向蛋白表达预测，虽然说，目前仍存有依赖抗体行免疫荧光成像等问题，但大都可以期待新型的细胞技术合作解决。该模型为标准组织病理学中的空间生物学研究提供了低成本且可扩展的方法，这使得原本受限于成本和通量的空间分子分析，首次有可能在更大规模的临床数据中展开。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>京东首届AI影视创作大赛启动 最高奖金10万元邀全民共创AI视频</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Wed, 14 Jan 2026 12:48:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1月14日，京东正式发起首届AI影视创作大赛，面向全民发出邀约，邀请广大用户用AI技术结合京东年货节全民寻马IP形象&amp;ldquo;马红红&amp;rdquo;、京东数字人男团E&amp;#39;Core或品牌指定的商品形象创作视频，激发创意潜能。本次大赛设有丰厚的基础奖金：冠军5万元、亚军3万元、季军2万元，另设1万元马年特别创意奖及最高4万元品牌赛道奖，个人可叠加获得最高10万元现金奖励。此外，京东还为所有参赛作品提供千万流量扶持，作品征集期持续至2月1日。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c1049b01-21e6-4dbe-b3e1-eb4f1b072151/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20260114124239_1234_212.jpg" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;为让更多参赛者便捷参与，本次大赛设置了极简报名通道，参赛者只需打开京东APP搜索&amp;ldquo;AI大赛&amp;rdquo;即可直达活动专区，关注&amp;ldquo;圈子&amp;rdquo;、点击报名、上传作品并关联赛事话题，即可完成参赛。本次大赛对参赛作品的要求兼顾专业性与包容性，参赛者需提交15秒以上的AI原创短片，比赛对所使用的AI工具则不做限制，无论是AI生成画面、数字人驱动、音频合成还是特效增强，只要显著应用了AIGC技术，均符合参赛条件。值得注意的是，如果参赛者的作品包含非 AI 生成的音乐、字体、影像片段、图片等第三方素材，需要取得完整的商用授权，严禁使用未经合法授权的任何版权素材参赛。&lt;/p&gt;&lt;p&gt;在奖项设置方面，大赛奖金由基础奖金、马年特别创意奖和品牌奖金三部分构成，单人可叠加获得最高10万元现金奖励。具体来说，大赛基础奖金奖励大赛作品前三名，第一名将获得5万元，第二名3万元，第三名2万元；此外，如果参赛者作品中使用了京东年货节全民寻马IP形象&amp;ldquo;马红红&amp;rdquo;，还有机会获得马年特别创意奖，奖金1万元，该奖项将于1月19日开启报名。京东全球购、京喜业务及美的、追觅、科大讯飞、小度品牌为参与品牌赛道的优质参赛者提供额外的奖金，参赛者可选择指定合作商家进行命题创作，将AI剧情与品牌商品结合，单个商品作品冠军可赢取最高4万元奖金或价值不低于3000元的品牌新春礼盒。&lt;/p&gt;&lt;p&gt;大赛评选机制注重数据表现与专业水准的双重考量。参赛者的视频内容效果数据占50%的权重，由平台数据系统根据视频浏览量自动计分；专业评审团的反馈同样占50%权重，评审团由外部导演、高校专家及京东AI影视创作大赛组委会成员组成，将从审美创意、主题创意、AI技术完成度及原创性四个维度进行综合评估。所有提交作品将在48小时内完成合规性初筛，通过后公开展示并积累热度数据，所有获奖名单将于2月6日在大赛官方页面公示。&lt;/p&gt;&lt;p&gt;在奖励发放方面，现金奖励将于中奖信息公示后30个工作日内统一发出，参赛者可在&amp;ldquo;京东创作服务平台&amp;rdquo;的收入中心进行提现；实物奖品则需中奖用户于2月28日前通过问卷登记收件信息，届时京东将在核实信息后30个工作日内寄出。&lt;/p&gt;&lt;p&gt;京东首届AI影视创作大赛的举办，致力于为广大AI视频创作者打造一个展示创意才华、实现商业价值的舞台。无论是参赛者是专业的AI视频创作者还是业余爱好者，都可以在这个马年新春，用AI技术讲述属于自己的创意故事。即日起至2026年2月1日，打开京东APP搜索&amp;ldquo;AI大赛&amp;rdquo;，开启你的AI影视作品创作之旅。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>合合信息多模态文本智能产品“上新”，覆盖AI教育、AI健康、AI Infra多元场景</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 10:39:30 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;随着人工智能（AI）产业进入&amp;ldquo;落地为王&amp;rdquo;的新阶段，AI技术与多元化场景的融合成为行业焦点。近期，上海合合信息科技股份有限公司（简称：合合信息，股票代码：688615.SH）集中发布了系列基于多模态大模型的创新产品，覆盖AI教育、AI健康管理、AI Infra（AI&amp;nbsp;基础设施）、AI Agent应用等多个领域，展现了文本智能技术与垂直场景结合的创新潜力，为AI商业化落地提供了新思路。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;解锁文档服务、教育、健康管理&amp;ldquo;AI玩法&amp;rdquo;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;当前，AI大模型发展正从通用能力向行业纵深落地演进，在通用文档处理领域，合合信息旗下产品扫描全能王推出&amp;ldquo;CS-AI一站式智能化文档解决方案&amp;rdquo;，实现从影像数字化向文档全周期智能服务升级。CS-AI覆盖了扫描、阅读、编辑和学习等核心场景，可自动修复图像质量问题，实现智能重排文档、优化排版。据扫描全能王产品团队介绍，依托在文档解析、版面还原上的技术优势，CS-AI预计将在跨境电商、出境游、专业文档翻译等市场中展现强劲的出海潜力。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;strong&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;&lt;img width="453" src="https://image.jiqizhixin.com/uploads/editor/ae17f4cb-a8dc-4b44-b177-b58f8d5cab6f/1768357688399.jpeg" alt="descript" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;color:#7F7F7F;'&gt;图说：扫描全能王&amp;ldquo;CS-AI一站式智能化文档解决方案&amp;rdquo;功能一览&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:justify;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;依托多模态大模型文本智能技术，合合信息将AI能力拓展至教育、健康等垂直场景，将&amp;ldquo;千人千面&amp;rdquo;的体验变为现实。在教育领域，合合信息面向国内及海外市场，推出了AI错题学习管理工具&amp;ldquo;蜜蜂试卷&amp;rdquo;&amp;ldquo;QuizAI&amp;rdquo;，相关产品可智能识别手写体试卷，提供批改及&amp;ldquo;举一反三&amp;rdquo;等互动学习功能，实现个性化的&amp;ldquo;因材施教&amp;rdquo;。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;&lt;img width="453" src="https://image.jiqizhixin.com/uploads/editor/88b11d4d-6690-4921-8ef8-edc5bb60becd/1768357688404.png" alt="descript" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;color:#7F7F7F;'&gt;图说：&amp;ldquo;蜜蜂试卷&amp;rdquo;举一反三功能演示&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;在健康领域，合合信息推出AI饮食健康助手Appediet，用户通过拍照即可识别食物营养成分，生成热量报告。此外，Appediet还可结合用户健康数据定制饮食计划，并提供个性化营养分析报告、健康食谱推荐、定制饮食计划等服务，打造&amp;ldquo;人人可用的&amp;nbsp;AI&amp;nbsp;随身营养师&amp;rdquo;。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;u&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;&lt;img width="453" src="https://image.jiqizhixin.com/uploads/editor/6e9e22e8-7f7f-421b-9cee-bf98c8f5309a/1768357688408.jpeg" alt="descript" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:center;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;color:#7F7F7F;'&gt;图说：Appediet拍照识别食物营养成分&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;AI Infra&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;、Agentic AI产品重塑数据处理流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;text-align:justify;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;在企业级市场，Agent智能体的规模化落地正将AI Infra推至重要位置，高质量数据成为AI Infra&amp;nbsp;发挥效能的关键。据国际数据公司IDC预测，到2028年全球数据量将增长至393.8ZB，2023至2028年期间复合年均增长率达24.4%。目前，企业数据仍以碎片化、杂格式的形态沉淀在各类业务系统中，既拉低了模型训练效果，也限制了智能应用的落地深度。合合信息旗下智能文本处理企业级AI产品线TextIn发布了AI Infra&amp;nbsp;产品xParse，以AI赋能通用文档非结构化数据挖掘，释放数据价值，在知识库与Agent&amp;nbsp;落地、智能翻译、合规风险管理等场景中具备广阔的应用前景。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;AI&amp;nbsp;&lt;/span&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;与业务的深度融合是企业级智能体落地的方向。麦肯锡11月发布的2025年AI报告《The state of AI in 2025》提到，62%的受访组织（企业）已经在试验智能体类应用。TextIn打造了Agentic AI产品INTSIG Docflow，让产品能够像&amp;ldquo;数字员工&amp;rdquo;一样，对合同、票据、报表、招投标文件等高复杂度、非结构化文档进行解析、分类、抽取、审核、比对及跨系统业务流转，让AI深度作用于企业核心业务流程优化。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;AI&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style='font-size:17px;font-family:"微软雅黑",sans-serif;'&gt;原生应用&amp;ldquo;一句话&amp;rdquo;开启商业数据智能新时代&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;本次发布过程中，面向商业数据智能分析领域，合合信息旗下启信慧眼推出了多项AI原生应用，让可信、可靠的数据真正作用于企业风险管控、营销与智能决策。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;例如，&amp;ldquo;AI智能寻源&amp;rdquo;功能用AI自动拆解寻源品类的结构化参数，过滤信息杂质，让客户实现&amp;ldquo;一句话从3.4亿家企业中，找到合作目标&amp;rdquo;的便利，在具体使用场景中，帮助客户寻源拓客效率平均提升超过30%；&amp;ldquo;AI准入尽调&amp;rdquo;功能将行业&amp;ldquo;Know-How&amp;rdquo;与全盘数据相结合，给出&amp;ldquo;靠谱&amp;rdquo;的供应商合作建议；&amp;ldquo;AI关系洞察&amp;rdquo;功能用AI透视隐形风险，智能锁定关键风险，降低决策门槛及业务风险。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;据悉，启信慧眼AI原生应用功能已在制造、医药、半导体、电子、能源、汽车、金融等多个行业中应用，日均风险扫描次数超过2000万次。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;span style='font-family:"微软雅黑",sans-serif;'&gt;未来，AI技术正向着多模态融合、Agent 智能体规模化的方向加速突破。合合信息将持续深耕AI领域，推进多模态文本智能技术研发工作，不断拓宽技术的应用边界，探索AI应用落地的新机遇、商业化增长的新路径。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-top:3.0pt;margin-right:0cm;margin-bottom:3.0pt;margin-left:0cm;font-size:15px;font-family:minorHAnsi;color:#333333;"&gt;&lt;br&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>500万次围观，1X把「世界模型」真正用在了机器人NEO身上</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 10:21:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2ca205b5-ae1a-4076-816f-d2a6662ac99e/1768357071298.png" style="width: 700%;" class="fr-fic fr-dib"&gt;还记得那个穿着「Lululemon」紧身衣、主打温柔陪伴的&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650998749&amp;idx=1&amp;sn=614264e1d1fefcf5aa9064932a79c60c&amp;scene=21#wechat_redirect" target="_blank"&gt;家用人形机器人 NEO&lt;/a&gt; 吗？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsatpLSPbFMFhk1mPymfGavtaXQuF13ict3WO3icUAyVK0jKyTAythhryzg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5370370370370371" data-type="png" data-w="1080" data-width="1080" data-height="580" data-imgfileid="503528121" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5ad2d686-a48d-4e0d-8ab6-37c71a4477ca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="5"&gt;上次聊到它时，大家还在吐槽其「远程操控」的隐私安全问题，调侃每个机器人的背后可能都是一个「印度小哥」。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;昨天，1X 公司带着它的全新「大脑」亮相：&lt;strong&gt;1X World Model&lt;/strong&gt;。这一次，NEO 似乎准备把「背后的操作员」给解放了。&lt;a href="https://mp.weixin.qq.com/s/xFODYAk17WiRBp6eGAvRAw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/37768424-3a57-4d30-9a44-a106dd3f9f50/1768357095646.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;简单来说，现在的 NEO 不再只是死记硬背动作，它学会了像人一样「想象」。通过观看海量的网络视频和人类第一视角的实操录像，它理解了物理世界是如何运作的：东西掉了会下落，门是可以推开的。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;他们把类似 Sora 的视频生成技术装进了 NEO 的脑子里，接到指令时，它会先在脑海里生成一段「自己成功完成任务」的视频，然后倒推身体该怎么动，才能把这段想象变成现实。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;不过，官方博客中也表示，有时候会出现「脑子学会了，手没学会」的情况：脑补出的视频很完美，但实际动作可能会抓空。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaf7a9oUFeR0CEuYKFmOYuWxoHOCZLvAibsM2eu3fRwwrAuWmeYicS3EJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5131428571428571" data-type="png" data-w="875" data-width="875" data-height="449" data-imgfileid="503528122" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/de697d30-2f65-45ec-be50-1ad198edc117/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="11"&gt;那么这一次是「瑜伽服」下的真功夫，还是只存在于 Demo 里的「剪辑魔法」呢？不管技术落没落地，热度已经先爆表了。到截稿时间，官方推文浏览量已突破 500 万。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicITJN4FJYabK6gOKndKpt006gbgLSvL4KYRrMAiaYr9oGHpbas77Zr7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0608108108108107" data-s="300,640" data-type="png" data-w="740" type="block" data-imgfileid="503528182" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/eb5b879a-0143-40e0-8da5-74ed129cbd88/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;看来，在经历了 AI 时代各式各样炫酷 Demo 的轮番轰炸之后，大家还是忍不住想看看：这一回，它是真长脑子了吗？&lt;/p&gt;&lt;p data-path-to-node="13"&gt;以下是 1X 技术团队对这颗「新大脑」的硬核拆解：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaq8Rsh8BzlibYAU8eJs157EEnpZq89wwVT4GLReYrFNibPzpzjQGAwnqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528123" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/bebd967b-78aa-4a57-8904-08792475dfe2/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="14"&gt;家庭机器人要真正走进现实环境，必须具备常识性的行为能力以及对物理世界的深刻理解。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;当前许多机器人基础模型采用的是 VLA 范式：即在一个预训练的 VLM 之上，增加一个用于预测机器人动作的输出头（例如 PI0.6、Helix、Groot N1.5）。VLM 能够从互联网规模的数据中学习到丰富的知识，但其训练目标更侧重于视觉与语义理解，而非对物理动态过程的预测。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;因此，即便是对人类而言非常简单的任务，模型往往也需要数万小时、成本高昂的机器人数据才能学会完成。此外，为了进一步强化模型对物理交互中空间关系的理解，研究者通常还需要引入各种辅助训练目标（如 MolmoAct、Gemini-Robotics 1.5）。&lt;/p&gt;&lt;p data-path-to-node="17"&gt;在这篇博客中，1X 介绍了&lt;strong&gt;基于视频预训练的世界模型&amp;mdash;&amp;mdash;1XWM&lt;/strong&gt;，并将其集成进 NEO 机器人作为其控制策略。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;与 VLA 模型直接从静态的图像-语言输入中预测动作轨迹不同，世界模型驱动策略是通过文本条件下的视频生成来推导机器人应采取的动作。&lt;strong&gt;借助互联网规模视频中蕴含的真实世界动力学规律，该世界模型能够在无需大规模机器人数据预训练&lt;/strong&gt;、也不依赖任何相关的遥操作演示的情况下，即可泛化到全新的物体、运动方式和任务场景。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;这标志着机器人智能范式的一次转变：机器人开始直接受益于视频预训练规模化带来的能力跃迁，而这一切得以实现，离不开一整套为高保真人类具身到机器人具身迁移而设计的硬件系统支持。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsas2yRupVm3tXjHzYhRH61JZGfCGAgYicD1iaMTKVRsblZzWLQY7YrfKpw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.471875" data-type="gif" data-w="640" data-width="856" data-height="404" data-imgfileid="503528126" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e0845a64-4ac4-436a-9fec-4b2f3accf32f/640.gif" data-order="0" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;&lt;strong&gt;从视频知识到世界模型&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;如今，诸如 Veo 和 Sora 等前沿文生视频模型已经能够生成极其逼真的视频内容。然而，这些模型在零样本生成场景下并未与机器人具身形态对齐，因而在控制任务所需的多个关键维度上往往存在不足，表现在以下几个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="22,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="22,0,0"&gt;视觉/空间层面&lt;/b&gt;：生成的视频是否与机器人的相机内参和自我中心视角一致？是否能够准确保留操控任务所需的深度信息以及精确的空间关系？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="22,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="22,1,0"&gt;运动学层面&lt;/b&gt;：生成视频中的机器人动作是否在该具身形态下可实现，是否遵循其结构特性、关节极限、速度约束以及执行器能力？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="22,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="22,2,0"&gt;物理层面&lt;/b&gt;：生成过程是否避免了物理上不可能的结果（例如物体瞬移），从而保证其能够转化为现实世界中的成功执行？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="23"&gt;原始视频能够提供看起来会发生什么，但并未给出如何去做。为了将视频知识转化为真正可用于控制的世界模型，1X 借助自身的端到端系统架构，采用了一种两阶段的对齐过程，思路与 DreamGen、UniPi 等已有工作一脉相承：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,0,0"&gt;世界模型主干&lt;/b&gt;：这是一个文本条件扩散模型：先在互联网规模的视频数据上进行预训练，随后在人类第一视角视频数据上进行中期训练，并最终在 NEO 专属的传感器-运动日志上进行微调。该模型能够高保真地预测场景随时间演化的过程，在视觉、空间和物理一致性方面表现出色。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,1,0"&gt;逆动力学模型（Inverse Dynamics Model, IDM）&lt;/b&gt;：通过训练 IDM，将像素空间与执行器控制连接起来，使其能够预测在生成帧之间完成状态转移所需的精确动作序列。同时利用 IDM 的评估指标和拒绝采样机制，对生成结果施加运动学约束，从而确保动作在具身层面上的可行性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;在推理阶段，系统接收一个文本指令和一帧初始画面：世界模型负责生成符合意图的未来场景演化，逆动力学模型从中提取所需的动作轨迹，最终由机器人在现实世界中执行该动作序列。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsaMhBkAehic28chZuNGv2w5yWf04AU57HzQwR0tBsf9L2J2Sg7LJRic5Vw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.601113172541744" data-type="gif" data-w="1078" data-width="1308" data-height="786" data-imgfileid="503528127" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/af6d2e10-ff22-4b21-a7ef-95f5f24abd07/640.gif" data-order="1" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="26"&gt;&lt;strong&gt;1XWM 的训练与推理流程&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;1XWM 的主干模型基于一个 140 亿参数的生成式视频模型。为了使该模型适配 NEO 的具身形态，1X 还采用了一种多阶段训练策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="28,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,0,0"&gt;第一视角中期训练&lt;/b&gt;：使用 900 小时的人类第一视角视频数据进行训练，使模型对第一人称的操作任务产生对齐。在这一阶段，模型能够学习到通用的操作行为模式，但仍然难以生成由 NEO 执行具体任务的视频。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="28,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,1,0"&gt;具身微调&lt;/b&gt;：随后，使用 70 小时的机器人数据进行微调，使模型进一步适配 NEO 的视觉外观与运动学特性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="29"&gt;以 DALL&amp;middot;E 3 等工作为例，已有研究表明，通过使用更具描述性的视觉文本标注进行训练，可以显著提升视觉基础模型对提示词的遵循能力。然而，许多第一视角数据集仅包含简要的任务描述。为此，1X 利用一个 VLM 生成更加详细的描述性字幕，并通过字幕上采样的方式将其用于训练。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;此外，IDM 在 400 小时未经过滤的机器人数据上进行训练，其中既包括随机探索数据，也包含与任何具体任务无关的运动轨迹。这使得模型能够在任意状态下对 NEO 的运动进行准确追踪。&lt;/p&gt;&lt;p data-path-to-node="31"&gt;在测试阶段，系统接收一帧初始画面以及一条指导 NEO 执行动作的文本指令。1XWM 负责生成未来的视频序列，随后由 IDM 从生成视频中提取对应的机器人动作轨迹，并将其直接下发至机器人执行。为保证轨迹的平滑性，IDM 的输出会在多个初始噪声样本和滑动窗口维度上进行时间平均处理。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="762" data-imgfileid="503528128" data-ratio="0.8581081081081081" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaib3yZY9Ac0QOfp2hn9lDibeE4CdK1RV5jsW1cVT1ArwkE7Sl3osla8EA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="888" data-width="888" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6d2d90f7-ac16-44cb-acce-63667c5fff69/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="32"&gt;&lt;sup&gt;NEO 后训练数据集主要包含高质量的抓取和放置数据（98.5%），这些数据经过筛选，仅包含桌面操作且手部可见的场景。通过利用基础视频模型的网络级预训练，1XWM 模型可以泛化到各种未曾见过的物体、环境和任务。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;1XWM 到底能做啥&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;研究团队进一步评估了 1XWM 在任务泛化方面的能力，重点关注其是否能够完成 NEO 从未经历过的任务，以及生成视频与真实机器人执行之间的一致性程度。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;在实验中，搭载 1XWM 的 NEO 被用于执行多种超出既有经验的任务，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="36,0,0"&gt;抓取分布内与分布外的物体；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="36,1,0"&gt;操作此前从未见过、但具备复杂可供性的物体；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="36,2,0"&gt;完成需要全新动作模式的全新任务。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="37"&gt;实验结果显示，1XWM 生成的视频与真实世界中的执行过程整体高度一致。将模型生成的视频与机器人实际完成任务后拍摄的视频进行并排对比，可以发现二者在视觉表现上非常接近。这表明，1XWM 在空间结构理解、运动学约束建模以及物理一致性等方面已经具备较强能力。&lt;/p&gt;&lt;p data-path-to-node="38"&gt;&lt;b data-index-in-node="0" data-path-to-node="38"&gt;抓取：&lt;/b&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsafY224WBthhF7ib31QibGcA1tFgElWcX5dc6273YSjnOq2o7YNLwpmGXA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.4638888888888889" data-type="gif" data-w="1080" data-width="1940" data-height="900" data-imgfileid="503528130" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/e5cb3ca5-442b-4b2f-a0f2-7412febd73c1/640.gif" data-order="2" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="40"&gt;&lt;b data-index-in-node="0" data-path-to-node="40"&gt;新动作：清洁&lt;/b&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsa22x4nb6hjMJTejzGHEcwgD4YaadFAzsnocadLNeOMBUtJkOcxRozmQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.45597775718257644" data-type="gif" data-w="1079" data-width="1969" data-height="898" data-imgfileid="503528135" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/f1f201de-9aac-4c0d-a449-b2a71610f28f/640.gif" data-order="3" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="41"&gt;接下来，1X 尝试需要双手协调和人机交互的任务。这些能力并未包含在训练数据集中。这表明此类知识来源于视频预训练和以第一人称视角进行的人机交互训练。由于 NEO 的身体结构与人类非常相似，因此从人类视频数据中学习到的功能可以直接迁移应用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYYnDJJkJKh7NDwtc0YFt5eYa2GzkqfuW56GFbWGAbkVHJW0kiaYmorg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-ratio="0.45918367346938777" data-type="gif" data-w="1078" data-width="1962" data-height="901" data-imgfileid="503528131" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/43436d0f-edf7-4d4a-9cdc-ccd913d74eac/640.gif" data-order="4" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsaSQ288DgkjS2iby24QasMBgIXiawOGc8IicK3plibqe5ocqhodrto48w1CQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.48148148148148145" data-type="gif" data-w="1080" data-width="1960" data-height="944" data-imgfileid="503528132" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/6d648529-e593-4d86-b9e1-0df382800019/640.gif" data-order="5" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="42"&gt;研究团队还通过系统性的实物实验评估了 1XWM 在分布内（ID）与分布外（OOD）任务上的表现。每类任务均重复执行 30 次。结果显示，1XWM 在多种动作原语上都保持了稳定的成功率，不过部分对精细操作要求较高的任务（例如倒液体、绘图等）仍然具有一定挑战性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaQVdr2nABydOqc8NFARHQC6qAxPCiaLHflKEaDBbVI00Y2DtzCxv7Pbw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.7564814814814815" data-type="png" data-w="1080" data-width="1110" data-height="840" data-imgfileid="503528129" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/2074235c-49ce-43c7-86ed-f223825b8404/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="43"&gt;&lt;strong&gt;能否将视频质量与任务成功率联系起来？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="44"&gt;如果可以，就能使用视觉指标来衡量和改进视频质量，并估计实际任务成功的可能性。&lt;/p&gt;&lt;p data-path-to-node="45"&gt;有时，生成的视频是否可能成功一目了然。例如，向 1XWM 模型输入拉取纸巾指令，有时会生成 NEO 机器人拿起纸巾盒而不是拉取纸巾的视频。执行这些错误生成的视频时，成功率几乎为 0%。&lt;/p&gt;&lt;p data-path-to-node="46"&gt;1X 团队注意到像测试时计算这样的方法可以提高任务成功率。受此启发，他们尝试并行生成多个视频，并执行其中质量最好的一个。这个选择过程可以手动完成，但也可以使用 VLM 评估器进行自动化。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaPbzzTlESRQWNhS2tMqc0fSglRFyomKKf2NhMicasSDtrRicGoKYqyfdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.4975417895771878" data-type="png" data-w="1017" data-width="1017" data-height="506" data-imgfileid="503528133" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/ac78d71a-cead-4263-b3ed-8e1a5dea1eea/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="47"&gt;&lt;strong&gt;第一视角数据与高质量字幕的重要性&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="48"&gt;基于此前假设：生成视频的质量与任务成功率之间存在相关性，研究团队对若干训练选择进行了视觉层面的消融分析，重点考察了字幕上采样以及第一视角人类数据训练这两项因素的影响。&lt;/p&gt;&lt;p data-path-to-node="49"&gt;实验共使用了三个评测数据集，每个数据集均包含 500 组起始图像&amp;ndash;提示词对：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="50,0,0"&gt;分布内数据集：包含与机器人训练数据分布一致的复杂任务和场景，主要是杂乱环境中、物体位置较为困难的抓取与放置任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="50,1,0"&gt;新任务数据集：由一组全新的任务构成，例如搅拌碗、抽纸、相对尺寸判断（选择更大的物体）、双手协同操作等，数据采集于真实世界中的简单背景场景。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="50,2,0"&gt;分布外 T2I（OOD T2I）数据集：完全由抓取任务组成，其初始帧由文生图模型生成，随机采样分布外的家庭物体与背景场景。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="51"&gt;下面是新任务数据示例：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicFZCBCia2pic36dtxra88bsazTYicyQF0bJNVg1hmKwkG61ewIqIZwSib10nNE902O03WzzLRl8g3x2A/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-ratio="0.98125" data-type="gif" data-w="640" data-width="1031" data-height="1012" data-imgfileid="503528136" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/f1fe4ef0-d2d4-4dc1-93d9-72e8b73f2e9f/640.gif" data-order="6" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="52"&gt;团队还要求人工标注员审查每个生成的视频，并根据物理合理性、任务完成情况以及与 NEO 的形态和能力的一致性来决定接受或拒绝该视频。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsacAUthpib2lSZjeCp9wrkDRqRydmpUXC4HXkzYg4dKBPQznhYh8UwxKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.9635258358662614" data-type="png" data-w="987" data-width="987" data-height="951" data-imgfileid="503528134" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/bdcad60d-e62e-4270-9687-149f30e01b82/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="53"&gt;字幕上采样在所有评测数据集上都能提升视频生成质量，因为更细致的字幕与视频模型预训练时的文本条件更加匹配，也能更清晰地引导具体动作生成。&lt;/p&gt;&lt;p data-path-to-node="54"&gt;引入第一视角人类数据则显著提升了新任务和分布外场景下的生成质量，说明这类数据为操作任务提供了可迁移的通用先验，且与 NEO 的类人具身高度契合。&lt;/p&gt;&lt;p data-path-to-node="55"&gt;不过，在已有大量 NEO 数据覆盖的分布内任务上，额外加入第一视角数据可能会稀释后训练数据分布，对效果提升有限，甚至略有负面影响。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaboLTUMOAHxQFQBNV3xaLhBbG25CaNLxfdrQfPPxFQqFqDXNWATEKog/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.9522388059701492" data-type="png" data-w="1005" data-width="1005" data-height="957" data-imgfileid="503528137" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/d3683309-b9b9-46e9-9344-2529cb08d941/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="56"&gt;&lt;sup&gt;参考链接：https://www.1x.tech/discover/world-model-self-learning&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>跳出「黑盒」，人大刘勇团队最新大语言模型理论与机理综述</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 10:15:03 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/fcad1371-16af-44c3-ba7e-77b0e1e3b8c4/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大语言模型（LLMs）的爆发式增长引领了人工智能领域的范式转移，取得了巨大的工程成功。然而，一个关键的悖论依然存在：尽管 LLMs 在实践中表现卓越，但其理论研究仍处于起步阶段，导致这些系统在很大程度上被视为难以捉摸的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;黑盒」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;为了打破这一僵局，中国人民大学的研究者们采用了一种统一的基于生命周期的分类法，将 LLM 理论研究整合为六个阶段：数据准备、模型准备、训练、对齐、推理和评估。&lt;/p&gt;&lt;p&gt;本文系统综述了驱动 LLM 性能的底层理论与机制，深入分析了数据混合的数学依据、不同架构的表示极限以及对齐算法的优化动力学，并指出了合成数据自我提升、安全保证数学边界等前沿挑战。本综述旨在为 LLM 发展从工程启发式方法向严谨科学学科的转型提供结构化路线图。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528001" data-ratio="0.4101851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYqTX4hmbt5zlBSnkz24BJG7c8z8ttRMia5YQicTGmguA7Dwbbq0Rckcw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1de12a9e-107d-4b6b-833e-0564a13fe841/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Beyond the Black Box: Theory and Mechanism of Large Language Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2601.02907&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，ChatGPT、DeepSeek、Llama、Claude 等模型的涌现标志着 AI 领域的深刻变革。随着系统规模的扩大，LLMs 展现出类似人类推理的行为，正改变着人类与信息交互的方式。然而，正如核物理的发展经历了从爱因斯坦的质能方程到原子弹爆炸的 40 年跨度，AI 领域的理论与应用同步也存在显著滞后。&lt;/p&gt;&lt;p&gt;尽管工程上取得了巨大成功，LLM 的理论理解仍面临两大挑战：一是规模带来的前所未有的数学复杂度；二是模型展现出的诸多「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;涌现」现象（如幻觉、涌现能力、Scaling Laws 等）难以在统一框架下解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;为了解决研究碎片化的问题，来自&lt;strong&gt;中国人民大学高瓴人工智能学院&lt;/strong&gt;的研究团队发布了最新综述论文 《Beyond the Black Box: Theory and Mechanism of Large Language Models》。本文不仅是一份文献索引，更是一份试图将 LLM 研究从 「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;工程启发式」推向「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;严谨科学」的路线图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;本综述提出了涵盖六大阶段的生命周期路线图。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528022" data-ratio="0.42592592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkARHFgibQFgkMWGO8GofIh3R98Grh5ib6zMwicDNRtm6Sk5SActLYNaRiaNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/42f8b15b-df44-4b02-bd3b-43e99ce14f31/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 1: 大语言模型理论与机制路线图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;LLM 理论与机制的六大阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据准备阶段 (Data Preparation)&lt;/strong&gt;：探讨如何保证更好的数据利用率，并量化数据特征对模型最终能力的影响，分析数据混合策略 (Data Mixture)、去重与过滤机制以及记忆 (Memorization) 与模型能力之间的关系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型准备阶段 (Model Preparation)&lt;/strong&gt;：从理论上评估架构能力，理解 Transformer 结构的表示能力极限、优化景观（如「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;河谷」假设）以及从展开优化视角设计新架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练阶段 (Training)&lt;/strong&gt;：研究简单的学习目标如何锻造出复杂的涌现能力，分析 Scaling Laws 的本质、预训练的获益机制以及参数高效微调（PEFT，如 LoRA）的机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对齐阶段 (Alignment)&lt;/strong&gt;：探讨鲁棒对齐是否在数学上可实现，分析 RLHF（的动力学，研究「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;超级对齐」（Superalignment）与「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;弱到强泛化」 (Weak-to-Strong Generalization)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理阶段 (Inference)&lt;/strong&gt;：解密冻结权重的模型如何在测试时模拟学习与算法执行，分析提示工程 (Prompt Engineering)、上下文学习 (In-Context Learning) 的机制以及推理时扩展 (Inference-Time Scaling) 带来的推理能力提升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;评估阶段 (Evaluation)&lt;/strong&gt;：从理论上定义与衡量复杂的、主观的人类价值观，探讨基准测试的有效性、LLM-as-a-Judge 的可靠性以及安全性与透明度的形式化保证。&lt;/p&gt;&lt;p&gt;各个阶段代表性的研究内容如下所述。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1 数据准备阶段：智能的基础&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528023" data-ratio="0.5305555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVRv5OkJcmuvXfaPduNl6kpBVsUwz2fhHFzVdjskkJbbsjgpQV65IAQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5b9c431e-ba85-415b-ba2e-63250e25f909/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 2: 数据准备阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;数据准备不仅仅是工程上的设计，而是决定模型能力的基石。研究者们从三个维度剖析了数据的理论机制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据混合的数学逻辑&lt;/strong&gt;：研究者利用多源学习视角，证明了当多任务结构共享时，泛化界限不再取决于模型海量的原始参数，而是取决于总压缩编码长度。通过引入「数据混合定律」（Data Mixing Laws），小规模实验拟合验证损失函数，实现对大规模混合策略性能的预先计算。最终，研究者们使用各种不同的理论框架，动态寻找最优数据混合权重的前沿方法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;去重与过滤的理论保障&lt;/strong&gt;：实证研究确认了去重能直接减少不必要的记忆，从而降低隐私风险。各种理论框架证明了高质量、高信息密度的网页数据甚至能超越人工精选语料。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;记忆机制的量化分析&lt;/strong&gt;：模型对数据的记忆并非简单的「死记硬背」。理解这种记忆机制是平衡知识获取与隐私保护的关键。研究者们认为模型通过整合模糊重复序列形成复杂记忆，也揭示了熵与记忆之间的相关性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，这一阶段也存在着重要的前沿开放问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;合成数据与自主进化&lt;/strong&gt;：合成数据能否为模型带来理论上的性能提升？模型是否能够通过生成合成数据从而实现自主进化？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据污染&lt;/strong&gt;：训练与测试数据的泄漏为 LLM 的隐私问题带来了挑战，能否从理论上规避或者缓解这一问题？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2 模型准备阶段：架构的表示极限&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528024" data-ratio="0.5222222222222223" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8Fz5ibfwBpfhF8PqU3NPmwAJI05zqnDMVK9rzJh8qTypdibagHvorINA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/330195d7-19e2-4814-b21a-5899d9d61c59/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 3: 模型准备阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;选择何种模型架构不仅关乎效率，更决定了信息的表示上限。研究者们通过以下视角探讨了架构的本质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;表示能力的边界&lt;/strong&gt;：研究者们探讨了 Transformer 作为通用逼近器的数学证明，并分析了在无限精度下 Transformer 的图灵完备性。通过电路复杂度（Circuit Complexity）理论，研究者分析了 Transformer 等架构在处理层级结构语言时的表达上限与下限，揭示了模型宽度如何成为函数组合能力的通信瓶颈。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;优化景观的几何特性&lt;/strong&gt;：研究者们提出了诸如「河谷（River Valley）模型」等假设，解释了 Warmup-Stable-Decay 类学习率调度如何引导参数在复杂的函数空间中跨越「山坡」并在「河床」方向高效前进。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;理论驱动的架构设计&lt;/strong&gt;：从「展开优化（Unrolled Optimization）」和「测试时训练（TTT）」的视角，研究者将网络层等效为优化算法的迭代步骤，为理解前沿的模型架构提供了统一框架。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除此之外，研究者们也在关注模型架构的演进，并从理论视角对新架构进行设计与分析：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;线性注意力模型&lt;/strong&gt;：线性递归模型在提升效率的同时，是否存在无法逾越的表示瓶颈（如关联回想能力的缺失）？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;循环模型与隐式推理&lt;/strong&gt;：权重共享的循环架构是否能通过增加推断深度，在更少的参数量下实现更强的泛化？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3 训练阶段：模型能力的锻造炉&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528025" data-ratio="0.5175925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAnIIoVWtAGibmPdST5yPqpKup4hllCYaic5w7zIFA35LmyN09icwhLKVcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/589c5a18-4c2c-4adc-9b69-2d1ff28cf0ab/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 4: 训练阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;训练阶段将静态架构转化为具备智能的实体。研究者们对预训练和微调的机制进行了深入解构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;预训练的收益机制&lt;/strong&gt;：研究者论证了预训练本质上是学习数据的底层上下文结构，并提出了「压缩即智能」的观点，认为语言模型的目标是实现对海量数据的无损压缩。从信息论视角出发，论证了 LLM 作为强大的无损压缩器，其压缩效率与下游任务性能之间存在强线性关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Scaling Laws 的本质&lt;/strong&gt;：通过对计算、数据和参数规模的幂律关系分析，研究者探讨了能力「涌现」背后的连续性过程，并分析了流形假设下内在维度如何决定缩放指数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;微调的数学保障&lt;/strong&gt;：针对 LoRA 等 PEFT 技术，研究者分析了其在低秩子空间中的优化动力学，证明了低秩适配器在对齐预训练特征梯度方面的有效性，并揭示了权重初始化（如 A 随机、B 置零）对收敛稳定性的关键影响。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，这一阶段也存在着优化层面的前沿探索：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;超参数迁移&lt;/strong&gt;：如何实现在小规模模型上寻找的最优超参数，能够「零样本」地直接应用于万亿级模型？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;优化算法的演进&lt;/strong&gt;：除了 Adam 等一阶优化器，矩阵敏感型优化器（如 Muon）如何利用 Hessian 结构的块对角特性加速收敛？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;4 对齐阶段：安全与价值的数学边界&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528027" data-ratio="0.5212962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAXJvycGnbBgvJlzFgaLFSk9Ve5aG6QT1iaiaGX84EgsNGlpGFgpxkQKQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3ac70102-6f95-40a1-bc36-8d26823f78a5/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;图表 5: 对齐阶段的理论概览。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对齐不仅是指令遵循，更是人类价值观的注入。研究者们从安全性与动力学视角进行了审视：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;对齐的理论基础&lt;/strong&gt;：研究者分析了安全对齐的数学边界，探讨了现有对齐方法是否只是「浅层防御」，以及对齐后的模型是否存在回复原始分布的「弹性」。研究者认为只要有害行为的概率不被完全消除，通过对抗性提示触发违规行为在数学上是不可避免的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;弱到强泛化（W2SG）&lt;/strong&gt;：在超智能时代，弱监督者如何可靠地控制强受训者？研究者从偏差 - 方差分解等视角，分析了强模型纠正弱信号错误的机制，并界定了泛化增益。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;强化学习的作用&lt;/strong&gt;：研究者探讨了 RL 是激活了预训练中的潜在模式（如代码能力、数学推理能力），还是通过长期的策略复位真正扩张了推理边界。同时量化了对齐与预训练知识保持之间的权衡，并从变分信息瓶颈视角提出了缓解「Reward Hacking」的方法。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，对齐阶段还面临着深层次的开放挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练与对齐的关系&lt;/strong&gt;：SFT 和 RL 在塑造模型行为上有何本质区别？为什么 RL 在泛化性上通常优于简单的行为克隆？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;RL 的前沿疆界&lt;/strong&gt;：在缺乏验证器的开放领域，如何设计高效的奖励信号？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;5 推理阶段：解密静态模型的前向过程&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528029" data-ratio="0.5203703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMh6lNNOaVvLJibh5KDOicZqRic5oMoxctGyiaWNfVLPFibbgRfRcJvia1uVw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3518a42f-7090-4137-8eed-25f18b8839d3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 6: 推理阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;推理是释放模型潜力的关键环节。研究者们解密了大模型推理中的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;思维」过程：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;提示工程与机制分析&lt;/strong&gt;：研究者从任务重参数化角度理解 Prompt，利用 Token 分布动力学和归纳头（Induction Heads）机制，剖析了 Prompt 如何引导模型内部的信息路由。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;上下文学习（ICL）的机制&lt;/strong&gt;：研究者对比了「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;算法执行」与「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;任务定位」两种观点，探讨了 Transformer 是否在推断时隐式地运行了优化算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;推理时扩展（Inference-Time Scaling）&lt;/strong&gt;：研究者分析了 CoT 如何作为模型的 「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;深度扩展器」，证明思维链能显著提升 Transformer 的计算复杂度上限，并探讨了搜索算法如何通过外部计算换取推理质量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，推理阶段也暴露了一些特殊的理论现象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;过度思考（Overthinking）&lt;/strong&gt;：在推理时投入更多计算资源是否总是正向的？模型为何会在简单问题上陷入冗余推理？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;隐式推理（Latent Reasoning）&lt;/strong&gt;：模型能否在不输出显式 Token 的情况下，直接在隐空间中完成多路径的思维并行？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;6 评估阶段：从基准测试到形式化保证&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528030" data-ratio="0.5120370370370371" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkABFOic2spzHLCebEvtZYY94brBtoHtRCyON4TDbQTJw7nFT4zAbCOmLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ae580a0b-3e07-470f-9a56-15d70e9dcf7d/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图表 7: 评估阶段的理论概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;评估是大模型进步的标准，但当前的评估手段正面临严峻挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基准测试理论&lt;/strong&gt;：研究者利用不同的理论框架分析了传统基准测试的饱和问题与捷径学习现象，并剖析了「LLM-as-a-Judge」模式中的系统性偏见。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;安全性与透明度&lt;/strong&gt;：研究者深入探讨了可解释性（如 Sparse Autoencoders），对模型内部特征进行解构，并利用计算不可解性证明了在任何可计算的 LLM 中，幻觉都是不可消除的理论必然。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;抗误用机制&lt;/strong&gt;：研究者通过水印（Watermarking）等技术，探讨了识别 AI 生成内容与保持文本质量之间的理论权衡。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，评估阶段也催生了关于模型内部表示的深刻讨论：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;线性表示假设&lt;/strong&gt;：语义概念（如真实性）在模型潜空间中是否真的以线性方向编码？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;推理失效模式&lt;/strong&gt;：如「逆转诅咒（Reversal Curse）」和「位置偏差（Lost-in-the-Middle）」，这些失败案例揭示了自回归模型在逻辑对称性上的本质缺陷。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;结语：迈向 AGI 的未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管我们已经迈出了从经验迈向科学的第一步，但随着 LLM 的不断发展，更多的前沿理论问题依然亟待解决。正如爱因斯坦所言：「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;科学的伟大目标是用最少数量的假设或公理推导出最大数量的经验事实。&lt;/span&gt;」我们希望为社区提供一份结构化的 LLM 理论研究路线图，共同揭开黑盒背后的真理。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;刘勇&lt;/strong&gt;，中国人民大学，长聘副教授，博士生导师，国家级高层次青年人才。长期从事机器学习基础理论研究，共发表论文 100 余篇，其中以第一作者 / 通讯作者发表顶级期刊和会议论文近 50 篇，涵盖机器学习领域顶级期刊 JMLR、IEEE TPAMI、Artificial Intelligence 和顶级会议 ICML、NeurIPS 等。获中国人民大学「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;杰出学者」、中国科学院「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;青年创新促进会」成员、中国科学院信息工程研究所「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;引进优青」等称号。主持国家自然科学面上 / 基金青年、北京市面上项目、中科院基础前沿科学研究计划、腾讯犀牛鸟基金、CCF - 华为胡杨林基金等项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;甘泽宇&lt;/strong&gt;，中国人民大学高瓴人工智能学院博士研究生，本科及硕士研究生毕业于中国人民大学信息学院。当前主要研究方向包括大模型机理分析。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>百川开源全球最强医疗大模型M3，「严肃问诊」定义AI医疗新能力</title>
      <description>&lt;![CDATA[多指标性能更强大、幻觉率更低的医疗大模型]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 09:26:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;昨天，百川智能正式开源新一代医疗大模型 Baichuan-M3，其在全球最权威的医疗 AI 评测 HealthBench 中以 65.1 分的综合成绩位列全球第一；在专门考验复杂决策能力的 HealthBench Hard 上，也以 44.4 分的成绩夺冠。&lt;/p&gt;&lt;p&gt;这一成绩，不仅刷新了 HealthBench 的最高分，更首次在医疗领域实现了对 GPT-5.2 的全面超越。在 OpenAI 引以为傲的低幻觉领域，M3 也实现了超越，幻觉率 3.5 全球最低。&lt;/p&gt;&lt;p&gt;此外，M3 还首次具备了原生的 “端到端” 严肃问诊能力。它能像医生一样主动追问、逐层逼近，把关键病史和风险信号问出来，进而在完整的信息上进行深度医学推理。评测显示，其问诊能力显著高于真人医生的平均水平。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Hugging Face 地址：https://huggingface.co/baichuan-inc/Baichuan-M3-235B&lt;/li&gt;&lt;li&gt;GitHub 地址：https://github.com/baichuan-inc/Baichuan-M3-235B&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;医疗沟通和推理能力超越 GPT-5.2，登顶世界第一&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;2025 年 5 月份，OpenAI 发布 HealthBench，由 262 位来自 60 个国家的医生共同构建，收录了 5000 组高度逼真的多轮医疗对话，构建了全球最权威、也最贴近真实临床场景的医疗评测集。这一事件，被视为 OpenAI 在医疗领域开始 “重兵投入”，吹响进军医疗的号角。&lt;/p&gt;&lt;p&gt;相当长一段时间里，无论是 HealthBench 总分还是 HealthBench-Hard 子集， GPT 系列模型从未被超越。2025 年 8 月，百川开源医疗增强大模型 M2 在 HealthBench 上力压 gpt-oss-120B、DeepSeek-R1 等同期所有开源模型，并在 HealthBench Hard 上取得 34.7 分的成绩，仅次于 GPT-5，成为全球唯二突破 32 分的模型。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/af4c0af2-6825-42b4-a119-489baef87e5c/1768353665316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2025 年，强化学习无疑是新一代 Scaling Law 的技术中轴。在 M2 发布后的五个月里，百川智能对强化学习系统进行了全面升级，将原本以患者模拟器和静态 Rubric 为主的半动态反馈，升级为随模型能力不断演进的全动态 Verifier System。随着监督信号持续变细、变难，模型得以不断突破能力上限，使 M3 在复杂医学问题上的表现实现跃迁，不仅在 HealthBench 总分上超越 OpenAI 最新模型 GPT-5.2，也在 HealthBench Hard 上登顶，成为当前全球医疗沟通和推理能力最强的医疗大模型。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;重构幻觉抑制的训练范式，刷新医疗幻觉率底线&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;幻觉是这一代大模型技术范式的通病，更是 AI 进入严肃医疗的拦路虎。在大多数场景幻觉只是体验问题，而在严肃医疗场景可导致安全事件。&lt;/p&gt;&lt;p&gt;降低幻觉，一直是 OpenAI 最重视的研究方向之一。几乎每一代 GPT 模型的幻觉率均为行业最低。OpenAI 也是第一个单独评测医疗能力和提供医疗服务的通用模型公司。&lt;/p&gt;&lt;p&gt;国内 DeepSeek 等模型的普及，让越来越多人开始使用 AI 并尝试进行医疗健康咨询。但大多数模型公司并没有把 “降幻觉” 提升到与推理、代码等相同的高度。用这样的模型获取健康咨询和诊疗建议，对 AI 医疗的普及和医患信任建立带来很大困扰。&lt;/p&gt;&lt;p&gt;百川 M3 将医疗幻觉抑制前移至模型训练阶段，在强化学习过程中将医学事实一致性作为核心训练目标之一，将 “知之为知之，不知为不知” 直接作用于模型自身能力的形成过程。这一新的训练方法将医学事实可靠性内化为 M3 自身的基础能力，使其在不借助任何外部系统的情况下，依然能够基于自身医学知识进行稳定、可信的作答。&lt;/p&gt;&lt;p&gt;通过将事实一致性约束融入训练流程，M3 重构了幻觉抑制的训练范式，在不依赖工具或检索增强的纯模型设置下，医疗幻觉率 3.5，超越 GPT-5.2，达到全球最低水平。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/26310800-527a-4066-a8ff-63241be5aea9/1768353715138.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;h3 style="text-align: center;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;strong&gt;构建「严肃问诊」新能力，端到端问诊超越真人医生&lt;/strong&gt;&lt;/h3&gt;&lt;h3 style="text-align: center;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;p&gt;除了强推理和低幻觉，端到端的问诊能力是本次 M3 最重要的一项突破。2025 年行业的技术共识是，用户提供更完整的上下文，模型才有更好的表现。可在医疗领域，患者很难完整表达自己的病症，需要模型像医生一样有能力把患者的混乱叙述转变成可做诊疗决策的信息。&lt;/p&gt;&lt;p&gt;HealthBench 代表了 OpenAI 对临床场景的认知高度，然而它本质上是一个切片式的评测，考核的更像是 “AI 会不会回答问题”，而不是带着诊疗目标，完整的患者信息收集。这也正说明了行业对问诊重要性和建模思路的理解不足。&lt;/p&gt;&lt;p&gt;应用实践中，通过 prompt “你是一位经验丰富的医生”，激活模型的 “角色扮演” 是更常见的做法。这种方式得到的是模型的表演行为，而非内生能力，激活的是模型应该提问的行为，而不是必须获取关键信息的思考。例如，临床医生面对患者的第一反应，永远是先排除危急重症，再考虑常规诊疗，这是刻在职业本能里的安全优先级。但常见的 “角色扮演” 的问诊方式，无法将 “红旗征识别与处置” 作为核心行动原则。这种不围绕关键风险点展开的信息收集，即便对话看似完整，也难以支撑安全、可靠的临床判断，从根本上偏离了医疗 “安全第一” 的原则。&lt;/p&gt;&lt;p&gt;针对这一行业困境，百川智能提出了 “严肃问诊范式” 与 “SCAN 原则”，通过 Safety Stratification（安全分层）、Clarity Matters（信息澄清）、Association &amp;amp; Inquiry（关联追问）与 Normative Protocol（规范化输出），将临床问诊中高度依赖经验的思维过程，第一次系统性地 “白盒化”。&lt;/p&gt;&lt;p&gt;围绕 SCAN 原则，百川智能借鉴医学教育里长期使用的 OSCE 方法，联合 150 多位一线医生，搭建了 SCAN-bench 评测体系，该体系以真实临床经验作为 “标准答案”，将诊疗过程拆解为病史采集、辅助检查、精准诊断三大阶段，通过动态、多轮的方式进行考核，完整模拟医生从接诊到确诊的全过程。相比于 HealthBench，SCAN-bench 是更加全流程端到端的动态评测新范式。&lt;/p&gt;&lt;p&gt;同时，百川智能还使用原生模型训练方法取代角色扮演 prompt，针对 GRPO 无法稳定进行长对话训练的问题，设计了新的 SPAR 算法，使模型能够在有限对话轮次中，把临床真正需要的关键问题问全、问准，把风险兜住，让输出经得起复核。&lt;/p&gt;&lt;p&gt;在实验过程中发现，问诊准确度每增加 2%，诊疗结果准确度就会增加 1%。评测结果显示，M3 在 SCAN 的四个维度均显著高于人类医生基线水平，并大幅领先于国内外顶尖模型，成功构建了从精准的临床问询、深度医学推理到安全可靠决策的闭环。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f0ee5beb-e7ff-4129-87fe-9ea83c3ad5b4/1768353751451.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;从 1 月初 OpenAI 发布医疗产品 ChatGPT Health，到今天 Anthropic 推出 Claude for Healthcare，AI 医疗正在全球范围内提档加速，竞争也正式进入深水区。在这场竞速中，作为国内唯一专注医疗的大模型企业，百川持续突破低幻觉率、端到端问诊和复杂临床推理等核心能力，已从 “跟随者” 跃迁为行业 “引领者” 与新范式的 “定义者”，正以硬核实力扛起中国 AI 医疗发展的旗帜。&lt;/p&gt;&lt;p&gt;百川智能的医疗应用 “百小应” 已同步接入 M3，面向医生与患者开放相关能力。医生可借助它推演问诊与诊疗思路，患者及家属也可通过该应用更系统地理解诊断、治疗、检查与预后背后的医学逻辑。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
