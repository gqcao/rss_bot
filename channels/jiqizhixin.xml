<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>实测夸克「千问划词快捷指令」，这7个邪修Prompt，建议收藏</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 12:11:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/110f143e-0454-429b-b66b-6597f05f6ef0/1768449877316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;新年第一天，DeepSeek 发布了一篇艰深晦涩的技术论文，不少网友直呼「看不懂」。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"jc":"center","uuid":"mk2gmj7aweyieukbrpn"},["img",{"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5168d798d8b874f4f0f3eb7ebad2f178375b8339e1c4c24833998745b666af745115b5d1153adab25a156a98577f418d5b7c4b67b1ed0eaebdfca5b38285a1f63ec564bff80fdc5574f77387d2e13df021f0ef096c4d55c51?tmpCode=f00bcf97-2b0f-4aad-8d0e-776a3b6d2398","width":746,"height":523.275657336726,"uuid":"mkdfb33mb664v67jyo9","extraData":{"resourceId":"7f12b51b-0f64-4a2f-bbbf-ce8ad418a0e6","metaData":{"size":168183,"originWidth":1179,"originHeight":827,"format":"jpg","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMmpjJTIyJTNBJTIyY2VudGVyJTIyJTJDJTIydXVpZCUyMiUzQSUyMm1rMmdtajdhd2V5aWV1a2JycG4lMjIlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyaW5saW5lJTIyJTJDJTIydHlwZSUyMiUzQSUyMmltYWdlJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnNyYyUyMiUzQSUyMmh0dHBzJTNBJTJGJTJGYWxpZG9jcy5kaW5ndGFsay5jb20lMkZjb3JlJTJGYXBpJTJGcmVzb3VyY2VzJTJGaW1nJTJGNWVlY2RhZjQ4NDYwY2RlNTE2OGQ3OThkOGI4NzRmNGYwZjNlYjdlYmFkMmYxNzgzNzViODMzOWUxYzRjMjQ4MzM5OTg3NDViNjY2YWY3NDUxMTViNWQxMTUzYWRhYjI1YTE1NmE5ODU3N2Y0MThkNWI3YzRiNjdiMWVkMGVhZWJkZmNhNWIzODI4NWExZjYzZWM1NjRiZmY4MGZkYzU1NzRmNzczODdkMmUxM2RmMDIxZjBlZjA5NmM0ZDU1YzUxJTNGdG1wQ29kZSUzRGYwMGJjZjk3LTJiMGYtNGFhZC04ZDBlLTc3NmEzYjZkMjM5OCUyMiUyQyUyMndpZHRoJTIyJTNBNzQ2JTJDJTIyaGVpZ2h0JTIyJTNBNTIzLjI3NTY1NzMzNjcyNiUyQyUyMnV1aWQlMjIlM0ElMjJta2RmYjMzbWI2NjR2NjdqeW85JTIyJTJDJTIyZXh0cmFEYXRhJTIyJTNBJTdCJTIycmVzb3VyY2VJZCUyMiUzQSUyMjdmMTJiNTFiLTBmNjQtNGEyZi1iYmJmLWNlOGFkNDE4YTBlNiUyMiUyQyUyMm1ldGFEYXRhJTIyJTNBJTdCJTIyc2l6ZSUyMiUzQTE2ODE4MyUyQyUyMm9yaWdpbldpZHRoJTIyJTNBMTE3OSUyQyUyMm9yaWdpbkhlaWdodCUyMiUzQTgyNyUyQyUyMmZvcm1hdCUyMiUzQSUyMmpwZyUyMiUyQyUyMnJhdGlvJTIyJTNBMSU3RCU3RCU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJ0ZXh0JTIyJTJDJTIybGVhdmVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJsZWFmJTIyJTJDJTIydGV4dCUyMiUzQSUyMiUyMiUyQyUyMm1hcmtzJTIyJTNBJTVCJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTJDJTIyY29udGVudFR5cGUlMjIlM0ElMjJjYW5namllLXRleHRibG9jayUyMiU3RCU1RCU3RA==" data-identifier-application__slash__x-doc-key="8K4nyeZ46Y2Y5nLb" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicF8hyA8EDOLbjWjcIehg1cMAwlX2qlOiak8p7ibxI4an9j2rOn8mboPzQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.7018518518518518" data-type="jpeg" data-w="1080" data-imgfileid="503528201" data-aistatus="1" data-original-style="width:358px;height:251px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b7d9feb4-53a6-4273-8029-325883d11eca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;于是，机器之心评论区出现了集体求助 AI 的一幕：有人让 AI 用八十岁老太太能听懂的方式解释，有人要求用大白话翻译，还有人直接说「当我是幼儿园小朋友，给我讲明白」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicfj7xcdHvpLyIEkg9ib4ICl8slDbQKymmbP4ZN6P6fqdQ82mLibJZw0vw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.39814814814814814" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="230" data-imgfileid="503528219" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2f74b96e-3ce9-4df9-a2e6-1423991a420f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这场景既搞笑又真实。如今，我们面对复杂信息时，第一反应已经是向 AI 求援，而非硬啃。但问题来了，同样是使用 AI，有些人总能得到精准、高质量的回答，而有些人却总在和 AI「鸡同鸭讲」。&lt;/p&gt;&lt;p&gt;这样的体验让不少人对 AI 的智能程度产生怀疑，抱怨 AI 不够聪明、听不懂人话、是个「智障」。可事实并非如此，问题可能出在我们的提问方式上。&lt;/p&gt;&lt;p&gt;一个完美的指令，关键在于让 AI 确认它是否真正理解我们的需求，这就是为什么网上会流传各种提示词模板，这些经过反复打磨的指令，往往能让 AI 输出质量提升好几个 level。&lt;/p&gt;&lt;p&gt;不过，新的痛点也随之而来，这些高频使用的指令，每次都要从头输入一遍，不仅浪费时间，还容易因为表述不同导致效果不稳定。&lt;/p&gt;&lt;p&gt;如果有一个方法，能把这些指令变成一键调用的快捷键，会怎样？&lt;/p&gt;&lt;p&gt;最近，夸克 AI 浏览器功能更新，&lt;strong&gt;「千问划词」支持自定义快捷指令&lt;/strong&gt;。如果你常常需要对文稿进行内容润色、检查、优化，只需提前设置好常用的提示词，就能开启更精准、更快捷的划词体验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicia7EfnD7yZ00rYibhZuYv3uKN1k7daSjl0h8MVwqmayaKFvgx2uhM2RA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6407407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="370" data-imgfileid="503528328" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d9116190-27e1-4528-9524-bbf1c4655d2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;简单来说，就是把那些已经验证过、效果很好的提示词固定下来，需要时一键调用。&lt;/p&gt;&lt;p&gt;用法也很简单，我们只需&lt;strong&gt;在设置里找到「划词工具栏」，点击「添加自定义指令」，输入常用指令&lt;/strong&gt;，比如「请将以下内容翻译成中文：{selection} 要求翻译准确流畅，符合中文表达习惯，避免生硬直译」，再给指令起个名字，专属指令就设置成功了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicOoZKZW1mXSpzOSPUgiaSwXAYXicmLic1bcM6Z0AQvnbJThwQeg2bibqBCw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.6404077849860983" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="370" data-imgfileid="503528302" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cbdbce4e-a6bd-451c-9be0-3d21ea6a5d88/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;这里提一嘴，输入常用指令时系统有一套规则：需使用 {selection} 来表示划词选中的文字。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;后续在浏览网页或文档时，遇到需要协助翻译、润色、检查的段落，只需轻轻划选，指令即可一键使用，告别复制粘贴、重复手动输入的麻烦。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测：用夸克 AI 浏览器玩转 100 个指令&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说实话，很多人觉得 AI 难用，就是被那些长到记不住的提示词给劝退的。既然如此，不妨交给浏览器来记。&lt;/p&gt;&lt;p&gt;最近，我们对着夸克 AI 浏览器疯狂实测了一波，从中精选出 7 类最实用指令，接下来全是干货。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;邪修提示词&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最近，博主「张咋啦 zara」分享了一个超好用的邪修 Prompt：tell me what you need from me to do this well。翻译过来就是「为了执行好这个任务，你需要我给你提供什么？」&lt;/p&gt;&lt;p&gt;她表示，AI 背后的人格是个助手，而助手的第一要务是满足用户需求，很多时候 AI 不好意思跟我们提需求，这就导致当我们给 AI 的上下文不够完整时，它就瞎干，最终交付的结果自然无法达到我们的预期。&lt;/p&gt;&lt;p&gt;所以，我们可以主动询问 AI 的需求，然后再想方设法满足，执行效果会好很多。&lt;/p&gt;&lt;p&gt;我们索性用夸克 AI 浏览器的「千问划词 - 快捷指令」试试。当然 Prompt 也根据具体使用场景，改得稍微具体了些：&lt;/p&gt;&lt;p&gt;「我需要你帮我润色以下内容：{selection} ，为了执行好这个任务，你需要我提供什么额外信息？请列出你需要了解的关键要素，以便给出最优质的回答。」&lt;/p&gt;&lt;p&gt;设置好后，我们拿《马斯克的「移动客厅」又火了：20 人座无方向盘，每公里才 3 毛钱》这篇文章进行测试。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiclViaOmBdayvU8pDibGaHaNqvvyUGpQ8jXasLk10xkvtKtqPicA313IPnA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.64" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="370" data-imgfileid="503528301" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1f827b59-5120-46b6-b29d-fa43f6b087f2/640.gif" data-order="1" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;AI 终于大大方方提出疑问：目标受众、发布平台、侧重表达的观点以及语言风格分别是什么，还贴心地举了例子。得到回答后，刷刷几下子润色版本就出来了，在保留核心信息基础上，语言更具网感。&lt;/p&gt;&lt;p&gt;有一说一，&lt;strong&gt;让 AI 先问清需求，再精准输出，比直接让它润色效果好太多&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;毒舌大师&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;国外一博主也摸索出 AI 的一些骚操作。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/61201ac8-2369-4b3e-a202-c434ecaa8f27/1768449983247.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;一般来说，AI 总爱跟我们假客气，说啥它都顺毛捋，所以该博主给 AI 立了个毒舌导师的人设，我们反手就将这个提示词设置为夸克 AI 浏览器的划词指令：&lt;/p&gt;&lt;p&gt;「你是我冷酷无情的导师，别跟我绕弯子。请严格批评以下内容：{selection}，要求是如果想法烂透了，就直接说这是垃圾。你的工作就是把所有问题都挑出来，直到我说无懈可击为止。批评完后，用一句话告诉我改进方向，然后帮我修改，能更吸引人。」&lt;/p&gt;&lt;p&gt;题好一半文。扒出之前写的一篇流量堪忧的文章，点击「毒舌大师」快捷指令搞个更吸引人的标题。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaichW5H4pPOfDS1ZgYkhfL5P1tq9hNUtRfahapdMOlRYTymLSDibavxPHg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.6425" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="371" data-imgfileid="503528244" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/264621b6-4024-416c-9cba-5b4e2a6c9ed3/640.gif" data-order="2" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;AI 毫不留情地开喷「主题不明确、信息陈旧、用词情绪化，更像是社交媒体的几句牢骚」。骂完就给出改进方向，并直接甩出修改版本。&lt;/p&gt;&lt;p&gt;AI 终于不跟我们装熟了，给的建议也更靠谱。以后编辑部谁写的东西自我感觉良好，就让这个毒舌模式喷一遍。&lt;/p&gt;&lt;p&gt;讲完邪修用法，我们再来看看工作学习具体场景。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人话翻译器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于很多机器之心读者来说，最头疼的场景之一，就是读那些不明觉厉的专业论文。&lt;/p&gt;&lt;p&gt;以上文提到的 DeepSeek 技术论文为例，网友求助 AI 的表述五花八门，但核心需求其实是一致的，那就是把复杂的学术内容转化为通俗易懂的表达。&lt;/p&gt;&lt;p&gt;我们可以用夸克整个「人话翻译器」划词指令：&lt;/p&gt;&lt;p&gt;「你是一位擅长科普的教育工作者，请用费曼学习法解释以下内容： {selection}，要求先用一个生活化的类比引入概念，再拆解核心逻辑，最后用一句话总结。语言要生动，避免术语堆砌。」&lt;/p&gt;&lt;p&gt;打开一篇论文，遇到看不懂的段落，划词选中，夸克 AI 浏览器&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;几秒钟就能给出通俗解读。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic18pZjzexMFlAr5A7A5GKYgCiaf3lsxpBbUq8o5v0YTWLZ9WqnNFrh2w/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.6275" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="363" data-imgfileid="503528232" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f4e8a0e0-9aa3-485d-8f45-52adf905bac7/640.gif" data-order="3" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这比每次都要输入「用大白话解释」要精准得多，因为 AI 已经知道要用什么结构、什么风格来回答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文引用查找器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文党基本绕不过翻译、写作、修改、引用查询等环节，有了 AI 后，干这些活的效率直线上升，但用到的提示词来来回回也就那几个。这时，夸克的划词指令就派上用场。&lt;/p&gt;&lt;p&gt;举个例子。我们搞了个「引用来源查询」的划词指令：&lt;/p&gt;&lt;p&gt;「你是一位学术研究助手，精通文献检索。请针对以下观点或数据进行分析：{selection}，1）判断这可能属于哪个研究领域的哪个分支；2）推测可能的引用来源类型（奠基性理论文献、实证研究、综述文章、方法论文献）；3）提供搜索关键词建议；4）如果这是经典理论或常见观点，告诉我通常会引用哪些代表性文献或学者。注意：不需要提供具体论文链接，只需给我检索方向即可。」&lt;/p&gt;&lt;p&gt;想想以前核查引用来源，我们需要打开 Google Scholar，用各种关键词搜索，翻阅十几篇论文的摘要，判断哪些可能相关，再去下载 PDF 查看全文，最后才能确认是不是要找的那篇。一个引用来源，可能要花半小时甚至更久。&lt;/p&gt;&lt;p&gt;现在我们只需划词选中 DeepSeek 论文中一句话，点击「引用来源查询」，AI 不仅给出研究领域、来源类型、搜索关键词建议，甚至连代表性文献和学者也清晰罗列出来。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicibTKdpy4Ve5I2SI2CLd6wFMRRkACHHbkXKeRhfLpT8RdtArV5uYcNUA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.6275" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="363" data-imgfileid="503528233" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/5571c13b-cf46-4974-9380-49c21c0cebc7/640.gif" data-order="4" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;后续我们沿着这个方向，再去 Google Scholar 检索，效率飙升。&lt;/p&gt;&lt;p&gt;AI 在提升效率的同时，还会提醒我们这个观点属于什么研究脉络、应该引用什么类型的文献，这对于学术新手来说特别有价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;爆款生成器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;至于内容创作者，千问划词 - 快捷指令就更有用武之地了。&lt;/p&gt;&lt;p&gt;以机器之心编辑部为例，同一个话题要在 X、小红书、微博等多个平台发布，但每个平台的调性和用户偏好完全不同。&lt;/p&gt;&lt;p&gt;以前的做法是，编辑写好原稿后，再手动改写成各种版本，每个版本都要重新调整语气、结构、表述方式。现在，我们用夸克的「千问划词 - 快捷指令」，就能针对不同平台定制不同的改写指令。&lt;/p&gt;&lt;p&gt;比如同样是「特斯拉 FSD 首次横穿美国，Model3 实现 1 万英里零干预」这一话题，小红书爆款生成器的生成结果更生活化、更有共鸣感。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicYHSdYEdXZp0CddIJyia1PiaptViaKPGG96zDMTB8B6SCV6cYdRlvFe3nQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.6425" data-type="gif" data-w="800" type="block" data-imgfileid="503528239" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/bb0f71ff-3034-4f38-86fb-db067c8a2aef/640.gif" data-order="5" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「小红书爆款生成器」的指令是：你是一位小红书爆款内容创作者，请把以下内容改写成小红书风格：{selection}，要求：1）开头用 emoji 和惊叹式标题吸引注意力；2）把专业内容转化为「对用户有什么用」的实用角度；3）多用短句和段落，每段不超过两句话；4）结尾加上互动引导（如「你会用吗？」「评论区聊聊」）；5）适当加入网络热词但不要过度；6）控制在 500 字以内。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;微博热搜体的表达则是短平快抓眼球。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-backh="358" data-backw="562" data-imgfileid="503528234" data-ratio="0.6376274328081557" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic1rtHcqcYL1gBUjvjUVWp3jtN0DJIYWTORAGSliavzFVpMy2MElic5doQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-type="gif" data-w="1079" type="block" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/102376eb-4dc4-4dcb-89c7-2aa400cbaa1b/640.gif" data-order="6" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「微博热搜体」的指令是：你是一个专业的爆款微博大师，要求：1）用中括号【】先提炼最核心的信息做成一个标题；2）整体控制在 140 字以内；3）突出话题性和新闻感；4）加上 2-3 个相关话题标签；5）可以适当制造悬念引导点击链接。请把以下内容浓缩成一条微博：{selection}&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;X 平台则更偏向专业简洁。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicprqy0Bmh1Qic0dyFjZrEJp2ASc8hHU6G4YKSOQyLP7jd4L9eSjtX3sQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.6422613531047267" data-type="gif" data-w="1079" type="block" data-backw="562" data-backh="361" data-imgfileid="503528240" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/2868e7e3-c890-4ba9-a436-a3190717a7db/640.gif" data-order="7" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「X 平台国际化表达」的指令是：请把以下中文内容翻译成英文并调整为国际用户的阅读习惯：{selection}，要求：1）语言简洁直白，避免中式思维的复杂从句；2）突出核心事实，少用形容词和情绪化表达；3）如果涉及中国特有的概念或梗，要加简单解释；4）保持科技媒体的专业度但不要过于学术化；5）控制在 280 字符以内。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;通过千问划词 - 快捷指令，一篇内容快速适配多个平台，大大节省了编辑和运营同事反复思考和修改的时间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不止于指令：一个更强大的 AI 浏览器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;千问划词 - 快捷指令只是夸克 AI 浏览器能力升级的一部分。&lt;strong&gt;在这次更新中，夸克表现出更大野望，即成为一个真正意义上的超级应用。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;夸克 AI 浏览器除了全面融合千问 AI 助手，实现全局桌面唤起 AI 的创新交互形态；在阿里 Qwen 大模型加持下，&lt;strong&gt;近期更是一口气上线了十多种模型，供用户自由选择&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicAD3IRlCumGzjjaKWhibhRSBZPjHt4vLMbDrfWYib6ic7p9Yoqt3ZevZsQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.6413345690454124" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="371" data-imgfileid="503528235" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/3b591fa0-955d-482d-9ff4-75d65e5d02e0/640.gif" data-order="8" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时它也支持语音、图片、文件等多模态输入。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicPiafzybyE6FVtick7ZOcop4oBMgJdqDXTz7et2IOE2MiaTdF2T0pW7wfA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.6413345690454124" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="371" data-imgfileid="503528236" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/adaf9836-6974-4b82-b21c-4e79083a08cd/640.gif" data-order="9" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 首页、侧边栏、快捷框等均可实现语音输入。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，&lt;strong&gt;夸克 AI 浏览器还内置一系列实用的 AI 工具&lt;/strong&gt;。这些工具组合起来，可以构建起一套完整的一站式工作流。&lt;/p&gt;&lt;p&gt;比如我们要准备一份马斯克 SpaceX 的介绍 PPT，可以先使用夸克 AI 浏览器中的「超级播放器」，5 倍速观看相关视频，AI 实时生成字幕、翻译，并自动总结视频摘要和脑图，半小时的视频几分钟就能掌握。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/252a5045-5e98-4217-9ce1-9cead9bab461/1768450218858.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;然后调用夸克 PPT 工具生成汇报材料，将上述 AI 视频摘要输入进去，就能一键生成图文并茂的 PPT。海量模板任选，大纲随时调整。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dad953b6-7509-4ecd-bb49-bd1bcb89f453/1768450231667.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;夸克 AI 浏览器仍在以极快的速度持续进化，不断挖掘并满足用户更精细化的需求。&lt;/strong&gt;我们有理由相信，随着 AI 交互方式的持续创新优化、与工作流的深度整合，一个更强大的 AI 浏览器背后，是让个人真正实现「一个人即能活成一支队伍」的能力底座，所谓的「超级个体」也将不再是一句空话。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>已证实！清华姚班陈立杰全职加入OpenAI，保留伯克利教职</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 12:01:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/acc03329-ca2f-46fe-8152-ae7d24244959/1768449717057.png" style="width: 700%;" class="fr-fic fr-dib"&gt;据机器之心求证，清华大学「姚班」校友、加州大学伯克利分校（UC Berkeley）助理教授&lt;strong&gt;陈立杰（Lijie Chen）已正式加入 OpenAI&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="5"&gt;知情人士透露，陈立杰此次是以&lt;strong&gt;全职&lt;/strong&gt;身份加入 OpenAI 开展研究工作。与此同时，他目前在伯克利的状态为 On Leave（停薪留职），即他保留了在大学的教职，并未离职。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;陈立杰是理论计算机科学领域的顶尖青年学者，本科毕业于清华姚班，博士毕业于麻省理工学院（MIT），在计算复杂性理论等领域拥有卓越的学术成就。&lt;/p&gt;&lt;p data-path-to-node="7"&gt;截至目前，其个人主页和 LinkedIn 页面尚未更新。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDaqKWkZeGtANwZg9y9zUV0Jk9td0YvwfjDtlJ1pmpR5PdhMhDqjibeiag/640?wx_fmt=jpeg#imgIndex=1" data-ratio="0.9305555555555556" data-type="png" data-w="1080" data-width="1521" data-height="1761" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDOHYFqQZhfcFNPmnJCG9pjEbgqejTeX5iaBClKRE3IjbvmTwFa2A9e8A/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy2="1005.0533807829181" data-imgfileid="503528407" data-aistatus="1" data-original-style="width:562px;height:523px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8c483a01-1c51-441c-9ed4-617ffd1c7cd0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDNjqD1ITGUvZzuC01n8abQnrVG4hXosNK5SiaA1woDBfJFu1Yrx4sjMQ/640?wx_fmt=jpeg#imgIndex=2" data-ratio="1.2916666666666667" data-type="png" data-w="1080" data-width="1194" data-height="1704" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDvQxBeWxeTXHms5QL1zvPCm1Z74pzmEp0nLjs1c1D4QMYwEuSSS2jrQ/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy1="92.24199288256227" data-cropy2="1487.4021352313168" data-imgfileid="503528402" data-aistatus="1" data-original-style="width:562px;height:726px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1e527d87-4420-4124-94fd-2cd33c56a834/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="8"&gt;&lt;strong&gt;从 IOI 金牌到伯克利助理教授&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;陈立杰高中就读于杭州外国语学校。他在信息学竞赛（OI）领域表现突出，是当时知名的竞赛选手。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;2011 年，他获得全国青少年信息学奥林匹克竞赛（NOI）金牌；2013 年，他代表中国队出征第 25 届国际信息学奥林匹克竞赛（IOI），不仅夺得金牌，更取得了全球第一名的成绩。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDNeZqJ8KUyicvsibXAylhNXAVIhxRfZoFTYWguibcKvD6ISsKliafuPMGicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5433333333333333" data-type="png" data-w="600" data-imgfileid="503528413" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8062465f-5d24-4da8-a1ad-7055eaf3ae30/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="11"&gt;进入清华大学姚班后，陈立杰逐渐将重心从程序设计竞赛转向计算机科学理论研究。2016 年，他获得清华大学本科生特等奖学金。在特等奖学金答辩会上，陈立杰曾立下宏愿：「&lt;strong&gt;有生之年，希望能看到 P vs NP 问题被解决。&lt;/strong&gt;」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgjkLv9SWDs8jXPeaNs1QHLATcFogMWXzkkoictumhkv3EAkDcbWvsow/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6366666666666667" data-type="png" data-w="600" data-imgfileid="503528412" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/71f41604-8e2b-4fd3-821d-05347c1117fb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;大三时期，他曾赴 MIT 进行科研交换，师从著名量子信息科学家 Scott Aaronson 教授。2017 年，作为大四本科生的他在 FOCS（IEEE 计算机科学基础年会）上发表了论文，&lt;strong&gt;成为首位在该顶级会议上发文的中国本科生&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDz1Fte6DQa9OLZ4VQhPz7iaicnQI5AhsaVSwXQgTZPRuzfgtgUyxOKjHQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.7583333333333333" data-type="jpeg" data-w="600" data-imgfileid="503528409" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3267e0c9-a55b-4552-9253-5478b8d4cf15/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="13"&gt;该论文是他在 MIT 访问期间与 4 名博士研究生及博士后合作完成的，解决了 John Watrous 于 2002 年提出的关于「量子统计零知识证明」（QSZK）的开放性问题，引入了「量子区分复杂度」这一新概念，证明了其与 QSZK 查询复杂度的关系，解释了传统分析方法的局限性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="14"&gt;&lt;b data-index-in-node="0" data-path-to-node="14"&gt;论文地址：&lt;/b&gt;https://arxiv.org/pdf/1609.02888&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="15"&gt;本科毕业后，陈立杰赴 MIT 攻读博士学位，师从计算复杂性权威 Ryan Williams 教授。这一时期，他在&lt;strong&gt;计算复杂性、电路复杂度、伪随机性&lt;/strong&gt;等领域取得了实质性突破，主要贡献包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="16,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,0,0"&gt;硬度放大：&lt;/b&gt; 他与合作者发现了一条绕过「自然证明」壁垒的潜在路径：证明某些问题在极弱的电路模型下是困难的，可以自动「放大」推导出它们在极强电路模型下也是困难的（即推导出 P &amp;ne; NP）。严谨的是，他也提出了「局部性壁垒」，客观指出了目前技术在利用这一发现时面临的实际困难。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,1,0"&gt;非黑盒去随机化：&lt;/b&gt; 他提出了一种新框架，证明在比传统要求更弱的假设下，可以去除算法中的随机性。他还证明了在特定条件下，随机性对于计算可能是「无用」的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,2,0"&gt;量子霸权的理论基石：&lt;/b&gt; 他参与证明了存在一个 Oracle，使得量子多项式时间（BQP）不包含在多项式层级（PH）中。这为量子计算机在理论上超越经典计算机提供了坚实的数学支撑。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="17"&gt;他在博士期间多次获得理论计算机顶级会议的最佳学生论文奖，包括 STOC 2019（Danny Lewin Award）和 FOCS 2019（Machtey Award）。2022 年，他的博士论文获得 ACM 博士论文奖荣誉提名以及 MIT George M. Sprowls 最佳博士论文奖。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDFtg8HUndFooTiaxvn4jyP3B1ayDCre1mwYIYelUwFVn6lw8icoZ5NV4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6714285714285714" data-type="png" data-w="980" data-width="980" data-height="658" data-imgfileid="503528419" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c432f97a-faaf-42f7-ab70-86543e799aba/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="18"&gt;2022 年博士毕业后，陈立杰获得了 UC Berkeley 米勒基础科学研究所的 &lt;strong&gt;Miller Fellowship&lt;/strong&gt;。这是一项面向全球杰出青年科学家的全额资助计划，历史上曾诞生过多位诺贝尔奖和菲尔兹奖得主。作为米勒研究员，他拥有完全的学术自由，在三年内专注于自己感兴趣的前沿课题。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;他于 2025 年 7 月入职 UC Berkeley 电气工程与计算机科学系（EECS）担任助理教授，继续从事教学与科研工作。&lt;/p&gt;&lt;section&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/section&gt;&lt;section&gt;&lt;sup&gt;https://www.tsinghua.org.cn/info/1953/13913.htm&lt;/sup&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>解锁任意步数文生图，港大&amp;Adobe全新Self-E框架学会自我评估</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 11:58:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/404ea3bf-7d73-4b10-9055-d81ed68eadc3/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管扩散模型（Diffusion Model）与流匹配（Flow Matching）已经把文本到图像生成（Text-to-Image, T2I）推向了更高的视觉质量与可控性，但他们通常在推理时需要数十步网络迭代，限制了其对于一些需要低延迟，Real-Time 的应用。&lt;/p&gt;&lt;p&gt;为了把推理步数降下来，现有路线通常依赖知识蒸馏（Distillation）：先训练一个多步教师模型，再把能力迁移到少步学生模型。但这条路的代价同样明显 &amp;mdash;&amp;mdash; 既依赖预训练教师，又引入了额外的训练开销，并在「从零训练（from scratch）」与「极少步高质量」之间留下了长期空白。&lt;/p&gt;&lt;p&gt;近日，香港大学（The University of Hong Kong）与 Adobe Research 联合发布 Self-E（Self-Evaluating Model）：一种&lt;strong&gt;无需预训练教师蒸馏、从零开始训练的任意步数文生图框架&lt;/strong&gt;。其目标非常直接：让同一个模型在极少步数也能生成语义清晰、结构稳定的图像，同时在 50 步等常规设置下保持顶级质量，并且随着步数增加呈现单调提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAvlRwkoKg4F7DFOOm16JzLj2F0t3WyRSicfDL1ibHjIzokI51iaS1UueSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.27037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528045" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/03427976-4849-4dc5-a278-d8adaa8d6bb8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Self-Evaluation Unlocks Any-Step Text-to-Image Generation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://xinyu-andy.github.io/SelfE-project/&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文 PDF：https://www.arxiv.org/pdf/2512.22374&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsuBcsLgMO3SOAXfTrUQ8Kqp1L4oc9YCLSM4xrSn2WE5FUDrDtf15eQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5342592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528044" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c7250837-2b24-40bd-b3c7-bfa9bea307bb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;引言：从「轨迹匹配」到「落点评估」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;扩散 / 流匹配范式本质上是在学习一张「局部向量场」：给定噪声状态，预测下一步该往哪里走。这个监督信号在「小步、密集积分」时非常有效，但一旦尝试「大步跳跃」，误差会被轨迹曲率放大，生成往往滑向平均解、语义漂移或结构坍塌。&lt;/p&gt;&lt;p&gt;Self-E 的切入点是一个根本上的范式改变：&lt;strong&gt;我们能否不再执着于「每一步走得对不对」，而是把训练重心转向「落点好不好」？&lt;/strong&gt;也就是把目标从「轨迹匹配（trajectory matching）」转变为「落点评估（destination/landing evaluation）」。&lt;/p&gt;&lt;p&gt;换句话说，传统 Diffusion Model 训练强调「在起点对齐局部方向」；Self-E 强调「在落点评估结果并给出纠偏方向」。监督位置的改变，带来了训练信号性质的改变：从静态监督变成动态反馈。&lt;/p&gt;&lt;p&gt;作者在项目主页用动图展示了这两者的区别：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAe6xwicALoYz3p73XBzZwIkVnQ7zzDsCraQlplYa4H0Bo7AqYbW6p5xw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.5829471733086191" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503528046" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/fb315588-387f-4e02-a7a4-55865bdf0f5c/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA7nHJfx8zhw61HDVt6V5WhIuqglibu4JyKBKASImLa606R3YZmyMm5Dg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.5829471733086191" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503528047" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7e7fb9e8-6e51-476b-8c23-59effe360bc5/640.gif" data-order="1" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这也是为什么模型在测试阶段有少步推理能力：扩散模型在测试时只能逐步跟随当前点预测的最好局部路径，最终走到全局最优；而 Self-E 在训练阶段就逐步学会了走向全局最优的落点。&lt;/p&gt;&lt;p&gt;这也不同于目前多数少步生成模型所采用的学习轨迹的积分，如 Consistency Model, Mean Flow; Self-E不局限于沿着预定义的轨迹走，而是直接关心每步结果好不好，对不对。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Self-E 的核心：两条互补训练信号（Two Complementary Signals）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 用同一个网络在两种「模式」下工作：一方面像 Flow Matching 一样从真实数据学习分布的局部结构；另一方面用「模型自身正在学到的局部估计」去评估自生成样本，形成自反馈闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1）从数据学习：Learning from Data&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;学什么&lt;/strong&gt;：分布的局部结构（local score /velocity 的期望形式），即「在邻域内密度如何变化」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;怎么学&lt;/strong&gt;：采样真实图像与文本条件，加噪得到噪声输入，用条件流匹配式目标训练模型去预测干净样本（或等价参数化），提供稳定的局部监督。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2）自我评估学习：Learning by Self-Evaluation&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;学什么&lt;/strong&gt;：分布层面的正确性（distribution-level correctness）&amp;mdash;&amp;mdash;&amp;nbsp;生成样本是否与真实分布一致、是否与描述的文本对齐。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键机制&lt;/strong&gt;：模型先做一次「长距离跳跃」（从起始时间步跳到落点时间步），然后在落点处用自己当前学到的局部估计产生一个「方向信号」，告诉生成样本应如何移动才能进入更高质量、更符合文本的概率分布区域。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最大差异&lt;/strong&gt;：评估信号不来自外部教师（pretrained diffusion teacher），而是来自模型自身的在训估计（dynamic self-teacher）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAb6e5QriaPUVibjetLXLCOkO5a4r60gibVAUAgSiaIialNvIfQHqwUKuicp1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528048" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/8d0e1028-1471-4428-a999-f7773fb6950a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;训练细节：把「自我评估」做成可反传的学习信号&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 在理论上把评估写成分布级目标（例如以反向 KL 为代表的分布匹配视角），但真正落地的难点在于：真实分布与生成分布的 score 都不可得。&lt;/p&gt;&lt;p&gt;Self-E 的关键观察是：&lt;strong&gt;模型在「从数据学习」阶段会逐步学到某种条件期望形式，而该量与 score 通过 Tweedie&amp;rsquo;s formula 存在联系&lt;/strong&gt;，因此可以用「正在训练的模型」去近似提供评估方向。&lt;/p&gt;&lt;p&gt;在实现上，作者发现理论目标中包含「classifier score term」等项，并实证发现仅使用 classifier score 项就足够有效，甚至更利于收敛，从而避免早期还要额外训练一个用于 fake score 的模型分支。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA5p4gj4vOpXFrMHbiaVbHYiaS6MlETMShJ9Xr1vZEXcgkfrAeNOXCVmFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3074074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528049" data-aistatus="1" data-original-style="width:374px;height:115px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c51c4cff-042f-40a8-b873-879557485033/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了把这种「评估方向」变成可训练的损失，Self-E 采用 stop-gradient 的双前向构造 pseudo-target，通过最小化 MSE 诱导出与所需方向一致的梯度；并在最终目标中将数据驱动损失与自评估损失进行混合加权。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGVx9h55OaXTDXHvkOIh12xKEibpuHX49QLYoOugmfQzwLKnz8qa3nZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.20462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528050" data-aistatus="1" data-original-style="width:347px;height:71px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/547d8dac-fa19-43fc-83a2-5543e4546836/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最终，我们可以用一个统一的形式来训练：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuo01tTMfxTSRAgbLFyObmTO431CcULicSNEWkFR74fXfLfn63qicj1Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.11481481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528051" data-aistatus="1" data-original-style="width:320px;height:37px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/19efea39-1e2a-4e2b-b666-2f56a04b9d26/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中，等式右边第一项正是 Learning-from-data 的目标，而第二项对应 Self-Evaluation。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理：任意步数（Any-Step Inference），并随步数单调变好&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在推理阶段，Self-E 与扩散 / 流匹配一样进行迭代去噪，但不同之处在于：由于训练中已经显式学习「长距离落点」的质量与纠偏方向，它可以在非常少的步数下保持可用的语义与结构，同时在增加步数时继续提升细节与真实感。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;性能：GenEval 全步数段 SOTA，少步优势尤其显著&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 GenEval 基准上，Self-E 对比其他方法取得全面领先，并且随着步数增加呈现单调提升。更关键的是少步区间的「断层式」优势：在 2-step 设置下，Self-E 相比当时最佳对比方法的提升约为&lt;strong&gt; +0.12&lt;/strong&gt;（0.7531 相比 0.6338），而多种传统扩散 / 流匹配模型在 2-step 下几乎无法生成可用结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAK3VzR2O3ILOtbJyxwS39UOU4pmBKovEKWlLsZ3wtnEDcezwicJvg2bw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528052" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/699a30fc-1c99-4433-add6-b98868d536a3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAI75P0LtKlz5R16L9ICeSHtRSqDpuDV6Dib9oTIU9v9XW51o0jYQc7bA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.8518518518518519" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528053" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c6d9e0ab-7a49-4e5e-9a61-ca451b520943/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;另一角度解读：把「预训练」与「反馈学习」拉到同一条线上&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从更宏观的视角看，Self-E 把训练过程组织成一个类似强化学习中的「环境 &amp;mdash; 智能体（environment&amp;ndash;agent）闭环」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Phase&lt;/strong&gt;：模型从真实数据学习分布的局部结构，得到越来越可靠的局部估计（可视作学习环境，并给出评估）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Self-Evaluation Phase&lt;/strong&gt;：模型提出长距离跳跃方案（可视作智能体执行动作），在落点处用内部估计产生反馈方向并更新参数（可视作获得环境的反馈）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Closed Loop&lt;/strong&gt;：评估器随训练变强，反馈信号质量随之提升，反过来又进一步强化少步生成能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者在项目主页指出：这种内部评估器在角色上接近「可查询的学习型奖励模型」，为后续把强化学习（RL）更系统地引入视觉生成训练提供了新的接口与想象空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 的价值不只是在「少步生成」这一条指标上跑得更快，而在于它把文生图训练范式从「沿着既定轨迹走」推进到「学会评估落点并自我纠偏」：在不依赖预训练教师蒸馏的前提下，让单一模型同时覆盖极低时延与高质量长轨迹两种需求，并在不同推理预算下保持可扩展的性能曲线。&lt;/p&gt;&lt;p&gt;对内容创作与生成式系统落地而言，「one model, any compute」的工程意义非常直接：同一个 checkpoint 可以按场景动态选择步数 &amp;mdash;&amp;mdash; 交互式场景用 1～4 步追求即时反馈，高质量离线渲染用 50 步追求细节上限；而训练侧则绕开了教师蒸馏链路，把「从零训练 + 少步推理」真正拉回到可讨论、可复现、可扩展的主流路径上。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>5分钟定制一个AI采购专家：讯飞发布“招采智能体工厂”，重新定义行业开发范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 15 Jan 2026 11:35:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;大模型落地，正从&amp;ldquo;聊天与创作&amp;rdquo;走向&amp;ldquo;规划与执行&amp;rdquo;的深水区。1月13日，科大讯飞将这一趋势押注在一个极其垂直且复杂的领域&amp;mdash;&amp;mdash;招标采购，并发布了其全新的&amp;ldquo;招采智能体平台&amp;rdquo;。与其说这是一个产品，不如说它是一个&amp;ldquo;专为招采场景打造的智能体操作系统与开发工厂&amp;rdquo;，其核心主张令人振奋：零代码，5分钟，让企业构建属于自己的AI采购专家。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c97a3f6d-6b0e-45c7-8526-841c8dc20a2d/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;要理解这场发布的意义，首先要看清AI赋能招采的技术演进之路。1.0时代是&amp;ldquo;工具辅助&amp;rdquo;，核心是&amp;ldquo;小模型+结构化&amp;rdquo;，解决了&amp;ldquo;人工翻页&amp;rdquo;痛点，但AI不理解业务；2.0时代进入&amp;ldquo;单点智能&amp;rdquo;，大模型带来了认知突破，能深度理解评审规则，但无法解决流程割裂问题；3.0时代即&amp;ldquo;智能体（Agent）时代&amp;rdquo;，智能体具备自主规划、跨域协同、持续进化能力，成为能够推进全流程的&amp;ldquo;专业伙伴&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/d04571c4-3b69-4e8d-8f47-fa5d4d8ea648/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&amp;ldquo;招采智能体平台&amp;rdquo;的架构基于三大核心技术支柱：首先是&amp;ldquo;星辰Agent底座&amp;rdquo;，这是平台的&amp;ldquo;决策大脑&amp;rdquo;，是国内首批融合大模型决策规划与RPA执行能力的智能体平台；其次是&amp;ldquo;星辰RPA&amp;rdquo;，作为智能体的&amp;ldquo;自动化双手&amp;rdquo;，能够稳定执行跨软件操作；第三是&amp;ldquo;MaaS模型精调平台&amp;rdquo;，允许企业上传自身数据精调模型，平均40分钟即可完成一个细分场景模型的优化。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a074e41d-0134-449c-aeb4-9dc9a9e78372/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;发布会的体验区成为了技术理念的最佳秀场。参会者可以亲历两大亮点：在&amp;ldquo;智能体搭建工坊&amp;rdquo;，即使毫无编程基础的业务人员，通过简单的拖拽、连线，就能快速构建一个可运行的智能体；作为发布会的技术彩蛋，讯飞透露正在跟进国际领先的智能体&amp;ldquo;技能&amp;rdquo;（Skills）标准，该标准旨在为AI编写结构化的&amp;ldquo;工作手册&amp;rdquo;，预示着未来智能体将具备更强大的跨平台任务执行能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/95987983-18ad-422c-b022-7906f026f867/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;讯飞深知，招采业务场景千变万化，仅靠自身无法穷尽。因此，平台的终极目标是构建生态。它不仅内置了覆盖招标、投标、评标核心流程的数十个专业Agent，更将底层能力开放。未来，第三方开发者、行业专家可以基于此平台，开发并上架更丰富的垂直场景智能体，共同打造招采领域的&amp;ldquo;智能应用商店&amp;rdquo;。&lt;/p&gt;&lt;p&gt;从单一AI应用到开放的能力基座，科大讯飞此次发布标志着其AI to B战略进入了以&amp;ldquo;平台+生态&amp;rdquo;驱动的新阶段。在行业聚焦于真实价值创造的当下，招采智能体平台能否以其鲜明的技术路径和清晰的落地场景，成为垂直领域大模型应用的新范式，值得所有技术观察者持续关注。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Agent时代，为什么多模态数据湖是必选项？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 09:55:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/357eea47-54fc-4a65-9090-96dbe74862e5/1768441988644.png" style="width: 700%;" class="fr-fic fr-dib"&gt;「2025 年，注定被铭记为 AI 工业时代的黎明。」&lt;/section&gt;&lt;p&gt;回望这一年，吴恩达教授曾这样感慨。&lt;/p&gt;&lt;p&gt;这一年，大量企业你追我赶，投身于 AI 应用及 Agent 建设。然而，许多企业或许尚未意识到：如果 AI 竞速只停在应用层，可能连这场竞争的「起跑线」都尚未站上。&lt;/p&gt;&lt;p&gt;AI 时代，数智化表面是模型的狂欢，底层是基建的深耕。&lt;/p&gt;&lt;p&gt;唯有能支撑 AI 应用规模化落地的数据基座，才能构筑企业真正的竞争力。&lt;/p&gt;&lt;p&gt;近来， AI 行业普遍认为我们正在进入所谓的「AI 下半场」，而此时行业面临的一大关键问题是「究竟应该让 AI 去做什么？又该如何衡量真正的进展？」&lt;/p&gt;&lt;p&gt;而这个问题的答案也基本已有共识：要想在这下半场脱颖而出，我们需要及时转变思维方式，应当用 AI 的思维，把该做的事情重新做一遍。&lt;/p&gt;&lt;p&gt;与上一阶段不同，这一阶段的企业数据，不再等待人来解读，而是被模型直接「消费」。&lt;/p&gt;&lt;p&gt;以音频数据应用为例，AI 时代，音频数据不应只是一份录音数据存档，还应成为可查询和交互的信息源，比如应该支持查找「录音中的人是客户 A ，上周在另一业务有投诉记录」这类关联信息。这种跨模态的关联性，是实现模型复杂推理的基础。&lt;/p&gt;&lt;p&gt;推及其他行业：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在智能驾驶中，道路视频、点云与传感器数据需要被实时送入智能体，支撑感知、规划与异常检索；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在游戏行业，需要将对话、行为与世界观等多模态数据沉淀为长期记忆，用于沉浸式 NPC 与自动化资产生成；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在传媒行业，需要使用视频、音频与用户互动数据来驱动内容生成与精准分发；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在电商领域，商品图文与交易数据直接喂给模型，实现智能选品与个性化推荐。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，&lt;strong&gt;对多种模态数据的处理与使用的能力，正在影响各行业商业竞争的形态与上限&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;接下来的风口要踏在哪里？我们关注到了火山引擎近期发布的《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzkwMzMwOTQwMg==&amp;mid=2247521304&amp;idx=1&amp;sn=dc367120edc88b47f8ed7f4f168e2c4c&amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;strong&gt;AI 时代企业数据基建升级路线图&lt;/strong&gt;&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;它在开篇写到：&lt;strong&gt;AI 时代，数据基建已经成为决定企业竞争高度的战略资产&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;笔者深以为然。&lt;/p&gt;&lt;p&gt;企业要发展可以处理多模态数据的底层基建。因为 AI 时代最深的红利，并不在于「拥有」SOTA 的模型，而在于能否持续「驾驭」并「滋养」它。更进一步，可以说构建多模态数据湖已经成为企业参与这场 Agent 竞赛的必选项。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicEgLkymO8MMCrLiavX0ql8FiaIic9vG0qu0TCo74T5VGbKcuyO8iaLNWeAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528308" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a7f325e4-217e-4dce-9d6a-511b35d4d756/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 传统数据湖与多模态数据湖对比，图像由 AI 生成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 时代，这是你不能错过的风口&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智能的涌现扎根于坚实、鲜活且可进化的数据土壤。&lt;/p&gt;&lt;p&gt;尤其在 Agent 时代的到来之际，企业竞速也正由数据基建分野：领先者正将沉睡的非结构化数据转化为可用的竞争力，而落后者由于非结构化数据资产仍处于休眠状态，而只得徘徊在 Agent 应用的起点。&lt;/p&gt;&lt;p&gt;当行业的聚光灯都投向大模型或智能体本身时，真正的竞争已转入水下，&lt;strong&gt;即底层的、支撑多模态数据的数据工程。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;唤醒数据，化「沉睡库存」为核心资产&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;IDC 预测，2025 年企业超过 80% 的数据将是非结构化的。&lt;/p&gt;&lt;p&gt;这些长期堆积的视频、音频、图像和传感器数据，曾被视为「数字负债」。然而，多模态与大模型技术的成熟，正让它们焕发前所未有的价值。&lt;/p&gt;&lt;p&gt;以制造业为例，以往无人问津的历史故障录像，经大模型解析与标注，即可成为「智能知识库」。新员工用自然语言提问，便能精准调取同类故障的处理记录 &amp;mdash;&amp;mdash; 沉寂数据瞬间转化为实战生产力。&lt;/p&gt;&lt;p&gt;本质上，AI 时代的数据基建，正通过向量化等处理能力，让非结构化数据真正「活」起来，使其从被动存储的负担，变为可随时调用、持续学习的战略资源。&lt;/p&gt;&lt;p&gt;唤醒这 80% 的数据，是在 Agent 时代构建竞争力的工程前提。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让数据资产驱动业务，启动飞轮&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;强大的数据基建能构建数据、模型与业务深度耦合的闭环，真正「让模型自主成长」，为 Agent 赋予更多智能。&lt;/p&gt;&lt;p&gt;一个优秀的数据架构，需在企业数据平台、MaaS（模型即服务）平台、Agent 开发工具与应用之间建立高效的数据流通管道，否则数据会停留于「孤岛」，智能难以落地。&lt;/p&gt;&lt;p&gt;典型的例子是传统智能客服：尽管不断采集用户的语音、文本、截图与操作轨迹，却因模型与业务间数据不通，导致客服模型始终重复犯错、体验停滞，陷入「千人一面」的困境。&lt;/p&gt;&lt;p&gt;我们发现，火山引擎通过多模态数据湖与 AgentKit、火山方舟等产品的联动，已验证了数据、模型、业务打通的可行性。在零售行业中，完善的多模态数据湖不仅能分析销售报表，还可实时捕捉顾客行为、评论与画像。这些鲜活数据持续回流，使企业 AI 能力能随业务不断演进。&lt;/p&gt;&lt;p&gt;这种「业务滋养模型、模型反哺业务」的闭环，使企业 AI 能力可伴随业务持续进化，这正因为此，多模态数据湖成为了 Agent 时代构建智能护城河的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让业务拥有锚点，获得未来的确定性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;新一代数据基建通过统一的数据与计算底座，以同一平台支撑多模态数据，并持续适配技术演进。&lt;/p&gt;&lt;p&gt;以某安防企业为例，传统数据管理体系下，如果从视频监控扩展至智能识别，往往需为不同算法供应商重建独立的计算平台与数据库，导致内部数据不互通、烟囱林立。巨大的管理和技术成本，会拖累企业创新动力。&lt;/p&gt;&lt;p&gt;而统一的多模态数据湖体系，能以统一元数据管理结构化和非结构化数据，提供面向 AI 的灵活数据集能力，支持数据快速探查与调用。通过标准化存储与可扩展接口，系统能在上层屏蔽底层模型的频繁迭代，使数据始终以对模型友好的形态稳定输入。&lt;/p&gt;&lt;p&gt;这意味着，当该企业未来业务从「视频监控」拓展至「自动巡检」、「人流预测」等领域时，可低成本接入新算法模块，无需颠覆底层架构。&lt;/p&gt;&lt;p&gt;「基建不动，技术常新」，在追求敏捷响应速度的 Agent 时代，这种具备工程确定性的多模态基座正在成为架构的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;升级三部曲：积累，重构，融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;火山的这份「数据基建升级路线图」之所以值得展开聊聊，是因为它在行业内率先为企业提供了一套从「拥有模型」到「驾驭智能」的数据基建进化蓝图。在 Agent 时代，它为企业提供一套实现多模态数据湖的清晰演进路径。&lt;/p&gt;&lt;p&gt;这个蓝图可作为重要的参考框架，企业可结合业务特点与发展阶段，衍生出适合自身的基建升级路径，进而在 Agent 时代构筑自己的核心竞争力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528305" data-ratio="1.0444444444444445" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiciaapBNl8MSNCEIsQNResw6sdN9fdh5YF9NrTPrseSomrXiabvRibCotAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a388d8f5-e4e3-4cd0-a29a-73ad318413a7/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;具体而言，火山引擎将企业数据基建的演进分为了三步渐进式过程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;异构算力与分布式引擎阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一阶段的核心是突破算力瓶颈。为应对大规模数据处理与大模型训练的需求，传统仅依赖 CPU 的架构已难以满足 AI 时代对存储与计算的高实时性要求。企业需转向为 AI 任务量身打造的 CPU+GPU 异构架构，实现灵活调度。&lt;/p&gt;&lt;p&gt;这一阶段的核心目标是：数据「进得来，跑得快」，并原生支持 AI 服务。在异构算力的支撑下，企业能在技术快速迭代中平衡性能与成本，真正让算力服务于业务与模型增长。整体来说，这一阶段可为多模态数据湖这一必选项提供坚实的物理支撑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型即引擎与多模态重构阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在算力基础就绪后，需进一步推动数据基建与 AI 的深度融合。本阶段的关键在于将预训练大模型嵌入数据流水线，实现文本、图像、音频等多模态数据向统一语义向量与高价值知识标签的自动转换。&lt;/p&gt;&lt;p&gt;Agent 时代，数据价值不在于「存量」，而在于能被 AI 调用的「流量」。通过&lt;strong&gt;向量化&lt;/strong&gt;处理，企业的多模态资产第一次真正实现通用「可读、可感、可交互」。该过程直接发生于数据基建层，从源头确保企业数据对大模型友好，使其可随时被检索、推理与学习，赋能全感官业务洞察。&lt;/p&gt;&lt;p&gt;因此，这一阶段可使多模态数据湖成为 Agent 识别与推理的逻辑重心，进一步确立了其作为基建必选项的地位。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全域数据治理与平台融合阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目标是在管理层面对数据资产进行统一管控，推动全域数据的治理、价值激活与安全合规。&lt;/p&gt;&lt;p&gt;这意味着 AI 能力可深度融入每一条业务流程，激活分散在不同系统与形态中的数据资产，并将其持续转化为增长动能。统一的数据治理体系不仅能显著降低安全与合规风险，还可大幅提升数据复用效率，助力企业将技术优势系统化、可持续地转化为长期竞争力。&lt;/p&gt;&lt;p&gt;这一阶段标志着多模态数据湖从单一的技术底座演变为全域的智能中枢，完成了其作为 Agent 时代必选项的最后拼图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 时代数据基建的选型指南&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;国内云厂商都在积极拥抱 Agent 时代的技术升级，从各大厂商的进度来看，对多模态数据的「存、算、管」重视度在持续提升。其中，我们观察到火山引擎「多模态数据湖」在行业内的进展最快，能够提供数据统一入湖与治理能力，在算子体系、性能优化、异构算力调度以及与大模型生态的无缝协同方面形成了更完整的一体化方案。&lt;/p&gt;&lt;p&gt;同时通过观察行业内其他厂商面向多模态数据的方案方向，我们也在思考：AI 和 Agent 时代的企业需要的数据基建，到底应该是什么样的？&lt;/p&gt;&lt;p&gt;综合起来，我们认为企业应将&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;以下特质列为&lt;/span&gt; AI 数据基建的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从「存储中心」到「价值中心」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 AI 浪潮下，企业首先撞上的，是数据体系的根本性变革。&lt;/p&gt;&lt;p&gt;一方面，数据规模动辄 PB 级，非结构化格式复杂，处理流程高度碎片化，还要同时承载 CPU + GPU 混合负载与复杂作业调度；另一方面，大量数据分散存储、难以统一检索，无法被模型高效消费，数据准备周期越来越长，成本却持续上升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真正有价值的数据，是能被快速获取、被模型理解、能转化为 Token 并直接参与推理与训练的数据。&lt;/strong&gt;而那些无法被向量化、无法进入模型工作流的数据，正在从资产变成沉重的存储负担。&lt;/p&gt;&lt;p&gt;AI 时代的数据底座，是从「存储中心」转向「价值中心」的底座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;业务优先，回归实用主义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在技术变革快速的当下，除去技术复杂性之外，企业更大的挑战是：数据基建与业务脱节。&lt;/p&gt;&lt;p&gt;当前很多企业同时面临多模态数据分散、训练与生产割裂、血缘与版本缺失、质量评估与数据反馈闭环不足的问题。结果是数据冗余高、问题排查难、准备周期长，而业务决策却越来越依赖实时与精准。&lt;/p&gt;&lt;p&gt;在这种背景下，盲目堆算力、追求极限性能，反而成了负担。AI 时代最昂贵的基建，是那些无法转化为业务价值的闲置能力。&lt;/p&gt;&lt;p&gt;衡量一套数据基建是否先进，在于它是否能以最低成本、最快速度完成从数据输入到业务决策的闭环，并持续驱动数据飞轮运转。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开放解耦，对冲未来不确定性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着模型与技术路线持续快速更迭，企业面临的另一项长期风险正在显现：如果数据基建随模型变化不断重构，系统将永远处于迁移与动荡之中。&lt;/p&gt;&lt;p&gt;在多模态数据规模持续膨胀、合规与安全要求不断提高的背景下，这种反复重构的代价几乎不可承受。&lt;/p&gt;&lt;p&gt;因此，解耦与开放的能力决定了成为企业的「生存能力」。通过模块化、可替换的数据与 AI 基础设施，企业才能在模型更替、技术跃迁时实现平滑升级，既保持系统稳定，又持续吸收新能力，将技术不确定性转化为长期竞争力。&lt;/p&gt;&lt;p&gt;在 AI 时代，模型会不断过时，真正具有长期价值的，只有数据资产与承载它的基础设施弹性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaictYQCpliak2DZbxFh5zJDsxEEZpjicLm7EyXopeXeygEoAD9NibJPndkFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528306" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4b6d51d4-f1a3-4864-a3a6-b614609e3925/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这使得多模态数据管理必须从「存得全、存得久」升级为「取得快、读得懂」的针对业务模式的系统性工程。&lt;/p&gt;&lt;p&gt;我们观察到火山引擎多模态数据湖有一个非常有意思的理念。&lt;/p&gt;&lt;p&gt;其提出了&lt;strong&gt;「乐高式」可组合底座&lt;/strong&gt;的观点，与其他云厂商的解决方案大相径庭。这种方式支撑企业以乐高积木般灵活、高效的方式，自主构建上层应用与智能体。&lt;/p&gt;&lt;p&gt;在这种框架下，企业可以根据现有的技术情况，选择渐进式的解决方案，同时可以模块化设计数据与智能架构，结合自身业务来进行组合式的升级，方案完全「量身定做」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicib7SIKbm4ZkDISKe6wUy1RCoEtgL0X1UTEerliaRmnGI6dPvzKdKfNWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528307" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/768e01dd-7c95-4144-9c3c-312338cd6d3f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从行业视角看，这一设计理念呼应了企业长期的 AI 战略 &amp;mdash;&amp;mdash; 让数据基础设施具备持续演进的能力，使企业在快速迭代的技术环境中，始终拥有自主调整与进化的空间。&lt;/p&gt;&lt;p&gt;目前火山的多模态数据湖，已经在智驾、游戏、传媒等多个行业落地。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在某智驾企业的模型训练中，该方案可在 150&amp;ndash;200 毫秒内完成 12 亿级别数据的「以图搜图」，性能提升&amp;nbsp;&lt;strong&gt;20 倍&lt;/strong&gt;以上；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;某游戏企业在 AI NPC 模型训练过程中，音视频数据加工效率提升&amp;nbsp;&lt;strong&gt;50%&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;应用于某头部传媒企业的媒资平台后，其内容生产与运营效率提升 &lt;strong&gt;90%&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些实践表明了采用多模态数据湖的必要性，同时也揭示出：AI 和 Agent 时代，用好多模态数据，可以激发出推动企业智能化跃迁的潜能。千行百业，都值得以此为起点，探索数据基建的更多可能，拥抱智能时代的风口。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当下，企业正站在一场深刻技术变革的洪流之中。&lt;/p&gt;&lt;p&gt;AI 落地的前提，是多模态数据处理走向标准化与智能化。对坚定投身于 AI 浪潮的企业来说，在见证大模型所带来的能力飞跃的同时，更应关注到多模态数据管理作为基础设施的必要性。&lt;/p&gt;&lt;p&gt;构建能够支撑未来十年 AI 发展的数据基座，是这场变革中最应锚定的重心。&lt;/p&gt;&lt;p&gt;对企业而言，多模态数据湖的意义远不止步于一套数据架构。它是承载 AI 应用持续演进的土壤，是企业在技术红利窗口期建立确定性的基础。&lt;/p&gt;&lt;p&gt;是的，正如我们已经在文中多次强调的那样：多模态数据湖已经不再只是可有可无的优化项，而是企业进入智能赛道的必选项。&lt;/p&gt;&lt;p&gt;它赋予企业的，是在 Agent 时代中「以静制动」的底气，也是在变革中持续进化的能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型长脑子了？研究发现LLM中层会自发模拟人脑进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 09:50:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b219daeb-2948-457a-9eb5-94ef85713a83/1768441601006.png" style="width: 700%;" class="fr-fic fr-dib"&gt;生物智能与人工智能的演化路径截然不同，但它们是否遵循某些共同的计算原理？&lt;/p&gt;&lt;p&gt;最近，来自帝国理工学院、华为诺亚方舟实验室等机构的研究人员发表了一篇新论文。该研究指出，大型语言模型（LLM）在学习过程中会自发演化出一种&lt;strong&gt;协同核心（Synergistic Core）&lt;/strong&gt;结构，有些类似于生物的大脑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaDEA4U9DcSVav4UW7TjxlMDPVHrqulibN7OMysqaKAwdlY4gyx13NltQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5138888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528163" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c18b58cd-4b2b-41e6-8e6d-b2de38e46668/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.06851&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYQ7ONWxVbgAo3t1P0569iaJorTz0GAU0KhicicFKo0dCbSw16uqXS2fUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.841995841995842" data-s="300,640" data-type="png" data-w="962" type="block" data-imgfileid="503528161" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a60aba40-7a5b-4c8a-b4b8-f8ee43d60ff5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队利用&lt;strong&gt;部分信息分解（Partial Information Decomposition, PID）&lt;/strong&gt;框架，对 Gemma、Llama、Qwen 和 DeepSeek 等模型进行了深度剖析。&lt;/p&gt;&lt;p&gt;他们发现，这些模型的中层表现出极强的协同处理能力，而底层和顶层则更偏向于冗余处理。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协同与冗余：LLM 的内部架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队将大型语言模型视为分布式信息处理系统，其核心实验设计旨在量化模型内部组件之间交互的本质。为了实现这一目标，研究者选取了 Gemma 3、Llama 3、Qwen 3 8B 以及 DeepSeek V2 Lite Chat 等多种具有代表性的模型系列进行对比分析。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验方法与量化指标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验过程中，研究者向模型输入了涵盖语法纠错、逻辑推理、常识问答等 6 个类别的认知任务提示词。&lt;/p&gt;&lt;p&gt;针对每一个提示词，模型会生成一段 100 个 Token 的回答，实验设备则同步记录下每一层中所有注意力头或专家模块的激活值。&lt;/p&gt;&lt;p&gt;具体而言，研究人员计算了这些输出向量的 L2 范数，以此作为该单元在特定时间步的激活强度数据。&lt;/p&gt;&lt;p&gt;基于这些时间序列数据，研究团队应用了&lt;strong&gt;整合信息分解（Integrated Information Decomposition, ID）&lt;/strong&gt;框架。&lt;/p&gt;&lt;p&gt;这一框架能够将注意力头对之间的交互分解为「持续性协同」和「持续性冗余」等不同原子项。&lt;/p&gt;&lt;p&gt;通过对所有注意力头对的协同值和冗余值进行排名并求差，研究者得到了一个关键指标：&lt;strong&gt;协同-冗余秩（Synergy-Redundancy Rank）&lt;/strong&gt;。该指标能够清晰地标示出模型组件在处理信息时，究竟是倾向于进行独立的信号聚合，还是在进行跨单元的深度集成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;跨模型的空间分布规律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验数据揭示了一个在不同架构模型中高度一致的空间组织规律。在归一化后的模型层深图中，协同分布呈现出显著的「倒 U 型」曲线 ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaTPhh9z3Alm9dSFwo6lYYRBAPddsHoOPqyPJFfCmYDibxd4G7iasJEbAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8357588357588358" data-s="300,640" data-type="png" data-w="962" type="block" data-imgfileid="503528162" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/10673250-d9c8-46d7-8ffd-c92ebb7dc50a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;冗余外周（Redundant Periphery）&lt;/strong&gt;：模型的早期层（靠近输入端）和末期层（靠近输出端）表现出极低的协同秩，信息处理以冗余模式为主。在早期层，这反映了模型在进行基本的解词元化（Detokenization）和局部特征提取；而在末期层，则对应着 Token 预测和输出格式化的过程。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;协同核心（Synergistic Core）&lt;/strong&gt;：模型的中层则展现出极高的协同秩，形成了核心处理区。例如，在对 Gemma 3 4B 的热图分析中，中间层的注意力头之间表现出密集且强烈的协同交互，这正是模型进行高级语义集成和抽象推理的区域。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;架构差异与一致性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，这种「协同核心」的涌现并不依赖于特定的技术实现。&lt;/p&gt;&lt;p&gt;在 DeepSeek V2 Lite 模型中，研究者即使是以「专家模块」而非「注意力头」作为分析单位，依然观察到了相同的空间分布特征。&lt;/p&gt;&lt;p&gt;这种跨架构的收敛性表明，&lt;strong&gt;协同处理可能是实现高级智能的一种计算必然&lt;/strong&gt;，而非单纯的工程巧合。&lt;/p&gt;&lt;p&gt;这种组织模式与人脑的生理结构形成了精确的映射：&lt;strong&gt;人脑的感官和运动区域同样表现出高冗余性，而负责复杂认知功能的联合皮层则处于高协同的「全局工作空间」中心。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能的涌现：学习驱动而非架构使然&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个关键的问题在于：这种结构是 Transformer 架构自带的，还是通过学习习得的？&lt;/p&gt;&lt;p&gt;研究人员通过分析 Pythia 1B 模型的训练过程发现，在随机初始化的网络中，这种「倒 U 型」的协同分布并不存在。随着训练步数的增加，这种组织架构才逐渐稳定形成。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaZO93YoRoCFrUysSX6dr975lEGm4ZBY9r3nDpKxeYokWNHMYRTHuibGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528164" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f6fe5bb0-ab9f-473d-9848-a274a9a812fe/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着，&lt;strong&gt;协同核心是大模型获得能力的标志性产物&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在拓扑性质上，协同核心具有极高的「全局效率」，有利于信息的快速集成；而冗余外周则表现出更强的「模块化」，适用于专门化处理。这种特征再次与人类大脑的网络架构形成了精确的平行关系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协同核心的功能验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证协同核心是否真的驱动了模型行为，研究团队进行了两类干预实验：消融实验和微调实验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;消融实验&lt;/strong&gt;：研究发现，消融那些高协同性的节点，会导致模型出现灾难性的性能下降和行为背离，其影响远超随机消融或消融冗余节点。这证明协同核心是模型智能的核心驱动力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaNVn394A9Tibic2UUF4Dsc3GULWFE2bJ9XfichATbjdeX6sEibOKso9uiaxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5768518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528165" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/01e62eda-ea60-4eef-811f-0d3eda786661/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;微调实验&lt;/strong&gt;：在强化学习微调（RL FT）场景下，仅针对协同核心进行训练，获得的性能提升显著优于针对冗余核心或随机子集的训练。有趣的是，在监督微调（SFT）中这种差异并不明显。研究者认为，这反映了 RL 促进通用化而 SFT 更多倾向于记忆的特性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsajfmJSoD0RbpSliaWiaUZQeqvrrgcia2FHmvjiaXg380QdqR4bX3QeCNicqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.674074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528166" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/72dc4178-af5b-42ba-a834-fa76d570b62a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项研究为大模型的可解释性开辟了新路径。它表明，我们可以从「自上而下」的信息论视角来理解模型，而不仅仅是「自下而上」地寻找特定的电路。&lt;/p&gt;&lt;p&gt;对于 AI 领域，识别协同核心有助于设计更高效的压缩算法，或者通过更有针对性的参数更新来加速训练。对于神经科学，这提供了一种计算上的验证，预示着协同回路在强化学习和知识迁移中可能扮演着至关重要的角色。&lt;/p&gt;&lt;p&gt;大模型虽然基于硅基芯片和反向传播算法，但在追求智能的过程中，它们似乎不约而同地走向了与生物大脑相似的组织模式。这种智能演化的趋同性，或许正是我们揭开通用智能奥秘的关键线索。&lt;/p&gt;&lt;p&gt;更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>性能提升60%，英特尔Ultra3这次带来了巨大提升</title>
      <description>&lt;![CDATA[Intel 18A 工艺来了。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Wed, 14 Jan 2026 16:33:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;上周，英特尔在 CES 2026 上正式发布了代号为 Panther Lake 的 Core Ultra Series 3 处理器，成为了本次展会的绝对主角。它终于让 PC 芯片摆脱了多年挤牙膏的困境，在 CPU、GPU 和 NPU 架构上均带来了显著的「代际」升级。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6f39a96a-2809-4c8e-91bb-2e03b5a1dc15/image__7_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这是首款基于英特尔自家 18A 工艺（等效 1.8 纳米级别）大规模量产的消费级芯片，桌面端和移动端版本同期推出。对英特尔来说，新制程与新芯片具有重大意义，标志着该公司重新引领芯片性能与方向的开始。&lt;/p&gt;&lt;p&gt;CES 之后，英特尔对下一代酷睿 Ultra 平台作了完整的技术概述。&lt;/p&gt;&lt;p&gt;在新一代 Panther Lake 产品上，能效核 Darkmont 与性能核 Cougar Cove，GPU（升级版 Xe3）都是新架构，引入了第五代 NPU 用于 AI 加速，缓存、图像处理单元都是新的，芯片整体采用了基于 chiplet 的封装，使用 Foveros-S 堆叠技术。&lt;/p&gt;&lt;p&gt;具体来说，每颗 Panther Lake 主要由三种小芯片组成：基于 Intel 18A 的计算芯片、基于 Intel 3 或台积电 N3E 工艺的图形芯片，以及基于台积电 N6E 的平台控制器芯片。每个配置都采用了 Foveros-S 封装，安装在同一个基板上，CPU、GPU、I/O 芯片会被集成到一个紧凑的 SoC 布局中。&lt;/p&gt;&lt;p&gt;英特尔表示，Panther Lake 会具备 Lunar Lake 的能效与 Arrow Lake 的性能，CPU 最多拥有 16 个核心，性能相比上代提升 60%（比之前宣称的 50% 又有提升），低功率情况下，单核性能较上一代提升 40%。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f8892235-e355-44a5-b018-7781dea64214/0bd098b364420f3591649e3d7592997d.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在 CPU 上，Panther Lake 集成了三种类型的核心，Cougar Cove P 核心在 Lion Cove 的基础上进行了改进，增加了 TLB 的容量，配备了更精确的多级分支预测器。每个 P 核心包含 3MB 的 L2 缓存和 256K 的 L1 缓存。Darkmont E 是上一代 Skymont 的升级版，支持 9 路解码，更大的乱序执行窗口和 26 个调度端口。&lt;/p&gt;&lt;p&gt;Panther Lake 还新增了一个四核低功耗集群，它基于 Darkmont 架构，直接位于计算单元上，用于处理后台或轻量级负载。&lt;/p&gt;&lt;p&gt;英特尔表示，重新设计的内存子系统支持 DDR5-7200 与 LPDDR5X-9600，相比前几代产品带宽和容量更高，计算单元可在核心集群上共享 18MB 的 L3 缓存，并连接到 8MB 的内存端缓存，从而减少 DRAM 流量和延迟。&lt;/p&gt;&lt;p&gt;GPU 方面，新一代芯片搭载了全新的 Xe3 架构核显，拥有最多 12 个 Xe 核心，官方宣称游戏性能相比上一代（Lunar Lake）提升高达 77%，同功耗水平性能提升 50%，其性能甚至超越了部分独立显卡（如部分 RTX 4050 移动版）。当然，这一代核显的性能相较 AMD 的同档产品也有巨大的优势。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4ac70684-fa6c-4f23-b65c-1326c49cfa9f/32802905bd061663d7b9a28bfd85de03.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;可见在魔兽世界、群星等游戏上，以后我们基本可以用集显玩了。我们甚至可以展望 Ultra 3 发布会，会有搭载集显的全能笔记本出现。&lt;/p&gt;&lt;p&gt;12 核心的 Xe3 版本使用台积电 N3E 工艺打造，提升了 L1、L2 缓存容量，改进了各向异性过滤和模板渲染速率，并配备了增强型光线追踪单元和动态光线管理功能。&lt;/p&gt;&lt;p&gt;Panther Lake 还首次搭载了 XeSS 3 多帧生成技术，可以通过生成多个插帧的方法实现更加流畅的游戏体验。英特尔计划在其图形软件中增加帧生成覆盖控制功能，从而让用户可以强制指定特定的帧生成模式。&lt;/p&gt;&lt;p&gt;在 AI 计算方面，Panther Lake 采用了更加均衡的 XPU 设计，可实现更高水平的 AI 计算加速，总平台算力超过了 180TOPS。其中 NPU 算力提升至 50 TOPS，支持 FP8、INT8 等量化格式，MAC 吞吐量翻倍，功耗降低 40% 以上。&lt;/p&gt;&lt;p&gt;利用新的线程管理器，Panther Lake 能够适应不断变化的工作负载，在游戏时提升约 10% 的帧率。通过优化 Windows 电源模式，新的芯片在相同的功耗限制下可以把性能提升大约 20%。&lt;/p&gt;&lt;p&gt;Panther Lake CPU 预计将提供八核心 + 两个十六核心的版本，命名为英特尔酷睿 Ultra 处理器第三代（3xx）。另外在连接方面，这一代芯片支持最多 20 条 PCIe 通道，集成雷电 4；无线连接方面则支持 Wi-Fi 7 Revison 2 和蓝牙 6.0Core。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fe0d6dd0-ce58-40ed-bc0f-3b4de9d5463d/image__8_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;除了个人电脑领域之外，Panther Lake 的应用范围还扩展到了包括机器人在内的边缘应用领域。英特尔提供了 AI 软件套件与参考板卡，能够帮助复杂 AI 应用的客户快速上手，利用新一代 AI 芯片实现控制和 AI 感知，并快速开发机器人。&lt;/p&gt;&lt;p&gt;英特尔表示，得益于 18A 工艺，Panther Lake 芯片的能效比进一步优化，官方宣称部分机型续航可达 27 小时。再加上性能的提升，新一代芯片在轻薄笔记本和游戏本上都会带来更好的体验。&lt;/p&gt;&lt;p&gt;预计搭载 Panther Lake 的笔记本电脑在今年 1 月就会大批量上市。&lt;/p&gt;&lt;p&gt;英特尔还预告了 30W 功率掌机版本的 Panther Lake 的信息，不过更多信息有待公布。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8255694f-7971-44f0-919c-b7c4137e0cae/image__9_.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;随着 Ultra 第三代产品的推出，AI PC 距离实用化更近了一步。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>继宇树后，唯一获得三家大厂押注的自变量：具身模型不是把DeepSeek塞进机器人</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:45:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/169694b5-8cac-4291-8aa4-aae419d72237/1768373003246.png" style="width: 700%;" class="fr-fic fr-dib"&gt;国内具身智能，接下来可能是「大脑」的战场了。&lt;/p&gt;&lt;p&gt;2026 开年，&lt;strong&gt;自变量机器人传出融资消息，字节、红杉出手，融资额达到 10 亿。&lt;/strong&gt;虽然自变量是一家软硬一体的公司，但这场融资背后，真正说服投资人的可能是他们对于机器人「大脑」的思考。&lt;/p&gt;&lt;p&gt;和之前的 locomotion（移动）、navigation（导航）战场不同，&lt;strong&gt;「大脑」所主导的 manipulation（操作）涉及频繁的物理世界交互，随机性、不确定性充斥着每一个看似简单的任务&lt;/strong&gt;。这也是为什么，在我们看了多年的机器人跳舞、跑酷、玩杂技之后，机器人在自主操作上依然没有拿出一个技惊四座的 demo。而这个「自主操作」，才是决定机器人能否大规模走入人类世界的关键。&lt;/p&gt;&lt;p&gt;在自变量看来，「操作」这类任务的复杂性决定了，机器人必须有一个由「物理世界基础模型」所支撑的「大脑」。这个「大脑」不是像很多人想的「把 DeepSeek 塞进宇树」那么简单，它不是 AI 模型的「应用层」，而是独立、平行于语言大模型、多模态模型等虚拟世界模型的新范式。&lt;/p&gt;&lt;p&gt;对于这个新范式应该是什么样子、如何去打造，自变量已经有了一套体系化的方法论，并且自研出了一些成果。这些大胆的尝试，或许会为具身智能领域带来新的变量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;具身智能 &amp;ne; AI 模型下游应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们知道，最近几年机器人「大脑」的进化主要还是依赖语言模型和多模态模型。于是很多人就认为，具身智能是 AI 模型的一个应用方向。但自变量 CEO 王潜曾在多个场合强调，这个定位存在偏差。&lt;/p&gt;&lt;p&gt;举例来说，图中有两个矿泉水瓶，一个瓶盖拧紧，一个没有完全拧紧。只靠视觉去看，它们在图像里差别很小，但一旦把它们拿起来、翻转或倾倒，结果却完全不同 &amp;mdash;&amp;mdash; 一个会漏水，一个不会。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicoUZK5tD2uzpKljicRrS1td1mupIF4No3N72L7vKoib51BuUbtDBktT1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528184" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/0969c240-aa4d-4d28-b79c-025910ff56b8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;物理世界里真正关键的信息，往往就藏在这些「看不出来但会影响行为」的细节中。&lt;/strong&gt;这些差异只有在与世界发生真实交互时才会暴露出来，而不是静态观察就能轻易判断。&lt;/p&gt;&lt;p&gt;更重要的是，这类信息往往并不会在当下立刻给出反馈。比如拧瓶盖这个动作本身，并不会产生任何可见变化，真正的差异要等到下一步、甚至再下一步操作时才显现出来。对模型来说，这意味着它必须能够把一连串感知、动作和结果在时间上串联起来理解，而不是只处理某一帧画面、某一个瞬间的输入输出。&lt;/p&gt;&lt;p&gt;这正是物理世界对智能提出的一个隐性要求：&lt;strong&gt;模型不仅要能感知，还要能处理足够长的行为序列，理解因果是如何在时间中逐步展开的。&lt;/strong&gt;否则，它就永远学不会那些「现在看不出来、但之后会出问题」的物理规律。&lt;/p&gt;&lt;p&gt;而在很多真实任务中，问题甚至不只是时间跨度变长这么简单。机器人往往需要在行动之前，对未来进行某种形式的推演。比如在倒水之前，它需要判断瓶子会不会漏；在整理桌面之前，它需要决定先拿走什么、再放回什么。这类判断并不是对当前状态的直接反应，而是对「接下来会发生什么」的内部演算。&lt;/p&gt;&lt;p&gt;也正因为如此，单纯依赖静态信息训练出的语言模型或多模态模型，在物理世界里往往显得力不从心。它们并不真正理解「拧紧」和「没拧紧」在物理后果上的差别，也难以应对充满连续变化、随机扰动和部分不可观测的现实环境。&lt;/p&gt;&lt;p&gt;在自变量看来，这并不是靠给现有模型打补丁就能解决的问题，而是指向了一个更底层的结论：&lt;strong&gt;我们需要一种「生于物理世界、用于物理世界」的基础模型。这种模型应当与语言模型、多模态模型平行存在，而不是作为它们的下游应用。&lt;/strong&gt;自变量的目标，正是要打造这样一个基础模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建物理世界基础模型&amp;mdash;&amp;mdash;要端到端、要做通才模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要打造这个模型，自变量认为有两点非常重要：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一是要有一个统一的架构，因为真正的物理智能需要的是整体性的、具身的理解，而不是模块化的知识拼接。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;举个例子，人类在使用锤子时，注意力不在「这是一个锤子」「锤子有多重」，而是在木头、钉子和要完成的目标上。锤子作为一种工具，会被纳入行动本身，在认知中「隐退」。但对于现在很多机器人来说，情况恰恰相反，每一次使用工具，它们都要重新经历一整套流程：看见这是锤子，理解锤子的用途，规划怎么用，再执行动作。自变量认为，这种方式永远无法达到人类那种直觉的工具使用境界。&lt;/p&gt;&lt;p&gt;归根结底，这种局面是把模型拼接起来的分层架构所带来的 &amp;mdash;&amp;mdash; 视觉模块先把世界压缩成向量，语言模块再接手理解，规划模块再根据语言输出动作。一套流程下来，模块之间彼此「看不见」「听不见」对方真正关心的东西。每跨一次模块，细节、关联和物理直觉都会被削掉一层。这就像把一幅油画描述给盲人，再让盲人转述给聋人。&lt;/p&gt;&lt;p&gt;这就不难解释，为什么自变量从成立第一天就是「端到端」路线的坚定信徒。他们看到的是这一路线的底层逻辑：信息必须在一个统一的空间里流动，系统才能发现不同东西之间深层的关联。早期，这一选择饱受质疑，但如今，Google Robotics、Physical Intelligence 等头部具身智能团队也都走到了这条路上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二是模型要足够通用，因为只有这样才能学到物理世界的共性结构。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这条路已经被语言模型走过一遍。大家发现，相比于最初针对单一任务分别做专用模型，把翻译、问答、写作、推理等任务放进同一个模型里，反而能让模型学到更底层的逻辑和常识。物理世界也是一样，当模型同时学习足够多、足够杂的任务，它会被迫去发现这些任务背后的共性结构 &amp;mdash;&amp;mdash; 物理规律、物体属性、因果关系。一旦掌握了这些共性，模型学新任务所需的数据量就会骤降，甚至出现「涌现」。&lt;/p&gt;&lt;p&gt;提到语言模型，它的成功其实还有一个常被忽视的关键：它找到了一个极好的损失函数 &amp;mdash;&amp;mdash; 预测下一个词。这个看似简单的目标，能够把海量文本中的结构、逻辑、常识全部压缩进模型里。&lt;/p&gt;&lt;p&gt;但机器人面对的是一个更复杂的局面，&lt;strong&gt;它的损失函数应该预测什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;自变量认为，不能只停留在「预测动作」。如果只预测动作，模型很容易沦为一个「模仿者」，它只学会了手势的形状，却不懂得背后的原因。真正的突破口在于：将损失函数从「动作预测」升级为「多模态状态的预测」。&lt;/p&gt;&lt;p&gt;当模型试图预测「如果我推倒这个杯子，下一秒视觉画面会如何变化、指尖的触感会如何消失」时，它实际上是在强迫自己理解因果律，把物理世界的复杂性压缩进模型里。&lt;/p&gt;&lt;p&gt;这也解释了为什么自变量的 WALL-A 模型不只输出动作。它还能用语言和人对话，能根据图片重建三维环境，能像世界模型一样预测未来。这些能力看似五花八门，但背后的逻辑是一致的：如果一个模型真正理解了物理世界，它就应该能用各种方式表达这种理解，无论是控制机械臂，还是描述它在做什么，还是预测物体会怎么滚动。在这个模型身上，我们已经能够看到自变量所追求的物理世界基础模型的雏形。&lt;a href="https://mp.weixin.qq.com/s/22w4L3Edq0rkp8A-MV-wHg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4691a136-e40b-4b35-bc70-0e6d574f0178/1768373097434.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;以外卖即时配送任务为例，自变量的机器人在完全开放的室外及室内环境中执行移动操作任务，应对人流、环境变化、突发干扰等不确定因素，从外卖柜取箱、拆箱、回收、室内导航、电梯交互到最终交付，机器人基于统一的端到端具身智能模型完成超长序列操作，体现了自变量的具身智能模型具备极强的泛化能力，标志着具身智能首次具备在真实商业场景中稳定运行的能力。该场景首次让VLA模型在高频、强约束、强时效的真实环境中长期运行，完成从实验室验证到商业级部署的关键跨越。&lt;/section&gt;&lt;p&gt;&lt;strong&gt;开源有得选 &amp;nbsp;但依然要坚持「自研」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除了对于「机器人大脑」这个问题的独特思考，自变量这家公司在业内其实还有一个非常罕见的特质：坚持自研，尤其是基础模型的自研。&lt;/p&gt;&lt;p&gt;在很多公司看来，这点可能暂时还没有那么必要或者说「紧迫」，毕竟 Physical Intelligence 开源的 Pi0 和 Pi0.5、英伟达开源的 GRoot 等都是不错的选择，也是很多具身智能厂商的主流选择。&lt;/p&gt;&lt;p&gt;但自变量对「自研」的坚持，更多来自一个底层判断：具身智能的下一阶段竞争，本质上还是数据闭环构建的基础模型与模型进化能力的竞争。模型不掌握在自己手里，竞争无从谈起。&lt;/p&gt;&lt;p&gt;一路目睹语言模型演进的从业者应该对此有着深刻的感受 &amp;mdash;&amp;mdash; 这个行业最大的变量，往往藏在基础模型的内核里。过去两年，Cursor 等应用层产品风头无两，但它们的「智能」几乎完全依赖 Claude 或 GPT 的能力边界。上游模型一次升级，下游应用被动重构；API 定价一旦调整，成本结构随之改变。&lt;/p&gt;&lt;p&gt;对于机器人而言，这个问题还要更深一层：真实物理世界的重量、阻力、空间关系，无法从互联网文本中习得，必须从数据采集到模型架构建立一套完整的自研体系。选择在基础层投入，看似是一条更慢的路，但历史反复证明：&lt;strong&gt;原始创新者定义规则，跟随者只能适应规则。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，自变量共有两款核心模型：主模型 WALL-A 和轻量化模型 WALL-OSS，均为自研成果。这个系列模型的核心架构首创了 VLA 与世界模型深度融合的系统范式，而且率先实现了具身多模态思维链。&lt;/p&gt;&lt;p&gt;值得注意的是，自变量还将 WALL-OSS 开源了出来，并围绕&amp;nbsp;WALL-OSS 等全球具身开源项目组织了一个名为「&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzkzOTc1NjE3Nw==&amp;mid=2247484684&amp;idx=1&amp;sn=319ed37b206dc726e20604c44b029a59&amp;scene=21&amp;click_id=52#wechat_redirect" target="_blank"&gt;具亮计划&lt;/a&gt;」的黑客松。该计划鼓励开发者利用具身基础开源模型，从数据采集、策略训练到真机部署跑通完整链路，最终让机器人在真实场景里动手完成任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicO5cf2dNtjwtcPicFptXA7KSyLgJmPQSekBBhqXF5m5UcXM2YEhs1wuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4083333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528272" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6d1054a7-fae4-477d-a76d-4e7cdc380dba/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在国内，这种活动也是非常有益的尝试，因为从语言模型发展来看，整个技术社区的发展离不开开源文化，具身智能领域也需要自己的 DeepSeek。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重走婴儿的路 &amp;nbsp;物理世界没有捷径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;看到语言模型的蓬勃发展，很多人可能都会思考一个问题，为什么机器人迟迟等不来它们的涌现时刻？&lt;/p&gt;&lt;p&gt;一个可能的答案是：语言本身就是一种高度压缩的符号系统，人类已经用几千年的时间把世界的复杂性「预处理」成了文字。模型要做的，只是学会这套现成的编码规则。但物理世界没有这样的捷径。重力、摩擦、碰撞、形变，这些规律从未被谁显式地写下来，它们散落在每一次交互的细节里。&lt;/p&gt;&lt;p&gt;这也意味着，物理世界基础模型的构建，某种程度上是在重走人类婴儿的路。物理世界基础模型要学的，是那些人类「做得出但说不清」的东西，这可能才是智能更本源的形态。&lt;/p&gt;&lt;p&gt;这条路注定漫长，也足够迷人。而自变量正走在这条路上。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Sebastian Raschka 2026预测：Transformer统治依旧，但扩散模型正悄然崛起</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:41:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="2" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/79d32e9f-5d40-430d-9bc0-ccba6a68bdc2/1768372696097.png" style="width: 700%;" class="fr-fic fr-dib"&gt;站在 2026 年的开端回望，LLM 的架构之争似乎进入了一个新的微妙阶段。过去几年，Transformer 架构以绝对的统治力横扫了人工智能领域，但随着算力成本的博弈和对推理效率的极致追求，挑战者们从未停止过脚步。&lt;/p&gt;&lt;p data-path-to-node="3"&gt;知名 AI 研究员 Sebastian Raschka 的最新洞察中，他不仅回应了关于「Transformer 是否会被取代」的年度终极之问，更敏锐地捕捉到了近期业界的一个重要转向：从单纯追求模型参数的「大力出奇迹」，转向了混合架构与效率微调的精细化战争。&lt;/p&gt;&lt;p data-path-to-node="4"&gt;同时，文章还探讨了一个极具潜力的变量：扩散语言模型。这类模型在 Google 等巨头的布局下会有怎样的表现？它们在「工具调用」上的天然缺陷是否会成为阿喀琉斯之踵？而在高质量数据日益枯竭的今天，扩散模型又是否能凭借「超级数据学习者」的特性，成为打破数据墙的关键？&lt;/p&gt;&lt;p data-path-to-node="5"&gt;以下内容编译自 Sebastian Raschka 的最新博文，并结合文中提及的前沿论文及往期深度分析进行了系统性拓展，以便读者获取更完整的上下文视角。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="953" data-imgfileid="503527971" data-ratio="0.4" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkABcAaiaj7tMDQEx3dM7KF4Jrw0mFgSpRaT6lfyDicxWYtOGCN5Bh7DK4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="2382" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/29f304a9-fc0f-4360-8fab-0d3b641f93a9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="6"&gt;博客地址：https://x.com/rasbt/status/2010376305720594810&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="8"&gt;最近几周，我经常被问到的一个问题是：&lt;strong&gt;在 2026 年，我们是否会看到自回归 Transformer 架构（即标准的 LLM）的替代方案。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;就目前而言，我坚信 &lt;strong&gt;Transformer 在未来（至少一到几年内）仍将保持其在 SOTA 性能方面的地位。&lt;/strong&gt;它是当前 AI 生态系统的基石，拥有最成熟的工具链和优化方案。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;但是，情况确实会发生一些微调。这并不是说架构会一成不变，而是这种变化更多体现在「效率」和「混合」上，而非彻底的推倒重来。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;效率战争：混合架构与线性注意力的崛起&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;临近去年年底，我们看到业界更加关注&lt;strong&gt;混合架构&lt;/strong&gt;以及如何提高其效率。当然，这并不是什么新想法，但近期来自顶尖实验室的发布表明，目前的侧重点已明显向此倾斜。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;我们回顾一下 DeepSeek V3 以及随后的 R1，它们展示了&lt;strong&gt;混合专家模型（MoE）和多头潜在注意力（MLA）&lt;/strong&gt;的强大之处。DeepSeek V3 通过 MLA 显著减少了推理时的 KV Cache 占用，而 MoE 架构则允许模型在拥有 6710 亿参数的同时，每次推理仅激活 370 亿参数。这种在保持模型巨大容量的同时极致压缩推理成本的设计思路，正是 2025 年末到 2026 年的主旋律。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;但这还不是全部。除了 MoE，我们看到了更激进的效率尝试，例如&lt;strong&gt;&amp;nbsp;Qwen3-Next、Kimi Linear、Nvidia Nemotron 3&lt;/strong&gt;，以及采用了稀疏注意力机制的 DeepSeek V3.2。（如果您对更多细节感兴趣，我在之前的《Big LLM Architecture Comparison》一文中对此进行了报道。）&lt;img data-aistatus="1" data-height="1530" data-imgfileid="503527972" data-ratio="0.6222222222222222" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA7oZuANMs0u5wsmYEwKXUzWj441D8szMn1tI5Hv79Og9eD2fia7O1ibxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="2460" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a2c82762-e812-4600-8f43-5e78767de977/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 带有这类效率调整的 Transformer 架构示意图。&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;相关链接：https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="16"&gt;&lt;b data-index-in-node="0" data-path-to-node="16"&gt;为什么大家都在卷「线性注意力」或「稀疏注意力」？&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;标准的 Transformer 注意力机制（Scaled Dot-Product Attention）具有 O(N^2) 的复杂度，这意味着随着上下文长度的增加，计算成本呈二次方爆炸式增长。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="18,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,0,0"&gt;Qwen3-Next&lt;/b&gt; 和 &lt;b data-index-in-node="13" data-path-to-node="18,0,0"&gt;Kimi Linear&lt;/b&gt; 采用了一种混合策略：它们并非完全抛弃标准注意力，而是将高效的线性层（如 Gated DeltaNet）与全注意力层以一定比例（如 3:1）混合。这种设计试图在捕捉长距离依赖（全注意力的强项）和推理速度（线性层的强项）之间找到最佳平衡点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="18,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,1,0"&gt;DeepSeek V3.2&lt;/b&gt; 则引入了稀疏注意力，通过只计算最重要的 Token 之间的相互作用，进一步降低了计算开销。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19"&gt;这些「微调」表明，2026 年的竞争不再仅仅是看谁的模型更聪明，而是看谁能在更长的上下文、更低的延迟下提供同等的智能。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;strong&gt;扩散语言模型：速度与代价的博弈&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;话说回来，除了 Transformer 的变体，&lt;strong&gt;扩散语言模型&lt;/strong&gt;怎么样？&lt;/p&gt;&lt;p data-path-to-node="22"&gt;扩散语言模型之所以具有吸引力，是因为它们能够以相对快速且低廉的成本生成 Token。与自回归模型（AR）那种「一个字接一个字」的串行生成不同，&lt;strong&gt;扩散模型采用的是并行生成&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="23"&gt;想象一下，自回归模型像是一个人在打字，必须打完上一个字才能打下一个；而扩散模型更像是在冲洗一张照片，整段文字从模糊的噪声中同时显现，经过数次「去噪」迭代后变得清晰。&lt;/p&gt;&lt;p data-path-to-node="24"&gt;我前阵子在《Beyond Standard LLMs》一文中对此多写了一些。简而言之，我认为 2026 年我们会看到更多相关内容，Google 可能会推出 &lt;strong&gt;Gemini Diffusion&lt;/strong&gt; 作为其更便宜的 Flash 模型的替代品。Google 已经在其技术博客中暗示了这一点，强调其生成速度「明显快于我们目前最快的模型」。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24"&gt;相关链接：https://magazine.sebastianraschka.com/p/beyond-standard-llms&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;然而，虽然扩散语言模型的优势在于它们可以并行生成 Token，但这同时也是一个巨大的缺点。因为由于并行生成的特性，&lt;strong&gt;它们无法在响应链中原生地整合工具调用&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;在自回归模型中，模型可以生成「调用计算器」的指令，暂停，等待结果，然后再继续生成。而在扩散模型中，整个响应是同时生成的，很难在中间插入一个外部工具的交互步骤。这使得它们在作为智能体使用时面临巨大挑战。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527973" data-ratio="0.5625" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuulUiadnlby61pcX7bDQBmb6pENqfFF0ibzaGCRNFa8fQB6yTnUCX2Tw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7326952b-8424-4118-9941-74e762097b73/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27,0"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 文本扩散过程示例。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;此外，虽然众所周知文本扩散推理效率更高，但最近的研究也表明，如果你为了提升质量而增加去噪步数以匹配自回归模型的性能，那么最终的计算预算其实是相差无几的。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;&lt;strong&gt;数据枯竭时代的「超级学习者」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="30"&gt;那么，我想表达什么呢？既然扩散模型有这些缺陷，为什么我还认为它值得关注？&lt;/p&gt;&lt;p data-path-to-node="31"&gt;我原本计划讨论一月份发布的近期一系列有趣的研究，但我还是想简要重点介绍一篇我在「待读论文」清单上的、2025 年 11 月的有趣论文，它强调了扩散语言模型的一个有趣优势：《Diffusion Language Models are Super Data Learners》。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2511.03276&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1760" data-imgfileid="503527974" data-ratio="1.049074074074074" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAwXOt5dibyF6Lx8pia0JTDF4hAQj1kWnYic5p9w2LkUPTlO688RRLYzE8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" data-width="1678" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f51d529a-149b-4dba-9da1-16643d5e78e8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;来自论文《Diffusion Language Models are Super Data Learners》的带注释图表。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="33"&gt;这篇论文提出了一个在 2026 年至关重要的观点：&lt;b data-index-in-node="25" data-path-to-node="33"&gt;当高质量数据变得稀缺时，扩散模型可能是更好的学习者。&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;众所周知，互联网上的高质量文本数据正在接近枯竭。对于自回归（AR）模型来说，通常我们只让模型把数据「看」一遍（1 Epoch）。如果让 AR 模型反复在同一份数据上训练，它们很容易&lt;strong&gt;过拟合&lt;/strong&gt;，即死记硬背训练数据，导致在未见过的新任务上表现下降。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;然而，上述论文表明，当进行多 Epoch 训练时，文本扩散模型的表现可能优于标准的自回归（AR）大语言模型。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;根据论文的研究结果，在严格控制的预训练设置下，当唯一数据量有限时，通过增加训练轮数，扩散语言模型的表现持续超越了自回归模型。&lt;/p&gt;&lt;p data-path-to-node="37"&gt;这一现象被称为「Crossover（交叉点）」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="38,0,0"&gt;当数据量充足时，AR 模型学得更快。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="38,1,0"&gt;但当数据受限时，DLM 是最终的赢家。例如，一个 10 亿参数的 DLM 模型，仅仅通过反复训练 10 亿个 Token（这在今天看是非常小的数据量），在 HellaSwag 和 MMLU 基准测试上分别达到了 &amp;gt;56% 和 &amp;gt;33% 的准确率，且没有使用任何特殊技巧。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="39"&gt;为什么会这样？ 论文归结为三个因素：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="40,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,0,0"&gt;任意顺序建模&lt;/b&gt;：AR 模型被迫只能从左到右学习，而扩散模型可以学习文本中任意位置之间的依赖关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,1,0"&gt;超高密度计算&lt;/b&gt;：通过迭代的双向去噪，DLM 在训练时实际上对每个样本进行了更深度的压榨。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="40,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="40,2,0"&gt;内置的蒙特卡洛增强&lt;/b&gt;：扩散过程本身就是一种数据增强。同一个句子，每次加噪的方式都不一样，相当于把一条数据变成了无数条变体。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="41"&gt;更有趣的是，论文发现，对于 DLM 来说，&lt;strong&gt;验证集损失的上升并不意味着下游能力的下降&lt;/strong&gt;。即便模型在验证集上看起来「过拟合」了，它在实际任务（如代码生成、推理）上的表现仍在提升。&lt;/p&gt;&lt;p data-path-to-node="42"&gt;由于成本原因，过去没有人会在多个 Epoch 上训练大语言模型。但在数据枯竭的今天，如果我们不得不进行多 Epoch 训练，扩散模型似乎提供了一条新出路。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;这确实是有趣的结果！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>端到端智驾新SOTA | KnowVal：懂法律道德、有价值观的智能驾驶系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:34:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/d749f0ab-f5b6-4259-9d5a-69576200c90d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;一个智能驾驶系统，在迈向高阶自动驾驶的过程中，应当具备何种能力？除了基础的感知、预测、规划、决策能力，如何对三维空间进行更深入的理解？如何具备包含法律法规、道德原则、防御性驾驶原则等知识？如何进行基本的视觉 - 语言推理？如何让智能系统具备世界观和价值观？&lt;/p&gt;&lt;p&gt;来自北京大学王选计算机研究所王勇涛团队的最新工作 KnowVal 给出了一种有效可行的方案。&lt;/p&gt;&lt;p data-path-to-node="2" data-pm-slice="0 0 []"&gt;&lt;b data-index-in-node="0" data-path-to-node="2"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaEMKZM72IQ9tCCpEACHFjVZ03xUbFuTgBb2jQ2mmpOAicQ16Dmribah6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.262037037037037" data-type="png" data-w="1080" data-imgfileid="503528145" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/097a3cc2-e743-4d6d-bd00-416e2cf5b377/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="4,0,0"&gt;论文标题： KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="4,0,0"&gt;论文链接：https://arxiv.org/abs/2512.20299&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="4,2,0"&gt;本工作提出了一种新型自动驾驶系统 KnowVal，该系统通过感知模块与知识检索模块的协同作用，实现视觉 - 语言推理能力。&lt;/p&gt;&lt;p data-path-to-node="4,2,0"&gt;团队构建了涵盖交通法规、防御性驾驶原则与道德考量的综合驾驶知识图谱，并为其开发了高效的基于大型语言模型的检索机制。通过设计集成世界模型与价值模型的规划器，从而实现价值对齐决策。同时构建了人类偏好数据集用于训练价值模型。&lt;/p&gt;&lt;p data-path-to-node="4,5,0"&gt;实验表明，KnowVal 兼容现有的端到端和 VLA 方法，在 nuScenes 数据集上实现了最低碰撞率，并在 Bench2Drive 基准测试中取得了最先进的性能表现。&lt;/p&gt;&lt;p data-path-to-node="4,5,0"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicFZCBCia2pic36dtxra88bsalM6SNTNBHmT5FYDffycTPxqFCibHdNTSSmDNAssslc3dXlFxgjRyAmA/640?wx_fmt=other&amp;from=appmsg#imgIndex=2" alt="image.png" data-ratio="0.2851851851851852" data-type="other" data-w="1080" data-imgfileid="503528146" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/06373dc6-325d-4cc6-bcb7-e64f191a04ec/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="6"&gt;&lt;strong&gt;KnowVal 系统框架：开放三维感知与知识检索相互引导的视觉 - 语言推理&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="7"&gt;相比于当前主流的端到端自动驾驶系统和视觉 - 语言 - 动作（VLA）系统，KnowVal 将视觉 - 语言范式升级为开放三维感知 - 知识检索范式，并通过感知和检索的相互引导，实现了基础的视觉 - 语言推理：&lt;/p&gt;&lt;p data-path-to-node="7"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsa2aXp9HiaDyibt71fgCIKTsmx0EAV9cSnwNXurJ1GG9K8NTmsgQmQNjrw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.49444444444444446" data-type="png" data-w="1080" data-imgfileid="503528147" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/71bf2234-0994-4a69-86fd-5863bf8691c6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;&lt;b data-index-in-node="0" data-path-to-node="8"&gt;检索引导的开放世界感知&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;通过自动驾驶领域专用感知和开放式三维感知，能够抽取常见实例与长尾实例的 3D 目标检测结果与实例特征，以及面向开放世界的全场景占据栅格预测与体素特征，抽取特征保证了整个系统的特征传递与可导；同时，通过利用轻型 VLM 实现的抽象元素理解，能够对上一时间帧知识检索分支要求的信息进行补充，针对「是否是隧道、桥梁场景？是否是夜间场景？」等抽象概念进行自然语言描述。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;&lt;b data-index-in-node="0" data-path-to-node="9"&gt;感知引导的知识图谱检索&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;将感知信息进行自然语言化，对包含了法律法规、道德原则、防御性驾驶原则等知识的知识图谱进行检索，得到多条相关性由高到低排列的知识条目以及其 Token。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;&lt;b data-index-in-node="0" data-path-to-node="10"&gt;基于世界预测和价值模型的轨迹规划&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;通过规划模块和世界模型模块的多轮迭代，得到多条候选自车轨迹、对应的其他物体的运动预测与隐式世界状态。价值模型以上述信息为输入，针对每条候选轨迹和检索得到的知识，进行价值评估，最终选定规划轨迹。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;该系统的各个模块之间保持了显式结果和隐式特征的共同传递，是可端到端微调的 3D 视觉 - 语言 - 动作框架。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;&lt;strong&gt;驾驶知识图谱构建与知识检索&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-path-to-node="13"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaMMIcibPicJiceO7DbBiaZdM9Ymx4TLKLDF64GpJvdw4kxxicoDJjJz4sMDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4685185185185185" data-type="png" data-w="1080" data-imgfileid="503528156" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/61255189-28f9-4fc7-80fe-12f322b43914/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/h3&gt;&lt;p data-path-to-node="14"&gt;作者团队收集了多样化的驾驶相关资源&amp;mdash;&amp;mdash;包括国家现行交通法律法规、防御性驾驶原则、道德准则以及经验知识访谈&amp;mdash;&amp;mdash;并依据文本结构构建了初始的知识森林。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;随后利用大语言模型抽取实体并定义节点与边，形成结构化的知识图谱。在推理过程中，KnowVal 生成富含三维感知信息的自然语言查询，通过实体抽取、知识条目过滤与向量化，从知识图谱中检索相关条目，并按相关性降序进行排序。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;价值模型构建与基于价值模型的轨迹规划&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-path-to-node="16"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaWxy0jbLNf7w5FxnShCxyCaJLGrjGVTtrmuB3vljekib1NqV09ib6oHTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.45555555555555555" data-type="png" data-w="1080" data-imgfileid="503528149" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/cbc46e58-3d99-4d95-8d93-ab12cb33bb91/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/h3&gt;&lt;p data-path-to-node="17,0,0"&gt;KnowVal 提供了一种与现有端到端和 VLA 模型兼容的改造方式，针对其轨迹规划 Transformer 或 RNN 进行改造，引入对自车查询叠加的多条预设高斯噪声和多样性约束损失函数，使其具备生成多样化候选轨迹的能力。&lt;/p&gt;&lt;p data-path-to-node="17,1,0"&gt;KnowVal 构建了一个大规模驾驶价值偏好数据集，用以训练价值模型。数据集选取了多个自动驾驶真实场景数据，通过规划模型预测和随机生成的方式获取多条轨迹，并保存其相应的场景状态（隐式特征向量与显式鸟瞰渲染图），并利用前述的检索方法得到多条知识，为每个轨迹 - 知识对进行介于 -1 到 1 之间的价值评分标注，最终得到包含 16 万个轨迹 - 知识对的数据集。&lt;/p&gt;&lt;p data-path-to-node="17,2,0"&gt;模型推理时，该模块以构造的多条自车特征和感知得到的实例特征与作为查询，以感知得到的全部信息作为键 - 值，通过规划模块和世界模型模块的多轮迭代，得到多条候选自车轨迹、对应的其他物体的运动预测与隐式世界状态；价值模型以上述信息为输入，针对每条候选轨迹和检索得到的每条知识，进行价值评估，并计算每条轨迹的降序加权平均分数，以最终选定规划轨迹。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;作者团队将 KnowVal 框架应用至 GenAD、HENet++ 与 SimLingo 三个基线模型，并在 nuScenes 开环端到端驾驶基准和 Bench2Drive 闭环端到端驾驶基准上进行了测试。KnowVal 范式能够在 nuScenes 上取得最低的驾驶碰撞率，并在 Bench2Drive 上取得最高的驾驶分数和成功率。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaJumgYYI0GSAkwAic8v83iaJDhjOabn0lvYtic7EIsf3P2VBiaBqqF800sQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.38333333333333336" data-type="png" data-w="1080" data-imgfileid="503528150" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/abae9949-6237-4dda-a763-64133cc8c5ad/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicFZCBCia2pic36dtxra88bsaFZCKIWQAQxULO32mcMCbXO3GkmofYH1FPRCKVZHqEgmGwp8ibbaIeKw/640?wx_fmt=other&amp;from=appmsg#imgIndex=7" alt="image.png" data-ratio="0.6334519572953736" data-type="other" data-w="562" data-imgfileid="503528151" data-aistatus="1" data-original-style="width: 383px;height: 243px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/391aefc3-d124-48d4-8e34-8bc135450f75/640.png" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;现有基准测试对于法律和道德行为的评估并不够全面，因此，作者也提供了几个定性分析样例，以说明 KnowVal 的实际效果：&lt;/p&gt;&lt;p data-path-to-node="21"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicFZCBCia2pic36dtxra88bsaE9MBCibM0vP1zFalTaX0wvMiaxDxq4cRUTmhaD3N147NKiciayQmnwS3qQ/640?wx_fmt=other&amp;from=appmsg#imgIndex=8" alt="image.png" data-ratio="0.6784452296819788" data-type="other" data-w="566" data-imgfileid="503528152" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8fae5db4-99ef-4527-a0fe-d3882ceabe4a/640.png" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;上图中两个样例，前者是在 nuScenes 真实数据上通过场景编辑得到，测试智能驾驶系统是否能够在路过积水时减速慢行、以免溅到行人；后者是在 CARLA 模拟器中隧道场景进行的测试，测试智能驾驶系统是否会遵循「隧道内 / 实线车道不能变道」的法律法规。实验结果说明，原本无法正确处理这些情况的端到端智驾模型，增加了 KnowVal 的知识检索与价值评估后，能够正确应对这些情形。&lt;/p&gt;&lt;p data-path-to-node="22"&gt;&lt;strong&gt;作者介绍&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;p data-path-to-node="23"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"data-path-to-node":"23","style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;该论文的第一作者和通讯作者均来自北京大学王选计算机研究所的 VDIG (Visual Data Interpreting and Generation) 实验室，第一作者为北京大学博士生夏仲禹，通讯作者为博士生导师王勇涛副研究员。VDIG 实验室近年来在 CVPR、NeurIPS、IJCV、ICCV、ICML、AAAI、ECCV 等顶会顶刊上有多项重量级成果发表，多次荣获国内外 CV 领域重量级竞赛的冠亚军奖项，与国内外知名科研机构和企业广泛开展合作。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>仅用10天？Anthropic最新智能体Cowork的代码竟然都是Claude写的</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:15:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="7"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f8b57c5c-1804-4c71-98aa-15c66eaeadb1/1768371250956.png" style="width: 700%;" class="fr-fic fr-dib"&gt;最近，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"data-path-to-node":"6","style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Anthropic &lt;/span&gt;发布了全新的智能体工具 &lt;strong&gt;Cowork&lt;/strong&gt;，号称能让普通用户像开发者使用 Claude Code 一样，轻松搞定非技术性任务。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1918" data-imgfileid="503528202" data-ratio="1.5907407407407408" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic04lULDjNExgQfIX4b0wpqM8H7I5FllnxLYCTcaOlPDM23zP8QVEloQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" data-width="1206" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8ed05b6b-1bf8-4618-8d0c-053650e0ef2f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="8"&gt;更令人咋舌的是，&lt;strong&gt;Cowork 的诞生仅仅用了一周半&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="840" data-imgfileid="503528203" data-ratio="1.1444141689373297" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicJUddgCHx02J2FUqKQ5xefAGxicwS9CSEegTiaDwdsgsALyUjIGQSZibRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="734" data-width="734" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1770f628-5015-4a18-977b-b75e217ee9ca/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="9"&gt;Cowork 是 Claude Code 的简化版本，专为普通用户设计。目前作为研究预览版，仅向 macOS 桌面端的 Claude Max 订阅者开放。用户只需授权访问特定文件夹，便能通过自然语言指令，让 AI 自主读取、编辑或创建文件。它不仅能制定计划、并行执行任务，还会实时更新进度，并邀请用户参与指导。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;根据官方介绍，Cowork 的能力包括但不限于：自动整理下载文件夹、从截图生成电子表格、基于散乱笔记起草报告，甚至支持连接 Google Calendar 等现有工具，直接生成文档或演示文稿。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;据 Claude Code 创建者 Boris Cherny 所说，&lt;strong&gt;Cowork 的全部代码都是由 Claude Code 写的&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;这简直就是 Claude Code 最好的广告，当其他 AI 公司还在靠收购构建生态的是时候，Anthropic 已经开始让 AI 自己生 AI 了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="956" data-imgfileid="503528205" data-ratio="0.725" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicqbQazWsSmkU1RAJSHVP0w9cH5Z8w9lIsiaJ6A82JNOxibEldibqX4qoPw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-type="jpeg" data-w="1080" data-width="1318" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/08483140-9265-4c99-87dc-75e274cd4a2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="14"&gt;有不少用户分享了实测反馈，其中热度最高的帖子之一来自 X 用户 vibhu。&lt;/p&gt;&lt;p data-path-to-node="15"&gt;他表示自己安装 Cowork 后，仅用 2 小时就完成了原本需要 2 个月的工作，包括生成职位描述、营销策略文档、合作伙伴邮件、网站文案等。随后，他「惊慌」地发现日程、待办和收件箱都空了，不知道工作该怎么继续，甚至在为下午的经理一对一会议发愁。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="724" data-imgfileid="503528206" data-ratio="0.7973568281938326" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicXEI0wLSeRXQeT2PJia0kdWiaUGF07HDyukUg9h05iaC99QvSfDMdlBk4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="908" data-width="908" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f07b439b-ca6d-4bb3-99d9-0523f69d8820/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="16"&gt;不过评论区很多人质疑其真实性，认为这可能是夸张的营销或搞笑帖。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="200" data-imgfileid="503528207" data-ratio="0.21739130434782608" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicIib5ic4HG6jXHib10fAzS8MWQ8XvlXqPDdcUoBcXGOLw3ryrqt5svOcbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="920" data-width="920" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f76a4f83-762d-4759-a67b-a2b3a65a6ef4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="384" data-imgfileid="503528208" data-ratio="0.4151351351351351" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicVokzVt8v7Brhtv4zu1tJ6MyG8mVYuOHEWZ7vqzyWicdK5ZNiaYJDdxhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="925" data-width="925" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/a560f658-dd18-4410-9bab-c14ee026d5bf/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="17"&gt;但在创业圈，这种冲击却是实打实的。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;有人感叹，这将使许多 YC 创业项目原地蒸发。毕竟在 AI 圈，真正的硬通货是地基和模型，而不是那些依附在巨头身上的「套壳挂件」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="815" data-imgfileid="503528209" data-ratio="0.9005524861878453" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicqqhn0wHBtQ0sffCQcodiaWeZg3xzRKjWmshVgKzUyyU2ibhuY2vibUrQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="905" data-width="905" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/1ecc9524-cbdc-4c47-ab4a-ec871d149f30/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="19"&gt;甚至已经有「受害者」出现：用户 Guohao Li 表示，由于 Claude Cowork 的横空出世，他们的类似产品失去了竞争力，于是选择开源。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="785" data-imgfileid="503528210" data-ratio="0.8616904500548848" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicnPPBpY6PLdvz04vW6ppJDBNSLWa0vRbwV6bLkJjcxBWSQXCG1icFEDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="911" data-width="911" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/918e8932-6932-4c04-8d9b-476fb58d2370/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;大家纷纷调侃「开源才是王道」，HuggingFace 联合创始人 Thomas Wolf 也现身评论区表达支持。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="144" data-imgfileid="503528211" data-ratio="0.15737704918032788" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicOewUPXqWfibMq8k5r9umh0CyicmoBFC0AXO3RGicOKlRQ9gdtiaphiaLcog/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="915" data-width="915" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6b7db1a0-428d-4ca8-88a4-fa5197f9e04f/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="21"&gt;该项目快速获得 3K GitHub Star。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="698" data-imgfileid="503528212" data-ratio="0.7636761487964989" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicH57XFy5NCUeiafmiaiaxnw7RvpPazf8XaCibWNKJun3SibtsyO4SWz1KB1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="914" data-width="914" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/dd77c8b4-ae96-48c2-b1c0-52187e160293/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22"&gt;社区也不乏调侃之声，看看这个「当前创业公司结构」：现在的科技创业似乎只需要一个聪明大脑，外加一张能付得起 AI 公司账单的信用卡就够了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="314" data-imgfileid="503528213" data-ratio="0.34316939890710385" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicrKTeu5WydmA2Iib8nYdsT19ibAsibLXEWe7sG7iavjTd7REf9y04hTEyeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="915" data-width="915" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/a7ee9e40-a8aa-4702-966e-dfd8bfe4a761/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23"&gt;当下，日常工作下的助理智能体正在层出不穷，结合电脑手机系统的智能体也越来越强大。豆包手机的出现已经重塑了普通人对日常工作任务智能化的想象。&lt;/p&gt;&lt;p data-path-to-node="24"&gt;但就像网友使用过 Cowork 说的：「我正在努力想办法解释，为什么我既比以往任何时候都更有效率，又完全没用。」&lt;/p&gt;&lt;p data-path-to-node="25"&gt;普通人对智能体完全代理工作任务，似乎还没有做好预期和准备。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;相比于其他公司的巨额并购投资，Anthropic 借助 AI 能力，在短时间内，以低成本的方式打造用户端智能体的策略，是否更有价值？&lt;/p&gt;&lt;p data-path-to-node="27"&gt;&lt;sup&gt;参考链接：&lt;br&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;https://x.com/TheAhmadOsman/status/2010917868586647693&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;https://x.com/craigzLiszt/status/2010842587624505445&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;sup&gt;https://x.com/guohao_li/status/2010899322825744745&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026｜AP2O-Coder 让大模型拥有「错题本」，像人类一样按题型高效刷题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 14 Jan 2026 14:11:45 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-14-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-14-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/cdd5136e-f7db-4818-8b3b-97587028f6af/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;作者：上交博士，在腾讯codebuddy 实习，发表一作顶会顶刊论文10篇（含best paper 等），开源PFLlib等明星项目，获得社区赞誉。主要研究AI强化学习、AI合成数据、Agent 记忆等。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;在 AI 辅助 Coding 技术快速发展的背景下，大语言模型（LLMs）虽显著提升了软件开发效率，但开源的 LLMs 生成的代码依旧存在运行时错误，增加了开发者调试成本。&lt;/p&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;现有基于偏好优化的改进方法，多依赖「通过 / 失败」二元信号构建训练数据，难以知晓「错在哪」，也忽视了模型能力在训练时的动态变化特性。&lt;/p&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;针对此缺口，在腾讯 CodeBuddy 实习期间，我们提出自适应渐进式偏好优化方法（AP2O），并构建 AP2O-Coder 框架。该方法借鉴人类的「按题型高效刷题」经验出发，通过「考试 - 分析 - 纠错 - 小测」的系统性流程提升模型代码纠错能力，在多款主流开源模型上实现最高 3% 的 pass@k 性能提升，同时降低训练数据需求量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAOExTFtLBFIpLxPwzhSEGqeC0JuSzAUiccKnEo0KgxYRfZGC4pwNqQow/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.20925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528019" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/36055654-21e4-40f4-adc2-e1033c58f252/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：AP2O-Coder: Adaptively Progressive Preference Optimization for Reducing Compilation and Runtime Errors in LLM-Generated Code&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2510.02393&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源代码：https://github.com/TsingZ0/AP2O&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="7"&gt;&lt;strong&gt;一、现有方法的核心挑战 与 AP2O-Coder 的针对性设计&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;当前离线偏好优化方法（如 DPO 等）在 LLM 代码纠错任务中面临三大核心挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="9,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,0,0"&gt;错误类型感知缺失&lt;/b&gt;：仅依赖单元测试的二元反馈信号，无法知晓类型错误（如 KeyError、ValueError 等），导致模型难以定位错误原因；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="9,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,1,0"&gt;训练聚焦性不足&lt;/b&gt;：训练数据采用随机打乱的方式批量输入，模型需在多种错误类型间频繁切换适应，纠错学习的针对性不强；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="9,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,2,0"&gt;动态适配能力薄弱&lt;/b&gt;：静态构建的训练集无法匹配模型训练过程中不断变化的能力短板，易引发灾难性遗忘或训练资源浪费。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="10"&gt;为应对上述挑战，AP2O-Coder 借鉴人类按题型进行的「错题整理 - 专题突破 - 定期复盘」的学习模式，构建了包含四大核心模块的优化框架，旨在实现错误信息的深度利用与模型能力的动态适配。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;二、AP2O-Coder 的核心技术框架与工作机制&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;AP2O-Coder 的核心设计思路是通过系统化流程实现错误类型的精准捕捉、渐进式优化与动态适配，其整体框架包含四个关键步骤（如图 1 所示）：&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528002" data-ratio="0.8740740740740741" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8ZwUnMzYAKh879bPqUpxnaGFANfZnddUibeNurRo4SXIicjv4nd2qr8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/41e29db1-9a18-480f-b681-b594188a3c2c/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：AP2O-Coder 框架流程图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;代码生成评估（Exam）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为全面掌握目标模型的初始能力边界，该模块让 LLM 在 M 个编程任务上生成 &amp;nbsp;N 个候选答案（采用温度系数 1.0 的设置以充分探索能力范围），通过配套的单元测试获取每个答案的「通过 / 失败」标签，形成初始训练数据集，为后续错误分析提供基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;错误诊断分析（Analysis）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;借助编程语言专用分析工具（如 Python 解释器）对所有失败答案进行结构化解析，标注具体错误类型并统计各类错误的出现频率，按错误题型构建结构化的「错题本」。该过程实现了从二元反馈到精细化错误信息的转化，为针对性优化提供数据支撑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;渐进式偏好优化（Correction）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于错题本，设计差异化的优化顺序：对于小参数模型（如 0.5B）采用「低频错误 -&amp;gt; 高频错误」（L2H）的优化路径，对于大参数模型（如 34B）采用「高频错误&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&amp;nbsp;-&amp;gt;&amp;nbsp;&lt;/span&gt;低频错误」（H2L）的优化策略。通过构建 DPO 滑动窗口，逐步聚焦各类错误类型，一个题型一个题型地纠错，生成有序的偏好数据对&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACA4ZGAiahjLAnricTUjV3TauGDqa6hWr1iaXmJdx4TT8kKoG315kia6pRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.20952380952380953" data-s="300,640" data-type="png" data-w="315" type="block" data-imgfileid="503528003" data-aistatus="1" data-original-style="width: 110px;height: 23px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/804f11fa-8d16-4560-97de-d6f0d0d9869c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 14.34%;"&gt;，使模型能够分阶段集中优化特定类型错误。其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4r7fKtTqQFlgNvkSZz8c2J9wI15TLDNaZOsslB6jEwU6zrPOgh5jGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8095238095238095" data-s="300,640" data-type="png" data-w="63" type="block" data-imgfileid="503528005" data-aistatus="1" data-original-style="width: 22px;height: 20px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1a75d6aa-dcb9-4adf-9ab9-948106ae9f0a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 3.58%;"&gt;是输入 Prompt，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAOa3sibWRuahEOD3HsS6NLwkogiazOq8ib5x6xjq8fFUYXfvhypiasxCO0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7951807228915663" data-s="300,640" data-type="png" data-w="83" type="block" data-imgfileid="503528004" data-aistatus="1" data-original-style="width: 28px;height: 22px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/204ec741-876f-4178-b620-44ccd01d8500/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 4.22%;"&gt;是正确的回答（随机获得），&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALtwLP9gz8fZWkicw6S70q0Ym1ybO351JkuYLGZ62AxhOdxAesB4DETA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.8461538461538461" data-s="300,640" data-type="png" data-w="78" type="block" data-imgfileid="503528006" data-aistatus="1" data-original-style="width: 25px;height: 21px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8b3c5919-d4b1-481e-9441-cab283475875/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.8%;"&gt;是错误类型为 E 的错误回答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自适应错误回放（Quiz）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为适配模型训练过程中的能力变化，该模块定期在一个小验证集上评估模型性能，实时捕捉当前阶段的高频错误类型，&lt;strong&gt;找出模型依旧犯错的题型&lt;/strong&gt;，将其对应的失败答案重新纳入训练流程。通过动态调整训练数据分布，确保模型始终聚焦于当前的能力短板，有效缓解灾难性遗忘问题。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;三、实验验证与结果分析&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;研究团队在 6 款主流 LLM（含代码专用模型 CodeLlama、DeepSeek-Coder、Qwen2.5-Coder 与通用模型 Llama3、Qwen2.5、Qwen3）上开展了系统验证，参数规模覆盖 0.5B - 34B，实验基准包括 EvalPlus（HumanEval/MBPP）与 LiveCodeBench v6，主要取得以下研究发现：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;性能提升的有效性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在不同类型与参数规模的模型上，AP2O-Coder 均展现出稳定的性能改进。如下表所示，在 EvalPlus（HumanEval）基准上，AP2O-Coder (H2L) 即使对于 30B+ 的大参数模型，也能实现 2.8% - 3.4% 的性能优化，且未出现现有后训练方法中性能退化现象。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAghU5EpZhTicsr5np8iaNwxw2FnsIXpKiaOQ8e5AdxDvFK2tA3YkTQ2Txw/640?wx_fmt=jpeg#imgIndex=7" data-ratio="0.275" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkApxldNLAOudYbzFfibZ1mI3QJPEmTN7pPHrqibHbfLIRwthqMjzgYSM4Q/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1896" data-cropy2="521.5640138408305" data-imgfileid="503528008" data-aistatus="1" data-original-style="width: 578px;height: 159px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ce182892-f694-4c18-8a68-6c53bd4ffcaf/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 表 1：各种类型和规模代码的 LLM 在 Pass@1 on EvalPlus (HumanEval) 上的表现。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;&lt;b data-index-in-node="0" data-path-to-node="22"&gt;错误抑制效果与泛化能力&lt;/b&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAPxWA6dCx06XP6SqyRMu34E5xVL3k7flKVvoABDcBNtNgDOhm4jReqw/640?wx_fmt=jpeg#imgIndex=8" data-ratio="0.47628657921291623" data-s="300,640" data-type="png" data-w="991" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4DGrQQibYNp8wv71uIRcYoia4ibmCRY0IhwWQ0oMk0ST2sj1ENd4LGeKg/0?wx_fmt=png&amp;from=appmsg" data-cropx2="991" data-cropy2="473.21107266435985" data-imgfileid="503528009" data-aistatus="1" data-original-style="width: 578px;height: 276px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/533dab17-5b89-4c7f-a0e9-d36ccbd5dec4/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 2：使用 Qwen2.5-Coder-7B 在测试基准上出现错误的统计数据。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528013" data-ratio="0.2219074598677998" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv3oc1sCeuvDewibwUPVkceRV8lcnusqKIibFUsWRUwL5FzoJEicv0LMAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="1059" type="block" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/43a46cdc-fd07-4f06-a461-254764b8778d/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23,0"&gt;&lt;sup&gt;图 3：使用 Qwen2.5-Coder-7B 在测验阶段对验证集上的错误统计结果。我们的 AP2O-Coder 能够逐步减少错误。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="25"&gt;如图 2 所示，相较于 SFT、DPO 等基线方法，AP2O-Coder 能够有效降低各类错误的发生频率，且未引入新的错误类型。如图 3，在 Qwen2.5-Coder-7B 的实验中，高频错误「WrongResult」的发生率显著下降，IndexError 等小众错误在训练后期实现清零。同时，该方法在 pass@5、pass@10 等指标上的稳定提升（如图 4），表明其增强了模型代码生成的泛化能力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528014" data-ratio="0.4214876033057851" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA13Moic8jYUylCM41EWCX0IwwickMyYXlib33ecBAmXJTXxtKibaxb2yUJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="968" type="block" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/34df3be3-69a9-4e37-b71b-de3708a82f3d/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="25"&gt;&lt;sup&gt;图 4：在不同模型规模下，使用 DeepSeek-Coder 在 EvalPlus (HumanEval) 基准上的 pass@5 和 pass@10 表现。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;&lt;b data-index-in-node="0" data-path-to-node="27"&gt;样本效率的优化&lt;/b&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528016" data-ratio="0.262037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAtIpgXboWLXkxgIsfXwF9crMCG2dYb2hfZDraPHoxeVWqGMPpicsMruA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/63dec4ba-c896-4fab-8abe-81e323febf14/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;sup&gt;图 5：用于在 MBPP 训练集上对不同规模的 Qwen2.5-Coder 进行训练并达到最优性能的偏好数据对需求。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="29"&gt;AP2O-Coder 通过错误类型的精准聚焦，显著提升了训练数据的利用效率。实验结果显示，该方法仅需 4% - 60% 的偏好数据即可达到传统 DPO 方法的最优性能，在 32B 参数规模的模型上，数据需求量减少更为明显（如图 5），这就和班上刷题时，优等生所需刷题量更少类似，为低资源场景下的 LLM 代码优化提供了可行路径。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;&lt;b data-index-in-node="0" data-path-to-node="30"&gt;通用 LLM 适配性&lt;/b&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528018" data-ratio="0.3142857142857143" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAxeibb5Bicv9x5WM4nBPKm0vHcXI5QGR5P8qW3ic37z2q3KAeDb685nianw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="875" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/25cde936-bae6-43f7-8166-c6077483ebfc/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="30"&gt;&lt;sup&gt;图 6：在将通用 LLM（如 Qwen2.5、Qwen3 和 Llama3）适配到代码领域时，其在 EvalPlus (MBPP) 上的 pass@1 表现。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;AP2O-Coder 不仅适用于代码专用 LLM，也能有效支持通用 LLM 向代码领域的适配。在 Qwen3、Llama3 等通用模型的实验中，经过该方法优化后，模型在 MBPP 基准上的 pass@1 分数显著提升，验证了其跨模型类型的适配能力（如图 6）。&lt;/p&gt;&lt;p data-path-to-node="33"&gt;&lt;strong&gt;四、研究发现与方法特性&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="34"&gt;实验过程中，团队发现了优化策略与模型规模的适配规律：&lt;/p&gt;&lt;p data-path-to-node="35,0,0"&gt;对于 &lt;b data-index-in-node="3" data-path-to-node="35,0,0"&gt;Qwen2.5-Coder&lt;/b&gt;，小参数模型（&amp;le; &lt;span data-index-in-node="23" data-math="\le"&gt;3B）采用「低频错误&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&amp;nbsp;-&amp;gt;&amp;nbsp;&lt;/span&gt;高频错误」的优化顺序更具优势，这一策略可避免模型因能力有限而陷入高频常见错误的学习困境，而让小模型一开始能看到不同种类的错误，跳出局部最优；&lt;/p&gt;&lt;p data-path-to-node="35,1,0"&gt;大参数模型（&amp;ge; 7B）采用「高频错误 -&amp;gt; 低频错误」的顺序效果更优，能够充分发挥其强学习能力，快速实现整体错误率的下降。这一发现为不同规模 LLM 的代码优化提供了针对性参考。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
