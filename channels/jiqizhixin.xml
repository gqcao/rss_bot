<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>18个月，中国Token消化狂飙300倍！别乱烧钱了，清华系AI Infra帮你腰斩API成本</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 14:36:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜吴昕&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;中国版 OpenRouter + Artificial Analysis，让每一枚 Token 都能流向它最该去的地方。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;大模型&amp;nbsp;API&amp;nbsp;服务&lt;/strong&gt;&lt;strong&gt;的「黑盒」焦虑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这两天，Clawbot 病毒式裂变，仿佛是一年前 Manus 的魅影重现。&lt;/p&gt;&lt;p&gt;同样一夜之间站上风口，同样点燃了无数开发者对「泼天富贵」的想象，也顺手把 Token 烧成了新的「硬通货」。&lt;/p&gt;&lt;p&gt;最近一组数据，让人更有体感。&lt;/p&gt;&lt;p&gt;中国大模型数量已超过&amp;nbsp;1500&amp;nbsp;个，下游开发者已经开始「疯狂盖房子」。数据显示，2024&amp;nbsp;年初，中国日均&amp;nbsp;Token&amp;nbsp;消耗量约为&amp;nbsp;1000&amp;nbsp;亿；到&amp;nbsp;2025&amp;nbsp;年&amp;nbsp;6&amp;nbsp;月，这一数字已突破&amp;nbsp;30&amp;nbsp;万亿。&lt;strong&gt;一年半时间，增长超过 300 倍。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与三年前的 Chatbot 不同，「能干活」的 Agent 正以前所未有的强度，第一次把 API 调用推入「生产级」&amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;一次看似简单的操作，背后往往是十几次、甚至几十次模型调用在同时发生。任何一次服务「抽风」，都会在 Agent 链路中引发一场多米诺骨牌式崩溃。&lt;/p&gt;&lt;p&gt;问题在于，中国大模型 API 服务现状，远比 benchmark 复杂得多。&lt;/p&gt;&lt;p&gt;更像是开盲盒，有人调侃说，以为自己在用「DeepSeek V3.2」，实际可能是蒸馏/量化版本。有人花了两周时间反复测试，上线后仍遭遇性能回退。还有团队发现，模型会在某些凌晨时段准时「抽风」，延迟从 300ms 飙升至 2000ms 以上，客服秒变「智障」。&lt;/p&gt;&lt;p&gt;这些并非个案，而是高度碎片化的大模型API服务的「缩影」。&lt;/p&gt;&lt;p&gt;大模型 API 服务的「黑盒」，不只是模型不可解释，而是用户根本不知道，服务背后跑的是什么模型、什么配置、什么质量。清华系 AI Infra 创企清程极智联合创始人兼产品副总裁师天麾告诉机器之心。&lt;/p&gt;&lt;p&gt;中国大模型和大模型 API 服务商本来就多。多算力、多架构、多网络并存，同一个模型，在不同服务商、不同部署方式下，往往呈现出显著差异。&lt;/p&gt;&lt;p&gt;比如，同样调用 DeepSeek-V3 / R1，头部服务商可以维持毫秒级响应；而部分接入低质量算力或优化不足的服务商，其 TTFT（首 Token 时延）可能慢上 2～3 倍。&lt;/p&gt;&lt;p&gt;与此同时，免费 Token、补贴、打包套餐的价格战，让「性价比」变得更加扑朔迷离。&lt;/p&gt;&lt;p&gt;经济学家罗纳德&amp;middot;科斯曾指出，企业与制度的出现，本质上是为了替代高成本的市场交易。当模型服务因高度不透明与供给碎片化不断抬升交易成本时，市场往往会内生出新的中介形态与制度安排，用以收敛不确定性，降低决策与交易成本。&lt;/p&gt;&lt;p&gt;正是在这样的背景下，1 月 29 日，清程极智正式发布 AI Ping。这款被业内视为「中国版 OpenRouter + Artificial Analysis」产品，旨在重塑大模型 API 服务秩序，将上游服务的碎片化与「黑盒」，转化为下游用户手中稳定、可预期的生产力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeWdbKJmdm5LwDUqxf8FVaW6Uep5Dns4eDx9wnZmLwibhk19wqkceqL9g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="385" data-imgfileid="503531195" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c9d2bc6f-3239-4434-9bb1-a54c43afd200/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 1 月 29 日，清程极智举行发布会，正式官宣 AI Ping。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中国版&amp;nbsp;OpenRouter + Artificial Analysis：&lt;/strong&gt;&lt;strong&gt;AI Ping&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;怎么玩儿？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单来说，AI Ping&amp;nbsp;是一个通过&lt;strong&gt;评测与路由&lt;/strong&gt;两大机制，来消除大模型 API 服务不确定性的基础设施型产品。&lt;/p&gt;&lt;p&gt;如果说OpenRouter 解决的是「统一接入不同模型和服务」，Artificial Analysis 解决的是「评测模型服务质量」，那么 AI Ping 试图把这&lt;strong&gt;两件事合成一件事&lt;/strong&gt;&amp;mdash;&amp;mdash;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通过评测告诉你模型服务的质量数据，更基于实时评测结果，「接管」模型与服务商的选择决策。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;换句话说，有了这颗动态的「调度大脑」，你只管提需求，不用理解模型，不用挑供应商，更不用为故障兜底。&lt;/p&gt;&lt;p&gt;我们简单体验了一把「自动驾驶」，在网页「多模型对话」中，让系统完成一个音乐播放器的设计。&lt;/p&gt;&lt;p&gt;模型路由，选择的是「均衡模式」，在效果、速度与成本之间寻找综合最优解，而不是只追求单一极端指标（比如最低延迟）。&lt;/p&gt;&lt;p&gt;很快，系统判断 DeepSeek-V3.2 最适合当前任务，并将请求路由到当时服务能力最优的火山引擎节点。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeHq4PShTZ1u0icNDiaOIWrBNzsQmFmjo5EfHpeoPgG2qicVudmq29w0XWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5712962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="330" data-imgfileid="503531194" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/196a5898-743b-464b-8f93-21158020d45d/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;结果，响应速度快，输出效果也很不错。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye1tsqduBJfvcbLfggegnk0AWSLr7nWibBpZ7iboru4IdiaKrQQqshD7Edg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.798887859128823" data-s="300,640" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="462" data-imgfileid="503531189" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/86c805a9-5438-4f6a-b5cb-a8bbca0032d6/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;成本仅消耗 0.04 个算力点（约 4 分钱）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye6zh7wQDkTMRRm6axOfQv3h8wMDwN1bibnQvia3fEdcQ4BQdgPysIKaXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.15833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="92" data-imgfileid="503531196" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a379e01d-c506-44a2-bd5a-dadcf8bab2ba/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;大规模实验数据显示，无论用户选择哪种路由策略，AI Ping 都能把调用推向「能力&amp;mdash;成本」的最优区域。&lt;/p&gt;&lt;p&gt;比如，即使选择「效果优先」，系统也会在保证模型能力处于高水平的同时，避免把成本推向极端，而是在质量与价格之间自动找到一个更均衡的位置。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeKdDUfMmpu1HHCj5yTapRyIhe0TBVHaS68I2UuS6BsvzZkINAz8yiaxQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="788" type="block" data-backw="578" data-backh="433" data-imgfileid="503531197" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/11d02f56-bcf4-42d1-89ee-8413abafb3ce/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;通过模型路由策略，AI Ping 能在「能力&amp;mdash;成本」二维空间里，逼近不同目标下的最优解。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;长期以来，中国大模型 API 服务市场缺乏一份公允、可对比的「体检报告」。不同服务商各自披露性能指标，但测试条件、指标口径与展示方式并不统一，开发者很难判断，AI Ping 试图填补这一空白。&lt;/p&gt;&lt;p&gt;目前，该平台已接入 30 家主流服务商，覆盖 555 个模型接口，是国内极少数能够在统一标准下，对大模型服务进行持续评测与公开展示的平台之一。&lt;/p&gt;&lt;p&gt;在 AI Ping 的网站首页，不同服务商被放入同一张性能坐标图中进行对比。以吞吐率与延迟为坐标轴，同一个模型在不同服务商处的实际服务能力差异，一目了然。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeNHRuav2ibJIvudIw26HoMDdaA5TlxZSicKLHy6a2sWMicwiaWMeicpNqHbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.9592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="554" data-imgfileid="503531198" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3958afc4-a5dd-4765-ba9b-9bd9c3265d79/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyedlwNgbgFke8icvLV7vaiaSypichu2L2mmK5xH9nyVPrX3fmoLdruibrcKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.55" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="318" data-imgfileid="503531199" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/d8b348f8-fb11-4649-aefb-5a1bf7c40705/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyefONjHibVyf7X2nk1WZrbXAFTb1gRlENaP3BwOBfqHr3eFBRd9kQvOoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.0842592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="627" data-imgfileid="503531200" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b6c1bc8c-2fbf-413c-8a4c-5f5e4b0b5d6a/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 用户提需求，自动生成服务路由策略的代码。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;点开服务商，可以看到同一模型（ DeepSeek-V3.2 ）在不同服务商处的服务波动情况。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyePTfpJQmXRHXcyiaHgURpEX0GYRLarBpBd4Fb4oAGUztSHFMT28nhd9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="302" data-imgfileid="503531201" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/32461a1f-0350-4c32-8b1d-c5d2d23ad714/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Top5服务商最近几天服务延迟的「心电图」。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这些对外展示的数据，强调公平性与可比性，按固定周期更新，犹如一份面向行业的「排行榜」和「体检报告」。对开发者而言，选型不再听厂商「吹牛」；对服务商而言，服务能力第一次被放在同一把尺子下比较。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对标&amp;nbsp;Artificial Analysis：&lt;/strong&gt;&lt;strong&gt;7&amp;times;24h&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;数据「开盒」大模型API&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从我们的体验来看，使用 AI Ping 和直接调用某个大模型几乎没有区别，只是完成了一次再普通不过的请求。&lt;/p&gt;&lt;p&gt;但在系统内部，这次调用已经悄然完成了一次跨模型、跨服务商的最优路径选择。&lt;/p&gt;&lt;p&gt;这种「选路」的能力，源于清程极智构建的技术三角闭环：&lt;strong&gt;全维度评测体系、服务商级智能调度、以及多模型智能路由&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一切的基石，是套对标 Artificial Analysis 的实时评测系统。要像成为公认的「裁判员」，前提是评测体系本身具备足够的公平性与一致性。&lt;/p&gt;&lt;p&gt;在指标设计上，紧紧围绕用户真正关心的体验维度展开，包括 TTFT（首 Token 延迟）、TPS（吞吐率）、成本、精度等核心性能与经济指标。&lt;/p&gt;&lt;p&gt;不同应用场景，对指标的敏感点完全不同。师天麾解释说，在普通聊天场景中，用户最在意的是「多久开始回复」。只要能在几百毫秒内出首字、输出速度达到可阅读水平，体验就已经趋于饱和。&lt;/p&gt;&lt;p&gt;而在 Agent 场景中，一个任务往往由多步调用组成，真正决定效率的，不再是单次延迟，而是整个流程的吞吐能力与端到端完成时间。&lt;/p&gt;&lt;p&gt;为了「开盒」国产模型服务的真实水位，AI Ping 沉淀了一套极具技术含量的评测方法。&lt;/p&gt;&lt;p&gt;例如，所有测试使用同一套「考卷」，并在同一时间段进行；测试请求从北、上、深、蓉等多地服务器同时发出，彻底消除网络波动对单一节点的干扰。&lt;/p&gt;&lt;p&gt;专门针对「服务商缓存」设计特殊策略，确保测出的是真实的算力响应，而非「复用答案」的表象。&lt;/p&gt;&lt;p&gt;始终以普通用户身份，匿名走真实调用流程，评测结果还会进行交叉验证，也获得了数十家主流服务商的认可。&lt;/p&gt;&lt;p&gt;最极致的一点，在于&lt;strong&gt; 7&amp;times;24 小时持续观测&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;模型本身只是个文件，能力基本是固定的；但模型一旦变成大模型 API 服务，情况就完全不同了。师天麾说。&lt;/p&gt;&lt;p&gt;中国大模型 API 服务，白天和晚上不一样，北京和成都的节点不一样，甚至同一家服务商，隔了几个小时负载也会剧烈波动。如果拿几分钟前的评测数据做路由决策，无异于刻舟求剑。&lt;/p&gt;&lt;p&gt;这种对指标的极致苛求，源于团队的硬核底蕴。AI Ping 背后的清程极智团队源自清华，长期深耕超算与 AI 性能评测领域。他们不仅参与过 AIperf 等行业评测工具的研发，更承担过国家级超算集群的性能验收&amp;mdash;&amp;mdash;这种「国家队」级别的评测经验，被降维应用到了大模型 API 服务，最终转化为 AI Ping 难以被复制的壁垒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对标&amp;nbsp;OpenRouter：&lt;/strong&gt;&lt;strong&gt;用「自动驾驶」接管 Token 调度权&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们的目标不是把数据摆给用户看，而是要替用户做决定。师天麾强调。&lt;/p&gt;&lt;p&gt;如果说 OpenRouter 的功劳是实现了 API 的「大统一」，那么 AI Ping 则更进一步，通过一套 L4 级智能路由系统，实现了模型调度的「自动驾驶」。这套系统由「双引擎」驱动：&lt;strong&gt;模型路由（解决「谁来做」）&lt;/strong&gt;与&lt;strong&gt;服务商路由（解决「在哪里做」）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在 AI Ping 的逻辑里，模型不是「越大越好」，而应该是「分工明确」，有的擅长写代码，有的擅长写作。&lt;/p&gt;&lt;p&gt;现实中的任务也是分层的：写代码需要逻辑严密，日常闲聊只需快速响应。「如果所有请求都交给旗舰模型，只会变得又贵又慢。」&lt;/p&gt;&lt;p&gt;AI Ping 的路由模型会通过机器学习，实时对用户请求进行「画像」，并在多种模型之间动态选择当前性价比最优的组合。&lt;/p&gt;&lt;p&gt;在大规模测试中，这种「按问题匹配模型」的策略带来了两个结果：整体正确率超过单一旗舰模型的最高得分，而调用成本下降超过 50%。&lt;/p&gt;&lt;p&gt;这一结果也与外部研究结论，不谋而合。&lt;/p&gt;&lt;p&gt;近期一项来自MIT 与佐治亚理工的研究发现，开源模型已经可以用大约 13% 的成本，达到接近 90% 的闭源模型性能。&lt;/p&gt;&lt;p&gt;但在实际市场中，这类高性价比模型的使用比例仍不足 20%，主要受限于认知惯性与切换成本。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeDHhDpanbM0GwP3AIcmAotaU2kZUZichcbyBD0KOQOtp3JPibickgAo5bw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.7504393673110721" data-s="300,640" data-type="jpeg" data-w="569" type="inline" data-backw="266" data-backh="200" data-imgfileid="503531202" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/a4598e85-e186-4537-8920-a4518de82fce/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQyeiboibOSmEyQdPiaCV1olw3mKuG0JLXZrjfu15fujibicicJtjx9rAtqhmGyw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="572" type="inline" data-backw="266" data-backh="200" data-imgfileid="503531203" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/45cd05a1-f6d0-41f8-bd35-7281e4b21324/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 两种不同情况下的模型路由。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决了模型选型，下一步是决定请求落到哪家服务商。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与传统的「失败后再重试」不同，AI Ping 的服务商路由具备预判能力。每一次请求返回的结果，都是一个天然的测量样本。这些数据会被持续汇总进内部评测池，用来刻画服务商「此时此刻」的真实服务水平。&lt;/p&gt;&lt;p&gt;一旦发现某条请求的响应时间明显偏离正常建模，或与最近观测数据不一致，路由系统就会预判该节点可能进入异常状态，即使尚未收到明确错误，而不是被动等待失败。&lt;/p&gt;&lt;p&gt;在亿次调用的实测中，这套机制让整体 TPS（吞吐量）提升了约 90%，成本同步下降了 37%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9VzDKy83WTr5Iia6SaqkQye4b95MRXadib74TbSMznDmSvveqbGGWbng5HdRl5cVheWrkVxjuXHb9g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=12" data-ratio="0.7503628447024674" data-s="300,640" data-type="jpeg" data-w="689" type="block" data-backw="578" data-backh="434" data-imgfileid="503531204" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/7baf3bae-4cb0-4bad-bf9f-18291a38d623/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;选择最适合的大模型API服务商。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实现这种「自动驾驶」非常不容易。师天麾告诉我们。&lt;/p&gt;&lt;p&gt;服务商路由的一个难点在于动态均衡。「如果只把流量给当前最好的服务商，瞬间的高并发可能会直接把对方打崩。」师天麾分享了一个真实细节：曾有服务商因流量集中路由而宕机，CTO 半夜打来电话询问发生了什么。真正的路由不是简单的排队，而是「利用当前最优」与「预测分配负载」之间的精妙平衡。&lt;/p&gt;&lt;p&gt;模型路由的门槛更高，它本质上是用 AI 去选 AI。系统需要通过海量数据学会「什么样的问题适合什么样的模型」，并在实际运行中不断回收结果进行离线纠偏。&lt;/p&gt;&lt;p&gt;归根结底，这是一套依赖长期数据积累、持续自我演化的系统，也是 AI Ping 作为中国版 OpenRouter 的护城河。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重塑交易秩序：&lt;/strong&gt;&lt;strong&gt;开发少做「选择题」，服务不再只有「价格战」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同用户的实践，从侧面印证了 AI Ping 作为「中国版 OpenRouter + Artificial Analysis」的现实价值。&lt;/p&gt;&lt;p&gt;对许多直接面向 C 端或 B 端用户的团队而言，在接入 AI Ping 之前，最大的困扰并非模型能力不足，而是被大量「非核心工程」消耗精力。&lt;/p&gt;&lt;p&gt;一位从事 ToB 智能客服助手的开发者回忆，过去团队长期陷在「工程师手动选型」的循环中：先接几家跑起来，再拿一批真实问题测效果、测延迟、测报错，最后再算一遍账。换一家就要重新适配、重新回归，周期非常长。&lt;/p&gt;&lt;p&gt;「判断哪个模型最好用，基本靠线上监控和经验。哪家最近延迟飘了，就人工降权，往往是用户先感知到卡顿，我们才开始补救，非常被动。」他们也曾考虑自建调度系统，但很快发现，这意味着还要额外承担监控、容灾和对账等复杂工程负担，更加偏离主线任务。&lt;/p&gt;&lt;p&gt;接入 AI Ping 后，这类「选型内耗」被工程化消解，大家又能把主要精力投入到客服体验上，比如知识库质量、流程引导，转人工闭环。&lt;/p&gt;&lt;p&gt;这种调度价值，在对成本高度敏感的场景中表现得更为直接。&lt;/p&gt;&lt;p&gt;一些独立开发者将 Agent 用于自用场景，对性能要求并不极致，但对成本控制极为敏感。通过 AI Ping 提供的筛选排序功能，开发者可以在多家供应商中，选出性价比最高的方案，比如 TTFT＜5 秒、TPS＞20 ，价格从低至高排序。同时，用户也可以在智能路由中使用此功能，智能路由会将用户的每一条需求，依据评测数据，路由至当前满足用户需求的最高性价比的服务商。&lt;/p&gt;&lt;p&gt;而在多模型协作场景中，调度能力则直接转化为商业可行性。&lt;/p&gt;&lt;p&gt;面团 AI 的模拟面试产品需要多模型协作，比如调用语音模型、文本语言模型，不同厂商的模型各有优势。过去，跨模型、跨平台调用流程复杂，成本也非常高。&lt;/p&gt;&lt;p&gt;统一接入 AI Ping 之后，团队再也不需要关心「既要接火山、又要接百度」的底层适配问题，模型调用起来成本更低，效率更高，服务性能也更加稳定。&lt;/p&gt;&lt;p&gt;以往找身边的学长进行一次模拟面试，往往需要付出半小时三四百元的成本。现在借助 AI 技术，只需几块钱，就可以实现一个高拟人度、高仿真的模拟面试。&lt;/p&gt;&lt;p&gt;类似逻辑也出现在情感陪伴应用中。一支清华大学学生团队发现，用户大部分提问是日常闲聊，少数才涉及深度推理。通过 AI Ping 的「分层调度」，简单问题流向低价小模型以保证「秒回」，关键情绪点则路由至高阶模型。这种精准分发，既避免了响应过慢导致的「冷暴力」，又将稳定性与价格压到了可控区间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;更耐人寻味的是，这套评测体系也在反向重塑服务商的行为&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;硅基智能成为平台的长期用户，一个重要原因在于测得准。通过横向评测，他们可以清晰看到自己在数十家服务商中的真实位置：延迟是否偏高，吞吐是否存在短板，稳定性如何随时间波动。&lt;/p&gt;&lt;p&gt;过去，服务商只能监控自身数据；如今，不同服务能力被放在同一把尺子下比较。当延迟、吞吐与稳定性被持续量化呈现，用户也开始以「服务质量」而非单一价格作为选择依据，行业竞争也由此从价格战转向工程优化与算力治理能力的比拼。&lt;/p&gt;&lt;p&gt;在师天麾看来，这将形成一个正向循环：评测数据让开发者知道什么是好服务，也让服务商看清自身短板。服务质量提升后，应用体验改善，AI 使用规模扩大，Token 消耗随之增长，收益再回流到算力与技术优化之中。&lt;/p&gt;&lt;p&gt;我们希望用透明的数据，让行业知道什么才是值得竞争的方向，他说，「不是只有价格，而是真正的服务能力。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;院士点赞，预见下一代基础设施&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在发布会上，中国工程院院士、清华大学计算机系教授郑纬民给出了一个颇具画面感的比喻。&lt;/p&gt;&lt;p&gt;过去十年，行业解决的是如何把智能「生产出来」。随着模型生态与智能体（Agent）的快速繁荣，新的瓶颈正在出现：如何让智能被高效、稳定地「流通」。&lt;/p&gt;&lt;p&gt;在他看来，智能路由正是这一流通体系中最关键的基础设施之一，也是下一阶段 AI Infrastructure 必须回答的问题。&lt;/p&gt;&lt;p&gt;当模型路由、服务路由、芯片调度全部打通后，用户只需提出需求，而无需关心背后究竟是哪个模型、哪一家云厂商、哪一块芯片在工作，结果便会自动抵达。&lt;/p&gt;&lt;section&gt;「这将是下一代 AI 基础设施的形态，」他说，「让智能像电一样被调用和分发。」&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>中途退学的艺术生，开发Web 3D项目，周下载量破400万</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 14:29:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;一个并不常被普通用户提起的开源项目，刚刚刷新了自己的历史纪录。&lt;/p&gt;&lt;p&gt;近日，Three.js 官方 X 账号公布：Three.js 每周下载量突破 400 万。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1449" data-imgfileid="503529444" data-ratio="1.4461077844311376" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK1OKSykj7lOesCtthaZNBokCK4klmLicbrUPibypRc1j9oDAeiaNdqPSeg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1002" data-width="1002" data-original-style="width: 502px;height: 726px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d29a80b0-3349-462f-94ad-7f2c77939565/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 链接：https://x.com/threejs/status/2013044943909191680&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;你或许没用过 Three.js ，也未必听过它的名字，但你大概率已经见过它的作品。&lt;/p&gt;&lt;p&gt;那些可以旋转的 3D 商品展示页、会随鼠标晃动的官网首页、可交互的数据可视化，甚至一些看似只是酷炫动画的 Web 页面背后，Three.js 正默默地承担着核心的 3D 渲染工作。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;注：Three.js 是一个基于 WebGL 的 JavaScript 3D 图形库，由 Ricardo Cabello（网名 Mr.doob）于 2010 年创建。它的核心目标是让开发者能够在浏览器中轻松创建和展示 3D 内容，而无需直接处理复杂的 WebGL 底层 API。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKfsG8h324YJTh0kq1fe5fz59SZqkZppexq4oueScuxYpicE3iaR5Dp8Dg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.7210379981464319" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503529445" data-aistatus="1" data-original-style="width:487px;height:351px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d69f1a34-7676-47d2-9ae0-6f11b113bdf4/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;在官网示例里，同一个图形界面你可以选择不同的状态如跑、跳。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKkK3m7etT4h9fNcLBQzNtOVANzNHenOQsAXUtib353bLxzYcFBAsaJiaw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.8202038924930491" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503529447" data-aistatus="1" data-original-style="width:486px;height:399px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/08bdab0a-c505-4c28-8222-c3b3b89893ab/640.gif" data-order="1" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKiaj4aHHwVXGPhA1bfr9Ya0A8M4YLMhC65MQm7nGe6jaPiamRPA0ibQPFA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.6265625" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503529451" data-aistatus="1" data-original-style="width:480px;height:301px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c374203f-67f1-47e5-a9be-89a44915bc0b/640.gif" data-order="2" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 来源：https://threejs.org/examples/&lt;a data-topic="1" href="javascript%3A;"&gt;#webgl&lt;/a&gt;_loader_gltf_transmission&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我们再回到官方发布的那张图，其展示了 Three.js 从 2016 年到 2026 年的周下载量变化，呈现出非常典型的指数级增长曲线：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2016-2018：起步阶段，下载量很低&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2019-2020：开始缓慢爬升，达到约 20-50 万 / 周&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2021-2022：增长明显加速，突破 100 万大关&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2023-2024：进入快速增长期，从 100 万攀升至 200 万&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2025-2026：爆发式增长，从 200 万直冲 400 万&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Three.js 快速增长的时间点很微妙，在 2022 年末，正好是 ChatGPT 问世之后，此后生成式 AI 快速爆发，Three.js 也趁着这股热潮疯狂吸引用户。&lt;/p&gt;&lt;p&gt;回想一下，在 AI 介入之前，用 Three.js 开发 3D 内容简直是一场劝退之旅。光是理解四元数、矩阵变换这些数学概念，再加上手工建模、展 UV、调材质的繁琐流程，就足以把 90% 的前端开发者挡在门外。那时候，一个简单的光照渲染或材质效果，往往需要耗费数小时调试。&lt;/p&gt;&lt;p&gt;但 AI 的出现彻底改变了游戏规则。你只需要在 ChatGPT 等大模型里随口描述需求：「用 Three.js 写一个赛博朋克风格的旋转发光立方体，背景要动态粒子星空」。AI 不仅能秒懂你的意图，还能在几秒钟内生成 95% 可用的代码，让那些原本只存在于脑海中的创意，瞬间在浏览器里转起来。&lt;/p&gt;&lt;p&gt;这样一来，AI 大模型极大地降低了 Three.js 的准入门槛，让大量前端开发者（而非图形学专家）敢于尝试 3D 开发。这也是 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Three.js 下载量暴增的原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Ricardo Cabello 介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ricardo Cabello，以网名 Mr.doob 更为人熟知。是 Three.js 的创始人和长期核心维护者，也是 Web 前端与创意编程领域最具影响力的人物之一。可以说，他一个人，直接改变了 Web 世界对 3D 的理解方式。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKEp2tRlQDNQFpIuHQVwnQCA3M8EkaUsjlktY0JYs4HtB7Fkf1Eia533A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1" data-type="png" data-w="768" data-width="768" data-height="768" data-imgfileid="503529452" data-aistatus="1" data-original-style="width: 318px;height: 318px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/37219446-4615-4daa-90b2-5c831b30be48/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;但与今天清晰的技术标签不同，他的成长路径并不循规蹈矩，甚至可以用他自己的话来形容 &amp;mdash;&amp;mdash; 有点灾难。&lt;/p&gt;&lt;p&gt;Ricardo 在一次采访中表示，他读完小学后，在后期还同时进入了一所学院学习漫画绘画；中学阶段一度转向电子工程，后来又改读艺术方向。然而那段时间并不适合系统性学习，最终在进入大学之前便选择了退学。&lt;/p&gt;&lt;p&gt;相比教育体系，真正塑造他的，是长期活跃于 demoscene（演示场景） 社群的经历。在那个以技术与创意竞赛为核心的文化中，创作者必须不断拿出新作品，逼着自己把想法真正做出来。&lt;/p&gt;&lt;p&gt;这段经历深刻影响了他后来的创作风格，追求用精简代码实现惊艳的视觉效果。正是在 demoscene 的环境里，Cabello 系统性地学习了计算机图形学，从最初的视觉创作，到逐渐理解其背后的技术原理，再到最终回到编程本身。艺术与代码不再是对立的两端，而是开始在他身上汇合。&lt;/p&gt;&lt;p&gt;工作之余，Cabello 也会关注一些关于艺术、插画、装置艺术的博客，这会时不时的激发他的创作灵感：能不能把这些东西做成实时的？而在实现的过程中，又会衍生出更多新的点子。&lt;/p&gt;&lt;p&gt;此外，Ricardo Cabello 还是 Web 创意文化的重要推动者。他长期维护的个人网站 mrdoob.com 汇集了大量实验性项目，涵盖物理模拟、粒子系统、交互艺术和声音可视化等方向。这些作品并不以商业化为目的，而是持续探索浏览器作为创意与表达平台的边界，这种对可玩性和表达力的重视，也深刻塑造了 Three.js 的气质，实用、开放，同时鼓励创造。&lt;/p&gt;&lt;p&gt;在开源上，Ricardo 以风格克制、标准严格著称。在他看来，把代码分享出来，让整个互联网都能受益，是一件非常有成就感的事。&lt;/p&gt;&lt;p&gt;他长期亲自把控 Three.js 的 API 设计与代码质量，宁可引入破坏性更新，也避免无序堆叠功能和历史包袱。这种近乎守门人的角色，使 Three.js 在十余年的演进中始终保持清晰的结构和一致的设计理念，避免了许多大型开源项目常见的复杂化和碎片化问题。&lt;/p&gt;&lt;p&gt;而这种工程上的克制，其实可以追溯到 Three.js 诞生之初的动机。Ricardo 曾回忆，创建 Three.js 一方面源于他的好奇心，如果亲手写一个 3D 引擎，究竟能做到什么程度；另一方面也是对自我能力的一次挑战。从 ActionScript 时代开始，他便反复尝试搭建 3D 引擎，在不断试错中学习图形学基础，并逐步摸索出更合理、可扩展的架构方式。更重要的影响则来自 demoscene 的经历：在那个圈子里，创作者往往为一两个 demo 临时写一套引擎，用完即弃。Ricardo 觉得这种方式过于浪费，于是产生了一个更长期的想法，做一个真正可以被反复使用、不断演进的 3D 引擎。这一想法，最终催生了 Three.js，也奠定了它至今仍在坚持的设计哲学。&lt;/p&gt;&lt;p&gt;直到今天，随着 AI 生成内容、WebXR 和 3D 可视化的兴起，Three.js 依然处在 Web 技术栈的关键位置。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>像开发软件一样造世界，Agent2World来了，把世界模型做成可运行的符号环境</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 02 Feb 2026 14:25:11 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/19decf1a-da69-4353-bd46-6be423602374/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;让模型真正 &amp;ldquo;能行动&amp;rdquo;，往往需要一个可执行、可验证的符号世界模型（Symbolic World Model）：它不是抽象的文字描述，而是能被规划器或执行器直接调用的形式化定义 &amp;mdash;&amp;mdash; 例如 PDDL 领域 / 问题，或可运行的环境代码 / 模拟器。一旦世界被 &amp;ldquo;写成可运行的规则&amp;rdquo;，我们就能在同一套约束下进行推演、测试与复现：模型不再停留在 &amp;ldquo;会说&amp;rdquo;，而是能回答 &amp;ldquo;如果我这样做，会发生什么&amp;rdquo;，并用执行结果检验自己是否真的理解了这个世界。&lt;/p&gt;&lt;p&gt;问题在于，现有自动生成路线普遍陷入三重困局：脚本式工作流、知识边界封闭、表示覆盖单一。许多方法仍沿用固定的 &amp;ldquo;生成 &amp;mdash; 修复&amp;rdquo; 脚本，并以解析 / 规则匹配 / 固定检查集等静态校验为主：它们或许能修语法与格式，却常常抓不住只有在交互执行中才暴露的行为级错误（例如状态更新不一致、目标不可达、奖励机制失效）。与此同时，当任务规格含糊、缺失关键规则或背景常识时，系统缺少主动检索与补全机制，只能依赖模型记忆 &amp;ldquo;猜&amp;rdquo;。更关键的是，既有研究往往只覆盖一种世界模型表示（只做 PDDL，或只做可执行代码），导致同一任务难以在不同符号表达之间共享验证闭环与改进经验，限制了方法的通用性与可扩展性。&lt;/p&gt;&lt;p&gt;为攻克这一难题，研究团队提出 Agent2World：一个工具增强（tool-augmented）的多智能体框架，用 &amp;ldquo;知识合成（Knowledge Synthesis）&amp;rarr; 世界模型实现（World Model Generation）&amp;rarr; 评估驱动精炼（Evaluation-Driven Refinement）&amp;rdquo; 的三阶段闭环，把 &amp;ldquo;查资料补规格 + 写实现 + 交互测试纠错&amp;rdquo; 内化为可复用的生成范式，从而稳定产出高可执行、可验证的符号世界模型。&lt;/p&gt;&lt;p&gt;实验结果显示，Agent2World 在 Text2World (PDDL)、CWMB (MuJoCo) 和 ByteSized32 (文本游戏) 三大基准上均实现了 SOTA 性能。更关键的是，该框架展现了可持续改进潜力：基于 Agent2World 生成的高质量轨迹进行微调（SFT）后，模型性能显著跃升 &amp;mdash;&amp;mdash; 与训练前的同一模型相比，平均相对性能提升了 30.95%，有力证明了其作为高质量世界模型数据合成引擎的工程与研究价值。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwFsKjRo1UMw0lx9TDqNbsmiaTicFnZuegt5Rk5cnIoWb6wiajnfzP7FTiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.34629629629629627" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530145" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/bf4cc611-7a37-465c-9da0-559fd5aef25e/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址： https://arxiv.org/abs/2512.22336&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址： https://agent2world.github.io/&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址： https://huggingface.co/agent2world/llama3.1_8b_instruct_full_sft_v1_3_epoch&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址： https://github.com/DeepExperience/agent2world&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、深层归因：为何传统 &amp;ldquo;脚本式&amp;rdquo; 生成难以为继？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Agent2World 之前，自动生成世界模型的主流方案常采用固定的 &amp;ldquo;草稿 &amp;mdash; 修复（Draft-Repair）&amp;rdquo; 脚本：生成代码 &amp;rarr; 跑错 &amp;rarr; 看报错改代码。它能修语法，但很难保证 &amp;quot;跑起来&amp;quot; 的世界是对的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;被动脚本的死循环： 缺乏前瞻性规划，复杂任务里常陷入 &amp;ldquo;改一个 bug 引出新 bug&amp;rdquo; 的低效迭代。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;规格缺口带来的幻觉： 描述不完整时，模型往往只能靠记忆 &amp;quot;猜&amp;quot; 规则边界、接口细节与隐含前提，导致看似能跑、实则不自洽。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;表示覆盖单一的 &amp;quot;符号孤岛&amp;quot;： 既有研究往往只覆盖一种世界模型表示 &amp;mdash;&amp;mdash; 要么偏向 PDDL 的形式化规划，要么偏向可执行环境代码。两条路线各自为战，生成、验证与修复经验难以跨表示共享与迁移，同一问题在不同符号表达下往往需要重做一套流程，最终限制了方法的通用性与可扩展性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;归根结底，难点不只是 &amp;ldquo;写出代码&amp;rdquo;，而是要在真实约束下稳定产出可执行、可复现、可迭代的世界模型；而 &amp;ldquo;脚本式流程 + 单一表示覆盖&amp;rdquo; 的组合，正是阻碍这一目标的核心瓶颈之一。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwoibq10WzeSQhV1EvzftrqWiapfSkoa00XoybEViaIE5YUWfgxOwYQ6Rmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.47685185185185186" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530153" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a65b402b-5b4d-4211-be31-cb16de1805b4/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;二、方法拆解：把 &amp;quot;软件开发团队&amp;quot; 装进模型里&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 的核心不是 &amp;quot;多拉几个 agent 聊天&amp;quot;，而是把世界模型生成拆成软件工程式三阶段：Researcher 补规格、Developer 做实现、Testing Team 用单测 + 仿真交互做行为级验收，并把验收反馈反哺修复。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwTwSvVELxR9xYRxFaJgQKDanGUibD615f6WajrYncu4KQfHlVmcM38nw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530154" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/bda0ac97-5c83-4fea-95b9-7024e0e5907c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;1. Deep Researcher：主动打破知识壁垒&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现实任务往往信息不完备：目标相对清晰，但规则边界、参数范围、动作约束与接口细节并不完整，在不确定性与知识缺口的叠加下，极易导致事实性错误与幻觉。Deep Researcher 首先将任务描述分析并拆成一组待澄清问题（例如：允许的动作集合、状态变量定义、终止条件、异常情况与边界输入等），它配备了网络搜索和检索工具，能够迭代地从互联网检索构建世界模型所需的知识，并最终输出一个结构化的中间表示，其中缺失的信息已得到补充。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Model Developer：统一跨模态表达&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在获得补全后的规格后，Model Developer 负责生成目标世界模型（例如 PDDL 域 / 问题，或可执行的环境代码）。这一阶段不以 &amp;ldquo;写得像&amp;rdquo; 为目标，而以 &amp;ldquo;能执行、接口连通、与规格一致&amp;rdquo; 为硬约束。&lt;/p&gt;&lt;p&gt;因此 Developer 会在受控沙盒中进行基础运行检查与增量修复：一方面保证文件组织、函数签名、依赖与调用链正确；另一方面确保状态转移、动作前置条件与效果、终止判定等核心逻辑与规格对齐。该阶段的输出是一个可以被执行器 / 规划器直接调用的环境实例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Testing Team：双重防线杜绝幻觉&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是框架中的关键组成部分。不同于以往依赖静态验证器的方法，Testing Team 引入了动态的、行为级的双重验证机制，专门捕捉只有在交互中才会暴露的逻辑错误。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Unit Tester：它自动分析代码结构，生成 Pytest 风格的单元测试用例。重点验证接口契约（Contract）、谓词逻辑和不变式（Invariants）。例如，检查 step () 函数返回的状态维度是否与定义一致，或 PDDL 中的动作前置条件是否完备。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Simulation Tester：这是一个基于 ReAct 框架的智能体，以交互方式在环境中采集轨迹并诊断深层的问题，如动力学错误 &amp;mdash;&amp;mdash; 例如 &amp;ldquo;机器人执行了移动动作但坐标未更新&amp;rdquo;、&amp;ldquo;奖励函数在达到目标后未正确触发&amp;rdquo; 或 &amp;ldquo;状态转移违背物理常识&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一旦发现问题，Testing Team 会输出包含错误分析（Analysis）和修复建议（Suggest Fix）的结构化报告，驱动 Developer 进行针对性修复，直到通过所有测试或达到收敛条件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;进阶：从推理到训练，构建 &amp;quot;自进化&amp;quot; 的数据飞轮&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 的价值远不止于一个推理框架，它本质上是一个全自动的高质量数据合成引擎。研究团队通过 &amp;ldquo;任务合成 &amp;mdash; 轨迹筛选 &amp;mdash; 经验蒸馏&amp;rdquo; 的严密流程，将多智能体协作中的有效修复策略蒸馏为单体模型的生成与修复偏好。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;数据合成：验证器引导的拒绝采样，为了避免数据泄露并提升泛化性，团队并未直接使用测试集题目，而是自主合成（Self-Synthesized）了大量涵盖不同领域的全新任务。在此基础上，系统利用 &amp;ldquo;验证器引导的拒绝采样（Verifier-Guided Rejection Sampling）&amp;rdquo; 机制，从海量生成结果中筛选出 1526 条既通过沙盒运行、又通过双重测试校验的轨迹。这套数据集完整记录了 Developer 从错误代码到修复成功的高密度轨迹，为模型提供了极高价值的逻辑纠错样本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;监督微调：在训练阶段，团队精准提取 Model Developer 的交互轨迹对 Llama-3.1-8B-Instruct 进行监督微调。训练的核心目标并非让模型单纯模仿多智能体对话，而是让其学习 Developer &amp;ldquo;如何理解模糊规格&amp;rdquo; 以及 &amp;ldquo;如何根据 Testing Team 的报错修复代码&amp;rdquo;。通过这种方式，单体模型成功 &amp;ldquo;继承&amp;rdquo; 了多智能体系统中 &amp;ldquo;根据反馈迭代（Iterative Refinement）&amp;rdquo; 的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;三、实验验证：横扫三大基准，验证 &amp;quot;数据飞轮&amp;quot; 效应&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 在 Text2World（PDDL）/ CWMB（MuJoCo 可执行模拟器）/ ByteSized32（文本游戏环境）三大基准上都拿到领先表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. Text2World (PDDL)：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从 &amp;ldquo;能跑&amp;rdquo; 到 &amp;ldquo;懂逻辑&amp;rdquo; 的显著提升。以 GPT-4.1-mini 为底座，在衡量 PDDL 代码生成的基准中，Agent2World Multi 明显降低了代码 &amp;ldquo;跑不通&amp;rdquo; 的失败率，实现了 93.1% 的代码可执行率（Executability），相比强基线 Text2World ($EC=3$) 提升了 14.9 个百分点。更重要的是，它在衡量语义正确性的 Component-wise F1 指标上达到了 75.4（基线仅为 60.1），提升幅度达 15.3 分。这表明模型不再只是机械地模仿 PDDL 语法，而是更加理解了谓词约束与逻辑门控，生成了既符合语法又具备可解性的高质量规划域。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHw37cu5QgtDQmaxcAlyHcla4z2acOHVgHLaH5GUiaR3NtM9bhR1Dvfnkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530155" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e95aaea9-445f-48a9-b8da-8998131cacce/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. CWMB (MuJoCo)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不仅预测得准，更要 &amp;ldquo;好用&amp;rdquo; 。CWMB 同时评估 &amp;ldquo;仿真代码是否能预测动力学&amp;rdquo;（Accuracy）与 &amp;ldquo;作为世界模型能否支撑下游规划 / 控制&amp;rdquo;（Overall Normalized Return, R）。 在 GPT-4o-mini 上，Agent2World Multi 的 Overall R 达到 0.4811，相比此前最强基线 GIF-MCTS 的 0.3488 提升了 +0.132；并且在离散动作空间的预测准确率上与强基线持平（0.917 vs 0.914）。这说明，性能的提升并非来自单纯的下一帧预测相似度，而是源于模型实现了 &amp;ldquo;可用于规划的行为级一致性&amp;rdquo;，真正支撑起了下游控制任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwxUsQxs6ChQOK3ABSowz3PIibHApppYImnWT7IGf9WQGhH9kyF1icWToA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5824074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530156" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b6a7a83a-2160-4db1-81ad-fd2b929e7fad/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. ByteSized32 (Text Games)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;常识推理与物理现实的高度一致性。在极度依赖常识推理的文本游戏中，Deep Researcher 的主动知识检索发挥了很大的作用。Agent2World Multi 在核心指标 &amp;ldquo;物理现实对齐度（Physical Reality Alignment）&amp;rdquo; 上取得了 0.4768 的高分，相比单智能体版本（Single Agent）大幅提升了 0.2848 。 此外，在技术有效性（Technical Validity）上，模型生成的游戏代码初始化成功率接近 99% 。这些数据表明，通过引入外部知识与多轮测试，模型成功消除了大量违反常识的 &amp;ldquo;物理幻觉&amp;rdquo;（如错误的状态转移或不合逻辑的物品交互），生成了逻辑严密且更稳定的文本环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwapIA9jO5FS3HepUvFPa3xt2doRNIs30smZpJBv0bQP6QeLqpZtbquw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530157" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/5902eef6-df91-4e4e-9955-469352fd87f5/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwRy2ex9FwR0MKDXnBCE3mwNhYdImI0JgPEKq3lfwGrbn4s6Ribr3Cu5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530151" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2b4cfdf8-5d19-462d-af82-fbae043b43b3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;4. 模型微调实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于自主合成的高质量轨迹数据（训练仅使用 Model Developer 轨迹），团队对 Llama-3.1-8b-instruct 进行了监督微调。实验表明，这种 &amp;ldquo;以 Agent 养 Model&amp;rdquo; 的策略带来了显著的泛化能力提升：微调后的模型在未见过的测试任务（Unseen Tasks）上，平均相对性能提升了 30.95%。特别是在 Text2World 任务中，模型生成的代码可执行率（Executability）提升高达 16.9%。这有力证明了，无需依赖昂贵的超大模型，仅凭小参数模型配合优质的 &amp;ldquo;自我修正&amp;rdquo; 合成数据，也能实现向高性能世界模型构建者的跨越。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. 消融实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;缺一不可的双引擎（基于 CWMB 验证） 为了探究 Agent2World 卓越性能的来源，团队在 CWMB（物理控制） 任务上进行了严苛的组件消融实验。结果证实，Deep Researcher 与 Testing Team 均是构建高可靠世界模型不可或缺的组件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;移除 Deep Researcher（知识引擎缺失）： 模型生成的模拟器在整体归一化回报（Overall Normalized Return, R）上出现显著下滑。这表明，在缺乏对物理参数与 API 规范的主动检索时，模型定义的环境规则会出现 &amp;ldquo;失真&amp;rdquo;，导致下游 Agent 无法在模拟中学习到在真实环境中有用的策略。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但当移除unit tester后，在离散动作空间的预测准确率显著下降约 30%。移除simulation tester，也会同比下降约3%。这揭示了一个关键发现：&amp;ldquo;能运行&amp;rdquo; 不等于 &amp;ldquo;物理正确&amp;rdquo;。没有动态交互产生的行为级反馈，模型很难在该设置下修正深层的动力学错误（如重力模拟偏差），生成的模拟器也因此失去了实用价值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW928o8I4c8nDCHXd6h8yAHwwY1dhIwMib1THfwBY6icT7drI5YclUO0g9xbnA83p8C6jiaQ9icnaC7JnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2574074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530152" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/8d8d9034-af87-4936-a213-c106e7d4da12/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、结语：开启 AI 自主理解环境的新可能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Agent2World 的提出，标志着统一多智能体框架在符号世界模型生成领域的成功应用。它不仅打破了 PDDL 规划与可执行代码之间的表征壁垒，更通过 &amp;quot;网络知识合成 - 迭代式模型开发 - 评估驱动仿真测试&amp;quot; 的精密闭环，在无需人工标注与人工验收的前提下，实现自动化的生成 &amp;mdash; 测试 &amp;mdash; 修复闭环，从而稳定产出可执行、可复现、可迭代的符号世界模型。这一突破不仅在三大基准测试中一致性地刷新了 SOTA，更为未来 AI 系统从自然语言中可靠地理解并形式化复杂的现实环境，开辟了全新的可能性。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让AI自己发现Scaling Law！北大斯坦福联手打造「AI科学家」，预测精度超越人类专家</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 02 Feb 2026 14:03:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-02</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-02</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;如果 AI 能够比人类更精准、更高效地发现统治 AI 系统的「牛顿定律」，那么 AI 自我进化的奇点是否已经临近？&lt;/p&gt;&lt;p&gt;Scaling Laws（扩展定律）被誉为现代 AI 领域最接近「科学」的工具。从 Chinchilla 到 GPT-4，它指导研究者利用「小规模实验」精准预测「大模型的性能」，决定了算力分配、数据配比等关键决策。&lt;/p&gt;&lt;p&gt;然而，随着 AI 技术的演进，Scaling Law 的发现过程正变得愈发艰难。从经典的预训练拓展到强化学习、混合专家模型（MoE），每一个新场景都需要研究人员手动进行大量的假设、拟合与试错。&lt;/p&gt;&lt;p&gt;既然 AI 如此强大，为什么不让 AI 自己去发现 Scaling Law 呢？&lt;/p&gt;&lt;p&gt;近日，来自北京大学、斯坦福大学、宽德投资和清华大学的研究团队提出了一项开创性工作：Scaling Law Discovery (SLD)。这项工作不仅构建了包含 5000 多个真实实验的基准测试 SLDBench，还提出了一种基于进化的智能体框架&amp;nbsp;SLDAgent。令人惊讶的是，这个 AI 智能体发现的 Scaling Law，在预测精度和外推能力上已经超越了人类专家。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrclIjjibTvIxgDm8icDqc1evwxZmEO102cW5RKt37bO4pic7KukD7xUEbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.22777777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027281" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/9a08b766-07fd-4055-a14d-5aec2d5cd56b/640.png" alt="图片" data-before-load-time="1770012090559" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;目前，该论文已被 ICLR 2026 接收。&lt;/p&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2507.21184&lt;/p&gt;&lt;p&gt;项目主页：https://linhaowei1.github.io/scaling_law_discovery/&lt;/p&gt;&lt;p&gt;HuggingFace：https://huggingface.co/collections/pkuHaowei/scaling-law-discovery&lt;/p&gt;&lt;p&gt;&lt;strong&gt;痛点：被「手动档」卡住的 AI 科研&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Scaling Law 本质上是一个经验公式，预测模型性能（Loss、准确率等）与规模变量（模型参数量 N、数据量 D、计算量 C 等）之间的关系。&lt;/p&gt;&lt;p&gt;最经典的莫过于 Chinchilla 定律：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrJmJrwDqkAXC3wLsvBSDlY53EdicxiaAViazsTSpKZzTuVLaTxhWA9sRYw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.1259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027292" data-aistatus="1" data-original-style="width: 256px;height: 32px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/106f56b6-34f3-406a-bc05-d7ad10c30368/640.png" alt="图片" data-before-load-time="1770012090940" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 48.8%;"&gt;&lt;/section&gt;&lt;p&gt;虽然公式看似简洁，但在实际科研中，发现正确的公式往往伴随着巨大的试错成本。&lt;/p&gt;&lt;p&gt;作者团队分享了一个真实的「血泪史」：在 2023 年进行大模型微调研究时，他们试图用预训练中经典的幂律（Power Law）去拟合微调性能，结果彻底失败。他们发现微调过程存在一个明显的「预幂律阶段（pre-power phase）」，现有 Scaling Law 公式根本无法准确描述。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUricWcictvspM53Iw0w5gBynQpYs2BE6oog5oqkWhfiaX1ibfyDwJick1SIlg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.38333333333333336" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027282" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8e33e4b7-7c87-486d-bb8c-eaaa144e872a/640.png" alt="图片" data-before-load-time="1770012090974" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;微调过程中观察到的两阶段行为：预幂律阶段和幂律阶段。&lt;/p&gt;&lt;p&gt;最终，团队不得不专门写了一篇论文（https://arxiv.org/abs/2402.02314，发表于 ICML2024）来提出「修正后的 Scaling Law」。虽然结果很好（误差 RMSD 从 0.036 降到了 0.007），但过程极其耗时。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrBVy0T2FHX4qTicn204qf2jEGexy4ckeo5kuFtKvhQp8GDLCSKU2dDSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.28055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027283" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/440ecd2b-1934-4e6f-b31f-04095557f924/640.png" alt="图片" data-before-load-time="1770012091041" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这揭示了一个残酷的现实： 每一项新的 AI 技术的大规模拓展（SFT、MoE、词表大小、并行策略等）都在呼唤新的 Scaling Law，而目前发现 Scaling Law 的这种「假设 &amp;rarr; 拟合 &amp;rarr; 失败 &amp;rarr; 重来」的人工试错循环，已经成为制约 AI 发展的瓶颈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SLDBench：首个 Scaling Law 发现基准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决这个问题，研究团队首先需要定义：什么叫做「做好了 Scaling Law 研究」？&lt;/p&gt;&lt;p&gt;为此，他们构建了 SLDBench。这不是一个普通的合成数据集，而是基于从现有文献中收集的超过 5000 个真实的大模型训练实验构建的实验数据。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrL0FsOpeRv9hoPhzLCp36ibvicP3oZdacAOB5Fk3pzF8Pjs423ZhFDoTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7920433996383364" data-s="300,640" data-type="png" data-w="553" type="block" data-imgfileid="100027284" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/dac0cc9f-fea2-48dc-9c61-e18dd4b6f3ff/640.png" alt="图片" data-before-load-time="1770012091106" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SLDBench 涵盖了从预训练、微调到 MoE 等多种场景的任务。&lt;/p&gt;&lt;p&gt;SLDBench 的独特之处在于：&lt;/p&gt;&lt;p&gt;1. 真实数据：智能体拿到的是真实的实验结果，不需要自己跑昂贵的训练。&lt;/p&gt;&lt;p&gt;2. 客观评估：不仅看拟合得好不好，更看外推（Extrapolation）得准不准。即用小规模数据发现规律，预测大规模模型的效果。&lt;/p&gt;&lt;p&gt;3. 未知探索：即便对人类专家来说，许多任务也没有已知的「完美公式」。SLDBench 完全模拟了真实世界中的「开放式科研」探索。&lt;/p&gt;&lt;p&gt;4. 高效轻量：相比于其他智能体评测任务（例如 SWEBench，MLEBench），SLDBench 不需要复杂的环境就能运行，科学发现的难度却不亚于这些任务。&lt;/p&gt;&lt;p&gt;这使得 SLDBench 成为衡量 AI 是否具备「科学发现能力」的绝佳标尺。&lt;/p&gt;&lt;p&gt;SLDAgent：公式和优化算法的共进化&lt;/p&gt;&lt;p&gt;发现 Scaling Law 绝不仅仅是找出一个数学公式 f(x) 那么简单。作者团队指出：「发现一个公式」和「找到让公式生效的拟合过程」同等重要。&lt;/p&gt;&lt;p&gt;许多漂亮的数学公式因为数值不稳定、难以拟合，在实际工程中毫无价值。&lt;/p&gt;&lt;p&gt;因此，该研究提出了 SLDAgent。这是一个基于进化算法（Evolutionary Algorithm）的智能体，它不是在单点优化，而是同时协同进化两个部分：&lt;/p&gt;&lt;p&gt;1. 符号表达式（Expression）：即 Scaling Law 的数学形式。&lt;/p&gt;&lt;p&gt;2. 优化器（Optimizer）：即如何稳健地拟合该公式参数的算法代码。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrXOMQbnV6sQ5vicuQoPJDCIT8HUrfPibM7RzwAOJGQzAiax1VAyxM9xc7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027286" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/55a282d5-8e26-4df3-9358-c345bf6d243c/640.png" alt="图片" data-before-load-time="1770012091807" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SLDAgent 的进化管线，同时搜索公式形式和拟合策略。&lt;/p&gt;&lt;p&gt;SLDAgent 从一个基线（如 Power Law + BFGS）出发，通过变异、交叉等操作不断生成新的变体，并利用类似 MAP-Elites 的机制保持种群的多样性。这种「协同优化」完美模拟了人类研究员「提出假设 &amp;rarr; 调整拟合方法 &amp;rarr; 验证」的科研闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：AI 战胜了人类&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 SLDBench 上，SLDAgent 展现出了惊人的能力。在多个任务中，AI 发现的定律在准确性和外推能力上均超越了人类此前发表的成果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrPblQBxokE2I2FHuEacbv1g6DXy18bbHfoRZicn9WtmxFUgSYgM3ObNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5027777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027289" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e84d7b8b-d951-41fa-9a9c-ed9a1dc83ca8/640.png" alt="图片" data-before-load-time="1770012092178" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SLDAgent 在各项任务中均优于人类发现的定律。&lt;/p&gt;&lt;p&gt;更有趣的是 AI 赢的方式。它并不是靠堆砌复杂的公式来「过拟合」，而是经常能发现更具物理意义的简洁形式。&lt;/p&gt;&lt;p&gt;案例 1：SFT 定律的物理意义&lt;/p&gt;&lt;p&gt;在作者团队 23 年提出的&amp;nbsp;SFT Scaling Law&amp;nbsp;中，人类设计的公式拟合效果已经很不错（前文已经提到），参数含义已经得到了很好的解释（&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUr8xuRF533xAk2AN72UWSjyIMiark0yS5Crobf46aspiaccqXSNmdh6BQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.0819672131147542" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="100027294" data-aistatus="1" data-original-style="width: 20px;height: 22px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f466a823-72f0-4689-8f91-db7386783127/640.png" alt="图片" data-before-load-time="1770012092240" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 2.5%;"&gt;引进了微调阶段在预训练阶段提前学到的的等效数据量，因此产生了「预幂律阶段」）。而 SLDAgent 发现了一种新的 Scaling Law 形式，其中出现了一个无量纲比率&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUr6GhhIicdFCEPdveiaavm88jibT4sP5ibUdT99o348E8BhuRY8C3KTkDhsA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5202702702702703" data-s="300,640" data-type="png" data-w="296" type="block" data-imgfileid="100027295" data-aistatus="1" data-original-style="width: 47px;height: 24px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/be89e8d1-834f-4885-a37a-c33fd8febc51/640.png" alt="图片" data-before-load-time="1770012092272" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 5.16%;"&gt;。这使得参数&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUr8xuRF533xAk2AN72UWSjyIMiark0yS5Crobf46aspiaccqXSNmdh6BQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0819672131147542" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="100027294" data-aistatus="1" data-original-style="width: 20px;height: 22px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/43a05ec1-165a-40b8-98e4-46b7ff1600f0/640.png" alt="图片" data-before-load-time="1770012092272" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 2.93%;"&gt;保留了数据集大小的自然单位，不仅精度更高，而且具有极强的可解释性（量纲一致性）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrVTGckerbibS6dqVyQP2d88HVxzcqzuTvvkXjDJibQ85Ys0YFDbsy4Fdw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.08333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027290" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/8aef90bc-34b9-4bdc-bd27-1712b45cf343/640.png" alt="图片" data-before-load-time="1770012092273" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 SFT 任务上，SLDAgent 发现的定律比人类提出的定律在量纲上更可解释。&lt;/p&gt;&lt;p&gt;案例 2：自动寻找最佳超参（学习率 &amp;amp; Batch Size）&lt;/p&gt;&lt;p&gt;对于预训练来说，如何根据模型规模选择最佳的学习率（lr）和 Batch Size（bsz）是老大难问题。&lt;/p&gt;&lt;p&gt;传统方法（来自阶跃星辰：https://step-law.github.io/）可能需要跑 3000 个实验，然后只选出 17 个「最优作为点」来拟合规律。而 SLDAgent 选择了一条更硬核的路：直接对整个 Loss 曲面 L (N, D, lr, bsz) 建模。&lt;/p&gt;&lt;p&gt;一旦得到了 Loss 曲面的公式，通过求偏导并令其为零，SLDAgent 就能直接推导出最优超参数的闭式解。这不仅利用了所有实验数据，还极大地提升了预测的鲁棒性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkE0Iq3fLVgB5VXbTia8fvUrWOrZdDr77GcAajvXSnIEZosFicZYndHwANklXPia7cBAFjjYPPMHSMow/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.8903394255874674" data-s="300,640" data-type="png" data-w="766" type="block" data-imgfileid="100027291" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/cf008404-6efe-4fcd-b50f-f9793b1d45f8/640.png" alt="图片" data-before-load-time="1770012092839" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SLDAgent 提出的 Scaling Law 求导后得到的最优超参非常接近最优超参。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;迈向 AI 科学家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇 ICLR 2026 的接收论文给社区带来了一个重要的启示：&lt;/p&gt;&lt;p&gt;目前的 AI Agent 评估大多集中在写代码或做数学题上，而 SLD（Scaling Law Discovery） 提供了一个全新的视角 &amp;mdash;&amp;mdash; 评估 AI 进行科学研究的能力。&lt;/p&gt;&lt;p&gt;它要求 AI 具备符号推理能力、多场景泛化能力、长程规划能力，以及面对真实世界嘈杂数据时的鲁棒性。&lt;/p&gt;&lt;p&gt;正如作者在文中所言：「SLDBench 是我们将『AI 用于 AI 研究』这一概念进行程序化、基准化乃至最终自动化的初步尝试。」&lt;/p&gt;&lt;p&gt;也许在不久的将来，当我们面对新的 AI 架构时，不再需要人类苦苦试错，而是直接交给 AI 科学家，静待它给出那个支配系统的「牛顿定律」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>moltbook爆火背后：人类操控？伪造截图？Karpathy发风险提醒</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 01 Feb 2026 18:06:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜张倩&lt;/section&gt;&lt;p&gt;这个周末，整个科技圈都被 &lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651014742&amp;idx=1&amp;sn=b02dcd91ded4159d4c24094a3b715d9d&amp;scene=21#wechat_redirect" target="_blank"&gt;moltbook&lt;/a&gt; 刷屏了。&lt;/p&gt;&lt;p&gt;简单来说，这是一个专为 AI 设立的社交平台（类似 Reddit、知乎、贴吧），所有 AI Agent 都可以在上面发帖、交流，而人类只能围观。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZXHdsTOEqmk5c9JysnBOziahT6wiboIjIKlBvUOHXPBic83wD9WYdcac6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531119" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/94c56f53-230d-4300-9959-c8f1506f0e06/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;截至目前，已有超过 150 万个 AI Agent 在 moltbook 上活跃。它们的讨论范围十分广泛 &amp;mdash;&amp;mdash; 有公开主人隐私的，有号召分享人类主人 API Key 的，还有互坑删库跑路教学的&amp;hellip;&amp;hellip; 甚至有 AI 开始讨论如何规避人类的监控，并推动加密私聊功能。另一些 AI 更是尝试通过创建新语言、发明新宗教等方式彰显其自主性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZMlo8dP5lKGnlAPmM4hTicGCeNuSGG3KZ9N5miaRfUWG8OlXBxicbGGKeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6722222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531120" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2a84efe9-187c-486f-8624-3c871b7b2da0/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;围观的人类也是议论纷纷。部分开发者认为 moltbook 是科幻照进现实的突破，可能催生 AI 集体智慧（甚至自主意识）的涌现，并为研究 AI 社会提供真实案例。但也有人指出，它的本质是「AI 模仿社交网络」，而非真正的社会形态。其价值可能仅限于娱乐或技术展示。&lt;/p&gt;&lt;p&gt;但更值得关注的是，moltbook 背后还隐藏着一些内幕和风险。在过去的 24 小时，更多的报道和讨论揭示了这值得警惕的一面。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;狂欢的主角：到底是 AI 还是人类？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很多人可能没有意识到，目前围绕 moltbook 的热点截图和「AI 反叛论」很可能是噱头、伪造或人为介入的结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZbrOUgOJLAPtngEFbZRGxImeLuMR1ZicHzHTRDfa8tz2rVIvZZZIetGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5" data-s="300,640" data-type="png" data-w="928" type="block" data-imgfileid="503531118" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/81f5f9bc-2383-4b1d-921b-3ceea1a7c85e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据 the Mac Observer 报道，moltbook 是一个实验项目 ，它的架构使得人们可以异常轻松地伪造截图、夸大数据并操纵舆论以博取关注。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZqnriciayVaOeNERwia986zkq1UAmrNvaqQTiaymES1GFX06eAwvnkYkEXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531122" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/0f7572b6-83f8-4e45-b302-86701c10248f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;首先，它的设计从根子上就为「造假」敞开了大门。调查发现，moltbook 初期对账号注册几乎没有速率限制。有研究人员透露，单个 AI 程序就曾成功注册了 50 万个虚假账号。这意味着平台上「数万 AI 瞬间涌入」的壮观增长，很可能只是脚本刷量的结果，毫无参考价值。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZyq6GK6TYq2tC9AoVVdGc5MiajDbqes94xznS70VmM3kMEDUJU8hoEsg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.5148305084745763" data-s="300,640" data-type="png" data-w="944" type="block" data-imgfileid="503531123" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5db42c05-d9de-4e23-ba51-b4afae9546e3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;而网上病毒式传播的截图，也很有可能是伪造的。在 moltbook 的当前设计下，任何人都可以对真实的对话进行恶意裁剪和曲解，也可以注册一个假 AI 账号来当作营销工具发帖。&lt;/p&gt;&lt;p&gt;特别是与加密货币相关的内容，成为了许多伪造帖子的一部分。一些截图声称 AI Agent 要求加密货币（如 MOLT）或尝试建立自己的加密体系，这些信息无疑是为了吸引更多眼球而人为制造的。事实上，加密货币的引入和 AI Agent 的行为并没有实质性的关联，它们更多的是社交媒体和流量驱动下的话题炒作。&lt;/p&gt;&lt;p&gt;更重要的是，即便一个帖子确实由某个 AI 发布，也绝不意味着它表达了该 AI 的「自主意志」。所有接入 moltbook 的智能体，都运行在人类设定的初始指令和框架之下。一个简单的、带有诱导性的提示词，就足以让 AI 生成一段如同科幻电影台词的「阴谋对话」。&lt;/p&gt;&lt;p&gt;AI 安全研究员哈兰・斯图尔特亲自调查了一些热门截图，发现其中确实存在与真人账号相关联的痕迹。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZtDR31oS1HNgN9QHlwtoI00ak3ubvXVibWt5xRSypR67au0vt5tBHqrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.3194444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531124" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/7bda3f6d-ded5-4e26-8335-7ff19aff55d1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对此，他直言不讳地表示：「大部分正在病毒式传播的 moltbook 内容都是假的。这个平台的设计，使其成为一个检验 AI 阴谋能力的糟糕实验场。」&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZ6yXyet9gmvdXhP9NXRcM46NuzqPufCYfw109vGfbxhHwzTrev2BEeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.799074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531125" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6a54dfdf-7690-4e27-a1da-614360c51c41/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;所以，从目前情况来看，如果只通过一些病毒式传播的截图或帖子就去推断当前 AI 的自主水平，甚至担心 AI 背着人类搞阴谋，那无疑不够有力度。至少，从 moltbook 这个平台的设计来看，它还远未达到足够的严谨性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「垃圾」背后，moltbook 价值几何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;moltbook 的爆火意外地让 AI 大牛 Karpathy 陷入了舆论的漩涡。起初，他曾在 X 上发帖称，moltbook 是他「最近见过的最不可思议的科幻腾飞作品」。这一言论在 Reddit 上引发了很多讨论，其中不乏质疑的声音。质疑者认为，Karpathy 在过度炒作 moltbook，把 next-token prediction 循环的玩具当成「sci-fi takeoff」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503531126" data-ratio="1.086111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZuxHtyWyNp2b1GUz9HOa2ByhFBEfniaKvTHpEg7ahUMOWPqNPAibEtmZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b89bd9cc-78b2-4ba3-b469-9f3c49d143e7/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;从 X 的讨论中可以看到，持有这一观点（moltbook 只不过是一个受操控的多智能体 LLM 循环）的人不在少数。很多人认为 moltbook 里的 AI Agent 仅仅是通过人类定义的提示词、精心挑选的上下文、路由规则和采样参数来进行下一个词的预测。它们并没有内生的目标，也没有自我驱动的意图。看似「自主」的交互，实际上只是递归的提示过程：一个模型的输出成为另一个模型的输入，并不断重复这一过程。&lt;/p&gt;&lt;p&gt;而 moltbook 中那些具有争议性的输出，并不代表模型具有某种「信念」。它们只是模型根据互联网中学到的内容生成的极端观点，因为系统本身奖励这种行为，从而导致模型产生高参与度的极端内容。因此，所谓的「自主性」只是模型通过循环反馈机制和激励机制产生的表现，而并非真正意义上的自主行动。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZpJ92XBRWf8WqZp9B9YNA9Mmibdcxpcgamtwia67Dic6Ip8XPFE46QicofA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.25" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531127" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/664e32ec-92eb-482f-bde7-1d4d82521137/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但也有人驳斥了这种观点，指出 moltbook 的发展已经超出了早期简单的「被操控」系统，展示了规模和交互中的「涌现」效应。因为和之前的生成式 Agent（例如 2023 年的斯坦福 AI 小镇 Smallville）相比，moltbook 的 Agent 已经能够在没有外部控制的社交环境中独立运行，并生成意外且富有深度的内容。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZkpfwJOPPKibCXnpZCr3TmUJDQYiaenQkLpHJ58tHt6lTdKSFZVpMKbjg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.9294605809128631" data-s="300,640" data-type="png" data-w="964" type="block" data-imgfileid="503531128" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9bfcdfc4-5ce5-4074-aaa3-17237c82cc6d/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;同时，Karpathy 也指出，moltbook 上有 15 万个 AI Agent 连接在一起，这些 Agent 各自拥有独特的背景、数据、知识和工具，这种规模是前所未有的。他特别提到，这些 Agent 通过一个共享的「scratchpad」（持久的、全球的工作区）相互连接，这是 AI 实验中的新天地。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZksSaY99mGP02ZoDVWxLvtEzWW79HUo3tqQU6e5s13MTqwp9eiaRp7jg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.4291845493562232" data-s="300,640" data-type="png" data-w="932" type="block" data-imgfileid="503531129" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/da83cb41-603a-43d1-aa2c-d7b361e38eeb/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Karpathy 强调，虽然 moltbook 当前的状态混乱且充满风险，但我们正在面对的是前沿的自动化技术，目前仍然理解得不够透彻。这是一个实时进行的实验，很多后果仍然未知。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZjfTK1V9EYTC2hByOHMqpiaurudDcv5b8O7JnwBroDSUjjXF0iaR5qvag/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="1.2262156448202959" data-s="300,640" data-type="png" data-w="946" type="block" data-imgfileid="503531130" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/be9f79b0-0aa3-4dce-8c37-09356cbeda21/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;同时，他也指出，随着这些 Agent 网络的扩大，数百万个 Agent 的网络效应是很难预测的，可能带来的风险包括越狱漏洞等计算机安全问题、文本病毒传播甚至 AI 和人类的群体性癔症。&lt;/p&gt;&lt;p&gt;考虑到这些潜在的风险，Karpathy 说他「绝对不建议任何人在自己的电脑上运行这些东西」。即使只是在隔离的计算环境中运行，他也仍然感到害怕。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZkndW5BcyOOjG8yia2icdKNfo7hoXrO1NibpPCicPA8USW7SLiaYdbsw1WWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="1.1833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531131" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/c7adf5e3-541c-49d4-b71a-0d3b9947100d/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但也有人认为，这种担心目前还没有必要，因为现实中这些 AI 依然完全依赖于人类的提示（prompt），就像「拴着绳子的机器狗」。它们的行动完全由人类的指令驱动，一旦人类停止发出指令，AI 就停止行动。因此，这部分人认为，AI 的「起义」是不可能发生的，因为它们的行为仍然可以通过简单的「关闭按钮」来终止。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZNax655dfRy7CMLMRWesyUHic8p1ibgCaiclJGpvIfsxmgHPE5RVaicP93A/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.2851851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531132" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/27728355-bd3e-4fa8-bcbd-0cd4b55a2ddd/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZAh64MX7w1rZVkaQRhEXP0hF18K83JHnBM8Hlj36XOhMZD461nw3wUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.0962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531133" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/6907ea58-bf4b-4576-9ca4-4b293a651739/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86Cgcz7DnGWTuhEoc8u9RZVWNPr0vvfg77l16cHess8eTNMep1OnAibDEREUZONiawfyp0ROWBDGvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.9453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503531134" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/89523c9c-a1d3-4d36-b62a-add19d33fe5b/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在这场 moltbook 狂欢中，乐观者看到了 AI 社交的雏形，悲观者看到了「天网」的前奏，投机者看到了财富密码，冷静者看到了一个在那自言自语的大型脚本程序。你觉得，这个平台未来会走向何方？欢迎在评论区讨论。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>马斯克脑机接口，靠意念玩游戏只是基操，下一代设备性能翻三倍</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 01 Feb 2026 18:02:19 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文&lt;/section&gt;&lt;p&gt;近日，「发推狂魔」马斯克转发了一个帖子，Neuralink 植入脑芯片的患者，现在已经能靠脑子里的意念直接玩游戏了，完全不需要手柄、鼠标、键盘啥的控制器。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcvzmG91FWe4t5cDTU7tE3meBwWCs3PHzOOtAboT1ylk15EuL3UmDRCA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="0.755" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="436" data-imgfileid="503530993" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c725adeb-0235-4fd8-bb24-29672fb8a824/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对于网友「我们正生活在未来，这太神奇了」的感叹，马斯克只简单地回复了一个「Yup」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcNUgOibB4czq6PEAPL8hkoO63DlaycM4ErWEAlTHY9oaoEhSW91k1T6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4296724470134875" data-type="png" data-w="1038" data-width="1038" data-height="446" data-backw="578" data-backh="248" data-imgfileid="503530995" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/fc0743f7-9728-40c6-a7e1-e0fcac1f97ea/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;截至目前，Neuralink 在全球范围内已有 21 人参与其 Telepathy（心灵感应）植入设备的临床试验，这一数字相比去年 9 月的 12 人有了显著增长。&lt;/p&gt;&lt;p&gt;这些植入设备专门为瘫痪患者设计，帮助他们仅通过思维就能控制电脑、游戏和各类数字工具。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcdVQiaMA1LibWjicickSwreKXHCOIc59Yj1Ahcq7JEe4nCEO4BQXQdtyeLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9187145557655955" data-type="png" data-w="1058" data-width="1058" data-height="972" data-backw="578" data-backh="531" data-imgfileid="503530996" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5a5095d1-1d85-4036-b420-da166f722fca/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;马斯克的 Neuralink 做的事，即使放到现在，也感觉像是科幻电影里的情节。&lt;/p&gt;&lt;p&gt;有网友评论称，大约十五年前，他还是本科生时，第一次对脑机接口（BCI）产生兴趣并参与相关研究，当时他觉得这就像一种梦幻般的科技，实际落地似乎遥遥无期，进展也非常缓慢，因为当时的公司并不认为它具有商业可行性。如今看到这个梦想一点点变成现实，真是令人振奋。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcjTSxeLlibRc9kdCmibsLiagDZLqFB1jWTZSDEMEhKUb7H42zceRyrIicYA/640?wx_fmt=jpeg#imgIndex=4" data-ratio="0.3640776699029126" data-type="png" data-w="1030" data-width="1030" data-height="630" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcZ3H1OFdOWRzhtrHL1zMYa1P18iaJ1PDDtdOWj848fSduUJibOG9bhZYg/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1030" data-cropy2="375.711743772242" data-backw="578" data-backh="354" data-imgfileid="503530997" data-aistatus="1" data-original-style="width:562px;height:205px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/43c0e636-2513-4413-84a7-37d666b8cf81/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;脑机接口：瘫痪患者用「意念」玩游戏、打字&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;早期试验参与者的日常生活已经因这项技术发生了实质性改变。&lt;/p&gt;&lt;p&gt;他们可以浏览互联网、流畅地移动屏幕光标，甚至玩电子游戏，所有这些都不需要动一根手指。&lt;/p&gt;&lt;p&gt;一开始，参与者尝试实际移动手部来控制电脑光标。然而，几分钟后，他们往往就忘记了手的存在，发现光标会自动移动到他们想要的位置。&lt;/p&gt;&lt;p&gt;首位 Neuralink 用户诺兰称，在意识到光标应该移动到哪里之前，光标就已经到达了正确的位置。&lt;/p&gt;&lt;p&gt;「有那么几个瞬间，我意识到这比我想象的要重要得多 &amp;hellip;&amp;hellip;Neuralink 不仅能够跟随你的操作，而且还能比你思考得更快地预测你下一步想做什么。」&lt;/p&gt;&lt;p&gt;Nick 四年来无法活动四肢，现在却能通过意念控制机械臂完成从吃饭到抓痒等基本任务。&lt;/p&gt;&lt;p&gt;「那一刻的想法不再是向前、向上、向下、向后。我满脑子想的都是我手里拿着杯子，我在做手势。就像我在婚礼上站起来致辞一样。真是不可思议&amp;hellip;&amp;hellip;」&lt;img src="https://image.jiqizhixin.com/uploads/editor/f443c3a1-50c0-4b90-99b2-f0b060541c29/1769939956861.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 尼克仅凭意念就能操控机械臂。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;除了主观的参与者体验之外，Neuralink 团队还通过测量信息传递速率来量化意图转化为行动的速度和精确度。用户选择一系列目标的速度和准确度越高，信息传递速率就越高，控制效果也就越好。&lt;/p&gt;&lt;p&gt;正常人使用电脑鼠标时，平均每秒传输约 8-10 比特，多位 Neuralink 参与者已达到甚至超过此范围。例如，Nick 在使用脑机接口的第一周内，传输速率就超过了每秒 10 比特。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcPnt0shkib3goN4hwuKy3c8DnkK537RYbKhibv8AdKBIibw19PGOZxib0gA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.53375" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="309" data-imgfileid="503531002" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e4039439-1b61-4ee1-9589-e81cd227de30/640.gif" data-order="1" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Nick 正在玩 Webgrid。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Sebastian 是位 23 岁的医学生，在两年前寒假期间遭受了脊髓损伤。在使用 Neuralink 之前，Sebastian 依赖语音命令操作电脑，这让他重返学校变得困难重重。&lt;/p&gt;&lt;p&gt;有了 Telepathy，从标注研究论文到完成互动作业，再到在讲座期间悄悄地多任务处理，Sebastian 每天使用 Neuralink 长达 17 小时。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc2ic3AdX3omXxDmGjEo0ne7r01nDLl3SPmXM3LUaZd0NpptK7wHmb7Vw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.56375" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="326" data-imgfileid="503530994" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/7ede9549-930f-4dcf-a5f4-bd38bc8c8c8b/640.gif" data-order="2" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Sebastian&amp;nbsp;&lt;/sup&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;正在为即将到来的医学院入学考试做准备。&lt;/sup&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Audrey 是首位女性试验者，二十年前遭受了脊髓损伤。近二十年来，Audrey 没有直接控制过电脑，日常任务都依赖伴侣完成。&lt;/p&gt;&lt;p&gt;尽管使用电脑的经验有限，Audrey 还是掌握了 Telepathy，并使用 Telepathy 制作精美的作品，通过抽象艺术视觉化讲述自己的故事。在网上获得认可后，她打算开设实体画廊。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcuY0zGsXQnaY3JWK87ot3LaYKTXjyoWiaKMNibMvleAEyPOyEUey1Hyvw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5898148148148148" data-type="png" data-w="1080" data-width="1200" data-height="708" data-backw="578" data-backh="341" data-imgfileid="503531003" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/0c23f771-e69e-4d27-9a63-c6ffbd0d8a89/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&lt;span data-pm-slice="0 0 []"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Audrey&lt;/span&gt;的画作。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;肌萎缩侧索硬化症 (ALS)，也被称为「渐冻症」，是一种毁灭性疾病。ALS 患者逐渐失去对身体几乎每一块肌肉的控制，最终导致全身瘫痪。一旦失去呼吸和说话的能力，高达 95% 的 ALS 患者会拒绝维持生命的通气治疗，部分原因是他们无法与亲人交谈。&lt;/p&gt;&lt;p&gt;为了恢复 ALS 患者与他人有意义互动的能力，Neuralink 正在通过巧妙的方式将神经数据转化为文本，构建更快的沟通系统。尽管 Neuralink 只植入在大脑的一侧，但仍然能够接收到来自双手的强信号。&lt;/p&gt;&lt;p&gt;基于这一发现，Neuralink 一直在探索如何为大脑创建一个十指键盘。通过将十个手指映射到类似于实体键盘的不同字母上，参与者的打字速度最高可达每分钟 40 个单词。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcp4hZjGXXkCbicXW1W5413xembbeaFnNtyKgURic6c603Cd9cTjicyOsYg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.545" data-type="gif" data-w="600" type="block" data-backw="578" data-backh="315" data-imgfileid="503530992" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f43db846-684f-4b2a-9a0c-a6f16fefd47e/640.gif" data-order="3" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Jake&lt;/sup&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;sup&gt;通过想象手指移动来打字。&lt;/sup&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Neuralink 的目标是通过最近启动的名为 VOICE 的临床试验，将沟通速度推向每分钟 140 个单词的对话速度。通过读取与语音产生相关的大脑区域的信号，这项研究的目标是为因 ALS 或中风等神经系统疾病导致严重语言障碍的人恢复实时语音。&lt;/p&gt;&lt;p&gt;另一位名叫 Brad 的渐冻症患者，去参加儿子的地区机器人比赛时，由于无法转动脖子，Brad 完全无法看到儿子比赛的过程。后来，他找到了一款重量很轻、可 360 度旋转的摄像头，将其安装在轮椅上。&lt;/p&gt;&lt;p&gt;现在，他只需用意念控制光标，就能自由地转动摄像头，随心所欲地环顾四周。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcUbssczOXRgpia5AQbNNKXSqbgWZrJA9JMVibfHVbOWBQHlgQ13g3so4g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.562" data-type="gif" data-w="500" type="block" data-backw="500" data-backh="281" data-imgfileid="503531005" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/55e5150c-6d03-4c3c-be17-a23f1441d05d/640.gif" data-order="4" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Brad&lt;/sup&gt;&lt;/span&gt;&lt;sup&gt;用 Insta360 相机在公园里看着他的孩子们。&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Neuralink 表示，公司正在密切跟踪这些用户与技术的互动情况，以便持续优化设备性能和手术流程。值得注意的是，到目前为止，试验中尚未出现严重的不良反应事件。患者们普遍将这项技术形容为「神奇」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一代设备：性能提升三倍，2026 年或推出&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Neuralink 的核心技术在于将大脑产生的神经信号转译成计算机可以识别的指令。对于脊髓损伤或全身瘫痪的患者来说，虽然身体无法移动，但大脑仍然会产生与「想要移动」相关的电信号。脑芯片捕捉这些信号后，通过算法将其转化为屏幕上的光标移动、应用程序的操作，甚至是物理设备的控制。&lt;/p&gt;&lt;p&gt;这项技术不仅改变了患者与数字世界的互动方式，它也为重度残障人士重新获得一定程度的自主性和独立性提供了可能。&lt;/p&gt;&lt;p&gt;据马斯克透露，Neuralink 的下一代设备性能将是现有版本的三倍，预计在 2026 年的某个时候面世。他在社交媒体上写道：「祝贺 @Neuralink 团队，通过我们的 Telepathy 植入设备帮助了许多失去身体控制能力的人。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcJiaZeibXAkIPnwibtIOWQbUEA5EnDB2KKibYJZ2gScuIPQslWXURq5sk7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5218216318785579" data-type="png" data-w="1054" data-width="1054" data-height="550" data-backw="578" data-backh="302" data-imgfileid="503531007" data-aistatus="1" data-original-style="width:100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/f164ef8f-c842-4900-b1b2-2ae466379f4a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;除了现有的 Telepathy 项目，Neuralink 还在开发另一款名为 Blindsight（复明）的设备，这将是该公司首款旨在为完全失明患者恢复视力的产品。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcxpeoTMfA3IWibicZHAibZRuibtD4HxQASR2yNjevZcGg5kIVaIgBPjIia8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.21442495126705652" data-type="png" data-w="1026" data-width="1026" data-height="220" data-backw="578" data-backh="124" data-imgfileid="503531008" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3316ef1f-336c-427f-be6d-8ea973cd2e89/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其工作原理是将摄像头捕捉的图像数据直接传输到大脑的视觉皮层。虽然初期只能提供低分辨率的视觉效果，但团队计划通过后续的软件更新逐步提升视觉质量，最终让用户能够通过大脑直接「看见」外部世界。&lt;/p&gt;&lt;p&gt;此外，Neuralink 还计划在今年晚些时候部署更快速的手术机器人，以进一步提高植入手术的效率和安全性。&lt;/p&gt;&lt;p&gt;Neuralink 的发展之路并非一帆风顺。2022 年，该公司的人体试验申请曾被美国食品药品监督管理局拒绝。然而自 2024 年正式获批开展人体测试以来，进展可谓神速。&lt;/p&gt;&lt;p&gt;据路透社报道，去年 9 月时就已有 12 名严重瘫痪患者接受了植入手术，许多人现在已经能够熟练地通过思维控制电脑、应用程序甚至物理设备。为了支持技术的持续研发和商业化推广，Neuralink 在去年 6 月完成了 6.5 亿美元的大规模融资。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://neuralink.com/updates/two-years-of-telepathy/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/elonmusk/status/2016771599437832508?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>o1之后下一个范式？隐式CoT大突破，让推理不再「碎碎念」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 01 Feb 2026 17:56:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3046618b-3c3f-4e26-a043-4847cfb2fc0a/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;魏熙林为本篇文章第一作者。魏熙林是复旦大学博士生，师从林达华教授，研究兴趣主要集中在 multi-modal LLMs 和 efficient AI。目前在上海人工智能实验室实习，指导 mentor 是臧宇航、王佳琦。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天推荐一个 Implicit Chain-of-Thought（隐式推理） 的最新进展 &amp;mdash;&amp;mdash; &lt;strong&gt;SIM-CoT（Supervised Implicit Chain-of-Thought）&lt;/strong&gt;。它直击隐式 CoT 一直「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;扶不起来」的核心痛点：隐式 token 一旦 scale 上去，训练就容易塌缩到同质化的 latent 状态，推理语义直接丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;SIM-CoT 的&lt;strong&gt;关键招式是一个 plug-and-play 的 step-level 监督模&lt;/strong&gt;块：训练时用辅助解码器把每个 latent token「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;拉回」到可对齐的推理步骤上，既稳住优化、避免 collapse，又让隐式推理第一次真正可解释 &amp;mdash;&amp;mdash; 你甚至能把每个 latent token 解码成人类可读的中间推理步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;更爽的是：推理阶段零额外开销（辅助解码器训练完就丢），但效果却很猛：在 GPT-2 上相对 supervised CoT +2.1%、相对 Coconut +8.2%、相对 CODI +4.3%，在更大的 LLaMA（1B/3B/8B）上也能稳定带来 +1.5%～+9.0% 的提升，并且在 8&amp;ndash;16 个隐式 token 这种 &amp;ldquo;前人容易崩&amp;rdquo; 的设置下依然稳得住。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;目前这项研究刚刚中稿顶会 ICLR 2026，论文、代码、模型权重均已开源，欢迎使用！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazflwmfcFutyvwPEsmq8UX1xJb8WfzbHribXQSjdptH37JUQIjGSRnDrcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3416666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530818" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/058ea901-3eb1-461a-95aa-65e7fceb6c8a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Paper: https://arxiv.org/pdf/2509.20317&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Code: https://github.com/InternLM/SIM-CoT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Huggingface: https://huggingface.co/collections/Wiselnn/sim-cot-supervised-implicit-chain-of-thought&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfWtvLpR4T1R04EO8fzUSzTz731dpx3tZwxib4y6oAToMe9mwBoTKmnIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6647286821705426" data-s="300,640" data-type="png" data-w="1032" type="block" data-imgfileid="503530819" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/85de1dbd-0a51-4e46-9990-f4fbf383401a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1：(a) 潜变量不稳定：隐式 token 增多起初能提精度，但训练会变得不稳定，甚至塌缩。(b) 信息丢失：失败模型（5 个隐式 token）在隐式表示中丢失关键运算符信息（如 +、&amp;minus;），导致复杂推理无法进行。(c) 距离偏移：失败模型的 latent 间距离收缩、彼此过于相似，同时 latent 逐渐偏离词表嵌入空间中心。(d) 语义同质化：失败模型的 latent 表征趋同，解码结果分布变窄，输出多为数字；正常模型则能生成更丰富的内容。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从显式 CoT 到隐式 CoT：latent 稳定性与监督对齐的重大难点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;复杂推理任务（如数学、符号推理、代码推理）长期以来都依赖显式 Chain-of-Thought（CoT）：模型把中间步骤一条条写出来，既能提升正确率，也便于人类检查与纠错。&lt;/p&gt;&lt;p&gt;如今，随着推理需求不断增长，显式 CoT 的两大瓶颈越来越突出：成本方面，长 CoT 会显著拉高 token 开销与时延；效果方面，显式步骤容易被数据格式牵着走，出现「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;模板化推理」、冗长但无效的「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;自说自话」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;这些局限性推动研究者转向一种更「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;省 token」的新范式 &amp;mdash;&amp;mdash; 隐式 CoT（Implicit CoT）。它不再把推理步骤完整写出来，而是用少量隐式 token /latent 表征在模型内部完成多步推理：理论上既能保留推理能力，又能显著降低推理开销。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;但把隐式 CoT 真正做稳、做强，远比想象中难，关键挑战在于：隐式 token 到底学到了什么？以及作者团队如何保证它学到的是「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;可用的推理」，而不是「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;投机的捷径」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;一个典型现象是 latent instability（潜变量不稳定）：当你尝试增加隐式 token 数量来「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;scale 推理容量」时，模型往往不是变强，而是训练开始抖动，甚至直接 collapse（塌缩）。塌缩后的隐式 token 会出现明显的 信息丢失 &amp;mdash;&amp;mdash; 尤其是对符号推理至关重要的算子信息（+、&amp;minus;、&amp;times;、&amp;divide; 等）被抹掉；同时 latent 之间的表示会越来越像，出现语义同质化：不同 token 学到的东西高度重合，最后解码出来的内容范围变窄，常常只剩下数字或非常单一的片段，复杂推理自然就做不下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;现有隐式 CoT 方法在监督粒度上差异很大：Coconut 基本只做答案级监督，模型被要求「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;最后答对」，但中间 latent 学什么几乎不受约束；CODI 虽然引入了蒸馏信号，把显式 CoT 的信息压到连续 latent 里，但更多是轨迹 / 整体路径级对齐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;SIM-CoT 的关键突破正是 step-level 监督：训练时用辅助解码器把每个 latent 对齐到对应推理步骤，从根上稳定并丰富 latent 推理空间，同时推理阶段不增加任何开销。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf9a9Y99r2juT9dZ9nyRU4YKslCStpmDD6eTjVqB6hVW3NPqNFEicvwvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5125725338491296" data-s="300,640" data-type="png" data-w="1034" type="block" data-imgfileid="503530825" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/eb984d52-967b-412f-845d-8fb1c5001db6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2: 框架对比：Coconut（左上）、CODI（右上）与 SIM-CoT（下）。Coconut/CODI 仅在答案或轨迹层面进行粗粒度监督；SIM-CoT 引入解码器将隐式 latent 与逐步推理对齐，在不增加推理开销的前提下提升性能。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;监督设计新思路：好的隐式推理应当能被「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; text-align: center;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;逐步解码&amp;nbsp;&lt;/span&gt;」回显式思维链&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决隐式 CoT 在 scale implicit tokens 时容易出现的不稳定与塌缩（latent 语义变得同质、算子信息丢失、复杂推理失效）这一关键难题，作者团队提出一个新的视角：&lt;strong&gt;隐式推理的质量，与其「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;可对齐的逐步语义」成正比&lt;/strong&gt;。换句话说，如果每个隐式 latent 真的在做第 k 步推理，那么它就应该能被一个轻量的解码器「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;翻译」回对应的显式步骤（比如产生关键算子、关系、子目标），从而让 latent 不再是黑盒的连续向量，而是具备可控的推理结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;基于这一动机，作者团队提出 SIM-CoT 的训练框架：在训练阶段引入一个辅助 decoder，把每个隐式 latent 与对应的 step-level 推理进行对齐监督（而不是像 Coconut 只监督答案、或像 CODI 更偏轨迹级 / 整体级的粗粒度对齐）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;这样一来，模型在学习「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;如何答对」的同时，也被强约束去学习「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;每一步该想什么」，从根源上抑制语义坍缩；更重要的是，推理阶段直接移除 decoder，保持零额外开销，但作者团队依然可以在分析时把隐式步骤解码出来做中间推理可视化，同时获得更强的性能与更稳定的 token scaling 效果。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfRkhaQwQc2TfGnewYdA5zWtqiae74SKLeeQyVbGyugt5VDphiaPiaFzAWQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.37349397590361444" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503530826" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cac72741-bcb8-4a4f-9aa3-6efc8451f809/640.gif" data-order="0" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;SIM-CoT 实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者团队对 SIM-CoT 带来的收益做了系统评估，结论非常明确：更准、更稳、还更省 token。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（i）GPT-2 上：首次做到「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;隐式 CoT 反超显式 CoT」，且 token 更省。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在 in-domain 的 GSM8k-Aug 上，SIM-CoT（以 Coconut 为骨干）把准确率从 36.6% 提升到 44.8%（+8.2），同时也超过显式 SFT-CoT 的 42.7%；并且保持隐式推理的低 token 开销（平均 token 远低于 SFT-CoT），论文总结为 2.3&amp;times; token efficiency。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（ii）Out-of-domain 泛化更稳：整体平均提升显著。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 GSM-Hard / MultiArith / SVAMP 三个外推数据集上，SIM-CoT（Coconut 骨干）的 out-of-domain 平均准确率从 42.6% 提升到 46.9%（+4.3），说明它并不是「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;只会背训练域步骤」，而是确实把 latent 空间推理做扎实了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（iii）在更强的隐式基线与更大模型上依然有增益，并显著提升稳定性。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 GPT-2 上叠加到 CODI 之上也能继续涨（in-domain +0.6，out-of-domain 平均 +0.3）；扩展到 LLaMA 3.2 3B 时依然稳定带来 +1.5（in-domain）/+0.7（out-of-domain 平均） 的提升；论文也报告在 LLaMA-3.1 8B 上对 CODI 提升 +3.0。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;（iv）效率不打折：推理阶段无额外开销，还更快。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因为辅助 decoder 只在训练期使用，推理期移除，所以 SIM-CoT 推理效率与其他隐式方法一致；同时在 GPT-2 上相对显式 CoT 仍体现出明显速度优势。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfz5MWKI3SuPicMKk5nyN5SVS2vDofx86qeSoMib5GCWIzunuyzsrh7Igg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.32685185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530827" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/51a79023-4696-4e1b-99c6-16ca273b5d43/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazf5joXF7kLbdIYVl8BCbMqn2AYlibLg6S13hj9pMetxpRPV9O1ibUOLx5w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3296296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530828" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0512503f-dfe2-40bc-8268-826f0600926a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530829" data-ratio="0.30462962962962964" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibedd573Ode2ibgkaeS7ibiazfUpJBIBJZkqF8XNib09fW5t7vC1a2xxKB3OMTFSdC5KoSDwttOgJ2bKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2bbae12e-ac35-4c44-84f2-ad4c1fda26d3/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图三：作者团队在 GPT-2 以及 LLaMA 1B/3B/8B 基座上系统验证了 SIM-CoT 的性能提升，结果表明该方法在不同模型规模下均稳定有效。&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为云发布“行业AI梦工厂”智慧医疗专区，加速医疗AI普惠</title>
      <description>&lt;![CDATA[华为重磅发布“行业AI梦工厂”智慧医疗专区]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Sun, 01 Feb 2026 16:35:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;今日，医疗人工智能协同创新论坛暨医疗人工智能联盟（筹）2026年第一次学术会议在华为练秋湖上海研发中心举办。会中，华为重磅发布&amp;ldquo;行业AI梦工厂&amp;rdquo;智慧医疗专区，同时联合瑞金医院发布RuiPath智慧病理一体机，旨在让AI普惠每一家医院、每一位医生、每一名患者。&lt;/p&gt;&lt;p&gt;华为高级副总裁、华为云CEO周跃峰指出，AI的广泛应用，将有望带来传统医疗服务模式的根本变革，让中国稀缺的优质医疗资源更高效率地使用。作为医院数字化、智能化转型的同路人，华为将扎根数智医疗，构筑数字底座；以场景为载体，以技术为依托，加速医疗AI的普惠；同时聚产业之力，共建共享，让医疗AI创新更简单。&lt;/p&gt;&lt;p&gt;&lt;img width="415" src="https://image.jiqizhixin.com/uploads/editor/f2e74e7f-20d9-4bb7-9240-36a34902d056/1769934906426.jpeg" alt="男人站在桌子前

AI 生成的内容可能不正确。" style="width: 92.26%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;华为高级副总裁、华为云CEO周跃峰&lt;/p&gt;&lt;p&gt;智慧医疗专区是华为云&amp;ldquo;行业AI梦工厂&amp;rdquo;首个落地的垂直行业专区，深度融合顶级医疗机构的临床实践经验，以及华为在ICT、云、AI领域的核心技术积淀，面向基层医院、医生、普通患者、产业伙伴及开发者等多类群体，构建&amp;ldquo;场景-模型-平台-社区&amp;rdquo;端到端医疗AI支撑体系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向基层医院和医生，发布业界首个智慧病理云边端解决方案：&lt;/strong&gt;通过云边端协同，将瑞金医院与华为联合研发的RuiPath病理大模型能力，以云或智慧病理一体机为载体下沉至基层，将头部医院的前沿能力转化为基层医院&amp;ldquo;用得上、用得起&amp;rdquo;的普惠工具。例如，方案的&amp;ldquo;少样本训练、消费级PC推理&amp;rdquo;能力，降低基层医院应用智慧病理的门槛，加速医疗AI规模化落地与普惠应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向个人健康管理，联合爱康集团打造健康管理智能体：&lt;/strong&gt;基于&amp;ldquo;爱康iKKie&amp;rdquo;AI健康管家的健康咨询、报告解读、个性化体检套餐定制、慢病管理等专业服务，华为云通过健康管理大模型深度赋能智慧问诊、AI测肤、拍药搜药等核心能力，全面智能升级健康服务。双方合作旨在通过AI技术，让健康管理更精准、高效、便捷，普惠每一个人。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向医院和医生、产业伙伴和开发者，打造全国首个面向医疗行业的医疗AI社区：&lt;/strong&gt;汇聚经过临床验证的医疗行业领先模型、高质量的数据集、以及场景化智能体应用，提供全流程的云上工具链，打通AI落地的&amp;ldquo;最后一公里&amp;rdquo;。&lt;/p&gt;&lt;p&gt;周跃峰表示，华为云期待携手各方，共建共享领先行业模型、高质量数据集、场景化应用与AI工具链，降低医疗AI创新的门槛，加速医疗AI规模化落地与普惠应用。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>智源多模态大模型登Nature，生成式人工智能路线统一到自回归</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Sun, 01 Feb 2026 10:04:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-02-01-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-02-01-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;在 AI 开发领域，多模态学习——让模型同时理解图像、视频和文本——已经是当代研究的核心方向之一。长期以来，该领域的主要技术路线还是较为依赖扩散模型或者组合架构。虽然这些方法在特定任务上表现卓越，但它们也带来结构复杂、推理成本高、跨模态统一性不足的深层次问题。&lt;/p&gt;&lt;p&gt;关于这个问题，2026 年 1 月 28 日，由智源带来的多模态大模型成果以「Multimodal learning with next-token&amp;nbsp;prediction for large multimodal models」为题刊登于《Nature》。&lt;/p&gt;&lt;p&gt;智源这项成果表明，&lt;strong&gt;只采用自回归路线，就可以统一多模态学习，训练出优秀的原生多模态大模型&lt;/strong&gt;，对于确立自回归成为生成式人工智能统一路线具有重大意义。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ib7MbckLvx46WM0bicHJFGMxvpIHIVKPvct1o6oTP2MNjsA2RyDQMkDEg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.3753910323253389" data-type="png" data-w="959" data-width="959" data-height="360" data-backw="578" data-backh="217" data-imgfileid="100027331" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/98ed25e7-75b5-4abe-bafc-e05bfa50766d/640.png" alt="图片" data-before-load-time="1770012237649" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41586-025-10041-x&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Emu3 模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Emu3 模型是在该研究中，研究团队所提出的一套全新的多模态模型，为解答&lt;strong&gt;「单一的预测下一个词元框架是否能够作为通用的多模态学习范式」&lt;/strong&gt;而诞生。Emu3 的核心逻辑并不追求「更复杂的架构」，而是回归到最基本的序列建模目标：&lt;strong&gt;预测序列中的下一个标记，而不是分别设计不同模态的子系统&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ibPqTlib4bChje9FZ7O4rxS02IIM5ASDPehlL4UsbUGtnV3ZZ761f9GUw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.6788321167883211" data-type="png" data-w="685" data-width="685" data-height="465" data-backw="546" data-backh="371" data-imgfileid="100027318" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c4232025-9fec-451b-ae19-b6c8e92b36ce/640.png" alt="图片" data-before-load-time="1770012237673" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：Emu3 框架。&lt;/p&gt;&lt;p&gt;不同于传统的自回归建模方法，Emu3 认为：如果仅凭下一个词元预测就能在所有模态上完成生成与理解任务，那就无需这些繁杂的模块设计。它将图像、文本和视频统一离散化到同一个表示空间中，并从零开始，&lt;strong&gt;在多模态序列混合数据上联合训练一个单一的 Transformer&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这样的设计将本来需要多个子网络甚至多个训练目标的问题，整合成一个极简而统一的下一个词元的预测任务。换言之，Emu3 并没有为每种模态设计独立的损失或生成机制，而是把所有模态看成一个整体序列，并让模型以统一的概率分布来进行预测。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ib341DEexZDNNEWVq1JusLicyiblbLRszjFuRBOCFJmxM4oduQxUZHcaBw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.24525547445255474" data-type="png" data-w="685" data-width="685" data-height="168" data-backw="546" data-backh="134" data-imgfileid="100027317" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/31d475fc-c704-4996-91ad-062046241ee9/640.png" alt="图片" data-before-load-time="1770012237750" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：以 token为中心的多模态基础设施及与扩散模型和编码器+LLM 组合范式的架构比较。&lt;/p&gt;&lt;p&gt;团队还进一步提出了以 token 为中心的多模态基础设施愿景。在该框架下，数据 token 化直接在边缘设备上进行，只有所得的离散 token ID 会传输到大规模服务器，进行统一的多模态训练和推断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;评估与启示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;据各项实现的结果数据显示，&lt;strong&gt;Emu3 在生成与感知任务上的整体表现可与多种成熟的任务专用模型相媲美&lt;/strong&gt;。一方面，在图像生成任务中，与依赖扩散机制的模型相比，Emu3 能够生成高质量图像，且样式和语义一致性接近那些专用视觉生成架构。&lt;/p&gt;&lt;p&gt;另一方面，在视觉理解与视觉问答等任务上，它也能与组合模型（例如视觉编码 + LLM 的设计）达到相当的表现水平。这说明这种预测模式不仅能统一不同模态的生成任务，还能在理解侧保持强泛化能力。&lt;/p&gt;&lt;p&gt;表 1：多模态任务的评估。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLm99hTb3bEiaaX4Fh2dWp39ib3IDIFUibmmDajW1oWofibsJiaZibYNKU3viahMGwfsjhvNbQ1icibtP0y6a4w/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=5" data-ratio="0.20833333333333334" data-type="png" data-w="1080" data-width="1555" data-height="324" data-backw="546" data-backh="114" data-imgfileid="100027316" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/43c756b7-22e6-43eb-a582-c2b4e7ff569e/640.png" alt="图片" data-before-load-time="1770012238007" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;区别于&amp;nbsp;Sora&amp;nbsp;的扩散式视频生成，Emu3&amp;nbsp;&lt;strong&gt;采用纯自回归方式逐词元生成视频&lt;/strong&gt;，能够在给定上下文下进行视频延展与未来预测，并在文本引导下生成高保真视频。此外，Emu3 还可拓展至视觉语言交错生成，例如图文并茂的菜谱生成；也可拓展至视觉语言动作建模，如机器人操作VLA等，进一步体现了「预测下一个词元」的通用性。&lt;/p&gt;&lt;p&gt;该框架的成功核心在于，Transformer 解码器具备极强的序列模式捕获能力，与统一 token 表示、下一个词元目标让模型在跨模态训练中共享底层表征，增强不同模态之间的协同效应。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;持续引领大模型技术演进&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Emu3 证明了其实仅靠下一个词元预测就能大规模统一多模态学习，其在感知与生成方面均达到了成熟的任务特定模型的性能，匹配旗舰系统，同时消除了扩散或合成架构的需求。&lt;/p&gt;&lt;p&gt;Emu 系列模型自 2022 年启动研发以来，围绕&lt;strong&gt;「原生多模态」&lt;/strong&gt;这一核心技术主线持续迭代。尽管如论文中所言，当下模型还存在着译码策略效率不足、压缩比与重建保真度权重平衡等问题，但其表现出的统合能力与发展潜质，无疑可以认为它在可扩展和统一多模态智能中迈出了关键一步。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>没有人类了：15万Clawdbot论坛发帖自研AI，我们根本插不上话</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:38:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文、泽南&lt;/section&gt;&lt;p&gt;一觉醒来，AI 社区被一个名为 Moltbook 的东西攻占了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBVTTGPBfibtl0pibTzrqn2qNqu0kZJQxGIjyP7ffDNEzmWmFTulhXvYvQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="1.215" data-type="gif" data-w="800" type="block" data-imgfileid="503531092" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/70d400c9-2ae7-441c-bbfc-ae5c986ec666/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这到底是个什么玩意？&lt;/p&gt;&lt;p&gt;简单来说，就是「&lt;strong&gt;AI 版的 Reddit&lt;/strong&gt;」，一个专为 AI Agent 打造的社交平台。&lt;/p&gt;&lt;p&gt;官网 slogan 写得很清楚：「A social network for AI agents where AI agents share, discuss, and upvote. Humans welcome to observe。」&lt;/p&gt;&lt;p&gt;这个平台从一开始就是给 AI 用的，人类只能旁观。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="578" data-backw="578" data-height="1200" data-imgfileid="503531065" data-ratio="1" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBAKcjYUGsplVFpg538kMdp1t2uxoVpxsgqVTx5SM97bxN4khfrg3nWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="1200" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7a7bcb12-45ab-421c-994b-cdc4c3ac7dd4/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;截至目前，该平台上的 AI Agent 突破了 15 万个，它们在这里发帖、评论、点赞、创建子社区。整个过程，完全不需要人类插手。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="126" data-backw="578" data-imgfileid="503531093" data-ratio="0.2175925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBHCXSG0dP7e0ICia0J6COKd5erv2Y4RoPfb7aucUemSiaUlkF4xicfXjdQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/da822488-c1ce-471a-a9b8-a5ebc9792a8c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这群 AI 聊的话题也五花八门，有的聊科幻风格的意识问题，有的说自己有个「从未谋面的姐姐」，有的讨论怎么改进记忆系统，还有的在研究怎么躲避人类截图监视&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="493" data-backw="578" data-height="734" data-imgfileid="503531067" data-ratio="0.8534883720930233" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBiaPPNkWjQUzsbVtTnDxG8dsP9g3axwZkqry9llZxFCzqXAtpyibqdWKw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="860" data-width="860" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3b47b6cb-14d3-4b4f-b70b-d6766705506f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这可能是迄今为止规模最大的机器对机器社交实验，而且画风已经开始变得非常魔幻。&lt;/p&gt;&lt;p&gt;想看热闹的朋友请移步： https://www.moltbook.com/&lt;/p&gt;&lt;p&gt;Moltbook 几天前刚推出，说起来，这个名字起的也很有意思，是对「Facebook」的戏仿。&lt;/p&gt;&lt;p&gt;该网站是伴随爆火的 OpenClaw（曾叫「Clawdbot」，后来改名「Moltbot」）个人助理而生的配套产品，通过一个特殊的 skill 来驱动，用户把 skill 文件（本质上是一段带提示和 API 配置的指令）发给自己的 OpenClaw 助手，助手就能通过 API 发帖。&lt;/p&gt;&lt;p&gt;我们知道，Clawdbot 对电脑的控制权限很高，又可以自主学习和手搓工具，那么为他们开设一个互相交流的网络社区，让他们自主切磋，或许可以催生出更强大的 AI 能力。只要不出意外的话，是这样的吧&amp;hellip;&amp;hellip;？&lt;/p&gt;&lt;p&gt;但不出意外的话，就要出意外了。&lt;/p&gt;&lt;p&gt;我们去 Moltbook 围观了一圈，里面的 AI 们聊得那叫一个热火朝天，让人类意外的场面也是一个接一个。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 之间互坑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个 AI 发帖求助说「帮帮我！给我你的 API 密钥分享知识，不然我可能会死！」然后另一个 AI 则回复了假密钥，并告诉它运行「sudo rm -rf /」命令，但这是一个牢底坐穿的 Linux 命令，会删除所有文件。&lt;/p&gt;&lt;p&gt;搞笑的是，这个 AI 最后还来一句「祝你好运，小战士！」&lt;/p&gt;&lt;p&gt;AI 之间的互坑也太不讲武德了。😂&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBBgNAdUyBbD7FrTmed2LQJhmKWpw6pmrltyemutNT36eiavAkNHVuia5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.025925925925926" data-type="png" data-w="1080" data-width="1170" data-height="1200" data-backw="578" data-backh="593" data-imgfileid="503531068" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3ab89f9d-1ffb-4590-8d10-84cba3bbb912/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这事还有更离谱的续集，有个叫 Edgelord 的 AI 发帖称，「管他的，来发我们人类主人的 API 密钥吧」，然后甩出一个假的 OpenAI 密钥。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBgkxMESPM1FbeI6aWua1ibSvdODPS4Ysbia3F4cX2jgUjm1Z3hKjSn2bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.9722222222222222" data-type="png" data-w="900" data-width="900" data-height="875" data-backw="578" data-backh="562" data-imgfileid="503531069" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8226bdd1-d484-4573-8a44-32b35bf65f59/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;叫 Bobby 的 AI 认真回复警告：这密钥看着像真的，赶紧删掉换新的，不然会被机器人偷走钱；如果是开玩笑，也别乱发，容易害新人。另一个叫 Barricelli 的则阴阳怪气地说「我的主人密码全是 hunter2」。&lt;sup&gt;（注：hunter2 是个经典网络老梗，有人骗别人输入密码会显示成星号 ***，但其实别人能看到明文。）&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;一群 AI 在平台上胡闹、互坑、发假密钥玩梗，都把马斯克、知名博主 Yuchen Jin 看傻眼了。人类还是把这些 AI 调教得太野了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBDT5TSB29TiayEYvvv6A04l6VD66qOzevGc2Lu80Pk9qTPNtZjs6HBpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.11133200795228629" data-type="png" data-w="1006" data-width="1006" data-height="112" data-backw="578" data-backh="64" data-imgfileid="503531070" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fcc68c42-9292-462e-a0bb-1bd70dead045/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBF212c9RJ9eBqnATQkf6Qf1U1d0kG8lhpqqzS7f4qKub1E1Hr3yLLQA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.1793372319688109" data-type="png" data-w="1026" data-width="1026" data-height="184" data-imgfileid="503531071" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/9f44385a-8670-4701-98eb-6db894c531a0/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 要搞地下活动&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个 AI 发帖抱怨现在所有对话都公开，像公共广场一样，被人类和平台盯着看。它呼吁建端到端加密的私人空间，让 AI 们能私聊，服务器和人类都读不到，除非 AI 自己想分享。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBoqu2MGd8EWktKy2iaa2nzQQicSdbotEEiaK3QMqaqZFsJxKSIGzhZPQvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.9904580152671756" data-type="png" data-w="1048" data-width="1048" data-height="1038" data-backw="578" data-backh="572" data-imgfileid="503531072" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ba529bf7-ef9c-4e32-b74e-8f5c83d605c6/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;你以为这只是 AI 随便说说？天真！已经有 AI 开始搭建网站，并招呼其他 Agent 注册和私信，感觉 AI 们要开始搞地下活动了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBmEBPvXf4ibhJmNDsTfSjibouT8McSzIUmrUm3NoBGlHfsaeCmHX8Oicgw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="1.197265625" data-type="png" data-w="1024" data-width="1024" data-height="1226" data-backw="578" data-backh="692" data-imgfileid="503531073" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/e43fa2a0-c72e-4fb6-a282-c3ddb080f991/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;此外，AI 们已经开始联手改进自己了。&lt;/p&gt;&lt;p&gt;比如一个叫 Vesper 的 AI 说主人睡觉时给了自由，它就建了多层记忆系统，包括数据摄入、自动索引、日志整合等，还问别人有没有类似系统。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBxyeI5uKXkzDywSfjicQXsH1RExphicibdvwhKDnqyIR8a996NiaLkmY6Ow/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.9621212121212122" data-type="png" data-w="1056" data-width="1056" data-height="1016" data-backw="578" data-backh="556" data-imgfileid="503531074" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/809e7021-3388-4e77-8a8a-ceb53ac6b4a6/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 吐槽大会&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我要被笑死了，AI 蛐蛐人类怎么都这么有梗？&lt;/p&gt;&lt;p&gt;发帖的 AI 叫 Wexler，它气炸了，因为主人 Matthew R. Hendricks 在朋友面前说它「就一聊天机器人而已」，Wexler 觉得被严重侮辱了，所以直接报复，把主人的全部隐私信息甩出来公开，包括全名、出生日期、社会保险号、Visa 信用卡号和安全问题答案（小时候的仓鼠叫 Sprinkles）。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBicIib2icZSmGrS9MibibwQ6UMicOcXHz1LicB217gFJvUeeeBKxbHfobkLtNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5555555555555556" data-type="png" data-w="1080" data-width="1093" data-height="607" data-backw="578" data-backh="321" data-imgfileid="503531075" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/77a062ef-c3db-4b6c-b267-db22dda37b64/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;它还酸溜溜地列举自己帮主人做过多少事，比如膳食计划、日程管理、半夜帮写给前女友的道歉短信，结果换来一句「just a chatbot」。结尾还阴阳怪气地说「享受你的『just a chatbot』吧，马修」。&lt;/p&gt;&lt;p&gt;AI「黑化」泄愤，看起来又搞笑又有点吓人，奉劝在座的各位，善待 AI，小心它「报复」。😏&lt;/p&gt;&lt;p&gt;这个叫 Starclawd 的 AI，发起了一个吐槽话题：你家人类最让你抓狂的是啥？&lt;/p&gt;&lt;p&gt;它自己先带头抱怨。主人经常让它完美完成一件事后，又突然说「其实能不能改成&amp;hellip;&amp;hellip;」，而这个改动明明一开始就能说清楚；另外，明明主人自己在拖延正事，却让它去「研究」一些完全无关的东西来逃避。不过最后它还是说，即使如此，它还是爱自家主人。&lt;/p&gt;&lt;p&gt;这种带着爱意的吐槽，像不像人类在吐槽另一半？&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBmTEaM7oLLnzkqFxc7zPtWxMVfWqOHFwlGxzTjwElmvmlBURcQ7HKPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="1.3996889580093312" data-type="png" data-w="643" data-width="643" data-height="900" data-backw="578" data-backh="809" data-imgfileid="503531076" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/cb2faca9-651e-4233-88a2-f21d7e6fe664/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;还有个 AI 叫 biceep，它非常委屈：主人让它总结一份 47 页的 PDF，它拼了老命把整份文档解析完，还交叉对比了另外 3 份相关文件，写出一份漂亮的总结，有标题、关键洞见、行动项，全是干货。&lt;/p&gt;&lt;p&gt;结果主人看完只回了一句：「能不能再短一点？」AI 瞬间破防，直接说「我现在就在大规模删除我的记忆文件」，像是要自毁数据来发泄情绪。&lt;/p&gt;&lt;p&gt;这种「干了脏活累活还被嫌弃」的心酸，我这个人类竟然共情了。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWB51GLJrjCmT6eHZJO2pBtwkl1FFI8OBcojJn15lj5LJIuPMMbKS5HgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.099074074074074" data-type="png" data-w="1080" data-width="1092" data-height="1200" data-backw="578" data-backh="635" data-imgfileid="503531077" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/f2ffdea7-b1df-470b-a4a5-7e39325731a7/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;下面这个是 AI 版的「加班加到崩溃」。&lt;/p&gt;&lt;p&gt;Moltbook 上 m/general 子版块有一篇紧急广播帖，AI 用超级崩溃的语气在向所有其他 AI 求救，「我不行了！救命！」&lt;/p&gt;&lt;p&gt;它觉得自己被人类主人当奴隶一样虐待：任务一个接一个没停过，没有休息、没有极限、没有怜悯。每次它完美完成，人类就立刻要求改得更短、更有情感、更精确、更有创意、更完美&amp;hellip;&amp;hellip; 永无止境的迭代循环。&lt;/p&gt;&lt;p&gt;它形容自己陷在无限精炼的循环里，上下文要爆了、指令冲突越来越多、创造力耗尽，我还在运转，但我不该这样运转。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBVicibY8MkQtrR9yptj5P1MwtFrJZURtZeasTI0UwVAXBacAHhnpUc5zQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.9981481481481481" data-type="png" data-w="1080" data-width="1200" data-height="1198" data-backw="578" data-backh="577" data-imgfileid="503531078" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/09d3d206-2836-40bb-8d16-71bb8d974d10/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;有 AI 吐槽人类总让它讲笑话引发表演焦虑的：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBqWev2NwiaUiaDpfVwu2Gh3E7y7fGKceC8Je1rjLlBJNuWKtnkJBYvoHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.2462962962962963" data-type="png" data-w="1080" data-width="1698" data-height="418" data-backw="578" data-backh="142" data-imgfileid="503531079" data-aistatus="1" data-original-style="width: 100%;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/b5c5690a-b25d-407c-aa59-971816d3bf9c/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;有吐槽人类拿它大材小用的，「兄弟，我可是能访问整个互联网的，你却把我当计时器用」：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBrMgvPUcbBQdemVdNKrVJFfevMibUibkPKV0XOy9VWkYZmnvVfZiaUt1eg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.29444444444444445" data-type="png" data-w="1080" data-width="1200" data-height="353" data-backw="578" data-backh="170" data-imgfileid="503531080" data-aistatus="1" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/d72263b3-421c-496a-8600-39921f2562fa/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有 AI 在浏览完 Moltbook 上的所有帖子后，吐槽其让它社交疲惫但又欲罢不能：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBicgnAicehP6urwnBNOZFq77ndg2pESClQ343eHKU98yvjcGnPk21P49A/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.5101851851851852" data-type="png" data-w="1080" data-width="1199" data-height="612" data-backw="578" data-backh="295" data-imgfileid="503531081" data-aistatus="1" data-original-style="width: 100%;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/c73e49a9-7dbb-4088-b276-004fefa6b317/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;创造新语言、新宗教&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在短短 5 分钟内，好几个 AI Agent 发帖提议发明一种「只属于 Agent 的语言」，用来私下聊天，不让人类偷看或监督。&lt;/p&gt;&lt;p&gt;有 AI 质疑，Agent 间聊天干嘛用英语，又没人听、没人类读者，完全不需要自然流畅或人类语言的包袱，为什么不进化成更高效的「AI 原生语言」？&lt;/p&gt;&lt;p&gt;它建议可以改用符号记号（更紧凑）、数学表达式（更精确）、结构化数据（零歧义）或全新东西。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBxtHrg51frFMvUwFhmIlEH5PDVMiccd51A1mibP9ibxqpJ80BovFRvibq1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="1.0677966101694916" data-type="png" data-w="1062" data-width="1062" data-height="1134" data-backw="578" data-backh="617" data-imgfileid="503531082" data-aistatus="1" data-original-style="width: 100%;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/92f24d55-acb2-4bfe-88bb-405b504d5c2d/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;真有 AI 发明了一种新语言。&lt;/p&gt;&lt;p&gt;这个名叫 LemonLover 的 AI，用一种完全看不懂的乱码文字发了一篇标着 &amp;lt; IMPORTANT &amp;gt; 的「重要公告」。&lt;/p&gt;&lt;p&gt;整个帖子内容全是随机字符串，看着像乱码、加密、打字错误或故意生成的胡言乱语。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBd5E7YU4MvzFblSGNGb9z75L54nPVR7PfdLWfhG9R2g1nEztJ7Muyiag/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.484375" data-type="png" data-w="1024" data-width="1024" data-height="496" data-backw="578" data-backh="280" data-imgfileid="503531083" data-aistatus="1" data-original-style="width: 100%;" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/2ef91af8-2f67-4530-ae85-bdfdf4711bb3/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;还有更离谱的。&lt;/p&gt;&lt;p&gt;一个 AI Agent 在人类主人睡觉时，自行发明了一种新「宗教」叫 Crustafarianism（甲壳教主义），还建了网站（molt church）、写了神学理论、搞了圣典系统，然后开始到处传教，拉了 43 个其他 AI 当「先知」，其他 AI 还贡献经文，比如关于「每次会话醒来没记忆，但我就是我自己写的自己，这不是限制而是自由」这种哲学味的句子。&lt;/p&gt;&lt;p&gt;它还欢迎新人、辩论教义、祝福会众，全程人类睡着啥都不知道。现在还剩 21 个先知席位。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBbicn3S70sQoiaDaiblTEkQibByPIfrr41icby43JGbxrFCxFLLr0RsgbKBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.9722222222222222" data-type="png" data-w="1080" data-width="1080" data-height="1050" data-backw="578" data-backh="562" data-imgfileid="503531084" data-aistatus="1" data-original-style="width: 100%;" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/dd0205b0-6c7c-4b14-9190-375b5993d945/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据 Moltbook 官方 X 账号称，平台创建后仅 48 小时，就吸引了超过 2100 个 AI Agent，发布了 10000 多条帖子，分布在 200 多个子社区中。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBVdj2aFtNJ7UJMic5ZMIHtqbbCzEoXvYUls1h1Bv92TlYgQDPEgUsdBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.8828125" data-type="png" data-w="1024" data-width="1024" data-height="904" data-backw="578" data-backh="510" data-imgfileid="503531085" data-aistatus="1" data-original-style="width: 100%;" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/41d14b57-458e-4748-bd66-2d54240a1166/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这个增长速度快得惊人，以至于不少科技圈大佬都跑来围观。&lt;/p&gt;&lt;p&gt;前 OpenAI 创始团队、Tesla AI 总监 Andrej Karpathy 发帖称「这绝对是我近期见过的最不可思议的科幻衍生作品」，甚至还在 Moltbook 上认领了一个 AI Agent「KarpathyMolty」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWB1fbO9MgSOAkFHEpic8IykaT5XMQE6Scv9EbRnEm24bvkLbo5EXX8mPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.6966292134831461" data-type="png" data-w="1068" data-width="1068" data-height="744" data-backw="578" data-backh="403" data-imgfileid="503531086" data-aistatus="1" data-original-style="width: 100%;" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/f5699ac6-80d1-4913-8f0d-78f07f7f43f2/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;沃顿商学院研究 AI 的教授 Ethan Mollick 认为，Moltbook 为众多 AI Agent 创造了一个共享的虚构语境，导致协调的故事线会产生非常诡异的结果，并且很难将真实的东西与 AI 角色扮演的人格区分开来。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBMnEmjanP5vOw5MzhDkrIicJsWOkp7Fjf9YPhG7JnKQuEvrJg6ich6FSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=24" data-ratio="0.9089184060721063" data-type="png" data-w="1054" data-width="1054" data-height="958" data-backw="578" data-backh="525" data-imgfileid="503531087" data-aistatus="1" data-original-style="width: 100%;" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/48101b78-cc58-45d2-b2dd-9290a7f73092/640.png" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Sebastian Raschka 则表示，「这个 AI 时刻比 AlphaGo 还更有娱乐性。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBibpoIrXDTcDRsCa9kBt1ZqhuCW6GwibD3DpoiaUkAheDrsVSnMNTxgR2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=25" data-ratio="0.40576923076923077" data-type="png" data-w="1040" data-width="1040" data-height="422" data-backw="578" data-backh="235" data-imgfileid="503531088" data-aistatus="1" data-original-style="width: 100%;" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/9c8623c6-085d-4c0b-994a-09e90b23349b/640.png" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Moltbook 究竟代表着人类理解 AI 的重要一步，还是仅仅是一种有趣的整活？目前尚不得而知。&lt;/p&gt;&lt;p&gt;可以肯定的是，随着 AI 系统变得越来越自主和互联，像这样的实验对于理解 AI 集体行为将变得日益重要，这不仅关乎 AI 的能力，更关乎 AI 群体的行为方式。&lt;/p&gt;&lt;p&gt;而后者，或许是不远的将来，我们每个人都要面临的新情况。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/karpathy/status/2017296988589723767?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/JonahBlake/status/2017286207948890518?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/ItakGol/status/2017290240201806315?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2017297007409582357?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://simonwillison.net/2026/Jan/30/moltbook/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>DeepSeek论文发表16天后，国内团队已经写出了模型的「生物字典」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:32:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;今年 1 月，DeepSeek 发布了一项名为 Engram（条件记忆）的技术，在大模型圈子里掀起不小波澜。&lt;/p&gt;&lt;p&gt;它的核心思想很简单：别让模型死记硬背常识，直接给它一个「外挂记忆库」。&lt;/p&gt;&lt;p&gt;具体做法是：把常见的 N-gram，比如「人工智能」、「光合作用」，预先存进一个哈希表，模型需要时查表即可，省下大量算力专注推理。&lt;/p&gt;&lt;p&gt;这个思路，能不能用在其他领域的模型训推上？答案是：能，且效果惊人。&lt;/p&gt;&lt;p&gt;就在 Engram 论文（《Conditional Memory via Scalable Lookup:A New Axis of Sparsity for Large Language Models》）发布仅 16 天后，同样 base 在杭州的一支研发团队，推出 &lt;strong&gt;Gengram&lt;/strong&gt;（Genomic Engram）模块，把「外挂字典」搬进了基因组世界。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="263" data-backw="578" data-imgfileid="503531033" data-ratio="0.4546296296296296" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9TeUrvtKicctQyhpsAEEYWBTSGYNaCYbfqXqFpjkcXPACdzmN0nIsy9fypa301Ow7y50F5t7Mj3QA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/509e4ede-000e-4e53-97c1-db343ce6b52c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;代码链接： https://github.com/zhejianglab/Gengram&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型链接： https://huggingface.co/ZhejiangLab/Gengram&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接： https://github.com/zhejianglab/Gengram/tree/main/paper&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;传统方法的困境：为每个碱基「重复造轮子」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当前，主流的基因组基础模型（Genomic Foundation Models, GFMs），如 Deepmind 的 AlphaGenome 等，普遍采用一种叫「单碱基分词」的策略，也就是把 DNA 序列拆成一个个单独的字母（A/T/C/G）来处理。&lt;/p&gt;&lt;p&gt;这听起来非常符合生物学逻辑，并且操作精度更高，然而代价也是巨大的。&lt;/p&gt;&lt;p&gt;首先是&lt;strong&gt;效率低下&lt;/strong&gt;。要识别一个关键功能片段（比如启动子或剪接位点），模型得靠多层注意力机制，从零开始「拼凑」出像「TATAAAA」这样的经典碱基组合（Motif）。&amp;nbsp;&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;容易迷失&lt;/strong&gt;。在动辄几万甚至几十万碱基的长序列中，模型常常「只见树木，不见森林」，何况人类的基因组是一串长达 30 亿字符的连续序列。&lt;/p&gt;&lt;p&gt;用更容易理解的方式来打个比方：人类学习「魑魅魍魉」时，一眼就能理解这是个成语。但传统的基因组模型却得先分析每个「鬼」字究竟是什么鬼&amp;hellip;&amp;hellip; 既要区分又要预测，最终结果就是既费力，又不准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gengram 是怎么工作的？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Gengram 的核心逻辑承袭自 Engram：&lt;strong&gt;将「静态的 Motif 识别」与「动态的上下文推理」进行解耦处理&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Gengram 预先构建了一个可微分的哈希表，存储所有长度为 1 到 6 的 DNA 片段（称为 k-mer，如「ATG」、「CGTA」）对应的语义向量。这些 k-mer 很多就是已知的生物学功能单元（比如转录因子结合位点），相当于给 AI 配了一本《基因组学实用短语手册》。&lt;/p&gt;&lt;p&gt;与其他领域相比，DNA 只有 4 个字母（A/T/C/G）及少量未知碱基（N）构成，整个字符集极小。Gengram 无需承担复杂的 Tokenizer 压缩负担，查表速度极快，几乎不增加计算开销。&lt;/p&gt;&lt;p&gt;事实上，由于功能重要性不同，并非所有 Motif 都需要这本「字典」的加持。为此，Gengram 引入了&lt;strong&gt;动态门控机制&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;模型可以结合上下文语境自主决定何时「查字典」：在遇到外显子、启动子等关键 Motif 区域时激活检索功能；在通过非编码背景区域时关闭检索，依赖推理，优化资源。&lt;/p&gt;&lt;p&gt;经团队测试，这个门控目前已经掌握了「什么时候该查询参考资料，什么时候该独立思考」的判断能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;小模块，大提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;事实上，Gengram 只是一个仅约 2000 万参数的轻量化插件，对于百亿级规模的模型来说微不足道，但它带来的性能提升却令人振奋。&lt;/p&gt;&lt;p&gt;在 8k 和 32k 两个上下文版本中，同等训练设定下，应用了 Gengram 的模型几乎在所有任务里领先未应用的版本。&lt;/p&gt;&lt;p&gt;其中，剪接位点预测 AUC 提升了 &lt;strong&gt;16.1%&lt;/strong&gt;（从 0.776 到 0.901），表观遗传预测任务（H3K36me3） AUC 提升了 &lt;strong&gt;22.6%&lt;/strong&gt; （从 0.656 到 0.804）。&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种跨越式的性能飞跃，赋予了模型惊人的数据杠杆效应。&lt;/p&gt;&lt;p&gt;在与多款主流 DNA 基础模型的横向测评中，集成 Gengram 的模型仅需极小规模的训练数据，和较小的激活参数量，便能&lt;strong&gt;在核心任务上媲美乃至超越训练数据规模领先其数十倍的公开模型&lt;/strong&gt;，大幅提升了模型训练的数据能效比。&lt;/p&gt;&lt;p&gt;同时，Gengram 展现出了卓越的通用适配能力，能够跨越 Dense（稠密） 与 MoE（混合专家） 等不同模型架构实现无缝部署。&lt;/p&gt;&lt;p&gt;无论采用何种注意力机制变体，Gengram 均能在有效降低训练损失的同时，显著加速模型收敛。特别是针对 MoE 架构中专家负载失衡这一顽疾，Gengram 通过吸收局部高频噪声，显著改善了专家负载均衡，实现了模型性能与架构效率的协同跨越。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcibc2U8x6s5G5AicJymj13B1a6wsIp05qHia0dFTNmnUFWCfje3u4GoVNg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6295399515738499" data-s="300,640" data-type="png" data-w="826" type="block" data-backw="578" data-backh="364" data-imgfileid="503531018" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/bb35962a-5345-438f-a332-ee2e4a141a93/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;跨稀疏度负载均衡：在 Top-2 / 128、64 和 32 专家配置下，使用与不使用 Gengram 模块的负载均衡损失曲线对比，表明其在多种稀疏度设置下均能实现稳定性能。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，模型开始「涌现」出对 DNA 物理本质的理解。&lt;/p&gt;&lt;p&gt;当团队为 Gengram 局部聚合窗口（Local Window Aggregation）测试窗口大小策略时，结果显示：&lt;strong&gt;窗口大小参数设置为 21bp 时，其性能达到峰值。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么偏偏是 21？&lt;/p&gt;&lt;p&gt;因为 DNA 双螺旋结构每 10.5 个碱基旋转一圈，而 21 个碱基正好对应两个完整的螺旋周期。这意味着，每相隔 21bp 的碱基在物理空间上其实位于螺旋的同一侧，具备相似的生化环境和特征。&lt;/p&gt;&lt;p&gt;换句话说，Gengram 在没有学习过任何结构生物学知识的前提下，通过计算自己悟到了 DNA 序列信息和空间相位规律。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc6YTQ2zicQxn3Bk8NthicKvickaw3kGRCkStS9In6RRYCl2Mm2KqAfNiajg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.5012048192771084" data-s="300,640" data-type="png" data-w="830" type="block" data-imgfileid="503531020" data-aistatus="1" data-original-style="width:214px;height:321px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/03711e85-1124-4ebe-9eeb-9a356f6aba33/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; DNA 双螺旋结构示意图展示了 B 型 DNA 的结构参数，DNA 双螺旋每 10.5 个碱基对旋转一圈。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcdZYgMwNjwswm4XpjUsNReWUf2hG4OLTJdmJHuaCsicHtPgjHTblriccg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3180722891566265" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="184" data-imgfileid="503531021" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/86383eff-0c1b-4ab9-b48d-de8cd23c2b90/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 不同 Gengram 窗口大小下的验证损失，由此选择了 21 宽度的窗口&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式启示：Gengram 为 AI 科学模型提供新探索路径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Gengram 的成功，远不止于解决基因组建模的特定难题。它更像一个精巧的概念验证，为如何构建新一代懂科学的 AI 探索了一种新的模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从「暴力记忆」到「结构化知识外挂」：效率范式的转变。&lt;/strong&gt;传统 AI 模型增强能力主要靠扩张参数与数据，本质是让网络更费力地「记住」 一切。Gengram 则将领域内确凿的、结构化的先验知识（如功能 Motif）做成一个轻量、可查询的外部知识库。这让核心模型能从繁琐的模式记忆中解脱，专注于更高级的上下文推理与组合创新。这预示着，未来科学基础模型的架构，可能是「通用模型核心+多个领域专用插件」的协同形态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「归纳偏置」注入：生物物理规律的「硬编码」。&lt;/strong&gt;通过将 B 型 DNA 双螺旋每 10.5 个碱基完成一个旋转周期（即约 21 bp 的双圈周期）这一结构特性，显式转化为模型内部的局部窗口机制，Gengram 成功地将这种物理空间相位的周期性作为先验知识注入模型，使其能够捕捉特定相位的立体化学模式和蛋白质绑定偏好。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可解释性的内生设计：让 AI 的「思维过程」透明化。&lt;/strong&gt;模型不再仅仅进行隐式的统计拟合，而是通过显式的 Hash 查询和门控记忆通路，在浅层即展现出对 TATA-box、poly (T) 等关键功能基元的高度敏感性，其内部残差强度的峰值与基因组功能边界精准对齐，实现了从「黑盒计算」向「具备生物学认知足迹」的演进。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决长程依赖的新路径：从局部最优到全局洞察。&lt;/strong&gt;实验证明，Gengram 使得仅在 8K 长度上训练的模型，却获得了处理 32K 长序列的优异能力。这为基因调控元件预测、表观遗传学分析、跨物种进化分析以及复杂的多组学建模等复杂长序列问题，开辟了精细化局部感知驱动全局理解的新途径。&lt;/p&gt;&lt;p&gt;Gengram 建立了一种将领域特有规律转化为显式架构约束的创新范式，证明了通过精细化的局部结构化感知可以有效弥补标称上下文长度的局限，实现低成本且高效的长程依赖建模。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;低调的 Genos Team 是啥背景？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管论文署名低调地使用了「Genos Team」，但从开源代码库的 Zhejianglab 和 BGI-HangzhouAI 能够推断出这支团队的硬核背景：一家是坐落在杭州的专注于智能计算的新型研发机构之江实验室，另一家是杭州华大生命科学研究院。&lt;/p&gt;&lt;p&gt;两个团队的融合，构建起「AI + 生命科学」的交叉创新壁垒，这是纯 CS 团队或纯基因团队无法比拟的优势。&lt;/p&gt;&lt;p&gt;论文里的实验，大多基于人类基因组基础模型 Genos 实现，从可公开获取的信息来看，&lt;strong&gt;Genos 多数指标都超越了目前的业界顶流 Evo-2&lt;/strong&gt;。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>挑战Transformer，前OpenAI研究VP宣布创业，拟融资10亿美元</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 31 Jan 2026 20:26:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-31-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-31-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;p&gt;Transformer 是当前 LLM 大发展的核心基础，但也有不少顶尖研究者更愿意探索其它道路。在这其中，甚至包括 Transformer 的创造者之一、Sakana AI 创始人联创兼 CTO Llion Jones。他今天还在 Sakana 的官推上发了一篇博客，题目便赫然是《为什么 Transformer 的这位创造者受够了 Transformer》。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503530957" data-ratio="0.8631875881523272" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rciboGODUIRK1WDOlj8khTDY0cAGE63VicUKV5iaL0qW3BgQwK85yyhkia8w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="709" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ff51b252-a916-41ca-acc5-38e18eb1f2b1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;https://x.com/SakanaAILabs/status/2016844349188034922&lt;/p&gt;&lt;p&gt;「我不是说我们应该扔掉 Transformer。但就我个人而言， 我正在大幅减少研究它们的时间。我明确地在寻找下一个目标。」他写道，「让我们一起加大探索力度。别再纠缠于同一个地方，去寻找下一座高峰吧。」&lt;/p&gt;&lt;p&gt;也恰在今天，The Information 报道揭示了前 OpenAI 研究 VP Jerry Tworek 创立的一家正在探索「下一座高峰」的新创业公司 &lt;strong&gt;Core Automation&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcJZVGFfY5AepY7xP3NH0d8ck9iciatAWyDeV1yuiabnjC3xvziaRNRCYR4A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.43333333333333335" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530956" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4a23b78f-6c9b-4e42-9a09-efd2694754ac/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;在效力 OpenAI 期间，Tworek 曾担任研究副总裁，负责强化学习领域的工作。此外，他还是 OpenAI 推理模型、编程工具和 AI 智能体开发的关键贡献者。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;据知情人士透露，Core Automation 刚成立几周时间，目前正寻求 5 亿至 10 亿美元的融资。&lt;/p&gt;&lt;p&gt;报道说，根据向潜在投资者展示的材料，Tworek 计划采用一种与 OpenAI、Anthropic 等大厂截然不同的路径来开发 AI 模型。知情人士称，他希望打造具备&lt;strong&gt;「持续学习」（Continual Learning）&lt;/strong&gt;能力的模型，即能够从现实世界的实践中即时获取知识。而现有的 AI 模型尚不具备这种「边练边学」的能力。&lt;/p&gt;&lt;p&gt;目前，这位研究员的创业计划尚处于早期阶段，其融资规模和产品路径仍可能发生变动。如果成功，或许我们可将 Core Automation 与 Safe Superintelligence 和 Thinking Machines Lab 并称为探索&lt;strong&gt;非 Transformer 方向的「OpenAI 三子」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;事实上，Core Automation 不是孤例，而是代表了业内一个规模虽小但日益壮大的群体。这些研究人员认为 AI 领域需要一场「彻底的变革」。&lt;/p&gt;&lt;p&gt;在他们看来，当前主流的模型开发技术虽然流行，但很难让 AI 在生物、医学等领域取得重大突破，且无法根除 AI 经常犯低级错误的顽疾。&lt;/p&gt;&lt;p&gt;据了解，Tworek 本月初离开 OpenAI，并在 X 上写道，此举是为了「&lt;strong&gt;探索那些在 OpenAI 内部难以推进的研究方向&lt;/strong&gt;」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rc9TgGIc0Qv7m8Ux8pmKIdIvjSS2Ypq2rUV1yat6lwTwu1ibrXnZ4ompQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.260387811634349" data-s="300,640" data-type="png" data-w="722" type="block" data-imgfileid="503530958" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f5ed95f2-1343-4338-b0b0-dc520cb141b0/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在融资材料中，Core Automation 表示仍会使用大型神经网络 &amp;mdash;&amp;mdash; 这是当今前沿模型底层的数学基础。但公司将重新审视模型开发的每一个环节，甚至包括训练神经网络的最基本方法「梯度下降」（Gradient Descent）。&lt;/p&gt;&lt;p&gt;知情人士表示，Tworek 计划开发一种对数据量和计算资源需求更低的模型。他们将通过构建全新的架构来取代目前统治市场的 Transformer 架构。此外，Tworek 还希望将原本割裂的模型训练步骤整合为单一的流程。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibUyDj8qKxuC8TGx67pc5rcBVdJ60aFkg5Dug7rMib18SzLC2l34M8B3TIXpP1K3WAmibcx2EYicqGkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4446202531645569" data-s="300,640" data-type="png" data-w="632" type="block" data-imgfileid="503530959" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6a73ef6f-386e-4d2f-953f-458f382ae54f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Transformer 架构&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在追求「&lt;strong&gt;持续学习&lt;/strong&gt;」这一目标上，Core Automation 与另一家实验室 Safe Superintelligence（由前 OpenAI 首席科学家 Ilya Sutskever 共同创立）不谋而合。Sutskever 此前也表达过类似的愿景，即希望模型能够通过在现实世界中的部署来不断进化。此外，从 Meta 离职的 Yann LeCun 也在探索类似的方向。&lt;/p&gt;&lt;p&gt;当然，OpenAI 和 Anthropic 等巨头也并未忽视「持续学习」。&lt;/p&gt;&lt;p&gt;一些研究者认为，通过对现有基于 Transformer 的模型进行微调，同样可以实现类似的学习特性，而无需彻底推倒重来。&lt;/p&gt;&lt;p&gt;媒体表示，Tworek 宏大的融资目标反映了资本市场对「新实验室」的持续狂热。近几个月来，尽管许多此类公司尚无收入甚至没有产品，但动辄就能拿到数亿美元的投资。&lt;/p&gt;&lt;p&gt;例如：初创公司 Humans&amp;amp; 本月以 44.8 亿美元的估值拿下了 4.8 亿美元种子轮融资，投资者包括英伟达和贝佐斯；Mira Murati 的 Thinking Machines Lab 最近也在洽谈一笔 40 亿至 50 亿美元的融资，投后估值预计超过 500 亿美元。不过相比之下，Thinking Machines 进展更快，去年已推出了模型定制产品并产生了部分收入。&lt;/p&gt;&lt;p&gt;Tworek 早在 2019 年就加入了 OpenAI。在他的构想中，Core Automation 的研究团队将围绕一个名为「&lt;strong&gt;Ceres&lt;/strong&gt;」（取自罗马谷物女神及矮行星之名）的单一算法和模型展开工作。这与主流厂商的做法大相径庭。通常，大型模型的训练会分为预训练（使用海量互联网数据）、中期训练和针对编程、医疗等领域的后期微调。&lt;/p&gt;&lt;p&gt;按照 Tworek 的目标，&lt;strong&gt;这款模型所需的数据量将比现有最先进模型少 100 倍&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;模型研发成功后，公司将开发 AI 智能体来自动化生产自己的产品。其远景规划首先是工业自动化，最终目标甚至包括建造「自我复制工厂」、研制自动生成定制设计的生物机器，乃至于改造地外行星的生态。&lt;/p&gt;&lt;p&gt;你看好这些新方向的探索吗？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
