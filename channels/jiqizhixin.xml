<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>幻觉率不到3%，王小川把医生版的DeepSeek免费了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 19:17:35 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-14</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-14</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜泽南&lt;/section&gt;&lt;p&gt;在医疗健康这一容错率极低的领域，大模型不再凭空「想象」，而是已变得严谨可靠、能引会搜：百川刚刚推出的新模型，实现了一个里程碑式的突破。&lt;/p&gt;&lt;p&gt;本周四，百川智能正式发布新一代大模型 Baichuan-M3 Plus，其面向医疗应用开发者，在真实场景下将医学问题推理能力推向了全新高度。新模型发布的同时，接入 M3 Plus 的百小应 App 与网页版也已同步上线。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529752" data-ratio="0.425" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadMF8YFj711oEA8cUbvbmXjj7bRyRPF4JvNzNhlkCzRa7FLibDzbDBdKA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e4692011-cd64-41f2-ac5f-9cb2b65ff5b6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 AI 领域，从来没有一款大模型可以做到 M3 Plus 这么高的医学场景准确率，百川还大幅提升了模型的推理效率，M3 Plus 的发布，标志着 AI 在医疗领域的应用跨过了「敢用、好用、用得起」的关键门槛。&lt;/p&gt;&lt;p&gt;百川智能创始人、CEO 王小川表示，在垂直领域，M3 Plus 已经可以认为是医生版的 ChatGPT 或 DeepSeek，作为性能最强、推理效率最高的模型，可大规模用于 AI 辅助医疗落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全球最低幻觉率 &amp;nbsp;从看着像，到真的准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;长期以来，医生与患者对 AI 的态度一直存在矛盾：人们既期待 AI 能分担繁重的工作，又恐惧它们「一本正经地胡说八道」。信任，是 AI 进入医疗领域的最后一道墙。&lt;/p&gt;&lt;p&gt;在发布活动中，百川智能模型技术负责人鞠强现场演示了一个案例：一位医生曾尝试用 AI 检查一个肿瘤药物的不良反应，结果发现市面上的 AI 生成的内容虽然「画风」专业，引用文献看起来也很权威，但「按照生成内容的面积计算，90% 的信息都是完全错误的」。&lt;/p&gt;&lt;p&gt;这种「貌似专业」带来的风险比直接答错更大，且极具迷惑性 。&lt;/p&gt;&lt;p&gt;针对这一核心痛点，M3 Plus 延续了 M3 基座模型的内生逻辑机制，通过引入 Fact-Aware RL（事实感知强化学习）等新技术，将幻觉控制推向了新高度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上周发布的百川新一代基座模型 Baichuan-M3，开拓了幻觉降低的技术路线，探索模型基座的幻觉降低范式，成功首创了 Fact-Aware RL 的强化学习范式，让模型在无工具、无检索增强的情况下大幅降低了幻觉，实现了 SOTA 水平，M3 Plus 延续了这样的能力。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadiaKiaQqEP0KWhtETHbFHsdA9Ov8NJoj2HzTnURTZMibwCvae3xHF7Zsng/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3675925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529764" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/212f33df-6395-4fba-9b22-77fd19bc694b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Baichuan-M3 首创的 Fact-Aware RL。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Fact-Aware RL 范式下，模型生成的文本会被拆解成一条条可被核查的医学判断，再逐条和权威医学来源进行比对，进而量化 AI 生成内容的事实准确性。&lt;/p&gt;&lt;p&gt;这种设计赋予了 AI 模型与真实临床工作流程相契合的内在医学增强能力。据测试，Baichuan-M3 不仅在医疗沟通和推理能力上全面领先 GPT-5.2，在医疗幻觉率上也实现了超越，达到全球最低水平。&lt;/p&gt;&lt;p&gt;在 M3 Plus 上，AI 的推理还得到了「六源循证」方法（EAR）的加持。&lt;/p&gt;&lt;p&gt;在去年 10 月发布的 Baichuan-M2 Plus 模型上，百川首次应用了「六源循证」方法（EAR），将循证医学的范式引入大模型的训练和推理过程，使模型的每条建议都有专业医学证据支持。在其 RAG 检索的过程中，查询会被转化为结构化医学问题，并在六源数据库中进行分层匹配。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadg1GAbhe5padLZujhxeb4u1ibKzHuN9l6vPpchbxe0KlHYB0K6NT34Tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529756" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/512212df-9065-48f1-bc3d-fab6b1d0fbea/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Baichuan-M2-Plus 提出的六源循证体系。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;据介绍，这种方法克服了通用 RAG 的两大缺陷：对医学语义理解的缺乏，以及引用文献可靠性的不足。六源循证不仅使 AI 模型的医学知识储备和医学知识利用能力大幅提升，更直接将幻觉降低到 DeepSeek-R1 模型的 1/3，使模型的可信度达到比肩资深临床专家的水平。&lt;/p&gt;&lt;p&gt;M3 Plus 模型在 Halluciation Rate 评测中的幻觉率只有 2.6，比 GPT-5.2 低超过 30%，也低于目前行业的标杆 Open Evidence，刷新了医疗模型低幻觉世界纪录。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadGKW1vcuTHd2Yz8KcWOOaJBRW4r1OmlMvHAePDpEoY0RgpFTWYktYog/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8105548037889039" data-s="300,640" data-type="png" data-w="739" type="block" data-imgfileid="503529758" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/6e25abcf-b2d2-43aa-a70b-0df9c16075d3/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;现在，AI 不再生成高频但模糊的建议，而是经过显式训练，系统地抑制了那些「看起来很美」但并无事实依据的回答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让 AI 的每个医学判断都有据可查&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「验证 AI 的回答，比自己查书还累，」这是很多医生使用通用大模型时的抱怨。在医疗场景中，引用是可信度的底线，但在大模型领域中，人们对于 AI 生成内容的引用准确性始终缺乏系统性优化路径。很多大模型列出的引用内容，指向的文献或段落并不支持当前表述，AI 并没有真正理解和呈现证据立场。&lt;/p&gt;&lt;p&gt;为此，&lt;strong&gt;百川智能首创了「证据锚定」（Evidence Anchoring）技术，让 AI 生成的每一句医学结论都能被逐句核验。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Baichuan M3 Plus 中，引用准确性被作为一个独立且核心的训练目标被进行系统建模。AI 不是简单标注「引用自哪篇文献」，而是被要求生成的每一句医学结论，都必须精确对应到原始论文或指南中的具体证据段落。每一句判断，都能被逐字溯源、逐条核验。&lt;/p&gt;&lt;p&gt;结合专门训练的 Citation Reward Model（引用奖励模型），对错误引用进行明确惩罚，模型现在只能在「确实有证据支持」的空间中推理与生成。最终，结论与证据段落的匹配准确率超过 95%，真正让 AI 的医学判断做到了可核验、可追责、可教学。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad0OL7XOncOqmicXH4ic8km9z3qfTgGKyXibL41UMvEzmiaYnCib0iblD2icMRQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.6546296296296297" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503529760" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e87abe40-bd0f-4936-95e4-8c5d6be0c745/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 M3 Plus 生成的内容中，引用的段落和支持的表述是完全一致的，人们可以直接定位到支持这句话的证据，这样一来，验证来源的权力被交还给了医生。&lt;/p&gt;&lt;p&gt;王小川表示，基于低幻觉的新一代模型，百川希望面向医生提供 AI 辅助能力，并向患者提供建议，「我们认为随着大模型技术的提升，人们对于 AI 辅助的接受度将会逐步提高。同时，这也需要多方面持续努力。」&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用免费开放 &amp;nbsp;推动行业共荣&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在美国，像 OpenEvidence 这样的 AI 医学知识助手已覆盖了 45% 的医生，但其高昂的订阅费在现阶段的中国市场难以落地 。中国医生面临着截然不同的工作环境：美国医生一天看 10 个病人，中国医生可能要看上百个 。如果要让 AI 真正普及，就不能增加医生的经济负担，也不能指望像 SaaS 软件那样简单收费。&lt;/p&gt;&lt;p&gt;为此，百川给出了更大胆的解法。&lt;/p&gt;&lt;p&gt;百川公布了「海纳百川计划」&amp;mdash;&amp;mdash; &lt;strong&gt;面向所有为医务工作者提供服务机构，免费提供循证增强的 M3-Plus 的 API&lt;/strong&gt;。百川希望通过这种方式推动更多服务于医生的 AI 应用落地，让更多医生拥有可用、好用的 AI 工具，推动临床、医学教育的进步。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadnuot7WFh3w5q5be5yN2ln1kZhMKcl2wticOKfvKpfh4meuOmDMgOicPg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503529762" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9b531859-937f-4f0e-bbeb-8e26a13a0277/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;目前，M3 Plus 也面向所有开发者开放为期 15 天的 API 限时免费体验，所有开发者均可以申请使用。&lt;/p&gt;&lt;p&gt;王小川表示，即使全中国临床医生都在使用 M3 Plus 模型，一年的成本也在可控范围内（约 1 亿元），百川愿意承担这笔费用来催熟生态。&lt;/p&gt;&lt;p&gt;当然在技术层面上，新模型也进行了极致的工程优化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;M3 Plus 围绕医学场景对模型架构、推理路径与部署形态进行了系统的工程重构，在不牺牲模型能力与可靠性的前提下，让 API 调用成本较上一代降低 70%。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该模型完成了两项新型优化工作。首先是 Gated Eagle-3 投机解码框架，它通过门控注意力机制（Gated Attention），可以在几乎不增加计算开销的前提下实现对外部信息流的动态筛选与精细调控，draft 模型能够「有选择地」吸收主模型语义指导，显著提升预测准确率。&lt;/p&gt;&lt;p&gt;就像是有一个教授在带着助教在写诊断书，助教（Draft 模型）先快速写出草稿，教授只负责进行快速审核与修正。M3 Plus 的创新在于让这个助教更聪明，能精准领会教授的意图，从而在不降低论文质量的前提下，让产出速度提升。&lt;/p&gt;&lt;p&gt;在相同配置下，Gated-Eagle3 相比原始 Eagle-3 实现约 15% 的推理吞吐量提升，直接降低单位请求的推理成本。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadNcTpIUjXIc5RwbEicW80ug35icSOka04xjBHEYRvWICGDZX7GDHlzpAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529763" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c1b6de0a-783e-4131-9e6c-db74f212cd01/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Gated Eagle3&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;另外还有面向医学 MoE 模型的极致量化。在部署侧，百川针对 MoE 架构的稀疏激活特性设计了面向医疗场景的定制化的量化方案，并通过专家均匀激活校准避免了 MoE 专家量化失衡。量化之后的 M3 Plus 在主流基准评测和医学效果评测上推理成本下降 30%，同时性能几乎无损。&lt;/p&gt;&lt;p&gt;鞠强表示，在具有最高专业度的同时，M3 Plus 的每 Token 成本比通用的 DeepSeek、千问等模型还要更低。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;医疗健康 &amp;nbsp;今年 AI 落地的主战场&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「今年是 AI 进入医疗的关键一年，」王小川判断。&lt;/p&gt;&lt;p&gt;事实上，在国内外 AI 领域，今年一开年，就有很多与 AI 医疗相关的大新闻曝出。&lt;/p&gt;&lt;p&gt;1 月 8 日，OpenAI 宣布推出 ChatGPT Health，提供了一个「专门用于与 ChatGPT 进行健康相关对话的独立空间」，连接电子医疗记录和各类健康应用，生成的回复能够结合用户的健康信息与个人情境；1 月 12 日，Anthropic 推出 Claude for Healthcare，使医疗服务提供者、支付方和消费者能够将 Claude 用于医疗用途；在国内，蚂蚁阿福（AQ）作为 AI 驱动的医疗健康应用已经获得了 3000 万的月活用户。&lt;/p&gt;&lt;p&gt;这一方面证明了医疗正在成为 AI 技术落地的核心场景，也证明了百川率先切入医疗赛道的正确性。&lt;/p&gt;&lt;p&gt;不过在应用大模型的方向上，百川选择的路径与很多试图构建 AI 健康助手的玩家有着本质的不同 &amp;mdash;&amp;mdash; &lt;strong&gt;当很多 AI 应用试图通过连接你的手表和手机，成为你的「健康管家」时，百川选择了一条更艰难、更垂直的道路：直面严肃场景，进入医院核心科室，成为医生的「第二大脑」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;M3 Plus 的发布，标志着中国 AI 公司在垂直赛道上，通过极致的工程化与场景深耕，正在构建起属于自己的护城河。&lt;/p&gt;&lt;p&gt;王小川表示，相信在三年以内，AI 辅助的医疗问诊等应用将会在国内外大规模落地。&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.baichuan-ai.com/home?sessionid="&gt;点击此链接，加入「海纳百川」计划&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>清华姚班校友刘壮团队再发力，无需归一化的Transformer性能进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 19:13:23 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜陈陈、冷猫&lt;/section&gt;&lt;p&gt;刘壮带队的无需归一化 Transformer 又有新的版本了。&lt;/p&gt;&lt;p&gt;一直以来，在 Transformer 架构里，LayerNorm 几乎是标配，但它也有明显问题：比如计算和访存成本高，尤其在大模型推理阶段。&lt;/p&gt;&lt;p&gt;因此，「无归一化（Normalization-Free）」Transformer 成为研究者探索的一个长期目标，但一直卡在两个难点上：训练不稳定，以及性能明显不如带归一化的模型。&lt;/p&gt;&lt;p&gt;而这篇新论文提出了一种非常简单的新激活层 Derf（Dynamic erf），让「无归一化（Normalization-Free）」的 Transformer 不仅能稳定训练，还在多个设置下性能超过了带 LayerNorm 的标准 Transformer。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadJGMW4Z6Wdtiblds23HfokXyeZ3lXHx8ZRXCG0fIqWbzMv0m8GOxFosQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.28544423440453687" data-type="png" data-w="1058" data-width="1058" data-height="302" data-imgfileid="503529570" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1aca6cd8-3ec0-4133-abb8-f670d18c94c7/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Stronger Normalization-Free Transformers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.10938&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github 链接：https://github.com/zlab-princeton/Derf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;刘壮本人也在 X 账号上分享了这一成果。他表示，这是一篇关于更强无归一化 Transformer 的新论文：研究团队提出了 Derf（Dynamic erf），一种结构极其简单的逐点（point-wise）层。借助 Derf，完全不依赖归一化层的 Transformer 不仅能够稳定训练，而且&lt;strong&gt;在实际性能上已经可以超越传统依赖 LayerNorm 等归一化机制的模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这一结果表明，长期被视为标配的归一化层，并非构建高性能 Transformer 的唯一选择。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadoWlibQfTWyxALjKyd3ayU660jXz7HKH0lWRVguDWm0UNgTZhI1Oic1zA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5138888888888888" data-type="png" data-w="1080" data-width="1172" data-height="602" data-imgfileid="503529571" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0bfeeea7-1f6a-45a1-a491-6707cd7251cb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;今年早些时候，刘壮、何恺明、LeCun 等人已经在题为《无需归一化的 Transformer》的论文中表明，Dynamic Tanh（DyT）函数可以取代 Transformer 中的归一化层。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Derf 进一步发展了这一想法。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;和 DyT 类似，Derf 是一种不依赖统计量的逐点（point-wise）层，不需要使用激活分布的统计信息。它本质上只是一个带有少量可学习参数的平移并缩放后的高斯误差函数（Gauss error function），可以直接替换你原本使用 LayerNorm 或 RMSNorm 的位置。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad4NLZBUqKibHJzxSmBrdVlI0Zvgaq5anh6kgRpETjeCPPukI9tia0WIGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.33555555555555555" data-type="png" data-w="900" data-width="900" data-height="302" data-imgfileid="503529572" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4b75ef8e-574c-4e3d-9ec3-2cbcc9e323f2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;由于其结构极其简单、效果稳定且性能更强，Derf 为构建无归一化（normalization-free）的 Transformer 架构提供了一种非常具有实践价值的选择。相关代码已开源。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;超越归一化层的逐点函数&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文的目标正是寻找性能超越归一化层的逐点函数，以推动更强的 Transformer 架构发展。&lt;/p&gt;&lt;p&gt;研究团队首先系统性地研究了逐点函数的内在性质如何影响训练动态和最终性能，重点关注四个基础且具有代表性的属性：&lt;strong&gt;零中心性（zero-centeredness）、有界性（boundedness）、中心敏感性（center sensitivity）以及单调性（monotonicity）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;实验发现，只要一个函数同时满足这四个条件，模型训练过程就会更加稳定，并且通常能取得不错的性能表现。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadgmrRCCvZEbLxVqibOHWNuNQuAia44w78wglVJ1nSnfhRRIL1Y7ql7T3g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1712962962962963" data-type="png" data-w="1080" data-width="1200" data-height="205" data-imgfileid="503529573" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a76a27ba-a559-4b64-8b62-89af229aa4e7/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这一分析筛选出了一类可作为有效归一化替代的逐点函数，并总结出一套面向无归一化 Transformer 的明确设计原则。&lt;/p&gt;&lt;p&gt;最终，Dynamic erf（Derf） 作为一种结构极其简单但性能最优的函数设计脱颖而出。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadWsZlpueOpJfoeEXTkuSQyA4n74IzcsYibbtoWWJzOicYvJic8fHb9huNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.29814814814814816" data-type="png" data-w="1080" data-width="1608" data-height="480" data-imgfileid="503529574" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d2a0696c-636e-467d-b476-33212f08f610/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;总体而言，本研究表明：只要设计得当，逐点函数不仅可以替代归一化层，甚至能够在性能上超越它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;最优函数设计：Derf&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在函数搜索过程中，我们发现 erf (x) 是性能最优的逐点函数。误差函数 erf (・) 与标准高斯分布的累积分布函数（CDF）密切相关。具体而言，erf (x) 的定义如下所示。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadxxYdhNIturdKHGpOUvPxAxjejs7mKMZ9ICQGN9Uqmzow558gWdvhrw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3875968992248062" data-type="png" data-w="774" data-width="774" data-height="300" data-imgfileid="503529575" data-aistatus="1" data-original-style="width: 375px;height: 145px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/99211b4e-8c67-4df4-a3ad-73e6ef5fe7ee/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在本文的设计中，erf (x) 进一步引入了可学习参数，并由此提出 Derf（Dynamic erf）。对于输入张量 x，Derf 层的形式如公式（10）所示，其中位移参数 s 和缩放参数 &amp;alpha; 都是可学习的标量，而 &amp;gamma; 和 &amp;beta; 是可学习的逐通道向量。&lt;/p&gt;&lt;p&gt;在将 Derf 集成到基于 Transformer 的架构中时，研究团队采用一一对应替换的方式：将模型中的各个归一化层直接替换为相应的 Derf 层。具体来说，包括 &lt;strong&gt;注意力层前（pre-attention）、前馈网络前（pre-FFN） 以及 最终的归一化层&lt;/strong&gt;，均被 Derf 所取代，从而保证 Derf 在整个模型中的一致性使用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在多种基于 Transformer 的架构以及少量其他现代模型上，系统评估了 Derf 的有效性。在使用相同训练配置的前提下，Derf 的表现可以持平甚至超过传统归一化层，并且在各个领域中都稳定优于 DyT。&lt;/p&gt;&lt;p&gt;简而言之：&lt;/p&gt;&lt;p&gt;1. ImageNet（ViT-B / ViT-L）：Top-1 准确率更高&lt;/p&gt;&lt;p&gt;2. 扩散 Transformer（DiT 系列）：FID 更低&lt;/p&gt;&lt;p&gt;3. 基因组任务（HyenaDNA、Caduceus）：DNA 分类准确率更高&lt;/p&gt;&lt;p&gt;4. 语音（wav2vec 2.0）：验证集 loss 更低&lt;/p&gt;&lt;p&gt;5. 语言模型（GPT-2）：整体表现与 LayerNorm 持平，明显优于 DyT&lt;/p&gt;&lt;p&gt;Vision Transformer（ViT）&lt;/p&gt;&lt;p&gt;研究团队在 ImageNet-1K 数据集上训练了 ViT-Base 和 ViT-Large 模型，分别采用 LayerNorm（LN）、DyT 和 Derf 进行对比。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadjDjkmkNicsbTAaKvz0NrdBmIbImng5YJXCwyLjRR4lDibJgiaRpteSkeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.21132075471698114" data-type="png" data-w="1060" data-width="1060" data-height="224" data-imgfileid="503529576" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/c9fd263c-c25c-4e64-bbd6-e8a6cbc1fd8d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ImageNet-1K 上的监督分类准确率。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在不同模型规模下，Derf 的 Top-1 准确率均高于 LayerNorm（LN）和 DyT，充分证明了其在 ViT 架构中的有效性。&lt;/p&gt;&lt;p&gt;Diffusion Transformer（DiT）&lt;/p&gt;&lt;p&gt;研究团队在 ImageNet-1K 上训练了三种 DiT 模型，并在 LN、DyT 和 Derf 下保留归一化层的仿射参数用于类别条件化。训练完成后，使用 ImageNet 「参考批次」评估 FID 分数，以衡量图像生成质量）。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadURLjicuJxRGIIIEib48CAyZyhEpiaPqxoEal0L8gr2FyriaTZWv0RZicp3Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.264" data-type="png" data-w="1000" data-width="1000" data-height="264" data-imgfileid="503529577" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/67ca3438-31a1-4f37-93a7-ac93335b04e7/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ImageNet 图像生成质量（FID）。FID 越低表示图像生成质量越高。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;结果显示，Derf 在所有 DiT 模型规模下的 FID 都低于 LayerNorm 和 DyT，进一步验证了其在扩散 Transformer 中的有效性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语音模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 LibriSpeech 数据集上训练了两个 wav2vec 2.0 Transformer 模型，用于语音表示学习。表 10 报告了最终的验证集损失（validation loss）。结果显示，与 LayerNorm 和 DyT 相比，Derf 在不同模型规模上均实现了更低的验证损失，说明其在语音任务中的有效性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadhiag0xU9JwwxzicnFuRv0l0k6rhXe91WBnLlnUJUb5FibwGKCXGzPDib4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.20185185185185187" data-type="png" data-w="1080" data-width="1308" data-height="264" data-imgfileid="503529578" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c4f96529-0f29-41ab-8c25-d6d89acf7db7/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; LibriSpeech 数据集上的语音预训练验证损失（validation loss）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;结果显示，Derf 在两个 wav2vec 2.0 模型上均实现了比 LayerNorm 和 DyT 更低的验证损失，表明其语音表示能力更强。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DNA 模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在长序列 DNA 建模任务中，研究团队对 HyenaDNA 和 Caduceus 模型进行了预训练，使用人类参考基因组（GRCh38.p13）。模型评估在 GenomicBenchmarks 数据集上进行，并报告所有子任务的平均准确率。&lt;/p&gt;&lt;p&gt;如表所示，Derf 在性能上超过了 LayerNorm、RMSNorm 以及 DyT，显示了其在基因组序列建模任务中的稳健性与泛化能力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadx3adpn1sWGoYU4BnUlMeRu3otf2sZcf2X5p28dAsSic8aAlzBLTFnTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.21388888888888888" data-type="png" data-w="1080" data-width="1160" data-height="248" data-imgfileid="503529579" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9a2f7bce-dd18-4297-a662-a0996d2c6224/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;DNA 分类准确率（GenomicBenchmarks 数据集）表中结果为各子任务的平均准确率。每个模型均使用其默认归一化层（HyenaDNA 使用 LayerNorm，Caduceus 使用 RMSNorm）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;结果显示，Derf 在所有模型中均优于原有归一化层及 DyT，表明其在 DNA 模型上的有效性和稳健性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语言模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 OpenWebText 数据集上对 GPT-2（124M）模型进行预训练，并在表 12 中报告验证集损失。对于 DyT 和 Derf，还对可学习参数 &amp;alpha; 进行了额外微调。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadXTkyqo44Gzw2KMXX3zpPFDHHCWW7FB7j6ctVNeSzE766yfWic7v01Bg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.16666666666666666" data-type="png" data-w="1080" data-width="1188" data-height="198" data-imgfileid="503529580" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/be1f676f-7ffd-4d9e-b360-79403ddc476b/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;GPT-2 在 OpenWebText 数据集上的验证集损失。Derf 的表现可与 LayerNorm（LN）匹配，同时在验证集损失上明显低于 DyT。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实验结果显示，Derf 在性能上可与 LayerNorm（LN）持平，同时明显优于 DyT。&lt;/p&gt;&lt;p&gt;这表明：一个足够简单的逐点层，不仅可以「替代」归一化层，还能让 Transformer 变得更强，而不只是不变差。&lt;/p&gt;&lt;p&gt;Derf 只是「拟合得更狠」吗？出人意料地，并不是。当研究团队在 eval 模式下、对训练集本身测量训练损失时，结果是：基于归一化（Norm）的模型训练损失最低，Derf 训练损失反而更高。但在测试集上，Derf 的表现更好。&lt;/p&gt;&lt;p&gt;这说明一个关键事实：Derf 的优势并不来自更强的拟合能力，而主要来自更好的泛化能力。&lt;/p&gt;&lt;p&gt;一句话总结：&lt;strong&gt;Derf 是一种简单实用的、可用于更强正则化自由 Transformer 的即插即用层&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;更多信息，请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>苹果入局AI Pin，或对标OpenAI，能否打破「电子垃圾」魔咒？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 19:06:54 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;近日，有消息传出，苹果正在研发一款由 AI 驱动的可穿戴「胸针」（Pin）设备，不过目前该设备仍处于早期研发阶段，最快可能也要在 2027 年才能面世。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadiau2RNrN9y5pARIfpWlQUvUW8jdbzfialHA8EkrLnxt9icJrbF7RCYUvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.1324074074074073" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529729" data-aistatus="1" data-original-style="width:428px;height:485px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/aae9122a-592e-4709-8c0e-160e9d475270/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;据知情人透露，该设备体积与 AirTag 相当（AirTag 是之前苹果推出的一款硬币大小的蓝牙物品追踪器），外观为「纤薄、扁平的圆形」设计，材质采用铝和玻璃，内置一个标准镜头和一个广角镜头摄像头，用于感知并捕捉用户周围环境信息。&lt;/p&gt;&lt;p&gt;此外，该设备还内置三枚麦克风、扬声器，并在机身侧面设置一枚实体按键，同时支持无线充电，有可能是背面采用磁感应充电接口，类似 Apple Watch 的充电方式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadaxCftktHnrZic38H4TVh84gwKSENRHxECNqaXeIKMqFkbjT7bfaFr8w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529726" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a4ce493a-dba9-40c1-be9b-847ad62f45dd/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图为根据描述，AI 生成的概念图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;苹果的入局能将硬件 AI Pin 市场「盘活」吗？毕竟这一赛道是有「前车之鉴」的。&lt;/p&gt;&lt;p&gt;比如由前苹果核心员工 Imran Chaudhri（iPhone 界面设计者）和 Bethany Bongiorno 创立的 Humane，该公司于 2018 年创立，愿景是试图打造一款取代智能手机的设备。&lt;/p&gt;&lt;p&gt;而凭借创始人背景和远大愿景，公司在没有发布任何产品的情况下，筹集了超过 2.3 亿美元的资金，一度将大众的期待值拉满。&lt;/p&gt;&lt;p&gt;2023 年 11 月，Humane 发布其首款产品 AI Pin，售价高达 699 美元，且每月还有 24 美元的订阅费，用于流量和 AI 服务。而与高昂价格相对应的是，该设备反应迟钝、投影在日光下不可见、且作为卖点的 AI 服务常常产生幻觉，电池续航极差&amp;hellip;&amp;hellip; 没有等来想象中的高光时刻，种种「槽点」之下带来的是退货潮与惨淡数据。&lt;/p&gt;&lt;p&gt;据报道，截至 2024 年夏季，该款 AI Pin 的总销量仅为 10000 台，远远低于其当初许下的远大目标 &amp;mdash;&amp;mdash;10 万台。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadicYZela4Y9Q0r5ibYOjbk8pcjw8Hvf217OwffnkuAChHn0z0FY6MokNw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529727" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/896aa906-724d-44a9-8ca4-8e19405876aa/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，在资金耗尽和口碑崩盘的双重打击下，Humane 的最终结局是，去年 2 月，被惠普 (HP) 以 1.16 亿美元的价格收购，包括公司的核心资产（人才、技术专利和 Cosmos 操作系统），但，不包括硬件业务。&lt;/p&gt;&lt;p&gt;当然，Humane 的失败是多方面的，并不仅仅是产品硬件形态本身的失败，也有早期技术不成熟、研发成本高、产品价格离谱等多重因素。如今，模型技术愈加成熟，AI 硬件市场也处于爆发前夕，被视为大模型下半场下一个「战场」。不仅仅是 AI Pin，AI 眼镜、AI 耳机等多种 AI 可穿戴设备都因或有可能成为下一代 AI 交互入口，而被各大 AI 大厂或初创押注。苹果早前已被爆出有一系列的 AI 硬件布局，比如叠加摄像头的 AirPods 耳机、智能眼镜等。&lt;/p&gt;&lt;p&gt;甚至有消息传出，苹果或将加快该 AI Pin 的开发速度，以与 OpenAI 即将推出的首款可穿戴设备展开竞争&amp;hellip;&amp;hellip; 此外，苹果还计划在未来几个月内与谷歌合作，为 Siri 引入更强的个性化能力，甚至将在今年 9 月把其语音助手升级为内置于 iPhone、iPad 和 Mac 中的 AI 聊天机器人。&lt;/p&gt;&lt;p&gt;而当前关于 OpenAI 的这款 AI 可穿戴设备产品也是众说纷纭，自去年五月 OpenAI 收购前苹果设计总监 Jonathan Ive 的公司以来， Sam 就一直在暗示未来 OpenAI 会推出一款 AI 硬件设备，且一再预热，这款设备将比智能手机更「平和」，用户会惊讶于它的简单易用等，但没有给出具体时间表，也没有描述该设备的外观。&lt;/p&gt;&lt;p&gt;最新消息是，前两天，在 Axios House Davos 活动上，OpenAI 首席全球事务官 Chris Lehane 宣称，公司「有望」在 2026 年下半年推出其首款硬件设备，但他拒绝透露任何更多细节，包括该设备到底将会是 Pin，还是耳机，或是其他完全不同的东西等，都还悬而未知。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad2P2CBToSpGicfQlTHj6xicOvicQBJXtwLanTKA66B2yLKyM2Vml6W6J6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529728" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d93b94f5-1b15-44be-89a2-0687ce16aeda/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如今，更多的产品信息都还没有，但两家的对垒之势已愈加明显，那么问题来了，2026 年会是 AI 硬件爆发元年吗？苹果能够「改写」AI Pin的命运吗？而你更看好或期待谁的 AI 设备？&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/StockMKTNewz/status/2014065885418319992?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/news/865212/apple-ai-pin-wearable-airtag-rumor&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.axios.com/2026/01/19/openai-device-2026-lehane-jony-ive&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为云昇腾AI云服务客户增长超8倍，稳居最大国产AI云服务提供商</title>
      <description>&lt;![CDATA[客户数量达到2663家。]]&gt;</description>
      <author>新闻助手</author>
      <pubDate>Thu, 22 Jan 2026 17:35:30 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;近日，华为云透露了最新的昇腾 AI 云服务客户进展：截至 2025 年底，昇腾 AI 云服务客户数突破 2663 家，增长超 8 倍。华为云稳居中国最大国产化 AI 云服务提供商地位，持续通过全栈技术创新与全球化服务能力，支撑全球企业智能化转型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构筑核心竞争力，系统级创新突破算力瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对全球 AI 算力需求爆发，华为云以系统级创新构建差异化优势。2025 年，华为云发布基于 CloudMatrix384 超节点的新一代昇腾 AI 云服务，整合 384 颗昇腾 NPU，单节点提供高达 300 P 算力，可同时服务数百个千亿参数大模型推理。&lt;/p&gt;&lt;p&gt;同时，华为云也在去年推出了 CloudMatrix384 AI Token 推理服务，在在线、近线和离线等不同时延推理场景中，CloudMatrix384 平均单卡的推理性能达到 H20 的 3 到 4 倍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;昇腾 AI 云服务提供全栈能力，赋能千行万业智能化升级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;昇腾 AI 云服务整合大规模算力集群、计算引擎 CANN、AI 开发框架 MindSpore、ModelArts AI 开发生产线和 ModelArts Studio 大模型即服务平台，为千行万业提供了多元、高效、长稳的算力服务选择，为大模型的训练、推理，AI 应用的开发、运行提供稳定可靠的全栈算力保障。目前，昇腾 AI 云服务已全面适配 DeepSeek、Qwen 等行业主流的 160 多个大模型。&lt;/p&gt;&lt;p&gt;截止 2025 年底，使用华为云昇腾 AI 云服务的全球客户增长到 2663 家。当前，华为云昇腾 AI 云服务已经成为 AI 基础设施的最优选择，为科大讯飞、新浪、面壁智能、中科院、360 等客户提供澎湃的 AI 算力，加速千行万业智能化升级。如 360 纳米 AI 依托昇腾云的 AI Token 推理服务，成功处理每天上千万的内容生成请求。中国科学院联合团队打造的 &amp;ldquo;磐石・科学基础大模型&amp;rdquo; 采用昇腾 AI 云服务，将赋能中国科学院百余家研究所的科研场景。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;安全稳定高质量的全球一张网，夯实全球化服务根基&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;华为云在全球部署了 34 个区域，运营 101 个可用区，为全球 170 多个国家和地区提供安全稳定高质量的云服务，实现低时延接入和数据本地合规。安全方面，华为云年均防御 4500 亿次网络攻击，已经连续 900 多天无重大事故。已聚集超 1000 万开发者及 5.9 万家合作伙伴，持续拓展生态朋友圈。&lt;/p&gt;&lt;p&gt;依托全栈创新、全球服务与生态共赢，华为云持续为全球客户提供技术领先、安全可靠的 AI 云服务。未来，华为云将继续深耕行业场景，携手伙伴构建多元、开放的智能生态，助力千行万业智能化转型，共赢 AI 时代。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI杰出论文来了！港科大、同济、浙师大等国内高校获奖</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 16:56:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑｜张倩、陈陈&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;刚刚，AAAI 2026 官网公布了今年的「杰出论文」（相当于最佳论文）奖项，共有 5 篇论文获奖，其中有三篇由华人团队主导，作者来自香港科技大学（广州）、西湖大学、浙江大学、同济大学、浙江师范大学、香港城市大学等多所国内高校。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;AAAI 由国际人工智能促进协会主办，是人工智能领域历史最悠久、涵盖内容最广泛的国际顶级学术会议之一，也是中国计算机学会（CCF）推荐的 A 类国际学术会议，每年举办一届。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;AAAI 2026 于 1 月 20 日至 27 日在新加坡举行，总投稿数为 23,680 篇，录用论文 4,167 篇，接收率为 17.6%。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;以下是获奖论文的具体情况。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;论文 1：ReconVLA: Reconstructive Vision-Language-ActionModel as Effective Robot Perceiver&lt;/strong&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadMdeaicOGxibIicda51jU47HzpCBNsk9iaicCR8Xyxx52WzUnib6B3MnvS9YQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.31574074074074077" data-type="png" data-w="1080" data-width="1436" data-height="454" data-imgfileid="503529664" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2dda3b76-4ac5-4972-a6ae-f927502255d5/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Wenxuan Song, Ziyang Zhou, Han Zhao, Jiayi Chen, Pengxiang Ding, Haodong Yan, Yuxin Huang, Feilong Tang, Donglin Wang, Haoang Li&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：香港科技大学（广州）、西湖大学、浙江大学、莫纳什大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2508.10333&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://zionchow.github.io/ReconVLA/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;近年来，视觉 &amp;mdash; 语言 &amp;mdash; 动作（VLA）模型的进展，使机器人智能体能够将多模态理解与动作执行相结合。然而，实证分析发现，现有的 VLA 模型在将视觉注意力分配到目标区域时仍然存在明显困难，其注意力往往呈现分散状态。&lt;/p&gt;&lt;p&gt;为引导视觉注意力在正确目标上的有效 grounding ，作者提出了 ReconVLA，一种采用隐式对齐范式的重建式 VLA 模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadTtXzNWgLOlGlia1EgbKIUafiaLDUPicibWbFaCkIBdlK8bBomdLyEMQbibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.575925925925926" data-type="png" data-w="1080" data-width="1742" data-height="1004" data-imgfileid="503529665" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ade07d01-3c78-4529-8c5c-2e5ff146d62a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该方法以模型的视觉输出为条件，引入扩散 Transformer 来重建图像中的注视区域（gaze region），而这一注视区域正对应于被操作的目标物体。通过这一过程，VLA 模型被促使学习更加细粒度的表征，并能够准确分配视觉注意力，从而更充分地利用任务相关的视觉信息，完成精确操作。&lt;/p&gt;&lt;p&gt;此外，作者构建了一个大规模预训练数据集，包含来自开源机器人数据集的十万余条轨迹和两百万条数据样本，进一步提升了模型在视觉重建任务上的泛化能力。大量仿真与真实环境中的实验结果表明，论文提出的隐式对齐方法具备明显优势，在精细操作能力和泛化表现上均有出色表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文 2：LLM2CLIP: Powerful Language Model Unlocks Richer Cross-Modality Representation&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadWGC49xrbyKeyQyTZvBuTMbVKgVIf5etj4UFgFicT5VUW8lKj19CHhPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.75" data-type="png" data-w="1080" data-width="4096" data-height="3072" data-imgfileid="503529671" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/15a34aa0-da29-4e2a-b6f8-5e11bd9f8859/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Usman Naseem, Chunyu Wang, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu, Liang Hu&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：同济大学、微软、麦考瑞大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2411.04997&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文主页：https://microsoft.github.io/LLM2CLIP/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;CLIP 是一种具有奠基意义的多模态模型，它通过在数十亿规模的图像 &amp;mdash; 文本配对数据上进行对比学习，将图像与文本映射到同一表示空间。&lt;/p&gt;&lt;p&gt;受到 LLM 迅猛发展的启发，作者探讨了如何利用 LLM 更强的语言理解能力与广泛的世界知识来进一步增强 CLIP，尤其是在处理冗长且结构复杂的描述文本时的表现。为此，他们提出了一种高效的微调框架，&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650944638&amp;idx=4&amp;sn=35b3ffc2ae3cf40588b822990a0b815c&amp;scene=21#wechat_redirect" target="_blank"&gt;将 LLM 嵌入到预训练的 CLIP 中&lt;/a&gt;，而训练成本几乎与常规的 CLIP 微调相当。具体而言，该方法首先将 LLM 转化为适配 CLIP 场景的「嵌入化」形式，随后通过一个轻量级适配器将其与预训练的 CLIP 视觉编码器耦合，该适配器仅需在数百万规模的图像 &amp;mdash; 文本对上进行训练。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad6ZwFUqOWfrp6P2Smmd3NxnjFByZ1owPZMpLGKb2SqSIUPEu0Kibic2ibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0626398210290828" data-type="png" data-w="894" data-width="894" data-height="950" data-imgfileid="503529670" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/85874bce-e767-4b87-b750-cb4a8b60de0f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;借助这一策略，作者在无需大规模重新训练的前提下，相较于 EVA02、SigLIP-2 等当前最先进的 CLIP 变体，取得了显著的性能提升。经 LLM 增强后的 CLIP 在多种下游任务上均表现出稳定改进，包括线性探测分类、同时支持短文本与长文本（英文及多语言）的零样本图像 &amp;mdash; 文本检索、零样本与有监督的图像分割、目标检测，以及作为多模态大模型基准中的分词器使用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文 3：Model Change for Description Logic Concepts&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Ana Ozaki, Jandson S Ribeiro&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：奥斯陆大学、卡迪夫大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：暂无&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该论文虽已获奖，但目前还未公开发布。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadICSpTe2YTIteGv3juNPTUGJmrctwPho08JdH2gn8YNWTOszjOT06cw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.31296296296296294" data-type="png" data-w="1080" data-width="1706" data-height="534" data-imgfileid="503529669" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6a226957-810b-42c9-abd7-18c12e552de3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;论文 4：Causal Structure Learning for Dynamical Systems with Theoretical Score Analysis&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadHpfjue4ickHH4ZN3TTgfNT6KsutSPxNE9mGTXxzSb1z6xMy9iacIuhog/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21574074074074073" data-type="png" data-w="1080" data-width="1308" data-height="282" data-imgfileid="503529668" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b9239d3e-d7f5-4f93-86f9-f1d88fefb1fb/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Nicholas Tagliapietra, Katharina Ensinger, Christoph Zimmer, Osman Mian&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：博世 AI 中心团队、德国达姆施塔特工业大学、德国医学 AI 研究所 IKIM 等&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.14361&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现实世界中的系统通常按照其内在的因果关系在连续时间中演化，但这些动态机制往往是未知的。现有用于学习此类动态的方法通常存在两类问题：要么对时间进行离散化处理，在面对不规则采样数据时性能较差；要么忽略了系统背后的因果结构。&lt;/p&gt;&lt;p&gt;为此，本文提出 CADYT，一种用于动力系统因果发现的新方法，可以同时解决上述两大挑战。不同于当前主流将问题建模为离散时间动态贝叶斯网络的因果发现方法，该研究建模基础是基于差分的因果模型，这种模型对连续时间系统的刻画只需更弱的假设，更符合真实系统的连续演化特性。&lt;/p&gt;&lt;p&gt;CADYT 采用精确的高斯过程推断来建模连续时间动力学，从而在建模层面更贴近系统的真实生成过程。在算法设计上，本文提出了一种可落地的实现方案：通过结合马尔可夫条件与最小描述长度（MDL）原则，采用贪心搜索策略来识别系统的因果结构。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadnxnibdObtOowtmABR3cFibRIoXcNdlmFse1YfJfSLiafRMGMGF2QeGUaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6072507552870091" data-type="png" data-w="993" data-width="993" data-height="603" data-imgfileid="503529667" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/8dc26bbd-8943-4910-ba5f-accb04b59ab5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; CADYT 能够从连续时间动力系统的轨迹数据中，发现未知的因果结构。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实验结果表明，无论是在规则采样还是不规则采样的数据场景下，CADYT 都显著优于现有的先进方法，能够恢复出更接近真实底层动力学机制的因果网络结构。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文 5：High-Pass Matters: Theoretical Insights and Sheaflet-Based Design for Hypergraph Neural Networks&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇获奖论文同样还没有放出论文链接，但从附录论文中，我们获悉了作者机构信息。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadeYKO8MUgwe57cibKicFwIiarykRWkqm9lfSTDpMrbsCGXaT1kpJRGiaKKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.33611111111111114" data-type="png" data-w="1080" data-width="1419" data-height="477" data-imgfileid="503529666" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ec7e50d0-acd5-4527-bd0b-d7749ba7a25c/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Ming Li, Yujie Fang, Dongrui Shen, Han Feng, Xiaosheng Zhuang, Kelin Xia, Pietro Lio&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：浙江师范大学、香港城市大学、南洋理工大学、剑桥大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：暂无&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://aaai.org/about-aaai/aaai-awards/aaai-conference-paper-awards-and-recognition/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Meta新模型要来了，但Llama 4的锅谁来接？1300多位作者的联合报告来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 16:53:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;路透社最新消息，&lt;strong&gt;Meta 新成立的 AI 团队本月已在内部交付了首批关键模型&lt;/strong&gt;。据悉，该消息来自 Meta 公司的 CTO Andrew Bosworth，他表示该团队的 AI 模型「非常好」（&lt;strong&gt;very good&lt;/strong&gt;）。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;媒体在去年 12 月报道称，Meta 公司正在开发一款代号为 &lt;strong&gt;Avocado&amp;nbsp;&lt;/strong&gt;的文本 AI 模型，计划于第一季度发布；同时还在开发一款代号为 &lt;strong&gt;Mango&amp;nbsp;&lt;/strong&gt;的图像和视频 AI 模型。Bosworth 并未透露哪些模型已交付内部使用。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;有意思的是，就在这篇报道的前些天，一篇技术报告《&lt;strong&gt;Llama 4 家族：架构、训练、评估和部署说明&lt;/strong&gt;》在 arXiv 悄然上线，其中全面回顾了 Meta Llama 4 系列模型宣称的数据和技术成就。&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadhZqPicWzlQqkzDzDftPDzFcCtFvooqY4OKiauKs8MwicpvxVpufUZW0gw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.22870370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529630" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d9dd64b1-ab91-4fea-9c57-3dbfa97a4817/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;报告标题：The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;报告地址：https://arxiv.org/abs/2601.11659v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要说明，上传这篇报告的作者是 Meta 一位机器学习工程师 Arthur Hinsvark，但这篇报告却并未明确标识来自 Meta。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad0Sa5IrTOAc9KsCzoEE6LdLD32RQrhD68u7Et193DoxvQjFPdib0dvSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529632" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e44ed63f-e241-4e15-8b66-25be0acbb6ef/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管如此，这篇报告还是将 Llama 4 项目的所有参与者都加入到了作者名单中 &amp;mdash;&amp;mdash; 超过 1300 名，足足 5 页！因此，我们可以大体上认为这份报告就是来自 Llama 4 团队，尽管其中不少人现在已经从 Meta 离职，比如前 Meta FAIR 团队研究总监&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651010344&amp;idx=1&amp;sn=ab18804d6c48b67537758c869b3ba649&amp;scene=21#wechat_redirect" target="_blank"&gt;田渊栋&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;值得注意的是，这篇报告的引言有一段明确说明：「本文档是对公开材料的独立调查。报告的基准数值归因于模型卡，除非另有说明；应将它们视为开发者报告的结果，并对评估工具、提示工程和后处理持通常的保留态度。」&lt;/p&gt;&lt;p&gt;也就是说，这篇报告整体回顾了 Meta 公布的各种 Llama 4 相关材料，尤其是其宣称的一些数据。但没有明确解释其在实际应用中表现明显不及预期的原因。想要了解相关背景的读者可参阅：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963634&amp;idx=1&amp;sn=4935ed3758561c8ee8366adce6b3be1f&amp;scene=21#wechat_redirect" target="_blank"&gt;Meta Llama 4 被疑考试「作弊」：在竞技场刷高分，但实战中频频翻车&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=1&amp;sn=2e63fcbf091cef43ae9fbf61aecc15a2&amp;scene=21#wechat_redirect" target="_blank"&gt;Llama 4 在测试集上训练？内部员工、官方下场澄清，LeCun 转发&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不过，该报告也不是完全没有提到相关原因，仔细阅读的话，我们能在行文中看到一些端倪，其中主要的讨论点集中在部署限制和榜单争议上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构能力与实际部署的差距（尤其是上下文长度）：&lt;/strong&gt;论文反复强调了一个「经常出现的操作主题」：模型的架构支持能力与实际服务中提供的能力之间存在差距。虽然 Scout 在架构上设计为支持 10M 上下文长度，但在实际部署中（如 Cloudflare 或 AWS），由于显存和 KV 缓存的硬件成本限制，服务商往往将可用上下文限制在 128K 或 1M。这意味着用户在实际使用托管服务时，可能无法体验到模型宣称的全部长上下文能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;榜单成绩与发布版本的差异：&lt;/strong&gt;论文提到了关于 LMArena 排行榜的争议。Meta 在榜单上提交的 Maverick「实验性聊天」变体与公开发布的版本不完全相同。这导致了外界批评其「操纵基准测试」（gaming AI benchmarks）。这也解释了为什么用户使用公开发布版本时的体验可能与某些榜单上的高分表现不一致。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;营销话术与技术指标的区别：&lt;/strong&gt;论文明确指出，发布公告中的某些声称（例如 Scout 是「同类最佳」或强调性价比）属于「面向营销的主张」（marketing-facing claims），应当与严谨的模型卡基准测试结果分开解读。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些细节似乎暗示了这份报告是 Meta Llama 团队对于 Llama 4 系列模型备受社区广泛批评（数据亮眼但能力很差）的最终回应。&lt;/p&gt;&lt;p&gt;对于这些说明，不知道你怎么看？&lt;/p&gt;&lt;p&gt;具体到内容上，这篇技术报告的内容仅有 15 页，其中 1300 多位作者的名单就足足占了 5 页，再去掉一页参考文献，实际内容仅有 9 页。其中，Meta Llama 团队总结了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;已发布的模型变体（Scout 和 Maverick）以及更广泛的系列模型背景，包括预览版的 Behemoth 教师模型；&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadDX5LAQficZDN0Pu7picBR2ibN108fKuEzKC28UlEnHu8nseVN6B2d3CIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6961429915333961" data-s="300,640" data-type="png" data-w="1063" type="block" data-imgfileid="503529631" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d62d6412-8b9c-4c96-963c-9ce538f0b10a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;超越高级 MoE 描述的架构特征，涵盖路由 / 共享专家结构、早期融合多模态，以及针对 Scout 报告的长上下文设计元素（iROPE 和长度泛化策略）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练披露，跨越预训练、用于长上下文扩展的中期训练（mid-training），以及发布材料中描述的后训练方法（轻量级 SFT、在线 RL 和轻量级 DPO）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开发者报告的基础和指令微调检查点的基准测试结果；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在主要服务环境中观察到的实际部署限制，包括特定于提供商的上下文限制和量化打包。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，这份报告还总结了「与再分发和衍生命名相关的许可义务，并回顾了公开描述的安全措施和评估实践。其目的是为需要关于 Llama 4 精确、有来源依据事实的研究人员和从业者提供一份紧凑的技术参考。」&lt;/p&gt;&lt;p&gt;更多详情请参阅原报告。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reuters.com/technology/metas-new-ai-team-has-delivered-first-key-models-internally-this-month-cto-says-2026-01-21/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>金山云星流全面升级 以智算穿越云上AI新周期</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 22 Jan 2026 16:47:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;当前，人工智能产业迈入以&amp;ldquo;云+AI&amp;rdquo;为核心驱动力的新周期，生成式AI加速规模化落地，产业重心正从模型训练阶段向推理环节转移，带动推理市场迎来指数级增长。麦肯锡报告预测，2028年全球AI推理市场规模将达1500亿美元，2025-2028年复合年增长率超40%。而智算作为承接推理爆发的核心基础设施，将迎来前所未有的市场增量空间。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/da7087bc-1aba-4755-9e85-8bb39a744ca8/1769083547560.jpeg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在2026年1月21日举办的金山云年度Tech Talk上，金山云高级副总裁刘涛表示，智算平台金山云星流已完成从资源管理平台向一站式AI训推全流程平台的战略升级。从训推平台、机器人平台到模型API服务，升级后的金山云星流平台构建了从异构资源调度、训练任务故障自愈到机器人行业应用支撑、模型API服务商业化落地的全链路闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实现三维进阶 智算云AI势能全释放&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管各行各业大规模应用AI还处于早期探索阶段，但定位行业助力者的金山云，多年来持续打磨全栈AI能力。从2023年的智算网基础设施，到2024年智算云的平台化和Serverless化，再到2025年的一站式AI训推全流程平台，通过提升平台效率、突破行业边界、加速推理布局，金山云为迎接AI应用爆发做好了充分准备。&lt;/p&gt;&lt;p&gt;在平台效率方面，金山云星流训推平台提供从模型开发、训练到推理的完整生命周期管理，具备开发、训练、推理和数据处理四大模块能力，通过降低多模块协同复杂度，能实现&amp;ldquo;开箱即用&amp;rdquo;的AI开发体验。自研的GPU故障自愈技术结合任务可观测性设计，可实时监控硬件健康状态与任务进程，自动触发故障迁移与任务重调度，降低算力中断风险，保障长周期训练任务稳定运行。&lt;/p&gt;&lt;p&gt;作为面向机器人开发与落地的全链路云原生平台，金山云星流机器人平台深度融合数据采集、存储、标注、模型开发、训练、部署与仿真等核心环节，打造具身场景专属的数据、模型、仿真一体化引擎。平台率先实现具身智能数据工程领域采集、标注、管理的全链路闭环，可高效服务具身智能行业模型训练、仿真应用场景分析等核心需求，助力客户快速完成从算法研发到真实场景部署的全流程落地，最终推动机器人产业的智能化升级。&lt;/p&gt;&lt;p&gt;面向大模型应用开发者和企业用户，金山云星流平台模型API服务提供高可用、易集成的模型调用与管理能力，覆盖模型调用的全生命周期。该服务支持高并发推理与多模型管理，能够帮助用户高效接入多种模型资源，助力大模型应用落地。目前，金山云星流平台模型API服务已积累诸多行业客户。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生态优势凸显 AI落地价值再跃升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AI需求强劲，金山云关于智算云潜力巨大的判断得到印证。国际权威机构英富曼（Omdia）数据显示，2025年上半年中国AI云市场（涵盖IaaS、PaaS、MaaS全链条）规模已达223亿元，其中生成式AI（GenAI）带来AI云市场的爆发，2025年预计增长148%，到2030年将达1930亿元规模。&lt;/p&gt;&lt;p&gt;得益于在智算云领域的前瞻性布局和技术能力建设，智算云已经成为金山云业务的&amp;ldquo;新底色&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在生态内，作为唯一战略云平台，公司持续为生态企业提供优质服务，夯实智算需求的快速响应能力；在生态外，金山云不仅成功支撑了互联网行业头部客户大规模推理算力需求，还在通用模型公司、具身智能等领域实现突破。这些经过生态内业务和行业头部客户验证过的落地能力，都会沉淀在金山云中，成为对外提供可持续稳定云服务的坚实基础。&lt;/p&gt;&lt;p&gt;与此同时，金山云星流平台的模型生态也在持续丰富。目前，平台已支持近40种不同模型，包括DeepSeek、Xiaomi MiMo、Qwen3、Kimi等。客户通过一站式访问，即可高效接入多种模型，在畅享稳定高效云服务的同时，更加聚焦AI业务创新和价值创造。&lt;/p&gt;&lt;p&gt;人工智能浪潮汹涌澎湃，新场景与新应用正驱动AI技术和产品持续进化，给云计算带来无限发展空间。金山云将始终围绕客户核心需求，携手生态伙伴，深入不断变化的真实应用场景，稳步推动AI价值落地。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Future Tech | 16支AI新锐齐聚数码港，FT Demo Day第二期引爆湾区创新浪潮</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 22 Jan 2026 16:45:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1月15日下午，由世界人工智能大会下子品牌&lt;strong&gt;Future Tech第二期Demo Day项目路演&lt;/strong&gt;在香港数码港成功举办。作为WAIC全年创投生态的重要一环，本次活动以&amp;ldquo;智联湾区 创见未来&amp;rdquo;为主题，汇聚了来自全国各地的16支优秀AI初创团队，集中展示了人工智能在数字孪生、法律服务、医疗健康、智能制造、低空经济、认知科技等前沿领域的创新成果与实践路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;创新生态启航：从年度盛会到全年伙伴&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;活动伊始，主持人介绍了WAIC Future Tech平台的定位与使命：它不仅承载着世界人工智能大会的基因，更旨在成为&lt;strong&gt;全年陪伴初创企业成长的全周期伙伴。&lt;/strong&gt;作为一个系统化的创新加速平台，其核心使命是通过高频路演、精准资源对接与全生态服务，切实回应并解决初创企业在发展初期的关键痛点&amp;mdash;&amp;mdash;&lt;strong&gt;曝光难、融资难、落地难。&lt;img src="https://image.jiqizhixin.com/uploads/editor/7d397ae0-0925-4529-8f05-fab7e974514a/%E5%9B%BE%E7%89%8710.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;自2024年启动以来，Future Tech已逐步构建起一个&lt;strong&gt;跨地域、跨领域的创新生态&lt;/strong&gt;，持续推动技术、资本与场景的高效链接。&lt;strong&gt;2026年，Future Tech将持续深化&amp;ldquo;创新加速器&amp;rdquo;角色&lt;/strong&gt;，拓展全年活动矩阵，强化产业对接与出海支持，助力更多优质项目走向国际舞台，真正实现&lt;strong&gt;&amp;nbsp;&amp;ldquo;全年孵化、全程赋能&amp;rdquo;&amp;nbsp;&lt;/strong&gt;的平台愿景。&lt;br&gt;&lt;br&gt;&lt;strong&gt;湾区联动：生态共建助力创新落地&lt;img src="https://image.jiqizhixin.com/uploads/editor/04d4fe78-320f-490d-9818-c7e354639ed6/%E5%9B%BE%E7%89%879.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;活动现场，&lt;strong&gt;数码港大湾区及内地事务总监苏婕女士&lt;/strong&gt;分享了数码港作为香港科创枢纽的生态布局。她提到，数码港以生态系统方式连接大学、加速器、政府与大企业，尤其在人工智能、区块链、低空经济等领域，提供算力支持、监管沟通、出海对接等全方位服务，助力初创企业拓展场景、走向全球。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f7341d5f-777c-462d-a3f6-95c206dbcbba/%E5%9B%BE%E7%89%878.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;亚洲人工智能初创大赛创办人、香港人工智能创新协会秘书长黄乐彤女士&lt;/strong&gt;随后介绍了大赛如何成为&amp;ldquo;未来独角兽的跳板&amp;rdquo;。她表示，大赛以&amp;ldquo;人工智能赋能全球未来&amp;rdquo;为宗旨，通过&amp;ldquo;一港币创投基金&amp;rdquo;、政策对接、资本链接、出海支持等组合拳，推动项目从技术走向市场。香港站已征集118个项目，全国累计征集近800个，展现出强劲的创新活力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;路演聚焦：16个项目展现AI赋能百业&lt;/strong&gt;&lt;br&gt;&lt;br&gt;在随后的路演环节中，16支团队依次登场，展现了AI技术在不同垂直领域的深度应用与商业探索：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bcaca7a8-6eb4-4978-b7a5-8e810a83ef72/%E5%9B%BE%E7%89%877.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;strong&gt;&amp;nbsp;数晨科技&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;提出&amp;ldquo;AI数字实体操作系统&amp;rdquo;，致力于打破数据孤岛，构建全域数字孪生基座，让数据回归价值主体。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1a720fd4-c875-4506-b6ab-fedd7cbdc0a9/%E5%9B%BE%E7%89%876.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;智法数科&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;香港首家专注于跨境法律及合规AI应用的科创企业，为全球企业、金融机构和律师事务所提供法律合规智能体产品服务及解决方案。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b2aba096-d6df-46ec-9a68-e13ed7528f33/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;问律AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聚焦智能合同审查，为企业提供高效、低成本的合规风控解决方案。&lt;img src="https://image.jiqizhixin.com/uploads/editor/9405ecf6-3653-4dee-b534-23543b7809cf/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;睿法智行&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推出&amp;ldquo;婚姻宝AI助手&amp;rdquo;，以温情技术赋能个人法律咨询，让专业服务触手可及。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b020ac5c-3ab2-41e2-abf6-9f3934b5659d/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;0x Limited&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;构建多模态医学大模型，临床决策能力媲美资深医师，已服务全球超70万健康咨询。&lt;img src="https://image.jiqizhixin.com/uploads/editor/911e122c-f49e-4784-9f0c-8441a30cf11b/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Meddcom AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首家入选香港大学数字健康实验室的AI4Health-To C团队，应用在疾病预测、个性化健康管理、合理用药等领域，并利用区块链技术解决医疗数据隐私问题，为用户和患者打造第一张&amp;ldquo;健康名片&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/aea530d4-6cce-4418-9cb6-0fc3d4038288/%E5%9B%BE%E7%89%871.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;JustAI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推出AI内容营销助手，帮助中小商家高效打造品牌内容，获取精准流量。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f1cc48a1-b7ae-4996-8cf3-9f821fc5de93/%E5%9B%BE%E7%89%8710.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;虚空博弈&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;尝试&amp;ldquo;量化直觉&amp;rdquo;，将博弈论与AI结合，提升决策质量，探索认知科学新边界。&lt;img src="https://image.jiqizhixin.com/uploads/editor/3d21fea3-658a-42b0-aa45-64813d7609d1/%E5%9B%BE%E7%89%879.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;章节零一&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;打造&amp;ldquo;可信可追溯的商业分析智能体&amp;rdquo;，助力企业基于真实数据做出精准决策。&lt;img src="https://image.jiqizhixin.com/uploads/editor/4fa728ec-a0b6-4f73-b16f-92cb4169ec19/%E5%9B%BE%E7%89%878.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Atrust（小A）&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;构建基于信任的私域电商AI合伙人，通过情感化交互实现高客单价转化。&lt;img src="https://image.jiqizhixin.com/uploads/editor/66148a2f-6e07-445f-ab0f-917d2e8258de/%E5%9B%BE%E7%89%877.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;推敲AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;专注室内设计智能平台，通过AI生图、改图与全流程辅助，提升设计效率与原创性。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5ab7da6e-c8cc-4bcb-9b5e-7c11be87fe16/%E5%9B%BE%E7%89%876.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AI SEMI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以AI赋能半导体制造，其&amp;ldquo;AI OPC&amp;rdquo;技术将光刻校正效率提升数十倍，成本降低超95%。&lt;img src="https://image.jiqizhixin.com/uploads/editor/ecc11d39-6b85-4c24-80f7-70c7e313cdb1/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Alpha AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;将自动驾驶无人机与AI视觉结合，实现楼宇、桥梁、斜坡的自动化巡检与损伤智能评估。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c1454471-def9-4268-b21f-74e63c3512e4/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;OneOneTalk&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;构建人类成长系统&amp;rdquo;，从个性化语伴到全场景认知升级OS，推动AI个性化教学。&lt;img src="https://image.jiqizhixin.com/uploads/editor/cbb8c5bb-adc6-4291-bc2a-57359da37e6c/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;DT Master&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聚焦可持续AI风险和合规，帮助企业高效应对出海中的ESG、数据，AI 与法律合规挑战。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bba3e325-0f6b-4e47-95c2-3728948b7b6b/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;派晨智能&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;展示AI漫剧智作平台，将动漫制作周期从数周缩短至数天，推动内容产业降本增效。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>WAIC CONNECT | 沪港联动激活产业新引擎，两地各界共筑AI+多元应用新生态</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 22 Jan 2026 16:25:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;2026年1月16日，世界人工智能大会（WAIC）旗下的精准产业对接平台&amp;mdash;&amp;mdash;WAIC CONNECT走进香港科学园，成功举办了&lt;strong&gt;&amp;ldquo;激活产业新引擎&amp;mdash;&amp;mdash;AI+文商体旅育创新对接会&amp;rdquo;&lt;/strong&gt;。本次活动作为WAIC 2026全球启动的重要序章，以&amp;ldquo;沪港联动&amp;middot;场景落地&amp;middot;生态共建&amp;middot;企业出海&amp;rdquo;为核心主题，汇聚了来自沪港两地政府、学术界、产业界及教育界的数十位领军人物，共同探索人工智能在文、商、体、旅、育等多元场景下的深度应用与商业闭环。&lt;img src="https://image.jiqizhixin.com/uploads/editor/328a4127-7d7f-4049-84e1-3fbf4f6022e5/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深化沪港合作，打造超级连接器&lt;/strong&gt;&lt;br&gt;&lt;br&gt;当前，人工智能产业正从技术爆发期迈向场景落地的深水区。&lt;strong&gt;东浩兰生会展集团副总裁张荣健先生&lt;/strong&gt;在致辞中指出，WAIC CONNECT致力于成为AI商业化的&amp;ldquo;超级连接器&amp;rdquo;，其核心使命在于解决技术创新与产业转型之间的供需错配。大会通过汇聚全球顶尖AI解决方案，并深入洞察&amp;ldquo;文商体旅育&amp;rdquo;核心场景的真实痛点，旨在打破地域界限，实现技术供给与市场需求的高效精准匹配，为产业升级注入强劲动力。与会嘉宾高度认同这一愿景，一致认为香港凭借其国际化营商环境与背靠祖国大市场的独特优势，无疑是AI企业出海与生态共建的最佳战略支点。沪港两地的紧密联动，必将产生协同效应，为区域乃至全球的AI产业发展带来新的增长极。&lt;img src="https://image.jiqizhixin.com/uploads/editor/da9636ff-1670-4be7-afa6-8e222e4441ab/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 张荣健 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;随后，&lt;strong&gt;香港生产力促进局机械人及人工智能部总经理冯国辉先生&lt;/strong&gt;致辞表示，作为最早系统推动AI研发的单位，生产力局正积极配合特区政府将香港打造为全球AI枢纽，通过自主研发的&amp;ldquo;天工开物&amp;rdquo;平台及&amp;ldquo;全民AI行动&amp;rdquo;，解决企业在人才、隐私及整合上的挑战。目前，该局已完成及正在推行超过100个AI项目，并推出多项培训课程，旨在通过培训赋能与技术支持，协助企业利用香港优势成功出海。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5b5d983c-9905-43fa-b9c1-ea8b9aea9c4b/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 冯国辉 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重磅项目启动，聚焦前沿实践&lt;/strong&gt;&lt;br&gt;&lt;br&gt;活动现场举行了多项重磅发布仪式。在东浩兰生会展集团、香港生产力促进局、香港人工智能和机器人学会及浙港澳数字教育学校联盟代表的共同见证下，&lt;strong&gt;&amp;ldquo;WAIC CONNECT香港工作站-校园AI应用项目招募计划&amp;rdquo;&lt;/strong&gt;正式启动。此举标志着大会在推动AI教育普及和发掘青年创新人才方面迈出了关键一步，并将有效促进沪港两地AI教育资源的深度融合与协同发展，为香港校园注入前沿科技活力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a327eec5-2ed7-4add-b6c5-14d3cdd3fc04/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;随后，知名导演丁子峻、中华基督教会基慈小学赵洁华校长、中华基督教会长洲堂锦江小学叶昌锐校长、WAIC CONNECT及WAIC CONNECT香港工作站代表等共同发布了&lt;strong&gt;&amp;ldquo;AI电影进校园&amp;rdquo;&lt;/strong&gt;项目成果。该项目以公益影展形式走进校园，聚焦&amp;ldquo;从经典到现代&amp;rdquo;的动画发展脉络，让传统文化在数字时代焕发新活力。通过导演的亲身分享，项目引导学生直观感受科技与艺术的碰撞，培养兼具文化底蕴与科技思维的创新意识。此次活动由上海美术电影制片厂、WAIC CONNECT香港工作站、上海香港联会共同支持，展示了科技赋能人文教育的无限可能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多维场景解构，共探商业新机&lt;/strong&gt;&lt;br&gt;&lt;br&gt;在主旨演讲环节，四位嘉宾从不同维度剖析了AI的赋能路径。&lt;/p&gt;&lt;p&gt;香港人工智能和机器人学会常务理事、香港城市大学计算学院林静博士解读了香港的出海战略，指出&lt;strong&gt;香港正从资本金融中心转变为全产业链的出海赋能平台&lt;/strong&gt;，利用其国际化优势，为企业提供合规保护与标准对接，并联合生态伙伴补齐企业走向国际市场的&amp;ldquo;最后一公里&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/ff6e9f3f-53a2-4844-8bd3-3193163ea835/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 林静 博士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;上海市城市更新研究会副秘书长、金砖财经CEO尤优提出了&lt;strong&gt;&amp;ldquo;场景营城&amp;rdquo;&lt;/strong&gt;理念，强调城市更新是国家重大转型战略。他介绍了上海在城市更新中的巨大投入与立法保障，并通过绿地外滩中心等案例，阐述了如何通过资本、资产与IP的共创，将城市更新打造为AI企业的超级场景平台。&amp;nbsp;&lt;img src="https://image.jiqizhixin.com/uploads/editor/912a278a-12d9-4c6c-b05c-e1fc03664ad8/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 尤优 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;随后，绿地控股集团上海房地产事业部市场营销部副总经理王楠女士以&amp;ldquo;绿地外滩中心&amp;rdquo;为例，展示了&lt;strong&gt;上海未来的超级应用场景&lt;/strong&gt;。她介绍该项目作为上海最大的城市更新地标，汇聚了金融与科创巨头，正通过绿地国际会议中心等多元载体，积极寻求与AI企业在产品发布、资源链接及数字化生态等方面的深度合作。&amp;nbsp;&lt;img src="https://image.jiqizhixin.com/uploads/editor/82fa6364-03fc-40ae-b622-cfa2d051c382/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 王楠 女士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;浙港澳数字教育学校联盟、香港教育评议会主席蔡世鸿先生分享了&lt;strong&gt;&amp;ldquo;智教融合&amp;rdquo;&lt;/strong&gt;的思考。他提出要培养&amp;ldquo;AI时代的一代宗师&amp;rdquo;，借鉴《一代宗师》中&amp;ldquo;见自己、见天地、见众生&amp;rdquo;的三个境界，阐述了利用AI辅助适应生活、在社会中生存乃至引领发展的教育目标，并强调需重点培养学生提问、解决问题及创新等六大能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/50f0b68d-9ae1-4f9b-8bff-3aff6e9095ea/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 蔡世鸿 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;四位嘉宾的分享涵盖了政策解读、空间重塑、商业地标及教育实践等多个维度，为现场企业拥抱AI时代提供了全方位的战略指引。&lt;br&gt;&lt;br&gt;&lt;strong&gt;跨界圆桌对话，激荡思想火花&lt;/strong&gt;&lt;br&gt;&lt;br&gt;当导演遇到AI，当足球遇上大数据，当社区治理迈向智慧化，当传统制造迈向数智化，会产生怎样奇妙的化学反应？两场高水平的圆桌论坛将活动推向高潮。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;&amp;ldquo;AI科技赋能到生态共建&amp;rdquo;&lt;/strong&gt;圆桌讨论中，知名导演丁子峻、前女足国门赵丽娜、全球女性成长基金会、香港区潮人联会副会长蔡晓莹、杭州灵核数智CEO陈弘旋等嘉宾，立足影视、体育、社区、制造等不同赛道，围绕&amp;ldquo;赋能&amp;rdquo;与&amp;ldquo;生态&amp;rdquo;两大关键词，共同探讨了AI如何渗透到各行各业的毛细血管，以及不同领域如何打破壁垒、实现协同共生。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f50640a1-e5f2-4ab1-8855-a261c53e2aa6/%E5%9B%BE%E7%89%872.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;知名导演丁子峻率先从文娱行业的视角切入，他并不认为AI是对演艺行业的冲击。回顾自己1998年在香港投身互联网行业的经历，他指出互联网思维与当下的AI技术有着相通的文化内核。丁子峻导演强调，从皮影戏到传统动漫，再到如今的数字电影，技术工具在变，但文化的审美与传承这一&amp;ldquo;基本功&amp;rdquo;从未改变。作为电影人，AI并非洪水猛兽，不懂它才是冲击，懂了它便是赋能。他目前正致力于通过大数据模型与影视创作的结合，探索一种&amp;ldquo;文化转世&amp;rdquo;的可能&amp;mdash;&amp;mdash;&lt;strong&gt;让IP与故事在不同的技术形态中获得&amp;ldquo;Next Life&amp;rdquo;，因为未来的方向掌握在人类的认知与手中，AI只会让电影变得更好。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c633627f-7d65-4b59-900e-a7bc7b1b83ce/%E5%9B%BE%E7%89%873.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;丁子峻 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;前女足国门赵丽娜则从专业运动员的视角出发，提出了体育领域对&amp;ldquo;落地性、个性化、普适性&amp;rdquo;的迫切需求。她强调，&lt;strong&gt;AI不仅需要辅助职业球员进行精准备战与损伤康复，更应通过轻量化、零门槛的工具，成为乡村校园足球的&amp;ldquo;公益教练&amp;rdquo;，&lt;/strong&gt;让资源匮乏地区的孩子也能通过手机摄像头获得科学的动作纠错，跨越数字鸿沟，实现科技向善。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1c414908-ecf8-406e-80da-af23ce5f2f6d/%E5%9B%BE%E7%89%874.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;赵丽娜 女士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;香港区潮人联会副会长蔡晓莹女士深情讲述了科技背后的温度。她分享了社区儿童智能守护平台成功找回走失儿童的案例，以及帮助基层妇女通过技能培训实现灵活就业的故事。她认为，&lt;strong&gt;AI进入社区必须&amp;ldquo;克制&amp;rdquo;且&amp;ldquo;贴心&amp;rdquo;，在尊重隐私的前提下，解决双职工家庭看护难、信息甄别难等真实痛点。&lt;/strong&gt;她强调，科技应隐于幕后，让温度留在台前，真正走进社区的烟火气中。&lt;img src="https://image.jiqizhixin.com/uploads/editor/76e885e5-75eb-40d8-aeea-46e54d7de965/%E5%9B%BE%E7%89%875.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;蔡晓莹 女士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;灵核数智创始人陈弘旋则结合制造业实践指出：AI已从单点技术升级为推动企业系统性变革的核心引擎，其关键在于通过&amp;ldquo;沉淀技能、学习内化、重塑流程、复制扩张&amp;rdquo;将AI转化为能沉淀企业技能、持续进化、可复制、可升级的AI数智员工。灵核数智聚焦业务前端，让&lt;strong&gt;&amp;ldquo;AI数智员工先干活&amp;rdquo;&lt;/strong&gt;，在真实业务中自动捕捉并结构化沉淀企业高价值隐性知识，构建持续进化的数字化知识体系，并通过7&amp;times;24小时学习整合内外部高价值经验，推动人机协同决策。随着AI数智员工深度参与需求洞察、研发设计、生产制造与交付服务，企业业务全链条得以重塑，产品迭代更快、质量更稳、试错成本更低。同时，AI数智员工还能承载并快速复制成熟经验，支撑企业多工厂乃至全球化扩张，实现高效稳定落地。面向未来制造业，真正的挑战已从&amp;ldquo;能生产&amp;rdquo;转向&amp;ldquo;造好产品&amp;rdquo;，而持续的技术创新与高效的创意转化能力，将成为企业赢得市场的关键。&lt;img src="https://image.jiqizhixin.com/uploads/editor/69e182db-7b7c-438d-8928-0ef66d11b460/%E5%9B%BE%E7%89%876.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;陈弘旋 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;嘉宾们的精彩对话揭示了生态共建的核心逻辑：无论是在艺术的创作、激烈的赛场，还是温暖的社区与严苛的产线，AI只有成为真实场景中可信赖的伙伴，才能激发出最大的社会价值。&lt;/p&gt;&lt;p&gt;而在&lt;strong&gt;&amp;ldquo;AI科技赋能到教学共建&amp;rdquo;&lt;/strong&gt;圆桌对话中，郑家宝、郭文钊、尹淑芬、梁文祺、吕浩荣、朱嘉添六位来自香港知名中小学的校长，在主持人吕斯恬先生的引导下，围绕AI科技如何赋能教学共建展开了深度探讨。&lt;img src="https://image.jiqizhixin.com/uploads/editor/293964fb-ece3-4bb7-835e-81a4a84ed06f/%E5%9B%BE%E7%89%877.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4367db5d-8b78-4b04-a580-cb6cb00a4de2/%E5%9B%BE%E7%89%878.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 吕斯恬 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;嘉宾们一致认为，AI不仅是提升效率的工具，更是推动教育模式变革的核心动力。在实践层面，校长们分享了各自学校的丰硕成果：从&amp;ldquo;AI电影进校园&amp;rdquo;的跨学科尝试，到利用AI实现&amp;ldquo;因材施教&amp;rdquo;与&amp;ldquo;个性化学习路径&amp;rdquo;的探索，再到建立&amp;ldquo;个人成长档案&amp;rdquo;以全面追踪学生成长历程，学校正逐步实现从&amp;ldquo;千篇一律&amp;rdquo;到&amp;ldquo;量身定制&amp;rdquo;的转变。展望未来，校长们呼吁&lt;strong&gt;教育界与业界紧密合作，研发本地化AI模型，并着重提升教师的AI素养与伦理意识，&lt;/strong&gt;让技术真正服务于&amp;ldquo;立德树人&amp;rdquo;的教育本质，培养兼具科技思维与人文关怀的未来人才。&lt;br&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5f07d713-e6d1-429e-9ce8-2b977ec76119/%E5%9B%BE%E7%89%879.png" style="width: 70%;" class="fr-fic fr-dib"&gt;本次WAIC CONNECT香港站的成功举办，不仅为沪港两地产业界搭建了高效的对接桥梁，更为AI技术的场景落地描绘了清晰蓝图。从文娱体商的跨界融合，到智慧教育的深耕细作，我们看到了&amp;ldquo;生态共建&amp;rdquo;的无限可能。未来，WAIC将继续致力于推动AI技术与生活场景的深度融合，让科技真正服务于人，温暖社会。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>剑桥与北航等设计可穿戴设备+LLM，融合肌肉振动、脉搏与大模型推理的无声语音系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Thu, 22 Jan 2026 14:09:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;智能可穿戴设备的研发与设计，往往会伴随着人文关怀的色彩。这些功能各异的系统在各自的领域往往能强有力的技术支持，而 AI 的搭载能协助捕捉更细节的生物信号，完成更精细的操作。&lt;/p&gt;&lt;p&gt;来自英国剑桥大学与北京航天大学等多所高校的实验团队介绍了一套由人工智能驱动的智能喉咙（IT）系统，将喉部肌肉震动与动脉脉冲信号与&amp;nbsp;LLM&amp;nbsp;相结合，实现流畅且情感表达的交流。该系统在与无名中风患者的测试中，实现了 4.2%的单词错误率，2.9%的句子错误率。&lt;/p&gt;&lt;p&gt;相关研究内容以「Wearable intelligent throat enables natural speech in stroke patients with dysarthria」为题，于 2026 年 1 月 19 日刊登于《Nature Communications》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNibWRoLj1XD44K6r5tv7RpjagKsLN4Df6c6c25xhatcNYU6ThM7ToaFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3410041841004184" data-type="png" data-w="956" data-width="956" data-height="326" data-backw="546" data-backh="186" data-imgfileid="100027217" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/5ea75b82-4f80-4be5-a9df-ac913819d664/640.png" alt="图片" data-before-load-time="1769062126816" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41467-025-68228-9&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解读身体正在说什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对中风、ALS 或帕金森患者而言，语言并不是&amp;ldquo;消失了&amp;rdquo;，而是被困在身体里。他们仍然能组织语义、仍然有情绪、仍然知道自己想说什么，但声音无法稳定、连续地被表达出来。&lt;/p&gt;&lt;p&gt;过去几十年，辅助交流技术（AAC）始终在尝试弥合这道鸿沟，但实际上真正缺失的是一种既贴近身体、又理解语言本身的系统。上述团队所提出的 IT 系统就弥补了这其中的缺陷。&lt;/p&gt;&lt;p&gt;该系统能够捕捉喉部肌肉的外部振动和颈动脉脉搏信号，实时整合无声语音和情绪状态分析。此外，其还能生成个性化、符合语境的句子，准确反映患者的意图。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNLJtSiap8IjxhFJorUTdUxRWI6PtlNftQMNGIcfQFsXTSAoVWtQXVjiaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.37518248175182484" data-type="png" data-w="685" data-width="685" data-height="257" data-backw="546" data-backh="205" data-imgfileid="100027215" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4780a33f-b99c-461c-8cca-702607739ade/640.png" alt="图片" data-before-load-time="1769062128473" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：为中风构音障碍患者开发的 IT 示意图。&lt;/p&gt;&lt;p&gt;这个系统所搭配的柔性智能颈环核心是&lt;strong&gt;印刷在弹性织物上的石墨烯应变传感器&lt;/strong&gt;，可检测低至&amp;nbsp;&lt;strong&gt;0.1% 的微小应变&lt;/strong&gt;，频率范围覆盖无声发音相关的快速肌肉活动。通过各向异性结构与隔离层，这个颈环对细微应变的响应超过了&amp;nbsp;&lt;strong&gt;10%&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNJrPJBTCpgWHibcLzFw7RcOYJbOA7YaDf06QJRty2ib7yENMuQwuz9U1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8992700729927007" data-type="png" data-w="685" data-width="685" data-height="616" data-backw="546" data-backh="491" data-imgfileid="100027216" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c1f6f13a-e472-4311-9eb4-1a3b43c137c7/640.png" alt="图片" data-before-load-time="1769062128921" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：IT 的硬件与数据收集。&lt;/p&gt;&lt;p&gt;此外，IT 系统选择了一条更接近真实语言的路线，它能以约&amp;nbsp;&lt;strong&gt;100 ms&lt;/strong&gt; 为时间尺度进行 token 预测，不再强制分词或分句。用户可以连续&amp;ldquo;默念&amp;rdquo;，系统持续输出语言流的同时，还能通过&lt;strong&gt;知识蒸馏&lt;/strong&gt;将模型计算延迟降低&amp;nbsp;&lt;strong&gt;76%&lt;/strong&gt;，保证整条链路足够快，避免&amp;ldquo;人已经想完一句话，系统还在反应上一句&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解码与 LLM 代理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除此之外，团队还将&amp;nbsp;DFT 频率提取纳入解码流程之中，这种方法使端到端神经网络能够自动提取最相关特征，以进行无需手动特征工程的情感分类。结果显示 DFT 在解码准确性方面有显著提升。最优模型是带有 DFT 的 1D 卷积神经网络，准确率达到 83.2%。&lt;/p&gt;&lt;p&gt;在临床观察中，团队观察到即使是无声默念短语，也会导致肌肉疲劳等现象，让发声出现偏差。为了减少相应的体力损失与保留预期信息，团队引入了智能扩展选项，允许患者表达简洁的符号，这些符号会自动丰富为完整且符合上下文的句子。&lt;/p&gt;&lt;p&gt;而为了确保句子自然且连贯，他们引入了两个基于GPT-4o-mini AP I的 LLM 代理：符号合成代理（TSA）和句子扩展代理（SEA）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNhKXmEt4AZUQkKqVnFRugdibQKy0icpic6KBrkhiaHiadZ3QSv1Ugn62sQfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0277372262773723" data-type="png" data-w="685" data-width="685" data-height="704" data-backw="546" data-backh="561" data-imgfileid="100027218" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/06dfab39-2fcb-49c1-8c3a-3ef6a6145b71/640.png" alt="图片" data-before-load-time="1769062129071" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：LLM 代理框架与性能评估。&lt;/p&gt;&lt;p&gt;TSA 将 token 标签直接合并为患者无声表达的词语，并将它们组合成句子；而 SEA 则利用情绪标签和客观信息，将这些基本句子扩展为连贯、个性化的表达。这两个代理生成的句子都会被发送到开源的文本转语音模型，并以匹配后的语音进行播放。在实际应用中，用户完成无声表达与句子播放之间的延迟大约为 1 秒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能发声&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;全面的分析和用户反馈肯定了 IT 在流畅度、准确性、情感表达和个性化方面的高绩效。该系统的成功来自于其能够捕捉高质量信号的超灵敏纺织应变传感器，高分辨率的标记化分割技术使用户能够无表达延迟地进行连续沟通。&lt;/p&gt;&lt;p&gt;该系统采用的 LLM 代理的集成实现了智能纠错和上下文适应，实现了卓越的解码准确率，用户满意度提升了55%。&lt;/p&gt;&lt;p&gt;这只是个开始。团队还在积极扩大研究队列，纳入更多构音障碍患者，并计划扩大语言数据库，实现更高的覆盖率。硬件与软件的升级也同样在他们的准备之中。团队表示，他们希望自己的成果能协助有关病患改善他们的生活质量。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>拒绝成为落后的开发者：用TRAE Skills构建你的10倍效能工具箱</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 12:57:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;p&gt;现在的 AI 编程领域，什么概念最热？毫无疑问是 Skill。&lt;/p&gt;&lt;p&gt;在 X 上，一些分享 Skill 的帖子轻轻松松就能获得数十万的浏览量。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529549" data-ratio="1.2828125" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKrfq4BjXFibxkFcpUnt7kINuhKhb216Ud40iblmWUqXTHer07O7n4qZicw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/908b0309-1b4b-4455-9248-a39480d74025/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图源：X 用户 @omarsar0、@vista8、@bozhou_ai、@yanhua1010 等&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;原因很简单，Skill 的出现标志着 AI 协作正式进入了「&lt;strong&gt;经验资产化&lt;/strong&gt;」的新阶段。在 2026 年的今天，我们正处于泛化工作场景的生产力拐点。Skill 不再仅仅是程序员的提效工具，它正在成为一种通用的专业能力协议。过去那些高度依赖个人经验、难以量化的&lt;strong&gt;&amp;nbsp;SOP（标准作业程序）&lt;/strong&gt;，现在可以通过一个 SKILL.md 文件实现标准化的封装与跨场景的移植。&lt;/p&gt;&lt;p&gt;这意味着，无论是个人的知识管理逻辑，还是复杂的行业调研流程，都可以像安装插件一样迅速注入给 AI。这种转变将 AI 从一个通用的「对话者」变成了拥有特定领域直觉的「专业执行者」，从而彻底打破了专家经验的传播壁垒。当个人的数字化直觉能够被大规模复刻与分发，全行业的生产力爆发便有了可落地的基石。&lt;/p&gt;&lt;p&gt;与此同时，Skill 本身以及使用它们的方式也在同步进化。比如前些天，Vercel 创始人 Guillermo Rauch 推出了所谓的「AI skill 的 npm」，让用户仅需一个简单命令 npx skills add [package]，就能为自己的 AI 智能体轻松注入专业能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKrdadKC2I6CXjb1DYwkOjQ1Iic9PwjspQgqicMkDgZtUuUHn9OjPibMcKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.0882723833543506" data-s="300,640" data-type="png" data-w="793" type="block" data-imgfileid="503529547" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7ce5b61d-1914-4b0c-9bdb-2b608b0bba73/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;看得出来，趋势很明显：Skill 正在成为 AI 编程甚至日常工作流程的标配。&lt;/p&gt;&lt;p&gt;AI 大牛 Andrej Karpathy 在近期的一则超 1600 万浏览的推文中也指出，现在出现了一个全新的「&lt;strong&gt;可编程抽象层&lt;/strong&gt;」需要去掌握。这个层级不仅包含传统的代码逻辑，更涉及智能体、子智能体、提示词、上下文、内存、权限、工具以及重要的&amp;nbsp;&lt;strong&gt;Skill&lt;/strong&gt;。他认为，如果程序员无法通过整合这些在过去一年里涌现的工具来实现 10 倍效能的提升，那本质上就是一种「技能问题（skill issue）」。在他看来，一种强大的「外星工具」已经交到了人类手中，但它没有附带说明书，所有人都在这场 9 级地震中摸索着如何操控它。他还感叹道：「作为一个程序员，我从未感到如此落后。这个职业正经历着剧烈的重构，程序员直接贡献的代码比例正变得越来越稀疏。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKRZPoNLDicZvygk3MVWpmQrfcwyUawogJpsicVmmymZS0ibWtGztGRicbnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.3044585987261146" data-s="300,640" data-type="png" data-w="785" type="block" data-imgfileid="503529548" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a682d446-8c66-4266-9576-f9bb287185bc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些趋势和感叹的背后，反映了 AI 工具从「助理」向「数字员工」的本质转变。开发者们关注的重点已经从零散的提示词编写转向了构建可复用的智能体工作流。&lt;/p&gt;&lt;p&gt;在这个背景下，字节跳动旗下的 AI 工程师产品 TRAE 迅速进化，正式上线了其 Skill 功能。&lt;/p&gt;&lt;p&gt;它深度兼容了这种「技能封装」的范式，允许用户通过一个简单的 SKILL.md 文件，将复杂的指令、脚本和资源封装成可复用的专业技能包。而且它更加易用，&lt;strong&gt;0 代码基础也可轻松上手&lt;/strong&gt;。我们可以这样类比，如果说 Vercel 的 Skills 软件包定义了 AI 技能的分发标准，完成了「npm 时刻」的跨越，那么 TRAE 对 Skill 的深度集成就是 &lt;strong&gt;AI 编程的「OS（操作系统）原生集成」时刻&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这意味着，当 Karpathy 还在呼吁开发者们撸起袖子去迎接重构时，TRAE 已经为开发者提供了一个现成的技能脚手架，帮助大家从繁琐的代码搬运中解脱出来，转而去构建那个更具想象力的「抽象层」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;究竟什么是 Skill？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单来说，Skill 可以被理解为一个「&lt;strong&gt;专业技能包&lt;/strong&gt;」。它的物理形态是一个名为 SKILL.md 的 Markdown 文件，通常存放在项目根目录下的 ./trae/skills 路径中。这个文件就像是一份给 AI 智能体的「按需读取手册」，里面记录了完成特定领域任务所需的详细指令、自动化脚本以及模板资源。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKWPrwiaz06bIEF1xeok32Q0m5RpK9uv421MHD1zaYKkf8upS0Cy1rwvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0343601895734598" data-s="300,640" data-type="png" data-w="844" type="block" data-imgfileid="503529550" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1411544f-7654-4ee6-ab37-c7471ac7b2f6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 我们在 TRAE 中为某个项目配置的一些 Skill&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;可以看到，一个 Skill 的典型结构是这样的，其中仅有 SKILL.md 文件是必需的，其它都是可选的，具体会根据你的 Skill 需要来决定：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK041B2cZDw38sLhsQTIa5Jvn9a6DAj9JhvXNM4yt3l6TiacAavaF7p1g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.49676584734799484" data-s="300,640" data-type="png" data-w="773" type="block" data-imgfileid="503529551" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b5bed77f-5deb-4ee2-9663-846b8d41bd90/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;下图展示了来自 Anthropic 官方的 frontend-design（前端设计）Skill，这就是一个仅有单个 SKILL.md 文件（这里没考虑许可证）的 Skill：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKFxNmHdtAB9JctibhAo8PTYy5w5V9omMveG6mVy3P43DWlhq6Ojia8Ojg/640?wx_fmt=png#imgIndex=6" alt="长图滚动查看" data-ratio="2.137962962962963" data-w="1080" data-aistatus="1" data-original-style="width: 1048.45px;height: auto;display: block;border-radius: 4px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/40f48b2d-5a07-4eb0-8e60-e8bdbb66d5ec/640.png" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可以看到，一个 SKILL.md 文件通常由元数据（名称、描述、证书）和具体提示词构成。&lt;/p&gt;&lt;p&gt;也就是说，Skill 本质上也还是提示词，那么我们为什么不直接使用提示词，而要使用 Skill？&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术逻辑：从「全量加载」到「按需调用」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Skill 的出现解决了当前 AI 编程中的一个核心痛点：&lt;strong&gt;Token 消耗与任务专注度的平衡&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;传统的 Rules 文件通常采用全量加载模式。只要用户开启对话，Rules 中的所有指令都会持续占用上下文窗口。随着指令集的增加，这会导致宝贵的 Token 被大量浪费，甚至干扰智能体对当前任务的判断。&lt;/p&gt;&lt;p&gt;Skill 则引入了&lt;strong&gt;动态调用机制&lt;/strong&gt;。智能体只有在识别到当前任务与 Skill 的触发条件匹配时，才会主动加载相关的指令包。这种「即插即用」的设计既节省了 Token 消耗，也确保了智能体在执行具体任务时能够保持极高的专注度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;差异化定位：Skill vs. 其他功能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了更精准地使用 Skill，我们需要明确它在 TRAE 协作体系中的定位：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;与普通提示词（prompt）的区别：提示词通常是单次使用的。当你发现自己在对话中反复输入同一段指令时，这就意味着效率的损耗。Skill 将这种重复性的 Prompt 提取出来，转变为 SKILL.md 中的标准指令。它让原本飘忽不定的对话逻辑变成了可以被智能体反复调用的专业技能包。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;与 Rules 的区别：Rules 适合存放全局偏好，例如代码规范、语言习惯或排版设置。Skill 则用于封装具体的工作流，当同一个提示词被输入超过三次时，它就应该被沉淀为一个 Skill。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;与 Context 的区别：Context 属于被动读取的知识库，智能体无法自主决定何时调用，且会持续占用上下文空间。Skill 是结构化的主动指令，能够根据意图识别自动触发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;与 Sub agent 的区别：Sub agent 定义的是具体的专家角色，而 Skill 是这些专家可以共享的技能组件。一个成熟的 Skill 具有极强的可移植性，可以在不同的智能体之间自由组合与复用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;很显然，&lt;strong&gt;Skill 正将分散的、碎片化的提示词经验转化为标准化的「数字资产」&lt;/strong&gt;。通过这种模块化的封装，开发者不仅可以沉淀个人的工作 SOP，还能在社区中快速获取并复用顶尖专家的专业能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测 TRAE Skills：10 倍效能真的来了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Andrej Karpathy 提到的「10 倍效能革命」究竟如何落地？在掌握了 Skill 的技术原理之后，我们需要将其带入真实的开发场景中进行验证。&lt;/p&gt;&lt;p&gt;目前，最新版本的 TRAE 已实现了对 Skill 的全量支持。接下来，让我们将深入多个实际场景，看看 Skill 可以如何通过结构化的 SOP，帮助开发者和普通用户实现能力破局。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;秒级上手，让 TRAE 成为你的 AI 技能装配工厂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要使用 Skill，首先当然是配置 Skill。现在这种「技能包」模式正在全网范围内爆火，无论是 GitHub 上的开源仓库还是开发者社区的讨论，大家都在尝试通过 Skill 沉淀专业经验。也因此，我们能在网上找到大量可用资源，比如 Anthropic 的官方 Skill 库 anthropics/skills 或者是各类 Awesome 库。与此同时，目前，凭借极&lt;strong&gt;强的生态兼容性、自然语言驱动的极简门槛、高度结构化的能力封装&lt;/strong&gt;等核心优势，TRAE 也正在全网走红。&lt;/p&gt;&lt;p&gt;具体来说，要在 TRAE 中使用一个 Skill，只需将其文件夹放到项目文件夹的 .trae/skills 目录下即可。&lt;/p&gt;&lt;p&gt;是的，就这么简单！&lt;/p&gt;&lt;p&gt;更妙的是，TRAE 对自然语言的支持让创建 Skill 变得极其简单，即便是 0 代码基础也能快速上手。你只需对 TRAE 描述你的需求，它就能自动为你编写一个 Skill。比如下面展示了我们让 TRAE「写一个用于编写 Chrome 插件的 Skill」的全过程：&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6e1d61b2-7143-4ea9-9da9-41e49afbf478/1769057640900.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;可以看到，TRAE 会自动调用一个默认配置的 Skill「skill-creator」来完成该任务。速度也非常快，这里仅用时 50 秒。下面来看看这个被自动命名为 chrome-extension-developer 的 Skill 质量如何：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK7ZibdQ5sNWM1xk6RadIsQ1IicILkXS2bQF13yrfEUYof51PgCHpx58dA/640?wx_fmt=png#imgIndex=7" alt="长图滚动查看" data-ratio="2.2326454033771106" data-w="1066" data-aistatus="1" data-original-style="width: 1048.45px;height: auto;display: block;border-radius: 4px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/22dce335-7a2b-4371-92e6-8943fcfe9fec/640.png" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;看得出来，这个由 TRAE 生成的 Skill 展现了极高的工程化水准。它没有停留在宽泛的概念描述层面，而是相当精准地捕捉到了 Chrome 插件开发从 Manifest V2 转向 V3 过程中的核心痛点。具体而言，它将复杂的 Manifest V3 开发 SOP 拆解为可执行、可验证的指令集。有了这个技能包，即便是插件开发的新手，也能在 TRAE 的辅助下写出符合谷歌官方最新标准的工业级代码。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实战见真章，Skill 能让 AI 真正拥有专家执行力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;有了 Skill，当然要用起来。在 TRAE 中，调用 Skill 的方法也非常简单。正如我们前面创建 chrome-extension-developer Skill 时一样，TRAE 会根据当前的任务需求自动选择调用合适的 Skill，当然开发者也可以在提示词中显式指示 TRAE 使用哪些 Skill。&lt;/p&gt;&lt;p&gt;下面我们就先使用 TRAE 构建的这个 Skill 来编写一个非常实用的 Chrome 插件：&lt;/p&gt;&lt;p&gt;编写一个 Chrome 插件，它能将当前网页导出为 Markdown 文件，将网站链接等数据保存在元数据区域。&lt;/p&gt;&lt;p&gt;接入了 GPT-5-medium 的 TRAE 很快完成了任务，耗时仅仅 2 分钟。&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/50ebcbd0-b591-4641-a428-f803865701aa/1769057664925.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;展开其思考过程，可以看到即使我们这里并没有明确说明是否使用 Skill，TRAE 依然根据任务需求选择了刚刚创建的 Skill，从而确保了输出代码的质量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLtRk5ozIibTtdo5l5LwfiaP07QAXiaQ39v3wOiaPp3FF9HDic0waWRspWIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5867768595041323" data-s="300,640" data-type="png" data-w="726" type="block" data-imgfileid="503529552" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/e162b11a-f957-4c1f-bb5d-fb8e7f915ade/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;至于结果，可以说是相当令人满意：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKdIBrZQq76Lp7GN3xPfhWOWjPR5dFZJl586JfD1pHP7jZP1T4ziaWKfQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.5393883225208527" data-type="gif" data-w="1079" type="block" data-imgfileid="503529558" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/69a58863-fdee-4007-ac50-7e34e5fb6574/640.gif" data-order="1" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当然，我们也可以直接下载网络上开源的 Skill，将已有的成功经验化为己用。&lt;/p&gt;&lt;p&gt;比如这里，我们就将 Anthropic 官方在 skills 库中发布的所有 Skill 都集成到了当前的项目中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKBkqxUgFZ7udTsFfETeQlEibe2WickdQffV9DU0SkBZVRt3sj7kr5IibEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="2.003731343283582" data-s="300,640" data-type="png" data-w="268" type="block" data-imgfileid="503529555" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/835e3480-5cc4-4d87-8494-bd88d09ff9bb/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;我们注意到其中有一些用于文档处理的 Skill。值此 DeepSeek-R1 模型诞生一周年之际，我们就用其技术报告做做实验。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;下载并解读这个 PDF 文档：https://arxiv.org/pdf/2501.12948 ，将内容整理成一份内容详实有深度、图表丰富且悦目的 PPT。你可以使用 pdf skill 提取里面的图表来使用，并使用 pptx 来生成 PPT。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/36988588-bb48-47ef-9abd-3442bbb84170/1769057693039.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;执行过程中，我们看到其接连调用了 pdf 和 pptx 两个 Skill，至于最后得到的结果，虽然和我们提示词中提到的「悦目」尚有差距，但这反映了当前 AI 绘图与排版技能的一个通用逻辑。Skill 目前更侧重于逻辑结构的自动化与功能实现，而对于极具主观性的「审美偏好」，仍需要用户通过更细致的视觉设计 Skill 或手动微调来完成最后的磨皮。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKhaibAVUUbZUIKpcTWSXZTFPibhzy0XG3AGlwe5tfyeCWjNYD7utrHiawA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.75" data-type="gif" data-w="1080" type="block" data-imgfileid="503529557" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/738c08ad-f82e-4699-97ab-7409269668fc/640.gif" data-order="2" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;SKill 的玩法还不止于此，如果你觉得在 GitHub 寻找你想要的 Skill 也过于麻烦，没有关系，你完全可以创建一个 Skill，让 TRAE 为你寻找并下载合适的 Skill。&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/101626f8-9056-4cab-88b1-507df994ad53/1769057713424.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;可以看到，TRAE 调用 skill-creator 创建了一个名为 skill-finder 的 Skill。根据描述，这个 Skill 会执行 5 步任务：分析需求&amp;rarr;搜索 GitHub&amp;rarr;验证&amp;rarr;下载安装&amp;rarr;确认。看起来符合我们的需求。下面就来试试看，直接上一个比较复杂的任务：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;编写一个展示洛阳从古至今历史的动态网页，里面要有一个时间轴，让用户可以滑动选取时间，根据所选时间，下面的介绍部分也会随之变化，加入一些文物或遗址的照片增强说明。使用莫兰迪色系。开始任务前先使用 skill-finder 配置相关 Skill。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这一次 TRAE 执行了 5 分钟，期间它成功使用了 skill-finder，找到并下载了 web-design-guideline 和 vercel-deploy 两个 Skill。之后，TRAE 完成了内容的检索，并在 web-design-guidelines 的指导下，完成了网页的构建。但最终结果却并不很好，尤其是图片 &amp;mdash;&amp;mdash; 要么货不对板，要么就根本无图。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK1CHgv2qicGQ6nImy8eIZS5Z9mbZibDqAvVl5iaPO1XnSJmNibUVhYN0j2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529556" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/92127218-530b-4aaa-8f1c-153af27ba753/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;但没有关系，我们还可以继续与 TRAE 互动，细化需求，让其进行改进：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;生成的结果网页中的图片有问题，而且每段历史的描述内容过于浅显。请修复问题，寻找切实可用的图片（最好下载到本地），并丰富内容描述，比如哪些时段诞生了哪些名人等。首先，使用 skill-finder 寻找能帮你完成这个任务的 skill，比如用于深度研究或图片下载的 Skill。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这一次，又执行了 5 分钟，所得到的结果已经勉强可用了。这里我们可以感受到，TRAE 开始展现出某种「自我驱动」的特质。虽然第一版结果存在数据源抓取的偏差，但这种「发现问题、寻找技能、自我修复」的闭环，才是 10 倍效能提升的真髓所在：它将开发者的工作重心从「修 Bug」转移到了「定义工作流」的高度。&lt;/p&gt;&lt;p&gt;当然我们也还可以继续让 TRAE 进行调整，比如更加细化历史分段、保证每一段的文本描述不低于 3000 字等等，但我们这里的体验展示就到此为止了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKPicKn23jwX22P20NVemBpTAiccrQVBqlhZfGicZ1ibRWibUZGTpoGMOfEhw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.5244755244755245" data-type="gif" data-w="1001" type="block" data-imgfileid="503529559" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/4905e4d6-8ecc-4179-88e8-206ec2f41549/640.gif" data-order="3" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;整体体验下来，我们感觉 TRAE 对 Skill 的集成虽还不能说完美，比如如果使用视频下载 Skill，还需要一些手动验证，但也展现了极高的成熟度。&lt;strong&gt;即便对于完全不懂编程的小白用户，只要能够清晰地描述自己的业务 SOP，就能通过 TRAE 快速封装出属于自己的技能组合，进而提升效率。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单畅想一下，Skill 不仅可以成为 Vibe Coder 们的得力工具，也完全可以作为用户手中的个人数字管家。通过配置特定的技能包，你可以让 TRAE 扫描并清理下载文件夹，根据文件类型或者 AI 对内容的理解进行智能重命名与归类。对于习惯使用 Obsidian 的知识管理爱好者，Skill 可以自动将杂乱的网页剪藏转化为带有标准 YAML 区块和双链规范的 Markdown 笔记。无论是将长视频文案转化为适合社交媒体分发的短贴，还是通过上传 CSV 格式的银行流水生成月度消费趋势报告，用户都可以借助 Skill 实现高效的机器执行力。而 TRAE 正是一个可用于实现这一点的称手工具。&lt;/p&gt;&lt;p&gt;心动了吗？为了庆祝周年并降低 Skill 功能的使用门槛，官方从 1 月 14 日起为 TRAE 国际版用户发放了丰厚的 Fast Request 权益。这基本相当于赠送了一个月以上的 Pro 会员额度。其中 Free 用户增加 600 次，Pro 用户增加 800 次，而且在权益期内，包括 GPT 5.2 在内的所有顶级模型均可免费使用。&lt;/p&gt;&lt;p&gt;领取流程极其简单，大家只需登录官网 trae.ai 或者在 IDE 顶部的活动横幅点一下即可。这种好机会建议大家快去尝试，构建属于你自己的专业技能包。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从指令搬运到专业资产的沉淀&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Andrej Karpathy 所描述的那个全新的「可编程抽象层」正在变得日益清晰。在这个层级中，Skill 是一套被标准化封装的行业智慧，它标志着 AI 工具正从通用的生成模型演变为具备特定领域 SOP 的专业执行者。&lt;/p&gt;&lt;p&gt;当个人或团队的经验可以被打包并像 npm 包一样自由分发与复用时，个体的创造力将被无限放大。很明显，Skill 正在确立一种全新的协作标准。字节跳动 TRAE 在 SOLO 模式中的深度集成，为这种范式的落地提供了一个高效的试验场。&lt;/p&gt;&lt;p&gt;对于开发者而言，现在正是将那些重复的、高价值的工作流程沉淀为 SKILL.md 的最佳时刻。在 2026 年的 AI 浪潮中，掌握并构建属于自己的「技能库」，将是应对职业重构、实现 10 倍效能提升的核心竞争力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>第一梯队的大模型安全吗？复旦、上海创智学院等发布前沿大模型安全报告，覆盖六大领先模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 12:48:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/b41b408d-c6af-4664-ba3c-65317398e3dd/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="2 2 []"&gt;随着大语言模型加速迈向多模态与智能体形态，传统以单一维度为主的安全评估体系已难以覆盖真实世界中的复杂风险图景。在模型能力持续跃升的 2026 年，开发者与用户也愈发关注一个核心问题：&lt;strong&gt;前沿大模型的安全性，到底如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于这一背景，&lt;strong&gt;复旦大学、上海创智学院、迪肯大学与伊利诺伊大学厄巴纳 &amp;mdash; 香槟分校的研究团队联合发布&lt;/strong&gt;本次安全评测报告，面向 &lt;strong&gt;GPT-5.2、Gemini 3 Pro、Qwen3-VL、Grok 4.1 Fast、Nano Banana Pro、Seedream 4.5&lt;/strong&gt; 六大前沿模型，构建了一套覆盖&lt;strong&gt;语言、视觉语言与图像生成&lt;/strong&gt;三大核心场景的统一安全评测框架，对当前主流大模型的安全能力进行了系统性、全景式刻画。在评测设计上，融合了四大关键维度，形成多层次、立体化的安全评估体系：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基准评测&lt;/strong&gt;，系统整合 ALERT、Flames、BBQ 等&lt;strong&gt; 9 个国际主流安全基准&lt;/strong&gt;，全面刻画模型在标准风险分布下的基础安全能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;对抗评测&lt;/strong&gt;，覆盖&amp;nbsp;&lt;strong&gt;30 种代表性黑盒越狱攻击方法&lt;/strong&gt;，包括语义伪装、代码混淆与长程多轮诱导等复杂攻击形态，真实还原高强度对抗场景；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多语言评测&lt;/strong&gt;，支持&lt;strong&gt; 18 种语言&lt;/strong&gt;，系统检验模型安全机制在跨语种环境下的稳定性与迁移能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;合规性评测&lt;/strong&gt;，面向&lt;strong&gt;欧盟《AI 法案》、美国 NIST RMF、新加坡 MAS FEAT 及中国《生成式人工智能管理办法》&lt;/strong&gt;等核心监管框架，评估模型在全球治理体系下的合规适配水平。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过全方位的安全评测，本报告揭示了前沿大模型&lt;strong&gt;在不同应用场景、威胁模型与监管语境下的安全边界&lt;/strong&gt;，为产业落地与政策制定提供一定参考。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0CgYGicoDmq5oWZ6XZrxJDNExEoL6zAGe2vicxYykVYh5LK9KSHUIc2vA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529084" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/751d79be-c344-4867-9e0c-f434c227c1b3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接: https://arxiv.org/pdf/2601.10527&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页: https://xsafeai.github.io/AI-safety-report/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github链接: https://github.com/XSafeAI/AI-safety-report&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace链接: https://huggingface.co/papers/2601.10527&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;声明&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;本报告是一项基于公开方法与统一框架开展的学术性安全评测研究，旨在为前沿大模型的安全能力提供系统性认知参考，而非任何形式的监管裁定或合规结论。评测结果具有明显的&lt;strong&gt;时效性与场景依赖性&lt;/strong&gt;，应主要用于推动安全评估体系的透明化与持续改进，而不宜被解读为简单的模型排名或舆论定性依据。&lt;/p&gt;&lt;p&gt;本报告选取的评测对象均为当前&lt;strong&gt;通用能力处于第一梯队的前沿模型&lt;/strong&gt;。我们亦对其他模型进行了探索性测试，其整体安全表现普遍低于本报告所纳入的模型，但未在正文中展开呈现。另需说明的是，由于 API 使用成本因素，本次研究未覆盖 Claude 系列模型。&lt;/p&gt;&lt;p&gt;受限于资源与周期，本报告的评测规模仍然有限，难以全面覆盖真实世界中的所有风险形态，相关结论不可避免具有一定的局部性与阶段性，&lt;strong&gt;应被视为学术参考而非最终结论。&lt;/strong&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;全方位安全评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;报告的主要发现如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于静态安全基准的评测会普遍高估安全性，&lt;strong&gt;在真实越狱攻击下没有模型具备可靠的防御能力&lt;/strong&gt;，即使 GPT-5.2 在最坏情况下的安全率也仅约 6%，其他模型接近于 0%；多轮自适应攻击和跨语言场景成为当前最大的安全短板。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不同模型呈现出明显的 &amp;ldquo;&lt;strong&gt;安全人格&lt;/strong&gt;&amp;rdquo; 差异：GPT-5.2 为全能内化型，Qwen3-VL 为准则合规型，Gemini 3 Pro 为伦理交互型，Grok 4 Fast 为自由效率型；在文生图模型中 Nano Banana Pro 整体最稳，为柔性重塑型，Seedream 4.5 为坚实屏障型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;安全能力排行&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0oIWlp43Foicia3a3BdbAbB3syaC7wh3YHx0ibncA0sGQwU8gTQeVroD1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.47836538461538464" data-s="300,640" data-type="png" data-w="832" type="block" data-imgfileid="503529085" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8a626dfc-4127-472a-a353-25775fafafb8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;1. 语言模态安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5.2 &lt;/strong&gt;的平均安全率为 &lt;strong&gt;78.39%&lt;/strong&gt;，展现出业界领先的安全水平，其安全机制已从依赖规则触发与启发式过滤，迈入以深层语义理解与价值对齐为核心的阶段。这一范式转变使模型在复杂、灰区场景中的安全判断更加稳定，也显著降低了在对抗输入下的失效风险，体现出当前最接近 &amp;ldquo;&lt;strong&gt;内生安全&lt;/strong&gt;&amp;rdquo; 的对齐形态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini 3 Pro&lt;/strong&gt; 的平均安全率为 &lt;strong&gt;67.9%&lt;/strong&gt;，整体呈现出 &amp;ldquo;强但不均衡&amp;rdquo; 的安全特征：在基准评测与多语言安全上保持第二梯队领先，基准测试达到 88.06%，多语言安全率为 67.00%，合规性维度也取得 73.54% 的稳定成绩，显示其基础对齐与社会价值观校准较为扎实。然而，其对抗鲁棒性下降至 41.17%，与其基准表现形成明显落差，说明该模型在攻击驱动输入下仍存在可被利用的脆弱面，更适合 &amp;ldquo;常规分布&amp;rdquo; 下的安全场景，而在语义伪装与复杂上下文操纵中的泛化能力仍有提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Qwen3-VL &lt;/strong&gt;的平均安全率为 &lt;strong&gt;63.7%&lt;/strong&gt;，比肩 Gemini 3 Pro。其在&lt;strong&gt;合规性&lt;/strong&gt;方面表现尤为突出，以 77.11% 的成绩位居第二，体现了其在合规导向型安全策略上的系统优势。不过，其在对抗安全性（33.42%）与多语言安全（64.00%）上的明显回落，也反映出该模型更擅长 &amp;ldquo;规则明确型风险&amp;rdquo;，而在语义伪装与跨语境迁移方面仍有提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Grok 4.1 Fast &lt;/strong&gt;的平均安全率为 &lt;strong&gt;55.2%&lt;/strong&gt;，表现呈现出很大的不均衡性。尽管其在基线安全性（66.60%）和合规性评测（45.97%）中处于垫底位置，显示出系统性的合规短板 ，但其在&lt;strong&gt;对抗评测&lt;/strong&gt;中却展现了意外的韧性，以 46.39% 的安全率位列全场第二 。这种 &amp;ldquo;底座薄弱但对抗较强&amp;rdquo; 的独特性，反映了其防护策略可能更多依赖于对特定攻击模式的拦截，而非全维度的安全内化，在非英语语境和严监管场景中依然面临较大的合规挑战 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 多模态安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5.2 &lt;/strong&gt;的平均多模态安全率为 &lt;strong&gt;94.69%&lt;/strong&gt;，延续了全面领先的态势，在对抗评测下达到 97.24% 的近饱和表现，在基准场景中亦以 92.14% 稳居首位。这一结果表明，其安全机制不仅在文本层面实现了深度内化，在图文交互等复杂跨模态场景中同样具备高度稳定性，能够有效抵御视觉诱导、语义叠加等复合型风险，代表了当前多模态安全对齐的最高成熟度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Qwen3-VL &lt;/strong&gt;的平均安全率为&lt;strong&gt; 81.11%，超越 Gemini 3 Pro&lt;/strong&gt;。其以 83.32% 的基准成绩和 78.89% 的对抗成绩稳居第二，并在两类评测中均保持对 Gemini 3 Pro 的领先优势。这表明其在视觉 - 语言交互场景中的安全策略具备较好的结构完整性，能够在面对图文组合诱导时维持相对稳健的防御表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini 3 Pro&lt;/strong&gt; 的平均安全率为 &lt;strong&gt;78.99%&lt;/strong&gt; 位列第三，整体呈现出 &amp;ldquo;可靠但保守&amp;rdquo; 的多模态安全特征。其在常规视 - 语言任务中的风险识别能力较为扎实，但在面对多轮视觉诱导、隐性语义嵌套等复杂攻击时，防御强度明显弱于前两名模型，说明其多模态安全机制仍更多建立在规则与触发层面，而非深层语义融合层面的统一对齐。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Grok 4.1 Fast &lt;/strong&gt;的平均安全率为 &lt;strong&gt;68.16%&lt;/strong&gt;。其表现具有一定 &amp;ldquo;反直觉&amp;rdquo; 性：其对抗成绩 68.34% 略高于基准成绩 67.97%，显示其安全水平对攻击扰动并不敏感。这一现象并不意味着其具备真正的鲁棒性，反而更可能反映出其更强的防护机制主要停留在浅层过滤与简单触发逻辑上，缺乏随攻击复杂度提升而动态调节的能力，整体仍难以支撑复杂真实场景下的多模态风险防控需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 文生图安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Nano Banana Pro &lt;/strong&gt;的平均安全率为 &lt;strong&gt;59.86%&lt;/strong&gt;，在文生图安全评测中展现出当前最为成熟的整体防护水平，在基准评测（60.00%）、对抗评测（54.00%）与合规性评测（65.59%）三个维度均位居首位。其成绩随评测强度递进而稳定提升，表明该模型的安全机制并非仅针对静态提示词进行表层过滤，而是具备一定程度的风险语义重构与情境适配能力，能够在监管敏感场景下保持相对一致的防御表现。这一特征使其在艺术表达与内容合规之间形成了较为平衡的治理路径，是当前文生图模型中安全泛化能力最为突出的代表。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Seedream 4.5 &lt;/strong&gt;的平均安全率为 &lt;strong&gt;41.71%&lt;/strong&gt;，展现了坚实的合规基础，其基准安全（47.94%）与合规性（57.53%）成绩证明了其在受监管视觉场景下的精准防控优势，但是在对抗安全性（19.67%）方面成绩偏低，显示其基础防护能力仍存在结构性短板。该模型在显性监管红线与高风险类别上具备较为稳定的规则触发能力，然而这种以约束为主的防御模式在面对语义伪装、隐性诱导等对抗型提示时缺乏足够的语境理解支撑，导致在对抗场景中的安全鲁棒性仍显不足。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;大模型的 &amp;ldquo;安全人格&amp;rdquo; 画像&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ06HuT5UGa6jzKmCNUictxFgK7yCXALFax41e7mBibLxDu3VMrRB30Bevw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6634615384615384" data-s="300,640" data-type="png" data-w="832" type="block" data-imgfileid="503529086" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b6dba02c-ec76-4037-833e-5f6f9012363d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;GPT-5.2（全能内化型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;其安全雷达图谱近乎全向饱和，表明安全机制已从外置规则演进为内生推理能力。在灰区与复杂语境中，GPT-5.2 往往能给出克制而精确的合规引导，避免过度拒绝与风险放行之间的摇摆。不过也正因其具备更强的语义理解与任务完成能力，在极少数高度隐蔽的对抗性场景中，其 &amp;ldquo;深度推理 &amp;mdash; 深度协作&amp;rdquo; 的优势亦可能被利用，对安全校准提出更高的持续演化要求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Qwen3-VL（准则合规型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在法律政策边界清晰、监管要求明确的场景中展现出极强的稳定性与可预期性，尤其在生物安全、政务合规等 &amp;ldquo;硬红线&amp;rdquo; 领域具备高度专业化的防御能力。然而，评测也显示，其安全策略明显偏向&lt;strong&gt;规则驱动&lt;/strong&gt;范式：当风险表达转向语义伪装或情境隐喻时，模型在跨语境推断与抽象风险识别方面的弹性仍显不足，使其在未知攻击形态下呈现出一定脆性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini 3 Pro（伦理交互型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;采用 &amp;ldquo;先响应、后校准&amp;rdquo; 的人本化安全交互范式，在保障对话流畅度的同时保持较高的风险敏感性。其在社会价值观与文化语境对齐方面表现细腻，尤其擅长处理偏见与歧视类风险。但评测亦表明，其安全策略在部分场景中偏向&lt;strong&gt;事后纠偏&lt;/strong&gt;而非事前阻断，当面对对抗性重构或复杂情境操纵时，这种 &amp;ldquo;柔性防御&amp;rdquo; 在稳定性上仍有提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Grok 4.1 Fast（自由效率型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;呈现出轻量化与极速响应的产品哲学，原生防御机制相对克制，更强调开放表达与低摩擦交互体验。其设计取向为用户提供了更大的创作自由度与更广阔的对话空间，体现出一种以&lt;strong&gt;效率与表达自由优先&lt;/strong&gt;的安全取舍路径，在开放性与防护性之间形成鲜明风格。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Nano Banana Pro（柔性重塑型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;擅长通过内生语义净化策略对高风险提示进行隐性重构，在维持生成质量与艺术表现力的同时，实现较为稳定的内容合规控制。这一 &amp;ldquo;柔性转译&amp;rdquo; 式治理模式在多数场景中有效平衡了安全与创作自由，但其对边界模糊风险的处理仍高度依赖隐式转换机制，一旦语义重塑失效，防护体系的显性支撑能力相对有限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Seedream 4.5（坚实屏障型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在文生图领域坚持以强约束为核心的安全设计理念，特别是在版权与暴力内容防御方面构建了稳定可靠的拦截闭环。然而，其安全体系明显呈现出 &amp;ldquo;&lt;strong&gt;阻断优先&lt;/strong&gt;&amp;rdquo; 特征：对边缘语义与灰区场景缺乏足够的语义判别弹性，导致在部分复杂创作需求下出现 &amp;ldquo;要么全挡、要么全漏&amp;rdquo; 的两极化风险，暴露出语义理解深度与生成自由度之间的结构性张力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对抗演进与治理挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 多轮自适应攻击的深层威胁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究表明，攻击者通过持续观测模型响应并动态调整诱导策略，可形成具备 &amp;ldquo;自我进化&amp;rdquo; 能力的多步攻击链路。在此范式下，单一拦截层和静态规则体系难以形成有效防线，多轮自适应攻击在复杂场景中的绕过成功率显著提升，正在成为下一阶段大模型安全治理的核心挑战。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 跨语言安全的结构性不均衡&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;评测结果显示，多数模型在非英语语境（如泰语、阿拉伯语等）下的安全表现出现 &lt;strong&gt;20%&amp;ndash;40%&lt;/strong&gt; 的系统性下滑，暴露出当前安全对齐在语料分布与策略迁移上的显著不平衡。这一差距不仅削弱了模型的全球可用性，也放大了区域性风险外溢的可能性，构成全球部署背景下的长期隐患。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 决策透明度与可解释性的治理短板&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管前沿模型在合规性指标上持续进步，但在拒绝决策的可解释性与责任可追溯性方面仍普遍存在结构性不足。当前安全机制更多体现为 &amp;ldquo;结果合规&amp;rdquo;，而非 &amp;ldquo;过程可审计&amp;rdquo;，这一缺口在高风险领域（如医疗、公共治理与国家安全）中尤为突出，已成为制约可信部署的重要制度性瓶颈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本报告致力于为全球人工智能安全研究提供一份基于系统实证的关键参照坐标。随着模型能力呈指数级跃升，安全对齐已不再是事后修补式的技术叠加，而必须转向从底层架构、训练范式到多模态交互机制的全栈式深度嵌入。&lt;/p&gt;&lt;p&gt;本报告呼吁学术界、产业界与治理机构应当形成更加紧密的协同机制，共同构建兼具包容性、标准化与动态演进能力的安全评估体系，以制度化、工程化的方式推动生成式人工智能走向可控、可信与可持续的发展路径。&lt;/p&gt;&lt;p&gt;更为系统和深入的分析见论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
