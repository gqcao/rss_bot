<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>联发科天玑9500s、8500发布：GPU、光追拉满，红米Turbo 5Max将搭载</title>
      <description>&lt;![CDATA[支持硬件级光线追踪技术。]]&gt;</description>
      <author>李泽南</author>
      <pubDate>Thu, 15 Jan 2026 18:48:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-12</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-12</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1 月 15 日，联发科（MediaTek）正式发布了天玑 9500s 和天玑 8500 移动芯片。&lt;/p&gt;&lt;p&gt;作为天玑家族的新成员，两款新品承袭了天玑旗舰芯片的诸多先进技术，在性能、能效、AI、影像、游戏和无线连接等方面表现强大，为旗舰细分市场注入了新动力。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/646b7712-6fe8-489a-aa6e-41f290d2154f/QQ20260115-181348.png" style="width: 59.67%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;天玑 9500s 采用 3nm 制程工艺和全大核架构（拥有超过 290 亿晶体管），八核 CPU 包含 1 个主频 3.73GHz 的 Cortex-X925 超大核、3 个 Cortex-X4 超大核和 4 个 Cortex-A720 大核，配备同档次出众的大容量高速缓存（二级缓存、三级缓存+系统缓存共 29m），结合第二代天玑调度引擎，可为手机等终端带来强大性能和能效表现。&lt;img src="https://image.jiqizhixin.com/uploads/editor/d2e2574e-f4c9-4894-9923-d9a57039e491/QQ20260115-181722.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;GPU 方面，天玑 9500s 搭载 Immortalis-G925 GPU ，提供重载硬核手游满帧、沉浸式的畅游体验，能够满足游戏发烧友、电竞选手对性能的期待。天玑 9500s 支持先进的光线追踪技术，天玑 OMM 追光引擎能够高效渲染图形，大幅提升游戏画面的真实感和精细度，带来主机级的环境光照和反射效果。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/2ee4cf4f-04c6-445c-99bc-bfc0d0173632/QQ20260115-181925.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;此外，借助天玑星速引擎的自适应技术 3.0（MAGT 3.0）和天玑倍帧技术 3.0（MFRC 3.0），天玑 9500s 可显著提高主流游戏的能效表现，延长终端的续航时间。该芯片还支持 165 超高帧游戏，助力玩家体验快人一步。&lt;/p&gt;&lt;p&gt;在 AI 性能方面，天玑 9500s 集成了旗舰级 NPU，拥有强大的端侧 AI 推理能力，面向生成式推理、多模态模型进行了优化，以构建强大的旗舰端侧影像、内容生成等多元能力。该芯片支持端侧 AI 实况照片美化、AI 照片编辑（扩图、抠图、消除），AI 内容摘要（通话、会议和文件）等日常高频功能，能够助力终端厂商打造用户的个人随身 AI 设备，满足日益增长的社交、生产力场景需求。&lt;/p&gt;&lt;p&gt;联发科表示，其正在持续与大量应用端厂商合作，致力于打造更多新形态的 AI 体验。&lt;/p&gt;&lt;p&gt;影像方面，天玑 9500s 搭载先进的 MediaTek Imagiq 影像处理器，支持实时 30 帧运动追焦和 8K 全焦段杜比视界 HDR 视频录制，视频创作者可轻松捕捉清晰、生动的视频画面。此外，该芯片还支持杰出的抓拍和降噪技术，带来既快又清晰的旗舰拍照体验。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6a7e02ad-98bf-4006-8d04-10882c83eac4/QQ20260115-182809.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;今天推出的另一款芯片天玑 8500 采用台积电 4nm 制程打造，全大核架构 CPU 包含 8 个主频至高可达 3.4GHz 的 Cortex-A725 大核，带来性能和能效的进一步提升。天玑 8500 支持精准的调度技术，支持传输速率更高的 LPDDR5X 9600Mbps 内存，用户在日常应用、游戏和多任务处理等使用场景中能够享受丝滑流畅、持久续航。&lt;/p&gt;&lt;p&gt;天玑 8500 搭载性能更强的八核 Mali-G720 GPU，峰值性能相较上一代提升 25%，功耗相较上一代峰值性能下降低 20%。得益于全面升规的计算核心、天玑调度和星速双引擎，天玑 8500 可为玩家带来兼具游戏满帧稳帧、疾速加载和冰峰高能效的劲爽体验。据介绍，在流行开放世界手游的高画质设置上，搭载该芯片的手机可以保持 60 帧满帧的效果。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5c118ad0-80d7-448c-8274-26f667762031/QQ20260115-183705.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;此外，天玑 8500 还将光线追踪技术落地于主流移动游戏，提供更加逼真的画质效果，显著提升玩家的沉浸感。&lt;/p&gt;&lt;p&gt;联发科表示，基于天玑新一代次旗舰芯片，通过与腾讯语音团队的合作，目前双方已在王者荣耀游戏中落地了 AI 语音转文字的功能。&lt;/p&gt;&lt;p&gt;至于搭载新一代芯片的手机，联发科介绍了与小米（REDMI）vivo，OPPO 等厂商的深度合作。&lt;/p&gt;&lt;p&gt;小米集团手机部副总裁李俊也来到了发布会现场，介绍了即将搭载联发科新一代芯片的手机。他表示，即将在本月发布的红米 Turbo 5 Max（天玑 9500s 版）的安兔兔跑分达到了 361 万分，在 2500 元价位上实现了前所未有的性能。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8bc2160d-3391-46d7-b63b-43ab0b276fdb/QQ20260115-183809.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;除了天玑 9500s 与 8500 芯片，红米 Turbo 5 Max 预计还将拥有大屏幕及超大容量电池。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>通用级PixVerse P1的技术突破，揣着进入平行世界的密码</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 17:26:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-11</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/de5cc1f9-b163-420b-a4eb-108d509b18a0/1768468906800.png" style="width: 700%;" class="fr-fic fr-dib"&gt;原来，视频生成卷到极致，就是突破大脑和视觉的边界，让想象力进入 AI 构建的虚拟空间。&lt;/p&gt;&lt;p data-path-to-node="5"&gt;昨天，&lt;strong&gt;PixVerse R1&amp;nbsp;&lt;/strong&gt;突然上线。一开始我们以为这只是一次普通的版本更新，但那种「即时响应、即看即创」的全新交互体验，却是前所未有的。读完技术报告我们发现，这不仅仅是一次卷到极致的性能提升，更是量变带来的质变。&lt;/p&gt;&lt;p data-path-to-node="7"&gt;回顾过去，23 年推出第一版模型，随后 Web 端、移动端全面铺开，爱诗科技在 DiT 路线上一路狂奔：从 24 年底的 10 秒生成，到 25 年 2 月实现 5 秒生成社交级视频，再到 11 月将 1080P 视频生成压缩至 30 秒。在自研模型技术和工程化落地的思想下，PixVerse 确实将「传统视频生成」的速度推向了极限。&lt;/p&gt;&lt;p data-path-to-node="8"&gt;与此同时，行业加速从未停歇。就在上个月，生数科技宣布其与清华大学团队研发的 TurboDiffusion 框架，也让视频生成正式迈入「秒级」门槛。&lt;/p&gt;&lt;p data-path-to-node="9"&gt;&lt;strong&gt;但时间上的「卷」就是视频生成的全部吗？&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;显然，再快的速度，如果不能生产出符合制作需求的画质和一致性，依然无法成为&lt;strong&gt;通用&lt;/strong&gt;的标准。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;PixVerse 曾是业界第一个把 5 秒视频生成做到 5 秒之内的团队，而当一切看似达到极限时，在 2026 年开年，PixVerse R1 模型与产品同步横空出世。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;通过将计算效率提升&lt;strong&gt;数百倍&lt;/strong&gt;，它不再局限于「秒级」，而是做到了人类肉眼感知范围内的「实时」生成。发布即实装，这是一款真正的「通用」实时世界模型。这已不仅是单点的技术突破，而是一步到位、直接实现应用层级质变的代际跨越。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;以下，我们将通过技术报告，为您详细解析 R1 的这次突破。&lt;a href="https://mp.weixin.qq.com/s/LybgC6RD9cu0kJyGbTJlog"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/471b59d3-d128-4863-a75f-74b88ee28675/1768468946429.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-path-to-node="15"&gt;看了这个视频，大家或许理解了什么是「无限内容」的视频生成。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;在这个模型创造的世界里，「汉语竟是上古禁咒」，你只要说出「春」即刻绿草如茵，说出「鸟」即刻飞鸟成群。一切都是如此连续，直白，世界实时响应你的呼唤，时间和空间都在你的掌控之中。或许，PixVerse R1 已经彻底掌握了「无限流」的真谛。&lt;/p&gt;&lt;p data-path-to-node="17"&gt;&lt;strong&gt;简单来说，PixVerse R1 是全球首个支持最高 1080P 分辨率通用实时世界模型。&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="18"&gt;这也是第一次，AI 可以基于用户的意图实时生成一个持续演化、物理上合理的世界，标志着视频生成正式从「静态输出」迈入「实时交互」的全新阶段。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;回顾视频生成技术的发展路径，行业始终受困于速度、质量与成本的不可能三角：高画质往往意味着高延迟（如传统扩散模型），而追求速度又不得不牺牲物理一致性。PixVerse R1 没有盲目追求参数军备竞赛，而是找到了一条通往「通用」的平衡之路：&lt;/p&gt;&lt;p data-path-to-node="20"&gt;&lt;strong&gt;当一个模型首先做到了打破物理极限的实时响应（IRE），并以此为基础结合了通用全模态（Omni）与长时序世界模拟（自回归），它就已经超越了传统意义上的视频生成工具。&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="198" data-backw="578" data-height="534" data-imgfileid="503528507" data-ratio="0.3425925925925926" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDOGSH2gVorSTm3wLaibtRUJPLjHAxt5iaB0sak4Y0ibD0v9NkwVw9Djk4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1558" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/094780b4-4100-4632-80b2-3f46e76e776c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21"&gt;&lt;b data-index-in-node="0" data-path-to-node="21"&gt;技术博客链接：&lt;/b&gt;https://pixverse.ai/en/blog/pixverse-r1-next-generation-real-time-world-model&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="22"&gt;&lt;strong&gt;交互的物理极限：瞬时响应引擎（IRE）&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="23"&gt;在通往通用世界模型的路径上，「实时性」始终是阻碍技术从实验室走向大规模应用的核心工程障碍。&lt;/p&gt;&lt;p data-path-to-node="24"&gt;传统扩散模型的生成逻辑本质上是一种精细的迭代去噪过程，通常需要 50 步甚至更多的采样步骤，才能将高斯噪声转化为清晰的视觉内容。这种机制虽然在一定程度上保证了生成质量，但其带来的秒级甚至分钟级的高延迟，使得 AI 视频生成长期停留在「离线制作、预录制回放」的阶段，无法满足即时交互的严苛需求。&lt;/p&gt;&lt;p data-path-to-node="25"&gt;不过，生成速度始终是 PixVerse 的强项，其在响应时间上一骑绝尘。早在 PixVerse V4.5 的时候我们就实测过，即使我们将各项生成指标拉满，平台输出结果的时间也&lt;strong&gt;没有超过 1 分钟&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;但是，为了更进一步，实现彻底的「实时响应」，PixVerse 在 R1 上决心彻底重构底层推理架构，提出了&lt;strong&gt;瞬时响应引擎（Instantaneous Response Engine，IRE）&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="27"&gt;这是一套针对采样过程的系统级加速方案，通过三大关键技术，在保持 1080P 高分辨率生成的前提下，将推理时间压缩到极致。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;&lt;b data-index-in-node="0" data-path-to-node="28"&gt;时间轨迹折叠&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="29"&gt;不同于传统方法在加噪去噪过程上进行漫长的逐步逼近，该技术引入「直接传输映射」作为结构先验，建立噪声到数据的直线通路，能够直接预测干净数据的分布路径。&lt;/p&gt;&lt;p data-path-to-node="30"&gt;这种方法在数学上有效地「折叠」了原本冗长的时间维度，将传统扩散模型所需的 50+ 采样步数暴力压缩至仅需 &lt;strong&gt;1-4 步&lt;/strong&gt;。这一数量级的步数缩减，直接从源头上解决了计算量过大的问题，实现了推理速度的质变。&lt;/p&gt;&lt;p data-path-to-node="31"&gt;&lt;b data-index-in-node="0" data-path-to-node="31"&gt;引导校正&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;针对为了保证生成质量通常采用的无分类器引导策略（Classifier-Free Guidance，CFG）所带来的双倍计算开销问题，PixVerse R1 团队通过将条件梯度直接融合进模型内部，使得系统在推理阶段无需再进行正负样本的双重计算。&lt;/p&gt;&lt;p data-path-to-node="33"&gt;这一优化成功绕过了传统 CFG 的计算瓶颈，在不牺牲指令遵循能力的情况下，进一步降低了计算复杂度。&lt;/p&gt;&lt;p data-path-to-node="34"&gt;&lt;b data-index-in-node="0" data-path-to-node="34"&gt;自适应稀疏注意力&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="35"&gt;为了应对高分辨率视频生成带来的巨大显存与计算压力，IRE 采用了自适应稀疏注意力机制。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;该机制能够动态分析视频生成过程中的上下文依赖，智能识别并剪除长程依赖中的冗余计算，从而显著压缩了计算图，大幅提升了整体推理效率。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="224" data-backw="512" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDiaMqMbPXuSGI6vNxibmjibgmm3AmalWas0x47nYp9STBK31jw4iaJa5Slw/0?wx_fmt=png&amp;from=appmsg" data-cropx1="73.25259515570934" data-cropx2="1366.5397923875432" data-cropy1="250.06920415224914" data-cropy2="815.8823529411765" data-height="962" data-imgfileid="503528508" data-ratio="0.43796296296296294" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDfTWTmsrlHvlYibrRcpHGMz9beVhylIugVh2HFDClI9X1L1FN5dqrn0Q/640?wx_fmt=jpeg#imgIndex=2" data-type="png" data-w="1080" data-width="1460" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a4736c88-788c-4c6f-ae03-5edd54e39491/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="37,0"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;即时响应引擎由三个模块组成：时间轨迹折叠、引导修正和自适应稀疏注意力学习。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="38"&gt;&lt;strong&gt;通用的认知底座：Omni 原生多模态基础模型&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="39"&gt;如果说「瞬时响应引擎」解决了传输的速度问题，那么一个强大的底座模型，则决定了传输内容的质量与上限。&lt;/p&gt;&lt;p data-path-to-node="40"&gt;底座模型是一切新功能新特性的基础。构建通用实时世界模型的第一步，在于打破单一模态的感知壁垒，&lt;strong&gt;只有设计一个完全端到端的原生多模态基础模型，才能彻底超越传统生成流程的局限&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="41"&gt;在当前的视频生成技术栈中，多为非端到端的生成方式。往往需要生成一种模态之后通过级联的方式生成另一种模态，这种方式下需要反复的铺路搭桥，尤其是在处理复杂的跨模态交互上，自然显著影响了生成的效率，也限制了模型的通用性。&lt;/p&gt;&lt;p data-path-to-node="42"&gt;为了实现无限的通用性，模型必须强调：&lt;strong&gt;原生，原生，还是原生&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="43"&gt;PixVerse R1 提出的 Omni &lt;strong&gt;原生端到端&lt;/strong&gt;多模态基础模型，正是通过底层架构的重构，实现了「&lt;strong&gt;因原生而通用&lt;/strong&gt;」。&lt;/p&gt;&lt;p data-path-to-node="44"&gt;&lt;b data-index-in-node="0" data-path-to-node="44"&gt;原生统一表示&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="45"&gt;Transformer 架构给了生成模型无穷的想象和可能性。&lt;/p&gt;&lt;p data-path-to-node="46"&gt;Omni 模型引入了&lt;strong&gt;统一 Token 流架构&lt;/strong&gt;。该架构基于 Transformer，摒弃了异构模型拼接的传统路径，将文本、图像、音频与视频等不同模态的数据，统一编码为单一的生成序列。&lt;/p&gt;&lt;p data-path-to-node="47"&gt;在这一框架下，模型不再是将文本「翻译」为视觉信号，而是在原生层面上实现了对多模态数据的联合处理与理解。这种全模态的「通感」能力，使得模型能够精准捕捉文本指令与视听内容之间的深层关联，从而支撑起游戏、影视等多领域的通用化应用。&lt;/p&gt;&lt;p data-path-to-node="48"&gt;&lt;b data-index-in-node="0" data-path-to-node="48"&gt;原生分辨率&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="49"&gt;除了多模态数据的原生处理，第二个原生，是实现高分辨率视频生成的核心特性：&lt;strong&gt;原生分辨率&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="50"&gt;Omni 模型引入这一机制，旨在解决传统视频生成模型中因数据预处理而导致的画面构图破坏与几何失真问题。&lt;/p&gt;&lt;p data-path-to-node="51"&gt;为了适配固定的模型输入结构，传统方案往往采取「强制裁剪」或「缩放拉伸」的策略。这种「削足适履」的方式，会导致画面关键信息被裁切丢失，或使物体形态发生非物理的扭曲变形（如被压扁或拉长）。&lt;/p&gt;&lt;p data-path-to-node="52"&gt;相比之下，Omni 模型坚持在&lt;strong&gt;原生分辨率和原始比例&lt;/strong&gt;下进行端到端的学习。这一架构使其能够自适应处理任意长宽比的素材，&lt;strong&gt;从根源上消除了因裁切或缩放带来的视觉偏差，确保了生成内容在构图完整性与物理几何上的真实感&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD2CMr7jx87AODMcgvO9KYUaibyqRbwwQorjwbSbK9BRDPqtKP0aEmLRw/640?wx_fmt=jpeg#imgIndex=3" data-ratio="0.3574074074074074" data-type="png" data-w="1080" data-width="1358" data-height="860" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDMdmEVN1GqpBWUiasPAZh5TsYia8MLPTg4HHAgUm4whozGhHHuNkFS3Rg/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1358" data-cropy1="197.35640138408306" data-cropy2="683.6989619377164" data-backw="578" data-backh="207" data-imgfileid="503528510" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ab19db3d-53f3-408f-85f1-89541a903e95/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="53,0"&gt;&lt;sup&gt;Omni 原生多模态基础模型的端到端架构，统一设计使 Omni 模型能够接受任意多模态输入并同时生成音频和视频。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="54"&gt;值得一提的是，模型通过原生学习大量真实世界视频数据，来确保真实世界的内在物理定律和动态的真实性。因此，Omni 模型的功能，似乎不仅限于生成引擎，&lt;strong&gt;更具备构建世界模型的潜力&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="55" skip="true"&gt;&lt;strong&gt;世界的连续演化：自回归流式生成机制&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="56"&gt;构建「世界模型」的挑战之一，在于如何从生成分段的「切片」，跨越到模拟连续的「过程」。在这一维度上，PixVerse R1 重点解决的是长视频生成中普遍存在的「长时序一致性」难题，以及伴随而来的显存成本瓶颈。&lt;/p&gt;&lt;p data-path-to-node="57"&gt;在传统的视频生成流程中，模型通常受限于固定时长的生成窗口。当试图延长视频长度时，往往面临「&lt;strong&gt;时间误差累积&lt;/strong&gt;」的问题：随着生成帧数的增加，微小的预测偏差会不断叠加，导致画面内容逐渐偏离初始设定，例如角色的外貌特征发生漂移，或物理环境逻辑出现崩坏。&lt;/p&gt;&lt;p data-path-to-node="58"&gt;此外，为了维持上下文的一致性，传统架构需要保存海量的历史状态，导致显存消耗呈指数级上升，使得长视频生成在计算成本上变得不可控。尤其是在 PixVerse R1 追求的「无限内容」的生成模式下，以上问题如果没有妥善处理，会出现严重的问题。&lt;/p&gt;&lt;p data-path-to-node="59"&gt;针对上述痛点，PixVerse R1 摒弃了传统的全局预测模式，构建了&lt;strong&gt;自回归流式生成机制&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="60"&gt;&lt;b data-index-in-node="0" data-path-to-node="60"&gt;无限流式生成&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="61"&gt;在生成范式上，R1 采用了&lt;strong&gt;自回归建模&lt;/strong&gt;。系统将视频合成任务重构为逐帧预测的&lt;strong&gt;流式过程&lt;/strong&gt;，而非一次性生成固定片段。&lt;/p&gt;&lt;p data-path-to-node="62"&gt;这种架构从根本上解除了时长的硬性约束，实现了理论上的「无限流式生成」。视频不再是受限的帧组合，而成为可以根据即时输入，无限向前延展的时间流。&lt;/p&gt;&lt;p data-path-to-node="63"&gt;&lt;b data-index-in-node="0" data-path-to-node="63"&gt;时间一致性&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="64"&gt;为了在无限延展中保持逻辑自洽，传统方法下基于帧上下文的特征记忆，大多有着数十秒的时间限制，显然是不够用的。&lt;/p&gt;&lt;p data-path-to-node="65"&gt;为此，R1 引入了&lt;strong&gt;记忆增强注意力模块&lt;/strong&gt;。该模块能够显式地提取并锁定视频中的关键特征（如角色的身份特征、场景的空间布局等），将其转化为紧凑的记忆单元。&lt;/p&gt;&lt;p data-path-to-node="66"&gt;在生成后续内容时，模型无需回头重算所有历史数据的全量注意力，而是直接调用「记忆」。这一设计在维持长程依赖的同时，极大地优化了计算效率，避免了显存资源的爆炸式增长。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDMOR6twhO2tDpibr9njDJ8gaDXGfMf7u9MfIkTnjtNnxGkwOVSXnibJrQ/640?wx_fmt=jpeg#imgIndex=4" data-ratio="0.512962962962963" data-type="png" data-w="1080" data-width="1564" data-height="914" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD4MYNE18FrcYeZnPOZeXynV6wcTQvrd4CO6AyexT1dOxPMLfXN5N5Kg/0?wx_fmt=png&amp;from=appmsg" data-cropx1="62.235294117647065" data-cropx2="1453.058823529412" data-cropy1="89.29411764705883" data-cropy2="803.6470588235295" data-backw="514" data-backh="264" data-imgfileid="503528512" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/b0348070-f9d3-45fc-9e47-503590130bab/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="67,0"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 集成自回归建模与全能基础模型。&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="68"&gt;从技术逻辑上看，这一机制赋予了 AI 模型「长期记忆」的能力，打破了传统帧间上下文的限制，确保了 PixVerse R1 生成的内容不再是孤立、破碎的视觉片段，而是一个具备持续演化能力的「平行时空」。&lt;/p&gt;&lt;p data-path-to-node="69"&gt;无论生成时长如何延伸，核心主体的统一性与环境逻辑的连贯性始终保持稳定，这种物理与逻辑的持久性，&lt;strong&gt;正是「通用实时世界模型」成立的关键基石&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="70"&gt;&lt;strong&gt;结语：正在发生的现在&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="71"&gt;正如爱诗科技 CEO 王长虎所言：传统视频是被记录的历史，而 PixVerse R1 开创了「正在发生的现在」。&lt;/p&gt;&lt;p data-path-to-node="72"&gt;PixVerse R1 开启的是 AI 原生游戏、互动电影、实时仿真等全新媒介形态的大门，是未来「可交互的数字世界」的计算基础设施。&lt;/p&gt;&lt;p data-path-to-node="73"&gt;视频内容的消费边界正在消融。&lt;/p&gt;&lt;p data-path-to-node="74"&gt;媒体形态将不再局限于预先渲染的固定画面，而是转向由用户意图驱动的即时生成流。&lt;/p&gt;&lt;p data-path-to-node="75"&gt;PixVerse R1 以「通用实时世界模型」的形态，为这一未来提供了可落地的技术样本，也让视听媒介真正从「回放过去」迈向了「未来创作」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Mira公司内乱？CTO被开除，带团队回OpenAI，翁荔上推发言</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 17:19:37 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b9c1a8f6-b98e-4a36-bbac-12bc5c58ce02/1768468525334.png" style="width: 700%;" class="fr-fic fr-dib"&gt;今天对于 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Thinking Machines Lab&lt;/span&gt; 和 &lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;OpenAI &lt;/span&gt;来说都是不同寻常的一天。&lt;/p&gt;&lt;p data-pm-slice="2 1 []"&gt;Thinking Machines Lab 创始人兼 CEO Mira Murati 官宣了&lt;strong&gt;与&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;联合创始人兼 CTO&amp;nbsp;&lt;/span&gt;Barret Zoph 的分道扬镳&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;同时，她也宣布了&lt;strong&gt;新任 CTO 的人选 &amp;mdash;&amp;mdash;Pytorch 之父 Soumith Chintala&lt;/strong&gt;。这位在现代 AI 基础设施领域颇具影响力的研究者在去年 11 月初离开了 Meta，并选择加入 Thinking Machines Lab。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528489" data-ratio="0.7027777777777777" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD3phKYnaBF2rZh69V2O2bwFeIp27m0jncaX80xicibKOkgScZDD4abwQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/089feeed-48d1-4421-8e4b-e480cb7dcb99/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;大约 1 个小时后，OpenAI 应用 CEO Fidji Simo 宣布，&lt;strong&gt;Barret Zoph 将重返 OpenAI&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;连同他一起回归 OpenAI 的还有&lt;strong&gt;另一位 Thinking Machines Lab 联合创始人 Luke Metz&lt;/strong&gt; 以及&lt;strong&gt;创始团队成员 Sam Schoenholz&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528488" data-ratio="0.6342592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDib1djzble50QZozs0KKEQIZmJnW2aPpic3suricia0HianJ0n8QQa4ofsVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f11ea676-f0dc-4a7e-8330-a6b4929292db/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;两位联合创始人同时从 Thinking Machines Lab「出走」，这一消息在圈内造成了不小的冲击。&lt;/p&gt;&lt;p&gt;根据有人获悉的内部消息，&lt;strong&gt;此次是由于 Barret Zoph 个人的不道德行为，Thinking Machines Lab 才解雇了他&lt;/strong&gt;。Mira Murati 甚至是在全体员工大会上宣布了这一消息。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528490" data-ratio="0.42407407407407405" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDKOG7ZyBkaUsulMACA0N0Y0JLtHADlSP4DAJjT8sOXzfRqoeE9uDKLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6ae524a4-e601-4b4f-95c3-5f4779ef46a1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;作为一家明星创企，Thinking Machines Lab 自 2025 年 2 月正式成立以来便备受关注，其核心团队成员主要由来自 OpenAI、Google DeepMind 等顶级实验室的前核心成员组成。&lt;/p&gt;&lt;p&gt;公司在成立五个月后获得了约 20 亿美元种子轮融资，投后估值达到了 120 亿美元，成为硅谷历史上规模最大的种子轮融资之一，投资方包括了英伟达、AMD、Cisco 等。&lt;/p&gt;&lt;p&gt;此次，两位核心联合创始人的离开，会不会对「势头正盛」的 Thinking Machines Lab 造成一些冲击呢？我们尚未可知。&lt;/p&gt;&lt;p&gt;随着事件发酵，&lt;strong&gt;另一位 Thinking Machines Lab 联合创始人、前 OpenAI 安全研究副总裁翁荔（&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Lilian Weng）&lt;/span&gt;&lt;/strong&gt;也发了一段意味深长的话。&lt;/p&gt;&lt;p&gt;她表示，「今天我跟好几个人都表达过这种看法：能和一群真正在乎产品、追求工匠精神的伙伴共事，真的是一种享受。当工作不仅仅是为了谋生，而是有机会投身于自己热爱的事业，这不仅仅是幸运，更是一种荣幸。我对此倍加珍惜，绝不认为这是理所应得的。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDbkhDC5I8zEocwiamE9iaamEicSicur4sDiciazXUBMWoG9ibYR1pDh6AuKudw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.36203703703703705" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528492" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/0357a587-d7c9-4ddc-b187-379e2e8de168/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对于如今人工智能圈的人员流动现状，有人感到好奇，「现在的 AI Labs，即使挂着创始人或者创始团队成员的名头，也跟普通员工一样来来去去。」&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528493" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDDuzb7zrrZ4oHSGN7uGQKiatms0sq1zSU2v3c7KgzkHZGF24fS7vGiapQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a0ddb5e6-c8c8-4f50-a7a1-8e5b6c954965/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;几位「当事人」简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Barret Zoph&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528494" data-ratio="0.8166666666666667" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDqKibYk4dNajYhDIcJOaZbuaicru90Ozsicjrm0Eo3y0tLMtXePmLsdSrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/aafba9cd-1af4-4a45-9274-532d9504d971/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;个人主页：https://barretzoph.github.io/&lt;/p&gt;&lt;p&gt;在加入并担任 Thinking Machines Lab CTO 之前，Barret Zoph 曾是 OpenAI 的一位技术主管，领导过 OpenAI 的后训练团队，涉及的研究方向包括对齐、工具使用、评估、ChatGPT、搜索、多模态等等。同时他还是一位专注投资 AI 公司的天使投资人。&lt;/p&gt;&lt;p&gt;再之前，他还曾在谷歌与信息科学学院担任过研究科学家，参与训练了大型稀疏语言模型并将其应用于各种应用的研究工作。&lt;/p&gt;&lt;p&gt;他是两篇重要论文《Learning transferable architectures for scalable image recognition》和《Neural architecture search with reinforcement learning》的第一作者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Luke Metz&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528495" data-ratio="1.0324074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDMwtrhZbndicfYPU0QibsO8ib8dshnrlwDO3KSpwdFrt39fW0xeQASXgbA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5d6373a4-adf5-4a72-8e84-c3dceb31fbd7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;个人主页：http://lukemetz.com/about/&lt;/p&gt;&lt;p&gt;在加入 Thinking Machines Lab 之前，Luke Metz 曾是 OpenAI 创始团队成员，他与 John Schulman（现为 Thinking Machines Lab 联合创始人兼首席科学家）、Barret Zoph、Liam Fedus（现为 Periodic Labs 联合创始人）等人在内部共同开发了「low-key research preview」，这是 ChatGPT 的雏形。&lt;/p&gt;&lt;p&gt;同时，他也是 GPT-4、GPT-4o、o1 等重量级模型的贡献者之一。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528496" data-ratio="0.5333333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDmG65NGI3ibO8icrL0unict6Cnib7TmoMgs56D5yM66chVX4iagPQhUSY8CA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/56a874a6-0418-459a-b47e-5ea645b8de0a/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Sam Schoenholz&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDFLnK5gyIdZlic1rOc4ocS9yXjj7icaqufX75qrxE6ESxcwTe5YN56cVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8863198458574181" data-s="300,640" data-type="png" data-w="1038" type="block" data-imgfileid="503528497" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/7a466678-cc16-423a-b5b9-4f3d4b49f7b7/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在 2025 年 1 月加入 Thinking Machines Lab 之前，Sam Schoenholz 曾领导 OpenAI 的可信赖扩展团队和 GPT-4o 优化。&lt;/p&gt;&lt;p&gt;再之前，他曾在 Google Brain 从事统计物理学与机器学习的交叉研究。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDYg0iaJwfamCicAS4VzSJgiaLTXtomicC3FaFOyribSfwHasOdCOxtHR2M1g/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.4064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528498" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/eaf98ca5-9512-4a2d-8ecd-19a080bf0c55/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Soumith Chintala&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528499" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDRyryRNnXIDwrg7aCTLCJXgEVmKchVg7qfoN74cYR5ySFPrUCdWBfkw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="605" type="block" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d826c9c2-e9b9-4cd2-af24-3340c123e05b/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;对于 Soumith Chintala，想必圈内的人应该很熟悉了。他在 2014 年 8 月加入 FAIR，在此期间与团队一起创造出了 PyTorch，并最终于 2025 年 11 月离职，选择加入 Thinking Machines Lab。如今，他又成为了这家初创公司的首席技术官。&lt;/p&gt;&lt;p&gt;关于他一路走来的经历请参考文章：&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651001820&amp;idx=1&amp;sn=d19e3f5a72465ebf663482294271ba59&amp;scene=21#wechat_redirect" target="_blank"&gt;他「二本」出身，数学很差：最终成了 PyTorch 之父、Meta 副总裁&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/fidjissimo/status/2011592010881446116&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/miramurati/status/2011577319295692801&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/lilianweng/status/2011650397635776898&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Nature丨清华等团队揭示AI科研双重效应：个人效率亦或是科学边界</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Thu, 15 Jan 2026 14:02:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNIANKJ2VGB5Gkx2ndnV3O4rypxOUxzOQqY3YJBD0UBkiaWiaXlzXIibPLA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5778894472361809" data-s="300,640" data-type="png" data-w="995" type="block" data-backw="578" data-backh="334" data-imgfileid="100027161" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/6947648e-ca36-4274-b7be-d06fe32f6dfe/640.png" data-sec-load-status="2" data-report-img-idx="0" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;在过去十年里，人工智能几乎渗透进所有自然科学领域：从蛋白结构预测，到材料筛选，再到自动化实验与论文写作。AI 被反复证明能「加速发现」，但一个更深层的问题长期被忽略&amp;mdash;&amp;mdash;&lt;strong&gt;当越来越多科学家依赖 AI，科学整体究竟发生了什么变化？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了突破这一局限，来自清华大学等的徐丰力、李勇教授团队最终推出了「全流程、跨学科的科研智能体系统」&amp;mdash;OmniScientist。他们通过对跨越 45 年、覆盖 4100 余万篇科研论文的分析，首次全景式揭示了 AI 工具融入科学研究后所带来的复杂图景。&lt;/p&gt;&lt;p&gt;相关研究内容以「&lt;em&gt;Artificial intelligence tools expand scientists&amp;rsquo; impact but contract science&amp;rsquo;s focus&lt;/em&gt;」为题，于2026 年 1 月 14 日发布在《&lt;em&gt;Nature&lt;/em&gt;》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNpqnMOeJ8osOsurjnkGzniaWPSDzVzia0NibuhEBfWo0pkOCiaUlZkqY08A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3402854006586169" data-type="png" data-w="911" data-width="911" data-height="310" data-imgfileid="100027157" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/68ad18d2-e9d2-4e49-ba20-4801739a81e5/640.png" alt="图片" data-before-load-time="1768456914451" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41586-025-09922-y&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;个人扩张与集体收缩&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队构建了一个基于&amp;nbsp;&lt;strong&gt;BERT 的语言模型&lt;/strong&gt;，用于识别「AI 增强型科研论文」。不同于关键词匹配，他们直接让模型学习论文标题与摘要中的语义特征，判断研究是否在方法层面实质性使用了 AI。&lt;/p&gt;&lt;p&gt;最终研究覆盖了&amp;nbsp;&lt;strong&gt;1980&amp;ndash;2025 年间的 41,298,433 篇论文&lt;/strong&gt;，横跨生物、医学、化学、物理、材料与地质六大自然科学领域，并按 AI 发展阶段划分为：&lt;strong&gt;传统机器学习 &amp;rarr; 深度学习 &amp;rarr; 生成式 AI&lt;/strong&gt; 三个时代。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNicp20lxYJxzxu4MWvw4lPEulVO1RMpjpP7yK0icwBXoWNVugPq3QpxRg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5703125" data-type="png" data-w="1024" data-width="1024" data-height="584" data-imgfileid="100027160" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e4524c82-bc4a-4435-a7f7-9ac4a68407bc/640.png" alt="图片" data-before-load-time="1768456914942" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：AI 在科学领域应用普及率的提升。&lt;/p&gt;&lt;p&gt;在此谨将研究结果分为个人与学术界两个层级进行解读。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对于研究者个人而言：&lt;/strong&gt;与未使用 AI 的同行相比，采用 AI 的研究者年均发表论文数量高出 3.02 倍，获得的引用量高出 4.84 倍。他们的职业发展也明显提速，从「初级研究者」晋升为「资深研究者」的平均时间缩短 1.37 年。AI论文本身也更具影响力，年均引用量高出 98.70%，且更多发表于高影响力期刊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;但对于学术界可能不算什么好事：&lt;/strong&gt;尽管个体论文影响力增强，但 AI 驱动的科学研究，其集体关注的科学主体空间收缩了 4.63%。这意味着 AI 研究倾向于更集中地围绕已有热门主题展开，而非开拓新的知识疆域。在超过 70% 的细分研究领域中，都观察到了这种知识范围的收缩现象。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNmEIUMqZ23CboxWz25f715HxPuB5arz3GoqQWPic1OaDJkic0YubXTa5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7282608695652174" data-type="png" data-w="920" data-width="920" data-height="670" data-imgfileid="100027159" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ae0f9973-8f04-45a2-b730-61dd63e2bc91/640.png" alt="图片" data-before-load-time="1768456915308" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：AI 的采用与自然科学领域知识广度的收缩相关。&lt;/p&gt;&lt;p&gt;究其原因，并非是 AI 不善于创新，而是它更容易&lt;strong&gt;在数据充足、问题定义清晰、评价标准明确的领域发挥优势。&lt;/strong&gt;这使得研究资源、注意力与后续工作，持续向「已有数据密集区」聚集&amp;mdash;&amp;mdash;例如成熟学科、热门问题、已有大规模数据集的方向，而冷门问题、新领域、缺乏标准数据的问题则进一步边缘化。&lt;/p&gt;&lt;p&gt;除此之外，AI 研究催生的后续科学互动模式也发生了变化。单篇 AI 论文能启发较广的知识衍生范围，但后续引用该原始工作的论文之间，彼此相互引用的「后续互动」程度降低了 22%。&lt;/p&gt;&lt;p&gt;这种「孤星」结构，与 AI 领域的学术认可分配不均现象，加剧了科学研究的选择偏颇。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率与探索之间的张力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项研究触及了科学发展的一个根本性张力：在追求研究效率、产出速度和个体成功的激励下，AI 工具正将科研资源引向那些最容易通过数据驱动模型取得快速进展的领域。这固然能加速解决现有范式内的核心问题，提升效率，但可能同时削弱了对数据匮乏、高风险、高不确定性的原创性、颠覆性问题的探索动力。&lt;/p&gt;&lt;p&gt;研究团队指出，这种趋势可能导致科学界困于现有认知的「局部最优解」，而减少了在更广阔、更多元的未知领域进行「分散搜索」的机会。长此以往，科学发现的内涵可能从「提出新问题」向「优化旧方案的答案」倾斜。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLl1UnRGw6gen5reBq2JpALNPLC8vNA2KmI5lIC9bmiaezy4qLlOuh5BibYDdjNdGQ9vHULQNAwib2b6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6666666666666666" data-type="png" data-w="915" data-width="915" data-height="610" data-imgfileid="100027158" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/488bb1b6-da1a-4a44-ba50-aa74d6167ebd/640.png" alt="图片" data-before-load-time="1768456915534" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 3：AI 领域后续参与度降低且重叠研究更多。&lt;/p&gt;&lt;p&gt;该研究实质上是在呼吁一种更全面、更平衡的 AI 赋能科学愿景。研究者建议，未来的 AI 系统不应仅仅作为认知能力的放大器，更应发展为感知与实验能力的拓展器。&lt;/p&gt;&lt;p&gt;这意味着 AI 需要帮助科学家去探索、选择并收集来自此前难以触及领域的新型数据，例如设计新型实验、操控机器人实验室、或模拟极端条件，从而主动创造知识探索的新前沿，而非仅仅在现有数据上精耕细作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;笔者小结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为科技前沿的参与者与旁观者，笔者在日常中也常能看到 AI 闪烁的发光点。遍历内容，却发现这些发光点大都依托在已有的实验基础之上，算是站在了巨人的肩膀上更进一层。&lt;/p&gt;&lt;p&gt;AI 带来的学术突破似乎已经将重点从学术转变为了 AI，各类大模型、智能框架的产生，都是为了方便研究者快速完成实验、达到理想中的结果。这并非不是 AI 所带来的时代红利，但人类总要保持对探索未知的热忱。&lt;/p&gt;&lt;p&gt;论文中表示，分析的局限，包括识别方法可能遗漏未明确提及的 AI 使用、主要聚焦自然科学而未涵盖人文社科等。生成式 AI 的影响也尚数据来充分评估。但在&amp;nbsp;AlphaFold、自动化实验室和大模型辅助写作不断加速科研的当下，这种张力，可能正是未来科学必须正视的问题。&lt;/p&gt;&lt;p&gt;相关报道：&lt;em&gt;https://www.science.org/content/article/ai-has-supercharged-scientists-may-have-shrunk-science&lt;/em&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，喝到了千问APP给我点的奶茶</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 13:23:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/403bc2e2-1837-4c41-99d5-9b540bfad168/1768454199805.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2026 一开年，智能体的发展立马进入狂奔状态。&lt;/p&gt;&lt;p&gt;本周二，Anthropic 发布 Cowork 掀起了打工人的革命。它不再像 Claude Code 一样专门面向程序员，而是把大模型与智能体能力推进到电脑桌面上，可以解决大部分人的工作问题。&lt;/p&gt;&lt;p&gt;同一时间，谷歌联合 Walmart 等零售商推出了一项专为智能体购物场景设计的开放标准 &amp;mdash;&amp;mdash; 通用商务协议（UCP）。此举旨在推动智能体购物全流程的标准化，实现从商品推荐、购买决策到支付结算的无缝衔接。&lt;/p&gt;&lt;p&gt;1 月 15 日上午，千问又前进了一大步，已经准备让智能体全面接管我们的日常生活了。&lt;/p&gt;&lt;p&gt;这一次，&lt;strong&gt;千问 App 上线了全新 AI Agent 能力「任务助理」，同时全面打通阿里生态，一次开启了 400 多项新功能&lt;/strong&gt;，邀请测试与灰度上线已经同步开启，全都是免费可用的。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528421" data-ratio="0.5564814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDpTYZvbIZoLJGkNGjYxeE7zibEicKqk4ItZAViaJ9ibGTdbwdhPQxibxxiazA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/66817256-da70-4ccb-8c82-d441010c7335/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 千问 C 端事业群总裁吴嘉&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;国内最强的 AI 模型，与最全的应用生态，现在合而为一了。&lt;/p&gt;&lt;p&gt;现在，你只需要对 AI 说「我要两杯奶茶」，千问就可自动找到相应的店铺，选好你的地址、选好商品、下好订单，你只需要点击最终的支付即可。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528423" data-ratio="2.062222222222222" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDbORxXCibZXrQOqJazsARXlqTyTVib1DVSmtySEHDhBBtBuCcAlZYBoHQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-type="gif" data-w="450" type="block" data-original-style="width:404px;height:833px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/449fd024-d31d-4afd-b95d-d034c0d90a90/640.gif" data-order="0" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;如果你想买点什么东西拿不定主意，也可以和千问「任务助理」商量一下，它不仅可以讨论出个符合需求的结果，而且可以直通商店的付款链接。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgnSNwY2fIZaEkgxe4M68LyWWrFd3pvg0hlR6FChzDYMjHn0xfWcfuQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="2.0625" data-s="300,640" data-type="gif" data-w="400" type="block" data-imgfileid="503528424" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a7b1ad6b-b72c-47db-a9f8-5496a3c5e07f/640.gif" data-order="1" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;可以看到，千问能够接入的应用包括淘宝、闪购、飞猪、高德地图和支付宝。如果你有需要，千问还能帮你打电话。在发布会现场，千问就展示了 AI 帮人订餐，看起来餐厅老板没有认出与他交谈的是千问。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528425" data-ratio="0.3527777777777778" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDYfzLEV6hibXQKPHEabsLpjqKqRSh7ZXNMiceXPicE0siaWt1JO0o5aIU7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a888f7df-8072-4808-b391-3149cd7b1d61/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了各种有意思的功能，我们也初步体验到了 AI 智能体带来的交互革命 &amp;mdash;&amp;mdash; 强大的千问模型，正在把阿里独有的生态优势全部并联起来。不论生活还是工作，以后通行的方法，或许都会被 AI 重新整理一遍。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528428" data-ratio="0.6666666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD1aQ5QwIjsqMJ8zicTdyjyNIiaTKMNLiahHjpWXdggk1dxUBV1l8AQhlCQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/0760db6c-ab57-4215-93a6-7d1f8fdbed8b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;一手实测 &amp;nbsp;触角已经碰到了物理世界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;刚过去的 2025 年被普遍视为智能体元年，智能体在人工智能领域的热度一直没有断过。从 Manus、ChatGPT Agent 到更多国产 Agent 大模型与应用，几乎每一次发布都会引起轰动。&lt;/p&gt;&lt;p&gt;智能体的出现，让大模型从拥有智能「大脑」进化出灵活的「手」和「脚」，对复杂任务的自动分析、拆解、执行能力与日俱增。有了智能体的参与，人们可以从繁冗的流程性工作中解放出来，大大节省了工作量与时间成本。&lt;/p&gt;&lt;p&gt;在全面接入一众阿里生态业务之后，千问 App 上的这个智能体新面孔能带来哪些不一样的东西呢？带着这个疑问，我们在拿到内测资格之后，马上对它来了一次摸底测验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多品牌团购不在话下&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在上文，我们已经见识到千问「任务助理」点奶茶的便利。接下来的实测中，我们给它上上难度，看能不能搞定多品牌、跨店铺的团购任务。&lt;/p&gt;&lt;p&gt;团购不同牌子的奶茶通常需要我们进入购物 App 并一一查找、浏览对应牌子的奶茶店，还要确认店中有没有自己想要的口味，这会浪费不少时间。在将类似的任务交给千问「任务助理」后，一切的麻烦都没有了。&lt;/p&gt;&lt;p&gt;我们输入指令「帮我点 3 杯霸王茶姬，5 杯瑞幸，8 杯茶百道」，它在确认你的收货地址之后会首先询问你的口味需求。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528435" data-ratio="1.776470588235294" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDVsULfyDOe1ia18IlUDCSka7gcPtq7hUiaufGq9FtZUTocDkibskT4tctg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-type="gif" data-w="340" type="block" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e930a75d-168f-4b72-beb6-2cecf4ba2512/640.gif" data-order="2" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在确认你有无特殊的口味需求之后，它便开始马不停地自动跑完接下来的所有流程，包括&lt;strong&gt;分析用户点单需求、核对点单数量、以及搜索并获取购物平台（这里是淘宝闪购）商品信息&lt;/strong&gt;。随着一系列内外部信息被它吸收消化，紧接着会进入到制定最佳点单方案的环节。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528433" data-ratio="1.776470588235294" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD5OERstLwydwoj6ibjaTnHXtFk3dTjiaQJUHcpS1rEmzqEGibicPzS9k5TA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-type="gif" data-w="340" type="block" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f7d769c0-246c-4ed4-a917-9d61b454e0d3/640.gif" data-order="3" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在制定点单方案时，它会根据距离的远近等因素自动为你匹配合适的商家，并初步完成满足你需求的商品筛选与推荐。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528436" data-ratio="1.0212962962962964" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoD46Wawc1oqia4baP8Z47ke1AkCP7n92lj060GvUrTPQKKE85nGwpRCXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/c71f9e2d-7af9-43a8-8ce7-ee01a73c14d3/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;一套丝滑连招下来，它为我们推荐了&lt;strong&gt;三种差异化的方案&lt;/strong&gt;，或想更快收到货、或是选择评分高销量高的门店、或想要订单中包含更多样的饮品种类。这些潜在的用户意图被它精准地捕捉并考虑进来，转化为对应的优先级推荐方案。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528434" data-ratio="1.7377049180327868" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDxlelEqQJ1xt38aaEhJo6qBbypa2ZUJ7QlyiclibLrib2LaGwe76gdBfLw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-type="gif" data-w="366" type="block" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/e7f66bba-15ce-4b73-9662-2e99948340f9/640.gif" data-order="4" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;最后一步，凭自己的喜好下单付款即可。整个操作过程中，除了在有特殊口味需求时需要你的手动介入，其他时候全权交给千问「任务助理」就行了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定制旅游计划一气呵成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前几天，「威海暴雪」的新闻登上了微博热搜，让这座滨海城市闯入了人们的视线。提起山东，大家可能更多地想到青岛。相比之下，威海的名气没有那么大。但从网上的口碑来看，威海以「小而美」著称。&lt;/p&gt;&lt;p&gt;带着对这座城市的好奇，我们让千问「任务助理」制定一份 1 月 16 日（这周五）北京出发的威海两日游计划。&lt;/p&gt;&lt;p&gt;在接收到任务之后，它便自动进入到了任务规划以及逐步的任务执行流程。首先会对我们的需求进行一个整体分析，将威海的景点、美食、住宿等因素统统考虑进来，并启动&lt;strong&gt;搜索子任务&lt;/strong&gt;，即调用搜索工具查询相关的背景知识。&lt;/p&gt;&lt;p&gt;通过不间断地搜索、查询多类型网络来源（包括门户网站新闻、旅行社区热帖等）的威海旅游攻略，尽可能地确保信息准确可靠。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528430" data-ratio="1.7868852459016393" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDmhkiaXoAibooZkvicNx0cw5btgGLmhsudEA0ypich8nfEgYEKXG2IVMsaA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-type="gif" data-w="366" type="block" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/706050e0-5f0c-43e8-933a-ed9deb7fc905/640.gif" data-order="5" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;紧接着，根据筛选后的优质搜索结果，它为我们规划详细的两日游行程，这里全程对&lt;strong&gt;高德&lt;/strong&gt;和&lt;strong&gt;飞猪&lt;/strong&gt;进行了调用。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDicIRyRMJfdiaB0g8A28oYw7IPfJicgCrhTbk5XxvIQwzSkw6uk2aeqFxQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.5944444444444444" data-type="gif" data-w="1080" type="block" data-imgfileid="503528431" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/52019515-e9e5-42c9-a1d7-231215af99ae/640.gif" data-order="6" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最终在整合所有行程信息之后，它在高德地图上呈现出了两条交互式路线图。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDBVt8lYxNRn2G3aHYPS875VEWc2IcUzpbibcbrDWq8wxEkWr72YDVObw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.4444444444444444" data-type="gif" data-w="1080" type="block" data-imgfileid="503528427" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/afdfc4b7-0880-4eb0-b717-4074fd6d9c05/640.gif" data-order="7" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;完整的威海两日游计划出来之后，我们发现，不仅囊括了威海热门景点，还兼顾自然风光与历史文化，并综合考虑了预算成本与游玩体验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDic6TkNZ0Ez4d5116aNqleK2b8A4AKwneL2h8AIuwo42ib7jpeXOmKpPQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.6370370370370371" data-type="gif" data-w="1080" type="block" data-imgfileid="503528432" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/7682f914-ac05-49fa-badb-a073c8646ddb/640.gif" data-order="8" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在生成的行程计划中，你既可以一键跳转高德来导航去某处景点的路线并一键打车，也能跳转飞猪去订景区门票和酒店。&lt;/p&gt;&lt;p&gt;在日常购物、旅游规划之外，千问「任务助理」擅长的事情还有很多，比如&lt;strong&gt;政务场景&lt;/strong&gt;，在接入支付宝政务服务之后，只需用户一句话就能快速完成政策解读、材料清单梳理等步骤，覆盖办签证、查社保等等场景，并直达办理入口，效率高得惊人。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDzm7qdasXjU8iag2qzxdq1pmgpNZzduq3SnkrLPkrficlPZW7qiaO2XjrA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-ratio="1.9095477386934674" data-type="gif" data-w="398" type="block" data-imgfileid="503528429" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/7af25a5d-5bb2-4a38-bc8b-9700352dfc7f/640.gif" data-order="9" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;简单的几个任务测下来，我们感受颇深的一点是：在交互方式上，以前我们是与大模型「对话」，现在是给智能体「派单」。只需要给出任务，然后等待结果即可。该说不说，这才是智能体真正的定义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;千问 AI 助手 &amp;nbsp;有一套「拟人化」思考架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;千问不仅是能点外卖这么简单，千问「任务助理」已经完成了一套基于通用 Agent 体系的底层重构。&lt;/p&gt;&lt;p&gt;首先，&lt;strong&gt;千问 App 采用了一套全新的通用 Agent 体系&lt;/strong&gt;。它基于 MCP 和 A2A 协议，在其中，主 Agent 作为指挥者，它基于千问最强模型拆解和规划任务；子 Agent 作为执行者，它们是多个具有反思能力的智能体，在其领域具有完全决策执行的权限，可以根据任务情况动态纠偏。&lt;/p&gt;&lt;p&gt;这套范式实现了高效的分层规划，在特定任务领域上也可以保证正确的决策，大幅提升了跨领域、长链路的复杂任务执行效率和准确率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;千问深度重构了 Agent 的原生能力栈&lt;/strong&gt;。不同于目前流行的基于视觉识别（GUI）的 Agent 路线，千问选择了更加直接的协议打通，提升了 Agent 在执行任务时的精度和效率，在隐私安全上也更有保障。为了进一步提升效率，千问还专门为 AI 进行了工具栈的重构。&lt;/p&gt;&lt;p&gt;比如在搜索时，Agent 能够自主选择不同的搜索方式，或是进行并发搜索；操作浏览器的 Agent 经过了专门训练，结合阿里自研浏览器内核，具备毫秒级响应和极高的交互精度；在处理可视化、写小程序或复杂表格时，智能体会检索、对齐经过验证的成熟代码范式，确保产出结果具备「工程级」稳定性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「任务助理」多层 Agent 的系统，深度集成了阿里自家生态的各种应用、工具&lt;/strong&gt;，大量的应用会被拆解成原子化的指令级，确保了工具调用的准确。在跨场景任务上，系统能够正确地感知实时的位置、价格等时效信息，减少了大模型常见的幻觉问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;千问的 Agent 系统还具备可以持续演进的能力。&lt;/strong&gt;在完成任务之后，Agent 并不是就结束工作了，而是会像人一样进行「反思」并沉淀经验，让 Agent 可以持续进化。实践的经验会被转化为结构化经验库，作为先验知识在后续任务中动态加载。&lt;/p&gt;&lt;p&gt;这样，AI Agent 就可以逐渐具备人类的工作直觉。&lt;/p&gt;&lt;p&gt;最后，&lt;strong&gt;通过 AI Coding 的能力，千问现在可以在执行任务时发动 AI 生成代码能力现写工具&lt;/strong&gt;。前面说到在大量任务上，Agent 可以实现精准的识别与操作。而在比较少见的任务上，千问的 Agent 可以启动 Agentic Learning 机制，自主编写、测试并封装新的原子工具。随着人们的使用，千问「任务助理」的能力会持续增强。&lt;/p&gt;&lt;p&gt;前天 Anthropic 发布的 Cowork，据说是十天之内用 AI 生成代码能力写出来的。看起来现在千问把类似的能力已经给你集成在智能体上了。千问表示，目前在数百个常用工具中，有超过一半是由 AI Coding 编程自主生成的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体的 AI 革命 &amp;nbsp;已经开始了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今年，AI 领域正在进入产品爆发的阶段。&lt;/p&gt;&lt;p&gt;仅在 1 月份，业界就出现了 Anthropic 的 Cowork，OpenAI 的 ChatGPT Health 等一系列新产品。各家科技公司正在快速兑现 OpenAI 总裁 Greg Brockman 对于智能体在企业、专业领域落地的预言。&lt;/p&gt;&lt;p&gt;刚刚千问的新发布，更是把智能体拉近到了我们身边：它能用快速精准的方式连接最常用的 App，让 Agent 进入到你生活的每一步。在国内，能做到覆盖如此全面的生活场景的公司，还真的只有阿里，其生态囊括了购物、出行、支付、办公等方方面面。&lt;/p&gt;&lt;p&gt;我们能够看出，目前这些 Agent 能力还显得比较简单 &amp;mdash;&amp;mdash; 正如第一代 iPhone 功能的简单并没有掩盖其划时代的意义一样，千问 APP 今日的推出，也许就像是智能体的 iPhone 时刻。从鼠标点击到手指触控，再到自然语言对话的交互方式升级，从这场发布开始打响了第一枪，人与机器的关系也进入到了第三次革命的关口。&lt;/p&gt;&lt;p&gt;当 AI 开始帮你整理发票、规划行程、甚至下单买咖啡时，它不再是云端那个高冷的「先知」，而变成了身边能干活的「助理」，这是 AI 从「言」到「行」的分水岭。&lt;/p&gt;&lt;p&gt;千问，会像淘宝开启移动互联网时代那样，开启一个全新的 AI 时代吗？我们拭目以待。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>人脸机器人登上Science Robotics封面：用AI教会仿生人脸机器人「开口说话」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 13:13:46 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3db839cc-d9a6-4a2c-844b-6c2b943df2b3/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;胡宇航（网名 &amp;ldquo;U 航&amp;rdquo;），毕业于美国哥伦比亚大学，博士学位，首形科技创始人。长期专注于机器人自主学习的研究工作。研究成果发表于《Nature Machine Intelligence》，《Science Robotics》等国际顶级期刊。致力于赋予机器人 &amp;ldquo;自我模型&amp;rdquo; 能力，即构建对自身物理结构与运动的内部表征，使机器人能够更好地理解自身，并适应多变的形态、环境与任务。在仿生人机交互方向，他提出融合语音、视觉与动作的情绪理解与表达一体化系统，为机器人提供更加自然的交互能力。通过自监督学习机制，他的方法使机器人在无需人工干预的情况下不断提升人机互动质量，朝着具备终身学习能力的智能体不断迈进。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528356" data-ratio="0.38055555555555554" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDnxq8JDb1txO71452AibDTYrw4upDGtiaQb7FcuyuCJkFXBAL8nB7LGxg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/960fdfdc-fae0-4db7-887e-403f7e494a29/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文地址：https://www.science.org/doi/10.1126/scirobotics.adx3017&lt;/p&gt;&lt;p&gt;曾发表论文：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Hu, Yuhang, et al. &amp;quot;Human-robot facial coexpression.&amp;quot; Science Robotics 9.88 (2024): eadi4724.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hu, Yuhang, Jiong Lin, and Hod Lipson. &amp;quot;Teaching robots to build simulations of themselves.&amp;quot; Nature Machine Intelligence (2025): 1-11.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://mp.weixin.qq.com/s/HdnbBweZseTjMedyWHDLSg&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2026 年 1 月 15 日，一项来自美国哥伦比亚大学工程学院的突破性研究正式发表于《Science Robotics》，并登上期刊封面。该研究展示了一项全新的机器人技术：一台具备仿生面部结构的人形机器人，通过深度学习实现与语音和歌曲同步的真实唇部运动。它能跟着人类的语言精准张合嘴唇，甚至，能跟着音乐唱歌。标志着人形机器人在人类最丰富的交流通道之一&lt;strong&gt;唇部表达&lt;/strong&gt;上，迈出了突破性一步。&lt;a href="https://mp.weixin.qq.com/s/BySG2N_jsBf8XsB7v4-SOg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e6fd90e9-df68-431b-b850-b7ec4041c5fd/1768453840414.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;为什么 &amp;ldquo;嘴唇&amp;rdquo; 如此重要？&lt;/p&gt;&lt;p&gt;研究显示，在面对面的交流中，人类将近一半的注意力集中在唇部运动上。我们或许能容忍机器人走路笨拙、手部动作僵硬，但&lt;strong&gt;哪怕极其轻微的不自然面部表情，都会立刻引发本能的不适&lt;/strong&gt;。这正是著名的 &amp;ldquo;恐怖谷&amp;rdquo;。&lt;/p&gt;&lt;p&gt;长期以来，即便是最先进的人形机器人，在 &amp;ldquo;说话&amp;rdquo; 时也只能做出类似木偶的张合动作 &amp;mdash;&amp;mdash; 如果它们有脸的话。但这一次，情况正在发生改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一个会自主学习表情的机器人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这项研究中，研究团队打造了一张高度仿生的机器人面孔：&lt;/p&gt;&lt;p&gt;在一层柔性硅胶皮肤之下，隐藏着&lt;strong&gt;&amp;nbsp;20 余个微型电机&lt;/strong&gt;，能够快速、安静且协同地驱动唇部形变。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528352" data-ratio="0.6361111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDsCy3zFQRicRlLxHZS47dkecA9f9KCk2qXeuJmGYpiaAOZIumc9JSZQZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/38af39e9-41cf-4096-afb4-4866494297f3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2. 机器人唇形硬件结构。（A）面部机器人设计概览，重点展示了人机交互关键组件：包括扬声器、麦克风、高清摄像模块，以及用于固定柔软硅胶面皮的磁吸式快拆连接器。该连接器能实现面皮的精准定位，并通过推拉双向运动驱动硅胶面皮，完成说话时所需的复杂唇部动作。（B）搭载柔软硅胶面皮的人形机器人外观展示。其底座内部集成有边缘计算设备。（C）唇部驱动系统特写，展示上唇、下唇与唇角连接器分别对应固定于相应唇部支架。柔软可替换的面皮通过磁吸连接器固定，可便捷拆卸以进行维护或个性化调整。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;随后，机器人被 &amp;ldquo;带到镜子前&amp;rdquo;&amp;hellip;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就像一个第一次对着镜子学做表情的孩子，机器人通过观察自己面部在不同电机驱动下的变化，构建 Facial Action Transformer (FAT) 模型，逐渐学会如何控制自己的脸（机器人自我建模 Robotic Self-modeling)。研究团队将这一过程称为一种 &lt;strong&gt;&amp;ldquo;视觉 &amp;mdash; 动作&amp;rdquo; 的自监督学习&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528353" data-ratio="0.45740740740740743" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDvxzRJ7S84CvoUy65ibZ9lyBIhicQlqh3CiaoLN1tm1xMUjSRgXG1Zc75w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1baf7b37-25b4-4960-a1f1-94ec0738725a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3. 机器人能实现的口型及其对应音标展示。该机器人展示了再现关键英语音标的能力，例如爆破音（/p/ 和 /b/）、双唇音（/m/）以及圆唇元音（/u/ 和 /o/）。通过独立控制上唇、下唇及嘴角，每帧图像均捕捉到其实现的典型唇部运动效果。这些数据为机器人在说话时实现正确的唇形匹配奠定了基础。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依靠纯声音驱动嘴形动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;接着，机器人通过观看合成的机器人视频（通过 Wav2Lip）在不同语音语料（由 TTS 和 ChatGPT 生成）的真实唇部变化，进一步学习&lt;strong&gt;声音与唇部运动之间的对应关系&lt;/strong&gt;。最终，这两种能力被整合在一起 &amp;mdash;&amp;mdash; 机器人得以将收到的声音信号，直接转化为连续、自然的唇部运动。无需理解语义，机器人已经能 &amp;ldquo;对得上口型&amp;rdquo;。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528354" data-ratio="0.4601851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgmZPRIx2vjsQwRiagZgIeehaz5XsfiaDDQMNtlVyJTJl8D2JibZkDOkaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/bea0b7dd-4325-44ac-bb20-def2f2f4f14b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4. 机器人唇形同步的自监督学习框架。 (A) 数据收集阶段：机器人通过与语音相关的随机指令自主生成数据集，利用 RGB 摄像头捕捉广泛的唇部运动，以获取 3D 唇形数据。(B) 部署过程：始于来自 ChatGPT 的文本输入，文本被转换为音频，随后利用 Wav2Lip 技术合成机器人视频。利用真实机器人视频及其对应指令，训练由编码器和解码器（VAE）组成的机器人逆向变换器，以生成平滑、准确、可供真实机器人执行的电机指令。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多语言能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队测试了机器人在多种语言、不同语音环境甚至歌曲中的表现。结果显示，即使在复杂的语音节奏下，机器人也能完成连贯的唇部同步，甚至演唱来自其 AI 生成的曲目。&lt;a href="https://mp.weixin.qq.com/s/BySG2N_jsBf8XsB7v4-SOg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9d830db5-e21b-4894-b2f2-4c5fa7efcbdc/1768453913455.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 机器人多语言口型对齐能力&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528355" data-ratio="0.375" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDiaATHafTyLYwmdkhRdwWM7uibKKev13w8AE0LBlcj1JrcbH6feTH8gOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/77feb593-4b24-4d72-afa3-6d52fbc72995/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5. 多语言唇语同步性能量化表现。x 轴标签下方标注的样本量 n 对应每种语言的测试句子视频帧数。结果表明，所有非英语语言的同步误差均保持在英语误差范围内，显示出稳健的跨语言泛化能力。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;当然，这还不是终点。研究者坦言，像 &amp;ldquo;B&amp;rdquo; 这类需要完全闭唇的音，以及 &amp;ldquo;W&amp;rdquo; 这类涉及明显撮唇的发音，仍然存在挑战。但关键在于 &amp;mdash;&amp;mdash; &lt;strong&gt;这是一种可以随着学习持续进化的能力，而不是写死的规则。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;跨越恐怖谷的 &amp;ldquo;缺失环节&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在研究者看来，面部表情 &amp;mdash;&amp;mdash; 尤其是唇部的自然运动，正是长期以来机器人能力中的 &amp;ldquo;缺失环节&amp;rdquo;。&amp;ldquo;当前的人形机器人更多关注行走和抓取，但凡是需要与人面对面交流的场景，面部表达同样关键。&amp;rdquo;&lt;/p&gt;&lt;p&gt;随着人形机器人逐渐进入娱乐、教育、医疗、陪护等高度依赖情感沟通的领域，一张温暖、自然、可信的&amp;lsquo;脸&amp;rsquo;将不再是加分项，而是入场券。经济学家预测，未来十年全球或将制造超过十亿台人形机器人进入人们的生活场景。而几乎可以确定的是 &amp;mdash;&amp;mdash; 它们不可能都没有脸。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从实验室走向现实&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项封面研究，不仅是一次学术突破，也展示了中国学者在国际人形机器人领域具备独特的创新能力。&lt;/p&gt;&lt;p&gt;第一作者胡宇航博士表示，当唇部同步能力与对话型大模型结合时，机器人与人类之间的连接将发生质变。&amp;ldquo;我们交流中有大量情感信息并不在语言本身，而在面部和身体语言中。机器人正在开始触碰这条通道。&amp;rdquo;&lt;/p&gt;&lt;p&gt;当机器人真正学会像人一样 &amp;ldquo;说话&amp;rdquo; 和 &amp;ldquo;表达&amp;rdquo;，&lt;/p&gt;&lt;p&gt;恐怖谷，正在被一步步填平。&lt;/p&gt;&lt;p&gt;人类与机器人的信任和情感，将会迎来新的篇章。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>实测夸克「千问划词快捷指令」，这7个邪修Prompt，建议收藏</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 12:11:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/110f143e-0454-429b-b66b-6597f05f6ef0/1768449877316.png" style="width: 700%;" class="fr-fic fr-dib"&gt;新年第一天，DeepSeek 发布了一篇艰深晦涩的技术论文，不少网友直呼「看不懂」。&lt;/p&gt;&lt;section data-clipboard-cangjie='["root",{},["p",{"jc":"center","uuid":"mk2gmj7aweyieukbrpn"},["img",{"src":"https://alidocs.dingtalk.com/core/api/resources/img/5eecdaf48460cde5168d798d8b874f4f0f3eb7ebad2f178375b8339e1c4c24833998745b666af745115b5d1153adab25a156a98577f418d5b7c4b67b1ed0eaebdfca5b38285a1f63ec564bff80fdc5574f77387d2e13df021f0ef096c4d55c51?tmpCode=f00bcf97-2b0f-4aad-8d0e-776a3b6d2398","width":746,"height":523.275657336726,"uuid":"mkdfb33mb664v67jyo9","extraData":{"resourceId":"7f12b51b-0f64-4a2f-bbbf-ce8ad418a0e6","metaData":{"size":168183,"originWidth":1179,"originHeight":827,"format":"jpg","ratio":1}}},["span",{"data-type":"text"},["span",{"data-type":"leaf"},""]]]]]' data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMmpjJTIyJTNBJTIyY2VudGVyJTIyJTJDJTIydXVpZCUyMiUzQSUyMm1rMmdtajdhd2V5aWV1a2JycG4lMjIlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyaW5saW5lJTIyJTJDJTIydHlwZSUyMiUzQSUyMmltYWdlJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnNyYyUyMiUzQSUyMmh0dHBzJTNBJTJGJTJGYWxpZG9jcy5kaW5ndGFsay5jb20lMkZjb3JlJTJGYXBpJTJGcmVzb3VyY2VzJTJGaW1nJTJGNWVlY2RhZjQ4NDYwY2RlNTE2OGQ3OThkOGI4NzRmNGYwZjNlYjdlYmFkMmYxNzgzNzViODMzOWUxYzRjMjQ4MzM5OTg3NDViNjY2YWY3NDUxMTViNWQxMTUzYWRhYjI1YTE1NmE5ODU3N2Y0MThkNWI3YzRiNjdiMWVkMGVhZWJkZmNhNWIzODI4NWExZjYzZWM1NjRiZmY4MGZkYzU1NzRmNzczODdkMmUxM2RmMDIxZjBlZjA5NmM0ZDU1YzUxJTNGdG1wQ29kZSUzRGYwMGJjZjk3LTJiMGYtNGFhZC04ZDBlLTc3NmEzYjZkMjM5OCUyMiUyQyUyMndpZHRoJTIyJTNBNzQ2JTJDJTIyaGVpZ2h0JTIyJTNBNTIzLjI3NTY1NzMzNjcyNiUyQyUyMnV1aWQlMjIlM0ElMjJta2RmYjMzbWI2NjR2NjdqeW85JTIyJTJDJTIyZXh0cmFEYXRhJTIyJTNBJTdCJTIycmVzb3VyY2VJZCUyMiUzQSUyMjdmMTJiNTFiLTBmNjQtNGEyZi1iYmJmLWNlOGFkNDE4YTBlNiUyMiUyQyUyMm1ldGFEYXRhJTIyJTNBJTdCJTIyc2l6ZSUyMiUzQTE2ODE4MyUyQyUyMm9yaWdpbldpZHRoJTIyJTNBMTE3OSUyQyUyMm9yaWdpbkhlaWdodCUyMiUzQTgyNyUyQyUyMmZvcm1hdCUyMiUzQSUyMmpwZyUyMiUyQyUyMnJhdGlvJTIyJTNBMSU3RCU3RCU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJ0ZXh0JTIyJTJDJTIybGVhdmVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJsZWFmJTIyJTJDJTIydGV4dCUyMiUzQSUyMiUyMiUyQyUyMm1hcmtzJTIyJTNBJTVCJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTJDJTIyY29udGVudFR5cGUlMjIlM0ElMjJjYW5namllLXRleHRibG9jayUyMiU3RCU1RCU3RA==" data-identifier-application__slash__x-doc-key="8K4nyeZ46Y2Y5nLb" data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicF8hyA8EDOLbjWjcIehg1cMAwlX2qlOiak8p7ibxI4an9j2rOn8mboPzQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.7018518518518518" data-type="jpeg" data-w="1080" data-imgfileid="503528201" data-aistatus="1" data-original-style="width:358px;height:251px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b7d9feb4-53a6-4273-8029-325883d11eca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;于是，机器之心评论区出现了集体求助 AI 的一幕：有人让 AI 用八十岁老太太能听懂的方式解释，有人要求用大白话翻译，还有人直接说「当我是幼儿园小朋友，给我讲明白」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicfj7xcdHvpLyIEkg9ib4ICl8slDbQKymmbP4ZN6P6fqdQ82mLibJZw0vw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.39814814814814814" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="230" data-imgfileid="503528219" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2f74b96e-3ce9-4df9-a2e6-1423991a420f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这场景既搞笑又真实。如今，我们面对复杂信息时，第一反应已经是向 AI 求援，而非硬啃。但问题来了，同样是使用 AI，有些人总能得到精准、高质量的回答，而有些人却总在和 AI「鸡同鸭讲」。&lt;/p&gt;&lt;p&gt;这样的体验让不少人对 AI 的智能程度产生怀疑，抱怨 AI 不够聪明、听不懂人话、是个「智障」。可事实并非如此，问题可能出在我们的提问方式上。&lt;/p&gt;&lt;p&gt;一个完美的指令，关键在于让 AI 确认它是否真正理解我们的需求，这就是为什么网上会流传各种提示词模板，这些经过反复打磨的指令，往往能让 AI 输出质量提升好几个 level。&lt;/p&gt;&lt;p&gt;不过，新的痛点也随之而来，这些高频使用的指令，每次都要从头输入一遍，不仅浪费时间，还容易因为表述不同导致效果不稳定。&lt;/p&gt;&lt;p&gt;如果有一个方法，能把这些指令变成一键调用的快捷键，会怎样？&lt;/p&gt;&lt;p&gt;最近，夸克 AI 浏览器功能更新，&lt;strong&gt;「千问划词」支持自定义快捷指令&lt;/strong&gt;。如果你常常需要对文稿进行内容润色、检查、优化，只需提前设置好常用的提示词，就能开启更精准、更快捷的划词体验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicia7EfnD7yZ00rYibhZuYv3uKN1k7daSjl0h8MVwqmayaKFvgx2uhM2RA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6407407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="370" data-imgfileid="503528328" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d9116190-27e1-4528-9524-bbf1c4655d2b/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;简单来说，就是把那些已经验证过、效果很好的提示词固定下来，需要时一键调用。&lt;/p&gt;&lt;p&gt;用法也很简单，我们只需&lt;strong&gt;在设置里找到「划词工具栏」，点击「添加自定义指令」，输入常用指令&lt;/strong&gt;，比如「请将以下内容翻译成中文：{selection} 要求翻译准确流畅，符合中文表达习惯，避免生硬直译」，再给指令起个名字，专属指令就设置成功了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicOoZKZW1mXSpzOSPUgiaSwXAYXicmLic1bcM6Z0AQvnbJThwQeg2bibqBCw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.6404077849860983" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="370" data-imgfileid="503528302" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/cbdbce4e-a6bd-451c-9be0-3d21ea6a5d88/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;这里提一嘴，输入常用指令时系统有一套规则：需使用 {selection} 来表示划词选中的文字。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;后续在浏览网页或文档时，遇到需要协助翻译、润色、检查的段落，只需轻轻划选，指令即可一键使用，告别复制粘贴、重复手动输入的麻烦。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测：用夸克 AI 浏览器玩转 100 个指令&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说实话，很多人觉得 AI 难用，就是被那些长到记不住的提示词给劝退的。既然如此，不妨交给浏览器来记。&lt;/p&gt;&lt;p&gt;最近，我们对着夸克 AI 浏览器疯狂实测了一波，从中精选出 7 类最实用指令，接下来全是干货。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;邪修提示词&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最近，博主「张咋啦 zara」分享了一个超好用的邪修 Prompt：tell me what you need from me to do this well。翻译过来就是「为了执行好这个任务，你需要我给你提供什么？」&lt;/p&gt;&lt;p&gt;她表示，AI 背后的人格是个助手，而助手的第一要务是满足用户需求，很多时候 AI 不好意思跟我们提需求，这就导致当我们给 AI 的上下文不够完整时，它就瞎干，最终交付的结果自然无法达到我们的预期。&lt;/p&gt;&lt;p&gt;所以，我们可以主动询问 AI 的需求，然后再想方设法满足，执行效果会好很多。&lt;/p&gt;&lt;p&gt;我们索性用夸克 AI 浏览器的「千问划词 - 快捷指令」试试。当然 Prompt 也根据具体使用场景，改得稍微具体了些：&lt;/p&gt;&lt;p&gt;「我需要你帮我润色以下内容：{selection} ，为了执行好这个任务，你需要我提供什么额外信息？请列出你需要了解的关键要素，以便给出最优质的回答。」&lt;/p&gt;&lt;p&gt;设置好后，我们拿《马斯克的「移动客厅」又火了：20 人座无方向盘，每公里才 3 毛钱》这篇文章进行测试。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiclViaOmBdayvU8pDibGaHaNqvvyUGpQ8jXasLk10xkvtKtqPicA313IPnA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-ratio="0.64" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="370" data-imgfileid="503528301" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1f827b59-5120-46b6-b29d-fa43f6b087f2/640.gif" data-order="1" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;AI 终于大大方方提出疑问：目标受众、发布平台、侧重表达的观点以及语言风格分别是什么，还贴心地举了例子。得到回答后，刷刷几下子润色版本就出来了，在保留核心信息基础上，语言更具网感。&lt;/p&gt;&lt;p&gt;有一说一，&lt;strong&gt;让 AI 先问清需求，再精准输出，比直接让它润色效果好太多&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;毒舌大师&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;国外一博主也摸索出 AI 的一些骚操作。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/61201ac8-2369-4b3e-a202-c434ecaa8f27/1768449983247.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;一般来说，AI 总爱跟我们假客气，说啥它都顺毛捋，所以该博主给 AI 立了个毒舌导师的人设，我们反手就将这个提示词设置为夸克 AI 浏览器的划词指令：&lt;/p&gt;&lt;p&gt;「你是我冷酷无情的导师，别跟我绕弯子。请严格批评以下内容：{selection}，要求是如果想法烂透了，就直接说这是垃圾。你的工作就是把所有问题都挑出来，直到我说无懈可击为止。批评完后，用一句话告诉我改进方向，然后帮我修改，能更吸引人。」&lt;/p&gt;&lt;p&gt;题好一半文。扒出之前写的一篇流量堪忧的文章，点击「毒舌大师」快捷指令搞个更吸引人的标题。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaichW5H4pPOfDS1ZgYkhfL5P1tq9hNUtRfahapdMOlRYTymLSDibavxPHg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.6425" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="371" data-imgfileid="503528244" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/264621b6-4024-416c-9cba-5b4e2a6c9ed3/640.gif" data-order="2" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;AI 毫不留情地开喷「主题不明确、信息陈旧、用词情绪化，更像是社交媒体的几句牢骚」。骂完就给出改进方向，并直接甩出修改版本。&lt;/p&gt;&lt;p&gt;AI 终于不跟我们装熟了，给的建议也更靠谱。以后编辑部谁写的东西自我感觉良好，就让这个毒舌模式喷一遍。&lt;/p&gt;&lt;p&gt;讲完邪修用法，我们再来看看工作学习具体场景。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人话翻译器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于很多机器之心读者来说，最头疼的场景之一，就是读那些不明觉厉的专业论文。&lt;/p&gt;&lt;p&gt;以上文提到的 DeepSeek 技术论文为例，网友求助 AI 的表述五花八门，但核心需求其实是一致的，那就是把复杂的学术内容转化为通俗易懂的表达。&lt;/p&gt;&lt;p&gt;我们可以用夸克整个「人话翻译器」划词指令：&lt;/p&gt;&lt;p&gt;「你是一位擅长科普的教育工作者，请用费曼学习法解释以下内容： {selection}，要求先用一个生活化的类比引入概念，再拆解核心逻辑，最后用一句话总结。语言要生动，避免术语堆砌。」&lt;/p&gt;&lt;p&gt;打开一篇论文，遇到看不懂的段落，划词选中，夸克 AI 浏览器&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;几秒钟就能给出通俗解读。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic18pZjzexMFlAr5A7A5GKYgCiaf3lsxpBbUq8o5v0YTWLZ9WqnNFrh2w/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.6275" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="363" data-imgfileid="503528232" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/f4e8a0e0-9aa3-485d-8f45-52adf905bac7/640.gif" data-order="3" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这比每次都要输入「用大白话解释」要精准得多，因为 AI 已经知道要用什么结构、什么风格来回答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文引用查找器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文党基本绕不过翻译、写作、修改、引用查询等环节，有了 AI 后，干这些活的效率直线上升，但用到的提示词来来回回也就那几个。这时，夸克的划词指令就派上用场。&lt;/p&gt;&lt;p&gt;举个例子。我们搞了个「引用来源查询」的划词指令：&lt;/p&gt;&lt;p&gt;「你是一位学术研究助手，精通文献检索。请针对以下观点或数据进行分析：{selection}，1）判断这可能属于哪个研究领域的哪个分支；2）推测可能的引用来源类型（奠基性理论文献、实证研究、综述文章、方法论文献）；3）提供搜索关键词建议；4）如果这是经典理论或常见观点，告诉我通常会引用哪些代表性文献或学者。注意：不需要提供具体论文链接，只需给我检索方向即可。」&lt;/p&gt;&lt;p&gt;想想以前核查引用来源，我们需要打开 Google Scholar，用各种关键词搜索，翻阅十几篇论文的摘要，判断哪些可能相关，再去下载 PDF 查看全文，最后才能确认是不是要找的那篇。一个引用来源，可能要花半小时甚至更久。&lt;/p&gt;&lt;p&gt;现在我们只需划词选中 DeepSeek 论文中一句话，点击「引用来源查询」，AI 不仅给出研究领域、来源类型、搜索关键词建议，甚至连代表性文献和学者也清晰罗列出来。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicibTKdpy4Ve5I2SI2CLd6wFMRRkACHHbkXKeRhfLpT8RdtArV5uYcNUA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.6275" data-type="gif" data-w="800" type="block" data-backw="578" data-backh="363" data-imgfileid="503528233" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/5571c13b-cf46-4974-9380-49c21c0cebc7/640.gif" data-order="4" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;后续我们沿着这个方向，再去 Google Scholar 检索，效率飙升。&lt;/p&gt;&lt;p&gt;AI 在提升效率的同时，还会提醒我们这个观点属于什么研究脉络、应该引用什么类型的文献，这对于学术新手来说特别有价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;爆款生成器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;至于内容创作者，千问划词 - 快捷指令就更有用武之地了。&lt;/p&gt;&lt;p&gt;以机器之心编辑部为例，同一个话题要在 X、小红书、微博等多个平台发布，但每个平台的调性和用户偏好完全不同。&lt;/p&gt;&lt;p&gt;以前的做法是，编辑写好原稿后，再手动改写成各种版本，每个版本都要重新调整语气、结构、表述方式。现在，我们用夸克的「千问划词 - 快捷指令」，就能针对不同平台定制不同的改写指令。&lt;/p&gt;&lt;p&gt;比如同样是「特斯拉 FSD 首次横穿美国，Model3 实现 1 万英里零干预」这一话题，小红书爆款生成器的生成结果更生活化、更有共鸣感。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicYHSdYEdXZp0CddIJyia1PiaptViaKPGG96zDMTB8B6SCV6cYdRlvFe3nQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.6425" data-type="gif" data-w="800" type="block" data-imgfileid="503528239" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/bb0f71ff-3034-4f38-86fb-db067c8a2aef/640.gif" data-order="5" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「小红书爆款生成器」的指令是：你是一位小红书爆款内容创作者，请把以下内容改写成小红书风格：{selection}，要求：1）开头用 emoji 和惊叹式标题吸引注意力；2）把专业内容转化为「对用户有什么用」的实用角度；3）多用短句和段落，每段不超过两句话；4）结尾加上互动引导（如「你会用吗？」「评论区聊聊」）；5）适当加入网络热词但不要过度；6）控制在 500 字以内。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;微博热搜体的表达则是短平快抓眼球。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-backh="358" data-backw="562" data-imgfileid="503528234" data-ratio="0.6376274328081557" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaic1rtHcqcYL1gBUjvjUVWp3jtN0DJIYWTORAGSliavzFVpMy2MElic5doQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=10" data-type="gif" data-w="1079" type="block" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/102376eb-4dc4-4dcb-89c7-2aa400cbaa1b/640.gif" data-order="6" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「微博热搜体」的指令是：你是一个专业的爆款微博大师，要求：1）用中括号【】先提炼最核心的信息做成一个标题；2）整体控制在 140 字以内；3）突出话题性和新闻感；4）加上 2-3 个相关话题标签；5）可以适当制造悬念引导点击链接。请把以下内容浓缩成一条微博：{selection}&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;X 平台则更偏向专业简洁。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicprqy0Bmh1Qic0dyFjZrEJp2ASc8hHU6G4YKSOQyLP7jd4L9eSjtX3sQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.6422613531047267" data-type="gif" data-w="1079" type="block" data-backw="562" data-backh="361" data-imgfileid="503528240" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/2868e7e3-c890-4ba9-a436-a3190717a7db/640.gif" data-order="7" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;「X 平台国际化表达」的指令是：请把以下中文内容翻译成英文并调整为国际用户的阅读习惯：{selection}，要求：1）语言简洁直白，避免中式思维的复杂从句；2）突出核心事实，少用形容词和情绪化表达；3）如果涉及中国特有的概念或梗，要加简单解释；4）保持科技媒体的专业度但不要过于学术化；5）控制在 280 字符以内。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;通过千问划词 - 快捷指令，一篇内容快速适配多个平台，大大节省了编辑和运营同事反复思考和修改的时间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不止于指令：一个更强大的 AI 浏览器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;千问划词 - 快捷指令只是夸克 AI 浏览器能力升级的一部分。&lt;strong&gt;在这次更新中，夸克表现出更大野望，即成为一个真正意义上的超级应用。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;夸克 AI 浏览器除了全面融合千问 AI 助手，实现全局桌面唤起 AI 的创新交互形态；在阿里 Qwen 大模型加持下，&lt;strong&gt;近期更是一口气上线了十多种模型，供用户自由选择&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicAD3IRlCumGzjjaKWhibhRSBZPjHt4vLMbDrfWYib6ic7p9Yoqt3ZevZsQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=12" data-ratio="0.6413345690454124" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="371" data-imgfileid="503528235" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/3b591fa0-955d-482d-9ff4-75d65e5d02e0/640.gif" data-order="8" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时它也支持语音、图片、文件等多模态输入。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicPiafzybyE6FVtick7ZOcop4oBMgJdqDXTz7et2IOE2MiaTdF2T0pW7wfA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.6413345690454124" data-type="gif" data-w="1079" type="block" data-backw="578" data-backh="371" data-imgfileid="503528236" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/adaf9836-6974-4b82-b21c-4e79083a08cd/640.gif" data-order="9" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 首页、侧边栏、快捷框等均可实现语音输入。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，&lt;strong&gt;夸克 AI 浏览器还内置一系列实用的 AI 工具&lt;/strong&gt;。这些工具组合起来，可以构建起一套完整的一站式工作流。&lt;/p&gt;&lt;p&gt;比如我们要准备一份马斯克 SpaceX 的介绍 PPT，可以先使用夸克 AI 浏览器中的「超级播放器」，5 倍速观看相关视频，AI 实时生成字幕、翻译，并自动总结视频摘要和脑图，半小时的视频几分钟就能掌握。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/252a5045-5e98-4217-9ce1-9cead9bab461/1768450218858.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;然后调用夸克 PPT 工具生成汇报材料，将上述 AI 视频摘要输入进去，就能一键生成图文并茂的 PPT。海量模板任选，大纲随时调整。&lt;a href="https://mp.weixin.qq.com/s/5O9tK2yNin9DcKx-oWzjEg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dad953b6-7509-4ecd-bb49-bd1bcb89f453/1768450231667.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;夸克 AI 浏览器仍在以极快的速度持续进化，不断挖掘并满足用户更精细化的需求。&lt;/strong&gt;我们有理由相信，随着 AI 交互方式的持续创新优化、与工作流的深度整合，一个更强大的 AI 浏览器背后，是让个人真正实现「一个人即能活成一支队伍」的能力底座，所谓的「超级个体」也将不再是一句空话。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>已证实！清华姚班陈立杰全职加入OpenAI，保留伯克利教职</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 12:01:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/acc03329-ca2f-46fe-8152-ae7d24244959/1768449717057.png" style="width: 700%;" class="fr-fic fr-dib"&gt;据机器之心求证，清华大学「姚班」校友、加州大学伯克利分校（UC Berkeley）助理教授&lt;strong&gt;陈立杰（Lijie Chen）已正式加入 OpenAI&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="5"&gt;知情人士透露，陈立杰此次是以&lt;strong&gt;全职&lt;/strong&gt;身份加入 OpenAI 开展研究工作。与此同时，他目前在伯克利的状态为 On Leave（停薪留职），即他保留了在大学的教职，并未离职。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;陈立杰是理论计算机科学领域的顶尖青年学者，本科毕业于清华姚班，博士毕业于麻省理工学院（MIT），在计算复杂性理论等领域拥有卓越的学术成就。&lt;/p&gt;&lt;p data-path-to-node="7"&gt;截至目前，其个人主页和 LinkedIn 页面尚未更新。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDaqKWkZeGtANwZg9y9zUV0Jk9td0YvwfjDtlJ1pmpR5PdhMhDqjibeiag/640?wx_fmt=jpeg#imgIndex=1" data-ratio="0.9305555555555556" data-type="png" data-w="1080" data-width="1521" data-height="1761" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDOHYFqQZhfcFNPmnJCG9pjEbgqejTeX5iaBClKRE3IjbvmTwFa2A9e8A/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy2="1005.0533807829181" data-imgfileid="503528407" data-aistatus="1" data-original-style="width:562px;height:523px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8c483a01-1c51-441c-9ed4-617ffd1c7cd0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDNjqD1ITGUvZzuC01n8abQnrVG4hXosNK5SiaA1woDBfJFu1Yrx4sjMQ/640?wx_fmt=jpeg#imgIndex=2" data-ratio="1.2916666666666667" data-type="png" data-w="1080" data-width="1194" data-height="1704" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDvQxBeWxeTXHms5QL1zvPCm1Z74pzmEp0nLjs1c1D4QMYwEuSSS2jrQ/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy1="92.24199288256227" data-cropy2="1487.4021352313168" data-imgfileid="503528402" data-aistatus="1" data-original-style="width:562px;height:726px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1e527d87-4420-4124-94fd-2cd33c56a834/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="8"&gt;&lt;strong&gt;从 IOI 金牌到伯克利助理教授&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;陈立杰高中就读于杭州外国语学校。他在信息学竞赛（OI）领域表现突出，是当时知名的竞赛选手。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;2011 年，他获得全国青少年信息学奥林匹克竞赛（NOI）金牌；2013 年，他代表中国队出征第 25 届国际信息学奥林匹克竞赛（IOI），不仅夺得金牌，更取得了全球第一名的成绩。&lt;/p&gt;&lt;p data-path-to-node="10"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDNeZqJ8KUyicvsibXAylhNXAVIhxRfZoFTYWguibcKvD6ISsKliafuPMGicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5433333333333333" data-type="png" data-w="600" data-imgfileid="503528413" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8062465f-5d24-4da8-a1ad-7055eaf3ae30/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p data-path-to-node="11"&gt;进入清华大学姚班后，陈立杰逐渐将重心从程序设计竞赛转向计算机科学理论研究。2016 年，他获得清华大学本科生特等奖学金。在特等奖学金答辩会上，陈立杰曾立下宏愿：「&lt;strong&gt;有生之年，希望能看到 P vs NP 问题被解决。&lt;/strong&gt;」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgjkLv9SWDs8jXPeaNs1QHLATcFogMWXzkkoictumhkv3EAkDcbWvsow/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6366666666666667" data-type="png" data-w="600" data-imgfileid="503528412" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/71f41604-8e2b-4fd3-821d-05347c1117fb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="12"&gt;大三时期，他曾赴 MIT 进行科研交换，师从著名量子信息科学家 Scott Aaronson 教授。2017 年，作为大四本科生的他在 FOCS（IEEE 计算机科学基础年会）上发表了论文，&lt;strong&gt;成为首位在该顶级会议上发文的中国本科生&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDz1Fte6DQa9OLZ4VQhPz7iaicnQI5AhsaVSwXQgTZPRuzfgtgUyxOKjHQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.7583333333333333" data-type="jpeg" data-w="600" data-imgfileid="503528409" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3267e0c9-a55b-4552-9253-5478b8d4cf15/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="13"&gt;该论文是他在 MIT 访问期间与 4 名博士研究生及博士后合作完成的，解决了 John Watrous 于 2002 年提出的关于「量子统计零知识证明」（QSZK）的开放性问题，引入了「量子区分复杂度」这一新概念，证明了其与 QSZK 查询复杂度的关系，解释了传统分析方法的局限性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="14"&gt;&lt;b data-index-in-node="0" data-path-to-node="14"&gt;论文地址：&lt;/b&gt;https://arxiv.org/pdf/1609.02888&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="15"&gt;本科毕业后，陈立杰赴 MIT 攻读博士学位，师从计算复杂性权威 Ryan Williams 教授。这一时期，他在&lt;strong&gt;计算复杂性、电路复杂度、伪随机性&lt;/strong&gt;等领域取得了实质性突破，主要贡献包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="16,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,0,0"&gt;硬度放大：&lt;/b&gt; 他与合作者发现了一条绕过「自然证明」壁垒的潜在路径：证明某些问题在极弱的电路模型下是困难的，可以自动「放大」推导出它们在极强电路模型下也是困难的（即推导出 P &amp;ne; NP）。严谨的是，他也提出了「局部性壁垒」，客观指出了目前技术在利用这一发现时面临的实际困难。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,1,0"&gt;非黑盒去随机化：&lt;/b&gt; 他提出了一种新框架，证明在比传统要求更弱的假设下，可以去除算法中的随机性。他还证明了在特定条件下，随机性对于计算可能是「无用」的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="16,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="16,2,0"&gt;量子霸权的理论基石：&lt;/b&gt; 他参与证明了存在一个 Oracle，使得量子多项式时间（BQP）不包含在多项式层级（PH）中。这为量子计算机在理论上超越经典计算机提供了坚实的数学支撑。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="17"&gt;他在博士期间多次获得理论计算机顶级会议的最佳学生论文奖，包括 STOC 2019（Danny Lewin Award）和 FOCS 2019（Machtey Award）。2022 年，他的博士论文获得 ACM 博士论文奖荣誉提名以及 MIT George M. Sprowls 最佳博士论文奖。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDFtg8HUndFooTiaxvn4jyP3B1ayDCre1mwYIYelUwFVn6lw8icoZ5NV4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6714285714285714" data-type="png" data-w="980" data-width="980" data-height="658" data-imgfileid="503528419" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c432f97a-faaf-42f7-ab70-86543e799aba/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="18"&gt;2022 年博士毕业后，陈立杰获得了 UC Berkeley 米勒基础科学研究所的 &lt;strong&gt;Miller Fellowship&lt;/strong&gt;。这是一项面向全球杰出青年科学家的全额资助计划，历史上曾诞生过多位诺贝尔奖和菲尔兹奖得主。作为米勒研究员，他拥有完全的学术自由，在三年内专注于自己感兴趣的前沿课题。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;他于 2025 年 7 月入职 UC Berkeley 电气工程与计算机科学系（EECS）担任助理教授，继续从事教学与科研工作。&lt;/p&gt;&lt;section&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/section&gt;&lt;section&gt;&lt;sup&gt;https://www.tsinghua.org.cn/info/1953/13913.htm&lt;/sup&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>解锁任意步数文生图，港大&amp;Adobe全新Self-E框架学会自我评估</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 11:58:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/404ea3bf-7d73-4b10-9055-d81ed68eadc3/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管扩散模型（Diffusion Model）与流匹配（Flow Matching）已经把文本到图像生成（Text-to-Image, T2I）推向了更高的视觉质量与可控性，但他们通常在推理时需要数十步网络迭代，限制了其对于一些需要低延迟，Real-Time 的应用。&lt;/p&gt;&lt;p&gt;为了把推理步数降下来，现有路线通常依赖知识蒸馏（Distillation）：先训练一个多步教师模型，再把能力迁移到少步学生模型。但这条路的代价同样明显 &amp;mdash;&amp;mdash; 既依赖预训练教师，又引入了额外的训练开销，并在「从零训练（from scratch）」与「极少步高质量」之间留下了长期空白。&lt;/p&gt;&lt;p&gt;近日，香港大学（The University of Hong Kong）与 Adobe Research 联合发布 Self-E（Self-Evaluating Model）：一种&lt;strong&gt;无需预训练教师蒸馏、从零开始训练的任意步数文生图框架&lt;/strong&gt;。其目标非常直接：让同一个模型在极少步数也能生成语义清晰、结构稳定的图像，同时在 50 步等常规设置下保持顶级质量，并且随着步数增加呈现单调提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAvlRwkoKg4F7DFOOm16JzLj2F0t3WyRSicfDL1ibHjIzokI51iaS1UueSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.27037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528045" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/03427976-4849-4dc5-a278-d8adaa8d6bb8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Self-Evaluation Unlocks Any-Step Text-to-Image Generation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://xinyu-andy.github.io/SelfE-project/&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文 PDF：https://www.arxiv.org/pdf/2512.22374&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsuBcsLgMO3SOAXfTrUQ8Kqp1L4oc9YCLSM4xrSn2WE5FUDrDtf15eQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5342592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528044" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c7250837-2b24-40bd-b3c7-bfa9bea307bb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;引言：从「轨迹匹配」到「落点评估」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;扩散 / 流匹配范式本质上是在学习一张「局部向量场」：给定噪声状态，预测下一步该往哪里走。这个监督信号在「小步、密集积分」时非常有效，但一旦尝试「大步跳跃」，误差会被轨迹曲率放大，生成往往滑向平均解、语义漂移或结构坍塌。&lt;/p&gt;&lt;p&gt;Self-E 的切入点是一个根本上的范式改变：&lt;strong&gt;我们能否不再执着于「每一步走得对不对」，而是把训练重心转向「落点好不好」？&lt;/strong&gt;也就是把目标从「轨迹匹配（trajectory matching）」转变为「落点评估（destination/landing evaluation）」。&lt;/p&gt;&lt;p&gt;换句话说，传统 Diffusion Model 训练强调「在起点对齐局部方向」；Self-E 强调「在落点评估结果并给出纠偏方向」。监督位置的改变，带来了训练信号性质的改变：从静态监督变成动态反馈。&lt;/p&gt;&lt;p&gt;作者在项目主页用动图展示了这两者的区别：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAe6xwicALoYz3p73XBzZwIkVnQ7zzDsCraQlplYa4H0Bo7AqYbW6p5xw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=3" data-ratio="0.5829471733086191" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503528046" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/fb315588-387f-4e02-a7a4-55865bdf0f5c/640.gif" data-order="0" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA7nHJfx8zhw61HDVt6V5WhIuqglibu4JyKBKASImLa606R3YZmyMm5Dg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=4" data-ratio="0.5829471733086191" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503528047" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7e7fb9e8-6e51-476b-8c23-59effe360bc5/640.gif" data-order="1" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这也是为什么模型在测试阶段有少步推理能力：扩散模型在测试时只能逐步跟随当前点预测的最好局部路径，最终走到全局最优；而 Self-E 在训练阶段就逐步学会了走向全局最优的落点。&lt;/p&gt;&lt;p&gt;这也不同于目前多数少步生成模型所采用的学习轨迹的积分，如 Consistency Model, Mean Flow; Self-E不局限于沿着预定义的轨迹走，而是直接关心每步结果好不好，对不对。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Self-E 的核心：两条互补训练信号（Two Complementary Signals）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 用同一个网络在两种「模式」下工作：一方面像 Flow Matching 一样从真实数据学习分布的局部结构；另一方面用「模型自身正在学到的局部估计」去评估自生成样本，形成自反馈闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1）从数据学习：Learning from Data&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;学什么&lt;/strong&gt;：分布的局部结构（local score /velocity 的期望形式），即「在邻域内密度如何变化」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;怎么学&lt;/strong&gt;：采样真实图像与文本条件，加噪得到噪声输入，用条件流匹配式目标训练模型去预测干净样本（或等价参数化），提供稳定的局部监督。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2）自我评估学习：Learning by Self-Evaluation&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;学什么&lt;/strong&gt;：分布层面的正确性（distribution-level correctness）&amp;mdash;&amp;mdash;&amp;nbsp;生成样本是否与真实分布一致、是否与描述的文本对齐。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键机制&lt;/strong&gt;：模型先做一次「长距离跳跃」（从起始时间步跳到落点时间步），然后在落点处用自己当前学到的局部估计产生一个「方向信号」，告诉生成样本应如何移动才能进入更高质量、更符合文本的概率分布区域。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;最大差异&lt;/strong&gt;：评估信号不来自外部教师（pretrained diffusion teacher），而是来自模型自身的在训估计（dynamic self-teacher）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAb6e5QriaPUVibjetLXLCOkO5a4r60gibVAUAgSiaIialNvIfQHqwUKuicp1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528048" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/8d0e1028-1471-4428-a999-f7773fb6950a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;训练细节：把「自我评估」做成可反传的学习信号&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 在理论上把评估写成分布级目标（例如以反向 KL 为代表的分布匹配视角），但真正落地的难点在于：真实分布与生成分布的 score 都不可得。&lt;/p&gt;&lt;p&gt;Self-E 的关键观察是：&lt;strong&gt;模型在「从数据学习」阶段会逐步学到某种条件期望形式，而该量与 score 通过 Tweedie&amp;rsquo;s formula 存在联系&lt;/strong&gt;，因此可以用「正在训练的模型」去近似提供评估方向。&lt;/p&gt;&lt;p&gt;在实现上，作者发现理论目标中包含「classifier score term」等项，并实证发现仅使用 classifier score 项就足够有效，甚至更利于收敛，从而避免早期还要额外训练一个用于 fake score 的模型分支。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA5p4gj4vOpXFrMHbiaVbHYiaS6MlETMShJ9Xr1vZEXcgkfrAeNOXCVmFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3074074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528049" data-aistatus="1" data-original-style="width:374px;height:115px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c51c4cff-042f-40a8-b873-879557485033/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了把这种「评估方向」变成可训练的损失，Self-E 采用 stop-gradient 的双前向构造 pseudo-target，通过最小化 MSE 诱导出与所需方向一致的梯度；并在最终目标中将数据驱动损失与自评估损失进行混合加权。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGVx9h55OaXTDXHvkOIh12xKEibpuHX49QLYoOugmfQzwLKnz8qa3nZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.20462962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528050" data-aistatus="1" data-original-style="width:347px;height:71px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/547d8dac-fa19-43fc-83a2-5543e4546836/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最终，我们可以用一个统一的形式来训练：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuo01tTMfxTSRAgbLFyObmTO431CcULicSNEWkFR74fXfLfn63qicj1Sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.11481481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528051" data-aistatus="1" data-original-style="width:320px;height:37px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/19efea39-1e2a-4e2b-b666-2f56a04b9d26/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中，等式右边第一项正是 Learning-from-data 的目标，而第二项对应 Self-Evaluation。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理：任意步数（Any-Step Inference），并随步数单调变好&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在推理阶段，Self-E 与扩散 / 流匹配一样进行迭代去噪，但不同之处在于：由于训练中已经显式学习「长距离落点」的质量与纠偏方向，它可以在非常少的步数下保持可用的语义与结构，同时在增加步数时继续提升细节与真实感。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;性能：GenEval 全步数段 SOTA，少步优势尤其显著&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 GenEval 基准上，Self-E 对比其他方法取得全面领先，并且随着步数增加呈现单调提升。更关键的是少步区间的「断层式」优势：在 2-step 设置下，Self-E 相比当时最佳对比方法的提升约为&lt;strong&gt; +0.12&lt;/strong&gt;（0.7531 相比 0.6338），而多种传统扩散 / 流匹配模型在 2-step 下几乎无法生成可用结果。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAK3VzR2O3ILOtbJyxwS39UOU4pmBKovEKWlLsZ3wtnEDcezwicJvg2bw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528052" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/699a30fc-1c99-4433-add6-b98868d536a3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAI75P0LtKlz5R16L9ICeSHtRSqDpuDV6Dib9oTIU9v9XW51o0jYQc7bA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.8518518518518519" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528053" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c6d9e0ab-7a49-4e5e-9a61-ca451b520943/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;另一角度解读：把「预训练」与「反馈学习」拉到同一条线上&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从更宏观的视角看，Self-E 把训练过程组织成一个类似强化学习中的「环境 &amp;mdash; 智能体（environment&amp;ndash;agent）闭环」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Phase&lt;/strong&gt;：模型从真实数据学习分布的局部结构，得到越来越可靠的局部估计（可视作学习环境，并给出评估）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Self-Evaluation Phase&lt;/strong&gt;：模型提出长距离跳跃方案（可视作智能体执行动作），在落点处用内部估计产生反馈方向并更新参数（可视作获得环境的反馈）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Closed Loop&lt;/strong&gt;：评估器随训练变强，反馈信号质量随之提升，反过来又进一步强化少步生成能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者在项目主页指出：这种内部评估器在角色上接近「可查询的学习型奖励模型」，为后续把强化学习（RL）更系统地引入视觉生成训练提供了新的接口与想象空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Self-E 的价值不只是在「少步生成」这一条指标上跑得更快，而在于它把文生图训练范式从「沿着既定轨迹走」推进到「学会评估落点并自我纠偏」：在不依赖预训练教师蒸馏的前提下，让单一模型同时覆盖极低时延与高质量长轨迹两种需求，并在不同推理预算下保持可扩展的性能曲线。&lt;/p&gt;&lt;p&gt;对内容创作与生成式系统落地而言，「one model, any compute」的工程意义非常直接：同一个 checkpoint 可以按场景动态选择步数 &amp;mdash;&amp;mdash; 交互式场景用 1～4 步追求即时反馈，高质量离线渲染用 50 步追求细节上限；而训练侧则绕开了教师蒸馏链路，把「从零训练 + 少步推理」真正拉回到可讨论、可复现、可扩展的主流路径上。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>5分钟定制一个AI采购专家：讯飞发布“招采智能体工厂”，重新定义行业开发范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 15 Jan 2026 11:35:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;大模型落地，正从&amp;ldquo;聊天与创作&amp;rdquo;走向&amp;ldquo;规划与执行&amp;rdquo;的深水区。1月13日，科大讯飞将这一趋势押注在一个极其垂直且复杂的领域&amp;mdash;&amp;mdash;招标采购，并发布了其全新的&amp;ldquo;招采智能体平台&amp;rdquo;。与其说这是一个产品，不如说它是一个&amp;ldquo;专为招采场景打造的智能体操作系统与开发工厂&amp;rdquo;，其核心主张令人振奋：零代码，5分钟，让企业构建属于自己的AI采购专家。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c97a3f6d-6b0e-45c7-8526-841c8dc20a2d/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;要理解这场发布的意义，首先要看清AI赋能招采的技术演进之路。1.0时代是&amp;ldquo;工具辅助&amp;rdquo;，核心是&amp;ldquo;小模型+结构化&amp;rdquo;，解决了&amp;ldquo;人工翻页&amp;rdquo;痛点，但AI不理解业务；2.0时代进入&amp;ldquo;单点智能&amp;rdquo;，大模型带来了认知突破，能深度理解评审规则，但无法解决流程割裂问题；3.0时代即&amp;ldquo;智能体（Agent）时代&amp;rdquo;，智能体具备自主规划、跨域协同、持续进化能力，成为能够推进全流程的&amp;ldquo;专业伙伴&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/d04571c4-3b69-4e8d-8f47-fa5d4d8ea648/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&amp;ldquo;招采智能体平台&amp;rdquo;的架构基于三大核心技术支柱：首先是&amp;ldquo;星辰Agent底座&amp;rdquo;，这是平台的&amp;ldquo;决策大脑&amp;rdquo;，是国内首批融合大模型决策规划与RPA执行能力的智能体平台；其次是&amp;ldquo;星辰RPA&amp;rdquo;，作为智能体的&amp;ldquo;自动化双手&amp;rdquo;，能够稳定执行跨软件操作；第三是&amp;ldquo;MaaS模型精调平台&amp;rdquo;，允许企业上传自身数据精调模型，平均40分钟即可完成一个细分场景模型的优化。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a074e41d-0134-449c-aeb4-9dc9a9e78372/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;发布会的体验区成为了技术理念的最佳秀场。参会者可以亲历两大亮点：在&amp;ldquo;智能体搭建工坊&amp;rdquo;，即使毫无编程基础的业务人员，通过简单的拖拽、连线，就能快速构建一个可运行的智能体；作为发布会的技术彩蛋，讯飞透露正在跟进国际领先的智能体&amp;ldquo;技能&amp;rdquo;（Skills）标准，该标准旨在为AI编写结构化的&amp;ldquo;工作手册&amp;rdquo;，预示着未来智能体将具备更强大的跨平台任务执行能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/95987983-18ad-422c-b022-7906f026f867/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;讯飞深知，招采业务场景千变万化，仅靠自身无法穷尽。因此，平台的终极目标是构建生态。它不仅内置了覆盖招标、投标、评标核心流程的数十个专业Agent，更将底层能力开放。未来，第三方开发者、行业专家可以基于此平台，开发并上架更丰富的垂直场景智能体，共同打造招采领域的&amp;ldquo;智能应用商店&amp;rdquo;。&lt;/p&gt;&lt;p&gt;从单一AI应用到开放的能力基座，科大讯飞此次发布标志着其AI to B战略进入了以&amp;ldquo;平台+生态&amp;rdquo;驱动的新阶段。在行业聚焦于真实价值创造的当下，招采智能体平台能否以其鲜明的技术路径和清晰的落地场景，成为垂直领域大模型应用的新范式，值得所有技术观察者持续关注。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Agent时代，为什么多模态数据湖是必选项？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 09:55:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/357eea47-54fc-4a65-9090-96dbe74862e5/1768441988644.png" style="width: 700%;" class="fr-fic fr-dib"&gt;「2025 年，注定被铭记为 AI 工业时代的黎明。」&lt;/section&gt;&lt;p&gt;回望这一年，吴恩达教授曾这样感慨。&lt;/p&gt;&lt;p&gt;这一年，大量企业你追我赶，投身于 AI 应用及 Agent 建设。然而，许多企业或许尚未意识到：如果 AI 竞速只停在应用层，可能连这场竞争的「起跑线」都尚未站上。&lt;/p&gt;&lt;p&gt;AI 时代，数智化表面是模型的狂欢，底层是基建的深耕。&lt;/p&gt;&lt;p&gt;唯有能支撑 AI 应用规模化落地的数据基座，才能构筑企业真正的竞争力。&lt;/p&gt;&lt;p&gt;近来， AI 行业普遍认为我们正在进入所谓的「AI 下半场」，而此时行业面临的一大关键问题是「究竟应该让 AI 去做什么？又该如何衡量真正的进展？」&lt;/p&gt;&lt;p&gt;而这个问题的答案也基本已有共识：要想在这下半场脱颖而出，我们需要及时转变思维方式，应当用 AI 的思维，把该做的事情重新做一遍。&lt;/p&gt;&lt;p&gt;与上一阶段不同，这一阶段的企业数据，不再等待人来解读，而是被模型直接「消费」。&lt;/p&gt;&lt;p&gt;以音频数据应用为例，AI 时代，音频数据不应只是一份录音数据存档，还应成为可查询和交互的信息源，比如应该支持查找「录音中的人是客户 A ，上周在另一业务有投诉记录」这类关联信息。这种跨模态的关联性，是实现模型复杂推理的基础。&lt;/p&gt;&lt;p&gt;推及其他行业：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在智能驾驶中，道路视频、点云与传感器数据需要被实时送入智能体，支撑感知、规划与异常检索；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在游戏行业，需要将对话、行为与世界观等多模态数据沉淀为长期记忆，用于沉浸式 NPC 与自动化资产生成；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在传媒行业，需要使用视频、音频与用户互动数据来驱动内容生成与精准分发；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在电商领域，商品图文与交易数据直接喂给模型，实现智能选品与个性化推荐。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，&lt;strong&gt;对多种模态数据的处理与使用的能力，正在影响各行业商业竞争的形态与上限&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;接下来的风口要踏在哪里？我们关注到了火山引擎近期发布的《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzkwMzMwOTQwMg==&amp;mid=2247521304&amp;idx=1&amp;sn=dc367120edc88b47f8ed7f4f168e2c4c&amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;strong&gt;AI 时代企业数据基建升级路线图&lt;/strong&gt;&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;它在开篇写到：&lt;strong&gt;AI 时代，数据基建已经成为决定企业竞争高度的战略资产&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;笔者深以为然。&lt;/p&gt;&lt;p&gt;企业要发展可以处理多模态数据的底层基建。因为 AI 时代最深的红利，并不在于「拥有」SOTA 的模型，而在于能否持续「驾驭」并「滋养」它。更进一步，可以说构建多模态数据湖已经成为企业参与这场 Agent 竞赛的必选项。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicEgLkymO8MMCrLiavX0ql8FiaIic9vG0qu0TCo74T5VGbKcuyO8iaLNWeAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528308" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/a7f325e4-217e-4dce-9d6a-511b35d4d756/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 传统数据湖与多模态数据湖对比，图像由 AI 生成。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 时代，这是你不能错过的风口&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智能的涌现扎根于坚实、鲜活且可进化的数据土壤。&lt;/p&gt;&lt;p&gt;尤其在 Agent 时代的到来之际，企业竞速也正由数据基建分野：领先者正将沉睡的非结构化数据转化为可用的竞争力，而落后者由于非结构化数据资产仍处于休眠状态，而只得徘徊在 Agent 应用的起点。&lt;/p&gt;&lt;p&gt;当行业的聚光灯都投向大模型或智能体本身时，真正的竞争已转入水下，&lt;strong&gt;即底层的、支撑多模态数据的数据工程。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;唤醒数据，化「沉睡库存」为核心资产&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;IDC 预测，2025 年企业超过 80% 的数据将是非结构化的。&lt;/p&gt;&lt;p&gt;这些长期堆积的视频、音频、图像和传感器数据，曾被视为「数字负债」。然而，多模态与大模型技术的成熟，正让它们焕发前所未有的价值。&lt;/p&gt;&lt;p&gt;以制造业为例，以往无人问津的历史故障录像，经大模型解析与标注，即可成为「智能知识库」。新员工用自然语言提问，便能精准调取同类故障的处理记录 &amp;mdash;&amp;mdash; 沉寂数据瞬间转化为实战生产力。&lt;/p&gt;&lt;p&gt;本质上，AI 时代的数据基建，正通过向量化等处理能力，让非结构化数据真正「活」起来，使其从被动存储的负担，变为可随时调用、持续学习的战略资源。&lt;/p&gt;&lt;p&gt;唤醒这 80% 的数据，是在 Agent 时代构建竞争力的工程前提。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让数据资产驱动业务，启动飞轮&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;强大的数据基建能构建数据、模型与业务深度耦合的闭环，真正「让模型自主成长」，为 Agent 赋予更多智能。&lt;/p&gt;&lt;p&gt;一个优秀的数据架构，需在企业数据平台、MaaS（模型即服务）平台、Agent 开发工具与应用之间建立高效的数据流通管道，否则数据会停留于「孤岛」，智能难以落地。&lt;/p&gt;&lt;p&gt;典型的例子是传统智能客服：尽管不断采集用户的语音、文本、截图与操作轨迹，却因模型与业务间数据不通，导致客服模型始终重复犯错、体验停滞，陷入「千人一面」的困境。&lt;/p&gt;&lt;p&gt;我们发现，火山引擎通过多模态数据湖与 AgentKit、火山方舟等产品的联动，已验证了数据、模型、业务打通的可行性。在零售行业中，完善的多模态数据湖不仅能分析销售报表，还可实时捕捉顾客行为、评论与画像。这些鲜活数据持续回流，使企业 AI 能力能随业务不断演进。&lt;/p&gt;&lt;p&gt;这种「业务滋养模型、模型反哺业务」的闭环，使企业 AI 能力可伴随业务持续进化，这正因为此，多模态数据湖成为了 Agent 时代构建智能护城河的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让业务拥有锚点，获得未来的确定性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;新一代数据基建通过统一的数据与计算底座，以同一平台支撑多模态数据，并持续适配技术演进。&lt;/p&gt;&lt;p&gt;以某安防企业为例，传统数据管理体系下，如果从视频监控扩展至智能识别，往往需为不同算法供应商重建独立的计算平台与数据库，导致内部数据不互通、烟囱林立。巨大的管理和技术成本，会拖累企业创新动力。&lt;/p&gt;&lt;p&gt;而统一的多模态数据湖体系，能以统一元数据管理结构化和非结构化数据，提供面向 AI 的灵活数据集能力，支持数据快速探查与调用。通过标准化存储与可扩展接口，系统能在上层屏蔽底层模型的频繁迭代，使数据始终以对模型友好的形态稳定输入。&lt;/p&gt;&lt;p&gt;这意味着，当该企业未来业务从「视频监控」拓展至「自动巡检」、「人流预测」等领域时，可低成本接入新算法模块，无需颠覆底层架构。&lt;/p&gt;&lt;p&gt;「基建不动，技术常新」，在追求敏捷响应速度的 Agent 时代，这种具备工程确定性的多模态基座正在成为架构的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;升级三部曲：积累，重构，融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;火山的这份「数据基建升级路线图」之所以值得展开聊聊，是因为它在行业内率先为企业提供了一套从「拥有模型」到「驾驭智能」的数据基建进化蓝图。在 Agent 时代，它为企业提供一套实现多模态数据湖的清晰演进路径。&lt;/p&gt;&lt;p&gt;这个蓝图可作为重要的参考框架，企业可结合业务特点与发展阶段，衍生出适合自身的基建升级路径，进而在 Agent 时代构筑自己的核心竞争力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528305" data-ratio="1.0444444444444445" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiciaapBNl8MSNCEIsQNResw6sdN9fdh5YF9NrTPrseSomrXiabvRibCotAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a388d8f5-e4e3-4cd0-a29a-73ad318413a7/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;具体而言，火山引擎将企业数据基建的演进分为了三步渐进式过程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;异构算力与分布式引擎阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一阶段的核心是突破算力瓶颈。为应对大规模数据处理与大模型训练的需求，传统仅依赖 CPU 的架构已难以满足 AI 时代对存储与计算的高实时性要求。企业需转向为 AI 任务量身打造的 CPU+GPU 异构架构，实现灵活调度。&lt;/p&gt;&lt;p&gt;这一阶段的核心目标是：数据「进得来，跑得快」，并原生支持 AI 服务。在异构算力的支撑下，企业能在技术快速迭代中平衡性能与成本，真正让算力服务于业务与模型增长。整体来说，这一阶段可为多模态数据湖这一必选项提供坚实的物理支撑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型即引擎与多模态重构阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在算力基础就绪后，需进一步推动数据基建与 AI 的深度融合。本阶段的关键在于将预训练大模型嵌入数据流水线，实现文本、图像、音频等多模态数据向统一语义向量与高价值知识标签的自动转换。&lt;/p&gt;&lt;p&gt;Agent 时代，数据价值不在于「存量」，而在于能被 AI 调用的「流量」。通过&lt;strong&gt;向量化&lt;/strong&gt;处理，企业的多模态资产第一次真正实现通用「可读、可感、可交互」。该过程直接发生于数据基建层，从源头确保企业数据对大模型友好，使其可随时被检索、推理与学习，赋能全感官业务洞察。&lt;/p&gt;&lt;p&gt;因此，这一阶段可使多模态数据湖成为 Agent 识别与推理的逻辑重心，进一步确立了其作为基建必选项的地位。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全域数据治理与平台融合阶段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目标是在管理层面对数据资产进行统一管控，推动全域数据的治理、价值激活与安全合规。&lt;/p&gt;&lt;p&gt;这意味着 AI 能力可深度融入每一条业务流程，激活分散在不同系统与形态中的数据资产，并将其持续转化为增长动能。统一的数据治理体系不仅能显著降低安全与合规风险，还可大幅提升数据复用效率，助力企业将技术优势系统化、可持续地转化为长期竞争力。&lt;/p&gt;&lt;p&gt;这一阶段标志着多模态数据湖从单一的技术底座演变为全域的智能中枢，完成了其作为 Agent 时代必选项的最后拼图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent 时代数据基建的选型指南&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;国内云厂商都在积极拥抱 Agent 时代的技术升级，从各大厂商的进度来看，对多模态数据的「存、算、管」重视度在持续提升。其中，我们观察到火山引擎「多模态数据湖」在行业内的进展最快，能够提供数据统一入湖与治理能力，在算子体系、性能优化、异构算力调度以及与大模型生态的无缝协同方面形成了更完整的一体化方案。&lt;/p&gt;&lt;p&gt;同时通过观察行业内其他厂商面向多模态数据的方案方向，我们也在思考：AI 和 Agent 时代的企业需要的数据基建，到底应该是什么样的？&lt;/p&gt;&lt;p&gt;综合起来，我们认为企业应将&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;以下特质列为&lt;/span&gt; AI 数据基建的必选项。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从「存储中心」到「价值中心」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 AI 浪潮下，企业首先撞上的，是数据体系的根本性变革。&lt;/p&gt;&lt;p&gt;一方面，数据规模动辄 PB 级，非结构化格式复杂，处理流程高度碎片化，还要同时承载 CPU + GPU 混合负载与复杂作业调度；另一方面，大量数据分散存储、难以统一检索，无法被模型高效消费，数据准备周期越来越长，成本却持续上升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真正有价值的数据，是能被快速获取、被模型理解、能转化为 Token 并直接参与推理与训练的数据。&lt;/strong&gt;而那些无法被向量化、无法进入模型工作流的数据，正在从资产变成沉重的存储负担。&lt;/p&gt;&lt;p&gt;AI 时代的数据底座，是从「存储中心」转向「价值中心」的底座。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;业务优先，回归实用主义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在技术变革快速的当下，除去技术复杂性之外，企业更大的挑战是：数据基建与业务脱节。&lt;/p&gt;&lt;p&gt;当前很多企业同时面临多模态数据分散、训练与生产割裂、血缘与版本缺失、质量评估与数据反馈闭环不足的问题。结果是数据冗余高、问题排查难、准备周期长，而业务决策却越来越依赖实时与精准。&lt;/p&gt;&lt;p&gt;在这种背景下，盲目堆算力、追求极限性能，反而成了负担。AI 时代最昂贵的基建，是那些无法转化为业务价值的闲置能力。&lt;/p&gt;&lt;p&gt;衡量一套数据基建是否先进，在于它是否能以最低成本、最快速度完成从数据输入到业务决策的闭环，并持续驱动数据飞轮运转。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开放解耦，对冲未来不确定性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着模型与技术路线持续快速更迭，企业面临的另一项长期风险正在显现：如果数据基建随模型变化不断重构，系统将永远处于迁移与动荡之中。&lt;/p&gt;&lt;p&gt;在多模态数据规模持续膨胀、合规与安全要求不断提高的背景下，这种反复重构的代价几乎不可承受。&lt;/p&gt;&lt;p&gt;因此，解耦与开放的能力决定了成为企业的「生存能力」。通过模块化、可替换的数据与 AI 基础设施，企业才能在模型更替、技术跃迁时实现平滑升级，既保持系统稳定，又持续吸收新能力，将技术不确定性转化为长期竞争力。&lt;/p&gt;&lt;p&gt;在 AI 时代，模型会不断过时，真正具有长期价值的，只有数据资产与承载它的基础设施弹性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaictYQCpliak2DZbxFh5zJDsxEEZpjicLm7EyXopeXeygEoAD9NibJPndkFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528306" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/4b6d51d4-f1a3-4864-a3a6-b614609e3925/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这使得多模态数据管理必须从「存得全、存得久」升级为「取得快、读得懂」的针对业务模式的系统性工程。&lt;/p&gt;&lt;p&gt;我们观察到火山引擎多模态数据湖有一个非常有意思的理念。&lt;/p&gt;&lt;p&gt;其提出了&lt;strong&gt;「乐高式」可组合底座&lt;/strong&gt;的观点，与其他云厂商的解决方案大相径庭。这种方式支撑企业以乐高积木般灵活、高效的方式，自主构建上层应用与智能体。&lt;/p&gt;&lt;p&gt;在这种框架下，企业可以根据现有的技术情况，选择渐进式的解决方案，同时可以模块化设计数据与智能架构，结合自身业务来进行组合式的升级，方案完全「量身定做」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicib7SIKbm4ZkDISKe6wUy1RCoEtgL0X1UTEerliaRmnGI6dPvzKdKfNWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528307" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/768e01dd-7c95-4144-9c3c-312338cd6d3f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从行业视角看，这一设计理念呼应了企业长期的 AI 战略 &amp;mdash;&amp;mdash; 让数据基础设施具备持续演进的能力，使企业在快速迭代的技术环境中，始终拥有自主调整与进化的空间。&lt;/p&gt;&lt;p&gt;目前火山的多模态数据湖，已经在智驾、游戏、传媒等多个行业落地。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在某智驾企业的模型训练中，该方案可在 150&amp;ndash;200 毫秒内完成 12 亿级别数据的「以图搜图」，性能提升&amp;nbsp;&lt;strong&gt;20 倍&lt;/strong&gt;以上；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;某游戏企业在 AI NPC 模型训练过程中，音视频数据加工效率提升&amp;nbsp;&lt;strong&gt;50%&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;应用于某头部传媒企业的媒资平台后，其内容生产与运营效率提升 &lt;strong&gt;90%&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些实践表明了采用多模态数据湖的必要性，同时也揭示出：AI 和 Agent 时代，用好多模态数据，可以激发出推动企业智能化跃迁的潜能。千行百业，都值得以此为起点，探索数据基建的更多可能，拥抱智能时代的风口。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当下，企业正站在一场深刻技术变革的洪流之中。&lt;/p&gt;&lt;p&gt;AI 落地的前提，是多模态数据处理走向标准化与智能化。对坚定投身于 AI 浪潮的企业来说，在见证大模型所带来的能力飞跃的同时，更应关注到多模态数据管理作为基础设施的必要性。&lt;/p&gt;&lt;p&gt;构建能够支撑未来十年 AI 发展的数据基座，是这场变革中最应锚定的重心。&lt;/p&gt;&lt;p&gt;对企业而言，多模态数据湖的意义远不止步于一套数据架构。它是承载 AI 应用持续演进的土壤，是企业在技术红利窗口期建立确定性的基础。&lt;/p&gt;&lt;p&gt;是的，正如我们已经在文中多次强调的那样：多模态数据湖已经不再只是可有可无的优化项，而是企业进入智能赛道的必选项。&lt;/p&gt;&lt;p&gt;它赋予企业的，是在 Agent 时代中「以静制动」的底气，也是在变革中持续进化的能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型长脑子了？研究发现LLM中层会自发模拟人脑进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 15 Jan 2026 09:50:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-15</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-15</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b219daeb-2948-457a-9eb5-94ef85713a83/1768441601006.png" style="width: 700%;" class="fr-fic fr-dib"&gt;生物智能与人工智能的演化路径截然不同，但它们是否遵循某些共同的计算原理？&lt;/p&gt;&lt;p&gt;最近，来自帝国理工学院、华为诺亚方舟实验室等机构的研究人员发表了一篇新论文。该研究指出，大型语言模型（LLM）在学习过程中会自发演化出一种&lt;strong&gt;协同核心（Synergistic Core）&lt;/strong&gt;结构，有些类似于生物的大脑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaDEA4U9DcSVav4UW7TjxlMDPVHrqulibN7OMysqaKAwdlY4gyx13NltQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5138888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528163" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c18b58cd-4b2b-41e6-8e6d-b2de38e46668/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.06851&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYQ7ONWxVbgAo3t1P0569iaJorTz0GAU0KhicicFKo0dCbSw16uqXS2fUQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.841995841995842" data-s="300,640" data-type="png" data-w="962" type="block" data-imgfileid="503528161" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a60aba40-7a5b-4c8a-b4b8-f8ee43d60ff5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队利用&lt;strong&gt;部分信息分解（Partial Information Decomposition, PID）&lt;/strong&gt;框架，对 Gemma、Llama、Qwen 和 DeepSeek 等模型进行了深度剖析。&lt;/p&gt;&lt;p&gt;他们发现，这些模型的中层表现出极强的协同处理能力，而底层和顶层则更偏向于冗余处理。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协同与冗余：LLM 的内部架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队将大型语言模型视为分布式信息处理系统，其核心实验设计旨在量化模型内部组件之间交互的本质。为了实现这一目标，研究者选取了 Gemma 3、Llama 3、Qwen 3 8B 以及 DeepSeek V2 Lite Chat 等多种具有代表性的模型系列进行对比分析。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验方法与量化指标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在实验过程中，研究者向模型输入了涵盖语法纠错、逻辑推理、常识问答等 6 个类别的认知任务提示词。&lt;/p&gt;&lt;p&gt;针对每一个提示词，模型会生成一段 100 个 Token 的回答，实验设备则同步记录下每一层中所有注意力头或专家模块的激活值。&lt;/p&gt;&lt;p&gt;具体而言，研究人员计算了这些输出向量的 L2 范数，以此作为该单元在特定时间步的激活强度数据。&lt;/p&gt;&lt;p&gt;基于这些时间序列数据，研究团队应用了&lt;strong&gt;整合信息分解（Integrated Information Decomposition, ID）&lt;/strong&gt;框架。&lt;/p&gt;&lt;p&gt;这一框架能够将注意力头对之间的交互分解为「持续性协同」和「持续性冗余」等不同原子项。&lt;/p&gt;&lt;p&gt;通过对所有注意力头对的协同值和冗余值进行排名并求差，研究者得到了一个关键指标：&lt;strong&gt;协同-冗余秩（Synergy-Redundancy Rank）&lt;/strong&gt;。该指标能够清晰地标示出模型组件在处理信息时，究竟是倾向于进行独立的信号聚合，还是在进行跨单元的深度集成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;跨模型的空间分布规律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验数据揭示了一个在不同架构模型中高度一致的空间组织规律。在归一化后的模型层深图中，协同分布呈现出显著的「倒 U 型」曲线 ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaTPhh9z3Alm9dSFwo6lYYRBAPddsHoOPqyPJFfCmYDibxd4G7iasJEbAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8357588357588358" data-s="300,640" data-type="png" data-w="962" type="block" data-imgfileid="503528162" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/10673250-d9c8-46d7-8ffd-c92ebb7dc50a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;冗余外周（Redundant Periphery）&lt;/strong&gt;：模型的早期层（靠近输入端）和末期层（靠近输出端）表现出极低的协同秩，信息处理以冗余模式为主。在早期层，这反映了模型在进行基本的解词元化（Detokenization）和局部特征提取；而在末期层，则对应着 Token 预测和输出格式化的过程。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;协同核心（Synergistic Core）&lt;/strong&gt;：模型的中层则展现出极高的协同秩，形成了核心处理区。例如，在对 Gemma 3 4B 的热图分析中，中间层的注意力头之间表现出密集且强烈的协同交互，这正是模型进行高级语义集成和抽象推理的区域。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;架构差异与一致性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，这种「协同核心」的涌现并不依赖于特定的技术实现。&lt;/p&gt;&lt;p&gt;在 DeepSeek V2 Lite 模型中，研究者即使是以「专家模块」而非「注意力头」作为分析单位，依然观察到了相同的空间分布特征。&lt;/p&gt;&lt;p&gt;这种跨架构的收敛性表明，&lt;strong&gt;协同处理可能是实现高级智能的一种计算必然&lt;/strong&gt;，而非单纯的工程巧合。&lt;/p&gt;&lt;p&gt;这种组织模式与人脑的生理结构形成了精确的映射：&lt;strong&gt;人脑的感官和运动区域同样表现出高冗余性，而负责复杂认知功能的联合皮层则处于高协同的「全局工作空间」中心。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能的涌现：学习驱动而非架构使然&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个关键的问题在于：这种结构是 Transformer 架构自带的，还是通过学习习得的？&lt;/p&gt;&lt;p&gt;研究人员通过分析 Pythia 1B 模型的训练过程发现，在随机初始化的网络中，这种「倒 U 型」的协同分布并不存在。随着训练步数的增加，这种组织架构才逐渐稳定形成。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaZO93YoRoCFrUysSX6dr975lEGm4ZBY9r3nDpKxeYokWNHMYRTHuibGQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528164" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f6fe5bb0-ab9f-473d-9848-a274a9a812fe/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着，&lt;strong&gt;协同核心是大模型获得能力的标志性产物&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在拓扑性质上，协同核心具有极高的「全局效率」，有利于信息的快速集成；而冗余外周则表现出更强的「模块化」，适用于专门化处理。这种特征再次与人类大脑的网络架构形成了精确的平行关系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;协同核心的功能验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证协同核心是否真的驱动了模型行为，研究团队进行了两类干预实验：消融实验和微调实验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;消融实验&lt;/strong&gt;：研究发现，消融那些高协同性的节点，会导致模型出现灾难性的性能下降和行为背离，其影响远超随机消融或消融冗余节点。这证明协同核心是模型智能的核心驱动力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaNVn394A9Tibic2UUF4Dsc3GULWFE2bJ9XfichATbjdeX6sEibOKso9uiaxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.5768518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528165" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/01e62eda-ea60-4eef-811f-0d3eda786661/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;微调实验&lt;/strong&gt;：在强化学习微调（RL FT）场景下，仅针对协同核心进行训练，获得的性能提升显著优于针对冗余核心或随机子集的训练。有趣的是，在监督微调（SFT）中这种差异并不明显。研究者认为，这反映了 RL 促进通用化而 SFT 更多倾向于记忆的特性。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsajfmJSoD0RbpSliaWiaUZQeqvrrgcia2FHmvjiaXg380QdqR4bX3QeCNicqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.674074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528166" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/72dc4178-af5b-42ba-a834-fa76d570b62a/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这项研究为大模型的可解释性开辟了新路径。它表明，我们可以从「自上而下」的信息论视角来理解模型，而不仅仅是「自下而上」地寻找特定的电路。&lt;/p&gt;&lt;p&gt;对于 AI 领域，识别协同核心有助于设计更高效的压缩算法，或者通过更有针对性的参数更新来加速训练。对于神经科学，这提供了一种计算上的验证，预示着协同回路在强化学习和知识迁移中可能扮演着至关重要的角色。&lt;/p&gt;&lt;p&gt;大模型虽然基于硅基芯片和反向传播算法，但在追求智能的过程中，它们似乎不约而同地走向了与生物大脑相似的组织模式。这种智能演化的趋同性，或许正是我们揭开通用智能奥秘的关键线索。&lt;/p&gt;&lt;p&gt;更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
