<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>EmbodiChain开源，用100%生成式数据自动训练具身智能模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 15:27:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["list",{"type":"ul","style":"list-style-type: disc","class":"list-paddingleft-1","start":null},"listitem",{"style":"color:#7b0c00"},"para",{"tagName":"p","attributes":{"style":"text-align: left; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;论文地址:&amp;nbsp;&lt;/span&gt;https://www.techrxiv.org/doi/full/10.36227/techrxiv.176153394.41323502&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源主页:https://dexforce.com/embodichain/index.html#/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库: https://github.com/DexForce/EmbodiChain&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;技术文档: https://dexforce.github.io/EmbodiChain/introduction.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大语言模型的爆发，让大家见证了 Scaling Law 的威力：只要数据够多、算力够猛，智能似乎就会自动涌现。但在机器人领域，这个公式似乎失效了。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 LLM 时代，数据是「存量」，我们只需要负责「清洗」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在具身智能时代，数据必须是「增量」，我们必须具备「创造」数据的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不同于互联网上唾手可得的万亿级文本，机器人所需的、经过 3D 标定且符合物理规律的高质量交互数据，极度稀缺且昂贵。正因如此，数据采集范式成为了近年来行业研究的绝对焦点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可以看到，整个行业正在向着更低成本、更便捷的方向全速推进：&amp;nbsp;&lt;/strong&gt;从昂贵的遥操设备，到基于动捕手套的灵巧手捕捉和更加便携式的夹爪方案，再到如今甚至不再需要佩戴手套、仅凭双手演示即可采集数据的创新方案。&lt;strong&gt;这些轻量化的数采范式正在将人类的经验数字化，这一路径不仅充满价值，更值得持续深耕，它是连接人类技能与机器人动作的桥梁。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;整个行业在将具身智能推向大模型时代的这个目标上狂奔。&lt;/p&gt;&lt;p&gt;但是，即使是最极致的采集效率，客观上仍受限于物理时间的流逝和人力成本的边界。当下没有任何现有的物理采集范式，能匹配 LLM 训练所需的「互联网级」规模。这成为了具身智能迈向更高阶智能的最大桎梏。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;效率定律&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了突破这一天花板，需要引入一个新的视角。在传统的 Scaling Law 中，主要关注数据集、算力和参数量。但在具身智能中，有一个被忽视的隐形变量：&lt;strong&gt;数据生成的速率（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:34px;height:23px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ce295742-ac2d-4024-a857-0c2f6da74a5f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dii" style="width: 4.32%;"&gt;）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是&lt;strong&gt;跨维智能团队在论文《GS-World》中提出的核心洞察：智能的进化存在一个「逃逸速度」。&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;瓶颈期&lt;/strong&gt;：&amp;nbsp;当数据生成太慢（依赖人工采集或低速仿真），模型参数再大也无济于事，因为模型「吃不饱」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;爆发期&lt;/strong&gt;：&amp;nbsp;只有当&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:36px;height:24px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2f4ea652-7313-489e-96b8-1950b398f2f3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 4.2%;"&gt;超过临界值&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0TwiaiaZsSVyibmRPSELzibOwhibJzhB33JjX2L46Esibt6oassQsiaYjicFd6w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6216216216216216" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503529097" data-aistatus="1" data-original-style="width:45px;height:28px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/92e1d024-db2f-4dbe-8ac8-8bfebbd17a7e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dii" style="width: 5.6%;"&gt;，数据不再是稀缺资源，而是像自来水一样源源不断时，模型性能才会随着参数量的增加而线性释放。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0dqnsfnUGYb2GCibhqYf5ZR85vPGnHZhUichVMvbKB31ibdicjfwJFGNOrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6376811594202898" data-s="300,640" data-type="png" data-w="828" type="block" data-imgfileid="503528999" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/dcf105fb-5df5-43d6-b393-633bba1c17b0/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 效率定律 (Efficiency Law) 下模型性能与数据生成速率的关系&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;要跨越这个鸿沟，除了物理采集的持续精进，另一种极具潜力的解决方式，就是&lt;strong&gt;构建一个能够超高速、自动化生成物理现实的数字世界&lt;/strong&gt;（跨维智能团队在《GS-World》中详述了这一路径）。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0c9DibAnhSlwxiavZtwwg5iczdngQJnppRcsx0KUn7OcGl4T9EpkopD5Gw/640?wx_fmt=jpeg#imgIndex=5" data-ratio="0.3925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0icQFeqRic5svorYD3gwqf7SGD3mQAQBRqEG3ibNtfvRROqKNURS22aDSA/640?wx_fmt=png&amp;from=appmsg" data-cropx2="1080" data-cropy1="26.903914590747327" data-cropy2="449.67971530249105" data-imgfileid="503529002" data-aistatus="1" data-original-style="width:562px;height:220px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3e2fc684-8258-467b-984c-8e75b7144d7b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在这个基于物理引擎的生成式世界中，数据的生成速率超越了时间的限制（Efficiency Law）；机器人可以在零成本的试错中习得对物理因果的深刻理解；所有的边缘情况（Corner Cases）都可以在这里被模拟、被攻克。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GS-World 与 EmbodiChain&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，跨维智能正式开源 EmbodiChain。作为通往&lt;strong&gt;&amp;nbsp;GS-World（基于生成式仿真的世界模型）&amp;nbsp;&lt;/strong&gt;的基石，EmbodiChain 不仅仅是一个数据和模型平台，更是一次对具身智能学习范式的重构。&lt;/p&gt;&lt;p&gt;跨维团队提出并验证一个大胆的假设：&lt;strong&gt;仅凭 100% 的生成式仿真数据，只要生成速率（Rate of Generation）突破临界点，机器人就能在真实世界中涌现出超越 SOTA 的泛化能力。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这不是科幻，这就是跨维正在验证的&lt;strong&gt;效率定律（Efficiency Law）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;EmbodiChain 的本质，就是一台&lt;strong&gt;将&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0he59Oh6gXzDujPiaZhA1P8tZVWd312W979SaoO27jxrMblc2K8fL4hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="60" type="block" data-imgfileid="503529096" data-aistatus="1" data-original-style="width:34px;height:23px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1850e3b5-3909-44ed-b0c1-8d67429646bc/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 4.11%;"&gt;拉满的数据和模型制造引擎&lt;/strong&gt;。它不再依赖对真实世界的有限采样，而是开启了具有物理真实性的数据的批量制造。&lt;/p&gt;&lt;p&gt;然而，要将 GS-World 从蓝图变为现实，绝非易事。跨维研究团队必须面对并攻克&lt;strong&gt;三个核心科学难题&lt;/strong&gt;，这也是 EmbodiChain 致力于解决的关键：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何实现数据生产自动化？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;真实世界极其复杂，如何仅凭少量先验（如一段视频、一句描述），就在数字世界中自动重建、生成海量且物理一致的场景与任务，而无需人工手动搭建？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何打破「虚实鸿沟」（Sim2Real Gap）？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;仿真数据再多，如果不能迁移到真机也是徒劳。如何在不依赖或尽量少依赖真实数据微调的情况下，让模型习得适应真实世界噪声与动态变化的鲁棒策略？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何突破数据生成的「IO 墙」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Scaling 需要亿级甚至十亿级的交互步数。传统的「生成 - 存储 - 读取 - 训练」模式效率极低。如何构建极致高效的数据流转机制，实现「在线数据流」？&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;EmbodiChain：一条永不停歇的「在线数据流和模型生产线」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了实现这一愿景，跨维智能构建了&lt;strong&gt;&amp;nbsp;GS-World（Generative Simulation World Model，生成式仿真世界模型）&lt;/strong&gt; 的核心基石 &amp;mdash;&amp;mdash;EmbodiChain。&lt;/p&gt;&lt;p&gt;EmbodiChain 作为一个底层的基建技术，可以把它看作&lt;strong&gt;去存储化的数字化流水线&lt;/strong&gt;。Scaling 需要亿级甚至十亿级的交互步数，传统的「生成 - 存储 - 读取 - 训练」模式在面对海量 3D 数据时，存储与传输将成为不可承受之重。&lt;/p&gt;&lt;p&gt;在 EmbodiChain 的架构中，可以彻底抛弃「先存硬盘、再读硬盘」的陈旧范式，取而代之的是在线数据流（Online Data Streaming）和模型自动生产线。&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/105066a2-86d0-4c78-bebe-8903fa14489a/1768893817074.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;EmbodiChain 的核心工作流。数据在生成的同时即被消费，橘色的数据流贯穿全场，无需落地存储。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这条流水线是如何工作的？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;世界生成（Generative Simulation）&lt;/strong&gt;：&amp;nbsp;引擎不仅是环境，更是造物主。Real2Sim 模块从极少的真实样本中提取物理先验，Gen2Sim 模块则响应语言指令，自动构建出符合牛顿力学等物理规律的 3D 场景与资产。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据扩增（Data Scaling）&lt;/strong&gt;：&amp;nbsp;数据不仅要多，还要「难」。系统自动进行视觉增强、物理参数随机化，并剔除那些机器人「够不着」的无效采样。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;自我修复（Closed-loop Recovery）&lt;/strong&gt;： 真正的智能来自于从错误中学习。当仿真中的机器人抓取失败，系统会自动生成修正轨迹。这种「失败 - 修正」的闭环，比单纯的成功演示更有价值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一切都在 GPU 内部并行高速运转，数据如洪流般产生，训练完即销毁，不留下一丝冗余，只留下模型能力的增长。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;路线之争：机器人需要的是物理精确的生成式模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在通往具身智能世界模型的路上，目前存在两条截然不同的路线。&lt;/p&gt;&lt;p&gt;一条是近期火热的&lt;strong&gt;视频生成路线（Video World Model）&lt;/strong&gt;，如 Sora 或 LTX-Video，它们试图通过「画出」下一帧来模拟世界。虽然视觉效果惊艳，但一些对比实验揭示了其致命弱点：&lt;strong&gt;幻觉&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;视频模型生成的画面往往缺乏长程的时空一致性，且很难精确遵循动力学方程。用这种「做梦」产生的数据训练机器人，就像让一个飞行员在爱丽丝的仙境中学习开飞机 &amp;mdash;&amp;mdash; 看着很美，一上真机就坠毁。&lt;/p&gt;&lt;p&gt;相反，EmbodiChain 选择的是 &lt;strong&gt;GS-World 路线（基于生成式仿真的世界模型）&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物理先验（Physical Priors）：&lt;/strong&gt; 跨维智能坚持世界模型必须是 3D 的、交互式的、物理严谨的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;特权信息（Privileged Information）：&lt;/strong&gt; 在 EmbodiChain 中，使用者拥有上帝视角。比如使用者能够获取物体的精确掩码、空间关系和可供性（Affordance）。通过训练模型预测这些真实世界中不可见的「特权信息」，迫使模型理解了场景背后的&lt;strong&gt;几何本质&lt;/strong&gt;，而不仅仅是表面的像素。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这正是 Yann LeCun 所倡导的理念：&lt;strong&gt;世界模型应该是对世界状态的预测与规划&lt;/strong&gt;。&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dd396cbb-f4b4-48f4-8828-758f30f822ca/1768893887934.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; EmbodiChain中可以获取的特权信息示例&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;零真实数据，VLA 真的可行吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了验证这套「效率定律」，跨维智能做了一件极端的测试：&lt;strong&gt;不使用任何真实数据训练模型。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;跨维智能训练出的 Sim2Real-VLA 模型，在真实世界中执行任务。结果令人惊讶：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;远超基线&lt;/strong&gt;：&amp;nbsp;在没有任何真实数据微调的情况下，它在操作成功率上大幅领先 ACT、Diffusion Policy 等主流方法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无惧干扰&lt;/strong&gt;： 即使跨维智能像「捣乱者」一样更换桌布、移动物体、改变光照，模型依然稳如泰山。甚至在某些任务中，由于去除了真实数据中容易过拟合的背景噪声，模型的表现反而比用真实数据训练还要好。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/b68ec599-9159-4c23-bad5-e4d31f5949b0/1768893920724.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;a href="https://mp.weixin.qq.com/s/IGe1myOEmAW7JOrQyBLhBA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c77d8ed0-5332-42f9-a212-65d5192f37e6/1768893933659.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0d8E8iamrJjup4bGsiaYKEj9bln7RDgf6pqtyYOlDso3Wmh6MbsiaALtKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5652173913043478" data-s="300,640" data-type="png" data-w="828" type="block" data-imgfileid="503529026" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/3a27c0cd-e3dd-46f2-8832-0755bc459581/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;Sim2Real-VLA 在全生成数据训练下，不仅击败了 SOTA，更展现了惊人的鲁棒性。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;愿景：通往 GS-World 的「效率奇点」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;EmbodiChain 的开源，只是一个开始。&lt;/p&gt;&lt;p&gt;GS-World 蓝图远不止于此。在跨维智能的规划中，&lt;strong&gt;这是一个引擎驱动的闭环路径（Engine-driven Loop）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不仅环境是生成的，任务也是生成的；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不仅策略是进化的，机器人的身体结构（Morphology）也会随着任务需求协同进化。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;跨维智能希望 EmbodiChain 能成为每一位具身智能研究者的基础设施。不需要再为了几千条数据而在实验室里没日没夜地遥操作，不需要再为几十 TB 的硬盘存储发愁。&lt;/p&gt;&lt;p&gt;因为智能的未来，不应该被困在数据的匮乏中。&lt;/p&gt;&lt;p&gt;EmbodiChain 现已开源，邀请你一起见证具身智能的「效率奇点」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一周对战2500万局，这些「AI假人」让人类游戏玩家破防了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 13:32:04 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜张倩&lt;/section&gt;&lt;p&gt;谁能想到，有朝一日，人在游戏里会被 AI 耍得团团转。&lt;/p&gt;&lt;p&gt;2025 年，国产游戏跑出一匹黑马 &amp;mdash;&amp;mdash; 巨人网络的《超自然行动组》。这款微恐题材多人合作游戏玩法直接：4 人组队进入古墓「摸金」，搜宝、打怪、限时撤离。7 月，这款游戏同时在线人数突破 100 万，它还长期霸占 App Store 免费榜和畅销榜前列。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528979" data-ratio="0.4609375" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0RHJZESx2H19ia9obIDE6YiasoKWtf7VFib9esc8icTbERTuwiaibZjDq30gA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/fa55cc72-ee4d-467b-92d4-407f3c9630d8/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0B6zHN7fRrCzhY4ExRc0cpCAwFZiciawWvCKibVsJ3MsvcG9cibh4coyxEQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-ratio="0.4609375" data-type="gif" data-w="640" type="block" data-imgfileid="503528980" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4840fd3d-90b5-42bd-82c5-bb71d87aab2f/640.gif" data-order="1" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更有意思的是，最近它又上线了一个新玩法：游戏里的怪物「假人」，接入了 AI 大模型。&lt;a href="https://mp.weixin.qq.com/s/jC9mZNs9mEy8v7c_SJGW1g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/06477058-b287-4031-8572-5e42b6cbd885/1768886894272.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;以前的 NPC 是脚本驱动，套路固定，老玩家一眼识破。现在不一样了，AI 假人会实时语音交流，能模仿队友音色，会说「跟我走，这边有好东西」，然后把你带进埋伏圈。它们会跳舞、会帮你打怪、会假装「中国好工友」，直到关键时刻突然反水&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/jC9mZNs9mEy8v7c_SJGW1g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9b30c4a4-ef3c-48c3-8878-8ef8c4142958/1768886913334.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 玩家被 AI 假人背刺案例。视频来源：抖音号 @钦佳丕定。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;新玩法上线后，玩家社区炸了。抖音、小红书上，「被 AI 背刺」「和 AI 假人尬舞」「全程没认出队友是 AI」的视频疯传。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ077RTzjzUT5FHyISg9jicHJb2OBtdtiaF8sNTJYsLT9SywwheiaYJKzaeQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="1.799074074074074" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528981" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/58dcc44c-7aac-45a8-b5dd-4ffe49cab1be/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0rwS5PRiaJZWWgvk3UQYpolykpibJuO9HzVA9ShjA7zJ6dFOHS3pVhTPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4935822637106184" data-s="300,640" data-type="png" data-w="857" type="block" data-imgfileid="503528982" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/faec334f-78bf-4d30-a035-27fa9c4cfab8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这不是实验室 Demo。上线一周，AI 就参与了近 2500 万场对局。巨人网络联合阿里云、火山引擎、腾讯云，在模型适配、实时推理、高并发稳定性上反复打磨，让这套系统真正跑了起来。&lt;/p&gt;&lt;p&gt;这也让《超自然行动组》成为&lt;strong&gt;国内首个在大 DAU 游戏中深度融合 AI 大模型、并实现规模化落地的产品&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这次探索让我们看到，当 AI 被放在合适的位置，它完全可以走进对局，参与博弈，让游戏本身变得更好玩，而不再只是站在玩法之外、可有可无的工具。当 AI 深度参与到游戏玩法的创造，游戏的研发也在从根本上发生改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 之于游戏 &amp;nbsp;无处不在，但游走于「安全区」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要说哪个行业最欢迎 AI，游戏行业绝对可以排进前几名。从直接生成美术资产到实时匹配队友、控制游戏难度再到扮演 NPC，AI 已经无处不在。&lt;/p&gt;&lt;p&gt;但如果仔细观察，我们可以发现一个现象：&lt;strong&gt;这些应用场景，绝大多数还处于「安全区」，AI 的「工具」属性非常明显。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就拿 AI NPC 为例。其实当前大多数 AI NPC 还是以对话型 AI 助手为主，它们会给你提供游戏攻略、武器使用说明等信息服务，甚至在支线剧情里演绎一些故事，但由于不参与对局，它们的存在本质上是和核心玩法分离的。无论 AI 表现如何，都不会影响玩家在对局中的实际体验。自动匹配队友、个性化内容推荐等功能也是一样，AI 同样游离于核心玩法之外。&lt;/p&gt;&lt;p&gt;更值得关注的是，&lt;strong&gt;目前大多数 AI 与游戏结合的探索仍停留在用户量较小的产品中，或仅在测试环境下进行验证&lt;/strong&gt;。一旦进入高并发、大 DAU 的真实场景，AI 系统的稳定性便难以得到保证，这也是游戏厂商们普遍保守的重要原因。&lt;/p&gt;&lt;p&gt;在这样的背景下，《超自然行动组》对 AI 大模型的深度整合看起来非常「前沿」，因为这次，&lt;strong&gt;他们用 AI 给人类创造了一些「对手」，在核心对局里验证稳定性、体验和风险&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;《超自然行动组》让 AI 加入核心对局，创造真实博弈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在《超自然行动组》中，AI 假人被设计成一个&lt;strong&gt;你必须认真对待的博弈对象&lt;/strong&gt;，因为它们会根据你的警惕程度、和你的距离、周围有没有目击者，动态决定是继续「装队友」还是趁机动手。你以为摸清了它的套路，下一局它可能就换了策略。这让体验从「背板过关」变成了「斗智斗勇」。&lt;/p&gt;&lt;p&gt;与此同时，AI 假人也被设计成一个「&lt;strong&gt;懂分寸的队友&lt;/strong&gt;」。它知道什么时候该互动、什么时候该闭嘴 &amp;mdash;&amp;mdash; 安全时主动找你聊两句，战斗时自动消停，不会在你手忙脚乱时刷屏。偶尔来一段跳舞、一个表情、一句调侃，存在感刚刚好，不抢戏，但让你觉得「这队友还挺有意思」。&lt;/p&gt;&lt;p&gt;这套设计落到实际体验里是什么样子？从玩家反应来看，AI 假人让人又爱又恨。有的玩家会把捡到的摸金符等道具丢给它，让它帮忙携带，但后来发现一旦自己被怪物攻击，AI 假人可能会带着所有物资逃跑，让人哭笑不得。很多玩家会跟它说「带我去找大金」，AI 假人确实会带路，有时还能找到雪莲花这类稀世珍宝，但也有可能把玩家带到死胡同里，让人一无所获。甚至，它们有时会抢玩家掉在地上或刚开棺发现的东西，玩家要是抢不过它们就只能努力把它们打死。&lt;a href="https://mp.weixin.qq.com/s/jC9mZNs9mEy8v7c_SJGW1g"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/11c068a9-e107-4c48-858c-9e72de3e7445/1768886994598.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; AI 假人帮助人类玩家案例。视频来源：小红书博主 @十（超自然）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;更有意思的是，由于 AI 假人可以模仿真人的语音、行为，还懂得「欺骗」，很多玩家一上来根本分不出它们是真人队友还是 AI，这就给对局带来了更大的&lt;strong&gt;不确定性和紧张感&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这正是《超自然行动组》与那些「安全区」AI 的本质区别：AI 假人的表现会直接影响玩家这局的胜负。它帮人背东西、找宝贝，玩家就能更快达成目标；它抢玩家物资、把人带进死胡同，这局可能就此翻车。&lt;strong&gt;这不再是一个「无论 AI 表现如何都不影响体验」的辅助模块，而是核心玩法本身。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这也对 AI 的能力提出了更高要求，因为 AI 假人必须在复杂多变的对局环境中实时做出自主判断，做不好就很容易影响体验。而更难得的是，这套系统已经面向全量玩家开放，在高并发场景下依然保持稳定 &amp;mdash;&amp;mdash; 这在 AI 深度参与核心对局的案例中几乎没有先例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;好玩、刺激背后 &amp;nbsp;让大模型在规则圈内尽情发挥&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于巨人网络来说，这是一次高难度的尝试。将 AI 放进一个高并发、大 DAU 游戏的核心对局，既要保证系统稳定，又要让 AI 不破坏体验、反而增强沉浸感，背后需要大量技术打磨。&lt;/p&gt;&lt;p&gt;这背后的核心是一套&lt;strong&gt;「规则框架 + 大模型决策」的混合架构&lt;/strong&gt;：规则层划定边界，确保 AI 不会做出离谱的事；大模型则在边界内基于实时局势做判断，让每一次反应都有临场感。&lt;/p&gt;&lt;p&gt;当你说「带我去找大金」，它不会机械回复「好的」，而是真的理解你的意图，结合当前环境决定怎么走、要不要绕路。走错了会停下确认，被打断会重新调整目标 &amp;mdash;&amp;mdash; 这种「会犯小错、也会自己改」的表现，反而更像真人。&lt;/p&gt;&lt;p&gt;更关键的是，AI 假人能保持「&lt;strong&gt;言行一致&lt;/strong&gt;」。它说的话和正在做的事是绑定的，还能记住短期对话上下文，不会前一秒答应帮你找东西、后一秒就忘了自己在干嘛。这种连贯性，是让玩家觉得「它是个队友」而不是「一个会说话的 NPC」的关键。&lt;/p&gt;&lt;p&gt;正是游戏设计与技术的双重打磨，让《超自然行动组》有底气走出「安全区」，把 AI 从旁观者变成真正的参与者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;做得了爆款，啃得了技术 &amp;nbsp;巨人多年布局终兑现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;看到这里，你可能会好奇：把 AI 扔进核心对局这么大胆的事，为什么是巨人网络先做出来了？&lt;/p&gt;&lt;p&gt;答案很简单：他们确实准备了很久。&lt;/p&gt;&lt;p&gt;在国内众多游戏厂商中，&lt;strong&gt;巨人网络是最早、最系统地把 AI 当成「核心业务」来做的一批&lt;/strong&gt;：2022 年成立 AI 实验室；2023 年把 AI 写进研发管线；2024 年拿下国内首张「游戏垂直大模型」备案；2025 年又投资了 AI 图像平台 LiblibAI 和 AI 视频生成公司爱诗科技。这种自研、投资、产业协同多线并进的做法让我们看到了巨人网络推动 AI 与核心游戏业务深度融合的决心。&lt;/p&gt;&lt;p&gt;这些布局在游戏里也开始跑通了。2024 年，他们在社交推理游戏《太空杀》中成功探索了 AI 原生玩法，陆续推出了「AI 推理小剧场」「AI 残局挑战」「AI 残局对决」等模式，相关玩法累计吸数百万玩家参与，产生了数千万对局，为 AI 在游戏中的规模化应用积累了实践经验。&lt;/p&gt;&lt;p&gt;这些积累，最终在《超自然行动组》身上开花结果。负责这款产品的是一支非常年轻的团队，2025 年暑期即冲进 iOS 畅销榜 Top 10，把小众赛道做成全民品类。如今，他们又把 AI 大模型带进了核心对局。既能做爆款，也能啃硬骨头，这支年轻团队的表现，或许正是巨人网络多年 AI 投入开始兑现的信号，也是巨人网络持续跑在游戏行业前沿的证明。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;玩家反感 AI？《超自然行动组》打消行业顾虑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回到开头的问题：为什么大多数厂商不敢把 AI 放进核心对局？除了技术难度，还有一个更现实的顾虑 &amp;mdash;&amp;mdash; 玩家可能不买账。&lt;/p&gt;&lt;p&gt;这种担忧并非没有依据。GDC 数据显示，认为「AI 会给游戏行业带来消极影响」的玩家比例，从 2024 年的 18% 上升到了 2025 年的 30%。&lt;/p&gt;&lt;p&gt;但《超自然行动组》的实践提供了另一种可能。它用真实的玩家反馈证明：&lt;strong&gt;玩家反感的并不是 AI 本身，而是被工具化、破坏体验的 AI。当 AI 真正参与博弈，成为风险和刺激的来源，它反而可能被接受，甚至被欢迎。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这也是《超自然行动组》对行业更大的价值所在。当 AI 进入胜负系统，游戏应该如何被重新设计？这款产品给出了一个已经跑通的样本。&lt;/p&gt;&lt;p&gt;这类高频、强互动、可持续运行的 AI 原生玩法，一旦验证可行，意义不止于「多了一种玩法」，而在于它打开了一条新的内容生产路径：AI 不再只是辅助工具，而是内容生成与博弈本身的一部分，每一局都能产生新的变化与体验。这或许才是游戏行业下一个真正的增长空间。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>TPAMI | DC-SAM：打破SAM交互限制，基于循环一致性的图像与视频上下文分割方法</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 20 Jan 2026 13:26:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/97bf003e-0c97-44cc-9d91-9a0a47ae3832/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;上下文分割（In-Context Segmentation）旨在通过参考示例指导模型实现对特定目标的自动化分割。尽管 SAM 凭借卓越的零样本泛化能力为此提供了强大的基础，但将其应用于此仍受限于提示（如点或框）构建，这样的需求不仅制约了批量推理的自动化效率，更使得模型在处理复杂的连续视频时，难以维持时空一致性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;北京邮电大学联合南洋理工大学等&lt;/strong&gt;机构发表的 IEEE TPAMI 期刊论文《DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency》，不仅为图像和视频的上下文分割建立了统一的高效框架 &lt;strong&gt;DC-SAM&lt;/strong&gt;，还构建了首个视频上下文分割基准&lt;strong&gt; IC-VOS&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;研究团队巧妙地提出基于提示微调的 &amp;ldquo;循环一致性&amp;rdquo; 机制，通过正负双分支与循环一致性注意力的协同，配合 Mask-Tube 策略，实现了 SAM 与 SAM2 在图像及视频上下文分割任务上的统一与高效适配。&lt;/p&gt;&lt;p&gt;实验结果显示，DC-SAM 在多个基准测试中均取得了 SOTA 性能：在 COCO-20&lt;sup&gt;i&lt;/sup&gt; 上达到 55.5 mIoU，在 &amp;nbsp;Pascal-5&lt;sup&gt;i&lt;/sup&gt; 上达到 73.0 mIoU；在新建的 IC-VOS 视频基准上，J&amp;amp;F 得分高达 71.52，显著优于现有方法。该篇论文已被 &lt;strong&gt;IEEE TPAMI &lt;/strong&gt;录用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14LjibtpoKdq7r88CTaBaqEfHljJ2g1xO6pmPzgyjXjJObLIE1YvhVCdw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.19537037037037036" data-type="png" data-w="1080" data-width="1604" data-height="314" data-imgfileid="503528903" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f3ae3690-9d81-4fde-ab70-0a80440952d6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2504.12080&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接：https://github.com/zaplm/DC-SAM&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;研究背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，以 &amp;nbsp;SAM 和 SAM2 &amp;nbsp;为代表的视觉基础模型凭借海量训练数据，展现了卓越的交互式分割能力，已成为医学影像、开放词汇分割等下游任务的强大基石。然而，尽管 SAM &amp;nbsp;在 &amp;ldquo;分割一切&amp;rdquo; 上表现出色，却缺乏 &amp;ldquo;上下文分割&amp;rdquo;（In-Context &amp;nbsp;Segmentation）的能力 &amp;mdash;&amp;mdash; 即无法仅凭一张参考示例（Support Image）及其掩码，自动在查询图像（Query Image）中分割出同类目标。&lt;/p&gt;&lt;p&gt;为了弥补这一短板，早期的少样本学习方法多依赖度量学习，但泛化能力有限。虽然 SegGPT 等通用模型通过大规模图文对训练实现了上下文分割，但其计算资源消耗巨大。相比之下，提示微调（Prompt &amp;nbsp;Tuning）提供了一条高效路径。然而，现有的 SAM 适配方法（如 VRP-SAM）主要依赖骨干网络提取的通用特征，忽略了 SAM 自身提示编码器（Prompt Encoder）的特征特性，且往往未能充分利用背景（负样本）信息来约束分割边界，导致生成的提示精度不足。&lt;/p&gt;&lt;p&gt;此外，视频领域的上下文分割研究尚处于空白阶段。现有的视频分割基准（如 DAVIS、MOSE）主要侧重于给定首帧掩码的半监督跟踪任务，缺乏评估 &amp;ldquo;基于参考示例进行视频分割&amp;rdquo; 能力的专用基准。&lt;/p&gt;&lt;p&gt;针对上述挑战，研究团队推出了&lt;strong&gt;首个视频上下文分割基准 IC-VOS&lt;/strong&gt;，并同步提出了 &lt;strong&gt;DC-SAM 框架&lt;/strong&gt;。该框架旨在通过提示微调技术，将 SAM 与 SAM2 的能力无缝迁移至这一新任务，实现了统一高效的图像与视频上下文分割。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD145SgGRkZkWVfr5zdsIKHZ2iaUNiaCbtzJeXibjzabC72YXRbQmAT10GrnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.2657407407407407" data-type="png" data-w="1080" data-width="1744" data-height="464" data-imgfileid="503528904" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8922185d-708b-4aab-9935-199813ea863f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;DC-SAM与现有方法的对比图。 a) 方法对比图，b) &amp;nbsp;预测可视化对比图，c）得分对比图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;IC-VOS：首个面向上下文视频分割的大规模基准数据集&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在研究过程中，研究团队发现该领域缺乏一个专门用于评估 &amp;ldquo;上下文视频对象分割&amp;rdquo; 的统一基准。现有的 VOS 数据集大多侧重于第一帧掩码的追踪，而传统的 Few-shot 图像数据集则完全丢失了时间维度。&lt;/p&gt;&lt;p&gt;为了填补这一空白，研究团队推出了 &lt;strong&gt;IC-VOS (In-Context Video Object Segmentation) &amp;nbsp;数据集&lt;/strong&gt;。这是首个旨在全面衡量模型在视频上下文中学习能力的数据集。IC-VOS &amp;nbsp;涵盖了极其丰富的场景，包括极小目标分割、快速运动变形以及复杂背景融合等。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wkJNOgR4aEgrNI8RYQVO1vibRkqWBDCYk7UXO6D7Bl5RMgvm0oJYBpw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.2601851851851852" data-type="png" data-w="1080" data-width="1832" data-height="476" data-imgfileid="503528905" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9b60bf01-c1de-405a-b265-5ec5282aad9e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; IC-VOS 分割基准：a) 数据来源，b) 词云图，c) 类别分布，d) 示例样本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DC-SAM 框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DC-SAM 框架由三个核心部分组成：&lt;strong&gt;基于 SAM 的特征融合、正负双分支循环一致性提示生成&lt;/strong&gt;，以及&lt;strong&gt;面向视频的 Mask-tube 训练策略&lt;/strong&gt;。该框架旨在充分利用 SAM 的特征空间，通过显式的正负样本约束和循环校验，生成高精度的视觉提示。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14KSSmu9k8NVAo8dibyRatMxCiaMGUNnawpvqErLf95aaCBn9dzOApI3yw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4388888888888889" data-type="png" data-w="1080" data-width="1668" data-height="732" data-imgfileid="503528906" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/62014ff3-9976-4b2c-8eaa-73e002fe7824/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; DC-SAM方法概览图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于 SAM 的特征融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现有的上下文分割方法通常仅依赖于预训练骨干网络（如 ResNet 或 DINOv2）提取特征，这导致生成的 Prompt 与 SAM 内部的特征空间存在 &amp;ldquo;语义鸿沟&amp;rdquo;。&lt;/p&gt;&lt;p&gt;为了弥补这一差距，研究团队提出了一种&lt;strong&gt;特征融合&lt;/strong&gt;策略。在提取查询和支持图像的骨干特征（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14AThkfFr7icJfgjPtr3Ts78ga3RlDD8xrg4vXrBHqeIDdsH5vAJBYGXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.9607843137254902" data-s="300,640" data-type="png" data-w="102" type="block" data-imgfileid="503528907" data-aistatus="1" data-original-style="width: 27px;height: 26px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/48f4f8c8-8349-401a-b3d0-3a475b9bc690/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.27%;"&gt;和&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JeP2uQ6D0F0KicTyEn61V8ibJLf0261TZlA3p85txFrdgk0h0SiczzN6A/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.8679245283018868" data-s="300,640" data-type="png" data-w="106" type="block" data-imgfileid="503528908" data-aistatus="1" data-original-style="width: 26px;height: 23px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1c7ecee8-ba84-40ee-bc44-77ec8ff5b1ae/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;）的同时，也提取 SAM Image Encoder 的特征 (&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14OQMXkfGejXlUIQ9fGcBevc6ibwzpJFyNxE7oODnv3PbqynnfxDG5HIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5945945945945946" data-s="300,640" data-type="png" data-w="222" type="block" data-imgfileid="503528909" data-aistatus="1" data-original-style="width: 43px;height: 26px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6eace2bc-1057-40fa-b5d2-87716279a39e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 6.22%;"&gt;和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14wyE1ibwYtcve7cHria3Hq1EdHRgRDtYdG2E34GAM61aCG4IbFkUlWEpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5259259259259259" data-s="300,640" data-type="png" data-w="270" type="block" data-imgfileid="503528911" data-aistatus="1" data-original-style="width: 44px;height: 23px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f70c9f26-9dcc-4fbf-891d-005a3ce5da6b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 6.54%;"&gt;&lt;span align="" alt="" border="" data-aiimageid="" data-aiimagesource="" data-aistatus="1" data-asynid="" data-backh="" data-backw="" data-before-oversubscription-url="" data-cacheurl="" data-cardimg="" data-copyright="" data-croporisrc="" data-cropselx1="" data-cropselx2="" data-cropsely1="" data-cropsely2="" data-cropx1="" data-cropx2="" data-cropy1="" data-cropy2="" data-fileid="" data-fromlib="" data-galleryid="" data-gallerysupplier="" data-height="" data-imgfileid="503528910" data-imgid="" data-imgqrcoded="" data-oversubscription-url="" data-positionback="" data-ratio="" data-remoteid="" data-retry="" data-s="300,640" data-src="" data-type="png" data-upload="" data-w="" data-width="" height="" ismap="" sizes="" src="" title="" type="block" usemap="" width=""&gt;)。随后，将骨干特征、SAM 特征以及通过参考掩码加权的特征进行拼接与融合：&lt;/span&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14vo9bteGqcY9L56QO3XYO9CeWWaGsDiaF5Qx4aPQxDXPt9N5XzW1icY9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.175" data-type="png" data-w="1080" data-width="1430" data-height="250" data-imgfileid="503528912" data-aistatus="1" data-original-style="width: 379px;height: 66px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/03b42633-1d9c-4fa0-a85d-5bfc6d10ada2/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HG6KeCFSDRpL68rGns4iagF12Cem3kiaYLWdL3ibA1IYkknY42rQYicGgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8918918918918919" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503528967" data-aistatus="1" data-original-style="width:29px;height:26px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/a5eeed39-65d5-4255-9830-ecdacee0f6a6/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.58%;"&gt;为参考掩码，&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14oKA9aq1tSwKhFibqXibNrmOLNpI0jnU4Iof4iaibI7Q0Iwoib6knybdWoUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0253164556962024" data-s="300,640" data-type="png" data-w="158" type="block" data-imgfileid="503528914" data-aistatus="1" data-original-style="width: 28px;height: 29px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3556447c-37ac-432b-83ee-55d1f1b1041f/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Zlskr3Rd3L8jaSw16kVKrpShk2wqxW3z7NdN9q2sN5Ry61fSAdv9RQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.971830985915493" data-s="300,640" data-type="png" data-w="142" type="block" data-imgfileid="503528968" data-aistatus="1" data-original-style="width:26px;height:25px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/a786f993-1062-483d-9262-4a378302dd09/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;为融合后的特征。这种设计确保了特征表示既包含通用的语义信息，又保留了 SAM 特有的视觉模式，为后续的提示生成提供了更适配 SAM 的输入。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14BjU4HLbWhrxsjFJKFYAqYENZ5qxEnn4icvWd9QSuAYwic1lpZGZknR1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5924764890282131" data-type="png" data-w="638" data-width="638" data-height="378" data-imgfileid="503528916" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/36646528-eddd-4931-a505-1b227b1f0f27/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 基于 SAM 的多源特征融合方法图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;正负双分支循环一致性提示生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;正负双分支循环一致性提示生成是 DC-SAM 的核心模块。为了解决单一前景提示带来的边界模糊问题，研究团队设计了正负双分支（Dual-Branch）结构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;正分支利用参考掩码&amp;nbsp;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HG6KeCFSDRpL68rGns4iagF12Cem3kiaYLWdL3ibA1IYkknY42rQYicGgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.8918918918918919" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503528967" data-aistatus="1" data-original-style="width:29px;height:26px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/1fa3bef8-fd55-4173-a5b2-c32a68363c3a/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dii" style="width: 4.42%;"&gt;生成正样本提示，聚焦目标主体；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;负分支利用背景掩码 1-&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14HG6KeCFSDRpL68rGns4iagF12Cem3kiaYLWdL3ibA1IYkknY42rQYicGgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.8918918918918919" data-s="300,640" data-type="png" data-w="148" type="block" data-imgfileid="503528967" data-aistatus="1" data-original-style="width:29px;height:26px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/ba016d36-b209-47ba-9ad1-d06e3ef74271/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 4.09%;"&gt;生成负样本提示，抑制背景噪声。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在每个分支内部，为了防止 &amp;ldquo;语义漂移&amp;rdquo;（即错误匹配非目标区域），研究团队引入了&lt;strong&gt;循环一致性交叉注意力（Cyclic Consistent Cross-Attention）&lt;/strong&gt;。其核心思想是：只有当支持图像中的像素 j 与查询图像中的匹配像素 j* 满足语义类别一致时，才保留该注意力权重；否则，通过偏置项 B 将其屏蔽：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14yXK5jKOv1ARoUcnW6nauDGgTompkT6zCQfCAUVILrENwWV3Hk1fTHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.24444444444444444" data-type="png" data-w="1080" data-width="1080" data-height="264" data-imgfileid="503528917" data-aistatus="1" data-original-style="width: 337px;height: 82px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/81225a0b-2cbc-4b7c-a052-b836a2b0b533/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;基于该偏置项，可以计算经过循环校验的注意力输出，确保生成的 Prompt 仅聚合高度可信的特征：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14U8g5ib70jfYcfL0kWvXPOXBZNl1fzxpDkLr8nZCY3D8v78jPZeicMxeg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.08333333333333333" data-type="png" data-w="1080" data-width="1132" data-height="94" data-imgfileid="503528918" data-aistatus="1" data-original-style="width: 391px;height: 32px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/f23eb5f4-97b4-48f6-99b3-6695be937c44/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;最终，正负分支生成的 Prompt 分别叠加 SAM 预训练的 Pos/Neg Embeddings，共同指导 Mask Decoder 生成精准掩码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Fe53GHHF7yps9HSz2vaX8YQqDzSrJLmONUBTmELNP4FxzQfMa9hiceQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.3574074074074074" data-type="png" data-w="1080" data-width="1316" data-height="470" data-imgfileid="503528919" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/3384da67-67a9-4adf-b3cb-3262726f7ed2/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 正负双分支循环一致性提示生成方法图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向视频的 Mask-tube 训练策略及模型优化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;得益于 SAM 与 SAM2 在 Prompt Encoder 上的架构一致性， DC-SAM 可以无缝迁移至视频领域。为了赋予模型处理时空动态的能力，研究团队设计了轻量级的 &lt;strong&gt;Mask-tube（掩码管道） &lt;/strong&gt;训练策略，通过数据增强将静态图像堆叠为伪视频序列，从而模拟连续帧之间的时序变化。&lt;/p&gt;&lt;p&gt;在优化阶段，无论是图像还是视频流的预测，均由二元交叉熵损失（BCE Loss）和相似度度量损失（Dice Loss） 共同约束。最终的总损失函数定义为两者的加权和，以平衡局部像素分类与整体区域重叠度的优化目标（超参数 &amp;lambda; 经验性地设置为 1）：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148vEsF9GboZIBv3ZR6PENJA2DK3JThE5y0A5Qf666HTZgIBR0VOEcnw/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.18253968253968253" data-s="300,640" data-type="png" data-w="504" type="block" data-imgfileid="503528969" data-aistatus="1" data-original-style="width:214px;height:39px;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/1867268c-686b-44c4-b09d-b268127b26fc/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;性能评估与实验分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结果方面，DC-SAM 在图像上下文分割基准 COCO-20&lt;sup&gt;i&lt;/sup&gt; 和 &lt;span data-pm-slice='2 2 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Pascal-5&lt;sup&gt;i&lt;/sup&gt; 上&lt;/span&gt;取得显著性能优势。与基础视觉模型对比，即使面对使用了海量图文对训练的通用模型 SegGPT（56.1 mIoU），基于 DINOv2 的 DC-SAM 依然在 COCO-20&lt;sup&gt;i&lt;/sup&gt; 上取得了 62.0 mIoU 的成绩，实现了近 6% 的性能反超，证明了所提出提示微调方法的泛化能力。与 基于 SAM 的方法对比，在同等骨干网络（ResNet50）下，DC-SAM 全面超越现有的 SAM 适配方法，即使对比最强的基准模型 VRP-SAM，也在COCO-20&lt;sup&gt;i&lt;/sup&gt; 超越了 1.6%，证明 SAM 特征融合方法以及 Prompt 生成的有效性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ClDClXHlcrXdia82sQaGrHd7icCpfk7ePMLPxcsdsMtDMPZcCDCJQhmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.7069351230425056" data-type="png" data-w="894" data-width="894" data-height="632" data-imgfileid="503528921" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/0c8c3e20-f824-4240-8f7d-3aef69950a31/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在团队首创的视频基准 IC-VOS 上，DC-SAM 取得了 71.52 的 J&amp;amp;F 得分，以 6.4% 的显著优势超越了 VRP-SAM，并大幅领先 PerSAM。这不仅充分验证了 Mask-tube 策略的有效性，更证明了循环一致性约束能有效抑制视频传播过程中的语义漂移，实现稳健的目标锁定。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD1485mGHAvf9Xh3dwK555mYuBdMnmovd14VZby4lAWNZ1mmtLMU6D2WVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.4111111111111111" data-type="png" data-w="1080" data-width="1630" data-height="670" data-imgfileid="503528922" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/e129a901-c1c7-46f4-bce0-d07d951e26c4/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;为了直观评估模型性能，研究团队对 &lt;span data-pm-slice='2 2 ["para",{"tagName":"p","attributes":{"data-pm-slice":"2 3 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"lang":"EN-US"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;Pascal-5&lt;sup&gt;i&lt;/sup&gt; 和 IC-VOS 上的分割结果进行了可视化分析。在&lt;strong&gt;图像任务&lt;/strong&gt;中，DC-SAM &amp;nbsp; 展现了对复杂结构和细粒度特征的强大捕捉能力。无论是 &amp;ldquo;瓶子&amp;rdquo; 的完整轮廓，还是 &amp;ldquo;鸟类&amp;rdquo; 的细微纹理，模型均能生成高精度的掩码；特别是在处理 &amp;ldquo;自行车&amp;rdquo; 和 &amp;ldquo;飞机&amp;rdquo; 等复杂物体时，DC-SAM &amp;nbsp;有效抑制了背景区域的误检（False Positives），边缘分割清晰锐利。&lt;/span&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14BXbKlPGiaCKEDxOUQub7rF5KXibqXzfY2fnibibDUfic7RwlTjYfgnYnKBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.45092592592592595" data-type="png" data-w="1080" data-width="1534" data-height="692" data-imgfileid="503528923" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/0979fcf1-1fcc-4b3b-9bc2-b5acc860ff99/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图像上下文分割效果对比图，黄色的叉表示明显错误。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在更具挑战的&lt;strong&gt;视频任务&lt;/strong&gt;中，DC-SAM &amp;nbsp;的优势进一步凸显。以 &amp;ldquo;摩托车&amp;rdquo; 视频序列为例，基线模型 PFENet &amp;nbsp;出现了明显的语义漂移现象，不仅漏检了车轮，还错误地将骑手包含在分割目标内。相比之下，DC-SAM &amp;nbsp;能够精准区分干扰对象（如骑手）与目标主体，在连续帧中实现了稳健的语义锁定与追踪。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Psv02VZcZPRuO1DLby4cZLoWSS39gcZiaXn5AktJWpkVQxBVTm4RmRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.4203703703703704" data-type="png" data-w="1080" data-width="1412" data-height="594" data-imgfileid="503528924" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/bf00ad17-61ca-46e1-ba34-aa02aba64330/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 视频上下文分割效果对比图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我们相信，DC-SAM &amp;nbsp;的提出为视觉大模型的落地应用，尤其是在需要高效、自动处理海量视频数据的工业与科研领域，提供了极具竞争力的解决方案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;齐梦实，北京邮电大学计算机学院，教授、博导。博士毕业于北京航空航天大学，美国罗切斯特大学联合培养博士。曾工作于瑞士洛桑联邦理工学院CVLAB担任博士后研究员，百度研究院访问研究员等。入选2021年第七届中国科协青年人才托举工程（中国人工智能学会）、2024年小米青年学者、2025年ACM北京分会新星奖。主要研究方向为人工智能、计算机视觉和多媒体智能计算等。作为主要负责人承担国家自然科学基金（面上/青年）、北京市自然科学基金-小米创新联合基金、腾讯犀牛鸟课题、小米、阿里、微软合作项目等，并作为核心研发人员参与了国家自然科学基金重大/重点项目、科技部重点专项和港澳台科技专项等，发表国际高水平期刊会议论文50余篇，包括顶级学术会议CVPR/ICCV/ECCV/NeurIPS/ACM MM/AAAI和权威学术期刊TPAMI/TIP/TMM/TCSVT/TIFS等，担任顶级会议AAAI、IJCAI的领域主席和TMM的特邀编辑。&lt;/p&gt;&lt;p&gt;毕萧扬，北京邮电大学计算机学院，硕士研究生。主要研究方向为人工智能、计算机视觉和自动驾驶等。作为核心研究人员参与北京市自然科学基金-小米创新联合基金、腾讯犀牛鸟课题等重点科研项目。发表的国际高水平论文成果收录于权威学术期刊TPAMI和顶级学术会议UbiComp。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>MIT、哈佛等让细胞「记住」自己的基因活动历史，首次在哺乳动物细胞中记录转录组状态</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Tue, 20 Jan 2026 12:02:30 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;细胞的状态随时间而调整，若要理解细胞如何做出自己的决策，需要能够将过去的分子状态与未来的表型结果联系起来。&lt;/p&gt;&lt;p&gt;故而，来自 MIT 与哈佛大学的团队设计了一个细胞时间胶囊，能够收集和存储过去活动的记忆。这些被称为 TimeVault 的细胞储存单元，可能有助于揭开抗癌药物耐药性和干细胞生物学的秘密，揭示过去事件如何塑造细胞的未来。&lt;/p&gt;&lt;p&gt;相关研究以「&lt;em&gt;A genetically encoded device for transcriptome storage in mammalian cells&lt;/em&gt;」为题，于 2026 年 1 月 15 日发布在《Science》。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="100027195" data-ratio="0.24777006937561943" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkjU5iagtb5ATnoR0Gnib45uCIos5a14ibjvAwh7FP2icYK7lHlpLraeibDWtYibSXk6nGQ1gjdg7zAzJgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1009" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/fdf2c857-57c3-430e-a542-fe97d3bfb0ce/640.png" alt="图片" data-before-load-time="1768881694791" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.science.org/doi/10.1126/science.adz9353&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;细胞录音机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;细胞是不断变化的，对于这种动态过程，研究人员通常会采用两种方式进行研究。一种方法是在显微镜下观察它们的生命，通过荧光标签追踪有限数量的分子数天。另一种方法是在试管中，在实验的单一时间点（通常是实验结束时），测量 mRNA 分子，并与其他细胞中的分子进行比较。&lt;/p&gt;&lt;p&gt;在过去十年里，研究人员开发了大量「细胞记录器」&amp;mdash;&amp;mdash;许多采用 CRISPR 基因编辑技术&amp;mdash;&amp;mdash;以创建一个不可磨灭的短暂事件遗传账本，比如某一特定分子通路随时间的活动 。随后，基因组测序可以读取该账本，识别后续的编辑，从而创建细胞事件的时间线。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="431" data-backw="546" data-imgfileid="100027196" data-ratio="0.7887029288702929" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkjU5iagtb5ATnoR0Gnib45uCb0ibsqfhaRouLE5vZK9UkhWEwqV7yZNfEHI6CS1cOrfQZFaqKgsiauyQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="956" type="block" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/dd155e9e-89bd-4a11-8175-90dd0e52fa83/640.png" alt="图片" data-before-load-time="1768881696313" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：TimeVault系统的概述和特征（部分）。&lt;/p&gt;&lt;p&gt;相关链接：https://www.nature.com/articles/d41586-025-03035-2&lt;/p&gt;&lt;p&gt;但这些实验也有缺点：研究人员必须提前决定要监测哪些事件，哈佛大学马萨诸塞州剑桥分校研究单细胞和基因组生物学的 Chen Fei 如此表示。&lt;/p&gt;&lt;p&gt;为了寻找一种公正记录细胞寿命的方法，Chen 和他的同事们在 YouTube 上获得了灵感。该实验室里的一名学生看到了一份关于 Leonard Rome 的资料。他是加州大学洛杉矶分校的细胞生物学家，20 世纪 80 年代，Rome 与他人共同发现了穹顶，这些穹顶在大多数哺乳动物细胞中均有数千个。然而，它们的功能自此一直未知。&lt;/p&gt;&lt;p&gt;为了将 vault 变成时间胶囊，该团队重新设计了 vault 蛋白，使其能够识别并连接 mRNA 分子的分子标志，从而捕获 vault 内的 mRNA。这种蛋白质的产生&amp;mdash;&amp;mdash;相当于按下「录音」按钮&amp;mdash;&amp;mdash;通过用药物治疗细胞触发，通过撤回药物停止。&lt;/p&gt;&lt;p&gt;团队发现，通过这些改造，时间宝库在 24 小时内捕获了人类细胞系产生的 mRNA 分子中的一小部分，并至少储存了一周。研究人员未发现携带时间宝库的细胞因货物而表现不同，桶状结构填充后也未发生变化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实际应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;关于如何应用他们的发明，团队的探索才刚刚开始。&lt;/p&gt;&lt;p&gt;在论文中，该团队利用时间宝库来理解并克服被称为顽固癌细胞的恶性癌细胞。这些细胞缺乏能躲避靶向癌症药物的基因突变，却能在药物治疗中存活下来。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="390" data-backw="546" data-imgfileid="100027197" data-ratio="0.7150368033648791" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLkjU5iagtb5ATnoR0Gnib45uCExTPp15ic19ibYFmbHMJGe0APvgfZBJflICyUD3RV94G1iaSP4ibMD749Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="951" type="block" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/32451ad4-5d93-4bfc-9d10-3596934ed7b6/640.png" alt="图片" data-before-load-time="1768881696760" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：TimeVault 揭示了 PC9 细胞对奥希替尼耐药性背后的转录异质性。&lt;/p&gt;&lt;p&gt;相关链接：https://www.nature.com/articles/d41573-020-00050-y&lt;/p&gt;&lt;p&gt;一种假说是，持久细胞中活性的 mRNA 转录本解释了它们逃避药物的能力。但 Chen 表示，测试这一观点颇为棘手，因为癌症药物会引起各种其他转录变化，这些变化难以与可能导致持续性的问题区分开来。&lt;/p&gt;&lt;p&gt;利用 TimeVaults，该团队识别出数百个在持续性肺癌细胞中过度活跃的基因，这些基因在接受药物治疗前就已存在。抑制这些基因中表达最高的部分，使癌症药物杀死了更高比例的肺癌细胞。&lt;/p&gt;&lt;p&gt;这个团队还开始使用 TimeVaults 研究干细胞如何分化成多样的细胞类型。&lt;/p&gt;&lt;p&gt;华盛顿大学西雅图分校的基因组科学家杰伊&amp;middot;申杜尔说，将金库变成细胞时间胶囊需要「一些创造力和勇气」。他预计这些设备将成为 CRISPR 记录仪的有用补充，就像他团队开发的那样。他还想知道金库是否可以被设计用来储存蛋白质和其他细胞纪念物，而不仅仅是 RNA。&lt;/p&gt;&lt;p&gt;报道链接：https://www.nature.com/articles/d41586-026-00116-8&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>钉钉上线AI差旅：企业免垫资，员工免报销，AI帮比价</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 11:58:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;一趟差旅回来，员工不用再为整理发票头疼，财务无需核对上百张零散票据，而公司却能省下大笔开支——这样的场景正在钉钉上成为现实。钉钉最新推出的“AI差旅”功能，正试图改变中小企业出差的烦恼。&lt;/p&gt;&lt;p&gt;1月20日，钉钉更新8.2.5版本，由钉钉、高德、支付宝合作的“AI差旅”产品正式上线，所有企业用户在最新的钉钉内搜索“AI差旅”、“差旅用车”、“机票”、“酒店”等相关关键词，即可零门槛、免费开通这一服务，无需垫资或支付服务费。在该版本中，AI印、AI听记同声传译等能力也全量上线。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5ce959d0-6837-4852-a315-5118dcb0e12c/1768881390350.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;把中小企业的差旅成本打下来，AI差旅让企业免垫资、员工免报销&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;钉钉AI差旅专为500人以下中小企业打造，整合了高德打车、支付宝企业支付等能力，为用户提供机票、酒店、火车票及用车四大核心场景的差旅服务。与市面上其他商旅平台相比，钉钉AI差旅直连锦江、如家、东呈、亚朵、雅斯特等酒店集团系统，酒店预订更便宜。该产品还提供AI比价功能，为用户在全网自动搜索比价，实时获取多个预订平台的酒店价格，来找到最低价的选项。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f4947085-55c4-4ca0-b594-d106d6c8890d/1768881418508.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;对经常出差的员工来说，AI差旅的差旅助理让出差更简单，实现一句话规划行程，即使是复杂的多城市路线也能在30秒内给出最优方案，并自动生成出差单，无需手动填写。&lt;/p&gt;&lt;p&gt;更让员工感到便利的是，钉钉与高德合作推出的“无感报销”用车功能。员工提交外出或差旅申请后，可直接在审批单内或通过搜索“高德打车”叫车；行程结束后，发票和行程单自动关联至对应的审批单，彻底告别了手动翻找票据的繁琐。在支付环节，钉钉携手支付宝企业码提供了企业代付能力，员工出差无需垫付，企业可按需开通。&lt;/p&gt;&lt;p&gt;对企业管理层，AI差旅内置了专业的差旅管理能力，可以自定义差旅标准，设置机票预订时限、酒店价格区间、火车席别等级；产品还可生成按部门、按员工维度的明细和排行榜，让差旅成本真正做到可视、可控。&lt;/p&gt;&lt;p&gt;在杭州一家机器人企业“原力无限”，HR负责人现场对比了钉钉和其他出行平台的价格后，当场决定启用。“钉钉上的酒店资源不仅连锁品牌全覆盖，价格也非常能打。”启用一月后，员工从提交申请到完成报销的全流程周期，从过去的10天大幅压缩至3天，公司当月差旅开支直接省下约15万元。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计打印太贵太麻烦？AI印让海报设计印刷像“网购”一样方便&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;同时上线的钉钉AI印，则将企业的物料设计和印刷流程打包在钉钉里，它能够提供从AI素材设计再到物料打印、物流接收的全流程支持，让用户享受到更有保障、更低成本、更高品质的海报设计及印刷服务。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b8236934-07a1-4b8f-ae30-e79230888b3e/1768881433472.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;过去设计靠外包、印刷要货比三家、物流难追踪，如今通过钉钉AI印，没有设计基础的运营、市场人员也能几分钟生成和精修出专业海报，一键下单直连全国六大印刷工厂，易拉宝、彩页、宣传册等主流品类全覆盖，价格远低于打印店等传统渠道，主要城市最快半日送达。&lt;/p&gt;&lt;p&gt;杭州扶一把网络科技有限公司CEO蒋迎安坦言：“以前打个易拉宝要多方询价、反复沟通；现在一站搞定，AI设计+平台物流，品质、效率、确定性全都有，我们省去了到处比价的繁琐，也大幅提升品质与效率。”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;外语不好没关系，AI听记为跨国开会配了AI翻译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在音视频协同方面，钉钉在8.2.5版本也进一步升级了AI翻译同传能力。在面对面沟通、跨国视频会议时，能及时听到翻译后的对话，就算外语不好，在国外旅游、开会时也不再焦虑。&lt;/p&gt;&lt;p&gt;面对面同声传译的新能力，不仅提供翻译字幕，也支持语音翻译。只要戴上一副普通的蓝牙耳机，即可实现中英日等多语种的实时互译，还可设置左右声道为不同语言，两人一人一只耳机即可顺畅沟通。钉钉视频会议则支持多语种双向同传，参会者只需设置自己的语言，即可在跨国会议中“听自己熟悉的母语”，会中还会自动生成纪要和待办，显著提升跨国协作效率。&lt;/p&gt;&lt;p&gt;“我们在国内和越南都有生产基地，在欧美都有分公司和经销商，每次开会涉及不同部门、国家和语言。AI同传让我们不再依赖专业翻译，也能实现周度月度的无障碍沟通”。杭州一家户外家居企业负责人表示。&lt;/p&gt;&lt;p&gt;从AI差旅到AI印，再到AI翻译，钉钉正把原本只有大企业才能享受的专业服务，通过AI下沉给更多中小企业，让出差不再折腾，印刷无需比价，跨国沟通不再焦虑，在降低成本的同时真正释放每一位员工的时间和精力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>零样本&amp;少样本横扫12个工业医疗数据集：西门子×腾讯优图新研究精准定位缺陷，检测精度新SOTA丨AAAI 2026</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 11:49:34 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;在工业质检与医学影像等真实场景中，&lt;strong&gt;异常检测&lt;/strong&gt;始终面临一个核心矛盾：&lt;/p&gt;&lt;p&gt;模型既要跨领域泛化，又要在几乎没有目标域数据的情况下，精确定位细微异常。&lt;/p&gt;&lt;p&gt;现实生产中，产线频繁换型，新产品刚投产，缺陷样本极少，而异常往往表现为局部、稀疏、小尺度的像素级变化。这使得大量依赖监督学习或目标域微调的方法难以真正落地。&lt;/p&gt;&lt;p&gt;近日，西门子与腾讯优图联合研究团队提出&lt;strong&gt;AdaptCLIP&lt;/strong&gt;，一种&lt;strong&gt;通用视觉异常检测框架，&lt;/strong&gt;具有以下亮点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;单一模型&lt;/li&gt;&lt;li&gt;无需目标域微调&lt;/li&gt;&lt;li&gt;同时支持&lt;strong&gt;图像级异常分类&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;像素级异常分割&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;兼容&lt;strong&gt;零样本&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;/&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;少样本&lt;/strong&gt;推理&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、为什么&amp;ldquo;通用异常检测&amp;rdquo;一直做不好？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通用异常检测要求模型在&lt;strong&gt;训练域与测试域分布显著不同&lt;/strong&gt;的前提下，仍能稳定检测异常。这一设定暴露了现有方法的结构性瓶颈：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;传统无监督&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;AD&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;方法&lt;/strong&gt;（如PaDiM、PatchCore、重建式模型）依赖大量正常样本，一旦面对未见类别或新领域，性能迅速退化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;驱动的方法&lt;/strong&gt;虽借助跨模态先验实现零样本检测，但代价并不小：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;WinCLIP 依赖密集窗口扫描，计算与显存开销巨大；&lt;/li&gt;&lt;li&gt;AnomalyCLIP、AdaCLIP 通过修改中间层或引入复杂token，削弱了 CLIP 的原始表征能力；&lt;/li&gt;&lt;li&gt;InCtrl、PromptAD 要么只支持图像级判断，要么仍需目标域重新训练。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;问题归结为一句话：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何在不破坏&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;原有泛化能力的前提下，让它真正学会&amp;ldquo;找异常&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、AdaptCLIP的答案：少即是多&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP&amp;nbsp;将&amp;nbsp;CLIP&amp;nbsp;视为一种&amp;ldquo;&lt;strong&gt;基础服务模型&lt;/strong&gt;&amp;rdquo;，不改动其主干结构，仅在输入与输出端引入&lt;strong&gt;三个轻量适配器&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视觉适配器（VisualAdapter）&lt;/li&gt;&lt;li&gt;文本适配器（TextAdapter）&lt;/li&gt;&lt;li&gt;提示-查询适配器（Prompt-QueryAdapter）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;并由两个关键洞见驱动：&lt;/p&gt;&lt;p&gt;1️⃣ &lt;strong&gt;视觉与文本表征不应联合学习，而应交替学习&lt;/strong&gt;；&lt;br&gt;2️⃣ &lt;strong&gt;少样本对比学习不能只看残差，还必须结合上下文信息&lt;/strong&gt;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/0576e23e-e1ba-451d-b881-32b0cd77a801/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图1 AdaptCLIP架构图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、交替学习：零样本异常检测的核心机制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.1 从 CLIP 的异常判别说起&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;给定查询图像，CLIP视觉编码器输出局部&amp;nbsp;patch token&amp;nbsp;与全局图像token，并与&amp;ldquo;正常&amp;nbsp;/&amp;nbsp;异常&amp;rdquo;文本嵌入进行相似度比对，即可得到图像级异常分数与像素级异常图。&lt;/p&gt;&lt;p&gt;但在工业场景中，&lt;strong&gt;原生&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;CLIP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;的像素级定位能力明显不足&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.2 视觉适配器：只做&amp;ldquo;微调&amp;rdquo;，不做&amp;ldquo;重塑&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视觉适配器分别作用于局部&amp;nbsp;patch token&amp;nbsp;与全局token，均采用&lt;strong&gt;残差&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;MLP&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;结构&lt;/strong&gt;，对 CLIP 表征进行轻量自适应调整：&lt;img src="https://image.jiqizhixin.com/uploads/editor/3c2bdec3-e780-4ad1-b811-49bf1f99e3d1/%E5%9B%BE%E7%89%871.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;其中&lt;img src="https://image.jiqizhixin.com/uploads/editor/d854eebe-7d63-4626-950b-cc7292090166/%E5%9B%BE%E7%89%871.png" style="width: 3.58%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/2923abc3-68cd-4fef-bc16-a2e05410c4df/%E5%9B%BE%E7%89%872.png" style="width: 3.69%;" class="fr-fic fr-dii"&gt;分别表示CLIP输出的局部 patch token和全局图像token，&lt;img src="https://image.jiqizhixin.com/uploads/editor/a92f6451-becd-4365-b695-c44879420433/%E5%9B%BE%E7%89%873.png" style="width: 2.74%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/a5f99854-9f2a-45d7-a1e8-291c9f12f9af/%E5%9B%BE%E7%89%874.png" style="width: 2.85%;" class="fr-fic fr-dii"&gt;为适配器可学习参数。&lt;/p&gt;&lt;p&gt;其目标是在&lt;strong&gt;固定文本语义空间&lt;/strong&gt;的前提下，使视觉特征更贴合异常检测任务，从而显著提升像素级定位能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.3 文本适配器：抛弃 prompt 工程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;文本适配器不再依赖人工设计的模板，而是&lt;strong&gt;直接学习&amp;ldquo;正常&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;/&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;异常&amp;rdquo;两类可优化提示嵌入&lt;/strong&gt;，并输入冻结的 CLIP 文本编码器生成语义表示：&lt;img src="https://image.jiqizhixin.com/uploads/editor/db3a3687-774e-4da0-af85-766dc7d60aa6/%E5%9B%BE%E7%89%871.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;其中&lt;img src="https://image.jiqizhixin.com/uploads/editor/512bbc31-3406-4185-ab17-3ecfc668a906/%E5%9B%BE%E7%89%871.png" style="width: 3.69%;" class="fr-fic fr-dii"&gt;表示CLIP文本编码器，&lt;img src="https://image.jiqizhixin.com/uploads/editor/1322ef86-05a3-4e35-b9fd-72884f95c556/%E5%9B%BE%E7%89%872.png" style="width: 4.96%;" class="fr-fic fr-dii"&gt;和&lt;img src="https://image.jiqizhixin.com/uploads/editor/898d53af-a6e8-4582-8cd3-5899dfc306ff/%E5%9B%BE%E7%89%873.png" style="width: 4.85%;" class="fr-fic fr-dii"&gt;为最终用于特征比对的异常与正常文本嵌入。&lt;/p&gt;&lt;p&gt;这一设计在保留&amp;nbsp;CLIP&amp;nbsp;原有语义结构的同时，降低了对&amp;nbsp;prompt&amp;nbsp;经验的依赖。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.4为什么交替学习优于联合学习？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文通过消融实验发现，在小规模训练数据下，&lt;strong&gt;联合学习易过拟合&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此&amp;nbsp;AdaptCLIP&amp;nbsp;采用交替优化策略：&lt;/p&gt;&lt;p&gt;固定文本&amp;rarr;&amp;nbsp;优化视觉；固定视觉&amp;rarr;&amp;nbsp;优化文本，循环迭代。&lt;/p&gt;&lt;p&gt;该策略在多个工业与医学数据集上，显著优于联合学习方案，成为零样本异常检测性能提升的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、对比学习：少样本场景下的关键补强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当可获得少量正常样本时，AdaptCLIP启用&lt;strong&gt;提示-查询适配器&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.1 空间对齐：先对齐，再比较&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对查询图像的每个patch，模型在正常样本中搜索&lt;strong&gt;欧氏距离最近的&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;patch&lt;/strong&gt;作为对齐目标，从而消除旋转、平移带来的干扰，并计算对齐残差特征。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.2 残差 + 上下文：避免&amp;ldquo;只见树木，不见森林&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文发现，仅依赖残差特征虽然能突出差异，但容易引入噪声、丢失上下文信息。&lt;/p&gt;&lt;p&gt;因此&amp;nbsp;AdaptCLIP&amp;nbsp;将&lt;strong&gt;原始查询特征与对齐残差逐元素相加&lt;/strong&gt;，形成联合特征：&lt;img src="https://image.jiqizhixin.com/uploads/editor/ca6a354d-1d59-4828-8acd-ba38320b64ae/%E5%9B%BE%E7%89%874.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在 1-shot 设置下，引入上下文后，在 MVTec 数据集上的像素级 AUPR &lt;strong&gt;提升约&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;40%&lt;/strong&gt;，成为少样本性能跃迁的关键因素。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.3 从联合特征到异常预测：极简分割与分类头&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在得到融合了&lt;strong&gt;上下文与对齐残差&lt;/strong&gt;的联合特征后，AdaptCLIP 采用一套&lt;strong&gt;轻量输出头&lt;/strong&gt;完成异常预测。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;像素级分割&lt;/strong&gt;：联合特征经 &lt;strong&gt;1&amp;times;1 卷积&lt;/strong&gt;与若干 &lt;strong&gt;转置卷积模块&lt;/strong&gt;上采样至原分辨率，生成异常图；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;图像级分类&lt;/strong&gt;：对联合特征进行&lt;strong&gt;平均池化与最大池化&lt;/strong&gt;，融合后输入 &lt;strong&gt;MLP&lt;/strong&gt;输出异常分数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推理阶段根据可用信息进行结果融合：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;零样本&lt;/strong&gt;：融合视觉适配器与文本适配器预测；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;少样本&lt;/strong&gt;：在此基础上进一步融合提示-查询适配器结果。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;五、实验结果：跨工业与医疗的一致验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP 在&lt;strong&gt;12 个公开基准数据集&lt;/strong&gt;（8 个工业 + 4 个医疗）上进行了系统评估，覆盖不同成像模态与异常类型。&lt;/p&gt;&lt;p&gt;在零样本异常检测场景下，AdaptCLIP 在 MVTec、VisA、BTAD、Real-IAD 等工业数据集上，图像级 AUROC 平均达到&lt;strong&gt;86.2%&lt;/strong&gt;（SOTA），在多类未见产品与跨类别测试中依然保持稳定优势。&lt;/p&gt;&lt;p&gt;在医学影像任务中，AdaptCLIP在内窥镜数据集Kvasir与Endo的零样本像素级异常分割AUPR平均达到&lt;strong&gt;48.7%&lt;/strong&gt;，并在Br35H（MRI）、COVID-19（X-ray）等数据集的零样本图像级异常检测中取得平均&lt;strong&gt;90.7%&lt;/strong&gt;的AUROC，均显著高于其他现有方法。&lt;/p&gt;&lt;p&gt;在少样本设置下，随着正常样本数量从 1-shot 增加至 4-shot，异常区域的定位逐步细化。提示-查询适配器显著降低了误报区域，使异常边界更加清晰。&lt;/p&gt;&lt;p&gt;从模型规模与效率来看，AdaptCLIP在零样本条件下仅引入约&lt;strong&gt;0.6M&lt;/strong&gt;额外可训练参数（对比方法可高达10.7M）。在 518&amp;times;518 分辨率下，零样本条件单张图像推理时间约&amp;nbsp;&lt;strong&gt;162 ms&lt;/strong&gt;，兼顾检测精度与实际部署需求。&lt;img src="https://image.jiqizhixin.com/uploads/editor/652672e5-67c0-432a-9138-77e0e6d2a54f/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;table border="1" cellspacing="0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan="5" valign="center" width="100%"&gt;&lt;p&gt;&lt;a name="u8650227d"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign="center" width="17.158931082981717%"&gt;&lt;p&gt;&lt;a name="u320fbf43"&gt;待检图像&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="21.940928270042193%"&gt;&lt;p&gt;真实缺陷标注&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="21.09704641350211%"&gt;&lt;p&gt;0-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="20.253164556962027%"&gt;&lt;p&gt;1-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;td valign="center" width="19.549929676511955%"&gt;&lt;p&gt;4-shot检出结果&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图2 &amp;nbsp;AdaptCLIP在工业与医疗数据上检测结果可视化&lt;img src="https://image.jiqizhixin.com/uploads/editor/222f8d35-1fea-4579-b844-df4fdef7140a/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;图3 &amp;nbsp;AdaptCLIP在工业与医疗数据上图像级AUROC分类结果与其他方法对比&lt;img src="https://image.jiqizhixin.com/uploads/editor/39d5826b-98c0-4aa9-b9dc-b77348676ed6/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图4 &amp;nbsp;AdaptCLIP在工业与医疗数据上像素级AUPR分割结果与其他方法对比&lt;img src="https://image.jiqizhixin.com/uploads/editor/7999c22a-1a03-48b1-9ebf-1dbb2e9f2024/%E5%9B%BE%E7%89%873.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图5 &amp;nbsp;AdaptCLIP与其他方法对比模型规模与效率&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AdaptCLIP&amp;nbsp;并未试图&amp;ldquo;重造一个更大的模型&amp;rdquo;，而是通过&lt;strong&gt;交替学习&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;轻量适配&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;+&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;上下文感知对比&lt;/strong&gt;，在不破坏&amp;nbsp;CLIP&amp;nbsp;原始能力的前提下，实现了真正可迁移的异常检测。&lt;/p&gt;&lt;p&gt;它为工业与医疗等开放场景提供了一条清晰路径：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用最少的结构改动，换取最大的泛化收益。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2505.09926&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>WAIC首次“南下”：沪港握手2026“WAIC UP!全球年终盛会”，共揭AI对话新篇</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻助手</author>
      <pubDate>Tue, 20 Jan 2026 10:40:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f064dd62-3632-4097-8448-c4f8c4378c24/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20260116223441_6204_11_min.png" style="width: 700%;" class="fr-fic fr-dib"&gt;香港，2026年1月16日——作为世界人工智能大会（WAIC）的年度重磅收官活动，“WAIC UP!全球年终盛会”今日在香港科学园举行。全天数千位观众与来自国际、中国大陆和中国香港的AI专家学者、企业家、投资人及香港立法会议员等共聚一堂。&lt;/p&gt;&lt;p&gt;此次盛会意义非凡，核心主题&lt;strong&gt;“WAKE UP MORE!”&lt;/strong&gt;，象征着一次从认知到行动、从个体到生态的全面唤醒。这不仅是世界人工智能大会（WAIC）首次在港举办年度旗舰活动，更标志着&lt;strong&gt;以上海为代表的内地前沿AI产业实践，与香港的国际枢纽功能完成了一次历史性的战略握手&lt;/strong&gt;，共同激发更广阔的技术前景、更深入的产业融合与更具全球影响力的创新生态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;顶格政商学阵容，筑就国际级思想高地&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大会获得香港各界的高度重视与支持。&lt;strong&gt;香港特别行政区行政长官李家超先生&lt;/strong&gt;特别通过视频为大会揭幕致辞，他表示，今年盛会首次在香港举办，以“WAKE UP MORE!”为主题，彰显了人工智能的无限可能。要借助AI推动创新，更要用于构建具包容性的经济体系、更具韧性的社区，更可持续创造所有人的未来。并阐明香港在全球AI版图中的战略定位，释放全力支持创新科技产业发展的政策信号。&lt;strong&gt;香港特别行政区创新科技及工业局局长，JP孙东教授&lt;/strong&gt;、&lt;strong&gt;香港科技园公司行政总裁黄秉修先生&lt;/strong&gt;，以及&lt;strong&gt;香港特别行政区立法会议员、香港资讯科技联会会长邱达根先生&lt;/strong&gt;亲临现场发表致辞。引人注目的是，&lt;strong&gt;第十四届全国人民代表大会港区代表，JP，MH冼汉迪先生&lt;/strong&gt;也莅临大会并致辞，与主办方&lt;strong&gt;东浩兰生会展集团股份有限公司副总裁裘皓明女士&lt;/strong&gt;共同启动这一国际AI界年度思想盛会。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a1ac9cb7-1d37-4974-9377-b5b406525f61/%E7%89%B9%E9%A6%96.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这一阵容与会上40余位全球顶尖的AI科技产业巨擘形成“政府战略+学界前沿+产业实战”的黄金三角，标志着一个连接长三角与大湾区、贯通顶尖技术与全球市场的创新闭环正在WAIC的平台上加速形成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三幕递进式论坛，精准匹配思想价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;议程设计突破传统模式，WAIC旗下五大生态品牌首次在香港并联，以“思想觉醒—拓维跃迁—灵感迸发”为主线，打造差异化体验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上午场【WAKE思想觉醒】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;聚焦新锐思想，锚定未来坐标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;上午立足全球前沿，&lt;strong&gt;WAIC UP!新锐思想&lt;/strong&gt;为我们打开视野，看见未来真正的轮廓。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;硅谷人工智能研究院创始人、院长皮埃罗·斯加鲁菲（Piero Scaruffi）&lt;/strong&gt;带来开幕主题演讲，以“70·40·10——人工智能与硅谷的过去、现在与未来”为框架，全面梳理了AI七十年的技术演进、硅谷四十年的创新生态以及未来十年的未知与希望。&lt;img src="https://image.jiqizhixin.com/uploads/editor/303e10ef-422e-4958-8de7-90fa6f7c3514/Piero_Scaruffi.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;中国工程院外籍院士、香港科技大学首席副校长郭毅可&lt;/strong&gt;将宏大的AI主权理念具象化为“港话通（HKChat）”等一系列深度本地化应用，展现AI技术如何扎根香港社会肌理与香港作为东西方AI枢纽的战略价值。&lt;img src="https://image.jiqizhixin.com/uploads/editor/aa41fac3-9f1a-4bf8-b523-139b4d248815/%E9%83%AD%E6%AF%85%E5%8F%AF.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;香港城市大学首席人工智能总监、香港人工智能与科学研究院院长马维英&lt;/strong&gt;阐述了“AI科学家”愿景，提出FLEX（Forward Learning From Experiences）框架配合分层记忆系统，实现智能与经验的闭环共进化，勾勒出AI重塑科学发现范式与大学研究教育体系的未来图景。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1ae09a9c-3334-41ef-b321-30058a9562e9/%E9%A9%AC%E7%BB%B4%E8%8B%B1.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下午场【UP拓维跃迁】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;WAIC矩阵并联，直击实战与生态&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下午进入高密度、分众化的实战对接环节。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC CONNECT实战案例&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Founders Space董事长兼首席执行官史蒂夫·霍夫曼（Steve Hoffman）&lt;/strong&gt;以“AI is Eating Everything（人工智能正在吞噬一切）”开场，用“吞噬”这一生动比喻与直观图示，宏观勾勒出技术爆发的全球图景与中美竞逐态势，最终引发“AI是否会取代人类工作”的紧迫且深刻思考。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b15f4abc-a96e-4d94-99fb-6b19b07fbb25/Steve_Hoffman.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;来自科研、算力、资本与市场的四方视角汇聚成&lt;strong&gt;“商业与产业圆桌”&lt;/strong&gt;，完整讨论了从技术研发到商业落地的闭环，尤其关注如何将实验室成果转化为稳定产品、如何突破规模化营收瓶颈、以及如何构建开放协同的AI生态，为AI产业化提供了清晰、务实的发展路径。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c0f89096-b685-465b-b805-d15826872233/%E4%BA%A7%E4%B8%9A%E4%B8%8E%E5%95%86%E4%B8%9A%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC YOUNG科教风向&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;香港大学、香港城市大学、香港理工大学的副校长级科学领袖聚首&lt;strong&gt;“校长圆桌”&lt;/strong&gt;，不仅剖析了教育评价体系、产学研脱节等瓶颈，更就深化粤港澳大湾区融合、构建“研究‑产业”并发式合作网络提出具体路径，为AI时代夯实科技根基提供了系统性思考与行动方向。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1d954436-ed50-4de2-a819-5f6729cba3fc/%E6%A0%A1%E9%95%BF%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;聚焦下一代的&lt;strong&gt;“青年观察家”&lt;/strong&gt;跨界对话中，宇宙学者、艺术家、教育者与生态构建者们从星际尺度、艺术本质、幼儿教育到文明价值等多重维度展开思辨，探讨AI作为“新生命形式”与人类在演化节奏、创造主体及价值定义上的根本性碰撞。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c4bcc467-c56d-4327-b3a8-22e52521758c/%E9%9D%92%E5%B9%B4%E8%A7%82%E5%AF%9F%E5%AE%B6.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;WAIC FUTURE TECH赛道机遇&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;穹彻智能联合创始人，非夕机器人联合创始人，上海交通大学人工智能学院副院长、教授，上海创智学院副院长卢策吾&lt;/strong&gt;聚焦具身智能，提出“真实基础-想象拓展-下意识学习”，首创群众采集（RoboPocket）范式，构建“数字基因”世界模型，强调力-位全信息融合，以突破Scaling Law困境。&lt;img src="https://image.jiqizhixin.com/uploads/editor/4d8560db-b30a-49f4-bc1c-6ab6b294123d/%E5%8D%A2%E7%AD%96%E5%90%BE.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“量子圆桌”&lt;/strong&gt;邀请“祖冲之号”量子计算总师朱晓波在内的多位技术路线代表与产业观察者同台交锋，话题涉及量子计算与AI的融合、不同技术路线的竞争与前景，以及量子计算从“优越性”到“实用性”的跨越，呈现了一场兼具前瞻性、批判性与建设性的前沿科技对话。&lt;img src="https://image.jiqizhixin.com/uploads/editor/88bad16b-b665-4218-a5cf-eaa010423fc9/%E9%87%8F%E5%AD%90%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AI GRAVITY链接全球&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;猎豹移动董事长兼CEO，猎户星空董事长傅盛&lt;/strong&gt;以自身“AI化”转型为实证，提出“一把手示范、全员革命、工具落地”的企业变革三部曲，用生动案例展现了一家老牌公司如何以All in姿态拥抱AI。&lt;img src="https://image.jiqizhixin.com/uploads/editor/102abbab-2880-4a92-8102-6db5a3237d8b/%E5%82%85%E7%9B%9B.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“出海战略圆桌”&lt;/strong&gt;汇集了基础模型、汽车金融、工业互联网、智慧物流领域的出海实践者，携同大湾区资源代表香港投推署与生产力促进局，积极探索通过技术赋能、生态合作与平台协同，实现从单点出海到体系化“舰队式”发展的升级路径。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b50e86b0-bcdd-4a3e-b636-42f509caf483/%E5%87%BA%E6%B5%B7%E6%88%98%E7%95%A5%E5%9C%86%E6%A1%8C.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;夜晚场【灵感迸发】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;打破圈层，激发“灵感迸发”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当维港的灯火亮起，这场持续全天的思想盛宴在夜晚场达到另一种形态的高潮。&lt;/p&gt;&lt;p&gt;WAIC五大生态品牌领衔的&lt;strong&gt;Free Talk Zone&lt;/strong&gt;提供无缝交流局，让最有价值的资源、机会与灵感在非正式对谈中自然流动。&lt;strong&gt;知乎创作者、WAYtoAGI和RTE开发者社区极客、BIM青年科学家、AI头部科技博主&lt;/strong&gt;与白天登台的大咖平等对话。&lt;strong&gt;史蒂夫·霍夫曼（Steve Hoffman）&lt;/strong&gt;带来一场“模拟人生：AI缔造的未来”特别互动演讲。&lt;strong&gt;加州大学伯克利VIVE增强现实中心创始执行主任杨安（Dr. Allen Yang）&lt;/strong&gt;首次现场揭秘Physical AI的真正野心。&lt;strong&gt;香港立法会议员、港区全国政协委员、优家健康创始人和埔思学院院长&lt;/strong&gt;深入“重构生命、财富与记忆”等终极议题。&lt;strong&gt;香港城市大学&lt;/strong&gt;的&lt;strong&gt;“Tech300”菁英汇&lt;/strong&gt;为当晚注入最鲜活的创新动能。创新因子在跨代际碰撞中集中涌现。&lt;img src="https://image.jiqizhixin.com/uploads/editor/0c0ee754-27ba-40a3-939d-428bdb99fbf9/%E5%A4%9C%E5%9C%BA.jpg" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从1956年达特茅斯会议到2026“WAIC UP!全球年终盛会”，AI对话正从纯技术思辨走向“技术-产业-人文”的融合共创。&lt;/p&gt;&lt;p&gt;香港的意义，远不止资本与技术的枢纽。这座东西方文明交汇的城市，为AI注入了独特的价值维度——在这里，效率与温度并存，创新与传统对话，全球视野与本土智慧交融。WAIC选择香港作为年终思想的收官之地，正是因为这片土地能孕育出不同于硅谷的AI文明形态。&lt;/p&gt;&lt;p&gt;“WAIC UP!全球年终盛会”既是对过往技术长征的致敬，更是开启“人类与机器智能对话”的新序章。当思想从彼岸到此岸，当创新从精英走向大众，一个更加多元、包容、可持续的AI未来，正在东方初现曙光。&lt;img src="https://image.jiqizhixin.com/uploads/editor/95133668-965d-4c47-b37b-3cb8b823c84d/_6014826-opq3014263146.jpg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于WAIC和WAIC UP!&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;世界人工智能大会（WAIC）是全球人工智能领域的顶级盛会，已成功举办八届，致力于探索AI技术前沿并推动该领域的创新发展。自创办以来，大会已汇聚了来自全球的8,100多位顶尖科学家、专家、企业家投资者及行业领袖，共同交流思想、分享突破性成果并探索合作机遇。&lt;/p&gt;&lt;p&gt;2024年12月，WAIC首份刊物《WAIC UP!》正式问世，它是AI时代的进化指南，更是WAIC精神的延伸。在数字化的浪潮中，信息的碎片化、同质化、孤岛化，让我们渴望深度与连接。创办《WAIC UP!》的初衷正是为了解决这一时代难题。我们想创建的也正是这样一个多元发声阵地、智慧共鸣窗口和思想启发工具。WAIC UP! WAKE UP MORE! 旨在唤醒更多人，探究关乎技术跃迁自我边界和未来文明的无限可能。&lt;img src="https://image.jiqizhixin.com/uploads/editor/59cf355c-c198-47f7-960c-eab34a5edcbe/WAIC_UP_%E5%85%A8%E7%90%83%E5%B9%B4%E7%BB%88%E7%9B%9B%E4%BC%9A%E5%90%88%E4%BD%9C%E4%BC%99%E4%BC%B4.jpg" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>“扣子”官宣2.0品牌升级：AI办公、AI创作全面更新，新增视频创作能力</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 20 Jan 2026 10:23:08 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-20</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-20</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1月19日，字节跳动旗下AI Agent平台&amp;ldquo;扣子&amp;rdquo;宣布2.0品牌升级。&lt;/p&gt;&lt;p&gt;扣子诞生于2024年2月，最初定位是新一代AI Agent平台。基于服务超1000万真实开发场景的经验，扣子2.0进行了全局重构，定位和使命是帮助更多的职场人。&lt;/p&gt;&lt;p&gt;扣子2.0集成了Agent Skill、Agent Plan、Agent Coding、Agent Office能力，让AI 真正成为用户的&amp;ldquo;工作伙伴&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/04bb453e-9e49-4fdd-b965-1c9138e9ba37/%E5%9B%BE%E7%89%871.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Skills：装上行业技能包，让通用AI变得更专业&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通用Agent已展现出强大的基础任务处理能力，在日常对话、信息整合与简单推理方面有了长足进步，但要应对高度专业化、高精度或高可控要求的复杂场景，仍需特定技能的增强。&lt;/p&gt;&lt;p&gt;通过封装领域知识、标准化操作流程或集成专用工具，&amp;ldquo;技能&amp;rdquo;（Skills）能够将通用AI的认知能力与特定任务需求相结合，更贴合实际应用场景中多元化、高标准的任务要求，保证输出稳定性。&lt;/p&gt;&lt;p&gt;扣子2.0推出的Agent Skills，本质上是「场景最佳实践 + 所需工具」的封装，旨在帮助更多用户调用专业技能，定向增强解决复杂专业问题的能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/3a04368a-21d1-493f-ae3c-13955ab7449e/%E5%9B%BE%E7%89%872.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在全新推出的技能商店中，用户可以浏览、选择并一键安装使用由扣子官方及优质开发者创建的各类专项技能模块，包括但不限于&amp;ldquo;新年绘本&amp;rdquo;&amp;ldquo;互动教学&amp;rdquo;&amp;ldquo;投资知识库&amp;rdquo;&amp;ldquo;法律类案检索&amp;rdquo;等。扣子可根据任务场景，智能调用或组合多个已安装技能，让Agent Skills提供综合性解决方案。技能库会持续更新，确保用户总能获取最前沿、最实用的能力支持。此外，用户可利用扣子提供的工具，为自己量身定制私有技能，还可以将个人经验沉淀封装为可复用的模块。&lt;/p&gt;&lt;p&gt;在Coze Skills生态中，行业专家能够把经验沉淀为&amp;ldquo;可出售的技能&amp;rdquo;，提升专业影响力；特定领域的新人即使没有行业经验，也可以一键使用他人的方法论。对于企业来说，团队能够共享专业标准作业程序（SOP）和最佳实践，新成员也能迅速掌握熟练员工的能力。&lt;/p&gt;&lt;p&gt;此外，扣子官方视频Skill也正式上线，该功能支持自动生成视频脚本、匹配视觉素材，并完成剪辑、转场、配乐等后续流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Plan：从&amp;ldquo;即时问答&amp;rdquo;到&amp;ldquo;长期计划&amp;rdquo;，AI持续执行并主动汇报&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;习惯使用AI产品提效的用户，需要的不只是即时解答问题的工具，更是一个能够理解长期目标、适应个人成长节奏、提供持续支持的智慧伙伴。&lt;/p&gt;&lt;p&gt;扣子2.0推出了Agent Plan，即&amp;ldquo;长期计划&amp;rdquo;，让AI从&amp;ldquo;即时问答工具&amp;rdquo;升级为&amp;ldquo;可持续运作的智能体&amp;rdquo;。用户只需要确定目标，规定好怎么完成、怎么实现，扣子能够持续执行，并向用户主动汇报、最终交付任务。&lt;br&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f5f1a150-e9b0-43ff-a2dd-08b7173af6d2/%E5%9B%BE%E7%89%873.png" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;长期计划实现了复杂目标的闭环管理，Agent将一个需要数小时、数天甚至更长时间才能完成的宏观目标（如&amp;ldquo;一款市场竞品分析报告&amp;rdquo;）分解为多个步骤，并持续追踪进度、管理中间状态，直至最终交付成果。这打破了传统单轮交互的局限。在执行长期任务过程中，Agent可以积累上下文信息、记忆用户偏好、总结历史经验，并动态调整后续策略。例如在长期客户服务场景中，它能基于过往互动提供越来越个性化的支持。&lt;img src="https://image.jiqizhixin.com/uploads/editor/43138986-07b1-4544-ac7b-e2984956c35a/%E5%9B%BE%E7%89%874.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;以自媒体账号运营为例，扣子能够和用户一起讨论账号定位，拆解每个阶段的运营策略，再帮用户创作内容。如果用户想写一本书，只需把写作主题和目标发给扣子，它会自己搜集资料、撰写初稿，再根据反馈自行调整，达成3周内写出10万字初稿的计划。用户还可以用长期计划来完成学习目标，比如考雅思，扣子会设定每日任务并准备学习资料。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Office：深度理解职场场景，AI办公、AI创作能力全新升级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AI通常能够针对用户的提问给到标准答案，但在真实的职场问题中，答案并不是模板化的。AI 只有理解具体场景，才能提供针对性解决方案。&lt;/p&gt;&lt;p&gt;扣子2.0面向职场类任务做了更多优化，写战略报告Word、做分析PPT、梳理数据Excel，都可以交给扣子来处理。&lt;/p&gt;&lt;p&gt;具体来说，扣子2.0增强了深度上下文理解能力，能够为用户提供洞察。用户不需要一次性把所有背景信息塞进去，扣子会通过多轮对话，逐步理解具体情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agent Coding：扣子编程，全栈式 Vibe Coding 开发平台&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近日，扣子开发平台正式升级为扣子编程。&lt;/p&gt;&lt;p&gt;作为一站式云端 Vibe Coding 开发平台，扣子编程实现了Vibe Agent、Vibe Workflow、Vibe Web、Vibe App几大核心功能开箱即用，用户通过连续对话，即可轻松构建智能体、工作流、网站、移动应用等，并提供 Vibe Infra 基础设施，实现一键部署上线。&lt;/p&gt;&lt;p&gt;在扣子编程平台，Agent能够自己写提示词、装知识库、开发工具，能在多轮对话过程中自我迭代。基于Vibe Workflow功能，用户彻底告别手动拖拽节点，只需要描述清楚需求即可创建工作流，还能够分节点进行调试和修改，让Vibe Coding更可控、更稳定，更好地支撑复杂业务需求。基于Vibe App功能，用户仅需输入自然语言指令即可打造一个跨端的全栈应用，扣子可以生成适配的界面和逻辑，并自动完成多端适配，帮你集成所需的组件，包括AI能力、数据库等等。&lt;/p&gt;&lt;p&gt;结合火山引擎在云计算领域强大的基础设施，扣子编程上线了Vibe Infra的能力，提供众多适合Vibe Coding用户的基础设施服务，包含服务器的资源分配、应用的版本部署，域名备案配置以及iOS和安卓的版本发布。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>最适合科研工作的模型是什么？Anthropic：斯坦福、MIT用Claude加速科研进程</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 19 Jan 2026 18:05:41 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑丨coisini&lt;/span&gt;&lt;/p&gt;&lt;p&gt;去年十月，Anthropic 推出了 Claude 生命科学版 &amp;mdash;&amp;mdash;Claude for Life Sciences，旨在让 Claude 成为生命科学领域工作者更得力的合作伙伴。&lt;/p&gt;&lt;p&gt;之后，Anthropic 投入大量资源，致力于将 Claude 打造为最适合科研工作的模型。最新推出的 Claude Opus 4.5 在图表解析、计算生物学和蛋白质理解等基准测试中均取得显著进步。&lt;/p&gt;&lt;p&gt;Anthropic 与学术界及产业界研究人员密切合作，致力于精准把握科学家如何运用人工智能加速科研进程。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-imgfileid="100027187" data-ratio="0.5472222222222223" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLk52jEyrejv0eC2uJnFTck9e4d4drbBUaSkftRfhNzib9jdLt0a5wk1K7cj7SkqERExpLza6GFLveQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-type="jpeg" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/116b4c43-ad32-4e08-951c-f076e021eaab/640.jpeg" alt="图片" data-before-load-time="1768817038743" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;研究人员已开发出定制化系统，将 Claude 的应用场景拓展到文献综述或代码辅助等基础任务之外。简而言之，Claude 正在重塑科学家的研究模式，推动科研领域迈向全新的科学洞察与发现。&lt;/p&gt;&lt;p&gt;Anthropic 最近列举了一些知名实验室采用 Claude 加速科研进程的例子。&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Biomni：&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;集成数百种工具与数据库的通用生物医学智能体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;生物学研究的一大瓶颈在于工具碎片化：现有数百个数据库、软件包和实验方案，研究人员需要耗费大量时间在不同平台间进行选择和掌握。在理想情况下，这些时间本应用于实验操作、数据解析或探索新课题。&lt;/p&gt;&lt;p&gt;斯坦福大学研发的智能 AI 平台 Biomni，将数百种工具、软件包和数据集整合进统一系统，由 Claude 驱动的智能体可在其中自主调度。研究人员使用自然语言提出需求，Biomni 会自动匹配合适资源。该系统能够提出假设、设计实验方案，并在超过 25 个生物学子领域执行分析任务。&lt;/p&gt;&lt;p&gt;以全基因组关联分析（GWAS）为例，这种研究旨在寻找与特定性状或疾病相关的基因变异。&lt;/p&gt;&lt;p&gt;基因组扫描相对简单，耗时环节在于数据解析与意义解读：基因组数据格式杂乱需要深度清洗；研究人员必须控制混杂因素并处理缺失数据；发现「命中信号」后，还需解析其生物学意义 &amp;mdash;&amp;mdash; 定位邻近基因、确定其表达细胞类型、推测影响的生物通路等。每个步骤都可能涉及不同工具、不同文件格式和大量人工决策。这种繁琐过程使得单次 GWAS 分析常需数月时间，而在 Biomni 的初期试验中，仅需 20 分钟。&lt;/p&gt;&lt;p&gt;Biomni 团队已通过多领域案例验证系统可靠性：在分子克隆实验设计中，盲评显示其方案与拥有五年以上经验的博士后水平相当；处理 30 名受试者超过 450 份可穿戴设备数据仅用 35 分钟，而专家完成相同任务预计需三周；分析 33.6 万个人类胚胎组织单细胞基因活性数据时，系统不仅验证了已知调控关系，更发现了研究人员未曾关联到胚胎发育过程的新转录因子。&lt;/p&gt;&lt;p&gt;Biomni 并非完美系统，因此设置了防护机制以监测 Claude 是否偏离正轨。它也不能解决所有问题，但当其能力不足时，专家可将方法论编码为技能 &amp;mdash;&amp;mdash; 教智能体模仿专家解决问题的思路而非任其自由发挥。&lt;/p&gt;&lt;p&gt;Biomni 代表了一种通用型解决方案，而其他实验室正在构建更专精的系统，以攻克特定研究流程中的瓶颈。&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Cheeseman 实验室：&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;大规模基因敲除实验解读自动化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当科学家需要了解基因功能时，常用方法是将其从细胞或生物体中移除并观察产生的异常。CRISPR 基因编辑技术使大规模精准敲除成为可能，但其应用仍受限制：实验室产生的数据量远超分析处理能力。&lt;/p&gt;&lt;p&gt;这正是麻省理工学院 Whitehead 研究所 Iain Cheeseman 实验室面临的挑战。他们使用 CRISPR 技术对数千万人类细胞进行数千种基因敲除，通过显微成像记录每个细胞的变化。&lt;/p&gt;&lt;p&gt;但解读基因簇的意义 &amp;mdash;&amp;mdash; 探究聚类原因、寻找共同特征、判断属于已知生物学关系还是新发现 &amp;mdash;&amp;mdash; 仍然需要专家逐基因查阅文献。这个过程极其缓慢：单次筛选可能产生数百个基因簇，由于时间、精力和专业知识限制，大多数簇从未被深入探究。&lt;/p&gt;&lt;p&gt;多年来 Cheeseman 亲自承担所有解读工作。他估计自己大约能记住 5000 个基因功能，但有效分析这些数据仍需数百小时。为加速这一进程，博士生 Matteo Di Bernardo 着手构建能自动化 Cheeseman 工作模式的系统。通过深入解析 Cheeseman 的解读方法论 &amp;mdash;&amp;mdash; 数据源选择、模式识别标准、发现价值判断 &amp;mdash;&amp;mdash; 他们最终创建了由 Claude 驱动的 MozzareLLM 系统。&lt;/p&gt;&lt;p&gt;该系统接收基因簇数据后，会执行 Cheeseman 式的专家分析：识别潜在共享生物过程、标注研究充分与欠缺的基因、突出值得跟进的目标。这不仅极大加速了研究进程，还帮助他们获得额外的重要生物学发现。在开发 MozzareLLM 的过程中，Di Bernardo 测试了多种 AI 模型。Claude 的表现始终优于其他模型。&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Lundberg 实验室：&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;测试 AI 主导的基因研究目标假设生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Cheeseman 实验室采用的光学混合筛选技术可在单次实验中敲除数千基因，其瓶颈在于结果解读。但并非所有细胞类型都适用混合筛选方法。斯坦福大学 Lundberg 实验室等研究团队进行的是规模较小、目标集中的筛选实验，他们的瓶颈出现在更前端：如何确定需要靶向的基因。&lt;/p&gt;&lt;p&gt;由于单次聚焦筛选成本可能超过 2 万美元且随规模增加，实验室通常仅选择数百个最可能关联特定条件的基因。传统流程需要研究生和博士后团队逐条添加候选基因并附简要理由或文献链接。这是基于文献调研、专业知识和直觉的「经验猜谜游戏」，受限于人类认知带宽，且依赖已有研究成果和在场人员记忆，难免存在疏漏。&lt;/p&gt;&lt;p&gt;Lundberg 实验室正运用 Claude 颠覆这种方法。他们的系统不再追问「基于已有研究我们能做出哪些推测」，转而探索「基于分子特性应该研究什么」。&lt;/p&gt;&lt;p&gt;团队构建了细胞内所有已知分子（蛋白质、RNA、DNA）的关联图谱，标注蛋白质相互作用、基因编码关系和结构相似性。随后向 Claude 提出目标 &amp;mdash;&amp;mdash; 例如寻找调控特定细胞结构或过程的基因 &amp;mdash;&amp;mdash;Claude 通过遍历分子关系图谱，依据生物学特性与关联度筛选候选基因。&lt;/p&gt;&lt;p&gt;该实验室正在开展验证实验，将对比人类专家与 Claude 的表现。若该方法验证有效，团队预期它将成为聚焦扰动筛选的标准前置步骤。实验室无需再依赖直觉博弈或当代研究中盛行的暴力筛选，而是基于信息做出精准靶向决策。&lt;/p&gt;&lt;p&gt;原文链接：https://www.anthropic.com/news/accelerating-scientific-research&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>租了8张H100，他成功复现了DeepSeek的mHC，结果比官方报告更炸裂</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:28:49 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;元旦期间，DeepSeek 发布的 mHC 震撼了整个 AI 社区。&lt;/p&gt;&lt;p&gt;简单来说，DeepSeek 提出的 mHC 通过将传统 Transformer 的单一残差流扩展为多流并行架构，并利用 Sinkhorn-Knopp 算法将连接矩阵约束在双拟随机矩阵流形上，成功解决了超连接（HC）在大规模训练中因破坏恒等映射属性而导致的数值不稳定和信号爆炸问题。更多详情请参阅《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651010187&amp;idx=1&amp;sn=cc9ae88f676873468dcfc98d54e98aa9&amp;scene=21#wechat_redirect" target="_blank"&gt;刚刚，梁文锋署名，DeepSeek 元旦新论文要开启架构新篇章&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;时至今日，这篇让众多读者大呼看不懂的论文依然是技术社区关注的一大焦点。解读分享这篇论文就好像已成为一种技术时尚。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14VNUWI9adiaSqribkZiavwWb6ylMFfyfib9zLbSr4A4f61P8qnXQ23IJGVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.8574317492416582" data-s="300,640" data-type="png" data-w="989" type="block" data-imgfileid="503528930" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ca024fa7-7692-4ae2-98d6-c4e95d668991/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14P7gbO6qkvHB6GLSKLFoyXgVicLvdV4RUmceGomNTQNQSLibfaQuYR2ug/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.336734693877551" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503528931" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4c2ab415-8c48-418f-abb5-37ebca1f8d2e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但还有更加硬核的，近日 &lt;strong&gt;FlowMode 工程师 Taylor Kolasinski 宣布成功复现了 mHC，并且在测试中还取得了比 DeepSeek 原始论文更好的成绩&lt;/strong&gt;！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148fxf77icFbcLA7DxbN7eIfhTicf2sclr7W6J3Yh7EniaP5UmV4PO63Wsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528932" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/85968fa3-a92d-4e79-801d-416710d17537/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;评论区也是直呼「不明觉厉」：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14iaSBv7DkfgMXeTsyEleE0tDmnzvefpZ7lNibLicF16WSbichWHC520Xl7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528933" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1564350f-b075-4649-a8b6-52572e618ee6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;目前，Kolasinski 正通过一个 mHC 复现系列博客介绍其复现成果，相关博客已经发布了 2 篇。这里我们进行了整理，以飨读者。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Z9dCZ27LYqfS77EtwVlvA79rQR1LuruLB9lUA39EbpHRQ9exEVWibwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6925925925925925" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528934" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ffe49afd-f69a-4c71-a9e5-4126cc73c561/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="2 2 []"&gt;博客 1：https://taylorkolasinski.com/notes/mhc-reproduction/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;博客 2：https://taylorkolasinski.com/notes/mhc-reproduction-part2/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;博客一：DeepSeek 的 mHC：当残差连接发生爆炸&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你使用过的每一个 Transformer 模型都采用了 2016 年以来的同一种残差连接设计。&lt;/p&gt;&lt;p&gt;GPT-5、Claude、Llama、Gemini。在底层，它们做的事情都是一样的：x + F (x)。信息流只有一条，穿过网络，每一层都向其中添加内容。&lt;/p&gt;&lt;p&gt;DeepSeek 提出了一个问题：如果它变得更宽会怎样？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14K67JcIibnb4KQMFVvfVicMYFgKPsFiabVXMTvP6nevicO6D8QWsOjdkUEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528935" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/98ae53d2-b127-4e77-a937-6a617b056476/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;标准残差连接是每一个现代 Transformer 的脊梁。其思路很简单：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ibNUSZVmyqBt9GqhG5AdZsIC6ZYib5pL7NibhiaMLSNpOCMpKWBvold3hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.18181818181818182" data-s="300,640" data-type="png" data-w="209" type="block" data-imgfileid="503528936" data-aistatus="1" data-original-style="width:109px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/24211aba-5f77-4311-a12c-c7087688b798/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;其输入原封不动地流过，加上该层的输出。这是一条单一的信息流。进去是什么，出来的就是什么加上一个学习到的更新量。这就是为什么 Transformer 可以深达数百层：梯度有一条干净的向后路径。简单。稳定。自 2016 年以来未曾改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;超连接（Hyper-Connections）&lt;/strong&gt;采取了不同的方法。它不再是单一流，而是扩展到 n 条并行流，并带有可学习的混合矩阵：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ib303XUokjGaECqsialpZEV9LWOhRFG0M0uOYUGZUiaysdic3uXibAibGSUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.10416666666666667" data-s="300,640" data-type="png" data-w="432" type="block" data-imgfileid="503528937" data-aistatus="1" data-original-style="width:198px;height:21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/02170543-56d9-4c80-ba29-6e3c99b14deb/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;下图对比了标准残差与超连接：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JdzbPqUPZV8m8z7lONBnWBq0aicFXAWxekS3Q8hUvLyX5picxIbUrsYw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.271875" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503528939" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/eba1344d-5cac-4d9f-840a-ec9e95cd2031/640.gif" data-order="0" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;三个矩阵控制着信息的流动方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;H_res：信息流在残差路径中如何混合（红色的交叉部分）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;H_pre：信息流在进入层之前如何组合&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;H_post：层的输出如何分配回各个流中&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;超连接表达能力更强。参数更多，但计算开销几乎可以忽略不计。理论上性能更好。亦可参阅报道《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650941988&amp;idx=2&amp;sn=1b35f2af9982c529a1c9217bfab24a02&amp;scene=21#wechat_redirect" target="_blank"&gt;字节豆包大模型团队突破残差连接局限！预训练收敛最快加速 80%&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;但问题是什么？那些混合矩阵是不受约束的。它们不仅能路由信号，还能放大信号。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;爆炸&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在激进的学习率下，作者的复现实验中超连接（HC）的信号放大达到了 7 倍，随后最终崩溃。Amax（行和列绝对值的最大值）衡量了一个矩阵能将信号放大多少。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14KTGPYOxRc0mIq9po5SS1CabBE40e9zLeqsBbz2rIquTVwKzLutn2RQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.33700137551581844" data-s="300,640" data-type="png" data-w="727" type="block" data-imgfileid="503528940" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5dff3de9-32d7-413b-84c0-6af93530b5ab/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 10M 参数的规模下，这也还行。但 DeepSeek 在 27B 参数下观察到了这种情况：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;「Amax 增益幅度产生了极值，峰值达到 3000」&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;你没有看错：&lt;strong&gt;三千倍&lt;/strong&gt;的放大。在 27B 参数下，不受约束的 HC 不仅仅是漂移，而是爆炸了。这里的 10M 复现中达到的 9.2 倍正是这种指数级故障的早期预警。&lt;/p&gt;&lt;p&gt;也因此，不受约束的混合矩阵在规模化时会崩溃。微小的放大呈指数级复合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14VWxBdN7nxiamNJd85YftJuh72KeQagAibiafxXkCHyGYJe67W4BybGV7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.43333333333333335" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528941" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d2363632-ac09-4089-9477-3b6d7a5e46ff/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;压力测试： 在激进的学习率下，HC 的信号放大在崩溃前达到了 7 倍。mHC 保持平稳，维持在 1.0。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;修复：约束流形&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek 的修复方案很干净：将混合矩阵约束为&lt;strong&gt;双重随机（doubly stochastic）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;一个双重随机矩阵具有以下特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;所有条目非负&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;行之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;列之和为 1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14GH15XHpicXwdEuRIu1Ft45cvA5z2HKhL5xqwibgzKu4ZaGTL2Qu0jwIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5158227848101266" data-s="300,640" data-type="png" data-w="632" type="block" data-imgfileid="503528942" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/8e58bf9b-32b7-4221-9277-1e6c83461eb4/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着混合操作只能对流进行加权平均。它可以路由信息，混洗它，融合它。但它不能放大。&lt;/p&gt;&lt;p&gt;DeepSeek 是如何做到塞？使用 Sinkhorn-Knopp 算法。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD143D4km7Z9CoWuwYU5rm6pTOia8oYH6HtQichr5EEbnlKN8JpNTZO74uMw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.9578163771712159" data-s="300,640" data-type="gif" data-w="403" type="block" data-imgfileid="503528943" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/2ec37ecc-006a-45a6-b4e8-9dd0c98efac3/640.gif" data-order="1" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该算法非常简单：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;从任意矩阵（原始学习到的权重）开始&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;取指数使所有条目变为正数：P = e^H&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归一化行，使每一行之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归一化列，使每一列之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重复 3-4 个步骤，直到收敛&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;就是这样。交替进行行和列的归一化。二十次迭代就足够了。&lt;/p&gt;&lt;p&gt;这个过程是可微分的。梯度可以回传穿过所有二十次迭代。网络学习原始权重 H，而 Sinkhorn 确保实际的混合矩阵始终是双重随机的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14rDcYB40OThxGxcascU0icJHCmTEZicdibrN77EKVoNLbRaPrYmzWejsww/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.12735849056603774" data-s="300,640" data-type="png" data-w="424" type="block" data-imgfileid="503528944" data-aistatus="1" data-original-style="width:210px;height:27px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/d0b60218-ea2f-46a2-bda4-8e081295ee6d/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;当作者第一次看到这个时，感觉像是作弊。你不是在学习稳定性，而是在强制它。但有些属性不应该被学习；它们应该被保证。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;技术说明：严格来说，只有递归矩阵 H_res 需要完整的 Sinkhorn 双重随机处理。它是层层复合误差的那个。输入 / 输出混合器（H_pre，H_post）仅通过 sigmoid 进行有界处理。Sinkhorn 的计算成本只花在最重要的地方。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD146neDNSz6smMWS4LF7bEm1h6Rym6naUn0JzrYIXrIj806DicaSWcfPBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.90744920993228" data-s="300,640" data-type="png" data-w="886" type="block" data-imgfileid="503528945" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/c814eeb5-3376-4ae3-90e3-691de546813c/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不同种子的结果（深度 24，3 个种子）&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14D8MTeOXCHfLaIK0w51V9a5c1nNo4G5vxML4x8A3zOwRbPH704R7nDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.24083769633507854" data-s="300,640" data-type="png" data-w="764" type="block" data-imgfileid="503528946" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/d64f4e03-95c7-4604-8ad7-4abc860b3681/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;HC 在原始性能上获胜：验证损失 0.88 对 1.12。在 10M 参数下，mHC 约束就像是一种稳定性税；你付出的是表达能力。但在 27B 参数下，这种税是防止你的模型爆炸成 NaN 的唯一手段。&lt;/p&gt;&lt;p&gt;但看看方差。HC 的损失在不同种子间的变化是 mHC 的 3 倍（&amp;plusmn;0.033 vs &amp;plusmn;0.012）。至于 Amax？HC 根据种子的不同在 6.1 到 7.6 之间摆动。mHC 是 1.00。每一个种子。每一次运行。零方差。&lt;/p&gt;&lt;p&gt;在 10M 参数下，这种不稳定性是可以存活的。HC 仍然获胜。但在 27B 参数下，那 6-7 倍的放大变成了 3000 倍。在这个规模下你无法赌博。&lt;/p&gt;&lt;p&gt;深度扩展&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14cKz5YI6AVeNYDOBMWaRs93eI1L9jHBrvyFWhLuuQNjKJvAMPo2bhXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.9187643020594966" data-s="300,640" data-type="png" data-w="874" type="block" data-imgfileid="503528947" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/73a9fe86-a9c5-40fc-b6a3-ac3eec3690fb/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作者还扫描了从 6 到 24 层的深度（保持约 11M 的常数参数预算）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;损失随着深度增加而改善，直到不再改善。深度 20 达到了甜蜜点（0.85 验证损失）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;深度 24 略有退步（0.93），这是由于为了将维度缩小到 192 而产生的宽度瓶颈。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Amax 是不可预测的。深度 20 飙升至 9.2 倍。深度 12 达到 6.6 倍。深度 8 保持在 4.3 倍。没有清晰的关系；HC 是混沌的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验细节&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;数据集： TinyShakespeare（约 1M 字符，字符级）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型： GPT-2 架构，约 10M 参数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练： 5000 步，AdamW (&amp;beta;1=0.9, &amp;beta;2=0.95)，权重衰减 0.1，余弦 LR 衰减&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;硬件： Apple M 系列 (MPS)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;深度扫描： 8 种配置（6-24 层），调整宽度以维持约 11M 参数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;种子变异： 3 个种子（42, 123, 456），深度 24&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;为什么这很重要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;残差连接不仅仅是帮助梯度流动的技巧。它们是一种守恒定律。&lt;/p&gt;&lt;p&gt;在物理学中，守恒定律约束了可能发生的事情，但使预测成为可能。你不能制造永动机，但你可以精确计算球会落在哪里。&lt;/p&gt;&lt;p&gt;残差连接中的恒等映射是类似的。它通过防止任意变换来约束网络，但它保证了稳定性。信号幅度被保留。&lt;/p&gt;&lt;p&gt;HC 打破了守恒；mHC 恢复了它，不是通过回归到恒等映射，而是通过找到一个更丰富的、仍然守恒信号的流形。&lt;/p&gt;&lt;p&gt;2016 年，何恺明等人引入 ResNets 来解决梯度消失问题，确保信号不会消亡。十年后，相反的问题出现了：超连接带来的信号爆炸。恒等映射通过被动的方式解决了第一个问题。mHC 通过强制守恒解决了第二个问题。&lt;/p&gt;&lt;p&gt;每一个残差连接都是一种守恒定律。mHC 强制执行了它。&lt;/p&gt;&lt;p&gt;不是黑客手段，不是技巧。这是一个原则性的约束，使架构能在规模化下工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;流持久性 Bug 让人学会谦卑。&lt;/strong&gt;作者的第一个实现看起来是对的。公式与论文相符。代码能跑。但当把输出投影回单一流并在每一层重新扩展它，扼杀了并行架构。「超连接」中的「超」部分实际上没做任何事。三次独立的审计都说「看起来是对的」。Bug 是架构上的，不是数学上的。作者是在问了「等等，层与层之间流动的实际形状是什么？」之后才发现的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;约束不是限制；它们是保证。&lt;/strong&gt;双重随机投影强制了稳定性。你不是在学习好的行为。你是在让坏的行为变得不可能。作者表示自己的第一反应是：「这不优雅。这是束缚。」但其实，HC 达到了 7 倍放大才是重点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无聊的选择能规模化。&lt;/strong&gt;标准残差连接自 2016 年以来一直存活，不是因为它们是最优的，而是因为它们是稳定的。HC 表达能力更强但脆弱。mHC 找到了一个中间地带：比标准残差表达能力更强，且带有稳定性保证。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;博客 2：10,924 倍：17 亿规模下的不稳定炸弹&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下面是 mHC 复现系列的第 2 部分。第 1 部分 展示了 10M 参数量下的不稳定性。现在，要扩大规模了。&lt;/p&gt;&lt;p&gt;在第 1 部分中，作者在 TinyShakespeare 数据集上训练了一个 10M 参数的 Transformer，并目睹了超连接（Hyper-Connections）将信号放大了 9.2 倍。DeepSeek 的论文 报告称在 27B 参数下放大倍数达到了 3000 倍。现在我们也扩大规模看看。&lt;/p&gt;&lt;p&gt;为了这次运行，作者租用了一个 8x H100 的节点。以下是他的发现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规模跃迁&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qRxwTSib2fNm2k7ExD0gK2mnlH1ibeCqFKgAV7bEIcicyeHvdrcqQhPEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.36363636363636365" data-s="300,640" data-type="png" data-w="869" type="block" data-imgfileid="503528948" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/aa27acf1-40f2-4709-845a-d6ccb323100a/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;10924 倍信号放大！这远远超出了 DeepSeek 论文中的 3000 倍。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇博客记录的是作者在三种架构上进行的 18 次实验，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Residual：标准的残差结构，即 x + F (x) 作为基线；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HC：采用无约束混合矩阵的超连接（Hyper-Connections）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;mHC：采用 Sinkhorn 投影的流形超连接（Manifold Hyper-Connections）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每种架构分别在两种网络深度下进行（32 层和 48 层），并使用三个随机种子（42、123、456），因此每种配置运行 3 次。&lt;/p&gt;&lt;p&gt;所有模型均在 C4 数据集上训练 5000 步，采用 bf16 混合精度。其中 32 层模型参数量为 17.3 亿（1.73B）；48 层模型参数量为 25.4 亿（2.54B）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主要结果&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qIudVn1dePL4W3zdUcrJI3JgJhqvEhYg8TFayEBHuMMlcDNicmR3JrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.712037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528949" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/92099748-1230-44ee-aca3-2634116ebb1e/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;首先，在 Loss 表现上：所有方法的收敛表现几乎一致。&lt;/p&gt;&lt;p&gt;三种方法最终都收敛到相近的 loss 区间（约 5.4&amp;ndash;6.0）。整体学习曲线几乎完全重合：HC 并没有学得更快，mHC 也没有变慢。从实验结果来看，引入 Sinkhorn 投影几乎没有额外代价。&lt;/p&gt;&lt;p&gt;其次，Amax 表现出强烈的不稳定性。Amax 是用来衡量混合矩阵对信号的放大程度，Amax = 1.0 表示对信号不放大（中性）；数值越高，表示信号被放大的程度越强。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD143CBnzK5jffKKxibNCgb5LicONnqYD8HaJwHQctPtFg4ibzxfLDEu0oDCw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=20" data-ratio="0.6284722222222222" data-s="300,640" data-type="gif" data-w="576" type="block" data-imgfileid="503528950" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/cac33753-49d5-445c-ae04-fa165554b3f6/640.gif" data-order="2" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验中发现，在深度为 32 时，HC 的 Amax 值飙升至 6500 倍，并伴随着剧烈的波动，而 mHC 值则稳定保持在 1.0。在深度为 48 时，这种模式再次出现：HC 猛增至 3500 倍，而 mHC 值保持不变。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14D4micrXBUEpxjwyjQtjLF8kSJY6wicwExtROYCPmRWTOYiaPVicnhvCQ4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528951" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/03f3c9d8-777a-4ead-a9d7-3aa4e83afe88/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Scaling Laws&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14PrayHRzwlbibf1yNI8eHOSMILT1dwCslXWAKfTkiagiblibId1qSHT2J8g/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528952" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/bc2965d9-9dd6-425c-9fd4-1730a20e6118/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在对 Amax 与模型参数规模进行 log&amp;ndash;log 绘制后，可以观察到明显的放大趋势：当模型规模为 1000 万参数时，Amax 约为 9.2 倍；在 17 亿参数规模下，这一数值跃升至 10924 倍；&lt;/p&gt;&lt;p&gt;而公开数据中，DeepSeek 的 270 亿参数模型对应的 Amax 约为 3000 倍。基于趋势线外推，模型规模达到 100 亿参数时，Amax 可能上升至约 50000 倍，在 1000 亿参数量级下，甚至可能接近 400000 倍。&lt;/p&gt;&lt;p&gt;实验结果并未显示出任何自我修正的迹象，相反，随着模型规模扩大，不稳定性呈现出持续加剧的趋势。值得注意的是，该实验中的 17 亿参数模型所表现出的不稳定性，甚至高于参数规模更大的 DeepSeek 模型。&lt;/p&gt;&lt;p&gt;这种差异可能源于架构设计、训练配方或测量方法的不同；批大小、学习率与网络深度之间的相互作用，也使得尺度效应并非严格单调。&lt;/p&gt;&lt;p&gt;尽管具体数值会受到多种因素影响，但这种不稳定性是客观存在的、可以被量化的，而且规模不容忽视。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可复现性&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Ft0XWaVGSUqCUxpHs8KiaNSQutq3lCBKkA0TAaGQ07bCQdAKcNjjUZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.662962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528954" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/56023cce-775a-471c-817c-796e54dcecbb/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，在三个不同的随机种子下，实验都呈现出完全相同的模式：所有 HC 的训练过程都会发生爆炸，而所有 mHC 的训练过程始终保持平稳。不同随机种子下的 loss 曲线几乎完全重合，两种方法的学习速度也一致。&lt;/p&gt;&lt;p&gt;唯一的差别在于模型内部正在发生的事情：HC 在不断积累不稳定性，这种不稳定性可能在任何时刻被引爆；而 mHC 则始终维持着自身的结构完整性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;逐层分析：不稳定性从哪里开始的&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD144OV30ySHmJNngohQHv5WMXgbTdjS4gVqdSOicAekOx87bzjHYqHZDFA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=24" data-ratio="0.8131487889273357" data-s="300,640" data-type="gif" data-w="578" type="block" data-imgfileid="503528955" data-aistatus="1" data-original-style="null" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/e521e269-94bd-4432-8058-8e09cfb7d8e0/640.gif" data-order="3" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这里有一个令人惊讶的发现：&lt;strong&gt;不稳定性始于输入端，而非输出端&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;HC 的第 0 层（可视化图表中的顶行）率先变红，随后其混合矩阵在训练初期就突破了 Amax 2.0，而更深层的网络则保持相对稳定。看起来问题不在于深度，而在于第 0 层 &amp;mdash;&amp;mdash; 这是唯一一层直接吞吐原始输入的层。&lt;/p&gt;&lt;p&gt;为什么是第 0 层？ 不同于深层网络前面有 LayerNorm 把关，第一个混合矩阵直接面对原始 Embeddings。其他每一层看到的都是经过归一化、变换后的表征，但第 0 层必须硬抗 Embedding 表吐出的任何数值。如果尺度（scale）没有完美匹配，第 0 层就会学习去补偿。&lt;/p&gt;&lt;p&gt;而在 HC 中，「补偿」可能就意味着「放大」。反观 mHC，在所有层级和所有训练步数中都呈现均匀的绿色。Sinkhorn 投影在限制最大值的同时，也完全防止了任何层发生漂移。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信号流：视觉展示&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148HrkPEicLkbMKY9a7yJk04NncECBn5s3SOwX0zx4H40DvwtYVmicv0tQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=25" data-ratio="0.41297935103244837" data-s="300,640" data-type="gif" data-w="678" type="block" data-imgfileid="503528956" data-aistatus="1" data-original-style="null" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/568b2609-5914-4f36-8ee7-3e7dc0cb25ba/640.gif" data-order="4" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在第 3000 步时，一个进入 HC 网络的信号在输出时被放大了 532 倍。而同样的信号经过 mHC 输出时倍率为 1.000003 倍，本质上保持不变。&lt;/p&gt;&lt;p&gt;LayerNorm 和非线性模块似乎「收拾」了大部分烂摊子，但这意味著它们消耗了模型容量，仅仅是为了去抵消上游制造的混乱。&lt;/p&gt;&lt;p&gt;这正是守恒定律的体现，它表明残差连接应当保持信号的幅度：输入了什么，就应当输出什么（再加上学习到的残差）。&lt;/p&gt;&lt;p&gt;HC 打破了这一规则，任由信号失控螺旋上升，而 mHC 则守住了底线。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;压力测试&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14gSaOIAWmiaMM9kuSlNMDvsqRcup1KHcxVicjP8NLXjuyKJZQvNrJgqiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.3509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528958" data-aistatus="1" data-original-style="null" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/87cf0514-a690-4404-ad93-b24701dd4154/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;正常的训练使用了 1e-4 的学习率。如果加大强度会发生什么？作者在 3 倍于正常学习率的条件下进行了压力测试：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14SVdwpjjUCsYuMK9fvtu3RoWcfzBYKp1pWE8CrvhDA1ygzK3ibYg3wuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=27" data-ratio="0.3731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528959" data-aistatus="1" data-original-style="null" data-index="29" src="https://image.jiqizhixin.com/uploads/editor/249935b6-0373-4cbd-a740-a053d055c11f/640.png" alt="图片" data-report-img-idx="27" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;深度 64 的模型在 Amax 达到 14765 倍后，开始在 2000 倍到 10000 倍之间剧烈振荡，同时，混合矩阵彻底失控。&lt;/p&gt;&lt;p&gt;反观 mHC，在所有配置、所有学习率下都表现得平坦、稳定且「无聊」，数值始终保持在 1.0。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;意料之外：HC 模型并未崩溃&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14gPM78lqLq2pMicicvSaG3vZemP982XL1koRM3AxpdVNuVE9Ew4U0QNSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=28" data-ratio="0.4324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528960" data-aistatus="1" data-original-style="null" data-index="30" src="https://image.jiqizhixin.com/uploads/editor/e401403d-fce4-471a-b9ee-4981ff560077/640.png" alt="图片" data-report-img-idx="28" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;有一个作者没想到的结果：所有的 HC（Hyper-Connections）运行实验都没有崩溃。&lt;/p&gt;&lt;p&gt;信号放大了 14765 倍，在深度 32 时放大了 10924 倍。Loss（损失）没有发散，训练也没有出现 NaN。模型仍在继续学习。&lt;/p&gt;&lt;p&gt;这是一种「定时炸弹」般的场景。不稳定性确实存在，但尚未导致灾难性的失败&amp;hellip;&amp;hellip; 至少目前还没有。&lt;/p&gt;&lt;p&gt;为什么没炸？作者列举了以下几种可能性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;梯度裁剪力挽狂澜。&lt;/strong&gt;将范数裁剪在 1.0 防止了最严重的梯度爆炸，这几乎肯定就是拯救了这次运行的关键。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;5000 步还不够。&lt;/strong&gt;如果训练时间再长一点，它可能就会爆发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;这些模型还太小。&lt;/strong&gt;在 100B（千亿）参数规模下，动力学特性可能会有所不同。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;稳妥的解读是：&lt;strong&gt;HC 正在积聚不稳定性，在不同条件下可能会被引爆，而 mHC则完全消除了这种风险&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;重访守恒定律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在第 1 部分中，作者将残差连接定义为了一种守恒定律，即「每一个残差连接都是一条守恒定律，mHC 强制执行了它。」&lt;/p&gt;&lt;p&gt;1.7B 参数规模的结果让这一点变得具体：HC 违反了守恒，信号在训练过程中增长了 10000 多倍。而 mHC 强制守恒，信号保持稳定。具体地，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 10M（一千万）参数时，违反守恒是可以存活的。作者在第 1 部分中看到的 9.2 倍放大虽然烦人，但尚在可控范围内。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 1.7B（十七亿）参数时，这就是个炸弹。10924 倍的放大意味着一个本该是量级 1 的信号，现在变成了 10924。梯度更新在与这种放大对抗，而优化器必须做额外的工作来补偿网络内部的混乱。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这还仅仅是在 5000 步的时候，如果训练更久、推高学习率、或者扩展到 10B 参数，在某个临界点，炸弹就会引爆。&lt;/p&gt;&lt;p&gt;mHC 不仅仅是降低了不稳定性，而是彻底消除了这种故障模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从这次运行中学到了什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一是，GPU 3 挂了。8 张 H100 中的一张在特定实验中不断报错 CUDA 错误。作者浪费了一个小时调试「代码问题」，才意识到是硬件故障。云端 GPU 是会坏的。&lt;/p&gt;&lt;p&gt;二是，Batch size（批次大小）的限制是真实的。2.5B 参数的 d48 模型无法在 batch size 为 8 时塞进显存。作者不得不降到 batch size 4。这意味着不同深度下的「每步 token 数」不同。&lt;/p&gt;&lt;p&gt;虽然同一深度下 HC 与 mHC 的对比依然有效（batch size 相同），但跨深度的对比就不那么完美了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果正在实现超连接：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用 Sinkhorn 投影。这里大概只有 10 行代码，却消除了一种在大规模下感觉真正危险的故障模式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在训练期间监控 Amax。如果你看到它爬升超过 10 倍，则是在积聚不稳定性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第 0 层是「金丝雀」（预警指标）。特别密切关注你的输入混合矩阵。如果你的基础模型有一个不稳定的第 0 层，微调期间的词表变更或 Embedding 漂移可能会导致网络不稳定。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该约束没有性能代价。mHC 的 Loss 与 HC 完全一致。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;代码和数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数据是公开的，代码即将发布。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;主要实验: wandb.ai/taylorkolasinski/mhc-part2&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;压力测试: wandb.ai/taylorkolasinski/mhc-part2-stress&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者表示，包含训练脚本的仓库即将推出。W&amp;amp;B 仪表板拥有每次运行的完整配置、指标和系统日志。实验在一个 Lambda Labs 的 8x H100 SXM5 节点上运行，耗时约 17 小时。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一步计划&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前有两个悬而未决的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;HC 真的会失败吗？ 作者看到了 10924 倍的放大，但训练没有发散。这是一种潜在风险，还是说训练时间更长就会导致失败？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Scaling Law 是什么？ 10M &amp;rarr; 9.2 倍。1.7B &amp;rarr; 10924 倍。到了 10B 会发生什么？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者想探索 Scaling Law 到 10B 参数，趋势线表明那里可能出现 50000 倍的放大。那个实验技术上已经准备好了，但需要计算预算的大幅提升。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>评审用不用AI，作者说了算？ICML 2026全新评审政策出炉</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:13:11 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;开始前，温馨提醒一下各位投稿 ICML 2026 的小伙伴们，投稿已于 1 月 8 日开放，也请大家注意投稿截止时间：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;摘要提交截止日期：2026 年 1 月 23 日。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;全文提交截止日期：2026 年 1 月 28 日。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;两个月前，ICML 2026发布了征稿新规，我们也&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651000328&amp;idx=2&amp;sn=7be350e14dc2b6b044763ad91f745a4a&amp;scene=21#wechat_redirect" target="_blank"&gt;详细做了报道&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;当时，为了应对大量的，超负荷的预期论文投稿量，以及其他顶会超负荷运行的前车之鉴，ICML 提出了互审数量限制和人工智能使用规定。&lt;/p&gt;&lt;p&gt;征稿要求中提到：评审过程中&lt;strong&gt;可能会使用 AI 工具辅助，但不会允许完全由 AI 执行评审&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;已经投稿了论文的小伙伴或许已经发现了，这次 ICML 似乎有了一些新变化，并且是在征稿要求中没有详细说明的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ucegjrN0AxZIeMX3T1mPs5sAd8t7icFiagK0XhSzCzGwwBoDsTVN4sxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5453703703703704" data-type="png" data-w="1080" data-width="1482" data-height="808" data-imgfileid="503528857" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/254144b5-2641-4b13-a22b-892c22aa7251/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;我们简单概括一下，ICML 2026 引入了评审类型选择机制，&lt;strong&gt;论文作者可以决定&lt;/strong&gt;在其论文评审过程中是否允许使用大语言模型。&lt;/p&gt;&lt;p&gt;具体包括两种政策：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;政策 A 是保守型&lt;/strong&gt;，简单直白好理解：&lt;strong&gt;严格禁止&lt;/strong&gt;在论文评审过程中使用任何大语言模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;政策 B 是宽松型，允许使用&lt;/strong&gt;大模型评审，但会议对使用大模型评审的方式做出了限制：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;允许的行为：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用大语言模型辅助理解论文内容及相关工作；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用大语言模型对评审意见进行语言润色；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;可将投稿论文提交给符合隐私合规要求的大语言模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;不允许的行为：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;向大语言模型询问论文的优点或缺点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型总结或建议评审应关注的关键点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型提供评审意见的结构或提纲；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型撰写完整的评审意见。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;隐私合规大语言模型，是指&lt;strong&gt;不会使用日志数据进行训练、且对数据保留期限作出限制&lt;/strong&gt;的模型工具。&lt;/p&gt;&lt;p&gt;这个小变化是比较新颖的。&lt;/p&gt;&lt;p&gt;过去，评审是否使用大模型，更多取决于评审人，或者处在一种默认被接受的灰色状态。这一次，ICML 明确把选择权交给了作者本身。在论文投稿量持续攀升、评审负担越来越重的现实下，ICML 既没有彻底禁止 AI，也没有完全放开 AI 评审，却给出了一个相对折中的方案。&lt;/p&gt;&lt;p&gt;问题在于，关于大模型使用的规定，执行起来一般都很困难。&lt;/p&gt;&lt;p&gt;就像&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651002013&amp;idx=1&amp;sn=c4588ce6e29f6464cda6e84dfded6af5&amp;scene=21#wechat_redirect" target="_blank"&gt;我们之前报道的&lt;/a&gt;，第三方机构对 ICLR 2026 的审稿意见进行系统性统计，其中就发现了大量 AI 审稿的现象。&lt;/p&gt;&lt;p&gt;在对 75800 篇论文的审稿意见统计中，竟然&lt;strong&gt;有 21% 完全由 AI 生成、4% 重度由 AI 编辑、9% 中度由 AI 编辑、22% 轻度由 AI 编辑，完全由人类（审稿人）撰写的仅占 43%&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14logWUV2YVJemybGdKOicgfps3icWfrfZQGibpFHkiaiaYsYgziagz9qvTTWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.32222222222222224" data-type="png" data-w="1080" data-width="1080" data-height="348" data-imgfileid="503528856" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4bb631eb-7238-43ce-86a2-c29d7c00af30/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;网友们也表达了类似的意见。&lt;/span&gt;AI 审稿已经达到了泛滥的程度，这也并不是 ICML 2026 这次的政策 B 能够完全限制的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14LF88DuOD6fVGxZCpxUVKiavQuaScTv2Seswonic0gNQAfzIaz7icJ7KWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.18796296296296297" data-type="png" data-w="1080" data-width="1450" data-height="272" data-imgfileid="503528858" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f9d22172-c902-42e7-8509-5deb8fb72a61/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;虽然说 ICML 明确规定了使用大模型审稿中不允许存在的行为，但谁又能保证审稿人一定遵从了这些限制呢？我们猜测，用大模型审稿的时候，提问大模型的第一句话就很可能是「给出这篇论文的优缺点」，但这明显是违反规定的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14YK49xxnNkW4vDEZEDHvuVDajoO45DIMWlrbdric1MNiaARR7CCRDzzBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1685185185185185" data-type="png" data-w="1080" data-width="1404" data-height="236" data-imgfileid="503528854" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/183ee06d-5c84-421d-bb9b-e800821af73a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;因此，这套规则或许更像是一种明确态度和方向的约定，而不是一套可以严格执行的机制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14zqG7XA1nMvLVZHian7WcQY4VOcDPQa28mgHSj6b5u3KfsYEOxeW7WBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2796296296296296" data-type="png" data-w="1080" data-width="1430" data-height="400" data-imgfileid="503528855" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/db7a43ce-c6bb-4965-b926-13e6d0a97f63/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不过，在大家如此担心大模型引发各种信任危机的情况下，ICML 还可以让作者选择拒绝大模型审稿。&lt;/p&gt;&lt;p&gt;有个「一刀切」的选项交到论文作者手中，也是当下一个不错的选择，不是吗？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>机器人终于「懂」家务了！伯克利MomaGraph让机器人像人一样做家务</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:02:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/03280580-d5bd-4fa7-bee4-757837eadd1f/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;想象这样一个日常画面：你吩咐家用机器人「烧壶开水」，它却当场卡壳&amp;mdash;&amp;mdash;水壶在哪？该接自来水还是过滤水？先插电还是先按开关？水开了又该如何判断？这些对人类而言像呼吸一样自然的家务，对过去的机器人却是大大的难题：要么忘了插电，要么找不到水壶，甚至会把柜门把手错当成开关一通乱按。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;最近，加州伯克利和马里兰大学联手推出的 &lt;strong&gt;MomaGraph 技术&lt;/strong&gt;，就是要让机器人彻底告别这种「做家务的人工智障」时刻。这套算法不仅能让机器人真正理解「做事的先后顺序」，更在星动纪元星动 Q5 上成功完成了开柜子、开微波炉、开电视、关灯等真实家务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFJH7iavGYicQG6ed7A7QR9c2HU2V7309dMkGQDjbOvguicH6FAKibQ5EcnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5722222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528573" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/daa3e230-b3ed-44a5-9547-2828f793c081/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;a href="https://mp.weixin.qq.com/s/H8aS7_QVhS0Who_tJee69Q"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8a03ed7d-0f3e-48c8-adab-7235162ba11b/1768812923781.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gWibFFuSlngZ6TUI2YBIRPjCRiaakUoUJj2dH6brT0QRZus4psqZYOD4vMJ21RTVh2zodjIssA97aTGg%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4347229785035112470" data-ratio="1.7777777777777777" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4347229785035112470" data-vh="371.8125" data-vidtype="2" data-vw="661" data-w="1920" height="384" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4347229785035112470"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;论文名称：MOMAGRAPH: STATE-AWARE UNIFIED SCENE GRAPHS WITH VISION&amp;ndash;LANGUAGE MODEL FOR EMBODIED TASK PLANNING&lt;/li&gt;&lt;li&gt;论文地址：https://arxiv.org/pdf/2512.16909&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="8"&gt;&lt;strong&gt;一、研究背景：家用机器人做不好家务的「三大卡点」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;家用移动操作机器人（比如帮你开窗户、热牛奶的机器人）需要同时「看路」（导航）和「动手」（操作），但过去的技术一直存在三个关键问题卡点，导致机器人「做不好家务」：&lt;/p&gt;&lt;p data-path-to-node="10,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,0,0"&gt;卡点 1：只知「在哪」，不知「咋用」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,0,0"&gt;比如机器人要开窗户，传统技术可能只知道「窗户在书桌右边」（空间关系），但不知道「窗户把手能控制开关」（功能关系）&amp;mdash;&amp;mdash;就像你知道手机在口袋里，却不知道按电源键能开机，自然用不了手机。&lt;/p&gt;&lt;p data-path-to-node="10,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,1,0"&gt;卡点 2：只认「图片」，不认「变化」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,1,0"&gt;传统模型会把场景当成静态图片，比如机器人转了窗户把手后，模型还以为「窗户没动」，不知道状态已经从「锁着」变成「待打开」；就像你关了灯，却还以为灯是亮的，后续行动规划肯定会出错。&lt;/p&gt;&lt;p data-path-to-node="10,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,2,0"&gt;卡点 3：只想「步骤」，不想「前提」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,2,0"&gt;过去的 AI（比如 GPT-5）会直接从图片里「想步骤」，比如让它「烧开水」，可能会说「装水 &amp;rarr; 加热」，却漏掉「插电源」这个关键前提；而人做这件事时，一定会先确认「水壶能通电」，再规划步骤。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFzmGzDCKZogFb1WibUPVEXs37KVQAuJg7uAd4zHUR0icoYzhrmazSnx0w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.49537037037037035" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528606" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9db73485-6f5f-4127-85f3-ca7146bba6cb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;二、突破思路：给机器人画一张「任务说明书」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;研究团队的核心想法很简单：&lt;strong&gt;让机器人先画一张「任务导向的场景图」，再按图规划任务执行步骤&lt;/strong&gt;，这就是「Graph-then-Plan」（先图后规划）思路，而这张图就是「MomaGraph」。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;这张图到底特殊在哪？举个「开窗户」的例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="14,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,0,0"&gt;统一空间 + 功能&lt;/b&gt;：图里会同时写「把手在窗户右侧」（空间）和「把手能控制窗户开关」（功能）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="14,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,1,0"&gt;动态更新状态&lt;/b&gt;：机器人转了把手后，图会从「把手未旋转 &amp;rarr; 窗户锁着」更新为「把手已旋转 &amp;rarr; 窗户待打开」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="14,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,2,0"&gt;紧扣任务需求&lt;/b&gt;：只保留和「开窗户」相关的信息（比如忽略窗户上的贴纸），不做无用功。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="15"&gt;简单说，传统模型是「看到图片直接猜步骤」，而 MomaGraph 是「先搞清楚『有什么、怎么用、状态如何』，再一步步规划」&amp;mdash;&amp;mdash;就像你做饭前会先看「冰箱有鸡蛋、锅能加热」，再想「打鸡蛋 &amp;rarr; 开火 &amp;rarr; 煎蛋」，而不是直接拿锅就烧。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;三、研究方法：从「数据」到「机器人」的全链条方案&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;要让 MomaGraph 落地，研究团队搭建了「数据集 - 模型 - 基准 - 真实机器人」的完整体系，其中星动纪元轮式人形机器人星动 Q5 成为了「把技术从实验室变实用」的核心硬件。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;b data-index-in-node="0" data-path-to-node="18"&gt;第一步：建「训练素材库」&amp;mdash;&amp;mdash;MomaGraph-Scenes 数据集&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="18"&gt;要教机器人「懂家务」，得先给它看足够多的「家务样本」。团队收集了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="19,0,0"&gt;6278 张多视角家庭照片（比如从正面、侧面拍柜子、微波炉）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="19,1,0"&gt;1050 个「任务场景图」（比如「开微波炉」的图里，标注了「微波炉把手在正面」「把手能开门」）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="19,2,0"&gt;覆盖 350+ 家庭场景、93 种任务（开窗户、烧开水、开电视等）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19,2,0"&gt;这些数据就像机器人的「家务课本」，让它知道不同场景下「物体该怎么用」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFeOWabv3DYFk9Haia8NO6bVjOeicwhLpMf3icUaoYQPUbrqvntjACDaJmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528607" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7b4b794f-3e1f-4009-bdae-19869adae1ec/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;&lt;b data-index-in-node="0" data-path-to-node="20"&gt;第二步：训「聪明大脑」&amp;mdash;&amp;mdash;MomaGraph-R1 模型&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;团队用 70 亿参数的视觉语言模型（VL 模型，基于 Qwen-2.5-VL-7B），通过强化学习训练出 MomaGraph-R1：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,0,0"&gt;训练逻辑：模型生成场景图后，系统会按「三个标准」打分（奖励）：步骤对不对？有没有漏物体？空间/功能关系准不准？比如生成「水壶插电才能加热」就加分，漏了「插电」就扣分；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="21,1,0"&gt;核心能力：能根据任务生成「精简有用」的场景图，比如「找遥控器开电视」时，会重点标注「遥控器在沙发上」「遥控器能控制电视」，忽略沙发颜色这类无关信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFRanGficNIfoGfE0QwqalLWfpfJpzQU48p0qw273iclBCL2Ub356mRA2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5342592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528609" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/38800394-6a9d-4c21-87f5-3749bda24dba/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22"&gt;&lt;b data-index-in-node="0" data-path-to-node="22"&gt;第三步：测「能力高低」&amp;mdash;&amp;mdash;MomaGraph-Bench 基准&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;为了判断机器人「学没学会」，团队设计了 6 种能力测试（比如「步骤对不对」「能不能找对物体」「知不知道操作后会发生什么」），覆盖从简单（开柜子）到复杂（烧开水）4 个难度等级，确保测试结果真实可信。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFAKABI3pJcuUKKiaF96LpcGaNwticF22a7fGwVNnxmYgoKecnVmuoCNyw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.587037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528612" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2c2f805b-3c4a-48a9-92ee-d55f87b9532f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23"&gt;&lt;b data-index-in-node="0" data-path-to-node="23"&gt;关键一步：真实机器人落地&amp;mdash;&amp;mdash;星动纪元 Q5 的硬件优势&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="23"&gt;再好的「大脑」也需要「手脚」来执行，研究团队选择星动纪元星动 Q5 轮式人形机器人做真实场景测试，这款硬件的优势直接帮 MomaGraph 发挥出最佳效果：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFdZibOFjYDBquiah9I42jO62Cp1icEkuyrtcfrVXfVdECrIGMGFyibrKc4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528614" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d75eb094-7ec7-408f-a067-b9b0e6bef843/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,0,0"&gt;双臂 + 移动底座&lt;/b&gt;：能「走」到不同房间（比如从客厅到厨房），还能「动手」精准操作&amp;mdash;&amp;mdash;开柜子时，双臂能稳定抓住把手并拉动；开微波炉时，能控制力度避免损坏；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,1,0"&gt;多视角相机（Intel RealSense D455）&lt;/b&gt;：能拍物体的多个角度（比如从上方看水壶、从侧面看插座），帮模型获取准确的空间信息，避免「认错位置」（比如不会把柜子把手当成开关）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,2,0"&gt;适应家庭场景&lt;/b&gt;：硬件尺寸适合家庭环境（不会撞坏家具），双臂力度可控（不会捏碎杯子），完美匹配「家务任务」的需求。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;比如测试「开柜子」时，星动 Q5 的相机先拍柜子和把手的多视角图，MomaGraph-R1 根据图片生成「把手在柜子正面、能开柜子」的场景图，再规划「靠近柜子 &amp;rarr; 抓把手 &amp;rarr; 拉柜子」的步骤，Q5 的双臂精准执行，成功率远超传统机器人。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;&lt;strong&gt;四、研究结论：机器人「做家务」的能力大幅提升&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;从基准测试到真实机器人实验，MomaGraph 交出了亮眼的成绩，核心结论可以总结为三点：&lt;/p&gt;&lt;p data-path-to-node="28,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,0,0"&gt;「先画图再规划」远胜「直接猜步骤」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,0,0"&gt;在 MomaGraph-Bench 基准测试中，MomaGraph-R1 的准确率达到 71.6%，比目前最好的开源模型（比如 LLaVA-OneVision）高 11.4%；而像 GPT-5 这样的闭源大模型，常会漏关键步骤（比如烧开水没提「插电源」），MomaGraph-R1 却能 100% 覆盖前提步骤&amp;mdash;&amp;mdash;因为它先画了「水壶需要插电」的场景图，再规划步骤。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFqPezApsTukQeG2EKkvibZeNIYFU61QJ7lfACET1bx1N1zMtnZpDa5gw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.36574074074074076" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528616" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7d587a6e-d541-486b-ba56-c3de150a0203/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="28,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,1,0"&gt;「空间 + 功能」一起看，比单独看更准&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,1,0"&gt;实验对比了「只看空间关系」、「只看功能关系」、「两者都看」的效果：MomaGraph-R1（统一版）在复杂任务（Tier 4）的准确率是 68.1%，而「只看功能」的版本只有 59.0%，「只看空间」的版本更低只有 45.4%。这说明：机器人既要知道「东西在哪」，也要知道「东西怎么用」，才能做好家务等任务的执行。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFOasOEIibn2p2CY4ZB5bLAmX7gNOl9IFg7K3qyGu0xBchrKob6JiaQJ1g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.18333333333333332" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528621" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/9152084b-020f-4ac7-ad9f-bf2bebc152a1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="28,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,2,0"&gt;在真实机器人上能落地，还能处理复杂任务&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,2,0"&gt;团队用星动纪元星动 Q5 测试了 4 个常见任务：开柜子、开微波炉、开电视、关灯，全部成功；更难的「长任务」（「开灯 &amp;rarr; 找遥控器 &amp;rarr; 开显示器」），10 次测试成功 7 次&amp;mdash;&amp;mdash;而这个任务需要机器人「先解决照明（状态影响可见性），再找遥控器（空间定位），最后开显示器（功能控制）」，传统机器人根本做不到。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFoDZIUibjTYwy749YZLLlTjFvic2lkFjiacEDdRnhCQCe3lBnRnspIKMicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528622" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/5ce92b65-3aa5-44df-bc87-b64667a49993/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="29"&gt;此外，MomaGraph-R1 在视觉对应任务上也表现突出，在 BLINK 基准和 MomaGraph-Bench 的对应任务中，比最好的开源模型分别高出 3.8% 和 4.8%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFGJGPS9xPrib2U2fzN3cRxce8HQFMtbUibG3ibpc19atXYS5eqKN0h81ZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.2324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528623" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/50952003-4af7-4e4c-ac49-5ebb79a842a6/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="30"&gt;&lt;strong&gt;五、行业意义：家用服务机器人离「进家门」又近了一步&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="31"&gt;MomaGraph 的价值，本质是解决了「机器人理解家庭场景」的核心难题：它让机器人从「只会按固定程序做事」（比如只会重复「推窗户」），变成「能根据场景灵活调整」（比如先看有没有把手，再决定转还是推）。&lt;/p&gt;&lt;p data-path-to-node="32"&gt;而星动纪元星动 Q5 这类执行硬件的参与，更证明了这项技术不仅仅适用于实验室&amp;mdash;&amp;mdash;仿人双臂、移动底座、精准相机的组合，让 MomaGraph 的「聪明大脑」有了可靠的「手脚」。未来，随着技术优化，我们可能会看到：机器人能帮老人烧开水、整理柜子，甚至帮上班族准备早餐&amp;mdash;&amp;mdash;家用服务机器人从「概念」走向「实用」，终于有了清晰的技术路径。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
