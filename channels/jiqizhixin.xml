<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>租了8张H100，他成功复现了DeepSeek的mHC，结果比官方报告更炸裂</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:28:49 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;元旦期间，DeepSeek 发布的 mHC 震撼了整个 AI 社区。&lt;/p&gt;&lt;p&gt;简单来说，DeepSeek 提出的 mHC 通过将传统 Transformer 的单一残差流扩展为多流并行架构，并利用 Sinkhorn-Knopp 算法将连接矩阵约束在双拟随机矩阵流形上，成功解决了超连接（HC）在大规模训练中因破坏恒等映射属性而导致的数值不稳定和信号爆炸问题。更多详情请参阅《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651010187&amp;idx=1&amp;sn=cc9ae88f676873468dcfc98d54e98aa9&amp;scene=21#wechat_redirect" target="_blank"&gt;刚刚，梁文锋署名，DeepSeek 元旦新论文要开启架构新篇章&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;时至今日，这篇让众多读者大呼看不懂的论文依然是技术社区关注的一大焦点。解读分享这篇论文就好像已成为一种技术时尚。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14VNUWI9adiaSqribkZiavwWb6ylMFfyfib9zLbSr4A4f61P8qnXQ23IJGVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.8574317492416582" data-s="300,640" data-type="png" data-w="989" type="block" data-imgfileid="503528930" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/ca024fa7-7692-4ae2-98d6-c4e95d668991/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14P7gbO6qkvHB6GLSKLFoyXgVicLvdV4RUmceGomNTQNQSLibfaQuYR2ug/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.336734693877551" data-s="300,640" data-type="png" data-w="784" type="block" data-imgfileid="503528931" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4c2ab415-8c48-418f-abb5-37ebca1f8d2e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但还有更加硬核的，近日 &lt;strong&gt;FlowMode 工程师 Taylor Kolasinski 宣布成功复现了 mHC，并且在测试中还取得了比 DeepSeek 原始论文更好的成绩&lt;/strong&gt;！&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148fxf77icFbcLA7DxbN7eIfhTicf2sclr7W6J3Yh7EniaP5UmV4PO63Wsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528932" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/85968fa3-a92d-4e79-801d-416710d17537/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;评论区也是直呼「不明觉厉」：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14iaSBv7DkfgMXeTsyEleE0tDmnzvefpZ7lNibLicF16WSbichWHC520Xl7w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528933" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1564350f-b075-4649-a8b6-52572e618ee6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;目前，Kolasinski 正通过一个 mHC 复现系列博客介绍其复现成果，相关博客已经发布了 2 篇。这里我们进行了整理，以飨读者。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Z9dCZ27LYqfS77EtwVlvA79rQR1LuruLB9lUA39EbpHRQ9exEVWibwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6925925925925925" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528934" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ffe49afd-f69a-4c71-a9e5-4126cc73c561/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="2 2 []"&gt;博客 1：https://taylorkolasinski.com/notes/mhc-reproduction/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;博客 2：https://taylorkolasinski.com/notes/mhc-reproduction-part2/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;博客一：DeepSeek 的 mHC：当残差连接发生爆炸&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你使用过的每一个 Transformer 模型都采用了 2016 年以来的同一种残差连接设计。&lt;/p&gt;&lt;p&gt;GPT-5、Claude、Llama、Gemini。在底层，它们做的事情都是一样的：x + F (x)。信息流只有一条，穿过网络，每一层都向其中添加内容。&lt;/p&gt;&lt;p&gt;DeepSeek 提出了一个问题：如果它变得更宽会怎样？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14K67JcIibnb4KQMFVvfVicMYFgKPsFiabVXMTvP6nevicO6D8QWsOjdkUEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6907407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528935" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/98ae53d2-b127-4e77-a937-6a617b056476/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;标准残差连接是每一个现代 Transformer 的脊梁。其思路很简单：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ibNUSZVmyqBt9GqhG5AdZsIC6ZYib5pL7NibhiaMLSNpOCMpKWBvold3hA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.18181818181818182" data-s="300,640" data-type="png" data-w="209" type="block" data-imgfileid="503528936" data-aistatus="1" data-original-style="width:109px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/24211aba-5f77-4311-a12c-c7087688b798/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;其输入原封不动地流过，加上该层的输出。这是一条单一的信息流。进去是什么，出来的就是什么加上一个学习到的更新量。这就是为什么 Transformer 可以深达数百层：梯度有一条干净的向后路径。简单。稳定。自 2016 年以来未曾改变。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;超连接（Hyper-Connections）&lt;/strong&gt;采取了不同的方法。它不再是单一流，而是扩展到 n 条并行流，并带有可学习的混合矩阵：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ib303XUokjGaECqsialpZEV9LWOhRFG0M0uOYUGZUiaysdic3uXibAibGSUA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.10416666666666667" data-s="300,640" data-type="png" data-w="432" type="block" data-imgfileid="503528937" data-aistatus="1" data-original-style="width:198px;height:21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/02170543-56d9-4c80-ba29-6e3c99b14deb/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;下图对比了标准残差与超连接：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14JdzbPqUPZV8m8z7lONBnWBq0aicFXAWxekS3Q8hUvLyX5picxIbUrsYw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.271875" data-s="300,640" data-type="gif" data-w="640" type="block" data-imgfileid="503528939" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/eba1344d-5cac-4d9f-840a-ec9e95cd2031/640.gif" data-order="0" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;三个矩阵控制着信息的流动方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;H_res：信息流在残差路径中如何混合（红色的交叉部分）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;H_pre：信息流在进入层之前如何组合&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;H_post：层的输出如何分配回各个流中&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;超连接表达能力更强。参数更多，但计算开销几乎可以忽略不计。理论上性能更好。亦可参阅报道《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650941988&amp;idx=2&amp;sn=1b35f2af9982c529a1c9217bfab24a02&amp;scene=21#wechat_redirect" target="_blank"&gt;字节豆包大模型团队突破残差连接局限！预训练收敛最快加速 80%&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;但问题是什么？那些混合矩阵是不受约束的。它们不仅能路由信号，还能放大信号。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;爆炸&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在激进的学习率下，作者的复现实验中超连接（HC）的信号放大达到了 7 倍，随后最终崩溃。Amax（行和列绝对值的最大值）衡量了一个矩阵能将信号放大多少。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14KTGPYOxRc0mIq9po5SS1CabBE40e9zLeqsBbz2rIquTVwKzLutn2RQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.33700137551581844" data-s="300,640" data-type="png" data-w="727" type="block" data-imgfileid="503528940" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/5dff3de9-32d7-413b-84c0-6af93530b5ab/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 10M 参数的规模下，这也还行。但 DeepSeek 在 27B 参数下观察到了这种情况：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;「Amax 增益幅度产生了极值，峰值达到 3000」&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;你没有看错：&lt;strong&gt;三千倍&lt;/strong&gt;的放大。在 27B 参数下，不受约束的 HC 不仅仅是漂移，而是爆炸了。这里的 10M 复现中达到的 9.2 倍正是这种指数级故障的早期预警。&lt;/p&gt;&lt;p&gt;也因此，不受约束的混合矩阵在规模化时会崩溃。微小的放大呈指数级复合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14VWxBdN7nxiamNJd85YftJuh72KeQagAibiafxXkCHyGYJe67W4BybGV7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.43333333333333335" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528941" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d2363632-ac09-4089-9477-3b6d7a5e46ff/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;压力测试： 在激进的学习率下，HC 的信号放大在崩溃前达到了 7 倍。mHC 保持平稳，维持在 1.0。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;修复：约束流形&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek 的修复方案很干净：将混合矩阵约束为&lt;strong&gt;双重随机（doubly stochastic）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;一个双重随机矩阵具有以下特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;所有条目非负&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;行之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;列之和为 1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14GH15XHpicXwdEuRIu1Ft45cvA5z2HKhL5xqwibgzKu4ZaGTL2Qu0jwIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5158227848101266" data-s="300,640" data-type="png" data-w="632" type="block" data-imgfileid="503528942" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/8e58bf9b-32b7-4221-9277-1e6c83461eb4/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这意味着混合操作只能对流进行加权平均。它可以路由信息，混洗它，融合它。但它不能放大。&lt;/p&gt;&lt;p&gt;DeepSeek 是如何做到塞？使用 Sinkhorn-Knopp 算法。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD143D4km7Z9CoWuwYU5rm6pTOia8oYH6HtQichr5EEbnlKN8JpNTZO74uMw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.9578163771712159" data-s="300,640" data-type="gif" data-w="403" type="block" data-imgfileid="503528943" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/2ec37ecc-006a-45a6-b4e8-9dd0c98efac3/640.gif" data-order="1" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该算法非常简单：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;从任意矩阵（原始学习到的权重）开始&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;取指数使所有条目变为正数：P = e^H&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归一化行，使每一行之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归一化列，使每一列之和为 1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重复 3-4 个步骤，直到收敛&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;就是这样。交替进行行和列的归一化。二十次迭代就足够了。&lt;/p&gt;&lt;p&gt;这个过程是可微分的。梯度可以回传穿过所有二十次迭代。网络学习原始权重 H，而 Sinkhorn 确保实际的混合矩阵始终是双重随机的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14rDcYB40OThxGxcascU0icJHCmTEZicdibrN77EKVoNLbRaPrYmzWejsww/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.12735849056603774" data-s="300,640" data-type="png" data-w="424" type="block" data-imgfileid="503528944" data-aistatus="1" data-original-style="width:210px;height:27px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/d0b60218-ea2f-46a2-bda4-8e081295ee6d/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;当作者第一次看到这个时，感觉像是作弊。你不是在学习稳定性，而是在强制它。但有些属性不应该被学习；它们应该被保证。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;技术说明：严格来说，只有递归矩阵 H_res 需要完整的 Sinkhorn 双重随机处理。它是层层复合误差的那个。输入 / 输出混合器（H_pre，H_post）仅通过 sigmoid 进行有界处理。Sinkhorn 的计算成本只花在最重要的地方。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD146neDNSz6smMWS4LF7bEm1h6Rym6naUn0JzrYIXrIj806DicaSWcfPBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.90744920993228" data-s="300,640" data-type="png" data-w="886" type="block" data-imgfileid="503528945" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/c814eeb5-3376-4ae3-90e3-691de546813c/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不同种子的结果（深度 24，3 个种子）&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14D8MTeOXCHfLaIK0w51V9a5c1nNo4G5vxML4x8A3zOwRbPH704R7nDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.24083769633507854" data-s="300,640" data-type="png" data-w="764" type="block" data-imgfileid="503528946" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/d64f4e03-95c7-4604-8ad7-4abc860b3681/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;HC 在原始性能上获胜：验证损失 0.88 对 1.12。在 10M 参数下，mHC 约束就像是一种稳定性税；你付出的是表达能力。但在 27B 参数下，这种税是防止你的模型爆炸成 NaN 的唯一手段。&lt;/p&gt;&lt;p&gt;但看看方差。HC 的损失在不同种子间的变化是 mHC 的 3 倍（&amp;plusmn;0.033 vs &amp;plusmn;0.012）。至于 Amax？HC 根据种子的不同在 6.1 到 7.6 之间摆动。mHC 是 1.00。每一个种子。每一次运行。零方差。&lt;/p&gt;&lt;p&gt;在 10M 参数下，这种不稳定性是可以存活的。HC 仍然获胜。但在 27B 参数下，那 6-7 倍的放大变成了 3000 倍。在这个规模下你无法赌博。&lt;/p&gt;&lt;p&gt;深度扩展&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14cKz5YI6AVeNYDOBMWaRs93eI1L9jHBrvyFWhLuuQNjKJvAMPo2bhXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.9187643020594966" data-s="300,640" data-type="png" data-w="874" type="block" data-imgfileid="503528947" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/73a9fe86-a9c5-40fc-b6a3-ac3eec3690fb/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作者还扫描了从 6 到 24 层的深度（保持约 11M 的常数参数预算）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;损失随着深度增加而改善，直到不再改善。深度 20 达到了甜蜜点（0.85 验证损失）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;深度 24 略有退步（0.93），这是由于为了将维度缩小到 192 而产生的宽度瓶颈。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Amax 是不可预测的。深度 20 飙升至 9.2 倍。深度 12 达到 6.6 倍。深度 8 保持在 4.3 倍。没有清晰的关系；HC 是混沌的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验细节&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;数据集： TinyShakespeare（约 1M 字符，字符级）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型： GPT-2 架构，约 10M 参数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练： 5000 步，AdamW (&amp;beta;1=0.9, &amp;beta;2=0.95)，权重衰减 0.1，余弦 LR 衰减&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;硬件： Apple M 系列 (MPS)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;深度扫描： 8 种配置（6-24 层），调整宽度以维持约 11M 参数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;种子变异： 3 个种子（42, 123, 456），深度 24&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;为什么这很重要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;残差连接不仅仅是帮助梯度流动的技巧。它们是一种守恒定律。&lt;/p&gt;&lt;p&gt;在物理学中，守恒定律约束了可能发生的事情，但使预测成为可能。你不能制造永动机，但你可以精确计算球会落在哪里。&lt;/p&gt;&lt;p&gt;残差连接中的恒等映射是类似的。它通过防止任意变换来约束网络，但它保证了稳定性。信号幅度被保留。&lt;/p&gt;&lt;p&gt;HC 打破了守恒；mHC 恢复了它，不是通过回归到恒等映射，而是通过找到一个更丰富的、仍然守恒信号的流形。&lt;/p&gt;&lt;p&gt;2016 年，何恺明等人引入 ResNets 来解决梯度消失问题，确保信号不会消亡。十年后，相反的问题出现了：超连接带来的信号爆炸。恒等映射通过被动的方式解决了第一个问题。mHC 通过强制守恒解决了第二个问题。&lt;/p&gt;&lt;p&gt;每一个残差连接都是一种守恒定律。mHC 强制执行了它。&lt;/p&gt;&lt;p&gt;不是黑客手段，不是技巧。这是一个原则性的约束，使架构能在规模化下工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;流持久性 Bug 让人学会谦卑。&lt;/strong&gt;作者的第一个实现看起来是对的。公式与论文相符。代码能跑。但当把输出投影回单一流并在每一层重新扩展它，扼杀了并行架构。「超连接」中的「超」部分实际上没做任何事。三次独立的审计都说「看起来是对的」。Bug 是架构上的，不是数学上的。作者是在问了「等等，层与层之间流动的实际形状是什么？」之后才发现的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;约束不是限制；它们是保证。&lt;/strong&gt;双重随机投影强制了稳定性。你不是在学习好的行为。你是在让坏的行为变得不可能。作者表示自己的第一反应是：「这不优雅。这是束缚。」但其实，HC 达到了 7 倍放大才是重点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无聊的选择能规模化。&lt;/strong&gt;标准残差连接自 2016 年以来一直存活，不是因为它们是最优的，而是因为它们是稳定的。HC 表达能力更强但脆弱。mHC 找到了一个中间地带：比标准残差表达能力更强，且带有稳定性保证。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;博客 2：10,924 倍：17 亿规模下的不稳定炸弹&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下面是 mHC 复现系列的第 2 部分。第 1 部分 展示了 10M 参数量下的不稳定性。现在，要扩大规模了。&lt;/p&gt;&lt;p&gt;在第 1 部分中，作者在 TinyShakespeare 数据集上训练了一个 10M 参数的 Transformer，并目睹了超连接（Hyper-Connections）将信号放大了 9.2 倍。DeepSeek 的论文 报告称在 27B 参数下放大倍数达到了 3000 倍。现在我们也扩大规模看看。&lt;/p&gt;&lt;p&gt;为了这次运行，作者租用了一个 8x H100 的节点。以下是他的发现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规模跃迁&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qRxwTSib2fNm2k7ExD0gK2mnlH1ibeCqFKgAV7bEIcicyeHvdrcqQhPEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.36363636363636365" data-s="300,640" data-type="png" data-w="869" type="block" data-imgfileid="503528948" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/aa27acf1-40f2-4709-845a-d6ccb323100a/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;10924 倍信号放大！这远远超出了 DeepSeek 论文中的 3000 倍。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇博客记录的是作者在三种架构上进行的 18 次实验，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Residual：标准的残差结构，即 x + F (x) 作为基线；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HC：采用无约束混合矩阵的超连接（Hyper-Connections）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;mHC：采用 Sinkhorn 投影的流形超连接（Manifold Hyper-Connections）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每种架构分别在两种网络深度下进行（32 层和 48 层），并使用三个随机种子（42、123、456），因此每种配置运行 3 次。&lt;/p&gt;&lt;p&gt;所有模型均在 C4 数据集上训练 5000 步，采用 bf16 混合精度。其中 32 层模型参数量为 17.3 亿（1.73B）；48 层模型参数量为 25.4 亿（2.54B）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主要结果&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14qIudVn1dePL4W3zdUcrJI3JgJhqvEhYg8TFayEBHuMMlcDNicmR3JrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.712037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528949" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/92099748-1230-44ee-aca3-2634116ebb1e/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;首先，在 Loss 表现上：所有方法的收敛表现几乎一致。&lt;/p&gt;&lt;p&gt;三种方法最终都收敛到相近的 loss 区间（约 5.4&amp;ndash;6.0）。整体学习曲线几乎完全重合：HC 并没有学得更快，mHC 也没有变慢。从实验结果来看，引入 Sinkhorn 投影几乎没有额外代价。&lt;/p&gt;&lt;p&gt;其次，Amax 表现出强烈的不稳定性。Amax 是用来衡量混合矩阵对信号的放大程度，Amax = 1.0 表示对信号不放大（中性）；数值越高，表示信号被放大的程度越强。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD143CBnzK5jffKKxibNCgb5LicONnqYD8HaJwHQctPtFg4ibzxfLDEu0oDCw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=20" data-ratio="0.6284722222222222" data-s="300,640" data-type="gif" data-w="576" type="block" data-imgfileid="503528950" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/cac33753-49d5-445c-ae04-fa165554b3f6/640.gif" data-order="2" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验中发现，在深度为 32 时，HC 的 Amax 值飙升至 6500 倍，并伴随着剧烈的波动，而 mHC 值则稳定保持在 1.0。在深度为 48 时，这种模式再次出现：HC 猛增至 3500 倍，而 mHC 值保持不变。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14D4micrXBUEpxjwyjQtjLF8kSJY6wicwExtROYCPmRWTOYiaPVicnhvCQ4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528951" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/03f3c9d8-777a-4ead-a9d7-3aa4e83afe88/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Scaling Laws&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14PrayHRzwlbibf1yNI8eHOSMILT1dwCslXWAKfTkiagiblibId1qSHT2J8g/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528952" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/bc2965d9-9dd6-425c-9fd4-1730a20e6118/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在对 Amax 与模型参数规模进行 log&amp;ndash;log 绘制后，可以观察到明显的放大趋势：当模型规模为 1000 万参数时，Amax 约为 9.2 倍；在 17 亿参数规模下，这一数值跃升至 10924 倍；&lt;/p&gt;&lt;p&gt;而公开数据中，DeepSeek 的 270 亿参数模型对应的 Amax 约为 3000 倍。基于趋势线外推，模型规模达到 100 亿参数时，Amax 可能上升至约 50000 倍，在 1000 亿参数量级下，甚至可能接近 400000 倍。&lt;/p&gt;&lt;p&gt;实验结果并未显示出任何自我修正的迹象，相反，随着模型规模扩大，不稳定性呈现出持续加剧的趋势。值得注意的是，该实验中的 17 亿参数模型所表现出的不稳定性，甚至高于参数规模更大的 DeepSeek 模型。&lt;/p&gt;&lt;p&gt;这种差异可能源于架构设计、训练配方或测量方法的不同；批大小、学习率与网络深度之间的相互作用，也使得尺度效应并非严格单调。&lt;/p&gt;&lt;p&gt;尽管具体数值会受到多种因素影响，但这种不稳定性是客观存在的、可以被量化的，而且规模不容忽视。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可复现性&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14Ft0XWaVGSUqCUxpHs8KiaNSQutq3lCBKkA0TAaGQ07bCQdAKcNjjUZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.662962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528954" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/56023cce-775a-471c-817c-796e54dcecbb/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，在三个不同的随机种子下，实验都呈现出完全相同的模式：所有 HC 的训练过程都会发生爆炸，而所有 mHC 的训练过程始终保持平稳。不同随机种子下的 loss 曲线几乎完全重合，两种方法的学习速度也一致。&lt;/p&gt;&lt;p&gt;唯一的差别在于模型内部正在发生的事情：HC 在不断积累不稳定性，这种不稳定性可能在任何时刻被引爆；而 mHC 则始终维持着自身的结构完整性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;逐层分析：不稳定性从哪里开始的&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD144OV30ySHmJNngohQHv5WMXgbTdjS4gVqdSOicAekOx87bzjHYqHZDFA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=24" data-ratio="0.8131487889273357" data-s="300,640" data-type="gif" data-w="578" type="block" data-imgfileid="503528955" data-aistatus="1" data-original-style="null" data-index="26" src="https://image.jiqizhixin.com/uploads/editor/e521e269-94bd-4432-8058-8e09cfb7d8e0/640.gif" data-order="3" alt="图片" data-report-img-idx="24" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这里有一个令人惊讶的发现：&lt;strong&gt;不稳定性始于输入端，而非输出端&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;HC 的第 0 层（可视化图表中的顶行）率先变红，随后其混合矩阵在训练初期就突破了 Amax 2.0，而更深层的网络则保持相对稳定。看起来问题不在于深度，而在于第 0 层 &amp;mdash;&amp;mdash; 这是唯一一层直接吞吐原始输入的层。&lt;/p&gt;&lt;p&gt;为什么是第 0 层？ 不同于深层网络前面有 LayerNorm 把关，第一个混合矩阵直接面对原始 Embeddings。其他每一层看到的都是经过归一化、变换后的表征，但第 0 层必须硬抗 Embedding 表吐出的任何数值。如果尺度（scale）没有完美匹配，第 0 层就会学习去补偿。&lt;/p&gt;&lt;p&gt;而在 HC 中，「补偿」可能就意味着「放大」。反观 mHC，在所有层级和所有训练步数中都呈现均匀的绿色。Sinkhorn 投影在限制最大值的同时，也完全防止了任何层发生漂移。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信号流：视觉展示&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD148HrkPEicLkbMKY9a7yJk04NncECBn5s3SOwX0zx4H40DvwtYVmicv0tQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=25" data-ratio="0.41297935103244837" data-s="300,640" data-type="gif" data-w="678" type="block" data-imgfileid="503528956" data-aistatus="1" data-original-style="null" data-index="27" src="https://image.jiqizhixin.com/uploads/editor/568b2609-5914-4f36-8ee7-3e7dc0cb25ba/640.gif" data-order="4" alt="图片" data-report-img-idx="25" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在第 3000 步时，一个进入 HC 网络的信号在输出时被放大了 532 倍。而同样的信号经过 mHC 输出时倍率为 1.000003 倍，本质上保持不变。&lt;/p&gt;&lt;p&gt;LayerNorm 和非线性模块似乎「收拾」了大部分烂摊子，但这意味著它们消耗了模型容量，仅仅是为了去抵消上游制造的混乱。&lt;/p&gt;&lt;p&gt;这正是守恒定律的体现，它表明残差连接应当保持信号的幅度：输入了什么，就应当输出什么（再加上学习到的残差）。&lt;/p&gt;&lt;p&gt;HC 打破了这一规则，任由信号失控螺旋上升，而 mHC 则守住了底线。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;压力测试&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14gSaOIAWmiaMM9kuSlNMDvsqRcup1KHcxVicjP8NLXjuyKJZQvNrJgqiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=26" data-ratio="0.3509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528958" data-aistatus="1" data-original-style="null" data-index="28" src="https://image.jiqizhixin.com/uploads/editor/87cf0514-a690-4404-ad93-b24701dd4154/640.png" alt="图片" data-report-img-idx="26" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;正常的训练使用了 1e-4 的学习率。如果加大强度会发生什么？作者在 3 倍于正常学习率的条件下进行了压力测试：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14SVdwpjjUCsYuMK9fvtu3RoWcfzBYKp1pWE8CrvhDA1ygzK3ibYg3wuw/640?wx_fmt=png&amp;from=appmsg#imgIndex=27" data-ratio="0.3731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528959" data-aistatus="1" data-original-style="null" data-index="29" src="https://image.jiqizhixin.com/uploads/editor/249935b6-0373-4cbd-a740-a053d055c11f/640.png" alt="图片" data-report-img-idx="27" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;深度 64 的模型在 Amax 达到 14765 倍后，开始在 2000 倍到 10000 倍之间剧烈振荡，同时，混合矩阵彻底失控。&lt;/p&gt;&lt;p&gt;反观 mHC，在所有配置、所有学习率下都表现得平坦、稳定且「无聊」，数值始终保持在 1.0。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;意料之外：HC 模型并未崩溃&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14gPM78lqLq2pMicicvSaG3vZemP982XL1koRM3AxpdVNuVE9Ew4U0QNSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=28" data-ratio="0.4324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528960" data-aistatus="1" data-original-style="null" data-index="30" src="https://image.jiqizhixin.com/uploads/editor/e401403d-fce4-471a-b9ee-4981ff560077/640.png" alt="图片" data-report-img-idx="28" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;有一个作者没想到的结果：所有的 HC（Hyper-Connections）运行实验都没有崩溃。&lt;/p&gt;&lt;p&gt;信号放大了 14765 倍，在深度 32 时放大了 10924 倍。Loss（损失）没有发散，训练也没有出现 NaN。模型仍在继续学习。&lt;/p&gt;&lt;p&gt;这是一种「定时炸弹」般的场景。不稳定性确实存在，但尚未导致灾难性的失败&amp;hellip;&amp;hellip; 至少目前还没有。&lt;/p&gt;&lt;p&gt;为什么没炸？作者列举了以下几种可能性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;梯度裁剪力挽狂澜。&lt;/strong&gt;将范数裁剪在 1.0 防止了最严重的梯度爆炸，这几乎肯定就是拯救了这次运行的关键。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;5000 步还不够。&lt;/strong&gt;如果训练时间再长一点，它可能就会爆发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;这些模型还太小。&lt;/strong&gt;在 100B（千亿）参数规模下，动力学特性可能会有所不同。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;稳妥的解读是：&lt;strong&gt;HC 正在积聚不稳定性，在不同条件下可能会被引爆，而 mHC则完全消除了这种风险&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;重访守恒定律&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在第 1 部分中，作者将残差连接定义为了一种守恒定律，即「每一个残差连接都是一条守恒定律，mHC 强制执行了它。」&lt;/p&gt;&lt;p&gt;1.7B 参数规模的结果让这一点变得具体：HC 违反了守恒，信号在训练过程中增长了 10000 多倍。而 mHC 强制守恒，信号保持稳定。具体地，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 10M（一千万）参数时，违反守恒是可以存活的。作者在第 1 部分中看到的 9.2 倍放大虽然烦人，但尚在可控范围内。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 1.7B（十七亿）参数时，这就是个炸弹。10924 倍的放大意味着一个本该是量级 1 的信号，现在变成了 10924。梯度更新在与这种放大对抗，而优化器必须做额外的工作来补偿网络内部的混乱。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这还仅仅是在 5000 步的时候，如果训练更久、推高学习率、或者扩展到 10B 参数，在某个临界点，炸弹就会引爆。&lt;/p&gt;&lt;p&gt;mHC 不仅仅是降低了不稳定性，而是彻底消除了这种故障模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从这次运行中学到了什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一是，GPU 3 挂了。8 张 H100 中的一张在特定实验中不断报错 CUDA 错误。作者浪费了一个小时调试「代码问题」，才意识到是硬件故障。云端 GPU 是会坏的。&lt;/p&gt;&lt;p&gt;二是，Batch size（批次大小）的限制是真实的。2.5B 参数的 d48 模型无法在 batch size 为 8 时塞进显存。作者不得不降到 batch size 4。这意味着不同深度下的「每步 token 数」不同。&lt;/p&gt;&lt;p&gt;虽然同一深度下 HC 与 mHC 的对比依然有效（batch size 相同），但跨深度的对比就不那么完美了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果正在实现超连接：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用 Sinkhorn 投影。这里大概只有 10 行代码，却消除了一种在大规模下感觉真正危险的故障模式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在训练期间监控 Amax。如果你看到它爬升超过 10 倍，则是在积聚不稳定性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第 0 层是「金丝雀」（预警指标）。特别密切关注你的输入混合矩阵。如果你的基础模型有一个不稳定的第 0 层，微调期间的词表变更或 Embedding 漂移可能会导致网络不稳定。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该约束没有性能代价。mHC 的 Loss 与 HC 完全一致。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;代码和数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数据是公开的，代码即将发布。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;主要实验: wandb.ai/taylorkolasinski/mhc-part2&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;压力测试: wandb.ai/taylorkolasinski/mhc-part2-stress&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者表示，包含训练脚本的仓库即将推出。W&amp;amp;B 仪表板拥有每次运行的完整配置、指标和系统日志。实验在一个 Lambda Labs 的 8x H100 SXM5 节点上运行，耗时约 17 小时。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一步计划&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前有两个悬而未决的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;HC 真的会失败吗？ 作者看到了 10924 倍的放大，但训练没有发散。这是一种潜在风险，还是说训练时间更长就会导致失败？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Scaling Law 是什么？ 10M &amp;rarr; 9.2 倍。1.7B &amp;rarr; 10924 倍。到了 10B 会发生什么？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作者想探索 Scaling Law 到 10B 参数，趋势线表明那里可能出现 50000 倍的放大。那个实验技术上已经准备好了，但需要计算预算的大幅提升。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>评审用不用AI，作者说了算？ICML 2026全新评审政策出炉</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:13:11 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;开始前，温馨提醒一下各位投稿 ICML 2026 的小伙伴们，投稿已于 1 月 8 日开放，也请大家注意投稿截止时间：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;摘要提交截止日期：2026 年 1 月 23 日。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;全文提交截止日期：2026 年 1 月 28 日。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;两个月前，ICML 2026发布了征稿新规，我们也&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651000328&amp;idx=2&amp;sn=7be350e14dc2b6b044763ad91f745a4a&amp;scene=21#wechat_redirect" target="_blank"&gt;详细做了报道&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;当时，为了应对大量的，超负荷的预期论文投稿量，以及其他顶会超负荷运行的前车之鉴，ICML 提出了互审数量限制和人工智能使用规定。&lt;/p&gt;&lt;p&gt;征稿要求中提到：评审过程中&lt;strong&gt;可能会使用 AI 工具辅助，但不会允许完全由 AI 执行评审&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;已经投稿了论文的小伙伴或许已经发现了，这次 ICML 似乎有了一些新变化，并且是在征稿要求中没有详细说明的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14ucegjrN0AxZIeMX3T1mPs5sAd8t7icFiagK0XhSzCzGwwBoDsTVN4sxw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5453703703703704" data-type="png" data-w="1080" data-width="1482" data-height="808" data-imgfileid="503528857" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/254144b5-2641-4b13-a22b-892c22aa7251/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;我们简单概括一下，ICML 2026 引入了评审类型选择机制，&lt;strong&gt;论文作者可以决定&lt;/strong&gt;在其论文评审过程中是否允许使用大语言模型。&lt;/p&gt;&lt;p&gt;具体包括两种政策：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;政策 A 是保守型&lt;/strong&gt;，简单直白好理解：&lt;strong&gt;严格禁止&lt;/strong&gt;在论文评审过程中使用任何大语言模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;政策 B 是宽松型，允许使用&lt;/strong&gt;大模型评审，但会议对使用大模型评审的方式做出了限制：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;允许的行为：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用大语言模型辅助理解论文内容及相关工作；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用大语言模型对评审意见进行语言润色；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;可将投稿论文提交给符合隐私合规要求的大语言模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;不允许的行为：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;向大语言模型询问论文的优点或缺点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型总结或建议评审应关注的关键点；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型提供评审意见的结构或提纲；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求大语言模型撰写完整的评审意见。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;隐私合规大语言模型，是指&lt;strong&gt;不会使用日志数据进行训练、且对数据保留期限作出限制&lt;/strong&gt;的模型工具。&lt;/p&gt;&lt;p&gt;这个小变化是比较新颖的。&lt;/p&gt;&lt;p&gt;过去，评审是否使用大模型，更多取决于评审人，或者处在一种默认被接受的灰色状态。这一次，ICML 明确把选择权交给了作者本身。在论文投稿量持续攀升、评审负担越来越重的现实下，ICML 既没有彻底禁止 AI，也没有完全放开 AI 评审，却给出了一个相对折中的方案。&lt;/p&gt;&lt;p&gt;问题在于，关于大模型使用的规定，执行起来一般都很困难。&lt;/p&gt;&lt;p&gt;就像&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651002013&amp;idx=1&amp;sn=c4588ce6e29f6464cda6e84dfded6af5&amp;scene=21#wechat_redirect" target="_blank"&gt;我们之前报道的&lt;/a&gt;，第三方机构对 ICLR 2026 的审稿意见进行系统性统计，其中就发现了大量 AI 审稿的现象。&lt;/p&gt;&lt;p&gt;在对 75800 篇论文的审稿意见统计中，竟然&lt;strong&gt;有 21% 完全由 AI 生成、4% 重度由 AI 编辑、9% 中度由 AI 编辑、22% 轻度由 AI 编辑，完全由人类（审稿人）撰写的仅占 43%&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14logWUV2YVJemybGdKOicgfps3icWfrfZQGibpFHkiaiaYsYgziagz9qvTTWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.32222222222222224" data-type="png" data-w="1080" data-width="1080" data-height="348" data-imgfileid="503528856" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4bb631eb-7238-43ce-86a2-c29d7c00af30/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;网友们也表达了类似的意见。&lt;/span&gt;AI 审稿已经达到了泛滥的程度，这也并不是 ICML 2026 这次的政策 B 能够完全限制的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14LF88DuOD6fVGxZCpxUVKiavQuaScTv2Seswonic0gNQAfzIaz7icJ7KWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.18796296296296297" data-type="png" data-w="1080" data-width="1450" data-height="272" data-imgfileid="503528858" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f9d22172-c902-42e7-8509-5deb8fb72a61/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;虽然说 ICML 明确规定了使用大模型审稿中不允许存在的行为，但谁又能保证审稿人一定遵从了这些限制呢？我们猜测，用大模型审稿的时候，提问大模型的第一句话就很可能是「给出这篇论文的优缺点」，但这明显是违反规定的。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14YK49xxnNkW4vDEZEDHvuVDajoO45DIMWlrbdric1MNiaARR7CCRDzzBg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1685185185185185" data-type="png" data-w="1080" data-width="1404" data-height="236" data-imgfileid="503528854" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/183ee06d-5c84-421d-bb9b-e800821af73a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;因此，这套规则或许更像是一种明确态度和方向的约定，而不是一套可以严格执行的机制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9WT9AH5D1x90Ezw7sMeD14zqG7XA1nMvLVZHian7WcQY4VOcDPQa28mgHSj6b5u3KfsYEOxeW7WBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2796296296296296" data-type="png" data-w="1080" data-width="1430" data-height="400" data-imgfileid="503528855" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/db7a43ce-c6bb-4965-b926-13e6d0a97f63/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;不过，在大家如此担心大模型引发各种信任危机的情况下，ICML 还可以让作者选择拒绝大模型审稿。&lt;/p&gt;&lt;p&gt;有个「一刀切」的选项交到论文作者手中，也是当下一个不错的选择，不是吗？&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>机器人终于「懂」家务了！伯克利MomaGraph让机器人像人一样做家务</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 17:02:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/03280580-d5bd-4fa7-bee4-757837eadd1f/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;想象这样一个日常画面：你吩咐家用机器人「烧壶开水」，它却当场卡壳&amp;mdash;&amp;mdash;水壶在哪？该接自来水还是过滤水？先插电还是先按开关？水开了又该如何判断？这些对人类而言像呼吸一样自然的家务，对过去的机器人却是大大的难题：要么忘了插电，要么找不到水壶，甚至会把柜门把手错当成开关一通乱按。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;最近，加州伯克利和马里兰大学联手推出的 &lt;strong&gt;MomaGraph 技术&lt;/strong&gt;，就是要让机器人彻底告别这种「做家务的人工智障」时刻。这套算法不仅能让机器人真正理解「做事的先后顺序」，更在星动纪元星动 Q5 上成功完成了开柜子、开微波炉、开电视、关灯等真实家务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFJH7iavGYicQG6ed7A7QR9c2HU2V7309dMkGQDjbOvguicH6FAKibQ5EcnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5722222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528573" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/daa3e230-b3ed-44a5-9547-2828f793c081/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;a href="https://mp.weixin.qq.com/s/H8aS7_QVhS0Who_tJee69Q"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/8a03ed7d-0f3e-48c8-adab-7235162ba11b/1768812923781.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gWibFFuSlngZ6TUI2YBIRPjCRiaakUoUJj2dH6brT0QRZus4psqZYOD4vMJ21RTVh2zodjIssA97aTGg%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4347229785035112470" data-ratio="1.7777777777777777" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4347229785035112470" data-vh="371.8125" data-vidtype="2" data-vw="661" data-w="1920" height="384" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4347229785035112470"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;论文名称：MOMAGRAPH: STATE-AWARE UNIFIED SCENE GRAPHS WITH VISION&amp;ndash;LANGUAGE MODEL FOR EMBODIED TASK PLANNING&lt;/li&gt;&lt;li&gt;论文地址：https://arxiv.org/pdf/2512.16909&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="8"&gt;&lt;strong&gt;一、研究背景：家用机器人做不好家务的「三大卡点」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;家用移动操作机器人（比如帮你开窗户、热牛奶的机器人）需要同时「看路」（导航）和「动手」（操作），但过去的技术一直存在三个关键问题卡点，导致机器人「做不好家务」：&lt;/p&gt;&lt;p data-path-to-node="10,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,0,0"&gt;卡点 1：只知「在哪」，不知「咋用」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,0,0"&gt;比如机器人要开窗户，传统技术可能只知道「窗户在书桌右边」（空间关系），但不知道「窗户把手能控制开关」（功能关系）&amp;mdash;&amp;mdash;就像你知道手机在口袋里，却不知道按电源键能开机，自然用不了手机。&lt;/p&gt;&lt;p data-path-to-node="10,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,1,0"&gt;卡点 2：只认「图片」，不认「变化」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,1,0"&gt;传统模型会把场景当成静态图片，比如机器人转了窗户把手后，模型还以为「窗户没动」，不知道状态已经从「锁着」变成「待打开」；就像你关了灯，却还以为灯是亮的，后续行动规划肯定会出错。&lt;/p&gt;&lt;p data-path-to-node="10,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="10,2,0"&gt;卡点 3：只想「步骤」，不想「前提」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="10,2,0"&gt;过去的 AI（比如 GPT-5）会直接从图片里「想步骤」，比如让它「烧开水」，可能会说「装水 &amp;rarr; 加热」，却漏掉「插电源」这个关键前提；而人做这件事时，一定会先确认「水壶能通电」，再规划步骤。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFzmGzDCKZogFb1WibUPVEXs37KVQAuJg7uAd4zHUR0icoYzhrmazSnx0w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.49537037037037035" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528606" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9db73485-6f5f-4127-85f3-ca7146bba6cb/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="11"&gt;&lt;strong&gt;二、突破思路：给机器人画一张「任务说明书」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;研究团队的核心想法很简单：&lt;strong&gt;让机器人先画一张「任务导向的场景图」，再按图规划任务执行步骤&lt;/strong&gt;，这就是「Graph-then-Plan」（先图后规划）思路，而这张图就是「MomaGraph」。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;这张图到底特殊在哪？举个「开窗户」的例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="14,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,0,0"&gt;统一空间 + 功能&lt;/b&gt;：图里会同时写「把手在窗户右侧」（空间）和「把手能控制窗户开关」（功能）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="14,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,1,0"&gt;动态更新状态&lt;/b&gt;：机器人转了把手后，图会从「把手未旋转 &amp;rarr; 窗户锁着」更新为「把手已旋转 &amp;rarr; 窗户待打开」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="14,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="14,2,0"&gt;紧扣任务需求&lt;/b&gt;：只保留和「开窗户」相关的信息（比如忽略窗户上的贴纸），不做无用功。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="15"&gt;简单说，传统模型是「看到图片直接猜步骤」，而 MomaGraph 是「先搞清楚『有什么、怎么用、状态如何』，再一步步规划」&amp;mdash;&amp;mdash;就像你做饭前会先看「冰箱有鸡蛋、锅能加热」，再想「打鸡蛋 &amp;rarr; 开火 &amp;rarr; 煎蛋」，而不是直接拿锅就烧。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;三、研究方法：从「数据」到「机器人」的全链条方案&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;要让 MomaGraph 落地，研究团队搭建了「数据集 - 模型 - 基准 - 真实机器人」的完整体系，其中星动纪元轮式人形机器人星动 Q5 成为了「把技术从实验室变实用」的核心硬件。&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;b data-index-in-node="0" data-path-to-node="18"&gt;第一步：建「训练素材库」&amp;mdash;&amp;mdash;MomaGraph-Scenes 数据集&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="18"&gt;要教机器人「懂家务」，得先给它看足够多的「家务样本」。团队收集了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="19,0,0"&gt;6278 张多视角家庭照片（比如从正面、侧面拍柜子、微波炉）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="19,1,0"&gt;1050 个「任务场景图」（比如「开微波炉」的图里，标注了「微波炉把手在正面」「把手能开门」）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="19,2,0"&gt;覆盖 350+ 家庭场景、93 种任务（开窗户、烧开水、开电视等）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19,2,0"&gt;这些数据就像机器人的「家务课本」，让它知道不同场景下「物体该怎么用」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFeOWabv3DYFk9Haia8NO6bVjOeicwhLpMf3icUaoYQPUbrqvntjACDaJmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528607" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7b4b794f-3e1f-4009-bdae-19869adae1ec/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;&lt;b data-index-in-node="0" data-path-to-node="20"&gt;第二步：训「聪明大脑」&amp;mdash;&amp;mdash;MomaGraph-R1 模型&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="20"&gt;团队用 70 亿参数的视觉语言模型（VL 模型，基于 Qwen-2.5-VL-7B），通过强化学习训练出 MomaGraph-R1：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,0,0"&gt;训练逻辑：模型生成场景图后，系统会按「三个标准」打分（奖励）：步骤对不对？有没有漏物体？空间/功能关系准不准？比如生成「水壶插电才能加热」就加分，漏了「插电」就扣分；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="21,1,0"&gt;核心能力：能根据任务生成「精简有用」的场景图，比如「找遥控器开电视」时，会重点标注「遥控器在沙发上」「遥控器能控制电视」，忽略沙发颜色这类无关信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFRanGficNIfoGfE0QwqalLWfpfJpzQU48p0qw273iclBCL2Ub356mRA2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5342592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528609" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/38800394-6a9d-4c21-87f5-3749bda24dba/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="22"&gt;&lt;b data-index-in-node="0" data-path-to-node="22"&gt;第三步：测「能力高低」&amp;mdash;&amp;mdash;MomaGraph-Bench 基准&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;为了判断机器人「学没学会」，团队设计了 6 种能力测试（比如「步骤对不对」「能不能找对物体」「知不知道操作后会发生什么」），覆盖从简单（开柜子）到复杂（烧开水）4 个难度等级，确保测试结果真实可信。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFAKABI3pJcuUKKiaF96LpcGaNwticF22a7fGwVNnxmYgoKecnVmuoCNyw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.587037037037037" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503528612" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2c2f805b-3c4a-48a9-92ee-d55f87b9532f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23"&gt;&lt;b data-index-in-node="0" data-path-to-node="23"&gt;关键一步：真实机器人落地&amp;mdash;&amp;mdash;星动纪元 Q5 的硬件优势&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="23"&gt;再好的「大脑」也需要「手脚」来执行，研究团队选择星动纪元星动 Q5 轮式人形机器人做真实场景测试，这款硬件的优势直接帮 MomaGraph 发挥出最佳效果：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFdZibOFjYDBquiah9I42jO62Cp1icEkuyrtcfrVXfVdECrIGMGFyibrKc4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.3731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528614" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d75eb094-7ec7-408f-a067-b9b0e6bef843/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="24,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,0,0"&gt;双臂 + 移动底座&lt;/b&gt;：能「走」到不同房间（比如从客厅到厨房），还能「动手」精准操作&amp;mdash;&amp;mdash;开柜子时，双臂能稳定抓住把手并拉动；开微波炉时，能控制力度避免损坏；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,1,0"&gt;多视角相机（Intel RealSense D455）&lt;/b&gt;：能拍物体的多个角度（比如从上方看水壶、从侧面看插座），帮模型获取准确的空间信息，避免「认错位置」（比如不会把柜子把手当成开关）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="24,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="24,2,0"&gt;适应家庭场景&lt;/b&gt;：硬件尺寸适合家庭环境（不会撞坏家具），双臂力度可控（不会捏碎杯子），完美匹配「家务任务」的需求。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="25"&gt;比如测试「开柜子」时，星动 Q5 的相机先拍柜子和把手的多视角图，MomaGraph-R1 根据图片生成「把手在柜子正面、能开柜子」的场景图，再规划「靠近柜子 &amp;rarr; 抓把手 &amp;rarr; 拉柜子」的步骤，Q5 的双臂精准执行，成功率远超传统机器人。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;&lt;strong&gt;四、研究结论：机器人「做家务」的能力大幅提升&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;从基准测试到真实机器人实验，MomaGraph 交出了亮眼的成绩，核心结论可以总结为三点：&lt;/p&gt;&lt;p data-path-to-node="28,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,0,0"&gt;「先画图再规划」远胜「直接猜步骤」&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,0,0"&gt;在 MomaGraph-Bench 基准测试中，MomaGraph-R1 的准确率达到 71.6%，比目前最好的开源模型（比如 LLaVA-OneVision）高 11.4%；而像 GPT-5 这样的闭源大模型，常会漏关键步骤（比如烧开水没提「插电源」），MomaGraph-R1 却能 100% 覆盖前提步骤&amp;mdash;&amp;mdash;因为它先画了「水壶需要插电」的场景图，再规划步骤。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFqPezApsTukQeG2EKkvibZeNIYFU61QJ7lfACET1bx1N1zMtnZpDa5gw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.36574074074074076" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528616" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7d587a6e-d541-486b-ba56-c3de150a0203/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="28,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,1,0"&gt;「空间 + 功能」一起看，比单独看更准&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,1,0"&gt;实验对比了「只看空间关系」、「只看功能关系」、「两者都看」的效果：MomaGraph-R1（统一版）在复杂任务（Tier 4）的准确率是 68.1%，而「只看功能」的版本只有 59.0%，「只看空间」的版本更低只有 45.4%。这说明：机器人既要知道「东西在哪」，也要知道「东西怎么用」，才能做好家务等任务的执行。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFOasOEIibn2p2CY4ZB5bLAmX7gNOl9IFg7K3qyGu0xBchrKob6JiaQJ1g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.18333333333333332" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528621" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/9152084b-020f-4ac7-ad9f-bf2bebc152a1/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="28,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="28,2,0"&gt;在真实机器人上能落地，还能处理复杂任务&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="28,2,0"&gt;团队用星动纪元星动 Q5 测试了 4 个常见任务：开柜子、开微波炉、开电视、关灯，全部成功；更难的「长任务」（「开灯 &amp;rarr; 找遥控器 &amp;rarr; 开显示器」），10 次测试成功 7 次&amp;mdash;&amp;mdash;而这个任务需要机器人「先解决照明（状态影响可见性），再找遥控器（空间定位），最后开显示器（功能控制）」，传统机器人根本做不到。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFoDZIUibjTYwy749YZLLlTjFvic2lkFjiacEDdRnhCQCe3lBnRnspIKMicA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528622" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/5ce92b65-3aa5-44df-bc87-b64667a49993/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="29"&gt;此外，MomaGraph-R1 在视觉对应任务上也表现突出，在 BLINK 基准和 MomaGraph-Bench 的对应任务中，比最好的开源模型分别高出 3.8% 和 4.8%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFGJGPS9xPrib2U2fzN3cRxce8HQFMtbUibG3ibpc19atXYS5eqKN0h81ZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.2324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528623" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/50952003-4af7-4e4c-ac49-5ebb79a842a6/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="30"&gt;&lt;strong&gt;五、行业意义：家用服务机器人离「进家门」又近了一步&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="31"&gt;MomaGraph 的价值，本质是解决了「机器人理解家庭场景」的核心难题：它让机器人从「只会按固定程序做事」（比如只会重复「推窗户」），变成「能根据场景灵活调整」（比如先看有没有把手，再决定转还是推）。&lt;/p&gt;&lt;p data-path-to-node="32"&gt;而星动纪元星动 Q5 这类执行硬件的参与，更证明了这项技术不仅仅适用于实验室&amp;mdash;&amp;mdash;仿人双臂、移动底座、精准相机的组合，让 MomaGraph 的「聪明大脑」有了可靠的「手脚」。未来，随着技术优化，我们可能会看到：机器人能帮老人烧开水、整理柜子，甚至帮上班族准备早餐&amp;mdash;&amp;mdash;家用服务机器人从「概念」走向「实用」，终于有了清晰的技术路径。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>迄今为止最大的细胞级CRISPR基因扰动数据集，AI加速药物发现与多组学整合，布局未来精准医疗</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 19 Jan 2026 14:06:24 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨%&lt;/p&gt;&lt;p&gt;2026 年 1 月 13 日，基因组学巨头&amp;nbsp;Illumina&amp;nbsp;宣布推出&amp;nbsp;&lt;strong&gt;Billion Cell Atlas&lt;/strong&gt;，这是迄今为止最大的细胞级 CRISPR 基因扰动数据集，包含了&lt;strong&gt;10 亿细胞&lt;/strong&gt;在 200 多种疾病相关细胞系中的响应数据。这一数据集将为 AI 模型提供训练基础，显著提升药物靶点识别、疾病机制理解和新疗法发现的效率。&lt;/p&gt;&lt;p&gt;此次发布标志着 Illumina&amp;nbsp;&lt;strong&gt;BioInsight 业务单元&lt;/strong&gt;首次推出数据产品，与辉瑞、默克等制药巨头展开合作，推动精准医学与 AI 药物发现的深度融合。这一数据集每年预计会生成约&amp;nbsp;&lt;strong&gt;20PB&lt;/strong&gt; 的单细胞转录组数据，并通过云平台加速 AI 模型的训练，推动科研进程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;单细胞资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;据公司新闻稿，Atlas 是 Illumina 新成立的 BioInsight 业务推出的首个数据产品。只有借助 Illumina 单细胞 3' RNA 制备平台才能实现，在单一实验中能够捕获数百万个单个细胞。&lt;/p&gt;&lt;p&gt;通过推出 Illumina 细胞图谱，并开发全面的疾病特异扰动数据集，结合先进的 AI 算法，Illumina 正在推动下一代细胞建模的发展。这本新的细胞图谱是在 Illumina 去年二月宣布的计划基础上，最终打造一个价值 50 亿的单细胞资源。到目前为止，Illumina 已从约 1.5 亿个细胞生成数据，预计年底前将达到 10 亿个。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwMuaA62qrKWS34lJdibrpdc6ojnkMczzXMiczMgibC8LFzohQPEibwdfgKQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.5399408284023669" data-type="png" data-w="676" data-width="676" data-height="365" data-imgfileid="100027178" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/6e0a13ff-be65-4c3f-b147-6a0779cf05ad/640.png" alt="图片" data-before-load-time="1768800471793" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;相关链接：&lt;em&gt;https://www.illumina.com/company/news-center/press-releases/press-release-details.html?newsid=383b9322-6cef-4fdd-8099-05a6f6904872&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Connected Multiomics 平台&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在公布该图谱的不久之前，1 月 6 日 Illumina 推出了&amp;nbsp;&lt;strong&gt;Connected Multiomics&lt;/strong&gt; 软件平台，旨在为研究人员提供跨基因组、转录组、蛋白组及表观组等多组学数据的整合分析与可视化工具。此平台结合了&amp;nbsp;&lt;strong&gt;AI 辅助变异解释&lt;/strong&gt;，支持大规模数据分析，为精准医疗和生物医药研发提供强有力支持。&lt;/p&gt;&lt;p&gt;Connected Multiomics 通过将多组学数据整合到单一平台，降低时间、成本和复杂性，使科学家能够加速发现并推动精准医疗的发展。在科罗拉多大学安舒茨医学院，肿瘤学研究人员利用该技术通过蛋白质组学数据分析，揭示了黑色素瘤的新见解。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLks49Uic5pFdzDf3ZD3g7ybwJm74gjicSUlsepF9ibdkuXNicLewxTQHOIjSDTEP7BOe2oyDXibc2Afq6Q/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.3148148148148148" data-type="png" data-w="1080" data-width="1460" data-height="459" data-imgfileid="100027177" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b3dec0f2-8bca-404c-8398-fe13736fdba6/640.png" alt="图片" data-before-load-time="1768800472290" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;相关链接：&lt;em&gt;https://investor.illumina.com/news/press-release-details/2026/Illumina-launches-powerful-software-for-connected-intuitive-and-scalable-multiomic-analysis&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;布局精准医疗与 AI 药物发现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从&lt;strong&gt;Connected Multiomics&amp;nbsp;&lt;/strong&gt;到&amp;nbsp;&lt;strong&gt;Billion Cell Atlas&lt;/strong&gt;，Illumina 正在加速推进&lt;strong&gt;AI 与精准医疗&lt;/strong&gt;的深度结合。随着数据集和多组学平台的不断发布，Illumina 在推动&lt;strong&gt;大数据驱动的药物发现&lt;/strong&gt;、&lt;strong&gt;基因组学进展&lt;/strong&gt;及&lt;strong&gt;AI 应用&lt;/strong&gt;方面，始终处于行业前沿。随着未来更多合作与技术落地，Illumina 的全方位布局可能会重塑精准医疗产业格局。&lt;/p&gt;&lt;p&gt;相关报道：&lt;em&gt;https://www.illumina.com/company/news-center/press-releases/press-release-details.html?newsid=fda84c92-b4b3-4691-a402-35555abe8605&lt;/em&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>你的论文有novelty吗？复旦搞了个顶会论文查新系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 12:07:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/382d228d-2bc6-4d38-b9b5-715533fd2a07/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="4" data-pm-slice="0 0 []"&gt;ICLR 2026 的 Rebuttal 结束了。当 OpenReview 上的喧嚣散去，我们发现，作者与审稿人之间漫长的拉锯战，最终往往只剩下一个核心分歧：「这个想法，以前真的没人做过吗？」&lt;/p&gt;&lt;p data-path-to-node="5"&gt;Novelty（创新性）是学术评审中被高度关注的指标之一， 但其评估在实践中仍高度依赖评审者的经验判断与检索覆盖。随 arXiv 文献数量的快速增长，仅靠人工检索与记忆来追溯相关研究工作，已难以满足高效的评审需求。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF2lMvtTzQu4zX9HHcsXgFJBo9IibXPXQFTyT5Q90GoxqhTy33C8cys1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5578034682080925" data-s="300,640" data-type="png" data-w="692" type="block" data-imgfileid="503528556" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e0c9c206-8e9e-40f0-bd0a-d2c261709eb2/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="6"&gt;针对这一挑战，复旦大学 NLP 研究团队与其此前孵化的学术搜索平台 WisPaper 展开合作，共同研发了 OpenNovelty&amp;mdash;&amp;mdash;一个基于大语言模型、强调证据与可验证性的自动化新颖性分析系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFYZqk3YVn7xsfHFPxEmgITKeDFb5xOibC0jmrUMQgIvTszWN8O5hv2IQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5453703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528555" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/4c4b5d53-8c4c-4980-a4fa-07f87d3a35cf/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="8,0,0"&gt;论文标题：OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,0,0"&gt;论文链接：https://arxiv.org/abs/2601.01576&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,1,0"&gt;Github 链接：https://github.com/january-blue/OpenNovelty&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,2,0"&gt;HuggingFace：https://huggingface.co/papers/2601.01576&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="8,3,0"&gt;官方网站：https://www.opennovelty.org&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="9"&gt;&lt;strong&gt;核心设计&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="10"&gt;OpenNovelty 的根本原则很简单：任何关于「该论文创新性不足」的判断，都必须附带可追溯的真实证据，这些证据必须来自于已发表的文献，并且能精确定位到原文具体段落。若系统未能找到相关证据，则如实说明「未发现支持该判断的证据」。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;与传统查重仅关注文字表层重叠不同，OpenNovelty 试图解决语义层面的重复。 系统会对投稿进行结构化抽取，将作者表述转写为更便于检索与对比的学术概念短句，自动提取出论文的一个核心任务（Core Task）和若干具体贡献（Contributions）。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;此外，系统还采用了「查询扩展（Query Expansion）」机制，针对提取出的每条信息，生成多个语义等价的变体，在 WisPaper 的索引库中进行地毯式检索，防止单一表述带来的检索遗漏。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;&lt;strong&gt;四步分析流程：从论文提交到生成 &amp;nbsp;可验证的新颖性评估报告&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="13"&gt;&lt;strong&gt;第一步：核心信息提取&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="14"&gt;系统从论文的标题、摘要和引言，精准地提取出两类信息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="15,0,0"&gt;&lt;strong&gt;核心任务&lt;/strong&gt;：论文拟解决的核心学术问题（例如：「基于多轮强化学习的 LLM 智能体长周期决策训练」）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="15,1,0"&gt;&lt;strong&gt;贡献声明&lt;/strong&gt;：作者明确宣称的创新点，如新方法、框架、算法或理论形式化（例如：「一个支持多种强化学习算法的统一训练框架」）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFUk4MYTAr5Bq0cEnLRGxVB0HTia5IO5tiblF3n1ASskpDggrR2pKNb9XA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0074074074074073" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528558" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1e750d25-830d-41a1-83aa-2c2f4e558859/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="16"&gt;&lt;strong&gt;第二步：相关文献检索与筛选&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;基于提取的信息，系统自动生成一组学术搜索语句（包括同义词及变体表达，避免因措辞差异而遗漏相关文献），然后利用 WisPaper 学术引擎展开地毯式搜索。&lt;/p&gt;&lt;p&gt;初步检索可能召回数百至上千篇潜在相关论文，随后通过去重、时间过滤与筛除弱相关性文献等步骤，最终形成约 60&amp;ndash;80 篇用于后续分析的候选论文集合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFhf9gngGTp3r5UBibBiapbXjmRchKEo55tEIYOlf8Qick5UUVjvbF486Ww/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7796296296296297" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528560" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/59a1a707-8492-42ac-9e96-223b9972d2ab/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;第三步：层次化分析与证据比对&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;这是系统的核心分析环节。系统会基于核心任务召回的候选论文构建层次化 taxonomy（树状分类体系），以呈现目标论文在相关研究脉络中的位置。提供目标论文在候选研究脉络中的相对定位，供评审者快速浏览。&lt;/p&gt;&lt;p data-path-to-node="20"&gt;针对每条贡献声明，系统会在贡献召回的候选论文集合中进行逐篇对比，并尝试给出可核验的对应证据片段。比对的结果有如下三种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,0,0"&gt;能反驳（can_refute）：找到已发表的论文具有相似贡献，必须附带双方论文的原文摘录作为证据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFolXicgIaYKq63HtYkg8SJRKMNjHRGicIk9wFtGhCwClOB9PTcHPnEfTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.8268518518518518" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528561" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/416499bb-64c6-4b58-b9e9-c34ea6dc3d2b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="21,1,0"&gt;无法反驳（cannot_refute）：在当前检索范围内，未发现可质疑该创新贡献的文献。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="21,2,0"&gt;存疑（unclear）：信息不足，无法判断。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="22"&gt;关键在于：如果系统做出「能反驳」的判断，但其提供的证据（即摘录段落）无法在原论文中找到或匹配度过低，该判断会自动降级为「无法反驳」。&lt;/p&gt;&lt;p data-path-to-node="23"&gt;&lt;strong&gt;第四步：「新颖性调查报告」生成&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="24"&gt;系统整合前三阶段结果，生成包含以下模块的评估报告：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="25,0,0"&gt;论文的核心任务&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,1,0"&gt;研究领域的分类体系&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,2,0"&gt;每条创新声明的比对结果和证据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="25,3,0"&gt;综合的「新颖性评估」叙述&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于系统给出的关键判断，报告会尽量提供可追溯的候选文献与可核验的原文证据位置，便于评审者快速定位与人工复查。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFbIpgAb3ianhG9BQvh4ceC11L6ZHKXHcR22tYWhjPmUkG9X2YJvqoLkA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6222222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528562" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/ea1c4630-21b0-45ee-9a85-43c031e8b62a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="27"&gt;&lt;strong&gt;系统部署与公开验证&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;截止到 1 月 16 日，团队已经在系统上分析了 1360 篇投稿，并且把所有生成的新颖性报告公开发布在其官方网站。任何人都可以查阅系统对某篇投稿的分析结果、检索到的相关文献以及判断依据。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;团队计划进一步将分析规模扩展至 2000+ 篇投稿，此外，还将持续优化系统，计划将其应用于其他 AI 顶级会议，并对所收集的报告和评审证据进行深入分析。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;&lt;strong&gt;OpenNovelty 的影响&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="30,0,0"&gt;&lt;strong&gt;对审稿人而言&lt;/strong&gt;：它是一个辅助工具而非替代。系统可以帮助评审者梳理文献脉络，快速掌握一篇论文在领域中的位置，从而将更多精力集中于更需要人类专业判断的关键环节，如研究意义、方法严谨性等问题。&lt;/p&gt;&lt;p data-path-to-node="30,1,0"&gt;&lt;strong&gt;对论文作者而言&lt;/strong&gt;：它可作为投稿前的自查工具。如果研究具备实质创新性，系统可以提供相关证据；如果漏引了重要文献，系统亦能指出问题。&lt;/p&gt;&lt;p data-path-to-node="30,2,0"&gt;&lt;strong&gt;对学术界而言&lt;/strong&gt;： 该系统提供了一种&amp;ldquo;可验证的新颖性评估&amp;rdquo;工程路径&amp;mdash;&amp;mdash;用检索到的真实文献与贡献级证据对比来约束结论输出，让判断能够被追溯与复核，而不是停留在模型的无证据生成。推动 AI 成为负责人的知识引证者，而非不可靠的内容生成器。&lt;/p&gt;&lt;p data-path-to-node="31"&gt;&lt;strong&gt;仍需人类判断&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="32"&gt;团队在论文里也明确指出了系统的局限性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="33,0,0"&gt;难以理解复杂的数学公式和图表&amp;mdash;&amp;mdash;如果一篇论文的核心创新藏在一个复杂的方程式里，系统可能会错过；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="33,1,0"&gt;只能搜到被索引过的论文，可能错过未被收录的小众期刊或非英语出版物；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="33,2,0"&gt;「无法反驳」仅表示在「检索范围内未找到」，并不等于「确实不存在」。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="34"&gt;因此，团队一再强调：&lt;strong&gt;这是辅助工具，而非决策主体&lt;/strong&gt;。最终的学术判断，仍然要由人类审稿人完成。&lt;/p&gt;&lt;p data-path-to-node="35"&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="36"&gt;OpenNovelty 的出现带有某种实验性的克制。它并非试图取代现有的同行评审体系，而是作为一套第三方审计系统介入。在 Rebuttal 结束后的最终决策阶段，它负责清洗迷雾，向 AC 展示那些被淹没的证据，而将最终的价值判断权留给人类。&lt;/p&gt;&lt;p data-path-to-node="36"&gt;目前，ICLR 2026 的部分论文查新报告已在 OpenNovelty 官网开放查阅。对于即将在明年继续冲击顶会的科研人员来说，这或许是一个审视自己工作的新鲜视角。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让机器人看视频学操作技能，清华等全新发布的CLAP框架做到了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 12:03:52 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/8f91d587-4689-4bf2-bce1-879a8a63af5b/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近日，&lt;strong&gt;清华大学与星尘智能、港大、MIT&amp;nbsp;&lt;/strong&gt;联合提出基于对比学习的隐空间动作预训练（Contrastive Latent Action Pretraining, CLAP）框架。这个框架能够将视频中提纯的运动空间与机器人的动作空间进行对齐，也就是说，机器人能够直接从视频中学习技能！&lt;a href="https://mp.weixin.qq.com/s/6qkoPGMbnZXFWOYg-MljlQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e843c007-a49d-4ee4-9d14-26ed5527b6c2/1768795269900.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;论文标题：CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.04061&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址：https://lin-shan.com/CLAP/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;长期以来，机器人学习面临着一个令人头疼的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;数据饥荒」难题：互联网上有着数以亿计的人类行为视频，但专门用于训练机器人的数据却寥寥无几。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;这种数据不对称现象的根源在于，收集机器人操作数据需要昂贵的硬件设备、专业的操作环境，以及大量的人工标注工作，成本高昂且效率低下。相比之下，人类行为视频数据虽然丰富，但由于视觉表征与机器人动作空间之间存在巨大的语义鸿沟，传统方法难以有效利用这些资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;现有的潜在动作模型（Latent Action Models）试图利用视频数据，但往往会遭遇「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;视觉纠缠」（visual entanglement）问题 &amp;mdash;&amp;mdash; 模型学到的更多是与实际操控无关的视觉噪声，而非真实的操控技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CLAP 框架的核心创新正是解决了这一长期困扰业界的技术瓶颈。&lt;/strong&gt;该框架能够将视频中提纯的运动空间与机器人的动作空间进行对齐，有效避免了以往潜在动作模型中普遍存在的「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;视觉纠缠」问题。通过对比学习，CLAP 将视频中的状态转移映射到一个&lt;strong&gt;量化的、物理上可执行的动作码本&lt;/strong&gt;上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;研究团队基于两种 VLA 建模范式进行训练：其一是 &lt;strong&gt;CLAP-NTP&lt;/strong&gt;，一种自回归模型，在指令跟随与对象泛化方面表现突出；其二是 &lt;strong&gt;CLAP-RF&lt;/strong&gt;，一种基于 &lt;strong&gt;Rectified Flow&lt;/strong&gt; 的策略，面向高频率、精细化的操控。&lt;/p&gt;&lt;p&gt;这一技术突破的实际意义体现在多个层面。首先，从数据利用效率来看，CLAP 框架使得机器人能够从 YouTube、抖音等平台上的海量视频中学习技能，极大扩展了可用训练数据的规模。其次，从成本效益角度分析，这种「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;看视频学技能」的方式显著降低了机器人技能获取的门槛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;此外，该框架还解决了机器人学习中的一个关键技术挑战 &amp;mdash;&amp;mdash; 知识迁移问题。通过&lt;strong&gt;知识匹配（Knowledge Matching, KM）&lt;/strong&gt;正则化策略，CLAP 有效缓解了模型微调过程中的灾难性遗忘现象，确保机器人在学习新技能的同时不会丢失已掌握的能力。&lt;/p&gt;&lt;p&gt;从产业应用前景来看，CLAP 框架的长期价值不仅在于技术创新，更在于其对机器人产业化进程的推动作用。当机器人能够通过观看视频快速掌握新技能时，企业部署机器人的成本和周期将大幅降低，这有望加速机器人在服务业、制造业等领域的规模化应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;详解 CLAP 框架&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDpoiaMxzHjtfdDs495VticjX6hLp5uD2iaUHicbnU34t7as4T9zEibyTCm4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.9" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528522" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/63f662bf-113b-4619-9e67-ec7430526a14/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队构建了一个统一的视觉 - 语言 - 动作（VLA）框架，使其能够同时利用&lt;strong&gt;机器数据的动作精确性与大规模无标注人类视频演示的语义多样性&lt;/strong&gt;。框架分为两个相互衔接的阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通过 CLAP 进行跨模态对齐&lt;/strong&gt;：建立共享的潜在动作空间，弥合无标注人类视频与有标注机器人轨迹之间的监督缺口。该过程基于对比学习进行隐空间动作预训练（CLAP）：它将人类视频中的视觉状态转移「锚定」到一个&lt;strong&gt;量化的、物理上可执行的动作空间&lt;/strong&gt;中。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDyAwt85U69iaUdBIVj3RWd9t9HBTR1K9fEzeibTenpITLbtTfvHNuarJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37962962962962965" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528523" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ce891345-2e02-4d2c-8651-1a0de81aea91/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分层策略训练&lt;/strong&gt;：研究团队通过连续训练两个 VLA 模型，将语义理解与控制动力学有效解耦：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CLAP-NTP&lt;/strong&gt;：采用「下一词元预测」（Next-Token-Prediction）训练的 VLA，擅长指令跟随与任务规划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;CLAP-RF&lt;/strong&gt;：包含一个 VLM 模型与一个采用 Rectified Flow 训练的动作专家，以实现高频、精确控制。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为高效适配新的本体形态并防止预训练先验在微调中发生灾难性遗忘，研究团队进一步提出&lt;strong&gt;知识匹配（Knowledge Matching, KM）&lt;/strong&gt;微调策略：一种正则化方法，在微调过程中将策略更新锚定在可信区域内。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDgHX6qibG0kurUP2HKTFBCKhFWK7P5iciazbWvfa4ac3MhkdE0Cc5icVsoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528525" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/57593a5e-a8dc-4330-97f9-fb342a0a36b1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;大量实验表明，CLAP 显著优于强基线方法，使得从人类视频中学习到的技能能够有效迁移到机器人执行中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;下表 1 为初始设置下，CLAP 与基线方法在真实世界任务中的性能比较。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDc0pibb9xbg0loFCgtYZiaPiaKfIUAwdQibuny80cINkEh48sXydnI9dGHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.287962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528527" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a5904f01-6636-4312-8f07-10ebc48a38b2/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;下表2 为 CLAP 与基线方法在环境扰动下的鲁棒性评估。&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicZPMSA6j9VpibI41cpxbGoDbQoTyLSf2FMQhzb07TnYicWy10VOPEa7lhwSfJtp4uZmCkqErbTsicGA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.28703703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528528" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/01e49ce1-6631-417d-a0a4-93c1da927ea0/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;更多实验结果请参阅原论文。&lt;/span&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>CES 2026趋势照进现实：算力引擎RK182X重塑千行百业，瑞芯微AI生态大会共建落地生态</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 10:32:10 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img alt="图片" data-aistatus="1" data-ratio="0.7574074074074074" data-src="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxQpJXzbBGljuPsptbV4I1Y3CScn5pmia6gl5n1eIqyNNIwXYLYNXRQqd8lH8iclt0oCiaiawGrQg30SPg/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=0" data-type="other" data-w="1080" data-original-style="height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e0bcff20-b6a1-4b42-8845-21144178ec64/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-font-family="微软雅黑"&gt;一年一度的&amp;ldquo;科技春晚&amp;rdquo;CES2026于上周落下帷幕，从今年的主题&amp;ldquo;定义AI的物理边界（Physical AI）&amp;rdquo;，可以看出全球科技新趋势正在推动AI从虚拟走向现实应用，通过多元化的消费电子、机器人、智能汽车等实体形态让生活智能化变得具象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;瑞芯微作为国内AIoT芯片领域的领军企业，正在这一科技浪潮中扮演着重要角色。全球首颗3D架构协处理器RK182X系列芯片的技术突破，不仅为全球&amp;ldquo;Physical AI&amp;rdquo;的发展提供强大的硬件和算力支撑，更是推进千行百业用AI重做一遍的AIoT2.0时代的落地进程。同时，瑞芯微将举办AI软件生态大会，&lt;span data-pm-slice="0 0 []"&gt;依托在AIoT千行百业、超过5000家全球客户的广大生态，&lt;span data-pm-slice="0 0 []"&gt;搭建起AI软件与市场的桥梁。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;瑞芯微RK182X：AIoT2.0的算力引擎&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在这一轮产业变革中，端侧AI能力将成为关键。&lt;/span&gt;驱动硬件设备从&amp;ldquo;被动执行&amp;rdquo;向&amp;ldquo;主动服务&amp;rdquo;跃迁，瑞芯微RK182X提供关键的&lt;/span&gt;&lt;strong&gt;主动感知与综合决策能力&lt;/strong&gt;。其在视觉语言模型和大语言模型上的卓越性能，构成了新一代&amp;ldquo;环境智能体&amp;rdquo;的双脑核心，使设备能主动预见需求、理解复杂场景并执行综合任务，真正实现&lt;strong&gt;从&amp;ldquo;功能机&amp;rdquo;到&amp;ldquo;智能体&amp;rdquo;的本质进化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;基于实测数据显示，RK182X运行Qwen2.5-3B模型输出速度突破百Token，是市场对标产品的3倍；同时&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;在多模态视觉语言模型任务上，瑞芯微已率先支持Qwen3-VL-2B/4B模型，实测数据业内领先。RK182X运行Qwen3-VL-2B模型输出速度达136.32TPS，运行Qwen3-VL-4B模型输出速度近百Token&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxRXhSj56Jbyw4twZFicb0CgQx4dich9SxQVBiaupzWrZRhU3icx4PeG1cEYduQficOvpRTmPOIma9iaoQFQ/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=1" alt="图片" data-ratio="0.5777777777777777" data-s="300,640" data-type="other" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/mmbiz_png/549lkW9auxRXhSj56Jbyw4twZFicb0CgQx4dich9SxQVBiaupzWrZRhU3icx4PeG1cEYduQficOvpRTmPOIma9iaoQFQ/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="578" data-cropsely2="349" data-imgfileid="503443581" data-aistatus="1" data-original-style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;vertical-align: bottom;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 676.984px !important;height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0e4303ad-5705-4a4d-9f8b-8f2ff02b631b/640.png" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;RK182X的技术突破主要体现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;从&amp;ldquo;看清&amp;rdquo;到&amp;ldquo;看懂&amp;rdquo;，处理复杂模型的&amp;ldquo;直觉&amp;rdquo;与&amp;ldquo;认知&amp;rdquo;。&lt;/strong&gt;&lt;/span&gt;新一代硬件需要充分理解用户指令并具备对&amp;ldquo;长尾场景&amp;rdquo;的认知能力。如传统的监控设备，能准确识别人、车、物等目标，&lt;strong&gt;RK182X的强大端侧AI算力，能够让新一代AI设备具备解读事件和行为的能力，实现同时分析四路视频实时预警功能，异常响应仅需 0.5 秒，每路均能输出视频理解后的场景和行为细节描述&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/9oOslerakonH91ROSsZL-A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/633ed16c-5edc-43b7-af35-3bba8bd17ee5/1768789738059.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;从&amp;ldquo;听清&amp;rdquo;到&amp;ldquo;听懂&amp;rdquo;，保障实时&amp;ldquo;交互&amp;rdquo;与隐私安全。&lt;/strong&gt;&lt;span data-font-family="微软雅黑"&gt;RK182X 直接颠覆了端侧 AI 音频的体验逻辑：在拾音端，它凭借强劲算力实现&lt;strong&gt;多人语音 AI 8 轨多音轨分离与精准声源定位&lt;/strong&gt;，彻底告别传统 &amp;ldquo;唤醒词&amp;rdquo;；不管环境多嘈杂，设备都能自主识别有效指令、抓准核心需求，再配合&lt;strong&gt;百 Token/s 级的本地处理速度，连续对话丝滑无卡顿&lt;/strong&gt;，不止 &amp;ldquo;听清&amp;rdquo; 用户的表达，更能 &amp;ldquo;听懂&amp;rdquo; 用户的需求甚至主动串联复杂任务；而这所有的处理都在设备本地完成，敏感数据无需联网，隐私安全直接拉满。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;输出端&lt;/strong&gt;&lt;span data-font-family="微软雅黑"&gt;，针对音乐播放，可通过深度学习模型将&lt;strong&gt;混合音频中的人声、吉他、贝斯、钢琴，鼓点等拆分为高保真，低串音的独立音轨&lt;/strong&gt;，可以根据需要重构声场，打造无与伦比的专属听觉体验。RK182X正是把端侧 AI 音频从 &amp;ldquo;能用&amp;rdquo; 推向 &amp;ldquo;好用、敢用&amp;rdquo; 的关键一步。&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;赋能场景：三大领域迎接硬件智能化浪潮&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;基于CES 2026展示的产品新趋势，RK182X将为三大核心领域提供技术驱动力，推动Physical AI快速落地。&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;消费电子领域&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;，展会上备受关注的智能眼镜、智能电视、智能镜柜等新一代智能硬件，&lt;strong&gt;将AI助手、实时翻译、视觉增强等功能融入其中&lt;/strong&gt;，需要强大的端侧AI能力来处理图像识别、语音理解和实时交互任务，RK182X正好满足这一需求，&lt;strong&gt;让消费电子产品从单一功能工具转向重塑交互，具备更强大的端侧多模态即时处理能力&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;机器人领域，&lt;strong&gt;RK182X为需要自主移动、环境交互的机器人提供核心算力&lt;/strong&gt;。CES上的能够武术表演的人形机器人、能爬楼梯的吸尘机器人、家务多功能机器人，正是这一趋势的缩影。&lt;strong&gt;未来的机器人不再仅仅是执行预设程序的机械装置，而是能够理解环境、适应变化并自主决策的智能伙伴。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;智能座舱领域，多家中国车企在CES 2026展示了最新的辅助驾驶技术以及功能更丰富的车载娱乐系统，端侧AI能力将成为关键支撑。&lt;strong&gt;凭借RK182X强大的本地AI处理能力，未来汽车能够在离线环境下仍做出安全决策，实现更自然的语音、手势等多模态交互。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;strong&gt;生态布局：瑞芯微携手软件伙伴实现场景落地价值变现&lt;/strong&gt;&lt;/span&gt;&lt;span data-font-family="微软雅黑"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-font-family="微软雅黑"&gt;在AIoT2.0时代，瑞芯微不仅提供硬件解决方案，更致力于构建完整的产业生态。瑞芯微将通过开放易用的工具链、深度合作的算法生态以及可快速复用的行业参考设计，构建&amp;ldquo;芯片+算法+行业方案&amp;rdquo;的全栈能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;瑞芯微首届AI软件生态大会，诚邀AI软件公司共聚福州，共同探讨端侧AI在机器人、机器视觉、智能座舱、自动驾驶、 工业应用、智能家居、AI电脑、AI手机、可穿戴设备等千行百业的落地路径与商业模式。共同搭建起AI软件与市场的桥梁，依托瑞芯微在AIoT千行百业、超过5000家全球客户的广大生态，实现AI软件算法的场景落地、价值变现。&amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/549lkW9auxRcrQiaG3hgqJcADfhGrskQibzUndjK1lTIw2Rgea7S1CpDxUQVehXgAgDooku0LPlUN9QxLQ5ze05A/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=2" alt="图片" data-ratio="2.1287037037037035" data-s="300,640" data-type="other" data-w="1080" type="block" data-imgfileid="503443562" data-aistatus="1" data-original-style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;vertical-align: bottom;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 676.992px !important;height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/677dee94-e5a9-43de-8cf4-9d3cd56846d8/640.png" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>效果、性能双突破，快手OneSug端到端生成式框架入选AAAI 2026</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 19 Jan 2026 10:25:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-19</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-19</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/54f5f759-6533-411a-9d04-fc212ec9c954/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []" data-source-doc-id="eZQB1lHk_VfBdTsNfXXRa7lqw"&gt;当你在电商平台搜索“苹果”，系统会推荐“水果”还是“手机”？或者直接跳到某个品牌旗舰店？短短一个词，背后承载了完全不同的购买意图。而推荐是否精准，直接影响用户的搜索体验，也影响平台的转化效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;查询推荐（Query Suggestion）是现代电商搜索系统中的关键功能，通过在用户输入过程中实时推荐相关查询，帮助用户快速明确意图，提升搜索体验与转化效率。传统方法通常采用多阶段级联架构（MCA），虽然在效率与效果之间取得了一定平衡，但由于各阶段目标不一致、长尾查询召回困难等问题，限制了系统性能的进一步突破。&lt;/p&gt;&lt;p&gt;基于上述问题，快手在业界首次提出端到端的生成式统一查询推荐框架 ——OneSug，成功将召回、粗排、精排等多个阶段统一在一个生成模型中，显著提升了推荐效果与系统效率，在快手电商场景中实现了业务指标与用户体验的双重提升。&lt;/p&gt;&lt;p&gt;本工作相关成果《OneSug: The Unified End-to-End Generative Framework for E-commerce Query Suggestion》已被人工智能顶级会议 AAAI 2026 接收。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFKcKWFJBStrhd53JZQo2Owl2tCBE1dMxiazxUx8PIX3HyLRESSx0oBLQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=1" data-ratio="0.3398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528571" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d23652fb-a3fb-4032-b779-3410e1a49748/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：https://arxiv.org/abs/2506.06913&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、研究背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统查询推荐系统通常采用多阶段级联架构，依次进行召回、粗排和精排。尽管该架构在响应时间与转化率之间实现了一定平衡，但也带来了明显的局限性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;级联式框架（召回 -&amp;gt; 粗排 -&amp;gt; 排序），前一链路性能决定下一链路上限；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;召回、排序分离技术迭代范式，全链路统一目标优化难；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;长尾前缀由于缺乏历史行为数据，难以召回高质量 Query。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;近年来，生成式检索（Generative Retrieval）因其强大的语义理解与生成能力，在推荐与搜索领域展现出巨大潜力。然而，现有方法多聚焦于视频推荐，其本质上是一个开集到开集的任务，难以直接应用于输入输出都是开放词表的的查询推荐场景。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFRoLHLL5ibKgL8v7qheyN3otXexv7Y9UFndDZkHOoLUInIGcl4ZRza6Q/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.5120370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528574" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0ee8c588-000e-4ed2-8086-6f1cdc2e6535/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFBCpcmJPPQrKLxr8RaLkBgysdk8JPU2x55Yzz7RBwUbjoMwyPVTHqSg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.24722222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528575" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/ed13c183-737c-42df-9684-81ce51e09d8e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;二、方法简介：OneSug 的三大核心模块&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFicPicM7ENLm6ZOqRaklM3MbicVM5hgb5vpfuYiavvaUHDy0QpMMN0stwMw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.5138888888888888" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528591" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/31bcea93-87ec-47fd-83dd-93243be517c5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;针对上述问题，快手提出了 OneSug 模型，整体架构如上图所示，主要包括 3 个部分：&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;（1）&lt;/span&gt;Prefix-Query 表征增强模块（Prefix2Query Representation Enhancement）&lt;/p&gt;&lt;p&gt;（2）统一的 Enc-Dec 生成架构（Unified Encoder-Decoder Architecture）&lt;/p&gt;&lt;p&gt;（3）用户行为偏好对齐（User Preference Alignment）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. Prefix-Query 表征增强模块&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Sug 场景下，用户输入的前缀往往较短且意图模糊（如 “苹果” 可指水果或品牌）。为此，快手提出的解决方式分为 2 个部分。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;语义与业务空间对齐：以 BGE 作为 base 模型，同时引入用户真实的 prefix2query、query2query 数据，使用对比学习对 BGE 进行微调，使其语义空间与快手电商的业务特征空间对齐。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;层次化语义 ID 生成：在对齐语义空间的基础上，引入 RQ-VAE，为每个前缀和 Query 生成层次化的语义 ID。RQ-VAE 可将任意文本映射为离散的语义 ID，同时保证语义相近的 query 会被编码到相同的簇中。通过这种方式，对于任何一个用户输入的前缀，可以快速匹配到与其语义 ID 最接近的 top-K 个相关 query，作为增强上下文输入后续生成模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 统一的 Enc-Dec 生成架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OneSug 的生成架构基于 Enc-Dec 结构，并直接通过自回归（Autoregressive）方式生成用户最有可能点击的 Query。&lt;/p&gt;&lt;p&gt;该模型的输入包含四个关键部分：&lt;/p&gt;&lt;p&gt;（1）用户当前输入前缀（如 “智能手机”）&lt;/p&gt;&lt;p&gt;（2）由 PRE 模块增强的相关查询序列（如 “智能手机性价比 2025”）&lt;/p&gt;&lt;p&gt;（3）用户历史行为序列（如过去搜索的 “蓝牙耳机”、“手机壳” 等）&lt;/p&gt;&lt;p&gt;（4）用户画像信息&lt;/p&gt;&lt;p&gt;输出即为模型生成的 Query 列表（如 “智能手机推荐 2025”、“智能手机性价比排行”）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 用户行为偏好对齐（RWR）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;3.1 用户偏好量化&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;首先对用户在搜索场景下的真实行为进行了精细化分级，将其划分为六个明确的层次，并为每个层级赋予一个基础奖励权重 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFiczZ1fE0LorYVJkunvZT8LkmmSDssHBXBT2FlTXAmHfb55xkuz5MMyg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=5" data-ratio="1.2222222222222223" data-s="300,640" data-type="png" data-w="27" type="block" data-imgfileid="503528592" data-aistatus="1" data-original-style="width: 20px;height: 24px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/9126e0ce-06ee-4f98-8dd5-08da0c8c83e4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 3.27%;"&gt;:&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFtf1Z22avuibg6SKln6BNkUqmTI2bK43DyHU44IhKRrQpMyGq8icQfoEA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.4211597151576806" data-s="300,640" data-type="png" data-w="983" type="block" data-imgfileid="503528595" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/20e1e396-2fd7-4435-ab1f-ccf578412b89/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Rand 随机负样本 0.0 为了进一步细致的调节样本权重，额外引入了调节因子 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFwXQ4bGchlzOVBpb4BfLpRuGRxW4jmps7up1zIYVm8RRTv1AyFwvCKg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=7" data-ratio="0.1813953488372093" data-s="300,640" data-type="png" data-w="215" type="block" data-imgfileid="503528597" data-aistatus="1" data-original-style="width: 149px;height: 27px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/1f07d416-3aff-4fd1-aac7-f5ec8f96a126/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 20.03%;"&gt;，其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF3zfiafKTCf3tgbA5iaOGKlfWtJ2f7eOMg6kmVhc2zkbO0nKib9BpVPRJw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=8" data-ratio="0.7333333333333333" data-s="300,640" data-type="png" data-w="45" type="block" data-imgfileid="503528599" data-aistatus="1" data-original-style="width: 37px;height: 27px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/29fc4e87-08d6-4d30-8a4f-7bdee4253ece/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 4.74%;"&gt;表示当前前缀下 query 的 ctr。&lt;/p&gt;&lt;p&gt;3.2 混合排序框架奖励加权偏好优化&lt;/p&gt;&lt;p&gt;传统的 DPO 使用 &amp;lt; 正样本，负样本 &amp;gt; 对进行训练，但默认两者同等重要。这在业务场景中是不合理的，因为区分 “点击” 和 “曝光” 的难度远小于区分 “点击” 和 “随机负样本”。&lt;/p&gt;&lt;p&gt;RWR 的核心思想是根据正负样本之间的奖励差距，为不同的样本对赋予不同的学习权重。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;构建了九种类型的样本对（如 &amp;lt;Order, Show&amp;gt;, &amp;lt;Click, Rand&amp;gt;）。对于每一对样本，计算其奖励差异权重 rwΔ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF7rdOMBBQhX2kkiboNicShxhjqnFj7BfEoeOehCEmhtrpGias5dicEWMlNg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=9" data-ratio="0.2125" data-s="300,640" data-type="png" data-w="480" type="block" data-imgfileid="503528601" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/954456c9-9da7-430f-be33-a0de8e407f72/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFOPWlnsiaLzXgtFPxWxZicmsoBANQH538iaE5jwI9icUiapWsHrO3wruy5tQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=10" data-ratio="0.5238095238095238" data-s="300,640" data-type="png" data-w="63" type="block" data-imgfileid="503528604" data-aistatus="1" data-original-style="width: 49px;height: 26px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/e63e6899-11b7-4ca8-b917-330e5595cbf9/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 6.79%;"&gt;值小：说明正负样本奖励差距大（如 &amp;lt; Click, Rand&amp;gt;），是 “容易样本”，模型正常学习即可。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFlWDL8wEg86t6hkcmQQEu0VqoZKuLYGGgS7ZzSJPPG1tDWicUjtvprsA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=11" data-ratio="0.5789473684210527" data-s="300,640" data-type="png" data-w="57" type="block" data-imgfileid="503528605" data-aistatus="1" data-original-style="width: 45px;height: 26px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/5833298e-b9d5-44e2-b0a7-237e6d2858f5/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 6.68%;"&gt;值大：说明正负样本奖励差距小（如 &amp;lt; Click, Show&amp;gt;），是 “困难样本”，RWR 会赋予更大的权重，迫使模型更加努力地学习其间微妙的偏好差异。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;3.3 混合排序框架&lt;/p&gt;&lt;p&gt;为了克服传统 Pairwise 范式的 DPO 在全局排序能力上的局限性，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;引入了一种混合排序框架。该框架将 listwise 范式的排序损失和 point-wise 范式的 sft loss 进行混合，使得模型既能获得高效的排序能力，同时避免 reward hacking 造成的生成能力下降。&lt;/p&gt;&lt;p&gt;Pairwise 范式对齐模型，在包含多个负样本的候选中无法学习到 “哪个是最好的”。受 Plackett-Luce 模型启发，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;设计了 Listwise 排序损失，对于正样本，让模型同时拉大它与所有负样本的奖励差距，迫使模型不仅要知道正样本比负样本好，还要学会在负样本越多、越强的情况下，依然将正样本排在前面，从而直接优化列表的整体排序质量。&lt;/p&gt;&lt;p&gt;论文中分别提出了基于 Pairwise 和 ListWise 范式的混合排序框架，同时在理论上证明了 Pairwise 范式的对齐模型是 ListWise 的特殊情况。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFY0xtQGLibaj7o4ALf6GTR3Gy6ysRwAYbkf5bPJCbnztmp1Pq6eHDCIQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=12" data-ratio="0.1037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528608" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/daabf0cc-9a01-495d-8e2d-af0fe2f128c6/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;三、实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;离线效果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在快手电商场景的大规模数据集上，OneSug 在 HR@16 和 MRR@16 指标上均显著优于传统多阶段系统与生成式基线模型。论文中同时提到，OneSug 不仅适用于 Enc-Dec 结构的生成式模型，Decode-only 架构的模型同样适用，且具有更高的离线指标，因为现阶段的推理耗时约束暂时没有进行在线实验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFV8yGnYdRsuHdDquPEiamTSQVB1L77O5n3yiazAMiapF1xsGfWTiaiaYvXlA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=13" data-ratio="0.7287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528610" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/8615898e-d89d-4ffa-b834-eb1e826a5eda/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;在线 A/B&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OneSug 模型目前已在快手电商搜索场景下全量推全。在 AB 实验中，OneSug 大幅度提高了 Ctr、订单和 GMV 等指标，同时人工测评 GSB 指标也有很大幅度的提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFucwZxSdrKpXao5icgXAF18MLMVoq5ZMke7hlCRBZGHowmGIuXSAMRiaQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=14" data-ratio="0.24351851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528611" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/3807bce8-9fd2-4db4-b0ee-98d570684025/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFCBVxBLPianMiamtREaaX4jwMibdbYqQvSJzZX4kWYA7Xl0MDlLe7kQYMw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=15" data-ratio="0.25833333333333336" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528613" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/fda3195c-f995-404e-a063-b2fe3a6d2195/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;在线推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;线上流程完全取代了召回 - 粗排 - 精排，使平均耗时降低了 43.2%，为后续优化提供了充足的空间。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFUdlJYpcibMnwNaz9XibdykPbQmhRfYqJc7FenMsvYO7rI6UJfFQ7lD2A/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=16" data-ratio="0.29907407407407405" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528615" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/2c0b5b8b-7726-40d4-bdb3-63335dccfeb1/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OneSug 是业界首个在电商场景中实现全流量部署的端到端生成式 Query 推荐系统，其统一建模方式显著提升了语义理解与个性化推荐的能力，为生成式模型在搜广推的落地提供了新范式。&lt;/p&gt;&lt;p&gt;未来，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;快手&lt;/span&gt;将进一步探索大语言模型在排序阶段的强化学习优化、实时更新等方向，持续推动端到端生成式系统在推荐、广告等多业务场景中的广泛应用。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>咖啡机变聪明后，我连咖啡都喝不上了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:50:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Sia&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;section&gt;目前还没有人真正解决这个问题：如何让 LLM 知道什么时候该精确、什么时候可以随机。&lt;/section&gt;&lt;/blockquote&gt;&lt;p data-pm-slice="0 0 []"&gt;这真是一个让人当场破防的早晨。&lt;/p&gt;&lt;p&gt;一位 The Verge 的科技记者起床、走进厨房、对着支持 Alexa 的博世咖啡机说了句，煮杯咖啡。&lt;/p&gt;&lt;p&gt;没有即兴发挥，也没提什么复杂要求，她只是希望机器老老实实执行一个早就设好的程序，结果，被拒绝了。&lt;/p&gt;&lt;p&gt;而且不是一次。&lt;/p&gt;&lt;p&gt;自从升级到 Alexa Plus（亚马逊的生成式 AI 语音助手）之后，这种对话几乎成了她的晨间固定项目。&lt;/p&gt;&lt;p&gt;每一次要它煮咖啡，Alexa 都能给出不同理由，以惊人的创造力告诉你，不行。&lt;/p&gt;&lt;p&gt;&lt;img alt="58 个梗图点子| 幽默, 搞笑, 迷因" data-aistatus="1" data-backh="229" data-backw="236" data-imgfileid="503525832" data-ratio="0.9703389830508474" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrOg05AAm5TMAVSnoU8227QfUMeibIdxVNv1mUnAXPxicbicUXMaoZn3ppg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="236" data-original-style="width: 259px;height: 251px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b60d4185-d146-49fb-a0ec-8077d05daa21/640.png" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/p&gt;&lt;p&gt;2025 年都快过去了，AI 会写论文、会写代码、会陪人聊天、会教书，却在清晨败给了一句&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;煮杯咖啡&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;在社区讨论中，类似吐槽场面非常壮观，可谓怨声载道。&lt;/p&gt;&lt;p&gt;开灯这个事儿，完全成了重灾区。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="225" data-backw="578" data-imgfileid="503525833" data-ratio="0.3895131086142322" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrtQmxicjhoOZ5ScCqJKGRSwtUVUqxmF6Rn6UCUbLzUR009Mic9sGPwofA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="801" type="block" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9eadcde3-3cbd-4f1d-83ac-8a90576d0ef8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrbsbDFaicYzYamX105u1icGYwSQljM33TNgznZZqM10gT8U1xX5icNDsXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5131086142322098" data-type="png" data-w="801" data-width="801" data-height="411" data-backw="562" data-backh="288" data-imgfileid="503525817" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/efdf8f11-258e-469d-a8dc-6e7a59140f88/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="286" data-backw="562" data-height="453" data-imgfileid="503525820" data-ratio="0.5084175084175084" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrgX6ibqlosK907iaCIgdBbk8ABlc7ib2P2ViakUuu405QfMbrux18fwgCpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="891" data-width="891" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/024e96c0-27c4-491a-b905-98d89f59aefb/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr3UG3Argc2sKHNM2DGkhBqe5YLOzgEVkEHr73eWkBBBNPGicfA1tBkkA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.12222222222222222" data-type="png" data-w="1080" data-width="1128" data-height="138" data-backw="562" data-backh="69" data-imgfileid="503525818" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a311f228-643c-4362-8aec-6261d9e92be4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="278" data-backw="562" data-height="510" data-imgfileid="503525823" data-ratio="0.4941860465116279" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrMC3Wq7XKkb7ktz3icnpk6Qyk2d6nkiatTrEBNCgWYyzvCnvGhJCC6qEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1032" data-width="1032" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1cb4b4af-351e-4aec-b55e-07a23756a93b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="70" data-backw="562" data-height="141" data-imgfileid="503525821" data-ratio="0.12407407407407407" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrVPAvQrib9j6gQsxKRjXWwiaw5Adk325d2aTsgXxDRe7INSyD38gqp0tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-type="png" data-w="1080" data-width="1134" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ec10f489-fafd-4cb0-bd43-53ebb547ddf5/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;播放歌曲也是艰难。&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="127" data-backw="562" data-height="243" data-imgfileid="503525819" data-ratio="0.22562674094707522" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrsGh85LiaQNcl9iaoIeyx2g1TflMFd7LVfoibibclETaY1QCnBN6qB2WkVQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1077" data-width="1077" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7ab0151d-d713-475e-8a22-4bb3ea6bce01/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;定个时也这么难了啊。&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="72" data-backw="562" data-height="144" data-imgfileid="503525816" data-ratio="0.1287037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrSuBKq1rbLq1FL3QfwrI6NMpGRa0nbGbfU2tFY1XRTAnc13J2zltdRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="1080" data-width="1116" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/8754d53c-d337-4645-a30e-15b06dca65aa/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;彻底心灰意冷的也有。&lt;/p&gt;&lt;p&gt;&lt;img data-aistatus="1" data-backh="61" data-backw="578" data-imgfileid="503525866" data-ratio="0.10555555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrf7AauzZZCVsjUlRfiayWR8GIWldK6xSnv1mfh5mlU98h4KHmn94u9PA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" type="block" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9e739da4-2121-48bf-950f-cde94939cabe/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;显然，现实与大家对 AI 的直觉预期，构成了鲜明反差。&lt;/p&gt;&lt;p&gt;传统助手虽然笨吧，但高度确定，只要你把（有点傻的）&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;咒语&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;念对，结果总是可以预期的。&lt;/p&gt;&lt;p&gt;现在好了，以 LLM 为核心的生成式AI助手，智商是高了，理解是深了，表达是丰富了，却偏偏在它们原本最擅长的事情上频频翻车：&lt;/p&gt;&lt;p&gt;开灯、设定计时器、播报天气、播放音乐、运行 Routine。&lt;/p&gt;&lt;p&gt;&lt;img alt="港產片｜這些經典對白梗圖你知道出處嗎？ | 影視時尚| 潮遊生活| 當代中國" data-aistatus="1" data-backh="317" data-backw="562" data-imgfileid="503525868" data-ratio="0.5635416666666667" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr06ywibZXIziczXneOAWJnxEIR4n4mom6rhuKBc4Ae4LZzGLkOiav3TYYg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-type="jpeg" data-w="960" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/ad4dd05d-8c58-4b7b-806f-44fe6c80113e/640.png" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;为什么会这样？&lt;/p&gt;&lt;p&gt;因为，LLM 天生引入了大量随机性。它能理解更多含义，也允许更自由的表达，但代价是：解释空间被极大放大了，包括误解的可能性。&lt;/p&gt;&lt;p&gt;你向 ChatGPT 提出同一个问题，今天和明天得到不同答案，这正是它的价值所在。但当这种特性被用于控制一台咖啡机时，就有问题了。&lt;/p&gt;&lt;p&gt;在要求即时、可重复、零容错的控制场景下谈概率，本身就是一个大 bug。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-height="192" data-imgfileid="503525822" data-ratio="0.17037037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrVdUeqfe45qhxAXfZPNwEPViarwVPxp5awMNiaBzZ6NKQJ7W9I858NP8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" data-width="1125" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/657530c7-7b33-4480-b710-dceed29393d9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;相比之下，传统语音助手的本质，其实是模板匹配器。它们并不理解，只是识别关键词，然后填参数。&lt;/p&gt;&lt;p&gt;比如你说&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;播放广播&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;，系统非常清楚，后面只可能跟&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;电台名称&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;为了弥补生成式模型在确定性上的短板，亚马逊和谷歌都尝试将 LLM 与智能家居 API 深度绑定。但这又引入了新的问题。&lt;/p&gt;&lt;p&gt;LLM 确实不擅长在每一次请求中，都生成完全一致、语法严格正确的系统调用。&lt;/p&gt;&lt;p&gt;而当它们被要求直接生成 API 调用、去控制真实设备时&amp;mdash;&amp;mdash;哪怕是一个极小的偏差，都可能导致整个操作失败。&lt;/p&gt;&lt;p&gt;这正是为什么，你的咖啡机有时就是死活不肯给你做咖啡。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="200" data-backw="562" data-height="399" data-imgfileid="503525824" data-ratio="0.35555555555555557" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrJQ4ElmQgLsTjqakGgvMaAXytcC8bUWcQq0aIKfSXcqFDss44aooZcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" data-width="1122" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/35ab64d9-397b-4c44-a6aa-23c5281afd4f/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;理论上，让新助手达到旧助手那样的可靠性，并非不可能，但这需要极其大量的工程投入、约束设计和失败兜底。&lt;/p&gt;&lt;p&gt;而在资源有限、 &lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;做点更刺激、也更赚钱的事情&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;诱惑又足够大的现实里， 最简单的路径就是先把技术推到现实世界中，再让它慢慢自我修正。&lt;/p&gt;&lt;p&gt;换句话说，我们正在集体扮演一个角色：AI 的长期内测用户。&lt;/p&gt;&lt;p&gt;目前还没有人真正解决&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;如何让 LLM 知道什么时候该精确、什么时候可以随机&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;的问题。所以，大家可能要在相当长的一段时间里，不断和它较劲、和血压搏斗。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="204" data-backw="350" data-imgfileid="503525934" data-ratio="0.5828571428571429" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvruvgz6GGT4RpoYZMtJBxK7eEaUGstLxeFVHPLhln9bJh3ib75aStxssA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=14" data-type="gif" data-w="350" type="block" data-original-style="width:441px;height:257px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/b2fd925a-05e3-446e-897e-f30323866f0c/640.gif" data-order="0" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;既然如此，为什么还要坚定地抛弃旧技术？&lt;/p&gt;&lt;p&gt;两个字：潜力。&lt;/p&gt;&lt;p&gt;所谓的代理式 AI（Agentic AI），让系统具备服务链式调用的能力：它能够理解复杂任务之间的内在关系，并在此基础上动态生成执行逻辑。&lt;/p&gt;&lt;p&gt;这也是旧技术路线必须被放弃的根本原因。&lt;/p&gt;&lt;p&gt;过去，基于固定规则与关键词匹配的语音系统，在架构层面就被限定为&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31);font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif;font-size: 15px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-align: start;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;display: inline !important;float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「&lt;/span&gt;&lt;/span&gt;单指令执行器&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt;，它们无法理解目标、拆解任务，更不可能在运行时生成新的行动路径。&lt;/p&gt;&lt;p&gt;这不是一次简单的技术升级，而是一次能力范式的切换。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="300" data-backw="300" data-imgfileid="503525933" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrWHLXEvlPETpaxh3nHll3vRDJUgibc6ROeLKFfjyVkK2dw4ZzuLZTMTA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=15" data-type="gif" data-w="300" type="block" data-original-style="width:378px;height:378px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/4b615278-c574-4d08-b93e-beef9648b7da/640.gif" data-order="1" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;回到社区舆论，虽然连最基本的指令都出错，但网友们也承认，升级后的语音助手在理解复杂命令这件事上，确实更强了。&lt;/p&gt;&lt;p&gt;比如你说，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;这里调暗一点，温度再高一点。&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt; 它可以同时调灯和调恒温器。&lt;/p&gt;&lt;p&gt;当质问&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;Alexa，你到底在干嘛？为什么不关掉我的音乐？！&lt;span data-pm-slice="0 0 []"&gt;」&lt;/span&gt; 它真的会去查一下发生了什么。&lt;/p&gt;&lt;p&gt;放在过去，这些都是不可想象的。&lt;/p&gt;&lt;p&gt;最为人称道的是是摄像头通知功能的变化。&lt;/p&gt;&lt;p&gt;传统系统往往只有一句高度概括的废话，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;后院检测到运动。&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;于是你不得不：打开 App &amp;rarr; 点开视频 &amp;rarr; 回看 &amp;rarr; 发现是一只猫。&lt;/p&gt;&lt;p&gt;现在，新系统会直接告诉你，&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;门口出现了不熟悉的面孔，但没有进入院子。&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;用语音设置复杂 Routine，也确实比在 Alexa App 里一层层点设置来得轻松，哪怕这些 Routine 运行起来并不那么稳定。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="512" data-backw="512" data-imgfileid="503525935" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr1ZRhMQelUklrxZnk6zad4ZsvV160PgTzH9I6ib06lkbnyAdevEEQL1g/640?wx_fmt=gif&amp;from=appmsg#imgIndex=16" data-type="gif" data-w="512" type="block" data-original-style="width:435px;height:435px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/6cddca10-f848-49f4-a9c3-5d789ec1290e/640.gif" data-order="2" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在大量用户讨论中，也逐渐形成了一个相对温和的共识：问题不在于是否引入 AI，而在于&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;边界&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;、是否试图用 AI 替代一切。&lt;/p&gt;&lt;p&gt;一些用户认为，更合理的方向不是&lt;span data-pm-slice="0 0 []"&gt;「&lt;/span&gt;去按钮化&lt;span data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"node",{"tagName":"span","attributes":{"style":"color: rgb(25, 27, 31); font-family: -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"PingFang SC\", \"Microsoft YaHei\", \"Source Han Sans SC\", \"Noto Sans CJK SC\", \"WenQuanYi Micro Hei\", \"MiSans L3\", \"Segoe UI\", sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;  background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;&lt;/span&gt;&amp;mdash;&amp;mdash;取代那些已经被验证过的、确定性的执行机制，而是让 AI 帮助人理解系统。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="148" data-backw="562" data-height="303" data-imgfileid="503525825" data-ratio="0.2638888888888889" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrib6tLj2YEiaj1DIyHRoDgibM80cvKr08BeYDllNbnIPrqrpYnC9nuQWcA/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-type="png" data-w="1080" data-width="1149" data-original-style="width: 100%;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/05ec9e55-444b-423b-8a36-8c4c8566188c/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当前出现的混乱，或许并不是生成式 AI 的失败，而是其被放置在了一个并不适合它的核心位置。&lt;/p&gt;&lt;p&gt;不过，至少在今天，这条清醒的边界远未被勾勒出来，也不知什么时候能被画出来。&lt;/p&gt;&lt;p data-end="237" data-pm-slice="0 0 []" data-start="205"&gt;那么，你的智能家具还好吗？有没有过类似的抓狂瞬间？欢迎来评论区唠唠。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theverge.com/tech/845958/ai-smart-home-broken&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/technology/comments/1pvh1c8/how_ai_broke_the_smart_home_in_2025_the_arrival/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>AAAI 2026｜相聚新加坡，探讨AI时代最核心难题</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:45:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;活动 1&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题：在 AI 重构人类主体性的时代，如何捍卫我们的自主决断权？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在人工智能潜移默化地重构人类能动性 (Human Agency) 的当下，我们该如何保留有意义的人类自主决断权？&lt;/p&gt;&lt;p&gt;诚邀您参加由 AI Singapore 主办的「&lt;strong&gt;工作、学习、拥有与选择的权利&amp;rdquo; (The Right to Work, Learn, Own &amp;amp; Choose)&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;研讨会。本次会议旨在探讨技术型 AI 社区与 AI 治理社区如何深度融合，共同推动尊重人类主体性，并维护我们在工作、学习、所有权及选择权方面权益的 AI 系统发展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFZAFDCG3BZRSTRfD33ovjVzmAoHEDFuIn01qyYJvLP3UIwTFIIAFaicQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.4148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528551" data-aistatus="1" data-original-style="width:523px;height:740px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/dd72b408-a8c8-48b3-a83d-8a0e0515b55a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;本次研讨会邀请了多位重量级嘉宾，包括 Ashok Goel (佐治亚理工学院)、Jungpil Hahn (新加坡国立大学计算机学院)、Luke Zettlemoyer (华盛顿大学 &amp;amp; Meta FAIR) 以及 Djallel Bouneffouf (IBM 研究院)。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF0pJVKg7kn3nbPrG3HaynUdelpa18xX4YYUItLnKM8Ep7Wia8QkWjG3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.4148148148148147" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528552" data-aistatus="1" data-original-style="width:535px;height:757px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/5f2f70bd-7228-43ee-b26a-c35b6047497f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;会议详情： &lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;日期： 2026 年 1 月 23 日（星期五）&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;时间： 08:30 - 13:30&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;地点： 新加坡国立大学 COM3 多功能厅 (11 Research Link, Singapore 119391)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现场将提供午餐及茶点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注册链接：&lt;/strong&gt; https://luma.com/xyon5cw4 (截止日期：2026 年 1 月 22 日)&lt;/p&gt;&lt;p&gt;主办方将发送确认邮件以确认您的名额。&lt;/p&gt;&lt;p&gt;注：本次活动是新加坡 AI 研究周 (Singapore AI Research Week) 的一部分，与 AAAI2026 同期举行。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动 2&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主题：探索 Agentic AI、自主智能体与多智能体系统的前沿融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;想要了解基于大语言模型 (LLM) 的智能体的前沿进展，以及构建和部署这些系统的经验教训吗？&lt;/p&gt;&lt;p&gt;诚邀您参加由新加坡国立大学人工智能研究所 (NAII)、DSO 国家实验室与亚马逊云科技 (AWS) 联合举办的专题研讨会：「&lt;strong&gt;Agentic AI meets Autonomous Agents and Multiagent Systems。&lt;/strong&gt;」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF8SMH1Pv1IY1ZxficxiaaKz2Dt6VIxwBKq1IXwzWxneQSYyHzInWtROfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.413888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528553" data-aistatus="1" data-original-style="width:498px;height:704px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/59d7d801-f6d3-42d3-aee9-78f3b53480f7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;现代 &amp;quot;Agentic AI&amp;quot; 系统（例如 LLM 驱动的智能体、使用工具的 Copilot 以及自主工作流）正从精心编排的演示 (Demos) 走向实际部署。这一转变要求系统具备长程规划能力、可靠的工具使用能力，以及与人类和环境进行稳健交互的能力。&lt;/p&gt;&lt;p&gt;本次研讨会不仅关注当下的 Agentic AI，更将其作为审视机器人学、具身智能 (Embodied AI) 以及多智能体系统 (Multiagent Systems) 中长期挑战的透镜。通过连接这些视角，我们旨在发掘共同面临的开放性问题，并激发跨领域合作，推动 Agentic AI 向更可靠、安全和高性能的方向发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;特邀演讲嘉宾：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Leslie Kaelbling (麻省理工学院 MIT)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Bo Li (伊利诺伊大学香槟分校 UIUC)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Pang Wei Koh (华盛顿大学 &amp;amp; Ai2)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Frank Dignum (瑞典于默奥大学)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFic38EMfO6tsEZX1EOKGJ1dGnx95FBbUrM9U1lQBpXUPHkCCZe1WqBWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.413888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528554" data-aistatus="1" data-original-style="width:500px;height:707px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4fd8ee4a-d22b-4505-a07e-d2dd2d7f6844/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;活动详情：&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;日期： 2026 年 1 月 21 日（星期三）&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;时间： 13:00 - 18:00&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;地点： 新加坡国立大学 COM3 多功能厅 (11 Research Link, Singapore 119391)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现场将提供茶点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;立即注册&lt;/strong&gt;： https://luma.com/9hz1jyvg&lt;/p&gt;&lt;p&gt;主办方将发送确认邮件以确认您的名额。&lt;/p&gt;&lt;p&gt;注：本次活动是新加坡 AI 研究周 (Singapore AI Research Week) 的一部分，与 AAAI2026 同期举行。&lt;/p&gt;&lt;p&gt;以上邀请是 &amp;ldquo;on behalf of 新国立副校长 Bryan Low &amp;nbsp;,助理教授 刘钿渤 &amp;rdquo;。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谷歌工程师抛出5个残酷问题：未来两年，软件工程还剩下什么？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:42:12 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;软件行业正站在一个颇为微妙的拐点上。AI 已经从自动补全代码，演进为能够自主执行开发任务的智能体。&lt;/p&gt;&lt;p&gt;在这一变化之下，初级开发者和高级开发者正同时被推入各自不同、却同样棘手的困境之中。&lt;/p&gt;&lt;p&gt;对初级开发者而言，最大的挑战不在于会不会写代码，而在于还没来得及成长，练级空间就被压缩了。企业不再愿意为学习成本买单，初级岗位要么减少，要么被要求一上来就能独立产出。&lt;/p&gt;&lt;p&gt;而对高级开发者来说，处境同样不好过。AI 并没有让他们更轻松，而是让责任进一步集中。当团队规模缩小、初级人手减少，高级工程师往往既要做架构决策，又要兜底 AI 和自动化系统带来的各种隐性风险，代码质量、性能、安全、合规。写代码的比例在下降，但判断、评审和决策的压力却在上升，一旦系统出问题，责任仍然落在人身上。&lt;/p&gt;&lt;p&gt;接下来会发生什么，充满了不确定性。&lt;/p&gt;&lt;p&gt;Addy Osmani，来自谷歌的一名软件工程师，在一篇文章中提出了 5 个可能在 2026 年前重塑软件工程的关键问题，并为每个问题给出两种截然不同的走向。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="399" data-imgfileid="503528238" data-ratio="0.3453703703703704" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaiczH3BljB58qB12ATwIAHhVjuyFBWSghCgia6xgZwZlCUXhGXbgg6td0w/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1154" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/abc09958-2bd4-4bc7-8c6d-a5ec751cc27d/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;文章链接：https://addyosmani.com/blog/next-two-years/&lt;/p&gt;&lt;p&gt;这五个问题都指向同一件事，软件工程正在从写代码的职业，转变为驾驭复杂系统与 AI 的职业。未来不是单一答案，而是多种路径并存，谁能适应变化，谁就能留下来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;初级开发者之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;结论很直接：随着 AI 开始自动化入门级任务，初级开发者的招聘可能会出现崩塌；也可能随着软件渗透到几乎所有行业而重新反弹。这两种未来都存在，但对应的生存策略完全不同。&lt;/p&gt;&lt;p&gt;像传统路径，学会编程、拿到初级岗位、逐步成长为高级工程师正在动摇。一项覆盖 6200 万名劳动者的哈佛研究发现，当企业采用生成式 AI 后，在六个季度内，初级开发者的就业人数下降了大约 9%&amp;ndash;10%，而高级开发者的就业几乎没有变化。过去三年，大型科技公司招聘的应届毕业生数量减少了 50%。正如一位工程师略带讽刺地说：既然一个 AI 编码智能体的成本更低，为什么还要花 9 万美元去雇一个初级工程师？&lt;/p&gt;&lt;p&gt;这并不只是 AI 的问题。像利率上升等宏观因素，在 2022 年左右就已出现影响，那时 AI 工具还未大规模普及。但 AI 加速了这一趋势。如今，一名配备 AI 辅助的高级工程师，产出已经相当于过去一个小团队的工作量。相比裁员，许多公司更常见的做法是悄悄地不再招聘初级开发者。&lt;/p&gt;&lt;p&gt;反过来的情景是：AI 在所有行业，而不仅仅是科技行业，释放出对开发者的巨大需求。医疗、农业、制造业、金融业都开始大规模嵌入软件和自动化。AI 不是取代开发者，而是成为一种放大器，把开发工作扩展到过去几乎不雇程序员的领域。初级岗位会更多出现，但形式不同：那些能快速为特定细分场景构建自动化和集成方案的 AI 原生开发者。&lt;/p&gt;&lt;p&gt;美国劳工统计局预计，2024 年到 2034 年间，软件相关岗位将增长约 15%。如果企业选择用 AI 来扩大产出，而不是单纯压缩人力规模，它们仍然需要人类去把握 AI 创造的新机会。&lt;/p&gt;&lt;p&gt;但悲观情景的一个长期风险常常被忽视：今天的初级开发者，就是 5 到 10 年后的高级工程师和技术领导者。如果完全切断人才培养管道，最终会造成领导力真空。行业老兵将这种现象称为缓慢衰退，一个停止培养接班人的生态系统。&lt;/p&gt;&lt;p&gt;如何应对？&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要让自己具备 AI 使用能力并保持多面性。证明一名初级开发者 + AI 的组合，能够匹配一个小团队的产出。使用 AI 编码智能体（如 Cursor、Antigravity、Claude Code、Gemini CLI）来构建更大的功能模块，但要理解并能解释其中的每一行代码，至少是大部分代码。把重心放在 AI 不容易替代的能力上：沟通能力、问题拆解能力、领域知识。将相邻岗位（如 QA、开发者关系、数据分析）视为切入口。建立作品集，尤其是包含 AI API 集成的项目。考虑学徒制、实习、合同制工作或参与开源项目。不要成为又一个需要大量培训的应届生，而要成为一个能够立刻产生价值、并且学习速度很快的工程师。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，初级人员减少意味着更多基础性工作会落到自己身上。要用自动化来应对日常事务，但不要什么都自己做。搭建 CI/CD、代码规范检查工具以及 AI 辅助测试，以捕捉基础问题。通过开源项目或辅导其他部门的同事，进行非正式的指导。如果未来初级岗位需求回升，要准备好高效地进行入职引导，并以结合 AI 的方式进行任务分配。你的价值不在于自己写了多少代码，而在于放大整个团队的产出。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528242" data-ratio="0.5895765472312704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicPgNrXjoliaeCr6aXeuCPkDmqD7qWnmSPm7zUSRbl57AQATosCkZmC3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="921" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ef33c45d-7e16-4101-b86a-fd474139c8b0/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;技能之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：当 AI 编写了大部分代码之后，编程基本功要么会逐渐退化，要么会因为人类开发者转向监督与把关而变得比以往任何时候都更重要。接下来的几年，将决定我们究竟是用理解力换速度，还是在效率提升的同时守住理解。&lt;/p&gt;&lt;p&gt;如今，已有 84% 的开发者在日常工作中经常使用 AI 辅助。对许多人来说，面对一个 Bug 或新功能时的第一反应，不再是从零开始写代码，而是先写一个提示词，把 AI 生成的代码片段拼接起来。入门级开发者正在跳过最难的那条路：他们可能从未亲手实现过一棵二叉搜索树，也从未独立排查过一次内存泄漏。&lt;/p&gt;&lt;p&gt;技能结构正在发生迁移：从实现算法，转向知道如何向 AI 提出正确的问题，并验证它的输出。职业阶梯的第一步，不再要求展示纯粹的编码能力，而是能够熟练地提示 AI、校验结果。一些资深工程师担心，这会催生出一代无法独立高质量写代码的开发者，一种事实上的去技能化。而 AI 生成的代码往往会引入隐蔽的 Bug 和安全漏洞，经验不足的开发者很容易忽略这些问题。&lt;/p&gt;&lt;p&gt;另一种对立的情景是：当 AI 处理掉 80% 的常规工作后，人类将专注于最困难的那 20%。架构设计、复杂集成、创造性设计、边界情况 &amp;mdash;&amp;mdash; 这些仍然是机器单独难以解决的问题。AI 的普及并不会让深度知识过时，反而会让人类专家的价值更加凸显。这正是高杠杆工程师：他们把 AI 当作放大器，但必须对系统有深入理解，才能真正驾驭它。&lt;/p&gt;&lt;p&gt;如果每个人都能使用 AI 编码智能体，真正区分优秀开发者的，是能否判断 AI 何时是错误的，或次优的。一位资深工程师曾这样说过：最好的软件工程师，不是写代码最快的人，而是最清楚什么时候不该相信 AI 的人。&lt;/p&gt;&lt;p&gt;编程工作的重心正在转移：更少时间用来敲模板代码，更多时间用来审查 AI 输出是否存在逻辑错误、安全缺陷，或与需求不匹配的问题。关键能力逐渐变成软件架构、系统设计、性能调优和安全分析。AI 可以很快生成一个 Web 应用，但只有经验丰富的工程师，才能确保它遵循了安全最佳实践，没有引入竞态条件。&lt;/p&gt;&lt;p&gt;在 2025 年，开发者社区的讨论明显分裂。一些人坦言自己几乎不再手写代码，认为面试和考核方式也应该随之演进；另一些人则认为，跳过基础训练会导致在 AI 输出失效时陷入更频繁、更痛苦的救火。整个行业开始期待工程师同时具备两种能力：AI 带来的速度，以及支撑质量的基础智慧。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要把 AI 当作学习工具，而不是拐杖。当 AI 编码智能体（如 Cursor、Antigravity、Claude Code、Gemini CLI）给出代码时，主动复盘它为什么能工作、哪里可能存在问题。偶尔关闭 AI 辅助，亲手实现关键算法。优先夯实计算机科学基础：数据结构、算法、复杂度分析、内存管理。一个项目可以做两遍，一遍借助 AI，一遍不借助 AI，对比差异。学习提示词工程和工具使用技巧。同时训练严谨的测试习惯：编写单元测试，在不立刻求助 AI 的情况下阅读堆栈信息，熟练使用调试器。深化 AI 难以复制的互补能力：系统设计、用户体验直觉、并发问题的推理能力。向外界证明，你既能借助 AI 高效产出，也能在它失效时解决棘手问题。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要将自己定位为质量与复杂性的守门人。持续打磨核心专长：架构、安全、可扩展性以及领域知识。练习在系统中引入 AI 组件时的整体建模，并提前思考失败模式。持续关注 AI 生成代码中暴露出的新型漏洞。主动承担导师和评审者的角色，明确哪些场景可以使用 AI，哪些场景必须人工审查（例如支付或安全相关代码）。把精力更多放在创造性和战略性工作上，让初级开发者 + AI 的组合去处理常规的 API 对接，而你来决定应该构建哪些 API。投资软技能和跨领域知识，持续跟进新工具和最佳实践。最终，进一步强化那些让人类开发者不可替代的能力：稳健的判断力、系统级思考，以及培养他人的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528243" data-ratio="0.6175925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8aNpw3cnGzHxwGIt0DZ2iaicfIzSfXLNBHxg6YrSL2VuNkCFJrdHAuib940tYnYlqiaDYBgmWHic2ILiaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cb39a5be-5ca3-4655-9ece-519525cececc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;角色之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：开发者这一角色，可能会收缩为一种有限的审计岗位（主要负责监督 AI 生成的代码），也可能扩展为一个关键性的编排者角色，负责设计和治理由 AI 驱动的系统。无论走向哪一种未来，创造价值都不再只是写代码本身。&lt;/p&gt;&lt;p&gt;这里的两种极端非常鲜明。在其中一种设想中，开发者的创造性职责被明显削弱。他们不再真正构建软件，而是主要负责审计和看护 AI 的输出。AI 系统承担实际生产；人类开发者检查自动生成的代码，查找错误、偏见或安全问题，并批准部署。创造者变成了检查者，写代码的乐趣被风险管理的焦虑所取代。&lt;/p&gt;&lt;p&gt;已经有报道称，一些工程师花在评估 AI 生成的 pull request 和管理自动化流水线上的时间越来越多，而从零开始写代码的时间却越来越少。编程逐渐不像是一种创造性的问题求解，更像是一种合规性工作。一位工程师曾无奈地感叹：我不想最后变成一个代码清洁工，只是收拾 AI 扔过来的烂摊子。&lt;/p&gt;&lt;p&gt;另一种未来则要有意思得多：开发者进化为高层次的编排者，融合技术、战略与伦理责任。随着 AI 工人的出现，人类开发者承担起类似架构师或总承包商的角色，负责设计整体系统，决定哪些任务交给哪一个 AI 或软件组件，并将众多运转中的部件编织成一个完整方案。&lt;/p&gt;&lt;p&gt;一位低代码平台的 CEO 曾这样描述这一愿景：在 Agentic 的开发环境中，工程师会成为作曲家，指挥由多个 AI 智能体和软件服务组成的合奏。他们不会亲自写下每一个音符，但会定义旋律 &amp;mdash;&amp;mdash; 系统架构、接口，以及各个智能体如何交互。这个角色本身具有跨学科和创造性：既是软件工程师，又是系统架构师，同时还是产品战略制定者。&lt;/p&gt;&lt;p&gt;更乐观的看法是：当 AI 接管重复性劳动后，开发者的角色将被迫转向更高价值的活动。工作本身反而可能变得更有意思。总得有人决定 AI 应该构建什么，验证产品是否合理，并不断对其进行改进。&lt;/p&gt;&lt;p&gt;最终走向哪一条路，很大程度上取决于组织如何选择整合 AI。把 AI 视为劳动力替代品的公司，可能会缩减开发团队规模，让留下来的工程师负责维持自动化系统运转；而把 AI 当作团队放大器的公司，则可能保持相近的人员规模，但让每位工程师承担更宏大的项目。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要主动寻找不只是写代码的机会。可以自愿参与测试用例编写、CI 流水线搭建或应用监控等工作，这些能力都与审计者 / 看护者角色高度契合。同时，通过个人项目保持对创造性编码的热情，避免失去构建的乐趣。培养系统思维：学习各个组件如何通信，理解什么样的 API 才算设计良好。多阅读工程博客和系统设计案例。熟悉代码生成之外的 AI 与自动化工具，例如编排框架和 AI API。提升书面和口头沟通能力，写文档时假设读者是另一个人。向资深同事请教时，不只问我的代码能不能跑，而要问我是不是考虑到了该考虑的事情。为自己做好准备，成为验证者、设计者和沟通者，而不仅仅是写代码的人。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要主动拥抱领导力和架构层面的责任。塑造 AI 和初级成员遵循的标准与框架，制定代码质量清单和负责任使用 AI 的规范。持续关注 AI 生成软件在合规与安全方面的新问题。把重心放在系统设计和集成能力上，主动梳理跨服务的数据流并识别潜在失效点。熟练使用各种编排平台，如 Kubernetes、Airflow、无服务器框架以及智能体编排工具。进一步强化技术导师的角色：更多代码评审、设计讨论和技术规范输出。打磨快速评估他人（或 AI）代码并给出高层次反馈的能力。同时培养产品和业务意识，理解为什么要做某个功能，以及用户真正关心什么。可以旁听产品经理的工作，或参与用户反馈会议。通过原型开发、黑客松或前沿技术研究，保护并延续自己的创造热情。从写代码的人，进化为指挥全局的指挥家。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;专才还是通才之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：过于狭窄的专才，面临其细分领域被自动化或淘汰的风险；而在一个快速变化、深度融入 AI 的环境中，更受青睐的是 T 型工程师，既具备广泛的适应能力，又在一两个方向上有深度专长。&lt;/p&gt;&lt;p&gt;在模型、工具和框架不断兴衰更替的背景下，把整个职业生涯押注在单一技术栈上，风险越来越高。某个传统框架的专家，可能会突然发现，当新的 AI 工具几乎不需要人工干预就能处理那套技术时，自己的需求度迅速下降。那些只专注于某一个技术栈、某一个框架或某一个产品领域的开发者，可能一觉醒来就发现，这个领域正在衰退，甚至变得多余。&lt;/p&gt;&lt;p&gt;回想一下 COBOL 开发者、Flash 开发者，或那些在行业转向时未能及时转型的移动游戏引擎专家。不同之处在于，如今变化的速度更快。AI 自动化可以让某些编程任务变得极其简单，从根本上削弱那些围绕这些任务建立起来的岗位。一个只会做一件事的专家（比如精调 SQL 查询，或把 Photoshop 设计稿切成 HTML），可能会发现 AI 已经承担了其中 90% 的工作。&lt;/p&gt;&lt;p&gt;招聘市场总是在追逐最新的细分领域。几年前，云基础设施专家炙手可热；如今，AI/ML 工程师成为焦点。那些只深耕于昨日技术的人，往往会在该领域失去吸引力时陷入停滞。&lt;/p&gt;&lt;p&gt;与此相对的是一种新的专业化形态：多面手式的专才，或者说 T 型开发者。他们在一到两个领域具备深度专长（纵向的一笔），同时对许多其他领域有广泛了解（横向的一笔）。这类工程师往往成为跨学科团队中的胶水，能够与不同方向的专家沟通，在需要时填补空白。&lt;/p&gt;&lt;p&gt;企业不再需要要么过于浅尝辄止、要么过度狭窄的开发者，而是希望工程师既有坚实的核心能力，又能在整个技术栈中协同工作。原因之一是效率：T 型工程师往往可以端到端解决问题，而不必等待频繁的交接；另一个原因是创新：不同领域知识的交叉，往往能催生更好的解决方案。&lt;/p&gt;&lt;p&gt;AI 工具实际上更能放大通才的能力，让一个人同时处理多个组件变得更加容易。后端工程师可以借助 AI 辅助生成可用的 UI；前端工程师也能让 AI 生成服务器端的样板代码。在一个 AI 高度充沛的环境中，人们可以更广泛地工作。相反，深度专才可能会发现自己的细分领域被部分自动化，却很难顺利横向扩展。&lt;/p&gt;&lt;p&gt;如今，接近 45% 的工程岗位都期望候选人具备多领域能力：比如既会编程，又懂云基础设施；或者以前端为主，但对机器学习有一定了解。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于初级开发者来说，要尽早打下宽广的基础。即便是因某个具体角色被录用，也要有意识地走出自己的竖井。如果你做移动端，就去学一些后端基础；如果你做前端，试着写一个简单的服务器。了解部署流程，熟悉 Docker、GitHub Actions 等工具。找出一两个真正让你产生兴趣的方向，持续深入，这将成为你的纵向专长。把自己定位成复合型角色，例如侧重云安全的全栈开发者，或具备 UX 专长的前端工程师。利用 AI 工具快速进入新领域：当你对后端还很陌生时，可以让 ChatGPT 生成入门级 API 代码并加以学习。培养持续再学习的习惯。通过黑客松或跨职能项目，强迫自己进入通才模式。主动告诉你的经理，你希望接触项目的不同部分。在职业早期，适应能力本身就是一种超能力。&lt;/p&gt;&lt;p&gt;对于高级开发者来说，要系统性地梳理自己的技能图谱：哪些领域是你的强项，哪些相邻领域只是浅尝辄止。选择一到两个相关方向，投入精力做到能对话、能上手。如果你是后端数据库专家，可以去熟悉一个现代前端框架，或学习机器学习流水线的基础。借助 AI 辅助，在自己薄弱的领域做一个小项目。把你的深度专长放到新的语境中：如果你擅长 Web 性能优化，就去探索这些能力如何应用到 ML 推理优化上。主动推动或设计更具跨职能属性的角色定位，争取成为多领域项目的整合负责人。在指导他人、扩散技能的同时，也从他们身上学习新东西。更新简历，突出你的多面性。利用经验识别可迁移的模式和知识。最终，成为 T 型工程师的榜样：在专长领域足够深入，带来权威和信任；同时不断横向延展自己的能力边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;教育之问&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;核心结论：计算机科学（CS）学位是否仍会是进入软件行业的黄金标准，还是会被更快的学习路径（训练营、在线平台、企业培训）所取代？在一个每隔几个月就发生变化的行业面前，大学可能越来越难跟上节奏。&lt;/p&gt;&lt;p&gt;长期以来，四年制计算机科学学位一直是进入软件岗位的主要通行证。但这一传统正在受到质疑。&lt;/p&gt;&lt;p&gt;其中一种未来是：大学仍然重要，但越来越难保持相关性。学位依然是默认的资质门槛，但课程内容落后于飞速变化的行业需求，受限于缓慢的课程更新周期和繁琐的审批流程。学生和雇主都会感觉，学术界与产业脱节，教授的要么是纯理论，要么是已经过时、无法直接转化为工作能力的实践。&lt;/p&gt;&lt;p&gt;许多应届毕业生表示，在整个本科学习期间，他们从未接触过云计算、现代 DevOps 或 AI 工具。如果大学要求学生投入高昂的时间和金钱，却提供低相关度的教育，就有可能被视为昂贵的看门人。但由于惯性，许多公司仍然要求学士学位，于是弥补技能差距的负担被转嫁给学生，他们不得不通过训练营、在线课程和自学项目来补齐短板。&lt;/p&gt;&lt;p&gt;企业每年要花费数十亿美元来培训新员工，因为毕业生并不具备职场所需的技能。大学可能会加一门 AI 伦理课，或开一门云计算选修课，但等到真正落地时，行业工具往往已经更新换代。&lt;/p&gt;&lt;p&gt;更具颠覆性的情景是：传统教育体系被越来越多的新系统所替代，编程训练营、在线认证、自学作品集，以及由雇主主导的培训学院。许多知名企业（如 Google、IBM）已经在部分技术岗位上取消了学历要求。到 2024 年，接近 45% 的公司计划在至少一部分岗位上取消学士学位门槛。&lt;/p&gt;&lt;p&gt;编程训练营本身也在成熟。它们培养出的毕业生，已经可以与科班 CS 毕业生一起进入顶级公司工作。这类项目周期更短（例如 12 周的高强度训练），重点放在实用技能上：当前流行的框架、云服务以及团队协作。招聘中的硬通货正在转向实时作品集、微证书和可验证技能。一份强有力的 GitHub 作品集或被认可的认证，已经可以绕过学位要求。&lt;/p&gt;&lt;p&gt;由雇主驱动的教育模式正在出现：公司建立自己的培训管道，或与训练营合作。一些大型科技公司已经为非传统背景的候选人开设了内部大学。AI 本身也带来了新的学习方式：AI 导师、交互式编程沙盒、个性化教学，使学习不再局限于大学校园。&lt;/p&gt;&lt;p&gt;一个模块化的学习生态，比昂贵的四年制学位更加普惠。一个身处缺乏优质 CS 大学国家的孩子，也可以修同样的 Coursera 课程，构建与硅谷学生同样水平的作品集。&lt;/p&gt;&lt;p&gt;如何应对：&lt;/p&gt;&lt;p&gt;对于有志或刚入行的开发者来说，如果你身处传统 CS 项目中，不要完全依赖它。用真实项目来补充课程：做一个 Web 应用，参与开源项目，争取实习或带薪实训。如果课程体系没有覆盖热门方向，就通过在线平台自学。获取行业认可的认证（如 GCP、AWS、Azure），向雇主证明你的实操能力。如果你是自学或来自训练营，重点打造有说服力的作品集，至少要有一个体量不小、文档完善的项目。积极参与开发者社区：贡献开源、撰写技术文章，通过 LinkedIn、线下聚会和开发者活动建立人脉。争取让一位有经验的开发者为你背书。持续学习，因为技术技能的半衰期很短。把 AI 当作你的私人导师，用作品集、认证以及对自己项目的清晰讲述来证明能力，这些都会为你打开机会之门。&lt;/p&gt;&lt;p&gt;对于资深开发者和管理者来说，单靠既有学历不会一直奏效。要持续投入学习：在线课程、研讨会、技术大会和认证。用新的方式验证自己的能力，做好准备应对以真实问题检验当前水平的面试。保持使用新技术的副项目。重新审视招聘要求：你真的需要新员工拥有 CS 学位，还是你真正需要的是某些技能和持续学习的能力？推动以技能为先的招聘方式，扩大人才池。支持内部培训项目或学徒制岗位，为没有传统背景的初级开发者搭建导师网络。积极与高校和替代教育体系互动：参与顾问委员会、做客座分享、反馈课程与行业需求之间的差距。也要在自身职业发展中体现这一点：真实世界的成果和持续学习，比再拿一个学位更重要。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://addyosmani.com/blog/next-two-years/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>红杉合伙人：2026，AGI已经来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 18 Jan 2026 20:39:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-18-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-18-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;我们常问：AGI 什么时候到来？你有没有想过，可能它已经来了。&lt;/p&gt;&lt;p&gt;最近，红杉资本合伙人 Pat Grady、Sonya Huang 联合发表了一篇博客，指出 AGI 已经到来，就在此刻。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528672" data-ratio="0.725925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFCb9l5v589m0Y81ebia13JeOtibXibWSjK3aNBPOx3ra84j0nH3ePMEHIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/afd414e8-a6bf-4682-b544-0616b4d22218/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在他们看来，AGI 不需要一个玄乎的技术定义 &amp;mdash;&amp;mdash; 它的本质就是「能把事情搞清楚的能力」。而以 Claude Code 为代表的长周期智能体，正是这种能力的第一批例证。&lt;/p&gt;&lt;p&gt;文中举了一个例子：一位创始人让智能体帮他找一个开发者关系负责人。智能体先在 LinkedIn 上搜索，发现职位头衔说明不了问题；于是转向 YouTube 找技术演讲，筛选出互动数据亮眼的演讲者；再与 Twitter 交叉比对，找出真正有品味、有粉丝的人；然后检查谁最近发帖变少了 &amp;mdash;&amp;mdash; 这往往意味着对现职的倦怠；最后锁定一位刚经历公司裁员、专业方向完全匹配的候选人，起草了一封精准的挖角邮件。&lt;/p&gt;&lt;p&gt;全程 31 分钟。 没有人告诉它该怎么做，它自己形成假设、验证、碰壁、转向，直到找到答案。这就是「把事情搞清楚」。而长周期智能体已经具备了这种能力。&lt;/p&gt;&lt;p&gt;更令人振奋的是，他们给出了一条清晰的指数曲线：长周期智能体的能力每 7 个月翻一番。按此推算，2028 年智能体能完成人类专家一天的工作，2034 年能完成一年的工作。&lt;/p&gt;&lt;p&gt;这意味着什么？&lt;strong&gt;你对 2030 年的梦想，2026 年就能实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个博客得到了一些从业者的认同。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528673" data-ratio="0.3907407407407407" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUF9cku6iahJjwuRcIgPfMDia7eOlLYLRLOrIFrgGoicqAI0n0CjtOBMcJ4g/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/10a8d6ba-6715-4659-84ae-ac10e10a3772/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528674" data-ratio="0.4583333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFAL8kGEiaibBjKzPWdAtJJHDa0bSRZtB2zic07TBfGjNqY5QbYI4DR9hog/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/14c409be-0b2f-4f91-b2d2-f65fbfc0c678/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但也有人认为其中忽略了一些东西，对于未来的预测过于乐观。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528675" data-ratio="1.0462962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFgH1QVx63ZMw8XWpIehXXA07TaB5A59hj0zq04lTjk3icOAZcQ8Lxl5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f319deac-c4f5-4bc7-8f02-c8f257b6e597/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528676" data-ratio="0.9481481481481482" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibicpeyvpwAFJZDoVSf4mxUFs1Crr1oxUCXwUkRBwX2jWIBfDML6RyIYezZAk1SXNqkcCkbOKpJEKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/dc2e73cf-3f1e-4dc0-9bf8-8f7ae39ff805/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;大家可以读完原文自行判断。&lt;/p&gt;&lt;p&gt;以下是博客内容：&lt;/p&gt;&lt;p&gt;几年前，一些顶尖研究者告诉我们，他们的目标是 AGI。我们急切地想听到一个清晰的定义，天真地问道：「你们如何定义 AGI？」他们顿了顿，彼此试探性地对视，然后给出了一个后来成为 AI 领域某种「箴言」的回答：「嗯，&lt;strong&gt;我们每个人都有自己的定义，但我们看到它的时候就会知道&lt;/strong&gt;。」&lt;/p&gt;&lt;p&gt;这段小插曲，正是我们追寻 AGI 具体定义之旅的缩影。这个定义始终难以捉摸。&lt;/p&gt;&lt;p&gt;然而，尽管定义难以捉摸，现实却并非如此。&lt;strong&gt;AGI 已经到来，就在此刻&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;编程智能体是第一个例证。更多案例正在涌现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长周期（long-horizon）智能体在功能上就是 AGI，而 2026 年将是它们的元年。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不受细节拖累&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在继续之前，有必要承认：我们没有资格提出 AGI 的技术定义。&lt;/p&gt;&lt;p&gt;我们是投资人。我们研究市场、创始人，以及两者碰撞的产物：商业。&lt;/p&gt;&lt;p&gt;因此，我们给出的是一个功能性定义，而非技术性定义。新的技术能力引出了 Don Valentine（红杉资本创始人、硅谷风险投资之父）的经典问题：So what？那又怎样？&lt;/p&gt;&lt;p&gt;答案在于现实世界的影响。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI 的功能性定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI 就是能把事情搞清楚的能力。就这么简单。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们深知，如此不精确的定义无法平息任何哲学争论。但从务实的角度来说，当你想完成某件事时，你想要什么？一个能把事情搞清楚的 AI。至于它是如何做到的，远不如它确实做到了来得重要。&lt;/p&gt;&lt;p&gt;一个能把事情搞清楚的人，拥有一定的基础知识、基于这些知识进行推理的能力，以及迭代找到答案的能力。&lt;/p&gt;&lt;p&gt;一个能把事情搞清楚的 AI，拥有一定的基础知识（预训练）、基于这些知识进行推理的能力（推理时计算），以及迭代找到答案的能力（长周期智能体）。&lt;/p&gt;&lt;p&gt;第一个要素（知识 / 预训练）推动了 2022 年 ChatGPT 横空出世的时刻。第二个要素（推理 / 推理时计算）随着 2024 年底 o1 的发布而到来。&lt;strong&gt;第三个要素（迭代 / 长周期智能体）则在过去几周内到来 &amp;mdash;&amp;mdash;Claude Code 和其他编程智能体跨越了一个能力门槛。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具有通用智能的人可以连续自主工作数小时，发现和修正自己的错误，无需被告知下一步该做什么就能自行判断。具有通用智能的智能体也能做到同样的事情。这是全新的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「把事情搞清楚」意味着什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一位创始人给他的智能体发消息：「我需要一个开发者关系负责人。技术能力要强到能赢得资深工程师的尊重，但又真正喜欢玩 Twitter。我们的客户是平台团队。去吧。」&lt;/p&gt;&lt;p&gt;智能体从显而易见的地方入手：在 LinkedIn 上搜索优秀开发者优先公司的「Developer Advocate」和「DevRel（高级开发者关系）」&amp;mdash;&amp;mdash;Datadog、Temporal、Langchain。找到了数百份简历。但职位头衔无法揭示谁真正擅长这份工作。&lt;/p&gt;&lt;p&gt;它转向寻找信号而非资历。它在 YouTube 上搜索技术大会演讲。找到了 50 多位演讲者，然后筛选出演讲互动数据亮眼的那些。&lt;/p&gt;&lt;p&gt;它将这些演讲者与 Twitter 进行交叉比对。一半人的账号不活跃，或者只是转发公司博客。这不是我们要的。但有十几个人拥有真正的粉丝群 &amp;mdash;&amp;mdash; 他们发表真实观点，与人互动，获得开发者的关注。而且他们的帖子很有品味。&lt;/p&gt;&lt;p&gt;智能体进一步缩小范围。它检查谁在过去三个月发帖频率下降。活跃度下降有时意味着对当前工作的倦怠。三个名字浮出水面。&lt;/p&gt;&lt;p&gt;它调研这三个人。一个刚宣布了新职位 &amp;mdash;&amp;mdash; 来晚了。一个是刚刚完成融资的公司创始人 &amp;mdash;&amp;mdash; 不会离开。第三位是一家 D 轮融资公司的 DevRel 人员，该公司刚刚在营销部门进行了裁员。她最近的演讲正好是关于这家创业公司所瞄准的平台工程领域。她有 1.4 万 Twitter 粉丝，发的梗图能让真正的工程师互动。她的 LinkedIn 两个月没更新了。&lt;/p&gt;&lt;p&gt;智能体起草了一封邮件，提到了她最近的演讲、与创业公司理想客户画像的重合度，以及关于小团队能提供的创作自由的具体说明。建议先随便聊聊，不是推销。&lt;/p&gt;&lt;p&gt;总耗时：31 分钟。创始人得到的不是挂在招聘网站上的一份 JD，而是一份只有一个人的候选名单。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这就是「把事情搞清楚」的含义。在模糊中导航以达成目标 &amp;mdash;&amp;mdash; 形成假设，验证假设，走进死胡同，然后转向，直到某些东西奏效。&lt;/strong&gt;智能体没有遵循脚本。它运行的是一位优秀招聘者脑中同样的循环，只不过它不知疲倦，31 分钟就完成了，且无需被告知如何做。&lt;/p&gt;&lt;p&gt;需要说明的是：&lt;strong&gt;智能体仍然会失败。它们会产生幻觉，丢失上下文，有时会信心满满地冲向完全错误的方向。但趋势是明确的，而且这些失败越来越可以被修复。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们是如何走到这一步的？从推理模型到长周期智能体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在去年的文章中，我们将推理模型描述为 AI 最重要的新前沿。长周期智能体将这一范式推进得更远，让模型能够采取行动并随时间迭代。&lt;/p&gt;&lt;p&gt;让模型思考更长时间并非易事。基础推理模型可以思考几秒或几分钟。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;两种不同的技术路径似乎都在奏效并能良好扩展：强化学习和智能体框架。&lt;/strong&gt;前者通过训练过程中的不断调整，从本质上教会模型保持更长时间的专注。后者则围绕模型的已知局限（记忆交接、压缩等）设计特定的脚手架。&lt;/p&gt;&lt;p&gt;扩展强化学习是研究实验室的领域。他们在这方面取得了非凡进展，从多智能体系统到可靠的工具使用。&lt;/p&gt;&lt;p&gt;设计优秀的智能体框架是应用层的领域。当今市场上一些最受欢迎的产品正是以其精心设计的智能体框架而闻名：Manus、Claude Code、Factory 的 Droids 等。&lt;/p&gt;&lt;p&gt;如果要押注一条指数曲线，那就是长周期智能体的性能曲线。METR 一直在细致追踪 AI 完成长周期任务的能力。进步速度呈指数级增长，大约每 7 个月翻一番。&lt;strong&gt;如果我们沿着这条指数曲线推算，到 2028 年，智能体应该能够可靠地完成人类专家需要一整天的任务；到 2034 年完成一整年的任务；到 2037 年完成一个世纪的任务。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那又怎样？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很快你就能「雇佣」一个智能体了。这是 AGI 的一个试金石。&lt;/p&gt;&lt;p&gt;你今天就可以「雇佣」GPT-5.2、Claude、Grok 或 Gemini。更多例子正在涌现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;医疗：OpenEvidence 的 Deep Consult 扮演专科医生&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;法律：Harvey 的智能体扮演律师助理&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;网络安全：XBOW 扮演渗透测试员&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;运维：Traversal 的智能体扮演 SRE&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;销售：Day AI 扮演业务开发代表、售前工程师和收入运营负责人&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;招聘：Juicebox 扮演招聘官&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数学：Harmonic 的 Aristotle 扮演数学家&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;芯片设计：Ricursive 的智能体扮演芯片设计师&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 研究：GPT-5.2 和 Claude 扮演 AI 研究员&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;从「说话者」到「行动者」：对创始人的启示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这对创始人有着深远的影响。&lt;/p&gt;&lt;p&gt;2023 和 2024 年的 AI 应用是「说话者」。有些是非常老练的对话者！但它们的影响力是有限的。&lt;/p&gt;&lt;p&gt;2026 和 2027 年的 AI 应用将是「行动者」。它们会给人同事的感觉。使用频率将从每天几次变成全天候、每一天，同时运行多个实例。用户不是这里省几个小时、那里省几个小时 &amp;mdash;&amp;mdash; 而是从作为个人贡献者工作，变成管理一个智能体团队。&lt;/p&gt;&lt;p&gt;还记得那些关于「出售工作成果」的讨论吗？现在这成为可能了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你能完成什么工作？&lt;/strong&gt;&amp;nbsp;长周期智能体的能力与模型的单次前向传播截然不同。在你的领域，长周期智能体能解锁哪些新能力？哪些任务需要持久性，哪些任务的瓶颈是持续的注意力？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你将如何把这些工作产品化？&lt;/strong&gt;&amp;nbsp;当工作的用户界面从聊天机器人演进到智能体委派时，你所在领域的应用界面将如何演变？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你能可靠地完成这些工作吗？ &lt;/strong&gt;你是否在痴迷地改进你的智能体框架？你是否有强大的反馈循环？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;你如何销售这些工作？&lt;/strong&gt; 你能否根据价值和成果来定价和打包？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;扬鞭策马！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;是时候驾驭长周期智能体的指数级增长了。&lt;/p&gt;&lt;p&gt;今天，你的智能体大概可以可靠地工作约 30 分钟。但它们很快就能完成一天的工作量 &amp;mdash;&amp;mdash; 最终是一个世纪的工作量。&lt;/p&gt;&lt;p&gt;当你的计划以世纪为单位衡量时，你能实现什么？一个世纪，是 20 万项从未被交叉引用的临床试验。一个世纪，是所有客户支持工单，终于被挖掘出信号。一个世纪，是整部美国税法，被重构得条理清晰。&lt;/p&gt;&lt;p&gt;你路线图上那个雄心勃勃的版本，刚刚变成了现实可行的版本。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;原文链接：https://x.com/HungamaHeadline/status/2011533578279272652&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
