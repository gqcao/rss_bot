<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>不上云、不租卡，如何优雅地在本地微调Qwen-VL-30B？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:39:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9e5b9119-5d5e-4841-87c6-b36c5b804f42/1768278956181.png" style="width: 700%;" class="fr-fic fr-dib"&gt;假如你是一个致力于将 AI 引入传统行业的工程团队。现在，你有一个问题：训练一个能看懂复杂机械图纸、设备维护手册或金融研报图表的多模态助手。这个助手不仅要能专业陪聊，更要能精准地识别图纸上的零件标注，或者从密密麻麻的财报截图中提取关键数据。&lt;/p&gt;&lt;p&gt;首先，你需要选择一个合适的模型。&lt;/p&gt;&lt;p&gt;7B 参数的小模型虽然跑得快，但「脑容量」太小，面对复杂的图文逻辑经常一本正经地胡说八道；而 70B 甚至更大的模型虽然聪明，但部署和推理成本直接劝退了客户。最后，你可能发现 30B 参数级的开源多模态模型（例如 Qwen-VL-30B）是个不错的选择。&lt;/p&gt;&lt;p&gt;30B 被称为大模型的黄金尺寸：它在理解能力上远超小模型，又比巨型模型轻量，是企业私有化部署的完美平衡点。&lt;/p&gt;&lt;p&gt;不过呢，你可能也会发现，「30B 参数」也是一个极具欺骗性的数字。&lt;/p&gt;&lt;p&gt;在纯文本时代，一张前沿的消费级显卡或许还能勉强塞下 30B 的推理。但在多模态（Vision-Language）场景下，事情完全变了。当模型需要处理高分辨率图像时，视觉编码器会产生大量的视觉 Token；而为了让模型真正懂行业 Know-how，必须用数千张有标注图像进行 LoRA 微调。&lt;/p&gt;&lt;p&gt;这就意味着，除了模型本身的权重，我们还需要在显存里塞进梯度、优化器状态以及训练过程中的激活值。&lt;/p&gt;&lt;p&gt;原本以为只是「稍微大一点」的任务，瞬间撞上了物理学的墙。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这些方案不太行&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你的开发环境是顶级消费级旗舰，拥有 24 GB 的超大显存，但在这次的任务面前，它显得如此无力。&lt;/p&gt;&lt;p&gt;当你尝试启动微调脚本时，终端里那行熟悉的红色报错如期而至：&lt;/p&gt;&lt;section&gt;&lt;pre data-lang="cs"&gt;&lt;code&gt;RuntimeError: CUDA out of memory. &lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;对于 30B 多模态模型的微调来说，24 GB 的显存就是不够。为了让程序跑起来，你可能会选择牺牲性能，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Batch Size 降到 1&lt;/strong&gt;： 哪怕训练速度慢到像蜗牛爬。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;开启梯度检查点&lt;/strong&gt;： 这是一个典型的「时间换空间」策略，通过不缓存中间激活值而是在反向传播时重算，来节省显存。但这让训练时间直接翻倍。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极限量化&lt;/strong&gt;： 将模型量化到 4-bit 甚至更低。但这也会带来新的问题：对于精密图纸的识别，量化后的模型精度下降明显，连零件号都经常认错。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;即使做了所有这些妥协，只要稍微喂进去一张分辨率高一点的图表，显存还是瞬间溢出，程序直接崩溃。那种「只差一点点就能跑通」的挫败感，最是折磨人。&lt;/p&gt;&lt;p&gt;「要不试试隔壁美术组那台 Mac Studio？」你可能会这样想。那台机器拥有 128 GB 统一内存（Unified Memory）。从硬件上看，这简直是完美的救星 &amp;mdash;&amp;mdash; 别说 30B，就是 70B 也能塞得下。&lt;/p&gt;&lt;p&gt;但当你兴冲冲地把代码拷过去，才发现这是另一个深坑。&lt;/p&gt;&lt;p&gt;首先是环境配置的噩梦。开源社区的主流多模态模型（尤其是涉及底层 CUDA 优化的视觉算子）在苹果芯片上的适配往往慢半拍。你可能会花不少时间解决各种编译报错，好不容易跑通了推理，却发现训练速度受限于优化，效率远不及预期。&lt;/p&gt;&lt;p&gt;更致命的是「生态隔离」。在 Mac 上微调出的模型检查点，想要部署回公司的 Linux 服务器（基于 NVIDIA GPU）上，需要进行繁琐的格式转换和精度对齐。这种开发环境与生产环境的割裂，对于追求快速迭代的工程团队来说，是不可接受的风险。&lt;/p&gt;&lt;p&gt;那么，你到底需要什么？&lt;/p&gt;&lt;p&gt;难道为了跑通这个 30B 模型，你真的要走漫长的合规流程去申请昂贵的 A100 云实例，时刻防范私密数据出域的风险？又或者，仅仅为了这一个开发项目，就专门配置一个高成本的工作站，甚至去采购一台必须安置在专业机房、且维护成本高昂的机架式服务器？&lt;/p&gt;&lt;p&gt;你需要这样一台机器：它要有 Mac Studio 那样海量的统一内存，让你不再为显存精打细算；它同时又必须流淌着纯正的 NVIDIA 血液，拥有原生的 CUDA 生态，让代码无缝迁移。&lt;/p&gt;&lt;p&gt;这个「既要又要」的幻想，直到一台 1 升体积的小盒子的出现，才变成了现实。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;桌面上的一升解决方案&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个盒子就是&lt;strong&gt;联想 ThinkStation PGX&lt;/strong&gt;。&lt;a href="https://mp.weixin.qq.com/s/qeWJwnchS2qNFAKFaHu-TA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e0ee0cbe-e5a4-49d1-b2ae-69eef17029c6/1768278994471.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;如果你关注过英伟达之前的动作，可能会觉得眼熟。没错，联想 ThinkStation PGX 在核心配置上与 NVIDIA DGX Spark 完全一致。&lt;/p&gt;&lt;p&gt;准确地说，ThinkStation PGX 正是英伟达 DGX Spark 的 OEM 量产版本。英伟达已将这一参考设计授权给了联想等厂商，由它们负责具体的工程化制造与差异化定制。&lt;/p&gt;&lt;p&gt;这台机器最直观的冲击力来自于它的尺寸：&lt;strong&gt;仅有 1 升（1L）&lt;/strong&gt;。它小到可以轻松塞进通勤背包，放在办公桌的一角几乎没有存在感。但就在这方寸之间，联想塞进了一颗基于 NVIDIA Grace Blackwell 架构的 GB10 超级芯片。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA0426a2g3EeEUicsZGqIv62q93ypn8Cb5mfygcewWia1x2gpFMriabrZmQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.5879629629629629" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527947" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3d5b0310-6e10-44e9-bf0b-d35d5cd48d29/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而对于被显存折磨得死去活来的开发者来说，它最性感参数是：&lt;strong&gt;128 GB 统一内存（Unified Memory）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这不仅仅是数字的胜利，更是架构的胜利。ThinkStation PGX 的统一内存架构允许 CPU 和 GPU 共享这 128 GB 的海量空间，且可通过 NVLink-C2C 技术实现高速互联。这意味着，开发者终于可以在桌面上拥有接近甚至超越专业级计算卡（如 H100 80GB）的显存容量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACFNGwzs9rpqowOxffYOwVbpj3FJAnicr7KqyibdVUZ0bZ88LezicK2a5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.612037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527945" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e50bbc83-c24e-43e6-8b33-f70c73e6c8c2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了核心算力，在数据存储方面，联想贴心地提供了 1TB 和 4TB 两个存储版本。对于大部分只是想快速验证模型原型的开发者，1TB 版本足矣；而对于需要本地存放海量训练数据（如医疗影像、自动驾驶点云或数万张高清图纸）的团队来说，4TB 版本显然是更具安全感的选择。&lt;/p&gt;&lt;p&gt;更关键的是，它是一台「原生」的 AI 机器。预装了 &lt;strong&gt;NVIDIA AI &lt;/strong&gt;软件栈，底层运行的是开发者熟悉的 Linux 系统，跑的是最纯正的 CUDA 环境。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAUWHEEOH6UdalyZXJTUsVxoGCiaUvXbNpiaHGwkxEXLqH9fXqSdYe1yCQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527946" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/aa108d5a-a934-41f7-8cec-6fc7012a79b4/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，就让我们亲手试一试这样显存巨大的性能小猛兽吧。&lt;/p&gt;&lt;p&gt;首先，掂一掂重量，着实非常小巧，甚至比 Mac mini M1 还小一些。同时，它的设计也非常精致，采用了标志性的蜂窝状散热设计，不仅看起来科技感十足，更是为了保证进风效率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAcqWFAJQD2rJNtPAWdVTPOeRib2zUu4WyXCF9Zy4wFzu3PXLuHiceg06Q/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.75" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527949" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/50317fdf-a6ba-4a5e-8474-0f85cd01bc2a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;接下来，把 ThinkStation PGX 连上显示器，通电开机，先来看看基本信息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkARuyPPVnt2obHricibVh9F3MZ9k2h0oDn84JcrKjPsJaDg0kRBa2yiao5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6724324324324324" data-s="300,640" data-type="png" data-w="925" type="block" data-imgfileid="503527948" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1b73c55f-9f80-453c-87ba-c3e779f185e6/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在终端输入 nvidia-smi，可以看到显卡型号是 NVIDIA GB10，CUDA 版本为 13.0。但这里有一个有趣的细节：在 Memory-Usage 一栏，它显示的是 Not Supported。&lt;/p&gt;&lt;p&gt;为什么不支持？其实，这反而是最大的利好。&lt;/p&gt;&lt;p&gt;在传统的独立显卡（如 RTX 4090）上，显存是独立的，所以会显示具体 MiB 数值。这里的「Not Supported」以及下面进程列表里能显示显存占用（如 Firefox 用了 230MiB），直接证明了它是&lt;strong&gt;统一内存（Unified Memory）&lt;/strong&gt;架构。&lt;/p&gt;&lt;p&gt;是的，PGX 的 GPU 没有自己封闭的小显存墙，而是直接访问系统的大内存池。&lt;/p&gt;&lt;p&gt;接下来我们将通过一个真实的微调场景来检验这台机器的能力。&lt;/p&gt;&lt;p&gt;首先，我们选择的模型是完整版的 Qwen3-VL-30B-A3B-Instruct。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZw2oLxQjhQBY9V4afmSdMhnRnTyL9hiajLib3lUiciapxBlVv7N0ia1PUcQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=6" data-ratio="0.3203342618384401" data-type="gif" data-w="1077" type="block" data-imgfileid="503527952" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0ca3647f-8db1-4be5-ba05-5b72a7f66464/640.gif" data-order="0" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;糟糕的网速下等待 1 个多小时，下载完成。而为了微调模型，我们还需要一个数据集，这里我们选择是的 lyan62 发布的 FoodieQA 数据集。据介绍，FoodieQA 是一个用于细粒度理解中国饮食文化的多模态数据集，其中包含多图像、单图像视觉问答（VQA）以及关于中国地方美食的文本问答问题。该数据集基于 350 种独特美食条目对应的 389 张独特美食图像构建而成。它要求模型不仅能看图，还要懂中国味。&lt;/p&gt;&lt;p&gt;接下来，我们先是自己尝试了编写微调脚本，但效果并不佳。于是我们决定直接让 AI 全程接管，来一次 vibe fine-tuning（氛围微调）！&lt;/p&gt;&lt;p&gt;给 PGX 装上 Claude Code，并配置好 MiniMax-M2.1。然后下达一小段指令：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;你是一位出色的 AI 模型微调专家，你现在需要在一台拥有 128GB 统一内存的联想 ThinkStation PGX 上微调一个 30B 大小的 MoE 模型。在这里，models/Qwen3-VL-30B 文件夹中是已下载的 Qwen3-VL-30B-A3B-Instruct 模型，FoodieQA 文件夹中是 lyan62/FoodieQA 数据集。请使用 FoodieQA 数据集完成对 Qwen3-VL-30B-A3B-Instruct 模型的进一步微调。&lt;/p&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAFYjISNZko35y7raGCbw1fIsRRp3few9KAJqJAWSrdu4iaIB8JiawuEPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.2092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527950" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/a49db964-d77f-41cb-8882-b2cb919662ab/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来就是等待。两三个小时后，训练方案终于确定下来。以下是训练稳定后 nvtop 监视画面。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAghCNzPibFDCthLo8ibG6aiczoG71fKbOHnhjo0ianR1GaYqzeicN3oSvjVQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=8" data-ratio="0.41929499072356213" data-type="gif" data-w="1078" type="block" data-imgfileid="503527957" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b1f9e8cb-9d44-44b2-bab6-7ad167c929de/640.gif" data-order="1" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可以看到，对于该任务，GPU 使用率大体在 23% 左右，显存（统一内存）的占用接近 60GB。&lt;/p&gt;&lt;p&gt;要知道，这 60GB 的显存占用，如果是消费级显卡早就炸了三次了，但在 ThinkStation PGX 上，显存条只吃了一半，它甚至游刃有余。更令人印象深刻的是温控。得益于出色的散热设计，在开了暖气的房间里，ThinkStation PGX 的 GPU 最高温度也仅达到了 40℃。&lt;/p&gt;&lt;p&gt;一夜之后，微调完成。在验证集上的损失从 4.03 成功降到了 1.06，下降了 74%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAJ2vv6xib7VCgKp2WUafTr4jID89da3mg14KLc3Qf2hB3uMnwo3n44mA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6832971800433839" data-s="300,640" data-type="png" data-w="461" type="block" data-imgfileid="503527951" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ce51367e-2baf-4cb2-bd34-40a9e33f39c4/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;来一张我们自己拍摄的食物照片来简单试试。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAArTTIicsI9ibKml8oWcpbx2mQpsHPzAACeSPJXqQXHia50Ht30zTichV9g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=10" data-ratio="0.5185185185185185" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527953" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/023683cd-22ad-43e9-a28d-7152e1ef0118/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAdkB1DbJFFB0s7v5mX0FLXiaibD2t6HGUevLA0UlSibRvpQeRmJZF9RrDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.550761421319797" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503527954" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/4920ef56-3021-49ef-9645-d19b976df625/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;结果大体正确，这个微调过的 Qwen3-VL-30B-A3B-Instruct 正确识别了中间的阳春面，并正确地指出了其属于淮扬菜，不过它也忽略了旁边的蟹黄（确实有点难以辨认）。&lt;/p&gt;&lt;p&gt;整体体验下来，联想 ThinkStation PGX 展现出了几个让开发者无法拒绝的优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;从容加载&lt;/strong&gt;：128GB 内存意味着我们可以不需要任何量化，甚至可以直接加载 FP16/BF16 精度的原始模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;大胆训练&lt;/strong&gt;：可以直接开启较大的 Batch Size，不用担心 OOM，训练效率成倍提升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;英伟达原生体验&lt;/strong&gt;：基于 Linux+CUDA，可以直接 clone 官方的微调代码库，配置好环境，一行命令 bash finetune.sh 直接开跑，没有适配的痛苦。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;结论很明显：&lt;strong&gt;联想 ThinkStation PGX 是目前桌面上唯一能让 30B 多模态模型「跑得舒服」的设备&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;事实上，微调模型绝非 PGX 的唯一用途。打开想象力，我们能发现很多适合它的大显存 AI 场景，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;算法工程师的本地沙盒&lt;/strong&gt;：用于金融或医疗等数据敏感行业。工程师可以在本地完整加载 70B+ 模型验证想法，无需申请云端资源，数据绝不出域。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;野外科研的离线算力站&lt;/strong&gt;：对于珍稀动物监测或地质勘探，野外往往没有高速网络。PGX 可塞进背包，离线处理海量红外监控影像。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;长视频生成的无限画布&lt;/strong&gt;：视频生成模型对显存需求随时间线性增长。PGX 的大内存能支持生成更长时间的连贯视频素材。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;具身智能的数字孪生&lt;/strong&gt;：在桌面运行高保真的 Isaac Sim 仿真环境，训练完成后直接部署到架构同源的 Jetson 模块，零迁移成本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数字艺术家的私有风格库&lt;/strong&gt;：长期累积创作者自己的 Style Checkpoint，本地运行风格迁移，不用担心独家画风泄露。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;为什么选择联想 ThinkStation PGX？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然核心芯片和架构与英伟达的参考设计（DGX Spark）一致，为什么我们更推荐联想的 PGX？&lt;/p&gt;&lt;p&gt;答案在于两个词：&lt;strong&gt;工程&lt;/strong&gt;与&lt;strong&gt;服务&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;驯服 240W 功耗的蜂窝美学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GB10 是一颗性能强悍的超级芯片，但其满载功耗高达 170W，整机功耗更达到 240W。在一个 1 升的极小空间内压制这种热量，如果设计不当，很容易导致积热降频，甚至变成桌面烫手宝。&lt;/p&gt;&lt;p&gt;联想没有简单照搬公版设计，而是沿用了 ThinkStation 家族标志性的「蜂窝状」散热设计。这种源自空气动力学的设计理念（灵感源于阿斯顿・马丁的进气格栅），最大化了机箱前后的进出风效率。&lt;/p&gt;&lt;p&gt;实测表明，相比于初期公版参考设计可能存在的积热问题，PGX 表现得更加「冷静」。对于需要连续跑几天几夜微调任务的开发者来说，这种基于 Top 1 工作站大厂的工程稳定性，意味着你不用半夜起来担心训练因过热而中断。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据保险&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于购买 PGX 的企业和科研用户来说，最值钱的往往不是机器本身，而是硬盘里的数据：那些私有的行业数据集、微调后的模型权重、以及核心算法代码。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAw4gLEVCNd27YsBd72iae12KfRFnYCY4ahGrDJDvv5HA7ibTmMJfmJic1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527955" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/0cc2b8b1-d652-4d44-a03c-732d515db106/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;作为中国市场份额第一的专业工作站品牌，联想给 PGX 配备了中国区独享的顶格服务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3 年上门保修&lt;/strong&gt;：相比于海淘水货或部分竞品可能仅提供的 1 年质保，这是面向生产力用户更合理、也更负责任的保障方案。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;硬盘数据恢复服务&lt;/strong&gt;：这是最打动企业用户的痛点。万一硬盘发生物理损坏，联想提供专业的数据恢复服务。对于科研实验室等数据至关重要的机构来说，这项服务的价值远超机器价格本身。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;售后技术支持&lt;/strong&gt;：联想工作站在全国拥有超过 1 万名认证工程师，2300 多个专业服务站，100% 覆盖 1-6 线城市，能保证 7x24 小时在线支持。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;升级空间：双机 NVLink&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你觉得 128 GB 依然不够用，PGX 还预留了升级空间。&lt;/p&gt;&lt;p&gt;借助内置的 NVIDIA ConnectX-7 网络技术，你可以将两台 ThinkStation PGX 通过高速互联。在 NVLink 的加持下，两台机器瞬间化身为一个拥有&lt;strong&gt; 256 GB 统一内存&lt;/strong&gt;的超级怪兽。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAhwCw3k69fCAP2A9CcZuN3P3c4Bpn1gLCbWKhow073SzSF26Id5PC3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6416666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527956" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/cddb1bde-5c2d-4d97-8f49-baf256a666b8/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这时，你的桌面算力上限将被进一步打破：你甚至可以尝试挑战上千亿参数量级别的超大模型推理。从 1 升小盒子到双机并行，这给了开发者极大的灵活性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算力普及的「最后一公里」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回顾这几天的体验，联想 ThinkStation PGX 给我们留下的最深印象，并不是某个具体的跑分数字，而是它带来的「&lt;strong&gt;确定性&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;在过去，想要在本地搞定 30B 级别以上的多模态模型微调，总是充满了不确定性：显存会不会爆？量化会不会掉点？算子能不能跑通？&lt;/p&gt;&lt;p&gt;而 ThinkStation PGX 用 128 GB 的海量内存和原生的 CUDA 生态，把这些不确定性变成了一条平滑的直线。它填补了消费级显卡（显存太小）和工业级服务器（动静太大）之间那个巨大的真空地带。&lt;/p&gt;&lt;p&gt;至于大家都关心的价格，在拥有 128GB 统一内存和原生 CUDA 生态的前提下，&lt;strong&gt;ThinkStation PGX 1TB 版本售价为 31999 元，4TB 版本售价为 36999 元&lt;/strong&gt;。这仅仅相当于一块高端专业显卡的价格，却可以换来一台完整的、开箱即用的桌面 AI 超算。&lt;/p&gt;&lt;p&gt;如果要我以编辑的身份给一个购买建议，我的答案是：对于深陷显存焦虑的专业开发者而言，&lt;strong&gt;联想 ThinkStation PGX 不仅值得买，甚至可能是目前 4 万元以内唯一的最优解&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;不妨算一笔账：在市面上，要获得同等规模（128GB）的显存容量，你通常需要购买昂贵的专业级计算卡，或者租用按小时计费且数据需上传云端的 A100 实例。而 ThinkStation PGX 以不到 3.7 万元的顶配价格，提供了一个拥有海量统一内存、原生 CUDA 生态且数据完全私有的桌面级方案。&lt;/p&gt;&lt;p&gt;如果你只是偶尔跑跑 7B 小模型，它或许略显奢侈；但对于那些受够了环境配置错误的算法工程师、对数据安全有极高要求的科研团队，以及希望快速验证 idea 的初创公司来说，PGX 买到的不仅仅是硬件，更是「不折腾」的权利：让你不必再为显存溢出修改代码，也不必再为跨平台移植浪费时间。这种&lt;strong&gt;让开发者回归创造力&lt;/strong&gt;本身的价值，远超机器售价本身。&lt;/p&gt;&lt;p&gt;这或许才是 AI 基础设施普及过程中，最动人的「最后一公里」。&lt;/p&gt;&lt;p&gt;如果你也受够了在 OOM 的边缘试探，ThinkStation PGX 值得成为你桌面上的下一台设备。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>OpenAI的首款硬件：是AI耳机，今年销量要冲5000万</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:33:40 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/11e3dc79-d6e5-4b72-88d1-4e44558abb1a/1768278719983.png" style="width: 700%;" class="fr-fic fr-dib"&gt;以人工智能技术闻名的 OpenAI，终于也要搞硬件了，而且一上来就是和苹果正面对标。&lt;/p&gt;&lt;p&gt;最近，有关 OpenAI 硬件的消息越来越多。&lt;/p&gt;&lt;p&gt;今天一早，数码博主 @智慧皮卡丘透露了关于 OpenAI「To-go」硬件项目的最新细节。&lt;/p&gt;&lt;p&gt;该硬件已被确认是&lt;strong&gt;一款取代 AirPods 的特殊音频产品，内部代号为「Sweetpea」（香豌豆）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;据他所说，在制造端，富士康已接到通知，要求在 2028 年第四季度前为五款设备做好量产准备。目前这些设备尚未全部揭晓，但一款家居设备和一款手写笔仍在研发考量中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaev2XJQyC8Ga5Z85b4dNlWJCbOibXLQB2P5s0JWPVcGiaGarmEmyP8wRw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528105" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5bc7eabe-54e4-4829-ae19-de07265a308f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 部分截图。原文链接：https://x.com/zhihuipikachu/status/2010745618734759946&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;多方消息来源反复确认了同一个信息：由于苹果前首席设计官 Jony Ive 团队的全力投入，&lt;strong&gt;「Sweetpea」目前处于最高优先级。该产品预计于 9 月左右发布，OpenAI 给它的第一年预估出货量高达 4000-5000 万部&lt;/strong&gt;（作为对比，苹果 AirPods 系列的年出货量约在 6000-7000 万支左右）。目前已知的具体细节如下，如下参考图所示。&lt;/p&gt;&lt;p&gt;在工业设计上，据称设计「独一无二、前所未见」，主机采用金属材质，外形酷似卵石（eggstone）。&lt;/p&gt;&lt;p&gt;在佩戴方式上，在「卵石」内部装有两个胶囊状单元，取出后可佩戴在耳后。&lt;/p&gt;&lt;p&gt;在核心性能上，主处理器目标锁定为 2nm 制程的智能手机级芯片（目前最看好三星 Exynos），因此可以让大部分 AI 推理任务在本地运行。此外，项目还开发了一款定制芯片，允许用户通过指令控制 Siri 来「替代 iPhone 的操作」。&lt;/p&gt;&lt;p&gt;在成本与定位上：由于选材和组件规格更接近手机，外界担心其 BOM（物料清单）成本极高，但据称该设备的功能将比现有产品更强大。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsac3fv7bvWn2TvfWOsRXdsukB93hFaiaNAhru6s5iaib7fKGatosE4MBMog/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8379629629629629" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528107" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9272e968-6864-4ab5-a0f3-60beee9a043b/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在评论区，这位博主回答了更多关于这款设备的信息，比如「它的发声是通过骨传导，还是内置了扬声器？」，答案是「目前没有采用骨传导的计划。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsa6MTyV8rkh0BDkR4LibVpVZdoTZkzMNGoxxA50NeL5icEzRrvnuVDrpNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3509259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528109" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2a4b3109-8cba-49a5-8970-e5efcb03b4c7/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;多位网友认为这款设备很酷，如果真的可以取代 Airpods，绝对是跨时代的产品。毕竟是苹果传奇设计师 Jony Ive 操刀的产品，期待可以拉高一些。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaSEQbdsJ9HopWTXJdwibnWp6w15kyKRX3jiaCHxQK2rY2QniabOCLThflg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3175925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528111" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e443b922-3b26-4c41-835b-6e06aba01b10/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;「这看起来是 OpenAI 进军可穿戴 AI 市场的一次大胆尝试。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicFZCBCia2pic36dtxra88bsaYRT36XIOhUzM8GXaaxaict7YJXjTrK6kRxDQODqIXs2GpOXjlUQav7g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.16203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528113" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d32dc35b-3f59-4d9d-99af-334698ad3749/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;去年 5 月，OpenAI 宣布以 65 亿美元的价格收购了由苹果前首席设计官 Jony Ive 创办的秘密硬件初创公司 io，这是 OpenAI 自成立以来规模最大的收购案。双方在 2025 年 7 月正式完成了团队整合。&lt;/p&gt;&lt;p&gt;io 原来的目标是开发一种「为 AI 时代而生」的新型计算设备，旨在打破目前以智能手机屏幕为核心的交互逻辑，寻找一种更自然、更具直觉的 AI 交互形态。至少在 OpenAI 耳机上，我们能看到这种思路的延续。&lt;/p&gt;&lt;p&gt;目前，虽然 OpenAI 的智能硬件仍然处于保密状态，但通过越来越多的爆料，我们已经可以逐渐勾画出它的大致样貌了。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考内容：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theinformation.com/articles/openai-ramps-audio-ai-efforts-ahead-device&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/kimmonismus/status/2010804115543114099&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为推出软工代码智能体SWE-Lego，解锁SFT训练极致性能</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 12:30:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ed362392-6d9c-4a7e-b1b5-1043314720f5/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&amp;ldquo;软工任务要改多文件、多轮工具调用，模型怎么学透？高质量训练数据稀缺，又怕轨迹含噪声作弊？复杂 RL 训练成本高，中小团队望而却步？&amp;rdquo;&lt;/p&gt;&lt;p&gt;华为研究团队推出 &lt;strong&gt;SWE-Lego&lt;/strong&gt;， 仅基于监督微调（SFT）的软件工程代码智能体，无需复杂 RL 流程，在 SWE-bench Verified 基准中斩获同等规模开源模型 SOTA，甚至超越部分更大规模闭源模型！项目已开源，代码、模型和全部数据一键获取！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;arXiv 地址：https://arxiv.org/abs/2601.01426&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub 地址：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://github.com/SWE-Lego&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace 地址：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;https://huggingface.co/SWE-Lego&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;SWE-Lego 具有三大创新，包括数据、训练和测试时扩展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 混合数据集构建：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;双数据管道互补&lt;/strong&gt;：GitHub 真实 PR 数据 + 注入真实场景 Bug 的合成数据，产出 32k 高质量任务实例 + 18k 专家轨迹；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;严格轨迹筛选&lt;/strong&gt;：过滤 Git 历史泄露、工具错误等噪声，重用部分解决的优质轨迹，提升 SFT 训练有效性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 改进的监督微调：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;两大亮点&lt;/strong&gt;：① 步骤级错误掩码，让模型从长轨迹中学习有效子轨迹；② 课程学习，按交互轮次分级提升任务难度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能提升&lt;/strong&gt;：比传统 SFT 在不同模型上提升 2~4%，筑牢 SOTA 基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3. 测试时扩展策略（TTS）：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;扩展优先级&lt;/strong&gt;：先串行扩展（增大轨迹最大交互轮数）至饱和，再分配资源给并行扩展（多备选答案选最优）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;打分器优选&lt;/strong&gt;：生成式打分器在并行扩展中，全程优于回归式打分器，适配不同模型规模与测试预算。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在软件工程领域，Code Agent 需要处理复杂的任务：修复 bug、重构代码、理解大型代码库。这些任务要求 Code Agent 具备&lt;strong&gt;长序列推理、多文件操作和工具使用&lt;/strong&gt;等能力。现有的训练方法通常需要复杂的训练范式，比如强化学习（RL）或者 RL 和 SFT 的迭代组合。&lt;/p&gt;&lt;p&gt;这些方法虽然有效，但计算成本高，训练过程复杂。能否用更简单的方法达到同样的效果？&lt;/p&gt;&lt;p&gt;华为的研究团队提出了 &lt;strong&gt;SWE-Lego，一个仅基于监督微调（SFT）的软工代码模型的解决方案&lt;/strong&gt;。在 SWE-bench Verified 基准测试上基于 Qwen3 系列模型作为起始模型，经过 SFT 之后得到 SWE-Lego-Qwen3-8B 和 32B 分别达到 42.2% 和 52.6%，&lt;strong&gt;达到了开源模型的 SOTA 水平，并超越了一些更大规模的闭源模型&lt;/strong&gt;。基于测试时扩展策略（TTS）可以进一步把性能提高 6~7%。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85vGYcMUqPLFJw5FDvLG6p4n105QiajNXViboAhGic0no60zl9Xaib3vg7NA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527131" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/303b5186-1e49-430a-9d96-d89fcdfed42f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1：SWE-Lego 系列模型在 SWE-bench Verified 上的性能对比，在同等规模模型中表现达到 SOTA&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、挑战与动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;软件工程任务与传统的单文件编程任务有着明显区别&lt;/strong&gt;：一个 bug 修复可能涉及代码项目里多个文件的修改，需要多轮工具调用（读取文件、执行测试、编辑代码等），必须在真实的代码库环境中验证修复效果，还需要理解代码逻辑、定位问题、设计修复方案等复杂推理能力。&lt;/p&gt;&lt;p&gt;为了训练具备软件工程项目级代码编写能力的代码模型，研究者们尝试了多种方法。强化学习（RL）虽然不需要预定义的轨迹，但训练成本极高。复杂组合方法将多种训练范式结合，比如 SFT 和 RL 的迭代训练，进一步增加了训练复杂度。更重要的是，高质量的训练数据稀缺。现有的数据集要么规模有限，要么缺乏可执行环境，要么难以扩展到足够大的规模。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、SWE-Lego 的三大核心组件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 包含三个核心组件：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85lBhxibD6hKhdgRupdPUsiaJafSV05zaEu0LtFFFbNibyjCAScYiajtRqgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.438423645320197" data-s="300,640" data-type="png" data-w="1015" type="block" data-imgfileid="503527133" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9d19b42c-8640-441e-90c4-3117c8152d85/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：SWE-Lego-Qwen3-32B 的性能提升分解，混合数据集贡献最大（+25.6%），改进的 SFT 贡献 + 3.8%，TTS 贡献 + 6.2%&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;从图 2 可以看到每个组件的贡献：混合数据集贡献 + 25.6%（最大贡献），改进的 SFT 贡献 + 3.8%，测试时扩展贡献 + 6.2%。总计从基线 23.2% 提升到 58.8%，提升了 35.6 个百分点。这些结果清楚地表明，好的数据集是性能提升的最大驱动力，而改进的 SFT 和测试时扩展提供了不错的增量收益。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件一：混合数据集构建&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 数据集包含 32,119 个高质量任务实例，18,110 个验证轨迹（其中 14,110 个完全解决，4,000 个半解决），覆盖 3,251 个代码仓库。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SWE-Lego 采用混合数据构建策略&lt;/strong&gt;，结合真实世界数据和合成数据。真实世界数据来自严格筛选的 GitHub Pull Requests （PRs），这里的 PRs 中非测试文件作为 Golden Patch, 也就是这个任务的解决方案。真实 PR 数据具有贴近生产环境的优势，能够提供真实的 bug 的复杂性，真实的任务参考 SWE-rebench [1]。但是&lt;strong&gt;真实数据数量有限，且每个任务需要独立的沙箱环境，成本较高&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;参考 SWE-smith [2] 的通过故意引入 Bug 来合成软工任务的方式，SWE-Lego 通过 AST 转换和 LLM 重写，基于真实代码仓得到相应的合成软工数据，对可以通过测试的代码库故意引入一些 Bug。具体地，AST 转换提取抽象语法树（AST）并应用随机变换，如移除条件 / 循环、修改运算符或依赖关系，而 LLM 重写则提示模型使用函数头和文档字符串等信息重写代码。引入 Bug 的补丁进行反转就可以得到解决这个任务的 Golden Patch。&lt;strong&gt;合成数据具有可扩展、成本低、多个任务可共享沙箱的优势，但复杂度相对较低&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在下一步，&lt;strong&gt;团队对真实和合成数据采用测试驱动的方式去得到验证后的软工数据实例&lt;/strong&gt;，筛选出合格的软工任务。具体地，在应用 Golden Patch 前可以通过的测试在应用 Golden Patch 之后仍然可以通过， 而应用 Golden Patch 前不通过的测试在应用 Golden Patch 之后也需要通过。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85bXdevAiaQDibeoMc08U2L0pYDoLIrWuoibBsj9icicNPSeg3DSYxQRMWdeg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.44814814814814813" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527134" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2dc7c643-6445-414d-a104-0b9830e869c5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：SWE-Lego 数据管道，结合真实 PR 和合成的软工任务实例，基于专家模型去生成可执行的轨迹用于 SFT 训练&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;真实数据提供深度（复杂性和真实性），合成数据提供广度（数量和覆盖范围）&lt;/strong&gt;。两者互补：真实数据提供主要收益但难以扩展，合成数据通过进一步扩展提供额外收益。实验证明，增加合成数据可以显著提升有效轨迹数量和下游性能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85xia36DysWTXYFxLWibXjz24g5VNhpAldaYBJVyC9aK2klkm8R5o6HKag/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527135" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c75ce22d-38c6-425e-943a-570d855069d5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 4：随着合成实例的增加，有效轨迹数量显著增长&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85XibhMDqGBpCxvjE0NXFQrKk54rn4qOQ3qZy0fH9Doy7icibemNQNwF4YA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527136" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/be29d2b9-3f37-471a-8685-a2bf1f18f7e4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 5：随着混合数据的增加，模型的性能逐步提升&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;轨迹质量优化&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了确保训练数据的质量，SWE-Lego 实施了严格的轨迹生成和验证流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;防止解决方案泄露&lt;/strong&gt;：最近 SWE-Bench 社区 [3] 发现，LLM 可能通过查看 Git 历史来 &amp;quot;作弊&amp;quot;，直接找到正确答案。为了防止这种解决方案泄露，对于真实实例，SWE-Lego 移除问题创建日期之后的所有提交和日志消息，使未来的修复不可见；对于合成实例，由于有 bug 的版本在无 bug 的版本之前（由于故意的 bug 注入），完全移除整个 Git 历史和所有日志，只暴露 buggy 代码库的单个快照。这迫使模型真正推理代码和测试，而不是从版本控制中读取答案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;处理工具调用错误&lt;/strong&gt;：在使用 Qwen3-Coder-480B-A35B-Instruct 作为教师模型时，观察到对 str_replace_editor 工具的频繁格式错误调用，例如将字符串传递给 view_range 或指定超出范围的行范围，导致工具失败并浪费交互预算。为了缓解这些错误，SWE-Lego 应用轻量级后处理：如果 view_range 是字符串，则在执行工具之前将其转换为整数；如果请求的行范围超过文件长度，则返回有效行的子集而不是引发错误，使得模型能够更可靠地检查代码。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;精简工具集&lt;/strong&gt;：虽然任务管理工具（如 task_tracker）已被一些最近的专有模型采用，但发现 Qwen3-Coder-480B-A35B-Instruct 无法有效使用它们，经常导致执行错误。因此，SWE-Lego 丢弃此工具，将工具集限制为四个基本操作：execute_bash、str_replace_editor、think 和 finish，以保持轨迹精简。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;轨迹过滤策略&lt;/strong&gt;：SWE-Lego 通过应用预测补丁并运行测试集来验证轨迹。如果轨迹通过所有测试，则分类为已解决，否则为未解决。然后，过滤低质量的已解决轨迹（例如，通过修改测试文件来 &amp;quot;作弊&amp;quot; 的轨迹），并重用部分解决轨迹（那些正确识别了所有相关文件但未能修复的轨迹）。这些部分解决轨迹提供了有价值的故障定位监督，我们发现加入此类数据会适当提升模型的性能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85aqgAJhnEwht3BZ4QicS0TLKlJalnticUCI1A4VSt0UnWpXLnYib523xIg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4212962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527141" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8b929db2-f5ae-4e82-9abd-7278171bc345/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 6：轨迹生成中的关键实践，包括防止 Git 泄露、处理工具错误、精简工具集&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85ElzKdAowjXhPXIqeOYlbdA8tcY8V3vTuwzNBqP81icCcxcnNG4Vxasw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527143" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/cf49ae17-ef08-48e6-8360-5a458b005b1a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 1：SWE-Lego 的可验证的任务实例和有效训练轨迹的统计以及和其他 SWE 相关工作的数据对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;具体的数据统计和对比见表 1，可以看出 SWE-Lego 的混合数据管道提供了数量充足的、代码仓多样的、环境可验证的 SWE 任务实例和轨迹。&lt;/p&gt;&lt;p&gt;总结：混合数据集是性能提升的最大驱动力。真实数据与合成数据互补确保了数据数量，严格的轨迹验证确保了轨迹的质量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件二：改进的监督微调&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通常的监督微调将通过测试验证的整条轨迹拿去训练，但实际上在软工的场景，专家轨迹需要多轮在沙箱中交互得到最后的预测补丁，即使&lt;strong&gt;最终成功解决的轨迹也可能包含中间错误步骤&lt;/strong&gt;，盲目学习这些错误可能强化不良行为。另外，不同数据的难度不同，&lt;strong&gt;在训练初期让模型学习难题可能比较吃力&lt;/strong&gt;。针对这些情况，SWE-Lego 提出了两个改进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;改进 1：步骤级错误掩码&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：保持完整轨迹上下文，但只对正确的步骤计算损失。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Nk2uT6COC4ZqEwyUPAfWKLkHNkMa1MzicUoaynibNWMqBp0Msor8oQQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.549074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527144" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/56d1eb5f-7d82-44dd-99f2-f12669881376/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 7：步骤级错误掩码示例，错误步骤被掩码，模型只学习正确的操作&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实现方法：使用正则表达式识别终端环境提供的错误消息，对相应的模型响应应用错误掩码。关键是要排除因复现 bug 或执行测试文件而产生的错误。&lt;strong&gt;这种方法保持完整的轨迹上下文，但只对正确的步骤计算损失&lt;/strong&gt;，使模型能够学习正确的操作和恢复策略，而不会强化错误。通过强调学习正确操作，直接减少了核心推理失败，如 &amp;quot;错误实现&amp;quot; 和 &amp;quot;定位错误&amp;quot;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;改进 2：基于难度的课程学习&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：从简单任务开始，逐步增加难度。&lt;/p&gt;&lt;p&gt;SWE-Lego 探索了两种难度分类方法：&lt;strong&gt;基于模型的评分和基于轨迹轮数的启发式&lt;/strong&gt;。研究发现，轨迹轮数与解决率之间存在强负相关（相关系数 - 0.95）。基于这一发现，&lt;strong&gt;SWE-Lego 采用可以直接获取的指标，轨迹轮数，作为轨迹的难度指标&lt;/strong&gt;，将数据分为三个难度等级：简单（0-50 轮）、中等（50-70 轮）、困难（70-100 轮）。训练策略采用三阶段课程：先训练简单任务，再逐步加入中等和困难任务。这种课程学习与训练动态一致：首先让模型在 &amp;quot;简单&amp;quot; 任务上克服基本的 &amp;quot;无法复现&amp;quot; 错误，然后引入 &amp;quot;困难&amp;quot; 任务以发展避免 &amp;quot;超出最大轮次&amp;quot; 失败所需的战略规划。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85X4dibbQLI0oiaS2Y95fY3B09vmGgztwKMOBed6NfZVZRGCTqEJ9tsVkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527147" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0577f126-d803-4eae-bf87-f3b605984a57/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8：轨迹轮次与平均解决率之间的强负相关关系&lt;/sup&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;训练过程分析&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过分析训练过程中的错误类型演变，可以清楚地看到模型的学习轨迹：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Ey25EvOiahC5oibIUnAYmHoJE0gy0ib0l1C4dPibduUfAqkiaR9WwAUicl9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527148" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/57b0e284-aa3d-465f-bf90-89ffdb951c6f/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9：训练过程中解决率的提升趋势&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85Ogmgib5lx8xXCEVLr16s50IGrLjiaHXicvia442GORicv820pBZJoYAMic3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527149" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/84f31828-103e-4cbb-8fe8-d246ea1d44c6/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10：训练过程中错误类型的演变，从早期的 &amp;quot;无法复现&amp;quot; 到后期的 &amp;quot;错误实现&amp;quot;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;错误类型的变化：训练初期时 &amp;quot;无法复现&amp;quot; 错误占主导，表明模型此时缺乏对软工任务基本的理解能力；训练中期时 &amp;quot;无法复现&amp;quot; 比例大幅减少，但 &amp;quot;定位错误&amp;quot; 比例仍有较多，表明缺乏战略规划；训练后期 &amp;quot;错误实现&amp;quot; 成为瓶颈，表明从过程失败转向推理失败。&lt;/p&gt;&lt;p&gt;改进的 SFT（错误掩码 + 课程学习）带来 3.8% 的性能提升。在 SWE-bench Verified 上，SWE-Lego-Qwen3-8B 达到 42.2%，SWE-Lego-Qwen3-32B 达到 52.6%。通过渐进式训练和选择性学习，模型能够更有效地掌握复杂任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心组件三：测试时扩展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;测试时扩展（TTS）可以在不重新训练的情况下，通过在测试阶段分配额外的计算资源来提升性能。SWE-Lego 系统研究了两个正交维度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;维度 1：串行扩展 vs 并行扩展&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;SWE-Lego 研究了串行扩展和并行扩展之间的资源分配。串行扩展通过增加最大交互轮次实现，在低测试预算的区域非常高效。额外轮次都能获得环境反馈，使模型能够纠正错误并迭代改进解决方案。这使得串行扩展在预算有限时成为首选策略。然而，模型性能在约 100-140 轮后开始饱和，此时相比于串行扩展，更加需要并行扩展来提升性能。&lt;/p&gt;&lt;p&gt;并行扩展生成多个候选轨迹，用打分器选择最佳的轨迹。&lt;strong&gt;在串行扩展饱和后，并行扩展变得更加有效，因为每个独立轨迹探索解决方案空间的不同路径。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85k1QHfdWvBNrJB9nhG1mLtXMw1QBcL34Wvk1os5XtNveuaanvjaPFAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5268518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527150" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/b5bb352e-b62d-4fef-8885-7fea41384c79/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 11：串行扩展和并行扩展的权衡，等延迟曲线显示了最优资源分配策略&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;有限的测试阶段计算预算下，应优先进行串行扩展；在串行扩展饱和后，将剩余计算资源分配给并行扩展&lt;/strong&gt;。图 11 中的等延迟等高线说明了这种权衡：在等效延迟下，最优分配随着总延迟预算的增加从顺序主导转向并行主导。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;维度 2：生成式 vs 回归式打分器&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;打分器用于从多个候选轨迹中选择最佳方案。SWE-Lego 比较了两种范式：回归式打分器和生成式打分器。&lt;/p&gt;&lt;p&gt;回归式打分器在模型上添加一个头输出，使用二元交叉熵损失训练，对整个轨迹转化为单个标量去打分。生成式打分器将验证表述为文本生成任务，预测 &amp;quot;是&amp;quot; 或 &amp;quot;否&amp;quot;，从输出 &amp;quot;是&amp;quot; 或 &amp;quot;否的&amp;quot;token 概率计算分数。生成式打分器的训练目标与预训练的下一个 token 预测目标对齐，可能更好地利用模型的固有知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85edYQZtPKoaUMyNLjU1nk8oCzflosCwaOaruCZug5Wxiaplkl2VsmZTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527151" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/eb87310c-d0e8-48c4-b96c-ae00c543d0f4/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 12：生成式打分器与回归式打分器的对比，生成式打分器在 K 值较大时持续改进&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 rollout 的个数（K 值）比较小时，生成式打分器与回归式打分器两者的性能相近；&lt;strong&gt;随着 rollout 的次数（K）的增加，回归式打分器趋于饱和，而生成式打分器持续改进&lt;/strong&gt;。对于 SWE-Lego-Qwen3-8B，在 K=16 时差距达到 2.8%（49.6% vs 46.8%）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LdfM1seB6IFxiby1Y10q85r2NrjLgQMcTTFGTTKUVPYicCcjJicXRVV6G1UsRErhx3eBTMr0DiagEdQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527152" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/ed9437fe-3f12-44e2-b6ba-e50f4c5b7cab/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 13：SWE-Lego 打分器与现有公开打分器的对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego-Verifier-8B 在 TTS@16 上达到 49.6%，超越了 OpenHands-Critic-32B（44.0%）和 R2E-Gym-Verifier-14B（47.0%）。除了绝对性能外，还观察到不同打分器范式的定性不同缩放行为。OpenHands-Critic-32B 采用回归式范式，在更高的 K 值下表现出性能下降，这是一个反直觉的结果，表明更大的候选池压倒了其判别能力。相比之下，生成式打分器（SWE-Lego 和 R2E-Gym）保持单调改进，趋向于 Pass@K 上限，进一步确认生成式表述提供了更稳健的缩放属性。&lt;/p&gt;&lt;p&gt;总结：测试时扩展可以在测试阶段带来额外提升。在测试的计算预算比较低的时候，串行扩展优先于并行扩展。生成式打分器在并行扩展中表现更优。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、结语与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SWE-Lego 证明了&lt;strong&gt;轻量级方法也能达到 SOTA&lt;/strong&gt;，不一定需要复杂的 RL 或 SFT 和 RL 的迭代训练，SFT 也可以取得软工任务的 SOTA 性能。数据质量至关重要，&lt;strong&gt;混合数据集和严格验证是性能提升的关键。训练技巧的价值也不容忽视&lt;/strong&gt;，错误掩码和课程学习等看似简单的改进也带来了性能提升。&lt;/p&gt;&lt;p&gt;未来将探索更大模型和更多数据的组合，&lt;strong&gt;扩展到 Python 之外的其他编程语言和其他类型的代码任务，处理企业级的长序列、多文件任务&lt;/strong&gt;，并将 SWE-Lego 应用到真实的软件开发流程中。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考文献&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[1] Badertdinov, I., Golubev, A., Nekrashevich, M., Shevtsov, A., Karasik, S., Andriushchenko, A., ... &amp;amp; Yangel, B. (2025). SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents. arXiv preprint arXiv:2505.20411.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[2] Yang, J., Lieret, K., Jimenez, C. E., Wettig, A., Khandpur, K., Zhang, Y., ... &amp;amp; Yang, D. (2025). Swe-smith: Scaling data for software engineering agents. arXiv preprint arXiv:2504.21798.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;[3] https://github.com/SWE-bench/SWE-bench/issues/465&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>大模型中标TOP10里的黑马：中关村科金的应用攻坚之道</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:46:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ac803b5a-ebae-4bb1-9db4-8ce61e88d0d6/1768271983190.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;一份大模型中标数据报告，揭示了产业重心转移的清晰轨迹：应用类项目占比近六成，市场用真金白银为 &amp;ldquo;落地&amp;rdquo; 投票。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;2025 年，中国大模型产业在招投标市场上演了一场令人瞠目的 &amp;ldquo;狂飙&amp;rdquo;。智能超参数的监测数据显示，全年大模型相关中标项目数量达到 &lt;strong&gt;7539 个&lt;/strong&gt;，披露金额 &lt;strong&gt;295.2 亿元&lt;/strong&gt;，较 2024 年分别激增 &lt;strong&gt;396%&lt;/strong&gt; 与 &lt;strong&gt;356%&lt;/strong&gt;。市场正以前所未有的速度，将技术潜力兑换为商业订单。&lt;/p&gt;&lt;p&gt;更关键的结构性变化在于项目类型：&lt;strong&gt;应用类项目占比高达 58%&lt;/strong&gt;，在 2025 年 11 月甚至达到 63% 的峰值。这明确宣告，产业的焦点已从实验室的参数竞赛，彻底转向商业场景的价值验证。市场用最直接的预算分配，为大模型的发展路径投下了决定性的一票。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;市场转向：从 &amp;ldquo;技术占位&amp;rdquo; 到 &amp;ldquo;价值锚地&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的大模型中标市场，描绘出一条陡峭的指数增长曲线。这不仅意味着市场规模在膨胀，更揭示了价值重心在迁移。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAuYVeYtzyMbImVLgNf2uVeQ1BHP8BC9Sqzw9hn09RBly0qdy9CFJxibA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7046296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527965" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b58f84a2-87a3-47bb-9bbe-c3a83e20add0/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;根据智能超参数的分类，大模型项目被划分为算力、数据、大模型（基座 / 平台）和应用（智能体 / 场景解决方案）四大类。2025 年的数据清晰地显示，&lt;strong&gt;应用类项目以 58% 的数量占比一骑绝尘&lt;/strong&gt;，成为绝对主流。从季度趋势看，其占比从第一季度的 44% 一路攀升至第三季度的 61%，并在第四季度稳定在 60.5%。&lt;/p&gt;&lt;p&gt;与此同时，&lt;strong&gt;算力类项目金额占比最高（52.9%）&lt;/strong&gt;，但数量占比（27%）远低于应用类。这背后是一个关键的市场信号：随着 DeepSeek、通义千问 Qwen 等高性能开源模型的成熟，更多企业选择直接采购算力，调用或微调现有成熟模型，以快速构建自己的应用。大模型（基座 / 平台）类项目占比为 10%，其中智能体开发平台的采购成为重要组成部分。&lt;/p&gt;&lt;p&gt;行业分布同样耐人寻味。教科、政务、通信、能源、金融是项目数量排名前五的行业。其中，&lt;strong&gt;政务行业以金额占比约 40% 位居榜首&lt;/strong&gt;，这与各地政府将智算中心升级为与大模型强绑定的产业赋能中心密切相关。金融行业则在下半年展现出从算力投资向应用部署的明显转向。&lt;/p&gt;&lt;p&gt;从厂商格局看，通用大模型厂商（如科大讯飞、百度、火山引擎、阿里云等）和拥有广泛渠道的三大运营商是中标主力。然而，一个值得注意的现象是，像&lt;strong&gt;中关村科金、蚂蚁数科这样的垂类大模型厂商，凭借在金融等细分赛道的深耕，同样在中标市场占据了一席之地&lt;/strong&gt;。这印证了一个产业判断：当通用模型的能力差距趋于收敛，&lt;strong&gt;生态构建能力与场景掌控力&lt;/strong&gt;，正取代单纯的模型性能，成为新的竞争壁垒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;攻坚样本：中关村科金的 &amp;ldquo;行业深潜&amp;rdquo; 与 &amp;ldquo;场景破局&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在通用大模型厂商凭借全栈能力横扫市场的同时，另一条深耕垂直领域的路径同样结出了硕果。中关村科金，这家并非以通用模型见长的企业，正是这条路径上的一个典型攻坚者，其在中标市场的表现，精准映射了 &amp;ldquo;应用为王&amp;rdquo; 时代的核心逻辑。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkArLp0HCauialpszTDMEvkN5GU1LqqF7UVA7Gd09GiblBmFyooR7S7t9vw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="1.8583333333333334" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527966" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6bcf4175-1285-4af1-b161-ccc93e228e7f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;智能超参数发布的《中国大模型中标项目监测与洞察报告 (2025)》显示，&lt;strong&gt;中关村科金以 23 个中标项目入围 2025 年应用类大模型项目中标厂商 TOP10 榜单，是榜单中少数聚焦垂类场景的大模型厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其战略自始就锚定 &amp;ldquo;应用&amp;rdquo; 与 &amp;ldquo;落地&amp;rdquo;。中关村科金自 2023 年起便战略布局大模型平台，并沿着&lt;strong&gt; &amp;ldquo;平台 + 应用 + 服务&amp;rdquo; 的三级引擎战略&lt;/strong&gt;，推动垂类大模型在垂直行业和场景的应用落地，为 &amp;ldquo;应用为王&amp;rdquo; 提供了多个维度的注脚，其在金融、政务、工业、汽车、零售等多个赛道的全面落地，展现了垂类大模型厂商的独特竞争力。&lt;/p&gt;&lt;p&gt;在工业制造这一复杂且专业壁垒极高的领域，中关村科金展现出将前沿 AI 技术与传统产业深度融合的深厚功力。其助力中国船舶集团经济研究中心打造的&lt;strong&gt;船舶行业大模型 &amp;ldquo;百舸&amp;rdquo;&lt;/strong&gt;，融合了船舶领域百万级专业知识库与长文本推理能力，构建了智能问答、研报写作、文档解读、情报分析等行业智能体，有效推动了船舶行业 &amp;ldquo;数智大脑&amp;rdquo; 的建设。&lt;/p&gt;&lt;p&gt;针对有色金属冶炼等高能耗场景，中关村科金与南方有色金属公司合作，打造了&lt;strong&gt;广西首个有色金属行业大模型&lt;/strong&gt;，通过落地冶炼工艺优化、能源管理、设备智能运维等核心场景智能体，取得了关键生产环节的量化突破：将主操手操作频率降低 90%，温度控制偏差由 &amp;plusmn;15℃收窄至 &amp;plusmn;5℃，并助力综合能耗下降 8%。这标志着垂类大模型已能深入高能耗流程的核心环节，为工业绿色智能化转型提供了关键技术支撑。&lt;/p&gt;&lt;p&gt;在交通基建这类传统上被认为与 AI 技术距离较远的行业，中关村科金也成功开辟了智能化新路径。其与宁夏交建联合打造的&lt;strong&gt;交通基建垂类大模型 &amp;ldquo;灵筑智工&amp;rdquo;&lt;/strong&gt;，基于上万份行业规范、工程技术文档等高质量数据训练，使模型在专业问题上的回答准确率较通用大模型提升 40%。基于该模型构建的专业智能体，在实际应用中平均提效超 60%，不仅解决了工程师撰写施工方案、核算工程量等耗时费力的痛点，更通过智能成本预警等功能，推动了整个行业从 &amp;ldquo;经验驱动&amp;rdquo; 向 &amp;ldquo;数据 + AI 驱动&amp;rdquo; 的转型。&lt;/p&gt;&lt;p&gt;如果说在工业等传统领域的突破证明了其技术下沉的能力，那么在数字化程度最高、要求最严苛的金融行业，中关村科金的深耕则更凸显了其 &amp;ldquo;行业 Know-how&amp;rdquo; 的价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依据智能超参数报告，中关村科金在金融行业大模型项目中标厂商中位列第四&lt;/strong&gt;，仅次于百度云、科大讯飞、火山引擎等大厂，成为垂类厂商深耕金融赛道的标杆代表。其中标项目广泛覆盖智能客服升级、远程视频银行、智能风控合规、智能运营提效等核心业务场景。&lt;/p&gt;&lt;p&gt;中关村科金深耕金融领域多年，已服务 500 多家头部金融机构，包括 50% 以上百强银行及 70% 的信托机构，沉淀了深厚的行业 Know-how。依托其 &amp;ldquo;得助大模型平台 + 金融行业智能体平台&amp;rdquo; 的核心产品组合，中关村科金打造了覆盖 &amp;ldquo;营销 - 风控 - 运营 - 企业服务&amp;rdquo; 全链路的金融智能体矩阵，这并非简单的工具叠加，而是将大模型能力深度融入金融机构从获客、服务到风险管理的核心业务流程。&lt;/p&gt;&lt;p&gt;例如，中关村科金与&lt;strong&gt;中信券商&lt;/strong&gt;合作打造大模型财富助手，能够实时洞察市场动态与数据，精准匹配理财产品与投资组合，并自动生成专业营销话术，助力展业效率提升 3 倍；为&lt;strong&gt;某国有大型商业银行&lt;/strong&gt;提供全栈音视频服务，实现视频银行、合规双录、视频客服、视频会议等全场景统一接入管理；与&lt;strong&gt;中国电建财务公司&lt;/strong&gt;联合打造 &amp;ldquo;财神大模型&amp;rdquo; 及办公智能体，实现员工业务知识获取效率提升 70%；为&lt;strong&gt;百年人寿&lt;/strong&gt;打造的保险知识库问答智能体，问答准确率稳定在 90% 以上，知识获取效率提升 50%，赋能内部 17 个部门；为&lt;strong&gt;申万宏源证券&lt;/strong&gt;打造合规垂直领域专有大模型，赋能员工高效查询制度文件，筑牢业务合规防线。&lt;/p&gt;&lt;p&gt;在智能客服与数字人这一大模型落地最火热的赛道，中关村科金的表现尤为突出，已成为该领域的核心参与者。IDC《中国智能客服市场份额，2024》报告显示，中关村科金位居中国智能客服市场第四，位列垂类大模型厂商第一。根据智能超参数的中标报告，&lt;strong&gt;在 &amp;ldquo;智能客服 &amp;amp; 数字人&amp;rdquo; 应用场景，科大讯飞、百度、中关村科金是中标项目数量排名前三的厂商&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;中关村科金的核心支撑源于自研的得助智能客户平台 5.0，这一覆盖营销服全场景的新一代人机协作智能平台，以 &amp;ldquo;人类员工 + 数字员工&amp;rdquo; 协同为核心，通过多智能体深度联动，让数字员工成为人类员工的专业伙伴与高效延伸。其解决方案已成功赋能金融、汽车、零售、跨境出海、政务民生等多个行业领域，形成了兼具广度与深度的行业实践图谱。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;汽车行业&lt;/strong&gt;，中关村科金的解决方案已深度融入客户运营全链路。例如，其与&lt;strong&gt;丰田&lt;/strong&gt;合作，通过大模型语音智能体进行老客精准营销外呼，在实现超 60% 高接通率，激活沉睡客户；为&lt;strong&gt;岚图汽车&lt;/strong&gt;构建的销售洞察质检平台，则将销售流程合规性提升 70%。这些实践表明，中关村科金正将智能客服从传统的服务支持角色，升级为驱动销售增长与客户体验升级的核心引擎。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;零售与消费领域&lt;/strong&gt;，面对海量、高频的客户咨询与严苛的服务体验要求，中关村科金为&lt;strong&gt;瑞幸咖啡、添可、老板电器&lt;/strong&gt;等知名品牌提供了从智能应答、全渠道服务到全量质检的一体化方案。这些方案不仅有效应对了大促期间的咨询洪峰，更通过智能化工具将客服中心从成本部门转变为提升客户满意度、挖掘服务价值的关键环节。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;全球化服务&lt;/strong&gt;方面，通过构建支持多语种实时互译、全渠道智能路由的 Instadesk 全球客户联络中心解决方案，中关村科金帮助&lt;strong&gt; Imou 乐橙、阿里巴巴国际站&lt;/strong&gt;等出海企业攻克了跨时区、跨文化的服务难题，实现了服务效率与全球用户满意度的双重提升；也为 &lt;strong&gt;UniUni &lt;/strong&gt;这样的北美本地物流平台，以及&lt;strong&gt;泰国大都会水务局&lt;/strong&gt;这样的海外公共服务机构，提供了稳定、高效的多语言智能客服支持，成功将服务能力从企业出海延伸至本地化公共服务领域。&lt;/p&gt;&lt;p&gt;这些遍布多行业的落地案例共同表明，中关村科金的智能客服解决方案不再是简单的问答工具，而是深度嵌入客户旅程、与业务流程紧密耦合的 &amp;ldquo;价值挖掘引擎&amp;rdquo;。这正契合了当前大模型应用从 &amp;ldquo;功能实现&amp;rdquo; 向 &amp;ldquo;业务赋能&amp;rdquo; 演进的核心趋势。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;未来展望：2026，价值交付的深水区与垂类厂商的护城河&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标数据，已经为 2026 年乃至更远未来的发展轨迹画下了清晰的延长线。市场增长的 &amp;ldquo;陡峭曲线&amp;rdquo; 或许会逐渐平缓，但竞争的 &amp;ldquo;深度曲线&amp;rdquo; 将陡然加剧。行业将全面驶入&lt;strong&gt;价值的 &amp;ldquo;深水区&amp;rdquo;&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一，ROI 成为硬指标：从 &amp;ldquo;成本中心&amp;rdquo; 到 &amp;ldquo;利润引擎&amp;rdquo; 的证明之战。&lt;/strong&gt; 随着大模型技术本身日趋成熟和开源化，获取先进 AI 能力的门槛正在迅速降低。2026 年，企业客户将不再满足于 &amp;ldquo;拥有大模型&amp;rdquo; 的演示效果，而是会苛刻地追问每一个 AI 项目的投资回报率（ROI）。这意味着，大模型必须从 &amp;ldquo;成本中心&amp;rdquo; 证明自己作为 &amp;ldquo;利润中心&amp;rdquo; 或 &amp;ldquo;效率引擎&amp;rdquo; 的价值。峰瑞资本创始合伙人李丰的判断正在成为行业共识：AI 投资将进入 &amp;ldquo;第三阶段&amp;rdquo;，即投资真正落地、能挣到钱的应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二，行业 Know-how 与高质量私有数据，将构筑起最坚固的护城河。 &lt;/strong&gt;当通用模型的底层能力可以通过 API 便捷获取时，决定应用效果的将不再是模型的通用性能，而是对特定行业业务流程、专业术语、合规红线的深度理解，以及基于私有数据训练出的 &amp;ldquo;领域专家&amp;rdquo; 能力。中关村科金为中国电建财务公司打造的 &amp;ldquo;财神大模型&amp;rdquo;，与宁夏交建用上万份规范训练的 &amp;ldquo;灵筑智工&amp;rdquo; 大模型，其价值核心正在于此。这些基于海量、高价值、非公开行业数据构建的垂类模型，不仅效果远超通用模型，更因其数据资产的独特性和专业性，形成了竞争对手难以短时间复制的壁垒。未来，&amp;ldquo;数据资产化&amp;rdquo; 与 &amp;ldquo;知识工程化&amp;rdquo; 的能力，将比单纯的算法创新更为关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三，应用形态将从 &amp;ldquo;单点智能工具&amp;rdquo; 演进为 &amp;ldquo;全链路业务智能体&amp;rdquo;。&lt;/strong&gt; 当前的应用大多集中于客服、问答、内容生成等单点环节。下一步，大模型将更深入地与业务流程融合，进化为能够自主完成复杂任务的 &amp;ldquo;业务智能体&amp;rdquo;（Agent）。未来的智能客服将不再是孤立的问答机器人，而是融入客户旅程，能够主动进行销售外呼、完成复杂业务办理、甚至进行客户情绪安抚与挽留的 &amp;ldquo;全能型数字员工&amp;rdquo;。这要求供应商提供的不是单点产品，而是一整套能够与企业现有 IT 系统深度集成、随业务需求灵活编排的智能体生态系统。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGib2wScIJJRS3gBdbXdGaNic1ooYib28CmErmYgno8QrjDaoRE2YwKYWw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527998" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/cfd2e9ac-9259-41e0-b7e5-1f31db85a9b2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;第四，生态协同将成为主流，垂类厂商与通用平台的关系从 &amp;ldquo;替代&amp;rdquo; 转向 &amp;ldquo;共生&amp;rdquo;。&lt;/strong&gt; 未来的市场格局很可能不是 &amp;ldquo;你死我活&amp;rdquo; 的替代关系，而是分层协作的共生生态。像中关村科金这样的垂类应用厂商，将更专注于在特定行业深挖场景，打造开箱即用的行业智能体解决方案；而通用大模型厂商和云厂商，则提供稳定、高效、低成本的算力与模型基座。&lt;strong&gt;中关村科金携手华为云、阿里云、百度智能云、火山引擎、亚马逊云科技、超聚变等企业共同发布的 &amp;ldquo;超级连接&amp;rdquo; 全球生态伙伴计划，正体现了这种开放协作的趋势。&lt;/strong&gt;2026 年，能否融入主流生态、能否与上下游高效协同，将决定一家厂商的市场边界。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025 年的中标狂飙，是中国大模型产业从技术狂热走向商业理性的成人礼。市场用近 300 亿的订单，宣告了 &amp;ldquo;应用落地&amp;rdquo; 时代的正式开启。&lt;/p&gt;&lt;p&gt;2026 年的 &amp;ldquo;价值深水区&amp;rdquo;，将是检验真功夫的战场。大厂之外，像中关村科金这样，凭借对行业的深刻理解与扎实的产品和价值交付能力，已然为企业级大模型和智能体厂商如何穿越周期、赢得市场，提供了一个清晰的范本。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，梁文锋署名开源「记忆」模块，DeepSeek V4更细节了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:18:05 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/30c33348-2e2f-4927-8387-a39e06b425ed/1768270430059.png" style="width: 700%;" class="fr-fic fr-dib"&gt;就在十几个小时前，DeepSeek 发布了一篇新论文，主题为《Conditional Memory via Scalable Lookup:A New Axis of Sparsity for Large Language Models》，与北京大学合作完成，作者中同样有梁文锋署名。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALWDibzfe0HzEE5mIybPwTIAI5uGiaI0QA1ZZqyzr79hq8C0bwgj2SOiaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528058" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8300495e-2055-4ff9-abf8-9873f1500199/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;简单总结一波&lt;strong&gt;这项新研究要解决的问题&lt;/strong&gt;：目前大语言模型主要通过混合专家（MoE）来实现稀疏化，这被称为「条件计算」。但是，现有的 Transformer 缺少原生的知识查找机制，只能被迫通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;针对这一现状，&lt;strong&gt;DeepSeek 提出了条件记忆（conditional memory），从而与 MoE 的条件计算互补，并通过引入一个新模块 Engram 来实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;目前，模块「Engram」相关的实现已经上传到了 GitHub。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA86NTkhF1jNYqnOSG9OAujyOVQa3cUGicFmAPEXKXroicohumgL38XGqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528060" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c16a6833-4c22-46d2-a7f8-a93402bade79/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;项目地址：https://github.com/deepseek-ai/Engram&lt;/p&gt;&lt;p&gt;这让网友们感慨：「DeepSeek is back！」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALjBOxiceaogbXLPCibElgW4JDeWTo2491OtK0YJTS7emWDCWWCPJh3WA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.9717514124293786" data-s="300,640" data-type="png" data-w="1062" type="block" data-imgfileid="503528062" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0a406ecb-aa43-4a96-923a-1b2ebd0b28f6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，结合元旦期间公布的研究《mHC:Manifold-ConstrainedHyper-Connections》，我们可以明确的是 DeepSeek v4 的模样愈发清晰，就等上新了！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;除了条件计算（MoE），LLM 还需要一个独立的条件记忆 Engram&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MoE 模型通过条件计算实现了模型容量的扩展，但现有的 Transformer 架构缺乏原生的知识查找原语，只能通过计算过程低效地模拟检索行为。&lt;/p&gt;&lt;p&gt;为了解决这一问题，DeepSeek 提出了条件记忆（conditional memory）这一与条件计算互补的稀疏化维度，并通过 Engram 模块加以实现。Engram 在经典 𝑁-gram 嵌入的基础上进行了现代化改造，使其能够以 O (1) 时间复杂度完成知识查找。&lt;/p&gt;&lt;p&gt;通过形式化提出稀疏性分配问题，DeepSeek 还发现了一条&lt;strong&gt;呈 U 型的扩展规律&lt;/strong&gt;，用以刻画神经计算（MoE）与静态记忆（Engram）之间的最优权衡关系。&lt;/p&gt;&lt;p&gt;在这一规律的指导下，&lt;strong&gt;DeepSeek 将 Engram 扩展至 270 亿参数规模，并在严格等参数量、等 FLOPs 的条件下，其整体性能显著优于纯 MoE 基线模型&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;尤为值得注意的是，尽管记忆模块本身主要被用于提升知识检索能力（如 MMLU 提升 +3.4、CMMLU 提升 +4.0），但 DeepSeek 观察到其在通用推理能力（如 BBH 提升 +5.0、ARC-Challenge 提升 +3.7）以及代码与数学推理任务（HumanEval 提升 +3.0、MATH 提升 +2.4）上带来了更为显著的增益。&lt;/p&gt;&lt;p&gt;进一步的分析表明，&lt;strong&gt;Engram 能够将静态知识的重建负担从模型的浅层中剥离出来，从而有效加深网络用于复杂推理的有效深度&lt;/strong&gt;。此外，通过将局部依赖关系交由查表机制处理，Engram 释放了注意力机制的容量，使其能够更专注于全局上下文建模，从而显著提升了长上下文检索能力（例如 Multi-Query NIAH 的准确率从 84.2 提升至 97.0）。&lt;/p&gt;&lt;p&gt;最后，Engram 在系统层面同样展现出基础设施感知的高效性：其确定性的寻址方式支持在运行时从主机内存进行预取，几乎不会带来额外的性能开销。&lt;/p&gt;&lt;p&gt;DeepSeek 认为，&lt;strong&gt;条件记忆将成为下一代稀疏大模型中不可或缺的核心建模原语&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;Engram 架构如下，其设计目标是在结构上将静态模式存储与动态计算过程从 Transformer 主干网络中分离出来，从而对其进行增强。该模块对序列中每一个位置依次执行两个功能阶段：检索与融合。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAFKoRVttBOmQoIev9VHCpaVOlLtibYm336AibGdPxlqx2d1wa5kr1OEMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6638888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528063" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d9aef974-d08b-4723-be55-ed8ac921b9a5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在运行过程中，DeepSeek 首先对当前位置的后缀 N-gram 进行提取与压缩，并通过哈希机制以确定性的方式检索对应的静态嵌入向量。随后，这些被检索到的嵌入会在当前隐藏状态的调制下进行动态调整，并进一步通过一个轻量级卷积操作加以精炼。最后，Engram 与多分支架构进行集成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;基于哈希 𝑁-gram 的稀疏检索&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一阶段的目标是将局部上下文映射到静态记忆条目，这一过程主要包括分词器压缩以及通过确定性哈希机制来检索对应的嵌入表示。&lt;/p&gt;&lt;p&gt;分词器压缩：为了最大化记忆单元的语义密度，DeepSeek 引入了一层词表投影（vocabulary projection）。为此，他们预先设计了一个映射函数&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAgSxiccS8q33sCb3TGn941oX3R7gPxTBPYUwhOuHPGQkUic5Y3KsYOmkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2389558232931727" data-s="300,640" data-type="png" data-w="996" type="block" data-imgfileid="503528064" data-aistatus="1" data-original-style="width:58px;height:20px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4b3f0322-af0a-4995-a5d2-f385e590fefe/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 12.44%;"&gt;，其将原始 token ID 映射为基于文本规范化等价关系（例如使用 NFKC 规范化、统一大小写等）得到的规范化标识符（canonical identifiers）。在实际应用中，对于一个规模为 128k 的分词器，该过程能够将有效词表规模缩减约 23%（详见附录 C）。&lt;/p&gt;&lt;p&gt;多头哈希：直接对所有可能的 N-gram 组合空间进行参数化在计算和存储上都是不可行的。借鉴 Tito Svenstrup 等（2017）的工作，DeepSeek 采用了一种基于哈希的近似方法。为了降低哈希冲突的影响，对于每一种 N-gram 阶数 n，引入 K 个相互独立的哈希头。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上下文感知门控&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前一阶段通过哈希 𝑁-gram 从条件记忆中检索得到的嵌入向量，本质上提供的是一种与具体语境无关的静态先验信息。然而，正因为其静态属性，这些嵌入缺乏对当前上下文的自适应能力，并且在实际应用中可能受到哈希冲突或词项多义性带来的噪声干扰。&lt;/p&gt;&lt;p&gt;为此，DeepSeek 在检索之后引入了一种上下文感知的门控机制，其设计灵感来源于注意力机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;系统效率：计算与存储的解耦&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在带有记忆机制的模型中，规模扩展往往受到 GPU 高带宽显存（HBM）容量有限的制约。然而，Engram 所采用的确定性检索机制天然支持将参数存储与计算资源进行解耦。不同于 MoE 依赖运行时隐藏状态进行动态路由，Engram 的检索索引完全由输入 token 序列决定。这种可预测性使得针对训练与推理阶段的专门优化策略成为可能，如图 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAD4Hibb8SMweeACleRMlsD8LmqQlMl1llDq9iciaO6Egveyo8RsPSLNpNQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.725" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528065" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4fe509c8-9e8d-412b-9529-666695d72011/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在训练阶段，为容纳大规模嵌入表，DeepSeek 采用标准的模型并行方案，将嵌入表分片分布在多张 GPU 上。在前向传播过程中，通过 All-to-All 通信原语收集被激活的嵌入行；在反向传播阶段，则将对应梯度分发回各个分片，从而使总可用记忆容量能够随加速器数量线性扩展。&lt;/p&gt;&lt;p&gt;在推理阶段，这种确定性特性进一步支持一种预取&amp;ndash;重叠（prefetch-and-overlap）策略。由于在前向计算开始之前即可确定所需访问的记忆索引，系统能够通过 PCIe 从容量充足的主机内存中异步地预取嵌入向量。为有效掩蔽通信带来的延迟，Engram 模块被放置在主干网络中的特定层级，利用其前序 Transformer 层的计算作为缓冲，从而避免 GPU 计算停顿。&lt;/p&gt;&lt;p&gt;这也要求一种硬件 &amp;mdash; 算法协同设计（hardware&amp;ndash;algorithm co-design）：一方面，将 Engram 放置得更深可以拉长用于隐藏通信延迟的计算窗口；另一方面，从建模效果来看，较早地介入以卸载局部模式的重建更为有利。因此，Engram 的最优插入位置必须同时满足建模性能与系统时延两方面的约束。&lt;/p&gt;&lt;p&gt;此外，自然语言中的 𝑁-gram 天然遵循 Zipfian 分布，即少量高频模式贡献了绝大多数的记忆访问。这一统计特性启发研究者可以构建一种多级缓存层次结构（Multi-Level Cache Hierarchy）：将高频访问的嵌入缓存于更快的存储介质中（如 GPU HBM 或主机 DRAM），而将大量低频的长尾模式存放在容量更大但速度较慢的存储介质中（如 NVMe SSD）。这种分层设计使 Engram 能够扩展到极大规模的记忆容量，同时对有效访问延迟的影响保持在最低水平。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;U 型扩展规律与稀疏性分配&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为「条件记忆」的一种具体实现，Engram 在结构上与 MoE 专家提供的「条件计算」形成了互补。本节旨在探究这种二元特性（Duality）的扩展属性，以及如何最优地分配稀疏容量。&lt;/p&gt;&lt;p&gt;具体而言，本项研究由两个核心问题驱动：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;有限约束下的分配&lt;/strong&gt;：在总参数量和训练计算量固定（即等参数、等 FLOPs）的情况下，应该如何在 MoE 专家与 Engram 嵌入之间划分稀疏容量？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无限记忆范式&lt;/strong&gt;：考虑到 Engram 具有不随规模增长（Non-scaling）的&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAHcWDB842FnjQ5Q4PhGicvSibickXHW66FibPGUah3vTkP1UyWSE1iblunJA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5721925133689839" data-s="300,640" data-type="png" data-w="374" type="block" data-imgfileid="503528067" data-aistatus="1" data-original-style="width:28px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6388a81a-17e5-41f7-ab56-1a51aee7b2c7/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 5.39%;"&gt;查找开销，如果放宽记忆预算或进行激进扩展，Engram 自身会表现出怎样的扩展行为？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首先来看 &lt;strong&gt;MoE 与 Engram 之间的最优分配比例&lt;/strong&gt;。在计算匹配公式时，DeepSeek 使用以下三个参数度量来分析这个权衡：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;P_tot：总的可训练参数，不包括词汇嵌入和语言模型头。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;P_act：每个 token 激活的参数。这一量度决定了训练成本（FLOPs）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMRupgtg13d22OV6JrKF6CiaUEO14Bnv7XCTEib2lv2Mc1fnm8WZlfWMA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.15789473684210525" data-s="300,640" data-type="png" data-w="836" type="block" data-imgfileid="503528069" data-aistatus="1" data-original-style="width:132px;height:21px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/a97cfbce-f1f9-4dc5-87d8-5998968c4163/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 24.99%;"&gt;：不激活的参数，表示可用于扩大模型大小而不增加计算成本的「自由」参数预算（例如未选择的专家或未检索的嵌入）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DeepSeek 在每个 FLOPs 预算内保持 P_tot 和 P_act 固定，这样模型具有相同数量的参数和相同的每 token FLOPs。对于 MoE，P_act 由选定的 top-k 专家决定，而未选择的专家的参数贡献给 P_sparse。对于 Engram，每个 token 只检索固定数量的槽（slots），因此增加嵌入槽的数量会增加 P_tot，但不会增加每 token 的 FLOPs。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAH43shOXT1A8Alp089KGPz1kC74mepCkHpMicXaflpbr2icTfyas8NeXA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.08055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528070" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/6544befb-5aa2-44cb-96da-70dd742d8244/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;「在无限内存模式下的 Engram」&lt;/strong&gt;。在固定参数预算下优化分配之外，DeepSeek 探索了互补的设置：激进的内存扩展。这个研究的动机来自于 Engram 独特的能力，能够将存储与计算解耦。&lt;/p&gt;&lt;p&gt;DeepSeek 使用一个固定的 MoE 主干，具有 P_tot &amp;asymp; 3B 和 P_act = 568M，并训练了 100B 个 token 以确保收敛。在此基础上附加了一个 Engram 表，并调整了槽的数量 M 从 2.58 &amp;times; 10⁵ 到 1.0 &amp;times; 10⁷（增加最多约 13 亿参数）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下图 3（左）揭示了验证损失与分配比例 𝜌 之间一致的 U 形关系&lt;/strong&gt;。值得注意的是，即使 MoE 分配减少到仅 𝜌 &amp;asymp; 40%（即 5.7B 模型为 46 个专家，9.9B 模型为 43 个专家），Engram 模型仍然达到了与纯 MoE 基准（𝜌 = 100%）相当的性能。&lt;/p&gt;&lt;p&gt;此外，纯 MoE 基准证明是次优的：将大约 20%-25% 的稀疏参数预算重新分配给 Engram 获得最佳性能。定量分析中，在 10B 范围内（𝐶 = 6 &amp;times; 10&amp;sup2;⁰），验证损失从 1.7248（𝜌 = 100%）改善到 1.7109，接近 𝜌 &amp;asymp; 80% 时的最优值（&amp;Delta; = 0.0139）。值得注意的是，这一最优点的位置在不同的范围内稳定（𝜌 &amp;asymp; 75%-80%），表明在固定稀疏性下，各个规模之间有一个稳健的分配偏好。这一观察到的 U 形确认了两种模块之间的结构互补性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;图 3（右）展示了增加内存槽数量会显著改善验证损失，并且这一改进在整个范围内持续稳定&lt;/strong&gt;。该曲线遵循严格的幂律（在对数空间中线性），这表明 Engram 提供了一个可预测的扩展旋钮：更大的内存在不需要额外计算的情况下继续带来收益。&lt;/p&gt;&lt;p&gt;关键一点是，在扩展效率方面：虽然 OverEncoding 通过更大的内存表受益，但 Engram 在相同的内存预算下释放了更大的扩展潜力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结合分配规律来看，这些结果验证了条件记忆作为稀疏容量的独立、可扩展轴的作用，它补充了 MoE 的条件计算。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYI9OhrrdFotHP42En2iajz85DmEC2doZWnOoJYLwSXO3e1sdqaCImJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.4925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528081" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/543c6639-1b21-4309-840f-f78637bb6ca7/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过提出的 Engram 架构以及经验推导出的分配法则，DeepSeek 将 Engram 扩展至数十亿参数规模，以验证其在真实语言模型预训练中的有效性。&lt;/p&gt;&lt;p&gt;总共训练了以下四种模型：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Dense-4B（总参数量 41 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MoE-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Engram-27B（总参数量 267 亿），&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以及 Engram-40B（总参数量 395 亿）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所有模型均采用完全相同的数据训练流程（相同的 token 预算及顺序），且在激活参数量上严格匹配。&lt;/p&gt;&lt;p&gt;关于实验设置，所有模型均在包含 2620 亿 token 的语料库上进行预训练，并采用了 DeepSeek-v3 的分词器，其词表大小为 128k。DeepSeek 在涵盖语言建模、知识、推理、阅读理解以及代码 / 数学的多样化基准测试集上对模型进行评估。对于每项基准测试，均遵循标准的提示词协议和评估指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;先来看大规模预训练的实验结果，如下表 1 所示，稀疏架构展示了比密集模型更优的扩展规律。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在相同的训练计算预算下，所有三种稀疏变体（MoE-27B，Engram-27B/40B）在所有基准测试中显著超越了 iso-FLOPs 的 Dense-4B 基准。&lt;/p&gt;&lt;p&gt;更重要的是，&lt;strong&gt;Engram-27B 在 iso - 参数和 iso-FLOPs 的 MoE-27B 基准上持续取得改进&lt;/strong&gt;。有趣的是，这些提升并不限于知识密集型任务（例如，MMLU: +3.0，MMLU-Pro: +1.8，CMMLU: +4.0），在这些任务中，内存容量直观上是有益的。此外还观察到，在一般推理领域（例如，BBH: +5.0，ARC-Challenge: +3.7，DROP: +3.3）以及代码和数学推理任务（例如，HumanEval: +3.0，MBPP: +1.6，GSM8K: +2.2，MATH: +2.4）中，改进更加显著。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;扩展到 Engram-40B 进一步减少了预训练损失，并提高了大多数基准测试的性能&lt;/strong&gt;。尽管它尚未在每个任务上严格超越 Engram-27B，但这可能是由于训练不足的结果。此外，Engram-40B 与基准模型之间的训练损失差距在训练结束时继续扩大，表明扩展的内存容量尚未在当前的 token 预算内完全饱和。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACCBl08YcAEt8TJGEtgr6co2ElHKhympbpN6GoEMgJUSpFhSAichtaQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.1018518518518519" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528082" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/3989c993-b2fb-4a25-b836-10319eb4d81b/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;接下来是&lt;strong&gt;长上下文训练&lt;/strong&gt;。通过将局部依赖建模卸载至静态查找，Engram 架构为处理全局上下文保留了宝贵的注意力容量。DeepSeek 通过进行长文本扩展训练，对这一结构性优势进行了实验验证。通过采用严密的评估协议，将架构设计带来的贡献与基础模型本身的能力剥离开来，证明了 Engram 在长程检索和推理任务中带来了显著的性能增益。&lt;/p&gt;&lt;p&gt;DeepSeek 首先解耦基础模型能力与架构设计之间的影响，其次进行受控对照分析，结果如下表 2 所示，主要得出了以下两个结论：&lt;/p&gt;&lt;p&gt;一是&lt;strong&gt;超越注意力机制的长文本能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;虽然注意力机制和位置编码为上下文处理提供了结构基础，但实验结果表明，长文本性能并非仅由架构先验决定。通过观察 Engram 的演进轨迹（从 41k 步到 50k 步），即使在控制相同模型架构和固定长文本扩展阶段计算预算的前提下，长文本性能仍随预训练进程单调提升。这表明长文本性能与基础模型的通用建模能力存在内在耦合。因此，严谨的架构对比必须通过对齐「基础模型损失（Loss）」而非仅仅对齐「训练步数」来控制这一混淆变量。&lt;/p&gt;&lt;p&gt;二是&lt;strong&gt;受控设置下的架构优越性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;基于上述原则，DeepSeek 将 Engram 与 MoE 基准模型进行了对比测试。在控制基础能力的前提下，Engram 模块的效率增益变得十分显著：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等损耗设置（Iso-Loss Setting，41k 步 vs. 基准）&lt;/strong&gt;：该设置严格分离了架构效率的影响。当对比 Engram-27B（46k 步）与完整训练的 MoE-27B（50k 步），即预训练损失完全对齐的两个模型时，Engram 表现出显著增益。具体而言，它在复杂检索任务中大幅超越基准模型（例如，多查询「大海捞针」 NIAH：97.0 vs. 84.2；变量跟踪 VT：87.2 vs. 77.0）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;等计算量设置（Iso-FLOPs Setting，50k 步 vs. 基准）&lt;/strong&gt;：在标准的等计算预算下，Engram-27B（50k 步）进一步拉大了差距，在所有指标上均实现了顶尖性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极端设置（约 82% 计算量）&lt;/strong&gt;：即使是提前停止训练的 Engram-27B（41k 步），在面对完整训练的 MoE-27B（50k 步）时依然极具竞争力。它在 LongPPL 指标上与基准持平，并在 RULER 测试中实现超越，这充分证明了 Engram 架构的内在优越性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503528083" data-ratio="0.45555555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAfwbCxbtEKFLia4VL5J1662B4LxwO0Paq8m6Heic6ia4E5OCA0R09tvB4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/62e24474-5ef0-4253-8ddc-2de57dec69c3/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，下图 4 是&lt;strong&gt;对表示对齐与收敛速度的分析&lt;/strong&gt;。(a) 基于 LogitLens 的逐层 KL 散度分析。在模型浅层，KL 散度持续保持在较低水平，这表明 Engram 加速了预测的收敛。(b-c) 为基于 CKA 计算的相似度热力图。高相似度对角线显著的向上偏移表明，Engram 的浅层在功能上等效于 MoE 模型的深层，从而有效地增加了模型的深度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZIWf0cDNkZhTrlYbpiaicpZlRyIRuflwhEsYTJR8Cziatupd9FzHzJ6kg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.5324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503528084" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/547b3877-47dc-45a6-9614-011ee6e43a5b/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更多细节请参考原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>一个模型统一4D世界生成与重建，港科大One4D框架来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 13 Jan 2026 10:10:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-13</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-13</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/9100d25b-1d5e-4994-8380-46ec7215d836/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;本文第一作者密振兴，香港科技大学计算机科学与技术学院人工智能方向博士生，研究方向是多模态理解与生成，视频生成和世界模型，目前正在寻找工业界全职职位。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近年来，视频扩散模型在 &amp;ldquo;真实感、动态性、可控性&amp;rdquo; 上进展飞快，但它们大多仍停留在纯 RGB 空间。模型能生成好看的视频，却缺少对三维几何的显式建模。这让许多世界模型（world model）导向的应用（空间推理、具身智能、机器人、自动驾驶仿真等）难以落地，因为这些任务不仅需要像素，还需要完整地模拟 4D 世界。&lt;/p&gt;&lt;p&gt;来自香港科技大学（HKUST）的研究团队提出 One4D，一个统一的 4D 生成与 4D 重建框架。One4D 构造了一个同步输出多模态的视频扩散模型，能够用一个模型同步输出 RGB 视频与 Pointmap（XYZ）几何视频，并支持从单张图像到 4D 生成、从稀疏帧到 4D 生成 + 重建、以及从完整视频到 4D 重建等多种任务形态。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAy5FibWXueDFAwrB8GuU8D5SeXcCfHSlScdE5NGdFUNwMiawiaZfkFgTVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.7925925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527905" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/aee20b91-4ff5-448e-bc7f-1b9d0cf75fca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2511.18922&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github：https://github.com/MiZhenxing/One4D&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;二、One4D 算法设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 的核心目标是用强大的视频生成模型（比如Wan Video）统一 4D 生成与 4D 重建，输出对齐的 RGB 和几何多模态结果。论文亮点有：&lt;/p&gt;&lt;p&gt;1. 多模态输出：RGB + Pointmap；&lt;/p&gt;&lt;p&gt;2. DLC：解耦 LoRA 控制，稳住 RGB 同时学几何对齐；&lt;/p&gt;&lt;p&gt;3. UMC：统一掩码条件，一套模型覆盖生成和重建任务。&lt;/p&gt;&lt;p&gt;具体来说，One4D 将动态 4D 场景表示为两种同步的输出模态。(1) RGB frames（外观）；(2) Pointmaps（XYZ），即与 RGB 视频对齐的 3 通道几何视频，每个像素存 XYZ 值，可进一步导出 Depth 并结合后处理估计相机轨迹，最终可视化为 4D 点云和相机。&lt;/p&gt;&lt;p&gt;并且，One4D 在一个框架内支持三种输入：单张图到 4D 生成，稀疏视频帧到 4D 生成 + 重建，完整视频到 4D 重建。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. DLC：解耦 LoRA 控制&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在基于视频扩散模型的 &amp;ldquo;RGB + 几何&amp;rdquo; 多模态联合建模里，一个常见做法是把模态在通道维拼接。但在低资源微调时，这会导致严重的跨模态干扰，几何学不好，基础模型的 RGB 质量也容易被拖垮。而将两个模态在长宽维度拼接，共享参数，也会导致跨模态干扰，几何精度不高，而且与 RGB 无法保持对齐。&lt;/p&gt;&lt;p&gt;One4D 提出 Decoupled LoRA Control（DLC） 来专门解决这个问题，设计目标包括：&lt;/p&gt;&lt;p&gt;(1) 低资源微调也尽量保住底座视频模型的强先验；(2) 解耦 RGB 与几何生成，减少互相干扰；(3) 仍要保留必要的跨模态通信，确保像素级对齐一致。&lt;/p&gt;&lt;p&gt;具体做法是：&lt;/p&gt;&lt;p&gt;1. 为 RGB 与 Pointmap 分别挂载模态专属 LoRA，并且形成两条解耦计算分支，共享冻结的 base 参数，但 forward 分开跑。确保两个模态能够相对独立。&lt;/p&gt;&lt;p&gt;2. 再用少量 zero-init 的 control links 连接对应层，让两个模态从 0 开始逐步学会互相控制，从而实现精确的像素级对齐。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQTZaZkW0GIAP9IuIHY8oIRqgkYpEs9mgSJVMfMjkiaqlRdevibVTZbHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3425925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527877" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b7804e0d-830e-4922-a9f5-72aa7875997f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从直观上理解 DLC 的设计， RGB 分支努力保持视频美学与运动先验，几何分支专心拟合几何视频的分布，少量控制连接负责对齐同步。这也正是 One4D 强调的多模态输出同步生成的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. UMC：统一掩码条件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了使用同一个视频模型统一 4D 的生成和重建，One4D 基于Wan Video的多任务框架，提出了 Unified Masked Conditioning（UMC），把不同类型的条件如单帧、稀疏帧、全视频，统一打包成一个条件视频，缺失帧用 0 填充，并使用一个 mask 张量指定哪些帧需要生成。单张图对应纯生成，稀疏帧对应混合生成 + 重建，全视频对应纯重建。在UMC的具体实现上，RGB 分支的条件视频通过 VAE 编码之后，连接到 RGB 的 latent states 上。而 XYZ 分支不直接使用这个条件视频，控制信号是通过 DLC 从 RGB 传递给 XYZ，这保证了 XYZ 分支能够更好地去适应新模态。UMC 的设计让 One4D 具备一个非常实用的能力，同一个扩散骨干，同时做 4D 生成和 4D 重建。One4D 模型不需要为不同任务改结构，只需改变输入帧的稀疏度，就可以在不同生成与重建任务之间平滑切换。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAnGBjSE74EJmJvQPuSGjUhwJE32v1YhP5XGCOibkzACIONCmbiaVSbsHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527906" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2844cf21-3eb5-49ac-91f4-7b3309ea4dbe/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 训练数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练 One4D，需要获得大规模 &amp;ldquo;外观 - 几何&amp;rdquo; 配对数据。One4D 的数据构建遵循两个原则：几何要准、分布要真实。因此我们采用合成数据 + 真实数据混合策略。&lt;/p&gt;&lt;p&gt;合成数据通过游戏引擎渲染动态场景，天然提供每帧的几何真值，用于为 Pointmap（XYZ）提供稳定监督，帮助模型学到可靠的时序几何一致性。&lt;/p&gt;&lt;p&gt;真实数据，收集自公开视频数据的真实场景视频，以覆盖复杂光照、材质、运动模式。由于真实视频通常缺少几何真值，我们使用现有的 4D 重建方法 Geo4D 生成几何标注，从而把真实世界外观分布引入训练。&lt;/p&gt;&lt;p&gt;这套数据策略带来的直接收益是，合成数据提供几何精度与稳定性，真实数据提供视觉多样性与真实分布，从而让 One4D 在保持视频质感的同时，也能输出可用、对齐、时序一致的 4D 几何结果。One4D 使用 34K 条视频在 8 张 NVIDIA H800 GPU 上训练 5500 步，就得到了很好的效果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 单图到 4D 生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文将 One4D 与 4DNeX 做了单图到 4D 的对比，评价指标有：&lt;/p&gt;&lt;p&gt;用户偏好（User study）：在一致性、动态性、美学、深度质量、整体 4D 连贯性等维度上，One4D 全面领先。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAWSiayo3LXZanO22cpWzGmfMu0fC3gibktSb7X851adcRyxS3EiaTxbu2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.3055555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527879" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/c6c11557-ff3c-46c6-9e87-2ce280279238/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;VBench：动态性（Dynamic）显著提升（55.7 vs 25.6），同时 I2V consistency 仍保持可比水平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAOKXBMNEWoX3XJu21mtsJlVXs9mUgWSw8PUyAXhyQl9OnGWzX1xDGDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3296296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527880" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/a987755f-c7a5-4872-8efc-7e49f3a9eada/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些结果支持了 One4D 的优势，输出的多模态结果有更真实的 RGB 动态、更干净的深度、更完整连贯的 4D 点云与相机轨迹。在不牺牲 RGB 视频质量的前提下，仍然能学到准确、细粒度的 4D 几何结构。更多对比视频请移步项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAbRXDSNibZtWxzuqTDrHCQStJ0aKz3mTkIRhz45XE1voWQx4orUR7ndw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5592592592592592" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527881" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/fd5af25d-4b44-48f2-a7a6-cc569a261c16/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. 完整视频到 4D 重建&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 并不只在 4D 生成任务上优势显著，它还是一个重建模型，在完整视频 4D 重建上也保持了不错的性能。在深度重建评测数据集 Sintel 和 Bonn 上，One4D 的表现明显超过一些只做重建的方法如 MonST3R 和 CUT3R。即使我们的方法使用 Geo4D 构造了训练数据，它也取得了与只做重建的 Geo4D 相近的效果。更多对比视频请移步项目主页：https://mizhenxing.github.io/One4D&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkANTdicLL9p38qtQ0fHwTX40IjPbZicqYHB7Sy8sXOYRYk5UZbMqsxEicbA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7611111111111111" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527883" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5b2e704c-5ffa-4106-bb34-074d79ac472e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsB03GfkiaTfwRp5l4yymUSDEMia5ZFPIGH79jQMgibXDEINrZ7jH3Yyhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.9259259259259259" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527884" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/97cf48e9-d4db-4a82-b270-cf479ba392f6/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在相机轨迹评估数据集 Sintel 和 TUM 上，One4D 的相机估计能力也保持了可用精度，充分证明了 One4D 统一重建与生成的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAQpRJNibhjhzibxogWwy7nd92WczNVIjMia9lcFusFFYmG5PAIiaBNChwsQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527902" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/7d7d6c39-71c5-402b-8808-2fbb97ccc0ca/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 稀疏视频帧到 4D 生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在稀疏视频帧设置下，One4D 的输入仅是首尾帧以及少量中间帧，此时模型需要生成缺失 RGB 帧并补全完整几何序列。实验证明，即使在极稀疏条件下，One4D 仍能得到合理的 4D 结构。这意味着 One4D 不止能做重建，而是真正具备生成动态 4D 场景的能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA9jhZuT98kJib0EibMzADYDm8W0vfZtPCvFcPMvVHdMW05mGboDse9vJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527901" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/94de583a-c911-4c5d-a94b-f7e55b25dcd5/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One4D 让视频扩散模型不再只会生成 RGB，而是能够同步生成外观（RGB）与几何（Pointmap / 深度 / 相机轨迹），在同一套框架中统一了 4D 生成和重建任务。它通过 UMC 与 DLC 解决了多任务切换与多模态联合训练中最关键的稳定性与对齐问题。One4D 推动视频生成走向生成可用于理解与交互的 4D 世界，为下一代世界模型与多模态内容创作提供了更实用的基础能力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>端到端智驾的算力困局，九章智算云这样破局</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Mon, 12 Jan 2026 17:08:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;前言：智驾的&amp;ldquo;iPhone时刻&amp;rdquo;，正在被算力重新定义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026年1月7日至8日， 中国汽车大数据融合与创新应用大会 在上海隆重举行。作为汽车产业数字化转型的重要风向标，本次大会汇聚了来自整车厂、零部件企业、高校科研机构及AI技术平台的300+行业精英，聚焦&amp;ldquo;数据驱动创新&amp;rdquo;的核心命题。&lt;img src="https://image.jiqizhixin.com/uploads/editor/63f8c2ab-1beb-432d-966b-48b61e9914de/%E5%9B%BE%E7%89%87000.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;在这场高规格的技术盛宴中， 九章智算云（Alaya NeW）技术总监胡宗星 受邀发表主题演讲《 跨越&amp;ldquo;算力墙&amp;rdquo;&amp;mdash;&amp;mdash;超大规模集群如何加速端到端智驾 》，深入剖析当前智能驾驶从模块化向端到端演进过程中面临的三大基础设施挑战，并系统性地展示了九章智算云在解决这些问题方面的方案与价值。&lt;img src="https://image.jiqizhixin.com/uploads/editor/18cb4a63-2fb9-48e0-aecc-8eb36afa7a72/%E5%9B%BE%E7%89%8700.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端到端智驾：一场从&amp;ldquo;规则驱动&amp;rdquo;到&amp;ldquo;感知决策一体化&amp;rdquo;的革命&lt;/strong&gt;&lt;br&gt;&lt;br&gt;这是九章智算云技术总监胡宗星指出，过去，大家做模块化智驾，是将感知、预测、规划拆开，告诉车见到红灯停、见到行人让。那时候，几十台服务器就够用了。而如今，行业正迈向端到端（End-to-End）架构 &amp;mdash;&amp;mdash;直接输入原始摄像头视频流，输出车辆控制指令。这不仅意味着模型参数量跃升至百亿级别，更带来了对算力、数据吞吐和系统稳定性的全新要求。&amp;ldquo;这不是简单的硬件升级，而是一场关于 超大规模计算集群 的战役。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三座大山：算力墙、存储墙、通信墙&lt;/strong&gt;&lt;br&gt;&lt;br&gt;智驾每升一级，算力需求增长10倍。这不是买几台服务器就能解决的问题，这是一场关于超大规模集群（Hyperscale Cluster）的战役。面对这场变革，传统IT架构迅速暴露出三大瓶颈：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;计算墙 ：单卡算力有限，无法支撑千亿级参数模型训练；&lt;/li&gt;&lt;li&gt;&amp;middot;存储墙 ：海量视频数据读取速度跟不上GPU计算速度，导致GPU空转；&lt;/li&gt;&lt;li&gt;通信墙 ：多卡间通信延迟高、拥塞严重，使得&amp;ldquo;1+1&amp;lt;2&amp;rdquo;的现象频发。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些痛点共同构成了所谓的&amp;ldquo; 基础设施危机 &amp;rdquo;&amp;mdash;&amp;mdash;即使你拥有最先进的GPU，也无法发挥其全部潜力。&amp;ldquo;如果把GPU比作大脑，那么网络就是血管，存储是食物供给。任何一个环节卡住，整个系统都会瘫痪。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;九章智算云的破局之道：专为AI而生的基础设施&lt;/strong&gt;&lt;br&gt;&lt;br&gt;针对上述挑战，九章智算云提出了一套完整的解决方案&amp;mdash;&amp;mdash; 构建面向AI原生的超大规模集群架构 ，具体体现在三个核心技术方向：&lt;img src="https://image.jiqizhixin.com/uploads/editor/b4a69cf9-d83d-4208-82ec-6c519457150f/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;strong&gt;&amp;nbsp;推倒&amp;ldquo;通信墙&amp;rdquo;：构建微秒级低时延无损网络&lt;/strong&gt;在千卡级集群中，网络是决定效率的关键。九章智算云采用 RoCE v2无损网络 + Fat-Tree结构 ，实现全链路微秒级延迟，确保数据高速流动，避免因网络拥塞造成训练中断。哪怕几千张卡同时吼叫，网络也能从容应对。&amp;ldquo;就像给数据修了一条永不堵车的高速公路。&amp;rdquo;&lt;br&gt;&lt;br&gt;打通&amp;ldquo;存储墙&amp;rdquo;：三级存储加速策略端到端训练最怕什么？怕GPU算得太快，数据读写跟不上。为解决数据供给瓶颈，九章智算云设计了&amp;ldquo; 热-温-冷 &amp;rdquo;三级存储架构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;热数据 ：通过全闪存阵列与分布式缓存，实现毫秒级响应；&lt;/li&gt;&lt;li&gt;温/冷数据 ：按访问频率分层存储，兼顾性能与成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一机制确保GPU始终处于&amp;ldquo;满负荷运行&amp;rdquo;状态，大幅提升资源利用率。搞定&amp;ldquo;稳定性&amp;rdquo;：故障自愈保障持续训练不管你的单卡多强，在千卡集群面前，硬件故障不是&amp;ldquo;会不会发生&amp;rdquo;，而是&amp;ldquo;什么时候发生&amp;rdquo;。 GPU掉卡、ECC报错、网络抖动，这是常态。试想一下，如果你跑了一个月的模型，因为最后一天一张卡坏了而前功尽弃，那是灾难。九章智算云有一个绝活是 &amp;ldquo;故障自愈&amp;rdquo;机制，通过实时监测，一旦发现某张卡有&amp;ldquo;罢工&amp;rdquo;的苗头，系统将自动隔离故障节点，并从最近的断点（Checkpoint）自动拉起训练任务，&lt;strong&gt;全程无需人工干预&lt;/strong&gt;。&amp;ldquo;我们将有效训练时间占比提升至95%以上，让一个月的训练不再因为一张卡掉线而功亏一篑。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语：专注模型，剩下的交给我们&lt;/strong&gt;&lt;br&gt;&lt;br&gt;在演讲最后，九章智算云技术总监胡宗星强调：&amp;ldquo;在端到端智驾的赛道上，算法专家应该专注于让模型更聪明，而不是去修服务器、调网络、处理崩溃。&amp;rdquo;九章智算云的存在意义，正是为了 将底层复杂的算力管理、网络优化、容错机制等&amp;lsquo;脏活累活&amp;rsquo;彻底解放出来 ，让客户能够以更低的成本、更高的效率，专注于模型创新与业务落地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;展望未来：助力中国智驾走向世界&lt;/strong&gt;&lt;br&gt;&lt;br&gt;此次在 2026中国汽车大数据融合与创新应用大会 上的精彩分享，不仅是九章智算云技术实力的一次集中展示，也标志着国产AI基础设施正在从&amp;ldquo;跟随者&amp;rdquo;向&amp;ldquo;引领者&amp;rdquo;转变。随着智能驾驶进入规模化落地阶段， 高性能、高稳定、高性价比的算力平台将成为产业竞争的新高地 。九章智算云将继续深耕AI原生基础设施，携手车企、研究院与开发者，共同推动中国智能汽车产业迈向新纪元。九章智算云（Alaya NeW） &amp;mdash;&amp;mdash; 用最强的网络、最快的存储、最稳的集群，加速智驾未来的到来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;后记&lt;/strong&gt;&lt;br&gt;&lt;br&gt;本次活动由ATC汽车技术平台主办，复旦大学大数据研究院协办。九章智算云作为受邀的AI算力基础设施服务商，展现了中国企业在智能驾驶底层技术领域的深厚积累与创新能力。&lt;br&gt;未来，我们将持续参与行业交流，推动技术开放与生态共建，为中国汽车产业的智能化转型注入强劲动力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>真香！刚骂完AI，Linux之父的首个Vibe Coding项目上线</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 15:06:20 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/14c32ba6-4250-4978-8901-f45ca54c0d89/1768201395481.png" style="width: 700%;" class="fr-fic fr-dib"&gt;时代变了，就连 Linus Torvalds 现在也氛围编程（Vibe Coding）了。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503527915" data-ratio="0.7001953125" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZ8fslDia3gtGZxsdFmyB0UQOK8V0hKNAQ6gyRcd07Mjibv09ZPyptSiaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1024" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/62a6f83c-0c3a-49c5-ac24-e4ccfb080e0c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;上周末，最著名程序员、Linux 作者 Linus Torvalds 发布 Vibe Coding 项目的消息让不少人始料未及。&lt;/p&gt;&lt;p&gt;大神在 GitHub 上发布了一个名叫 AudioNoise 的新项目，和 Linux 并列。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAy427dp7ocWbBPNN82LZn2OYG7xRvgibMcWbE3Wc32vesxwic1NyWR4fA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.4203703703703704" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527916" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7a3b288d-86cd-43e2-8d63-0508e9960f59/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在自述文件中，Torvalds 说这是一个和吉他效果器相关的代码库，「这些效果器在利用 AI 技术『模拟箱体』&amp;hellip;&amp;hellip; 另外需要注意的是，这个 Python 可视化工具基本上是用 Vibe Coding 的方式编写的。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAMiaAuGU6qeytHyicEiaEKtS3sPV48ZwCxXtQZPwjsnFAficqAumzpt7DoA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8274725274725274" data-s="300,640" data-type="png" data-w="910" type="block" data-imgfileid="503527917" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a64dbb4a-3fa8-4ab3-ae2b-10a7d6028837/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Torvalds 表示，他对模拟滤波器的了解要比对 Python 的了解要多得多。一开始写这个项目时，他就像平时那样通过谷歌搜索然后照搬照抄的方式进行编程，但后来他决定省略中间环节 &amp;mdash;&amp;mdash; 也就是他自己 &amp;mdash;&amp;mdash; 直接使用 Google Antigravity 来实现音频样本的可视化。&lt;/p&gt;&lt;p&gt;看起来在新年假期里，Torvalds 也没有闲着，他也在顺应最近科技界最大的 AI 潮流。&lt;/p&gt;&lt;p&gt;对此，人们的反应既有欢迎的，也有谨慎的。首先当然是普大喜奔：「官宣了，Vibe Coding 是合法的。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA8x6cUozDujmh2rWeTU3xcRkDxCjOsgncActwr0VSgVPykjFfUXmg2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.30886075949367087" data-s="300,640" data-type="jpeg" data-w="395" type="block" data-imgfileid="503527919" data-aistatus="1" data-original-style="width: 332px;height: 103px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/ee470b50-5d4f-47e0-83ab-d2df3b4876c7/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Torvalds 首个 AI 项目，生成了什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个名为「AudioNoise」的项目在 5 天前上传到了 GitHub，目前已经收获了 1.4k 的 Stars。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAqbDaPZiaWMYwbgDU6eoqpmDXTIEQotctFyIjicoZZVjnG8NicIuXXhRDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.40555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527921" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d6071f6d-92b2-4a74-9967-6629c1135407/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;GitHub 地址：https://github.com/torvalds/AudioNoise&lt;/p&gt;&lt;p&gt;根据主页介绍，&lt;strong&gt;AudioNoise 项目源自 Torvalds 几个月前做的一个「随机吉他效果器板设计」（GuitarPedal），包括电路原理图和代码&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这是他在 Linux 内核之外的一个兴趣尝试，目的不是打造成品设备，而是探索运算放大器（op-amp）等电路设计原理，详情可参考以下项目。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAmaKTsw8FXKyGukLEnfmeQPy1y8SNNicICZNMaICREjx29FlCxEBibgHg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.40185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527922" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8022af40-8e5c-490c-a1ce-ce7c4cbcb24f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;GitHub 地址：https://github.com/torvalds/GuitarPedal&lt;/p&gt;&lt;p&gt;从上个项目的结果来看，虽然 Torvalds 制作的基于树莓派 RP2354A 开发板和 TAC5112 音频编解码器的数字吉他单块效果器确实可以正常运行。但是 Torvalds 对一些模拟接口的选择并不太满意，尤其是那些电位器。此外他越来越讨厌那个会发出咔嗒声的脚踏开关，即使它能兼做编程时的引导选择开关。&lt;/p&gt;&lt;p&gt;因此，Torvalds 暂时没有去管硬件设计，而是认真琢磨了物理交互界面以及数字音效。他的想法很简单，「既然全都是数字化的，那就先搞模拟，别太纠结硬件。」&lt;/p&gt;&lt;p&gt;这就像 Torvalds 最开始做模拟电路一样，只是玩玩而已，不必太当真。&lt;strong&gt;本项目主要的设计目标是学习数字音频处理相关的基础知识，这和他此前做吉他单块项目来学习硬件的初衷完全一致。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;项目中并没有什么基于 FFT（快速傅里叶变换）的声码器，有的只是 IIR（无限冲激响应）滤波器和基础的延迟循环。&lt;/p&gt;&lt;p&gt;一切都是「单采样输入，单采样输出，并且零延迟」。采样可能会存储在延迟循环中，以便在后续调用时实现回声效果），但也没有进行任何复杂的实时处理。&lt;/p&gt;&lt;p&gt;Torvalds 对 TAC5112 在 ADC（模数转换器） 到 DAC（数模转换器） 链路中低于毫秒级的延迟表现很满意，因此现在也打算延续这种设计思路。再加上他以前没做过这些，所以单从新手这个角度来看，一切都显得非常基础和简单。&lt;/p&gt;&lt;p&gt;换句话说：这些 IIR 滤波器并不是现代单块或吉他音箱里那种高端的 AI「箱体模拟」。虽然它们确实能模拟移相器等模拟电路，但只是通过数字全通滤波器来模拟 RC（电阻器和电容器）网络的效果，并没有用到什么真正高深的技术。&lt;/p&gt;&lt;p&gt;Torvalds 特别强调了，&lt;strong&gt;项目中的 Python 可视化工具基本上是靠「氛围编程（Vibe-Coding）」写出来的&lt;/strong&gt;。他起初只是采用典型的「搜索并照猫画虎」式编程，但后来省去了中间人（他自己），&lt;strong&gt;直接让 Google Antigravity 来写这个音频采样可视化工具&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;对于 AI 编程工具的加入，Torvalds 自己的心得是：&lt;strong&gt;过程基本顺利&lt;/strong&gt;，虽然他有时需要琢磨一下使用「内置矩形选择」功能时到底出了什么状况。在告诉 Antigravity 直接写一个自定义的 RectangleSelector 之后，情况就好了很多。&lt;/p&gt;&lt;p&gt;如果要问&lt;strong&gt;氛围编程是不是要比他自己动手写出来的效果好呢？他的回答是肯定的&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkACA5B0s3ACOgNb4gVEh33pzz8btQaUzZlhVVEPTOVzZfqsF6m5lsRIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.8101851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527923" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/a7797ce0-f68e-4b45-9c27-c93f48c24dc8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Torvalds 使用的 AI 软件开发平台 Antigravity，是去年 11 月谷歌刚刚发布的智能体式开发平台，直接对标 Cursor。&lt;/p&gt;&lt;p&gt;它将传统的 AI 驱动的集成开发环境 (IDE) 发展为「智能体优先」的形态。背靠谷歌自家的最新大模型 Gemini 3，可以驱动编程智能体自主规划和执行复杂的、端到端的软件任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkADgk2tVxxfYxaA9QbDUHHmCgiaWzbic511MGK8iapfu84USNKdTtpWbkDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.48055555555555557" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527924" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/40082d06-25ad-43fc-866b-55748c77779e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然，更重要的是，这个工具目前在招揽用户时期是免费使用的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;圈内热评：AI 大势下的「顺流而下」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Linux 之父开始使用 AI 编程工具这一「罕见的盛况」，在圈内引发了现象级的讨论，简直是「活久见」系列。&lt;/p&gt;&lt;p&gt;有人感叹，「我认识的最厉害程序员，包括那些构建编译器、CUDA 内核和操作系统等最核心功能的程序员，他们以前对「所有 AI 代码都是垃圾」的呼声最高。但如今，他们的想法正在迅速改变，并对 AI 的强大感到震惊。没有时间去否认这一点了。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAkD0vtkPPqN9FunMmSZwo34rxMN0wiaQ2MSvXG31fibOyicpqyLqVYbKhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5657407407407408" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527926" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/c6722554-db52-4540-999f-4e766b47034a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Antigravity 创建者、谷歌 DeepMind 工程师 Varun Mohan 视 Torvalds 为自己的编程偶像之一，此次对其能够在最新的项目中使用该 AI 编程工具感到莫大的荣幸。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAKViaBtvqvJVt1eq5h7RFglF1icYj5PdqOyBaz8bVRa5VTw5PemKMOMTQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527927" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/21148314-de6f-493e-a9fd-dacf7e4b00d1/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;云开发平台 Vercel CEO Guillermo Rauch 列举了 2026 开年发生的几件大事，其中 Torvalds 在其非内核项目中使用氛围编程与陶哲轩宣布 GPT 和 Aristotle 自主解决 Erdős 问题、编程大神 DHH 收回在 Lex 播客中发表的「AI 不会编程」的言论等并列。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAJAIUUn5msB7M0DficqTq61lSlgZ2gjNgSb2bpcdsjOHOuTZy55XXhJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1.0212962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527928" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/d1049b86-28ea-400d-83c7-6de787b63a2a/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;几天前，Linus 还在骂 AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为曾经引领时代的程序员大神，Linus Torvalds 对于 AI 写代码这件事的态度还是相对保守的。至少直到去年底，他在几次采访中还是把编程分为「入门」与「生产」两个维度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv5lu1S4vnMM4s4xdIzso9Mw5l5pCiaxB6VPWMqs77azddWfLsL3AfLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527929" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/88bdfdcb-f8c4-4a05-8610-55c8940f4f52/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他认为对于非专业人士来说 Vibe Coding 是一项降低门槛的伟大技术，但对于生产环境和内核开发，Linus 明确表示 Vibe Coding「是一个非常，非常糟糕的主意 &amp;mdash;&amp;mdash; 如果你自己都不理解代码的逻辑，当它在生产环境中崩溃时，你根本无法修复。」&lt;/p&gt;&lt;p&gt;Torvalds 认为目前的 AI 辅助编程主要是「90% 的营销加 10% 的现实」，极其反感那些利用 AI 生成「垃圾代码」并提交给内核维护者的行为。&lt;/p&gt;&lt;p&gt;1 月 7 日，在 Linux 内核开发人员讨论如何规范 AI 生成的 Linux 内核时，Torvalds 忍不住插话进来：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAEGcdqpgTBeibuWylF7K64Uf71j4f83XBh7WjdAHCkwWDH7A3yQ9pDAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.9453703703703704" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527931" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/b93e1aa8-c963-4704-9893-e5b5f4ad73c2/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;他表示：「讨论 AI 生成的垃圾毫无意义，简直愚蠢至极。那些生成垃圾内容的人根本不会在他们的补丁中注明这一点。所以，停止这种愚蠢的行为。我不希望任何内核开发文档包含任何关于人工智能的声明。」&lt;/p&gt;&lt;p&gt;这样厌恶的态度，让人想起当年他对老黄竖起的中指。&lt;/p&gt;&lt;p&gt;不知为何在骂完之后，Torvalds 就放出了自己用 AI 写好的代码。&lt;/p&gt;&lt;p&gt;AudioNoise 这个小项目，会成为 Linus Torvalds 的「真香时刻」吗？&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reddit.com/r/theprimeagen/comments/1q9q2kd/linus_torvalds_is_a_vibecoder_now/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/AiBattle_/status/2010105477166969307?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://github.com/torvalds/AudioNoise&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://news.ycombinator.com/item?id=46569587&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/kimmonismus/status/2010445425694867753?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2010215226978042218?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/_mohansolo/status/2010023056778137699?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>引入几何约束后，VLM跨越了「空间推理」的认知鸿沟</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 15:00:53 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/6350129a-df86-4485-a3ff-06a05ead53f1/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;现有的视觉大模型普遍存在&lt;strong&gt;「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;语义-几何鸿沟」（Semantic-to-Geometric Gap）&lt;/strong&gt;，不仅分不清东南西北，更难以处理精确的空间量化任务。例如问「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;你坐在沙发上时，餐桌在你的哪一侧？&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」，VLM 常常答错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;这种「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语义‑几何鸿沟」源自于视觉大模型的语义空间无法承载高保真的几何细节，导致其在空间推理时是在「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;凭空瞎猜」，这使得模型读懂了画面的语义，却停留在「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语言的世界」中，不具备现实世界赖以运行的几何直觉，导致空间判断漏洞百出。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgzspD2PWXLxLQym7vvtfC3eTNejia4FcWw4mpZxicibN1HIyC6W79gUvfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.24259259259259258" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527563" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c909d735-54a3-4218-b7b2-b84337bc34eb/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="2 2 []"&gt;论文标题：Geometrically-Constrained Agent for Spatial Reasoning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2511.22659&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;作者团队：Zeren Chen, Xiaoya Lu, Zhijie Zheng, Pengrui Li, Lehan He, Yijin Zhou, Jing Shao, Bohan Zhuang, Lu Sheng&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;通讯单位：北京航空航天大学，上海人工智能实验室&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://gca-spatial-reasoning.github.io&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目代码：https://github.com/gca-spatial-reasoning/gca&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对这一痛点，&lt;strong&gt;北京航空航天大学&lt;/strong&gt;与&lt;strong&gt;上海人工智能实验室&lt;/strong&gt;的研究团队创新提出了&lt;strong&gt;几何约束智能体（Geometrically-Constrained Agent, GCA）&lt;/strong&gt;，开创了&lt;strong&gt;「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;先形式化约束，后确定性计算」&lt;/strong&gt;的空间推理新范式。GCA 不依赖海量数据微调，而是通过构建形式化任务约束，强制 VLM 从「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;模糊直觉」转向「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;精确求解」，通过视觉工具调用和编写计算代码进行参数化计算，为空间推理搭建了一座可验证、确定性的几何桥梁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;GCA 直接带领 Qwen、Gemini 等基座模型实现「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;能力跃迁」。在公认高难度的 MMSI-Bench 测试中，GCA 将模型性能提升近 50%，击败现有 Training-based 及 Tool-integrated 方法，并在多个主流空间推理测试中确立了空间推理领域的新 SOTA。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgQr3oibD3FysOQcuBpkd2oM90icGsmPHzPAFSFn2TXafb9tKfZ2Vjh2vA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.5055555555555555" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527564" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/305fea21-3161-4a19-9e7b-2f0d31949ec2/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;核心挑战：跨越「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px; margin-right: 8px; line-height: 1.75em; text-align: center;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;语义 - 几何」的认知鸿沟&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;视觉语言模型（VLM）在图像描述与通用语义理解上表现卓越，然而，当任务转向需要高精度几何计算的空间推理时 &amp;mdash;&amp;mdash; 例如判断物体的精确朝向、测量距离或进行视角变换 &amp;mdash;&amp;mdash; 其表现却显著下滑。&lt;/p&gt;&lt;p&gt;研究团队指出，这种能力断层的根源在于&lt;strong&gt;「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;语义 - 几何鸿沟」&lt;/strong&gt;。具体表现为：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉 &amp;amp; 几何信息的有损压缩&lt;/strong&gt;：VLM 将丰富的像素信息压缩为抽象的语义特征，这一过程如同将一幅详细地图简化为几个地标名称，导致物体精确位置、朝向、尺度等高保真几何细节大量丢失。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;几何想象的缺失&lt;/strong&gt;：以「坐在沙发上」这一场景为例，VLM 仅能调用模糊的空间常识（知道人与沙发通常同向），却无法在脑海中精确构建出「从沙发视角看去」的三维场景。这种几何想象力的匮乏，使其在面对复杂空间推理时力不从心。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;🛠️ 核心方法：基于形式化约束的两阶段推理&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgUXoJUTh5z052kicaIAmSTTRqNZeKVn3m5Yo5MJibHC3P7PiaCD2OXPR8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527565" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/86c1be07-eef2-4f1e-a7d3-00d5e9d0a330/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了在「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语义」与「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;几何」之间搭建可靠桥梁，GCA 创新性地引入了&lt;strong&gt;形式化任务约束&lt;/strong&gt;（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg649GlJcLYRXb4llT3GdVDoKTgxeaSGNxsAIyQNNLpz9zKqrUmTkY6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6885245901639344" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="503527605" data-aistatus="1" data-original-style="width:32px;height:22px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/96df95bb-0ab9-45f5-b42d-6e22ac071210/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 5.48%;"&gt;），将空间推理精准拆解为两个阶段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 任务形式化 &amp;mdash;&amp;mdash; 从「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;模糊指令」到「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;精确规则&lt;/span&gt;&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;VLM 首先扮演「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语义分析师」的角色，利用其强大的语义理解能力，将模糊的自然语言指令转化为明确的数学约束。这一步骤不涉及具体计算，而是确立规则：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参考系约束（&lt;/strong&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgqEYOrHNX9Y2yapcILnQUC9DAVT3QuzGt41qtJrHWWcQGrSAUBJl9pg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.975" data-s="300,640" data-type="png" data-w="80" type="block" data-imgfileid="503527606" data-aistatus="1" data-original-style="width:23px;height:22px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2f8842d6-d0e5-4123-a1db-38cefd4517eb/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 3.88%;"&gt;）：明确空间计算的「锚点」。GCA 归纳了三种人类常用的核心参考系，模型必须从中指定其一：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基于物体的参考系 (Object-based Frame)&lt;/strong&gt;：利用物体自身的坐标系。例如指令「当你在洗手时...」隐含了观察者必须「面对洗手池」，因此参考系由洗手池的朝向决定。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基于相机的参考系 (Camera-based Frame)&lt;/strong&gt;：即标准的视图坐标系。例如「从图 1 的视角来看...」，此时参考系直接绑定为相机的基于方向的参考系 (Direction-based Frame)：由两个物体的位置关系定义。例如「烤箱在水槽的北面」，此时「北」的方向由从水槽指向烤箱的向量严格定义。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgYThRIgSpvOCBp4JjnstV0UWTWxfdbqWwqNGS5zxOHbca9rzSeK1XDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527566" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/10fc5d16-5f48-4b13-af2e-c66920b5ef0a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;目标约束（&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgheBcibicBBk6VZtZoySialZCh09r4XLINKIibGC0JibvjVPr3icKv18ciaUdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.048780487804878" data-s="300,640" data-type="png" data-w="82" type="block" data-imgfileid="503527607" data-aistatus="1" data-original-style="width:22px;height:23px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5e959d53-0222-45f4-8ca7-e23bbc665399/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.88%;"&gt;）&lt;/strong&gt;：明确要解答的「几何问题」本身，例如具体的距离值、角度或方位。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. 几何计算 &amp;mdash;&amp;mdash; 在规则内进行「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;确定性求解」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在确立约束后，VLM 转变为「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;任务求解器」。它不再进行开放式的语义联想，而是严格遵循 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg649GlJcLYRXb4llT3GdVDoKTgxeaSGNxsAIyQNNLpz9zKqrUmTkY6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6885245901639344" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="503527605" data-aistatus="1" data-original-style="width:32px;height:22px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/684cb7b5-bf5c-49ee-920a-b1063a8a69b7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 5.59%;"&gt; 划定的边界，调用 3D 重建、目标检测、OCR 等感知与计算工具（Toolbox），执行确定性的几何计算，在参考系 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgqEYOrHNX9Y2yapcILnQUC9DAVT3QuzGt41qtJrHWWcQGrSAUBJl9pg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.975" data-s="300,640" data-type="png" data-w="80" type="block" data-imgfileid="503527606" data-aistatus="1" data-original-style="width:23px;height:22px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/738c2b55-be68-49b4-8dcf-5beb27a5a30e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 4.22%;"&gt; 下求解目标 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgheBcibicBBk6VZtZoySialZCh09r4XLINKIibGC0JibvjVPr3icKv18ciaUdA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="1.048780487804878" data-s="300,640" data-type="png" data-w="82" type="block" data-imgfileid="503527607" data-aistatus="1" data-original-style="width:22px;height:23px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/9c149648-84ce-43cb-ae2c-7be1cbbf6d08/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 3.48%;"&gt;。这一阶段的高效实现依赖以下三个核心设计：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;智能工具调度与绑定&lt;/strong&gt;：VLM 像指挥官一样，调度 3D 重建等感知工具获取数据，并能智能地将「最左边的椅子」等模糊描述，精准绑定到具体的几何对象上，消除语义歧义。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;感知与计算的无缝衔接&lt;/strong&gt;：感知工具负责将视觉世界参数化为高保真 3D 表示，计算工具则负责执行代码、完成坐标转换，二者在统一框架下协同，实现从「看到」到「算准」的闭环。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;检索增强的可靠计算&lt;/strong&gt;：采用类似 RAG 的策略，VLM 从一个已验证的几何公式库中检索正确模型来生成代码，从根本上杜绝「幻觉」，确保每项计算都基于可靠的物理原理。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;实验结果：全新的空间推理 SOTA&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 MMSI-Bench、MindCube-tiny、OmniSpatial 等多个主流空间推理基准上，GCA 证明了其有效性，构建了一个全新的空间智能 SOTA。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;综合性能提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GCA 取得了 65.1% 的平均准确率，显著超越了现有基于训练的方法与工具集成的方法。特别是在极具挑战性的多图空间推理基准 MMSI-Bench 中，面对复杂的视角变换与相对方位推断，现有主流模型往往只能徘徊在 25%~30% 左右的「随机猜测」水平线。&lt;/p&gt;&lt;p&gt;而基于 Qwen3-VL-Thinking 构建的 GCA，准确率从 32.6% 跃升至 47.6%。这一数据证明，GCA 成功让 VLM 摆脱了「蒙答案」的困境，向具备可靠的空间推理能力迈出了关键一步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强大的通用性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GCA 并非特定模型的「专属补丁」，而是一种无需训练（Training-free）的通用推理范式，可直接赋能各类基座模型。&lt;/p&gt;&lt;p&gt;实验显示，在搭载 GCA 架构后，受测模型在 MMSI-Bench 上的性能平均实现了约 37% 的相对提升。其中，基于 Gemini-2.5-Pro 构建的 GCA 表现尤为惊艳，其准确率从 36.9% 飞跃至 55.0%，有效地激发了顶级模型的空间推理潜力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgSsAaC9icez3QCfMGQiamW4EVNxIZ4XCYIMEICWibATwLB78EOVSnicLuDQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.3907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527567" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/0209a4ef-5201-4fea-9639-eb5904933f6e/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgVy7pVQib0UG9H4ChkJvsXdWmfr6pZxMnYoHV3Ad4avjauleWEk3haFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3592592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527568" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/f5af012e-416e-43bc-b9de-cc78427c763d/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;通过系统的消融实验与归因分析，研究进一步证实了 GCA 架构的前瞻性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;形式化约束至关重要&lt;/strong&gt;：对比实验表明，若仅为 VLM 提供工具而不施加形式化约束（Unconstrained Tool Use），其性能提升微乎其微。这证明，缺乏 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKg649GlJcLYRXb4llT3GdVDoKTgxeaSGNxsAIyQNNLpz9zKqrUmTkY6Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.6885245901639344" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="503527605" data-aistatus="1" data-original-style="width:32px;height:22px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/a40be931-1a12-4639-8a86-aab9e22b0aaf/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 5.92%;"&gt;&amp;nbsp;的引导，VLM 无法做出正确的几何规划；正是「先约束」的范式，真正释放了工具的潜力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可解释的错误归因&lt;/strong&gt;：得益于 GCA 架构的模块化设计，研究团队能够对推理链路进行精确的错误归因。分析显示，VLM 在「任务形式化」阶段的准确率已高达～70%，当前主要错误来源于下游感知工具（如 3D 重建失败或遮挡）。这表明，GCA 的推理逻辑是稳健的，其性能将随着感知模型的进步而持续提升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1JLmRXb2YuRrm3uG76sKgyKnW4wjg8vdxKZia7sFHXPMAnD5FfZBEgLHbiblLmNBzyoZGIUocibmqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.25555555555555554" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527569" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/fea59f97-ea24-41aa-9def-5d206280c4e5/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结与意义&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GCA 提出了一种「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;语言定义约束，几何执行计算」的新范式。通过将模糊的空间查询转化为带约束的数学问题，GCA 有效避免了 VLM 在有损语义空间中进行不可靠的空间想象。这不仅大幅提升了推理的准确性，也让机器向拥有「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;几何直觉」迈出了关键一步，回应了攀登「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;空间智能」高峰的核心挑战。&lt;/span&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>清华等团队用AI驱动百万倍速药物筛选，一天内十万亿次扫描的超高速虚拟平台</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 12 Jan 2026 14:11:13 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMsufN3S0jWLyiclA0PAgLaOIMPsJPiamLjZH2hYU4AhyYuiagf0QNL8Iyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5675925925925925" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027124" data-aistatus="1" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/e867f7bd-00ba-4c4e-a259-437989f37078/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;作者丨论文团队&lt;/p&gt;&lt;p&gt;编辑丨ScienceAI&lt;/p&gt;&lt;p&gt;人类基因组编码约有 20000 种蛋白质，其中 90% 与疾病密切相关，却长期处于 &amp;ldquo;无药可靶&amp;rdquo; 状态。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;关键生物机制隐藏在庞杂而碎片化的数据中，但即便拥有高通量实验和海量分子数据，研究者仍然需要依赖经验，在无数可能性中逐一试探。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;清华大学智能产业研究院（AIR）- 北京智源人工智能研究院&amp;ldquo;健康计算联合研究中心&amp;rdquo; 兰艳艳教授课题组带来了新的成果。他们研发的 AI 驱动的超高通量药物虚拟筛选平台&amp;nbsp;DrugCLIP，能以千万倍的对接速度实现精准的虚拟筛查。&lt;/p&gt;&lt;p&gt;相关研究内容以「Deep contrastive learning enables genome-wide virtual screening」为题，于&amp;nbsp;&lt;span data-pm-slice='1 1 ["para",null]'&gt;2026 年 1 月 9 日&lt;/span&gt;发布在《Science》。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMibqDUulV38fvFcQppy2iaoZXFpU89kMvCO67iaGcmYKzicuEibDSaytHRlA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4186046511627907" data-s="300,640" data-type="png" data-w="688" type="block" data-backw="546" data-backh="229" data-imgfileid="100027116" data-aistatus="1" data-original-style="width:100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/984815f9-4981-4ee1-a013-dfb4420aa963/640.png" alt="图片" data-before-load-time="1768198201754" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;论文链接：https://www.science.org/doi/10.1126/science.ads9530&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式重构：从&amp;ldquo;物理模拟&amp;rdquo;到&amp;ldquo;跨模态向量检索&amp;rdquo;的技术跃升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统药物筛选长期受困于&amp;ldquo;不可能三角&amp;rdquo;：精度、通量与化学空间规模。传统的分子对接高度依赖原子级的物理受力模拟，面对万亿级分子库时，庞大的计算代价让全基因组筛选成了不可能完成的任务。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMAQRYzFHEOXFvIeYibnqM4r2uicHtkRQpZn4gJuXTLIUvM0M3hx7qhmibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6926406926406926" data-s="300,640" data-type="png" data-w="693" type="block" data-backw="546" data-backh="378" data-imgfileid="100027117" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b7107aae-d3c8-4f87-bb89-4c4eb8fd0dbf/640.png" alt="图片" data-before-load-time="1768198201975" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：化学空间与化合物库。&lt;/p&gt;&lt;p&gt;DrugCLIP 的核心创新在于创造性地构建了蛋白质口袋与小分子的&amp;ldquo;向量化结合空间&amp;rdquo;。它不再执着于模拟分子如何&amp;ldquo;卡入&amp;rdquo;蛋白的动态过程，而是利用深度对比学习技术，将复杂的生物相互作用重构为计算机领域极度成熟的向量检索问题。&lt;/p&gt;&lt;p&gt;在这种硬核架构下，团队展现了极具前瞻性的 AI 逻辑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;自监督结构预训练： 团队创造性地从海量蛋白数据中切取片段模拟&amp;ldquo;假配体&amp;rdquo;，构造了多达 550 万组 训练样本。这种策略让 AI 在接触真实药物前，就已深刻领悟了蛋白表面的结构特征，赋予了模型极强的 Zero-shot泛化能力。&lt;/li&gt;&lt;li&gt;多尺度表征对齐： 团队通过训练两个深度神经网络编码器，将蛋白口袋的 3D 拓扑结构与小分子的化学表征映射到同一个高维共嵌入空间（Joint Embedding Space）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMibtvBRyNftOGiaVN4a7FwjfSzzQrWQiajrf3tFMVbfneNPbFymvV5bWaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9761006289308176" data-s="300,640" data-type="png" data-w="795" type="block" data-backw="546" data-backh="533" data-imgfileid="100027118" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/13799d7c-e8d3-45c9-a91c-2e131436c7e9/640.png" alt="图片" data-before-load-time="1768198202014" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：DrugCLIP 的框架。&lt;/p&gt;&lt;p&gt;这种算法级的范式转换，直接将单节点（128 核 CPU + 8 张 GPU）的日打分能力推向了 10 万亿次（10 的 13 次方） 的巅峰。相较于传统工具，筛选效率提升了 100 万倍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从预测到验证：攻克&amp;ldquo;暗靶点&amp;rdquo;与 AlphaFold 结构的无缝对接&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DrugCLIP 的价值不仅在于算力的飞跃，更在于其对全新靶点的硬核筛选能力。针对此前既无实验结构、也无已知抑制剂的&amp;ldquo;暗靶点&amp;rdquo;&amp;mdash;&amp;mdash;人源 E3 泛素连接酶 TRIP12（与癌症和帕金森相关），DrugCLIP 直接基于 AlphaFold2 预测的蛋白结构进行盲筛，成功命中多个活性抑制剂。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMSbMvadncckurMjeZvk9G3mtYQzpXHuPJ2VV3eONuPT2RBqldtNEASg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.2314814814814814" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="546" data-backh="673" data-imgfileid="100027119" data-aistatus="1" data-original-style="width:100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c7d2faa2-429f-4052-bb50-962e9a45026c/640.png" alt="图片" data-before-load-time="1768198202064" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：借助 GenPack 将 DrugCLIP 应用于 AlphaFold 预测结构。&lt;/p&gt;&lt;p&gt;在临床靶点 NET（去甲肾上腺素转运体）的实验中，DrugCLIP 筛选出的候选分子中有 15% 证实有效，且部分分子的活性直接超越了现有的一线临床药物。相关复合物结构已通过冷冻电镜解析，进一步验证了其生物学可信度。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMnzxXibpKHdOjHLrkLEgId99ibUpfbEchD3wW1fvR8UCKmibcdTBGAydLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.0537037037037038" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="546" data-backh="575" data-imgfileid="100027121" data-aistatus="1" data-original-style="width:100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/4b89e525-8d3d-4c5c-85a4-4f8e009d76e1/640.png" alt="图片" data-before-load-time="1768198202383" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：DrugCLIP 的计算机模拟基准测试结果及针对 NET 的湿实验验证。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;赋能万众创新：开启基因组级药物发现生态&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了践行赋能科研社区、重塑药物研发现状的愿景，研究团队利用 DrugCLIP 完成了人类历史上首次全基因组规模的虚拟筛选：覆盖约 1 万个蛋白靶点、2 万个结合口袋，对超过 5 亿个小分子进行全量对齐，产出 200 万个高潜力靶点分子对，并据此构建了目前全球规模最大的蛋白-配体筛选数据库 GenomeScreenDB。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMtua4TYkZknNyzE7XdPIHIVq0TedPzVITMuBntjgiclFtgmc66nENDVA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.4381720430107527" data-s="300,640" data-type="png" data-w="744" type="block" data-backw="546" data-backh="239" data-imgfileid="100027122" data-aistatus="1" data-original-style="width:100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/471dc8b7-73b0-4551-9584-b8c466a0cc38/640.png" alt="图片" data-before-load-time="1768198202398" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：全基因组虚拟筛选结果的 t-SNE 可视化图及实例与靶点数量维恩图。&lt;/p&gt;&lt;p&gt;早在 2025 年 6 月，清华 AIR 已联合智源研究院预先发布了 DrugCLIP 平台，正式向全球科研社区免费开放。截至目前，该平台已吸引了超过千余名科研人员深度使用，累计完成了超过万次大规模筛选任务。 这种极速、低门槛的筛选体验，正在极大地降低新靶点开发的起始门槛。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLn4Nic50kephkB1G2465uMXMZmjEyDlyTdibp8Fra8GeooAMOrbCwLl5coJzKPlksYNqpJE4elgZSCg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4603174603174603" data-s="300,640" data-type="png" data-w="693" type="block" data-backw="546" data-backh="251" data-imgfileid="100027123" data-aistatus="1" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b3e4a12d-a5e0-4640-9622-39952f80039e/640.png" alt="图片" data-before-load-time="1768198202414" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;图示：&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;DrugCLIP 官网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;相关链接：https://www.drugclip.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;作为 AI4S（AI for Science）重塑生命科学底层逻辑的绝佳范例，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;DrugCLIP&amp;nbsp;&lt;/span&gt;正在重新定义药物发现的路径与边界，推动人工智能成为下一代医疗突破的核心驱动力。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",null]'&gt;DrugCLIP 不仅实现了药物筛选速度的百万倍级提升，更首次完成了全基因组规模的药物映射，实现了从&amp;ldquo;大海捞针&amp;rdquo;到&amp;ldquo;精准定位&amp;rdquo;的筛选突破。在此基础之上，进一步提升靶点与药物分子匹配的精度、推动药物从筛选到设计的全链条贯通，成为接下来的关键方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",null]'&gt;DrugCLIP 的发表，不仅是对技术突破的国际认可，更意味着药物研发正式迈入&amp;ldquo;后 AlphaFold 时代&amp;rdquo;的规模化、系统化新阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;相关报道：https://phys.org/news/2026-01-ai-tool-discovery-life-medicines.html&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>2026年，大模型训练的下半场属于「强化学习云」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:24:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3177c979-5de5-4d7c-a344-0b87d712ac1d/1768195078091.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2024 年底，硅谷和北京的茶水间里都在讨论同一个令人不安的话题：&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650942531&amp;idx=1&amp;sn=2fabcd16a94b0966864aaf18c6338faf&amp;scene=21#wechat_redirect" target="_blank"&gt;Scaling Law 似乎正在撞墙&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;那时候，尽管英伟达的股价还在狂飙，但多方信源显示，包括彼时备受期待的 Orion（原计划的 GPT-5）在内，新一代旗舰模型在单纯增加参数规模和训练数据后，并未展现出预期的边际效益提升。另外，也有研究认为预训练所需的数据将会很快耗尽，其甚至还预测了明确的时间节点：2028 年。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkALf5AERXPc62A6EIBStJTcQ5GwfUPhS6q03jbbENvaZwc3e4589DtuQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.6027777777777777" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527888" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/cfad2cd2-a2e7-41a8-9305-9a758923b90f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 来自论文 arXiv:2211.04325v2&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;OpenAI 和 Safe Superintelligence Inc 的联合创始人 Ilya Sutskever 当时还留下了一句意味深长的判词：「2010 年代是规模扩大的时代，现在人们又回到了奇迹和发现的时代。」这句话在当时被许多人解读为悲观的预警，也就是单纯依靠堆砌算力和数据的预训练路线，恐怕已经触到了天花板。&lt;/p&gt;&lt;p&gt;直到 2025 年初，接连的惊喜打破了僵局。&lt;/p&gt;&lt;p&gt;那时候，OpenAI 的 o1 模型已在几个月前率先引入了强化推理，展示了模型在思考时间换取智能深度上的惊人潜力，证明了 test-time scaling（测试时间扩展）是一条通往更高智能的可行路径。然而，o1 的闭源特性让这项技术一度被视为只有巨头才能掌握的「黑科技」。&lt;/p&gt;&lt;p&gt;2025 年 1 月 横空出世的 DeepSeek R1 将 o1 的技术路线成功复现并彻底开源。它的意义不在于从零发明，而是用极低的成本和开放的姿态向全行业证明：&lt;strong&gt;Scaling Law 并没有撞墙，它只是换了引擎&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;DeepSeek R1 等推理模型的成功揭示了一个事实：&lt;strong&gt;深度的推理能力比单纯的参数规模更关键。&lt;/strong&gt;通过强化学习（RL）驱动的思维链（CoT），模型在后训练阶段展现出了类似于人类「慢思考」的推理能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAGA9be6iceO5Tmib7aYKia7hW5BiaEvPoK4u9Ox8kZWYhGndfO0v6rvsOFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.4583333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527887" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9590c21b-25cb-4e7d-95bf-3c11d8659ed9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; DeepSeek-R1 的多阶段训练流程，来自 arXiv:2501.12948v2&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;正如九章云极 DataCanvas AI 首席科学家缪旭在 2025 算力生态大会上回顾的那样：「DeepSeek 的横空出世，让我们第一次感觉到，原来强化学习可以让大模型的进化速度再次提升。」对于更广泛的开发者而言，这种「感觉」正是源于 DeepSeek 拉低了技术门槛。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAF8YQML1WXO2RHPPPoKOCq8z5JqlByCdWCGDicibB7anDdqdSeCoJzwfA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.6648148148148149" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527891" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/3b1b1126-7de7-4814-8d1f-40276a2d3246/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;看起来，算力的重心正从 &lt;strong&gt;pre-training scaling（预训练扩展）&lt;/strong&gt;走向&lt;strong&gt; post-train scaling（后训练扩展）&lt;/strong&gt;和&lt;strong&gt; test-time scaling（测试时间扩展）&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAsXPhyg7G7zEGtK6UCrVon26Rg53DFZz9X0mPhU8UDE5EZ2D5Equusg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527889" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/23487201-98cb-43cf-a471-09928702fb9a/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;来自英伟达博客&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 2026 年的今天，我们已经可以确信：&lt;strong&gt;大模型训练的下半场属于强化学习。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在这个阶段，模型不再仅仅是基于海量预训练数据的概率涌现，而是能像人类专家一样，通过与环境的交互、试错和自我博弈，进行深度的逻辑推演。&lt;/p&gt;&lt;p&gt;如果说预训练是培养一个通识教育的毕业生，那么基于 RL 的后训练就是将其投入真实世界，进化成一名真正的专家。然而，新的机遇也带来了新的基建危机：当算力的消耗重心从静态的&lt;strong&gt;训练&lt;/strong&gt;转向动态的&lt;strong&gt;探索与推理&lt;/strong&gt;，现有的云计算架构开始显得力不从心。&lt;/p&gt;&lt;p&gt;行业呼唤一种全新的算力形态，去承载这种以「&lt;strong&gt;进化&lt;/strong&gt;」为核心的新智能。而在这一轮基础设施的代际更迭中，谁能率先定义这种形态，谁就能握住下一个时代的入场券。&lt;/p&gt;&lt;p&gt;基于这一观察，缪旭在演讲中抛出了一个定义未来的公式：「&lt;strong&gt;当智能可以并行进化，强化学习云将成为群体智能的放大器。&lt;/strong&gt;」&lt;/p&gt;&lt;p&gt;这里的关键词「&lt;strong&gt;强化学习云&lt;/strong&gt;」，正是九章云极为应对这场范式转移给出的基础设施答案。作为&lt;strong&gt;独立智算云赛道的领军企业&lt;/strong&gt;，九章云极不仅首先提出了这一概念，更通过前瞻性的布局，率先定义了后训练时代的算力标准。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首发优势 &amp;nbsp;为什么九章云极能定义「强化学习云」？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 OpenAI o1 验证了路径，DeepSeek R1 引爆了热潮，那么九章云极则是在最短时间内率先给出了基础设施答案。&lt;/p&gt;&lt;p&gt;仅仅数月后的 2025 年 6 月，九章云极便正式发布了&lt;strong&gt;业界首个工业级强化学习云平台 Agentic RL&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;而当时，放眼全球，尽管以 Anyscale (Ray) 为代表的硅谷先驱已经在分布式计算框架层面为强化学习提供了底层支持，AWS、谷歌等云巨头也已将 RL 视为通用机器学习平台（如 SageMaker、Vertex AI）下的一个功能组件或工具包，但整体上主流市场的目光仍主要聚焦于如何构建更大的预训练集群或降低传统推理（inference 而非 reasoning）成本，尚未有任何一家企业像九章云极这样，敏锐地洞察到智能体（Agent）时代的算力特征变革，并&lt;strong&gt;将「强化学习」独立定义为一种全新的工业级云服务形态&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这种能够迅速捕捉前沿算法趋势，并率先将其转化为标准化、工业级云产品的能力，正是九章云极在独立智算云赛道中确立首发优势与领军地位的基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么我们需要专门的强化学习云？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统的云计算架构，本质上是为静态负载设计的。无论是 Web 服务还是传统的深度学习推理（inference），其计算特征相对线性且可预测。但强化学习截然不同，它是一个高频交互、动态探索的过程。智能体需要在模拟环境中进行海量的试错，而这会导致算力需求呈现出剧烈的波峰波谷特征，且对异构资源的调度有着极高的要求。&lt;/p&gt;&lt;p&gt;如果用传统的静态算力去跑 RL 训练，结果要么资源利用率极低，要么在探索高峰期直接卡死。&lt;/p&gt;&lt;p&gt;针对这一痛点，九章云极并没有选择在旧架构上打补丁，而是进行了系统级的重构。其强化学习云 Agentic RL 基于混合专家（MoE）架构与 Serverless 理念，实现了算力的「&lt;strong&gt;按需即取、即用即还&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;数据显示，相比于传统方案，&lt;strong&gt;Agentic RL 可将端到端训练效率提升 500%，综合成本下降 60%&lt;/strong&gt;。更关键的是，它是&lt;strong&gt;全球首个支持万卡级异构算力调度的强化学习基础设施平台&lt;/strong&gt;。这种对大规模异构算力的驾驭能力，标志着九章云极已经率先完成了从「卖资源」到「卖能力」的进化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agentic RL：让通用模型变成专家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;顾名思义，Agentic RL 的核心是 &lt;strong&gt;Agentic（智能体）&lt;/strong&gt;和 &lt;strong&gt;RL（强化学习）&lt;/strong&gt;。但 Agentic RL 并不只是智能体与强化学习的简单叠加，其内涵蕴涵了 AI 能力维度的一次关键跃迁：从单纯的「内容生成」转向复杂的「决策控制」。&lt;/p&gt;&lt;p&gt;在这里，「&lt;strong&gt;控制&lt;/strong&gt;」尤为关键。在九章云极看来，无论是供应链的动态调度，还是工业设计的精密规划，本质上都是一个高难度的&lt;strong&gt;控制问题&lt;/strong&gt;。Agentic RL 的核心目标，正是通过 RL 赋予大模型这种在动态环境中精准感知、规划并执行的能力，使其从单纯的语言专家进化为能解决实际物理世界难题的执行者。&lt;/p&gt;&lt;p&gt;正是为了支撑这种「从生成到控制」的能力跨越，在 2025 算力生态大会上，九章云极 AI 首席科学家缪旭进一步展示了其强化学习云背后的 Agentic RL 技术架构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4JzWZHTaqZEUZf7icMJ3vGj7tJMn2ATibdheat4U5dB6oTxpKwBLlC3Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.40370370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527890" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/61f69a39-03ec-4a65-b8ea-aeab9633e509/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;简单来说，Agentic RL 的使命是将通用模型进化为专家模型，其应具备长时程规划、长/短期记忆、复杂工具调用、检索增强生成优化、角色一致性等多种能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA0OQxPn9zm2AoBOtyq8icict5Iz0HFab93asDT65QCmAzJ0jmZPvmiaBZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527892" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/10c7a0ed-1165-435d-9424-ccbaad3c2e04/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;基于此，缪旭提出了一个更宏大的终局构想：未来的通用人工智能（AGI）可能不会是一个单一的巨型模型，而是由成千上万个垂类专家智能体组成的「&lt;strong&gt;群体智能&lt;/strong&gt;」。&lt;/p&gt;&lt;p&gt;不同于传统的强化学习，面向群体智能的 Agentic RL 面对的是极度复杂的目标，比如城市规划的长时序约束，或工业设计的精密系统组合。为了支撑这种高难度的进化，九章云极构建了一些核心技术，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;极致效能的异步系统&lt;/strong&gt;：针对 RL 训练中极不稳定的负载特征，九章云极研发了全异步训练架构，通过 rollout 和 n+1 模型更新机制，成功将 GPU 利用率长期保持在 95% 以上。在算力昂贵的今天，这种工程优化直接等同于巨大的成本优势。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;5 倍速的离线进化&lt;/strong&gt;：针对强化学习样本利用率低的顽疾，九章云极采用了「基于回放的离线强化学习算法」。通过对时间跨度的压缩与样本的高效回放，实现了 5 倍于传统方法的训练速度提升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAYBqvX5bPI7Dvfibic45t3XkxHYcMcrUsYmicfYC0mDVsRwAsibQJDBnZWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527893" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/73e8f8c3-bcbf-4603-bbb6-6c655a6982d3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;安全探索的「世界模型」&lt;/strong&gt;：在自动驾驶或医疗等「不能失败」的领域，九章云极与高校合作构建了可控的世界模型。它就像一个高保真的虚拟沙盒，让智能体在其中放手试错，解决现实世界「不敢探索」的难题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAIlXiblmwwjsnib9tbVnOjjEiaQSPqc7P6nkRWSFCgibvYI4yb04LxLzicsg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.4" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527894" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/06ccebc1-7e7d-4990-abf5-61cc643e6767/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Alaya NeW Cloud 的全栈重构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;九章云极强化学习云很强，这离不开其精心构建的 Alaya NeW Cloud 智能基础设施。&lt;/p&gt;&lt;p&gt;不同于传统云厂商在通用云上「打补丁」的做法，九章云极从一开始就围绕智能体的运行逻辑，完成了从底层基础设施到上层应用的四层全栈重构。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAibwlBHBbVcJXiaAQf3vicicqEl4sxfEVGxQiastD4NtPD9dIjO5a9wSGfSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527895" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/1a4022cb-eb97-48cf-97ea-5a5ac1858993/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;除了底层技术的突破，九章云极在工程化落地层面也展现出了惊人的敏捷性。为了让最前沿的模型能力即刻触达用户，平台实现了&lt;strong&gt;云容器实例 (CCI)&lt;/strong&gt; 的一键式部署，全流程覆盖，即开即用。以 2025 年终压轴上线的&lt;strong&gt;满血版 DeepSeek-3.2&lt;/strong&gt; 为例，在高端算力卡的加持下，其部署速度更快，运行更高效，完美诠释了平台对最新 SOTA 模型的快速支持能力。&lt;/p&gt;&lt;p&gt;整体看来，在这个智能体时代，九章云极扮演的角色不再仅仅是互联网数据中心（IDC）提供商，更是进化环境提供商。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;开发者&lt;/strong&gt;：只要极少代码即可启动完整的「训练-推理-回传」闭环。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于&lt;strong&gt;产业&lt;/strong&gt;：无论是城市规划、工业制造还是自动驾驶，每一个垂直领域的智能体都能在九章智算云上找到专属的进化路径。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;在黄山 &amp;nbsp; 打造城市级智算样板&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;技术领先只是起点，能否在复杂的真实物理世界中落地，才是检验「领军者」成色的试金石。&lt;/p&gt;&lt;p&gt;当大多数智算中心还停留在「建机房、堆显卡」的 1.0 阶段，九章云极已经率先在安徽黄山跑通了「&lt;strong&gt;智算+产业&lt;/strong&gt;」的 2.0 闭环。这里不仅有一座算力中心，更有一个正在运行的、基于强化学习云的城市级实验样本。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;48 天奇迹，这就是九章速度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在黄山，九章云极创造了一个行业纪录：&lt;strong&gt;48 天&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;是的，仅仅 48 天，一座规模达 500 PFLOPS 的&lt;strong&gt;「大位」智算中心&lt;/strong&gt;便拔地而起并投入运营。&lt;/p&gt;&lt;p&gt;这种令人咋舌的交付速度，不仅源于九章云极成熟的工程化能力，更验证了其智算操作系统在异构算力调度上的极致效率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当强化学习走进「全程 AI 伴游」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「大位」智算中心绝非一座冰冷的机房，它是国内首个「&lt;strong&gt;文旅+AI&lt;/strong&gt;」城市级产业应用基础设施。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAtLsGRlTFzvoVqqOAzKjAmlHiaJ1p2sL1yEicGsg6d1tQPsoaZhTeklpA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.524074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527896" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/56a97771-17ff-427e-a212-a55be332ea76/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在这里，九章云极的强化学习技术找到了最复杂的演练场：人类社会互动。依托算力底座，黄山实现了国内首个「全程 AI 伴游」景区。成千上万个智能体正在这里学习如何理解游客的意图、规划最优路线、处理突发状况。&lt;/p&gt;&lt;p&gt;这实际上是一场大规模的 Agentic RL 社会实验。每一个游客的反馈，都是一次 Reward（奖励）；每一次路线规划，都是一次 Policy（策略）更新。这种在真实高频场景中打磨出的智能进化能力，远比实验室里的数据更具商业价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智算经济：不仅是投入，更是增长引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于城市管理者而言，智算中心往往面临「建得起、用不起」或「不仅烧电、还烧钱」的质疑。九章云极则用数据打破了这一魔咒。&lt;/p&gt;&lt;p&gt;在本次大会发布的《2026 智算赋能城市产业发展白皮书》中，黄山被定义为「中小城市智算赋能标杆」。易观分析预测，随着「大位」智算中心的全面达产，每年将直接带动黄山市营利性服务业增加值增长不少于 2 亿元。&lt;/p&gt;&lt;p&gt;这一实战成果，正如九章云极董事长方磊在大会现场所下的判断：「&lt;strong&gt;全&lt;/strong&gt;&lt;strong&gt;球 AI 基建正重构生产力底座，算力核心价值在于普惠与落地效能。&lt;/strong&gt;」 黄山模式的成功，正是这一理念的最佳注脚。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAhaS8u56GrNnmozdkpTtGiawEibSUYRelm8ULDUBOnia4uA5ZffMcG2uEg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=11" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527897" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/a9fbd7fb-bc5d-427d-898f-ab65fac8cae2/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;通过「智算基建+文旅赋能+场景落地+商业闭环」，九章云极证明了强化学习云不仅能消耗电力，更能生产 GDP。&lt;/p&gt;&lt;p&gt;这种「黄山样板」正在产生强大的磁吸效应。大会现场，中科动力、百鹏互联、歌歌 AI 等 6 家 AI 企业集中签约落地。它们看中的，正是九章云极所构建的这个既有算力底座、又有丰富场景的智算生态。&lt;/p&gt;&lt;p&gt;从技术上的「定义者」到商业上的「破局者」，九章云极用黄山的实践告诉市场：下一代智算云，必须是能直接驱动产业增长的云。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;终局思维 &amp;nbsp;独立智算云赛道的「头号玩家」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 AI 基础设施的牌桌上，玩家虽多，但位置截然不同。有的在做「全能选手」（既做模型又做云），有的在做「卖水人」（只卖裸金属）。而九章云极选择了一条更为艰难、却也更为辽阔的道路：&lt;strong&gt;做独立智算云赛道的领军者。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;独立：真正开放生态的基础&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在「百模大战」向「千行百业」转型的今天，企业的顾虑显而易见：如果我把核心业务数据交给一个同时也做大模型的云厂商，它会不会既是裁判又是运动员？&lt;/p&gt;&lt;p&gt;这就是「独立智算云」存在的根本逻辑：&lt;strong&gt;中立性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;九章云极明确了自己的边界：不与客户争利，不绑定特定模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkATkgSKpvibFCHySBwdXGQm5ypicWMWxVdx7Ge4y5kgKBWeicicpm4ibkmuJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.40370370370370373" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527898" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c1cb6a9c-679e-4297-8d75-57fcab310611/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种「独立性」在算力高度集中的当下显得尤为珍贵。针对目前行业内只有不到 10 家巨头公司掌握 10 万卡以上资源的现状，九章云极明确倡导「开源 1000 专家模型」。&lt;/p&gt;&lt;p&gt;他们期望通过动态组合来放大群体智能，为那 10 万家中小企业提供高效的智能化解决方案，让每一个垂直领域的 Agent 都能在九章智算云上找到专属的进化路径 。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkASrmHOTAQrDPNFMQrOIQwmO2dzXjMgBkEEW6EGfwEY39F8MztibBdH8A/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.39537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527899" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/1fa31d6f-cc43-4d53-b362-42a0b7b49970/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这种「独立智算云+开源专家模型」的组合拳，彻底区别于那些试图绑定自家闭源大模型的巨头云厂商 ，使其更有可能成功构建起&lt;strong&gt;真正的开放生态&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;正如其发起的 AI-STAR 企业生态联盟，并没有排他性的门户之见，而是连接了上游芯片厂商与下游应用厂商，共同组成了一个自主可控的产业链闭环 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;领军：从卖算力到定标准&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;何为领军？不仅是规模最大，更是掌握定义规则的权力。&lt;/p&gt;&lt;p&gt;在算力计费混乱的草莽时代，九章云极率先推出了 「&lt;strong&gt;1 度算力&lt;/strong&gt;」 的普惠化标准，试图让算力像水电一样可度量、可流通。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVqdV8QPlkAtUyL0iaD0C2j3sVq9qpBCicCRyia1ZnyPXIgNJd40Wj5iaJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.18235294117647058" data-s="300,640" data-type="png" data-w="1020" type="block" data-imgfileid="503527900" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/cd0b3d30-03e2-405f-9067-df250bea8dbf/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;而在后训练时代，九章云极再次通过强化学习云定义了下一代基础设施的标准架构：&lt;strong&gt;一套包含 Agentic RL 技术架构、Serverless 弹性调度和异构资源管理在内的完整操作系统。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这正是九章云极区别于普通云厂商的核心标志。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;以领军之姿 &amp;nbsp; 为企业打造进化引擎&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年，当我们谈论云计算时，语境已经变了。&lt;/p&gt;&lt;p&gt;如果说过去十年的云计算是「能源时代」，厂商们比拼的是谁的电费更便宜；那么未来的十年，我们将进入「进化时代」，竞争的焦点是谁能让智能体进化得更快、更强。&lt;/p&gt;&lt;p&gt;作为&lt;strong&gt;独立智算云赛道的领军企业&lt;/strong&gt;，九章云极通过首创的强化学习云 Agentic RL，已经率先拿到了通往这个新时代的钥匙。它不仅仅是在提供算力，更是在为在这个星球上即将涌现的无数硅基智能体，提供进化的源动力。&lt;/p&gt;&lt;p&gt;在黄山的数据中心里，成千上万个智能体正在 7x24 小时地自我博弈。对于九章云极而言，这个关于「进化」的故事才刚刚开始。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>顶尖AI竟输给三岁宝宝，BabyVision测试暴露多模态模型硬伤</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Mon, 12 Jan 2026 13:15:13 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-12-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-12-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474618" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/87e98ff5-ace4-4784-93b8-bf34724c7b6a/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;01｜&amp;ldquo;看懂世界&amp;rdquo; 这关，大模型还没上幼儿园&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去一年，大模型在语言与文本推理上突飞猛进：论文能写、难题能解、甚至在顶级学术 / 竞赛类题目上屡屡刷新上限。但一个更关键的问题是：&lt;strong&gt;当问题不再能 &amp;ldquo;用语言说清楚&amp;rdquo; 时，模型还能不能 &amp;ldquo;看懂&amp;rdquo;？&lt;/strong&gt;UniPat AI 携手红杉中国 xbench 团队，并联合多家大模型公司与高校的研究员，发布新的&lt;strong&gt;多模态理解评测集 BabyVision&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;UniPat AI 致力于构建真实场景下 AI 训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。&lt;/p&gt;&lt;p&gt;如果一个视觉问题可以完全用文字描述且不丢信息，它本质上就会 &amp;ldquo;退化成文本题&amp;rdquo;。模型可以靠强大的语言推理能力一路通关，看起来很会看，其实是在走语言捷径。而真正的视觉能力，需要在没有语言扶梯的情况下完成：比较、追踪、空间想象、模式归纳。&lt;strong&gt;而 BabyVision 证明了多模态大模型的这些纯视觉能力还停留在 &amp;ldquo;三岁幼儿&amp;rdquo; 的阶段 ！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Google DeepMind 创始人 Demis Hassabis，在 25 年终播客中也提到类似观点：&amp;ldquo;大模型可以在国际数学奥林匹克拿金牌，却会在小学几何题上出错；它能生成惊艳图像，却不理解杯子为什么不会飘在空中。&amp;rdquo;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAv34HjyBhr0WO3FGBdqmvRrbnDBZzUGDlZVC913FMyxacweOZYiaCc1g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.7685185185185185" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503527858" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1bf74415-7494-4213-a76b-5e8975819e9b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAvm6LSBq5NQbzIVJZxPaEc85TcHZeUBCKvhy6h9icha0VRsTs3ziaprUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.39351851851851855" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527936" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/36a2451a-ea9a-486c-8894-635875ec5f22/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;blog：https://unipat.ai/blog/BabyVision&lt;/p&gt;&lt;p&gt;github：https://github.com/UniPat-AI/BabyVision&lt;/p&gt;&lt;p&gt;huggingface：https://huggingface.co/collections/UnipatAI/babyvision&lt;/p&gt;&lt;p&gt;&lt;strong&gt;02｜把顶尖模型和孩子放到同一张 &amp;ldquo;纯视觉试卷&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;BabyVision 先做了一项非常直接的对比实验：把 20 道视觉中心任务（vision-centric）作为 BabyVision-Mini 交给不同年龄段孩子（3/6/10/12 岁）和当下顶尖多模态模型来做。&lt;/p&gt;&lt;p&gt;这份 &amp;ldquo;小试卷&amp;rdquo; 要求严格控制语言依赖：&lt;strong&gt;题目要求很简单，答案必须靠视觉信息本身得出。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;结果非常 &amp;ldquo;扎心&amp;rdquo;（如图 1 所示）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;大多数模型的分数，&lt;strong&gt;聚集在明显低于平均 3 岁儿童的区间；&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini3‑Pro‑Preview 是唯一稳定超过 3 岁基线的模型，但&lt;strong&gt;距离 6 岁儿童仍差约 20 个百分点&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是其中一道题，直观且反直觉，连线垃圾分类，小孩可以轻松做对，但顶尖模型追踪一条线都能追丢。&lt;/p&gt;&lt;p&gt;任务：三件物品沿着线分别连到哪个颜色垃圾桶？&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVG7PticNxtFicKCaSwqYHFMQwzpf5ly3xFtmsnO0jDkXO87RumNq8xEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527859" data-aistatus="1" data-original-style="width:411px;height:325px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/892326aa-9ed8-412f-83e1-d377498231b9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkApiaZelZxwcLf36b74z4IyYeywSnTAe5PrZhawtKibnsV9icVHC7vibZUbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8843537414965986" data-s="300,640" data-type="png" data-w="882" type="block" data-imgfileid="503527860" data-aistatus="1" data-original-style="width:439px;height:388px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5f732fb9-9bdc-448d-89b8-9fda9e176a17/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;正确答案：A - 蓝，B - 黄，C - 绿&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型答案（Gemini3-Pro-Preview）：A - 绿，B - 黄，C - 蓝&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;人类的解法几乎是本能，从点出发沿线走到终点（&lt;strong&gt;下面照片是三岁幼儿真实做题痕迹&lt;/strong&gt;）。但模型会写出一大段 &amp;ldquo;逐段追踪&amp;rdquo; 的推理，最后仍把两条路径接反：看起来 &amp;ldquo;很会分析&amp;rdquo;，其实在最基础的视觉追踪上掉线。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;03｜BabyVision‑Full 用 388 题，把视觉能力拆成 4 大类能力 22 个子任务&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队将视觉能力提炼为四大核心类别，每类下细分若干子任务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;精细辨别（Fine-grained Discrimination）&lt;/strong&gt;：分辨细微的视觉差异（8 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉追踪（Visual Tracking）&lt;/strong&gt;：跟随路径、线条与运动轨迹（5 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;空间感知（Spatial Perception）&lt;/strong&gt;：理解三维结构及其关系（5 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;视觉模式识别（Visual Pattern Recognition）&lt;/strong&gt;：识别逻辑与几何规律（4 个子任务）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这套设计的核心理念很明确：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不是为了 &amp;ldquo;刁难&amp;rdquo; 模型，而是量化那些 &amp;ldquo;人类直觉就会、但构成智能地基&amp;rdquo; 的视觉原子能力。这同样是具身智能（embodied AI）走向现实世界的必修课。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了最大程度确保 &amp;ldquo;纯视觉&amp;rdquo; 考核的有效性，BabyVision 在数据构建上也下足了工夫。&lt;/p&gt;&lt;p&gt;项目团队首先参考了儿童认知教材和视觉发育测验，梳理出了上述 4 大类共 22 种基础视觉子任务。&lt;/p&gt;&lt;p&gt;接着，每个子技能挑选出 2-3 个种子示例（种子图片），作为该类型任务的典型代表。基于这些种子示例，研究者利用逆向图像搜索和关键词搜索，从互联网上爬取了约 4000 张相似的候选图片。&lt;/p&gt;&lt;p&gt;在数据收集过程中，团队严格遵守版权规范，只挑选可用于非商业或学术用途的素材，并过滤掉可能包含大量文字说明或需要文化常识才能理解的图片。由此获得的海量图片进入人工标注环节：多名专业人员逐一检查图片，筛除不适合出题的样本，对保留下来的图片精心设计问题和标准答案。为了确保答案的客观正确，每个问题还附有详细的 &amp;ldquo;解题过程&amp;rdquo; 说明，以证明答案确实可由视觉推理得出。&lt;/p&gt;&lt;p&gt;最终，所有标注完成的问题都经过 &amp;ldquo;双盲质检&amp;rdquo;&amp;mdash;&amp;mdash; 两位独立专家交叉审核，每道题只有在双方都认可其答案无误、推理严谨的情况下才被收录 ；若出现异议则退回修改，反复仍无法达成一致的题目则果断弃用。经过这一系列严苛的筛选，BabyVision 最终产出了 388 道高质量视觉题目，涵盖 22 种子任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAU8NkG6THshd0AU6313qseMxg0Mnr1x6SSGpjpXwFlq4GtaFxLpmQcQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.175" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527861" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/5a98a82d-5bc1-4e47-98fd-9eb1a6f84113/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;最终评测结果：人类 94.1%，最强闭源 49.7%，最强开源 22.2%&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 BabyVision‑Full 上，研究团队引入了人类基线，16 位至少本科背景的测试者完成全量 388 题，人类准确率达&lt;strong&gt;&amp;nbsp;94.1%&lt;/strong&gt;。&amp;nbsp;&lt;/p&gt;&lt;p&gt;再看模型：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;闭源最强：&lt;strong&gt;Gemini3‑Pro‑Preview 49.7%&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其后：&lt;strong&gt;GPT‑5.2 34.8%、Doubao‑1.8 30.2%&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;开源侧：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;最强模型（&lt;strong&gt;Qwen3VL‑235B‑Thinking&lt;/strong&gt;）整体 &lt;strong&gt;22.2%&lt;/strong&gt;，多数模型在 12&amp;ndash;19% 区间。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;更关键的是：&lt;strong&gt;差距不是集中在某一个类别&lt;/strong&gt;。四大类能力都在下滑，说明这是 &amp;ldquo;系统性缺基础视觉能力&amp;rdquo;，而非某个单点缺陷。 一些子任务甚至几乎 &amp;ldquo;全员翻车&amp;rdquo;，例如 &lt;strong&gt;Count 3D Blocks&lt;/strong&gt; 在多模型中普遍偏低，暴露的是模型结构化场景能力不足。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA6K7ZSNW1fC1k1hB7QuIujMbJhebibHxJr20HWutweCmibbfdk9JFSNzw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.9537037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503527862" data-aistatus="1" data-original-style="width:492px;height:469px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/f6d71de4-dd2d-4a73-9958-a533dc035d5d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;04｜为什么会这样？因为这些视觉推理题目是没法用语言描述的（Unspeakable）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最反直觉的地方在于：&lt;/p&gt;&lt;p&gt;BabyVision 里的很多题，对人类来说不难，甚至孩子会用指一指、圈一圈、沿着线走一遍就搞定。&lt;/p&gt;&lt;p&gt;但模型一旦用文字去 &amp;ldquo;复述&amp;rdquo; 视觉，再用语言推理去算，信息就丢了。&lt;/p&gt;&lt;p&gt;研究团队把这种现象概括为：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;这些视觉题是 &amp;ldquo;unspeakable&amp;rdquo; 的，无法在不损失信息的情况下被完整语言化；模型试图把视觉压缩成 token，细节在压缩中消失。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;并进一步总结了 4 类典型挑战：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战 1：看不见 &amp;ldquo;非语言细节&amp;rdquo;（Observing Non-Verbal Details）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAoHiczERwTu9nBSIV96lxpXLTGNBAUjNVmnuRTL5dK5oEwcYuGAmqMAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9316666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527863" data-aistatus="1" data-original-style="width:442px;height:412px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/71e1c1a5-ea0c-4969-9d75-df10a2bd59fb/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;比如拼图 / 补全题里，选项差别可能只是&lt;strong&gt;一个微小边界、一个局部凸起、一个像素级错位&lt;/strong&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;人类凭几何直觉 &amp;ldquo;对齐边界&amp;rdquo; 就能秒选；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型一旦把形状用语言概括成 &amp;ldquo;像钩子、两个腿、差不多七八个六边形&amp;rdquo;，细节就被抹平，选项在 token 空间里变得 &amp;ldquo;几乎一样&amp;rdquo;。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;挑战 2：追线追丢了（Manifold Understanding）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAVG7PticNxtFicKCaSwqYHFMQwzpf5ly3xFtmsnO0jDkXO87RumNq8xEg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.7916666666666666" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527864" data-aistatus="1" data-original-style="width:399px;height:316px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/7c82cac3-ee8c-49fd-9532-63643cf6e84a/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;连线 / 绕线 / 轨迹题，答案编码在 &amp;ldquo;连通性&amp;rdquo; 里：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;人类是&lt;strong&gt;锁定一条线&amp;rarr;穿过交叉&amp;rarr;一路追到终点&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型往往把线翻译成 &amp;ldquo;左 / 右 / 上 / 下&amp;rdquo; 的离散步骤，一遇到交叉点就出现分叉爆炸，&lt;strong&gt;容易 &amp;ldquo;换轨&amp;rdquo; 追错线&lt;/strong&gt;。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;挑战 3：缺少真正的空间想象（Spatial Imagination）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA4rsCA4xeU6OBqfcgbBE8QJd4x4gOFmyBiciaFnjIKKCJ2L9FsgXT145w/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.97" data-s="300,640" data-type="png" data-w="600" type="block" data-imgfileid="503527865" data-aistatus="1" data-original-style="width:415px;height:403px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/38f54f76-6739-4440-ae53-5012c6ca8c92/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;三维方块计数、视角投影、遮挡下的结构判断，人类通常不是 &amp;ldquo;用语言一步步描述&amp;rdquo;，而是把结构在脑中 &amp;ldquo;立起来&amp;rdquo;，换个角度看，再数。&lt;/p&gt;&lt;p&gt;模型则容易犯两类错误：&lt;strong&gt;漏掉隐藏块、投影关系搞错&lt;/strong&gt;。这不是逻辑差，而是缺少稳定的 3D 内部表征与变换能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;挑战 4：图形规律归纳难（Visual Pattern Induction）&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAZdItK1Dbetp1raMxwcRUaicTBNOdBvxgKwE63PwhRbRmGxFjTcV5Wog/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.7536764705882353" data-s="300,640" data-type="png" data-w="816" type="block" data-imgfileid="503527866" data-aistatus="1" data-original-style="width:443px;height:334px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/08ee768c-cff8-470b-b552-6a22e631e03a/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这类题要求从少量视觉示例里抽象出规则，再迁移到新图。&lt;/p&gt;&lt;p&gt;人类做的是关系映射，真正决定正确性的是 &amp;ldquo;&lt;strong&gt;发生了什么变化&lt;/strong&gt;&amp;rdquo; 而不是 &amp;ldquo;&lt;strong&gt;那里有什么&lt;/strong&gt;&amp;rdquo;，具体的形状、颜色、绝对位置都可以变，只有它们在变换中的 &amp;ldquo;身份&amp;rdquo; 不变。&lt;/p&gt;&lt;p&gt;模型常常盯着表面属性（颜色、形状），把 &amp;ldquo;结构规则&amp;rdquo; 误读成 &amp;ldquo;外观统计&amp;rdquo;，导致迁移时幻觉规则。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;05｜如果不让它用文字回答，让它 &amp;ldquo;画&amp;rdquo; 呢？BabyVision‑Gen 给出一个新方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;当文本推理不够用，一个自然的问题出现了：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;能不能让模型像孩子一样，用画、圈、连线、描轨迹来作答？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;于是有了 BabyVision‑Gen：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从原基准中重新标注出&amp;nbsp;&lt;strong&gt;280 道&lt;/strong&gt;适合 &amp;ldquo;生成式作答&amp;rdquo; 的题&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;要求模型输出图像 / 视频来表达解题过程或答案&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;并开发了自动评测工具，与人工评测一致性达 &lt;strong&gt;95%&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队在 BabyVision‑Gen 上评测了多种生成模型（包括 Nano‑Banana‑Pro、Qwen‑Image、Veo‑3、Sora‑2）。现阶段得到的结论很克制但重要：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;生成式推理在视觉追踪、精细辨别等 VLM 易翻车任务上出现 &amp;ldquo;更像人类&amp;rdquo; 的行为（会真的去画轨迹、做标注）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但整体仍然缺乏稳定到达完全正确解的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这至少说明：把视觉推理 &amp;ldquo;落地到视觉操作&amp;rdquo; 上，可能是补齐短板的一条路。&lt;/p&gt;&lt;p&gt;下面看一个具体的例子：&lt;/p&gt;&lt;p&gt;任务：用红线沿着从左上角图形延伸出的那条线，完整地描出其全程路径。&lt;/p&gt;&lt;p&gt;Sora2&lt;a href="https://mp.weixin.qq.com/s/-uCVMlIJKaQ80YSBzhRFOw"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6f413c5f-44af-4675-8ba7-48e14bf120e2/1768194840251.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkAc7uK2NthD9btBqJhXQbybcGxauqWkX6QRniawY9gP9gbXmOBN0mYJicw%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4338405709814808591" data-ratio="1.7777777777777777" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4338405709814808591" data-vh="380.8125" data-vidtype="2" data-vw="677" data-w="1280" height="393" scrolling="no" width="677"&gt;&lt;div data-key="wxv_4338405709814808591"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;NanoBanana-pro&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8Lwoiab3MsrMeRiawMnoTxkA3Eg5KqoBEbHcWj6NQnZ9ddl9pa33KXGHBG3SdFCNgxUB8ibhrq3IOKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.9253731343283582" data-s="300,640" data-type="png" data-w="1072" type="block" data-imgfileid="503527871" data-aistatus="1" data-original-style="width:491px;height:454px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/fa2e6b89-b019-4719-95be-2130bcd1d160/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;06｜为什么 BabyVision 重要？因为现实世界不靠语言提示&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;正如研究团队在 Blog（https://unipat.ai/blog/BabyVision）中所写：&lt;/p&gt;&lt;p&gt;很难想象一个视觉能力低于 3 岁孩子的机器人，能够可靠地在真实物理世界里帮助人类。&amp;nbsp;&lt;/p&gt;&lt;p&gt;今天，多模态模型 &amp;ldquo;会说会写&amp;rdquo; 已经很强。&lt;/p&gt;&lt;p&gt;但要走向真正的通用智能与具身智能，视觉地基必须补上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;看得准（细粒度辨别）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;追得住（轨迹 / 连通性）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;想得出（3D 结构想象）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;归纳得了（图形规则迁移）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;BabyVision 的价值正在于：把 &amp;ldquo;看懂世界&amp;rdquo; 拆成可测量、可诊断、可迭代的 22 个原子能力，告诉我们差距到底在哪里、下一步该补什么，从而引导多模态大模型发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;UniPat&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;UniPat AI 致力于构建真实场景下 AI 训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。&lt;/p&gt;&lt;p&gt;官网链接：https://unipat.ai&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
