<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>视远 · 正心明智——「AI 中国」机器之心2025年度评选正式揭晓</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 13:19:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-5</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe5QJ8IBG8nibRpDVIUB4tAsZ02f1uXn6OseqhOA9HB2UicJdIT3bNwI6A/640?wx_fmt=webp&amp;from=appmsg#imgIndex=0" data-ratio="0.5712962962962963" data-s="300,640" data-type="webp" data-w="1080" type="block" data-imgfileid="503526129" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/372907fd-2b19-4d58-842e-65673e69045d/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2025 年的日历已经翻到最后一页。&lt;/p&gt;&lt;p&gt;这一年里，大模型的演进速度被不断推高：新的模型架构、训练范式与推理策略轮番登场，技术边界一次次被向前推移。&lt;/p&gt;&lt;p&gt;放眼海外，GPT-5、Gemini 3 等新一代模型相继亮相，在理解、生成与推理等核心能力上持续抬升上限，通用智能的轮廓愈发清晰。&lt;/p&gt;&lt;p&gt;回到国内，2025 年的 AI 场面同样热闹。国产大模型一边在核心能力上不断拉近与国际头部模型的差距，甚至在个别方向上实现反超，另一边也在开源、工程化和应用适配上明显提速。&lt;/p&gt;&lt;p&gt;然而，在技术浪潮起伏中，我们更需要清醒识别真正具备长远价值的 AI 力量。因为决定行业走向的，从来不是某一次参数翻倍、某一项榜单刷新，而是哪些能力能够在真实世界中持续发挥作用 &amp;mdash;&amp;mdash; 它们是否真正重塑了生产方式，并在时间的检验中沉淀为基础能力。&lt;/p&gt;&lt;p&gt;正是基于这样的判断与追问，我们尝试把目光从短期热度中抽离，去辨认那些真正值得被记录的技术进展与创新路径。&lt;/p&gt;&lt;p&gt;带着这些思考与期待，机器之心精心策划了 2025 年度榜单，记录中国人工智能奋进的这一年，勾勒技术创新的璀璨未来。&lt;/p&gt;&lt;p&gt;今日，「AI 中国」机器之心 2025 年度评选正式揭晓：&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;最强技术实力企业/机构 TOP 10&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeawtmGqASNYD9ApHpmsb1ab5GBuOc9YFODDpxGUkSWZJvxAKVcBy4lA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.3601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526132" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f0f76124-6dca-4227-80bc-9c5c7fb636b9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;人工智能领军企业 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibend6ZuXedZQGToQroeiafFc5jLuDC2O5MHCvGzib4EfLhXeY3iaFgumU7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.8953703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526133" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/99207199-8921-491d-857e-a4b4aab8e143/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;最佳大模型 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe8udYv7NMF1V9Q8uicLITatvWwTs703BicQ9ACaicOVOeOSN2VDZu73IoQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="2.448148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526134" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/dae6faf7-5bae-469a-bfd9-26abf9c23c02/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;最佳大模型产品 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibes10ZjuzKmBHS1N4C5UcG6via2U83Wia4cxhvuVmcoPrZEmUMczj1icBOg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="2.448148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526135" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/9a0df25c-1f70-4cf7-b82d-a128721702dd/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;具身智能领军企业 TOP 20&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeUQVbvUWibhPu4bFP8WzDMCvJ4GAMY9UYOvGq8SibGp5QwKa8RHib3zFAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.8953703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526136" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/2e90595e-dd2d-4428-b14e-73ae6504dba3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;span data-pm-slice="0 0 []"&gt;&lt;strong&gt;ScienceAI 领军企业/机构 TOP 10&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeD0UiceN1D29jo7o5u1cHYFXxYespdHmaexN0YXSZkkXQeIlkibZicqicfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.3601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526137" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9c019211-7f58-4fdd-8abe-be7a41bba7ac/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>NUS尤洋教授深度探讨智能增长的瓶颈：或许我们将这样实现AGI？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 13:16:21 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-4</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;2026 年即将到来，AI 的发展也已经进入了一个新的阶段：我们已经取得了惊人成就，却同时面临进一步增长的瓶颈。&lt;/section&gt;&lt;p&gt;新加坡国立大学（NUS）的尤洋教授近期发表了一篇深度分析：《&lt;strong&gt;智能增长的瓶颈&lt;/strong&gt;》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LOniaWe4cQKOzUoUhicTOxStOI0kc6svMJxboh81K966XlZJvuuYmbkmw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.40063091482649843" data-s="300,640" data-type="jpeg" data-w="634" type="block" data-imgfileid="503526311" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/f6bd305d-ff9e-4e9a-81e0-3e72b54679ca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;原文链接：https://zhuanlan.zhihu.com/p/1989100535295538013&lt;/p&gt;&lt;p&gt;在这篇分析文章中，尤洋教授从技术本质出发，直指智能增长的核心矛盾，为我们揭示了 AGI（通用人工智能）的可能路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;观点速览&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;✅&lt;strong&gt; 智能增长的本质不是架构变革，而是算力如何转化为智能&lt;/strong&gt;：AI 的核心智能来自于预训练及其 Loss 结构（例如 GPT 的 Next-Token Prediction）。这些机制更像是把算力转化为智能的方法，而非智能本身。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ 现有智能增长遇到瓶颈的根源&lt;/strong&gt;：当前范式（Transformer + 超大算力）在面对进一步增长时， 难以充分消化不断增长的算力资源，这导致了所谓 &amp;ldquo;预训练红利递减&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ 算力并不是无限扩展就能解决问题&lt;/strong&gt;：即使算力指数级增长，如果现有算法无法有效利用这些计算资源，智能提升仍将受限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ 未来方向不在于工程优化，而是底层范式突破&lt;/strong&gt;：文章探讨了更高精度计算、更高阶优化器、更灵活的 Loss 设计、超大规模训练策略等潜在突破点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;✅ AI 未来仍然乐观&lt;/strong&gt;：智能增长瓶颈虽强，但仍有可能通过更好的算力利用方式被克服。预训练可能才刚刚开始，大模型智能仍有巨大的发展空间。&lt;/p&gt;&lt;p&gt;AGI 的未来将如何发展？让我们拭目以待。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibeTWEreV5NLd1rQ2ASjPBb10pQCTARuib8FAZ7YSNA11TaiaXUtXLShAwQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="1.5" data-s="300,640" data-type="jpeg" data-w="1000" type="block" data-imgfileid="503526216" data-aistatus="1" data-original-style="width: 296px;height: 444px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c8963d7f-778f-42e2-90d6-ef48a9999f72/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 尤洋教授，《智能增长的瓶颈》作者&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;以下为其分享原文：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能增长的瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2026 年已至。在 ChatGPT 诞生三年多后的今天，关于我们的智能水平是否令人满意，以及未来是否还能强劲增长，笔者想分享一些个人的看法。如有谬误，恳请大家指正。&lt;/p&gt;&lt;p&gt;为了能深入探讨智能的本质，本文将不涉及产品易用性、成本等商业化或落地问题，因为这些本质上与智能突破本身无关。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 智能的现状&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;什么是智能？其实目前并没有一个明确的定义。&lt;/p&gt;&lt;p&gt;从最近图灵奖得主 Yann LeCun 和诺贝尔奖得主 Demis Hassabis 关于 AGI 的争论中，我感受到即便是世界上最顶尖的&lt;strong&gt;专家&lt;/strong&gt;也无法准确定义智能。&lt;/p&gt;&lt;p&gt;个人感觉，AGI 很难定义，其标准也会随着时代的变化而变化。我依然记得十几年前，普通人对人脸识别技术感到不可思议。如果把今天的 ChatGPT 拿到 2006 年，相信那时候的很多人会毫不怀疑地认为我们已经实现了 AGI。&lt;/p&gt;&lt;p&gt;我觉得智能的核心是&lt;strong&gt;预测&lt;/strong&gt;和&lt;strong&gt;创作&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;我认为如果达到以下这种状态，那么就离 AGI 不远了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如果你选择接受哪个工作 Offer，完全听从 AI 的意见。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果你买足球彩票预测世界杯冠军，完全听从 AI 的意见。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果你有健康问题，会完全采用 AI 制定的方案去治疗。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;你分辨不清楚一部奥斯卡最佳电影是否是由 AI 生成的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;石油公司的勘探团队用 AI 替代了所有数值算法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 能指导初级高铁工程师在 5 分钟内排除高铁的疑难故障。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 能研制出一款专杀癌细胞且不破坏好细胞的药物。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 能通过某区域的地下结构数据，精准预测地震的时间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;等等&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;今天，我们显然还没实现这些。未来能否实现，取决于我们能否克服智能发展的瓶颈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 智能发展的瓶颈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，我们经常听到一些关于智能发展遇到瓶颈，或者预训练红利已尽的观点。何为瓶颈？我们先探讨一下智能从何而来。&lt;/p&gt;&lt;p&gt;过去 10 年，AI 大模型的技术本质，是把电力能源通过计算过程转化为可复用的智能。技术的好坏取决于这个转化效率的高低。类似的表述，我也听月之暗面的朋友提及过。&lt;/p&gt;&lt;p&gt;今天模型的智能本身，最主要还是来自预训练（往往是自监督方法），仅有少量来自微调或强化学习。&lt;/p&gt;&lt;p&gt;为什么？先算一笔浅显的经济账：因为预训练消耗的算力最多，消耗的能源也最多。&lt;/p&gt;&lt;p&gt;当然，预训练、微调、强化学习本质上都是在计算梯度以更新参数。如果有合适的海量数据和 Loss 函数，未来在预训练阶段采用 SFT（监督微调）或特殊的强化学习方法也有可能。&lt;/p&gt;&lt;p&gt;从智能增长的角度，我们甚至不用刻意区分预训练、SFT 和强化学习。它们的区别主要在于更新参数的次数与规模。&lt;strong&gt;从计算本质上看：预训练、微调、强化学习（比如 GRPO）都是在计算梯度的类似物，并用它来更新参数。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么，能源从何而来呢？这就是 GPU 或算力。英伟达在这点上做了最大的贡献。虽然英伟达有很多先进的技术，比如更强的 Tensor Cores、Transformer Engine、互联技术（NVLink / 网络化 NVLink）、软件栈等，但我先试图用一句话说清楚英伟达过去几年在技术上做的最重要的事情，即其 GPU 设计的核心思路。&lt;/p&gt;&lt;p&gt;简而言之，英伟达过去几年最重要的路线是：&lt;strong&gt;在同样的物理空间里堆更多 HBM（高带宽内存）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;HBM 虽然带宽很高，但依然是计算核心之外的内存（Off-chip from logic die），与计算核心存在不可忽略的物理距离。为了掩盖内存访问延迟，GPU 只能依赖超大的 Batch Size（批处理量）和大规模并行来处理数据。英伟达 GPU 本质上就是一台并行计算机。&lt;/p&gt;&lt;p&gt;因此，英伟达对算法层和软件层的要求非常明确：必须提供足够大的 Batch Size 或并行度。&lt;/p&gt;&lt;p&gt;面对英伟达的要求，很多研究团队都提出了自己的方案。比如 RNN、Transformer、卷积序列模型（CNN for Sequence）等等。甚至有人尝试用 SVM 来处理大规模序列数据。&lt;/p&gt;&lt;p&gt;那为什么 Transformer 率先脱颖而出？因为 Transformer 也是一台并行计算机。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe1zVVszeSf8HcLzhoFWnss4rObllWFmwFKjERQuPxb46iarzCZzVZsrw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="1.4559322033898305" data-s="300,640" data-type="jpeg" data-w="590" type="block" data-imgfileid="503526226" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/24e3ce8a-5297-4d2a-83ba-a7d43f9cb147/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 原初的 Transformer 架构&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这里我引用一下 Ilya Sutskever 的一句话：&amp;ldquo;Transformers: parallel computers in disguise&amp;rdquo;，直白的意思是：Transformer 本质上是一个被神经网络外壳包裹起来的并行计算机。这也是 Transformer 最先能够显现智能的核心原因，因为&lt;strong&gt;它的并行计算特性完美匹配了 GPU 的并行计算单元&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe74VN9hKHibtLDjZfxHoumJs5QKT9N1MbjgFETcbO9ZgUTzWWggHmuPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.43333333333333335" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526092" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/54926c94-fc79-4fc8-bb77-1679e570b877/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;同时，OpenAI 完美地实现了 &lt;strong&gt;Next-Token Prediction&lt;/strong&gt; 这个 Loss 函数，它给了 AI 大模型近乎无限的训练数据。理论上 BERT 的 Loss 函数（完形填空和 Next Sentence Prediction）也可以提供近乎无限的数据，但在实践中，Next-Token Prediction 的效果明显更好。&lt;/p&gt;&lt;p&gt;我推测，这个 Loss 函数最小化了人类的干预 &amp;mdash;&amp;mdash; 它不是人为设计的，而是大自然在进化过程中赋予人脑的逻辑。并且，Next-Token Prediction 其实是&lt;strong&gt;预测未来&lt;/strong&gt;，而 BERT 的完形填空其实是把过去的信息和现在的信息串联起来。这就好比让一个足球专家根据历史数据和当天的比赛结果去解释合理性，几乎所有专家都能做到；但是，如果让专家去预测每一场比赛的精准比分，他们会经常出错。这再次说明了，&lt;strong&gt;预测 (Prediction) 是智能的核心能力体现，难度远高于解释 (Explanation)&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其实我挺佩服 OpenAI 团队能够坚持下来的勇气。2018 年时，BERT 在媒体上的影响力几乎完全碾压了 GPT，且当时 OpenAI 的 AI 研发团队体量跟 Google 比起来微不足道。很佩服他们没有放弃 Next-Token Prediction，也没有转向类 BERT 的训练方式。真理往往需要时间去检验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe1ZT4VndxCK3n8phMO6pZVQX90icquXrCovlG5rxYI32Wmias4OY0WU1A/640?wx_fmt=webp&amp;from=appmsg#imgIndex=5" data-ratio="0.5" data-s="300,640" data-type="webp" data-w="800" type="block" data-imgfileid="503526223" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1350a0e1-c403-4655-9406-c6e2c6926123/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; BERT 对比 GPT&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;同时，以 Transformer 为核心的方案收获了 &amp;ldquo;一箭双雕&amp;rdquo; 的双重优势：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型的每层参数量越多，并行度就越高 (Tensor Parallelism)&lt;/strong&gt;。 所以，只要通信代价不显著增加，能同时利用的算力就越多。这点需要点赞行业领导者的先见之明。几年前，我看到 CNN 时代有研究人员试图把模型往深度发展，比如设想 1000 层的神经网络。其实非常深（层数非常多）的神经网络是不利于有效利用算力的，因为流水线并行提供的并行度上限不高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Transformer 的不同 Token 可以同时计算&lt;/strong&gt;。 序列长度越长，并行度就越高，只要通讯代价不显著增加，能同时利用的算力就越多。Sequence Parallelism 与 Data Parallelism 互补，进一步提供了更多的并行度。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;就这样，我们见证了 GPT-1、BERT、GPT-2、GPT-3、ChatGPT、Gemini 一步一步把智能提升到了今天的高度。&lt;/p&gt;&lt;p&gt;到这里，大家大概也清楚为什么 AI 模型的智能增长会遇到瓶颈了 &amp;mdash;&amp;mdash; 因为&lt;strong&gt;我们现在的范式无法充分消化持续增长的算力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;假定一次模型训练和微调消耗的浮点数计算次数（即程序员面试中的计算复杂度的具体值）从 10&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;ⁿ&lt;/span&gt; 变成 10ⁿ⁺&amp;sup3; 时，我们是否获得了一个显著更好的模型？&lt;/p&gt;&lt;p&gt;其实，很多时候我们把 &amp;ldquo;效率优化技术&amp;rdquo; 和 &amp;ldquo;智能提升技术&amp;rdquo; 混淆了。比如，明天我提出一个新的架构，实验发现达到跟 GPT-5 类似的效果，只需要 20% 的参数量或计算量。这其实更多是落地或商业化问题；智能的终极问题是：使用同样的浮点数计算次数（而非 Token 量），能否获得一个更好的模型。&lt;strong&gt;浮点数计算次数，才是算力最基本、最本质的计量单位。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 未来的方法探讨&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先从硬件层来看，我们&lt;strong&gt;需要持续产生更大的绝对算力&lt;/strong&gt;，这不一定局限于单位芯片上的算力提升。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibehp5PDHhwdbWXPpaSqxLx8D5ZrD5awkiaMCeWGqzSfyiagXjyj6e4fTBg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.4861111111111111" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503526228" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8026f37c-8700-4096-8342-5e6dc2027b49/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 前沿规模机器学习模型训练所用计算量的趋势，图源：Epoch AI&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;即便单位芯片上的算力没有大幅度提升，我们通过集群的方式也能构建更大的绝对算力。这里需要平衡的是：聚集芯片带来的性能增长，要高于 &amp;ldquo;芯片或服务器之间通信增长带来的负担&amp;rdquo;。&lt;/p&gt;&lt;p&gt;所以，具体的硬指标就是：增长或至少维持住 &amp;ldquo;计算开销/通信开销&amp;rdquo; 这个比值。这是整个 AI 基础设施层最核心的技术目标。要想实现这个目标，我们需要扩展性更好的并行计算技术，无论是软件还是硬件。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;更上层&lt;/strong&gt;的探索中，我们需要让 AI 模型在单位时间内 &amp;ldquo;吃下&amp;rdquo; 更多能源，并真正将其转化为智能。个人感觉大概有以下几点方向：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;更高精度的计算能力。&lt;/strong&gt; 今天，从 FP16 到 FP32，甚至 FP64，模型智能并未出现明显跃升。这本身就是一个瓶颈。理论上，更高精度应当带来更可靠的计算结果，这一点在传统科学计算中早已得到验证。这个观点可能与主流机器学习共识并不一致，而且真正发生可能需要很长时间，但从本质上看，智能仍然需要更精准的计算。这与过拟合并无直接关系，过拟合的根源在于数据规模不足或参数与数据不匹配。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;更高阶的优化器。&lt;/strong&gt; Google 的朋友告诉我，他们有时候已经不用类 Adam 优化器，而是用更高阶的优化器在训练模型。高阶优化器理论上能在学习过程中给模型更好的指导，算出更好的梯度，这是模型智能提升的本质。当然，高阶优化器的全面替代可能需要很长的时间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;扩展性更好的模型架构或 Loss 函数。 &lt;/strong&gt;我们仍然需要一种扩展性更好的整合和利用算力的方式。这点我们需要注意：优化效率不一定能提升智能。比如 Mamba 出来的时候，宣传重点是吞吐量的提升，用更小的模型获得同水平的智能。但是，本文关注的是：在最健全的 AI 基础设施上，用最大的可接受成本，能否训出更好的模型，获得更高的智能。比如，今天 Google 告诉你：预算 300 亿美元，半年内给我训出一个更好的模型，不考虑省钱问题，花 10 亿和花 100 亿没区别。在这个场景下，你最终是否会用 Mamba 这样的架构？你是否需要设计更好的 Loss 函数？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;更多的 Epoch 和更好的超参数。 &lt;/strong&gt;迫于成本压力，我们今天其实并没有对 AI 模型进行深度优化，甚至没有深度搜索超参数。这其实也是我之所以对 AI 模型的智能继续增长有信心的原因。我这里的意思不是直接训练更多的 Epoch。明知无效却生硬地跑更多 Epoch 其实是方法不对（比如参数量和数据量不匹配）。但是，根本上，更多的 Epoch 代表更多的浮点数、更多的能源。我们需要找到方法去 &amp;ldquo;吃下&amp;rdquo; 更多能源，并转化出更高智能。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;有些技术对大规模落地 AI 非常重要，比如低精度训练、剪枝、量化、蒸馏、PD 分离等推理优化技术。但是，在一个 &amp;ldquo;算力转智能&amp;rdquo; 极端有效的情况下，这些技术跟&lt;strong&gt;提升智能上限&lt;/strong&gt;无关。笔者对这些技术的贡献者非常尊重，它们在实际落地中至关重要，只是与本文探讨的主题无关。&lt;/p&gt;&lt;p&gt;智能增长归根到底还是算力利用问题。假定算力无限大，比如一个集群的算力达到今天的万亿倍，可能我们会发现更简单的模型结构比 Transformer 和 Next-Token Prediction 的扩展性更好。从 SVM 到 CNN、LSTM、BERT、GPT、MoE：我们始终在寻找能更高效利用算力且具备更好扩展性的方法。这个过程中，&lt;strong&gt;核心原因是问题的规模在不断扩大&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;我们在 AI 时代到来之前便已实现天气预报，然而至今仍未能攻克地震预报，尽管两者本质上都是针对地球数据的研究。究其原因，地下结构涉及比大气更加错综复杂、且变量规模呈指数级庞大的动态多模态数据。这种传统计算模式难以驾驭的高维复杂性，恰恰是未来 AI 技术大有可为的机遇所在。&lt;/p&gt;&lt;p&gt;所以，我有信心我们未来会不断找到更高效的算力使用方式。虽然过程中可能会有很多困难和低潮，但大趋势不可阻挡。&lt;/p&gt;&lt;p&gt;最后，借用 Richard Sutton 教授的一句话收尾：&lt;strong&gt;人工智能 70 年的研究留给我们最大的经验教训是，依托计算能力的通用方法才是最终的赢家，且具备压倒性的优势。&lt;/strong&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>重塑语音安全！上海交大联合宇生月伴，研发高性能高泛化语音鉴伪大模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 31 Dec 2025 13:10:18 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-3</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/f1107484-50ba-4c95-b5f6-1cfb11925ecd/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="3" data-pm-slice="0 0 []"&gt;在生成式 AI 技术日新月异的背景下，合成语音的逼真度已达到真假难辨的水平，随之而来的语音欺诈与信息伪造风险也愈演愈烈。作为应对手段，语音鉴伪技术已成为信息安全领域的研究重心。&lt;/p&gt;&lt;p data-path-to-node="4"&gt;然而，当前的语音鉴伪模型正面临严峻的「泛化性挑战」：许多在特定实验室数据集上表现优秀的模型，在面对现实世界中从未见过的生成算法时，检测性能往往会出现剧烈下滑。这种「泛化瓶颈」严重限制了鉴伪技术在复杂多变的真实场景中的应用价值。&lt;/p&gt;&lt;p data-path-to-node="5"&gt;针对这一难题，上海交通大学听觉认知与计算声学实验室和宇生月伴公司（VUI Labs）联合发表了最新研究成果，提出了一种以数据为中心的研究范式。该研究深入探究了训练数据分布与模型泛化能力之间的底层逻辑，通过系统性的实证研究与策略优化，构建了兼具高性能与高泛化性的语音鉴伪大模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe4cgqCfpbjHzmVcokJtibDVnZEQ5QkqednsQWXbFibVj2WJzI7ePomc3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2898148148148148" data-type="png" data-w="1080" data-width="2128" data-height="616" data-imgfileid="503526202" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/83ba4400-78c8-4189-9ec9-0a54dad89cff/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;论文标题：A Data-Centric Approach to Generalizable Speech Deepfake Detection&lt;/li&gt;&lt;li&gt;论文链接：https://arxiv.org/pdf/2512.18210&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="7,1,0"&gt;&lt;strong&gt;核心视角： 从单一构建到多源聚合&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;不同于以往关注架构创新的路径，论文从数据中心视角切入，将数据版图重构为两个核心视角：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="9,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,0,0"&gt;构建单一数据集：&lt;/b&gt; 基于不同信源（source）和生成器（generator）生成伪造样本，构建数据集。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="9,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="9,1,0"&gt;聚合多源数据集：&lt;/b&gt; 汇聚具有不同信源、生成算法及其他声学条件的异构数据池，构建多样化训练数据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiaJOBrrUfUHIaFKarm44d8cDY5g40HEzT5PibSDD3KmSWN4WteNQk56w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.2077625570776256" data-type="png" data-w="876" data-width="876" data-height="1058" data-imgfileid="503526180" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/6bf0a741-e040-4313-8eb7-69bf77872ce8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="10"&gt;基于上述视角，论文旨在通过系统性的实证分析探索两个核心问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="11,0,0"&gt;&lt;strong&gt;在单一数据集构建中&lt;/strong&gt;，如何在数据规模和多样性（信源 / 生成器）之间进行资源的科学分配？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="11,1,0"&gt;&lt;strong&gt;在聚合多源数据集时&lt;/strong&gt;，如何设计高效的混合与采样策略以实现最优泛化性能？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="12"&gt;&lt;b data-index-in-node="0" data-path-to-node="12"&gt;规模定律：&lt;/b&gt;&lt;b data-index-in-node="0" data-path-to-node="12"&gt;多样性远胜数据总量&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="13"&gt;为了揭示资源分配的最优原则，论文针对训练数据的组成规律开展了大规模实证分析。通过量化信源多样性、生成器多样性与样本容量之间的复杂关系，揭示了语音鉴伪领域内在的「规模定律」。&lt;/p&gt;&lt;p data-path-to-node="14"&gt;核心发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="15,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="15,0,0"&gt;多样性是泛化的首要动力：&lt;/b&gt; 在资源有限的情况下，提升信源与生成器的多样性所带来的性能增益，远比单纯增加数据总量更具效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="15,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="15,1,0"&gt;信源与生成器属性互补：&lt;/b&gt; 信源多样性有助于模型构建稳健的真实语音分布，而生成器多样性则显著强化了模型对各类伪造特征的识别。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="15,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="15,2,0"&gt;泛化表现具备可预测性：&lt;/b&gt; 泛化误差随数据多样性的增加呈现出稳定的幂律缩放特性，使泛化能力的提升从随机探索走向科学建模。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeY0aJsEibdwG4Rhib25mH3EGMFiaQWZ3ibnWRV5hiazic7sm9icH86IMSsOZNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5666666666666667" data-type="png" data-w="1080" data-width="1804" data-height="1022" data-imgfileid="503526224" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a93362fa-aa8e-4116-aaf2-14abff2bfc5a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="16"&gt;&lt;b data-index-in-node="0" data-path-to-node="16"&gt;采样策略：&lt;/b&gt;&lt;b data-index-in-node="0" data-path-to-node="16"&gt;科学混合异构数据池&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="17"&gt;既然多样性的价值远胜于纯粹的数据堆叠，那么如何科学地混合来自不同源头的异构数据，就成为了解决泛化难题的第二个关键问题。基于规模定律的分析，论文提出了多样性优化采样策略（Diversity-Optimized Sampling Strategy，DOSS）。该策略的核心在于将复杂的异构数据按照信源或生成器划分为细粒度的域，并相对公平地对待每一种已知的生成模式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="18,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,0,0"&gt;细粒度域定义：&lt;/b&gt; 将真实语音按「信源」划分，将伪造语音按「信源 + 生成器」的组合进行索引，从而在更微观的层面实施分布控制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="18,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,1,0"&gt;多样性筛选（DOSS-Select）：&lt;/b&gt; 一种基于数据剪枝策略，旨在构建更平衡且高效的训练子集，剔除边际收益递减的冗余样本以提升训练效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="18,2,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="18,2,0"&gt;分布加权（DOSS-Weight）：&lt;/b&gt; 一种数据重加权策略，在保留全量数据的同时，调整各数据域在训练时的采样概率，让模型更均衡地学习不同规模域的特征，避免被海量但单一的数据分布所主导。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-path-to-node="19"&gt;实验结果验证了该策略在处理大规模异构数据时的优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-path-to-node="20,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="20,0,0"&gt;极高的数据效率：&lt;/b&gt; 采用 DOSS-Select 策略，仅需使用约 3% 的总数据量，其泛化性能即可超越朴素聚合全部数据的基线水平。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-path-to-node="20,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="20,1,0"&gt;显著的性能提升：&lt;/b&gt; 采用 DOSS-Weight 策略，实现了相对朴素聚合基线约 30% 的大幅度误差削减。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibekCIVCt6zrran5LsKoiagxRqbESSbnp0FnoicIyguAye8AtpTIibibiclVWw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6601851851851852" data-type="png" data-w="1080" data-width="1802" data-height="1190" data-imgfileid="503526193" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8458b586-e59c-40f6-b294-797dfc0d42cc/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="21"&gt;&lt;b data-index-in-node="0" data-path-to-node="21"&gt;实战评估：&lt;/b&gt;&lt;b data-index-in-node="0" data-path-to-node="21"&gt;学术基准和商业接口实测&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="22"&gt;为了验证上述策略的稳健性与可扩展性，论文构建了一个包含 1.2 万小时音频、涵盖 300+ 个伪造领域的大规模异构数据池。通过应用 DOSS 策略进行训练，最终得到了高性能高泛化的大模型，并在多个学术基准和商业接口上进行了实测，均取得了突破性表现：&lt;/p&gt;&lt;p data-path-to-node="23,0,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="23,0,0"&gt;学术基准：刷新跨域性能记录&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="23,0,0"&gt;在多个公开测试集的评估中，模型平均等错误率（EER）降至 1.65%，在多个主流基准测试中均刷新了记录，确立了新的技术基准和 SOTA。此外，数据与模型效率的表现尤为出色：相较于之前最好的来自日本 NII 的系统&amp;mdash;&amp;mdash;在 7.4 万小时数据上训练的 2B 规模模型（平均 EER 3.94%），提出的新方案仅凭约 1/6 的训练数据与更精简的参数规模，便实现了检测误差的倍数级削减。即便是在更轻量的 300M 版本下，其性能表现依然稳健，证明了科学的数据策略比单纯的规模堆叠更能有效释放模型的泛化潜力。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeBB202hTMOaPdvXkGbicOl9eLicFptw3icTC6kcf9W5iapOpIvZGic7ujKGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.37037037037037035" data-type="png" data-w="1080" data-width="1894" data-height="702" data-imgfileid="503526200" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ded4c52a-dbed-426e-b4b4-670ea10b2d85/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="23,1,0"&gt;&lt;b data-index-in-node="0" data-path-to-node="23,1,0"&gt;商业接口：直面现实安全威胁&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="23,1,0"&gt;针对从 Google、Microsoft 等主流云服务到 ElevenLabs、MiniMax 等前沿高拟真引擎的 9 类最新商业接口进行评估，模型平均检测准确率达到了 96.01%。即便在面对目前极具挑战性的高保真合成引擎 Qwen3 时，模型仍能保持 87.32% 的高准度识别。这进一步印证了从多样化训练数据中学习到的表征，能够有效迁移并泛化至现实中不断进化的商业生成方式。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe3iaptPib8goy1P2k0J5Q7rkJ7WJuzLaFOcqeknlCwZ6TJUxDE7U9HCng/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.24814814814814815" data-type="png" data-w="1080" data-width="2036" data-height="506" data-imgfileid="503526201" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/4505ecc6-7b61-4fd9-a779-48888f59d65e/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="24"&gt;&lt;b data-index-in-node="0" data-path-to-node="24"&gt;总结&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="25"&gt;不同于以往在模型架构与算法优化上的迭代，深挖训练数据组成的底层逻辑正在成为重塑语音安全防线的关键。本论文通过量化多样性的规模效应并引入优化采样机制，成功实现了对异构数据资源的高效调度与深度挖掘。这种向「数据中心」范式的深刻转变，为构建高性能、高泛化的语音安全大模型提供了全新的探索思路。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;&lt;b data-index-in-node="0" data-path-to-node="26"&gt;团队介绍&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="27"&gt;研究团队来自于上海交通大学计算机学院听觉认知与计算声学实验室（SJTU Auditory Cognition and Computational Acoustics Lab，AudioCC Lab）和宇生月伴公司（VUI Labs），该团队由语音对话和听觉处理领域知名学者，教育部长江学者钱彦旻教授领导，专注于完整的听觉人工智能与计算声学领域的前沿研究。&lt;/p&gt;&lt;p data-path-to-node="28"&gt;实验室集结了一支由青年教师、博士生、硕士生、本科生及专职科研人员等组成的近 40 人科研团队，在语音、音频、音乐及自然声信号处理等领域积累了丰富的技术经验。实验室依托国家重点项目及企业合作支持，拥有数百块先进 GPU 计算资源，致力于解决产业级技术难题。&lt;/p&gt;&lt;p data-path-to-node="29"&gt;近年来，团队在国际顶级期刊和会议上发表了数百项学术成果，并在多项国际评测中斩获冠军。团队成员全面发展，毕业生均进入国内外顶级企业和研究机构，持续推动人工智能技术的创新与应用。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华北电力大学等开发基于AI的催化设计蓝图，跨材料的电化学通用设计框架</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Wed, 31 Dec 2025 12:00:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31-2</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwhz8RBNFIvNz4IKHZp78sRkGEH5dQujls2nwRM2OrIT5H7icBUWk8ULg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.5435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="314" data-imgfileid="100027018" data-aistatus="1" data-original-style="width: 100%;" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/a2230bb1-b2ff-4f6f-8e20-2cea1b80241a/640.png" data-sec-load-status="2" data-report-img-idx="1" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;编辑丨%&lt;/p&gt;&lt;p&gt;在日常生产中，时常能看到过氧化氢的影子，从消毒剂、医疗灭菌到环境清理和制造。都有它发挥价值的地方。但大多数双氧水仍通过需要大量能源的大规模工业工艺生产，仍需寻找相关的替代品。&lt;/p&gt;&lt;p&gt;来自华北电力大学等的研究团队在寻找相关反应的催化剂方面有了突破。他们开发了一个通用且可转移的催化剂设计框架，整合了加权原子中心对称函数（wACSF）描述符与机器学习和微动力学建模。&lt;/p&gt;&lt;p&gt;相关研究内容以「Universal Catalyst Design Framework for Electrochemical Hydrogen Peroxide Synthesis Facilitated by Local Atomic Environment Descriptors」为题，发表在《&lt;em&gt;Angewandte Chemie International Edition&lt;/em&gt;》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwTdfVbVrutSickbuvFGGcssAZiaAVOHlzgsNjQp25v6a8wImzIyAiaOicmw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3580683156654888" data-type="png" data-w="849" data-width="849" data-height="304" data-imgfileid="100027016" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/c0e6e366-c327-4481-afc1-b2d9ba6ced7f/640.png" alt="图片" data-before-load-time="1767153643151" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://onlinelibrary.wiley.com/doi/10.1002/anie.202518027&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计反应催化剂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过氧化氢合成被认为是一种经济高效的生产方式，并且相当环保节能。该方法还通过将电能转换为氢形式的化学能，提供了一种稳健的能量储存解决方案，从而将能源生产与环境可持续性相结合。&lt;/p&gt;&lt;p&gt;受到当前催化剂设计局限的启发，相关团队开发了一个通用且可转移的催化剂设计框架，将新构建的加权原子中心对称函数（wACSF）描述符与机器学习和微动力学建模整合。&lt;/p&gt;&lt;p&gt;与主要描述原子几何环境的传统 ACSF 方法不同，wACSF 描述符包含几何和化学特征，包括活性中心原子的内在活性活性特性。这种双重表示使得对多样化催化系统的统一描述成为可能，克服了传统机器学习辅助方法的可迁移性不足。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwh2RhuyAzjicysfIPbibUntbFoB0AcSmLImhVMSZriacFNNKxgY4c2xm8Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.676" data-type="png" data-w="500" data-width="500" data-height="338" data-imgfileid="100027015" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/db435881-6673-4de2-ae63-bc2b8c610a10/640.png" alt="图片" data-before-load-time="1767153643177" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 1：催化剂设计框架概述。&lt;/p&gt;&lt;p&gt;该框架的运行逻辑大致如下：&lt;/p&gt;&lt;ol start="1"&gt;&lt;li&gt;&lt;p&gt;首先选出主要材料，并根据催化剂的活性点位等构建原子的化学环境特征。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;利用 XGBoost 回归，随后进行特征分析和递归消去以丢弃冗余特征。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;采用先进的机器学习算法来开发有效模型，随后将得到的无吸附能量纳入微动力学火山模型中进行测试。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后，通过机器学习预测的无吸附能量筛选过程，将通过微动力学模型快速识别潜在高性能催化剂。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;性能与验证&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;利用该框架，团队成功预测了多种催化剂类型中的关键反应特性。这些预测与详细的量子力学计算结果及先前报告的实验数据高度吻合，表明该方法适用于多种材料。&lt;/p&gt;&lt;p&gt;接下来，团队通过 &amp;ldquo;通用设计框架&amp;rdquo; 筛选出最优候选催化剂 &amp;mdash;&amp;mdash;&lt;strong&gt;LiScO₂&lt;/strong&gt;，从电化学性能、稳定性、理论 - 实验匹配度三方面完成系统验证。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwmgRLj9ksx5UOZ3CP54GAhNAtdoLBttLs3WVIskm8LdO5eUr849DPAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6625" data-type="png" data-w="800" data-width="800" data-height="530" data-imgfileid="100027014" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a6887d69-aeb9-47f6-a18e-71077f8f4154/640.png" alt="图片" data-before-load-time="1767153643373" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图 2：理论预测的实验验证。&lt;/p&gt;&lt;p&gt;该框架所验证的结果显示， LiScO₂催化剂在 2.2 V vs. RHE 下 H₂O₂法拉第效率达 90%，2.4 V 时仍保持 &amp;gt; 80% 选择性。稳定性表现也相当优异，能在流动池测试中连续运行 168 小时，法拉第效率维持 82%&amp;ndash;86%，并且无结构降解。&lt;/p&gt;&lt;p&gt;验证结果与预测结果偏差值在 5% 之内，是目前 2e⁻ WOR 催化剂中最优匹配的例子。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该研究提出了一个&lt;strong&gt;通用的催化剂设计框架&lt;/strong&gt;。通过开发加权原子中心对称函数（wACSF）描述符，整合数据库自动化、机器学习（ML）和微动建模，其中 wACSF 结合了几何与化学特征，实现了跨不同催化剂家族的局部环境统一且可迁移的表示。&lt;/p&gt;&lt;p&gt;该框架可以实现夸材料催化剂筛选与机制洞察，体现了设计中的统一范式。它已被应用于数字催化平台（迄今为止最大的数字平台实验和计算催化数据库，由 Hao Li 实验室开发），可用于高效预测反应性质。&lt;/p&gt;&lt;p&gt;相关链接：https://phys.org/news/2025-12-ai-based-blueprint-catalysts-materials.html&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>华为云CEO周跃峰：要避免AI成为泡沫，必须要提升行业生产力</title>
      <description>&lt;![CDATA[用一行行代码解决真实问题。]]&gt;</description>
      <author>新闻助手</author>
      <pubDate>Wed, 31 Dec 2025 10:19:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-31</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-31</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&amp;ldquo;不能让今天的 AI 仅仅用于满足人的情绪价值，必须要提升我们的生产力。&amp;rdquo;&lt;/p&gt;&lt;p&gt;在近期召开的 2025 华为开发者大赛暨开发者年度会议上，华为高级副总裁、华为云 CEO 周跃峰面对数百名开发者，直指当前人工智能热潮中的 &amp;ldquo;泡沫&amp;rdquo; 隐忧。这位新任华为云掌舵人，首次系统阐释了华为云在 AI 时代的新蓝图 &amp;mdash;&amp;mdash; 联合开发者，在华为云 &amp;ldquo;黑土地&amp;rdquo; 上，共同打造行业 AI 的 &amp;ldquo;梦工厂&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;span class="fr-img-caption fr-fic fr-dib" style="width: 812.616px;"&gt;&lt;span class="fr-img-wrap"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/73101878-0016-4234-a8b1-26f7165822e0/%E5%9B%BE%E7%89%871.png"&gt;&lt;span class="fr-inner"&gt;华为高级副总裁、华为云 CEO 周跃峰&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行业 AI &amp;ldquo;梦工厂&amp;rdquo; 计划&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首次剧透的 &amp;ldquo;行业 AI 梦工厂&amp;rdquo; 计划，勾勒出华为云的 AI 宏图。&lt;/p&gt;&lt;p&gt;&amp;ldquo;华为云应该成为行业 AI 的&amp;lsquo;梦工厂&amp;rsquo;。&amp;rdquo; 周跃峰解释说，&amp;ldquo;这个梦工厂里会有各种&amp;lsquo;作坊&amp;rsquo;，每个作坊专注一个垂直领域。&amp;rdquo;&lt;/p&gt;&lt;p&gt;这些 &amp;ldquo;作坊&amp;rdquo; 实际指的是一个个面向垂直领域的社区。华为云将开放华为在医疗、自动驾驶、具身智能等领域长期积累的技术能力、工具链与行业实践经验，为开发者提供坚实而丰沃的创新土壤。首批透露的 &amp;ldquo;作坊&amp;rdquo; 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;具身智能开发者社区：开放具身智能相关的工具链、软件和仿真环境&lt;/li&gt;&lt;li&gt;&amp;ldquo;魔擎&amp;rdquo; 医疗社区：基于瑞金医院实践，让更多医院和医生能开发专属 AI 医疗方案&lt;/li&gt;&lt;li&gt;商专车自动驾驶社区：服务特定场景的自动驾驶开发需求&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;ldquo;从明年开始，业界会看到我们的一系列动作。我们也希望用我们的能力来打开中国各个行业 AI 的一扇扇大门，包括农业、育种、科研等等&amp;rdquo;，周跃峰表示，&amp;ldquo;我们会真正把华为云建设成为行业 AI 的&amp;lsquo;梦工厂&amp;rsquo;，使能千行万业实现他们的 AI 梦想。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;每个 Token 都要体现价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;ldquo;我希望今天我们 AI 做的很多东西能够真正改变提升我们的生产力，而不仅仅是情绪价值，不仅仅是 Token 数量。&amp;rdquo; 周跃峰的发言有着工程师式的务实，&amp;ldquo;我希望每一个 Token 背后都有非常高的社会价值和我们劳动价值的体现。&amp;rdquo;&lt;/p&gt;&lt;p&gt;这种务实态度源于他亲历的实践。在过去的 18 个月里，周跃峰深度参与了上海瑞金医院病理 AI 项目。这不是一个停留在论文或演示中的项目，而是一个已经深度融入医院日常诊疗流程的系统。&lt;/p&gt;&lt;p&gt;&amp;ldquo;今天在瑞金医院看病，病理切片基本都是机器先看，医生复核签字就行了。&amp;rdquo; 周跃峰透露，&amp;ldquo;这在全国是首家真正把 AI 用到临床流程中的医院。&amp;rdquo;&lt;/p&gt;&lt;p&gt;更关键的是系统的闭环设计 &amp;mdash;&amp;mdash; 医生每诊断一个病例，数据都会反馈到模型中进行再训练。在瑞金医院的屏幕上，实时显示着每位医生当天通过 AI 系统诊断的病例数，以及有多少数据进入了 &amp;ldquo;数据飞轮&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&amp;ldquo;医疗领域的每个 Token 都关联着鲜活的生命。&amp;rdquo; 周跃峰说，&amp;ldquo;金融风控的每个 Token 都守护着财产安全。这些价值，远比单纯追求 Token 数量有意义得多。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI 一定要沿着生产力提升的方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与一些云厂商侧重算力租赁的模式不同，华为云走的是一条更重、更难的路径。周跃峰坦言，华为云每年在基础设施上有着巨大投入，需要大量自研，成本很高。&lt;/p&gt;&lt;p&gt;但他坚信打造 &amp;ldquo;黑土地&amp;rdquo; 以及走行业 AI 路径的价值：&amp;ldquo;华为云在 AI 这条路上面走的跟别的云公司不太一样，但是我从内心认为，我们这条路是最踏实的、最坚实的，如果 AI 要成功的话，一定是沿着提升生产力的方向成功。&amp;rdquo;&lt;/p&gt;&lt;p&gt;未来，华为云将聚焦几个关键技术方向：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全栈自主的基础设施：基于昇腾、鲲鹏架构构建国产化算力底座&lt;/li&gt;&lt;li&gt;更开放的 ModelArts 平台：支持多模型调度和第三方模型&lt;/li&gt;&lt;li&gt;更智能的 CodeArts：集成更强大的智能编程能力&lt;/li&gt;&lt;li&gt;行业智能体平台：将推出面向行业场景的 Agent 编排平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;ldquo;华为公司有 20 多万员工，其中大量是研发人员。&amp;rdquo; 周跃峰自信地说，&amp;ldquo;在中国找不到第二家公司有如此丰富的编程环境 &amp;mdash;&amp;mdash; 从汇编到 Python，各种语言团队我们都有。做不好智能编程，我觉得是不可能的。&amp;rdquo;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;给开发者的建议：深耕行业价值&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对开发者的提问，周跃峰给出了明确的建议方向。&lt;/p&gt;&lt;p&gt;&amp;ldquo;建议大家关注那些真正能提升生产力的 AI 应用。&amp;rdquo; 他说，&amp;ldquo;比如如何用 AI 优化复杂决策系统 &amp;mdash;&amp;mdash; 就像电动车行业的供应链优化，订单下来后如何快速协调数百家供应商，这需要处理海量实时数据，传统方法很难解决。&amp;rdquo;&lt;/p&gt;&lt;p&gt;另一个方向是行业智能体开发平台。&amp;ldquo;今天很多 Agent 平台源自 C 端，但行业端的需求完全不同。&amp;rdquo; 周跃峰指出，&amp;ldquo;行业 Agent 的发育速度较慢，这正是需要开发者共同努力的地方。&amp;rdquo;&lt;/p&gt;&lt;p&gt;对于近期火热的具身智能，周跃峰既看好也保持理性：&amp;ldquo;当前算法还不足以支撑各行业对机器人的泛化要求，算法与身体的物理适配也还不够。&amp;rdquo; 为此，华为云将通过开放算力、工具链和仿真环境，降低开发门槛，让创业者能将更多资源投入到核心算法研发中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;华为的 &amp;ldquo;踏实&amp;rdquo; 文化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;ldquo;华为公司很务实。&amp;rdquo; 周跃峰也谈到了华为的内部文化，&amp;ldquo;我们不是上市公司，没法通过股市融资。每一分钱都是自己赚出来的。&amp;rdquo;&lt;/p&gt;&lt;p&gt;这塑造了华为的务实风格。周跃峰说，&amp;ldquo;正是这种&amp;lsquo;踏实&amp;rsquo;，让我们必须把每一分钱都投在能真正提升生产力的方向上。&amp;rdquo;&lt;/p&gt;&lt;p&gt;周跃峰最后留下自己的微信，邀请开发者直接交流。&amp;ldquo;这条路不容易，但我和团队相信，只有让 AI 真正提升生产力，技术才有长远价值。&amp;rdquo;&lt;/p&gt;&lt;p&gt;在 AI 热潮汹涌的今天，华为云选择了一条少有人走的路，沉入行业深处，用一行行代码解决真实问题。这条路径或许不会立即带来亮眼的 Token 数据，但正如周跃峰所说：&amp;ldquo;如果 AI 要成功，一定是沿着提升生产力的方向成功。&amp;rdquo;&lt;/p&gt;&lt;p&gt;科技发展的历史上，最终改变世界的，从来不是最热闹的技术，而是那些真正解决问题、创造价值的技术。华为云的 AI 路径，正在验证这个朴素的真理。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>摩尔线程天使投资人：对近期AI的四十个观察</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 30 Dec 2025 20:43:01 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-11</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-11</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;blockquote&gt;&lt;p&gt;本文作者为摩尔线程天使投资人、中国初代 AI 投资人王捷。他于今年 8 月发表了《浮现中的 AI 经济》一文，对即将到来的 AI 经济进行了展望和解读。本篇文章是他近期对当前 AI 的思考的小结。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;关于 AI 经济的四十个问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;《浮现中的 AI 经济》（以下简称 &amp;ldquo;文章&amp;rdquo;）发表以来，AI 行业继续发生了众多大事，OpenAI 牵头的千亿美金 &amp;ldquo;循环交易&amp;rdquo; 引发 &amp;ldquo;AI 泡沫论&amp;rdquo; 大讨论，模型公司估值来到数千亿美金级别，而 Gemini 3 和 GPT5.2 等新发布模型版本又持续体现了能力进步，中国模型也持续在开源领域保持全球领先。&lt;/p&gt;&lt;p&gt;我们看到，与 AI 相关的历史事实，正继续以 &amp;ldquo;&lt;strong&gt;非线性、非均匀&lt;/strong&gt;&amp;rdquo; 的特征往前发展：Scaling Law 并未收敛，AI 行业继续呈现加速发展的特点，与 AI 相关的经济活动规模来到了前所未有的量级；同时，历史进程呈现出 &amp;ldquo;非均匀&amp;rdquo; 的面貌，虽然人们是在同一个时空下，但是与 AI 有关的经济社会活动，和与 AI 无关的经济社会活动，看起来不在同一个历史进程中，前者正以强大的动能迅猛往前发展，而后者维持着我们所熟悉和习惯的、传统工业经济的节奏和特点。&lt;/p&gt;&lt;p&gt;另外，文章发表以来，一些行业领袖表达了与文章类似的观点，如马斯克认为社会将进入 &amp;ldquo;全民高收入&amp;rdquo; 时代，黄仁勋推测 AI 将把全球 GDP 推高 5 倍至 500 万亿美元，黄仁勋对于 &amp;ldquo;AI 工厂&amp;rdquo;、&amp;ldquo;数字员工&amp;rdquo; 的讨论。如何在有效框架下具体地讨论这些问题，越发成为大家共同的关注。&lt;/p&gt;&lt;p&gt;基于以上，为了集中回应读者朋友对于文章的兴趣，也为了对文章所表达的内容做更进一步的阐述，我们整理了关于 AI 经济的四十个重要问题，供关心 AI 大模型接下来对于经济、社会影响的朋友们参考。&lt;/p&gt;&lt;p&gt;我们希望这些观察，之于即将展开的 AI 经济，能对其为什么会发生、将有哪些结构性特征，给出一些可参考的观察；对于 AI 经济将要如何展开，给出一些理解、预判的视角、基准和指标；对于 AI 大模型即将带来的对于社会、经济的全面影响，给出一些观察和分析的基础框架。在一个即将展开的未知大时代，我们相信&lt;strong&gt;要揭开其全貌，提出问题，是开始的方式之一&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问题一：Transformer 架构的 Scaling Law 在何处收敛？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Scaling Law 启动了我们当前所在的 AI 大模型发展的大浪潮；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Scaling Law 作为 AI 大模型行业发展的基石，将会在何种条件下、什么时候收敛？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二：Transformer 之后，下一个将 AI 智能往前大幅推进的架构是什么？会诞生在哪里？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;这会决定我们到达 transformer 架构下的 AI 能力上限后，继续往哪里走；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;目前全球众多 AI 研究机构在做这方面的探索；正如 2015 年成立的 OpenAI 带来了这一轮的大语言模型浪潮，目前的边缘地带在十年后又可能成为最重要的技术推动力量。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三：我们需要知道更多关于 AI 大语言模型基础规律&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;目前，我们已经知道大语言模型的推理成本每 12 个月下降 90%、能力密度约每 100 天翻一番、完成复杂任务的能力每七个月翻倍等一些关于大语言模型的规律；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们能否发现 AI 大语言模型的 &amp;ldquo;摩尔定律&amp;rdquo;？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题四：AI 将以什么样的顺序、在什么时间扩散到各个行业、整个社会？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;回看蒸汽机和电力的扩散过程，基本分为&lt;strong&gt;核心原理成熟、工程化成熟、跨行业和规模化部署、成为基础设施&lt;/strong&gt;四个阶段；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;当前的 AI，处在核心原理成熟当中&lt;/strong&gt;（Scaling Law 尚未收敛）、&lt;strong&gt;工程化尚有巨大发展空间&lt;/strong&gt;（如 Deepseek、Kimi 通过工程优化都实现了明显提升模型效能）、&lt;strong&gt;跨行业和规模化部署处在早期&lt;/strong&gt;（各行业的专用 agent 均刚刚出现，都还在探索各自行业适用 AI 的最优解），这样一个阶段；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;蒸汽机完成上述过程用了 120&amp;ndash;150 年，电力完成上述过程用了 80&amp;ndash;100 年；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们初步预计，AI 完成上述整个过程可能会用 40&amp;ndash;60 年；AI 的研究始于 1956 年的达特茅斯会议；如果把 2012 年的神经网络 AlexNet 作为核心原理成熟的起点的话，那 &lt;strong&gt;AI 可能在 2035 到 2050 年完成上述过程&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题五：Transformer 架构的 Scaling Law 收敛时，对应的 AI 工作能力是怎么样的？需要一套对于 AI Agent 工作能力的评测体系&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;也就是，届时全球最领先的 AI 大模型所具备的 &amp;ldquo;工作能力&amp;rdquo;，将会达到什么水平？对于这里的 AI 工作能力，我们需要量化的评估指标，即一套对于 AI Agent 工作能力的评测体系；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当前流行的各项 AI 能力评测基准，评测任务基本不来自于真实经济活动；我们需要构建评测任务来自于真实经济活动的评测基准；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以上评测体系，可以让我们知道不同推理能力的 AI 大语言模型的 ROI / 创造价值能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题六：关于 &amp;ldquo;经济图灵测试&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在文章中我们提到，对于从事经济活动的 AI 而言，更好的评估基准是专门来评估其从事经济活动的能力，我们将其命名为 &amp;ldquo;经济图灵测试&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基于问题五提到的评测体系，我们应该有能力构建可用的 &amp;ldquo;经济图灵测试&amp;rdquo; 标准，来评价什么情况下我们认为 AI 独立完成了经济任务，什么情况下我们的经济和社会可以完全接受 AI 完成的工作结果，以及我们是否同意 AI 持续为我们完成这样的工作。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题七：关于产出增强倍数（Output Augmentation Multiple）&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;用一个经济体中一个劳动力一年的总成本，投入到 AI 和机器人系统执行该劳动力同样的任务，所得到产出与该劳动力一年产出的比值，我们称之为 &amp;ldquo;产出增强倍数&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;产出增强倍数，是这次由 AI 驱动的工业革命带给人类的结果的最显式和简洁的表达：同样的投入，人干和 AI 干，后者的产出是前者的多少倍？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在数字世界和物理世界，产出增强倍数各是多少？哪些行业的产出增强倍数高，哪些行业的产出增强倍数低？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题八：不同行业、不同经济体、AI 经济不同发展阶段的产出增强倍数各是多少？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不同行业、不同经济体的产出增强倍数各不相同；当我们有足够多的样本，我们将可以统计出这些产出增强倍数各是多少；这些产出增强倍数将为我们提供不同行业、不同经济体的 &amp;ldquo;AI 浓度&amp;rdquo; 和 &amp;ldquo;AI 有效度&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 AI 经济的不同发展阶段，会有不同的产出增强倍数；随着 AI 对于全球经济产出的贡献越来越大，对于产出增强倍数的跟踪，将有助于我们理解整个这次 AI 工业革命。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题九：在问题一的收敛状态到来时，AI 带来的工作能力会把一个经济体的全要素生产率提高百分之多少？会把稳态下的全球 GDP 增长率提高百分之多少？以及，AI 生产力会把全球的 GDP 提高到目前全球 GDP 的多少倍？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们知道，全要素生产率决定一个经济体的长期经济增长率。如果 AI 的工作能力提高了全要素生产率，那也会提高全球的长期经济增长率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第三问是问题七的加总：也就是我们在文章中提到的，&lt;strong&gt;&amp;ldquo;N 倍于当前人类经济总产出的产出能力&amp;rdquo;&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;现在大家对此有很多积极的猜测，比如黄仁勋认为是 5 倍；但是，我们需要更多扎实的基础性统计和计算工作。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十：我们会怎样进入 &amp;ldquo;非稀缺经济&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;对于一个经济体，我们将有机会定义其单位时间的&lt;strong&gt; &amp;ldquo;产出/需求比&amp;rdquo;（Output&amp;ndash;Demand Ratio）&lt;/strong&gt;，即该经济体的单位时间总产出，比上该单位时间该经济体总需求的倍数；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当单位时间的 &amp;ldquo;产出 / 需求比&amp;rdquo; 大于多少时，人们会感觉处在一个 &amp;ldquo;非稀缺经济&amp;rdquo; 中。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;&amp;ldquo;数字层使得每个个人的脑力的差异，在经济活动中被很大程度上抹除了 &amp;mdash;&amp;mdash; 新的情况是，只要有足够的电力和算力，你可以让无数个拥有科学家般智商的数字员工替你无休止地工作。&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题十一：文章提到 AI 经济阶段将可能出现的一个重要基础设施是 &amp;ldquo;数字层&amp;rdquo;。&amp;ldquo;数字层&amp;rdquo; 由用户的个人 AI 助理和各个垂类的 AI Agent 组成，全面了解消费者和生产者等经济主体，也全面了解物理世界。&amp;ldquo;数字层&amp;rdquo; 的工作机制是怎么样的？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于对个人 AI 助理和各个垂类的 AI Agent 的观察，我们可以初步说，当前正在出现的 &amp;ldquo;数字层&amp;rdquo; 是以&lt;strong&gt; LLM 为决策核心、以 Agent 为执行单元、在状态 &amp;mdash; 目标 &amp;mdash; 行动闭环中持续运行的代理化操作层&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以 chatbot 为例，它可以接收用户的问题和关于用户的环境信息，通过模型计算生成回答（可能结合实时信息获取模块），发送给用户；可以全天候工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以 agent 为例，它可以接收用户任务和环境信息，以任务为目标自主规划执行策略，收集所需信息，调用工具并执行，给用户交付该任务要求的结果；可以全天候工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以 AI 硬件 / 机器人为例，它可以感知和接收用户的环境信息，接收用户提出的任务，理解需求后自主规划执行策略，收集需要的信息，调用工具并执行，给用户交付该任务要求的结果；可以全天候工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 具有&lt;strong&gt;目标导向、自主搜索 / 获取信息、自主决策、自主行动、全天候&lt;/strong&gt;的特点。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十二：为什么数字层可能构建 &amp;ldquo;全知全能&amp;rdquo; 的能力？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数字层&lt;/strong&gt;承接了互联网和移动互联网的连接基础，&lt;strong&gt;最终将连接&lt;/strong&gt;全球所有的互联网和移动互联网用户，也就是&lt;strong&gt;全球经济活动中几乎所有的消费者和生产者&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;由于数字层可以完整执行 &amp;ldquo;收集信息 - 决策 - 行动&amp;rdquo; 链条，数字层将成为每位消费者和生产者在经济活动中的 &amp;ldquo;代理者&amp;rdquo;，在数字层能够赋能到消费者和生产者的任务中，帮助消费者和生产者完成该任务。一段时间之后，数字层&lt;strong&gt;会对使用它的消费者和生产者形成深度、完整的了解&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;所有数字层主体是通过数据协议相通的，它们都处在同一个互联网网络体系上。他们对作为各自用户的消费者和生产者的了解加总后，会形成对全球所有消费者和生产者近似于 &amp;ldquo;全知&amp;rdquo; 的了解。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;拥有了对全球所有消费者和生产者近似于 &amp;ldquo;全知&amp;rdquo; 的了解，数字层本身又可&lt;strong&gt;完整执行 &amp;ldquo;收集信息-决策-行动&amp;rdquo; 链条&lt;/strong&gt;，也就会形成近似 &amp;ldquo;全能&amp;rdquo; 的能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十三：&amp;ldquo;数字层&amp;rdquo; 如何降低交易成本？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;文章中提到，交易成本包括组织成本（组织内）和狭义的交易成本（组织间）。文章的角度是 AI 作为工具来辅助人，讨论了 AI 辅助人的情况下，两种交易成本是如何降低的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;另一种情形是，&lt;strong&gt;AI Agent 成为行动主体 &amp;mdash;&amp;mdash; 数字员工&lt;/strong&gt;。这也会产生&lt;strong&gt;拥有数字员工的公司&lt;/strong&gt;。这种情形下，&amp;ldquo;数字层&amp;rdquo; 也将有效地&lt;strong&gt;降低组织内&lt;/strong&gt;和&lt;strong&gt;组织间&lt;/strong&gt;两种&lt;strong&gt;交易成本&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;交易成本的下降，也会对 AI 生产力的提高起贡献作用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十四：&amp;ldquo;分散知识&amp;rdquo;，都会上传到数字层吗？&amp;ldquo;分散知识&amp;rdquo; 未来将如何发现、积累和传承？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;哈耶克认为，&amp;ldquo;&lt;strong&gt;社会经济问题&lt;/strong&gt;即：人们如何才能够确使那些为每个社会成员所知道的资源得到最佳使用的问题，也就是&lt;strong&gt;如何才能够以最优的方式把那些资源用以实现各种唯有这些个人才知道其相对重要性的目的的问题&lt;/strong&gt;。&amp;rdquo; 而 &amp;ldquo;&lt;strong&gt;有关各种情势的知识&lt;/strong&gt;（the knowledge of the circumstances），从来就不是以一种集中的且整合的形式存在的，而&lt;strong&gt;仅仅是作为所有彼此独立的个人所掌握的不完全的而且还常常是相互矛盾的分散知识而存在的。&lt;/strong&gt;&amp;rdquo;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;即，因为真实世界的多样和复杂性，从事经济活动的人们在不同领域形成了专长和比较优势，有了社会分工和交换，这是我们经济活动的基本结构；同时，从事不同领域经济活动的人们也形成了对该领域专门的认知、经验和知识，即上一段所说的 &amp;ldquo;&lt;strong&gt;分散知识&lt;/strong&gt;&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这些 &amp;ldquo;分散知识&amp;rdquo;，是在每一个有传承的行业群体中，由该行业的第一代人开始发现，经由后面的每一代人继续发现、积累和传承，到目前我们所处的这一代人脑中。这些 &amp;ldquo;分散知识&amp;rdquo; 通常以行业最佳实践、行业标准操作流程（SOP）、行业操作守则、该行业核心群体视之为财富的经验和认知等形式存在，是该行业的核心知识，为该行业的核心群体所护卫，会被严格控制传播范围，不会轻易传播为大众所知。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这些 &amp;ldquo;分散知识&amp;rdquo;，正是各个行业的从业人群，在此行业的经济活动中谋得成果和经济利润的信息和知识基础。目前我们可以看到，各个行业的 &amp;ldquo;分散知识&amp;rdquo;，都正在被上传到由 agent 构成的数字层中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数字层中的 agent 可以执行经济任务，&amp;ldquo;分散知识&amp;rdquo; 被上传至数字层后，将通过数字层中亿万个 agent 持续发挥作用。未来，当数字层执行的经济任务在人类所有经济任务中占比达到大部分或者绝大部分时，&lt;strong&gt;是否意味着，&amp;ldquo;分散知识&amp;rdquo; 的发现、积累和传承，将主要在数字层中进行？&lt;/strong&gt;这些过程与之前人类的这类过程有什么区别？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十五：&amp;ldquo;数字层&amp;rdquo; 将如何帮助、提升、增强用户？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;从有计算机开始，人们就希望计算机能够辅助和增强人类，如 &amp;ldquo;互联网之父&amp;rdquo; J.C.R. Licklider 在 1960 年的经典论文《Man-Computer Symbiosis》指出，计算机的价值在于&lt;strong&gt;放大&lt;/strong&gt;（amplify）&lt;strong&gt;人类思考与推理的能力&lt;/strong&gt;，计算机应该作为人类的 &amp;ldquo;认知放大器（cognitive amplifier）&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;有限理性&amp;rdquo; 的提出者赫伯特・西蒙认为，&lt;strong&gt;人类认知能力受限于注意力、记忆、计算能力&lt;/strong&gt;，因此是 &amp;ldquo;有限理性&amp;rdquo;；&lt;strong&gt;计算机&lt;/strong&gt;可以&lt;strong&gt;提供搜索、计算、模拟与信息组织能力&lt;/strong&gt;，因此能够扩展（amplify）人类的有限理性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 全面辅助人与物理世界的互动，进一步&lt;strong&gt;提高人类 &amp;ldquo;收集信息 - 决策 - 行动&amp;rdquo; 全链条的理性化程度&lt;/strong&gt;，是人类理性化的再一次重大进展；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;具体而言，人们作为 AI 产品的用户，已经可以感受到 Chatbot 和 Agent 在信息搜集、信息整理、逻辑化分析、形式化推理、无偏差实时执行、自我反思、反馈闭环方面的优秀功能，这些功能可以在各个实际场景帮助、提升、增强用户；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;同时，&amp;ldquo;数字层&amp;rdquo; 拥有上限非常高的智商和情商，可以&lt;strong&gt;作为普惠的、贴身的导师，帮助每个人成为更优秀的自己&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十六：具体而言，什么样的公司，会是构成 &amp;ldquo;数字层&amp;rdquo; 的有力竞争者？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;这会很大程度上很具体的决定，未来二十年我们生活在一个什么样的数字世界当中，由谁向我们提供数字世界的基础设施；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;互联网平台公司、基座模型公司、手机公司、AI 硬件公司、垂类 AI Agent、机器人公司&lt;/strong&gt;都是构成 &amp;ldquo;数字层&amp;rdquo; 的有力竞争者；谁会胜出？在什么时候？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十七：看起来，构成 &amp;ldquo;数字层&amp;rdquo; 的公司们，大部分以前也存在，为什么现在要单独以 &amp;ldquo;数字层&amp;rdquo; 来理解他们呢？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们在文章中提到，在人类活动数字化进程的第一阶段，互联网时代和移动互联网时代，数字世界起到的最大的作用是匹配，思考和决策还是需要人脑来做，数字世界不能单独闭环地完成工作；在人类活动数字化进程的第二阶段，数字世界可以闭环完成 &amp;ldquo;收集信息 - 决策 - 行动&amp;rdquo; 链条，便可以作为人和物理世界互动当中的 &amp;ldquo;代理层&amp;rdquo;，也就是文中提出的 &amp;ldquo;数字层&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;为什么&lt;strong&gt;人一定会把大部分与物理世界的互动交由经过这个 &amp;ldquo;代理层&amp;rdquo; 来处理呢&lt;/strong&gt;？因为这个 &amp;ldquo;代理层&amp;rdquo; 可以增强人的理性和行动能力从而提高效率，以及降低交易成本；在这几件事情上，有 &amp;ldquo;数字层&amp;rdquo; 和没有 &amp;ldquo;数字层&amp;rdquo; 的差异巨大。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十八：&amp;ldquo;数字层&amp;rdquo; 会成为经济和社会的一个基础设施吗？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在个体意义上，&amp;ldquo;数字层&amp;rdquo; 是个人和物理世界之间新出现的 &amp;ldquo;一层&amp;rdquo;，可以极大增强个人行动的理性和行动能力，增强到 &amp;ldquo;数字层&amp;rdquo; 出现之前个人很难达到的程度；同时降低经济活动的交易成本；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;因此在总体意义上，&amp;ldquo;数字层&amp;rdquo; 是个人和物理世界之间新出现的 &amp;ldquo;一层&amp;rdquo;，在本文问题四的 AI 扩散完成后，&lt;strong&gt;一种可能性是，大部分的经济活动都会通过 &amp;ldquo;数字层&amp;rdquo; 来完成&lt;/strong&gt;，&amp;ldquo;数字层&amp;rdquo; 会成为整个经济和社会中重要的基础设施。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题十九：我们当前处在 &amp;ldquo;数字层&amp;rdquo; 发展的什么时间点上？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;就 &amp;ldquo;数字层&amp;rdquo; 的出现，保证让 &amp;ldquo;数字层&amp;rdquo; 造福于人类而言，我们目前处在一个非常重要、同时也非常短暂的窗口期；&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果我们齐心协力往正确的方向推动，&amp;ldquo;数字层&amp;rdquo; 可以成为人类能力的 &amp;ldquo;放大器&amp;rdquo;、&amp;ldquo;增强器&amp;rdquo;，让机器智能补足人类的短板，同时核心的、终局的决策和权限保留在人类手中；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但另一方面，也存在 &amp;ldquo;数字层&amp;rdquo; 脱离我们控制，以及 &amp;ldquo;数字层&amp;rdquo; 的红利仅为少数人享有的风险，这是人类在这个阶段需要协力解决的重大问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;范式变化：整个经济活动范式从 &amp;ldquo;人的认知和经验&amp;mdash;行动&amp;mdash;经济产出&amp;rdquo; 变为 &amp;ldquo;使用电力和调用算力的 AI 大模型计算&amp;mdash;行动&amp;mdash;经济产出&amp;rdquo;。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题二十：AI 大模型商业形态的终局：在能源、算力、基座模型、应用之间的价值分配是怎么样的；通俗的话来说，用户所付的一块钱，是如何在以上四层之间分配的？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;目前我们处在 AI 经济刚刚启动的阶段，&lt;/strong&gt;我们能看到的是，&lt;strong&gt;行业在基座模型研发和算力消耗上投入了大量的花销，应用层的价值占比还很小，AI 计算尚未引起（局部或全局）的能源价格上涨&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们&lt;strong&gt;希望知道在 AI 大模型商业形态来到稳态&lt;/strong&gt;的时候，&lt;strong&gt;以上四层的价值分布&lt;/strong&gt;，以便于我们推断 AI 经济将给整个经济系统如何带来影响。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;目前可以预见的是，算力、模型层有显著的价值分配占比，且全球算力、模型层只有数量不多的一些公司，那意味着全球 GDP 的一定比例会流入这些公司，这些公司会有巨额收入和利润。我们应该如何理解和应对这样巨额的收入和利润？&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十一：AI 将按照怎样的顺序，具备从事不同职业的工作能力？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;自 AI 具备泛化地交付工作能力以来，AI 在交付的工作，目前主要是代码、计算机、数学、文生图 / 视频、设计、教育、线上销售等纯线上工作，以及机械化、重复性的脑力工作如笔记整理、发票整理、账目整理等工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果我们将所有职业列表出来，&lt;strong&gt;AI 将按照什么样的顺序，具备每一项职业所需要的工作能力&lt;/strong&gt;？总的来看，AI 能够完成的工作，具有任务清晰可形式化、输入输出标准化、评价函数明确、能力可通过数据规模提升等特点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于该时间表和发展顺序的合理估计，将有助于我们应对接下来要发生的系列变化。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十二：AI 对就业的冲击将如何发生？一个预估全景图&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如问题二十七所述，AI 具备泛化地交付工作能力之后，会具备越来越多的职业所需要的工作能力，也就会在客观上形成对原有就业的替代；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;有了以上 &amp;ldquo;AI 如何具备不同行业工作能力&amp;rdquo; 的路线图，我们将&lt;strong&gt;有能力绘制 &amp;ldquo;AI 对就业的冲击将如何发生&amp;rdquo; 的预估全景图&lt;/strong&gt;，以了解和清楚 AI 造成的就业替代将会如何发生；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这个预估全景图首先是&lt;strong&gt;告诉我们未来的全景是怎么样的&lt;/strong&gt;，影响的量级有多大，为此我们需要做什么样的心理准备；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其次，预估全景图&lt;strong&gt;是一个评价和纠正体系&lt;/strong&gt;，让我们知道相较于全局，我们此刻在哪，我们是否偏离了已预见的航道，如何调整，是否有调整的工具；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当然，我们会根据实际的进展情况，定期来评估和更新这个预估全景图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十三：会否形成初级工作的 &amp;ldquo;真空地带&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;目前 AI 对初级工作的替代已经开始了，在这些工作领域，会否形成初级工作的 &amp;ldquo;真空地带&amp;rdquo;？即对于人类有需求的职位直接从中级开始，年轻人没有了上手的工作，年轻人失去了职业发展的初始路径，这是需要仔细解决的问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十四：工作逻辑的变化：&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系正在形成当中&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在&lt;strong&gt;由人执行的经济活动中，单个劳动力是最小的行动单元&lt;/strong&gt;，且单个劳动力需要长期稳定从事某个工作，因此工作可被拆分的最小单元是职业 / 职位 / 工种，&lt;strong&gt;人类的工作是以职业为基本单元&lt;/strong&gt;；在由 &lt;strong&gt;AI Agent 执行的经济活动中&lt;/strong&gt;，最小的执行单元是 &amp;ldquo;一个任务&amp;rdquo;，因此&lt;strong&gt;工作可被拆分的最小单元是任务&lt;/strong&gt;。&amp;ldquo;任务&amp;rdquo; 是远比 &amp;ldquo;职位 / 工种&amp;rdquo; 更小的执行单元。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当 AI 在整个经济活动中承担的工作占比越来越大之后，工作的基本单元，会日渐从职业变化为任务。&lt;strong&gt;整个工作体系可能从 &amp;ldquo;以职业 / 职位为中心&amp;rdquo; 向 &amp;ldquo;以任务为中心&amp;rdquo; 转变&lt;/strong&gt;，&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系正在形成当中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系将使得工作的颗粒度更细，经济活动将被划分为可被更加细密排列的基本单元，从而提高经济活动的效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;职业可以被拆解为任务，也意味着人仍然作为职业主体的情况下，原来由其负责的任务，可以被 AI 来完成。这也是一种形式的人机协同。一方面，这是工作场景中 &amp;ldquo;AI 协助人&amp;rdquo; 的很好的形式，AI 完成一部分任务，人完成另一些 AI 尚不能完成的任务，并且管理 AI；另一方面，我们也需要防范一种可能性，即职业主体仍然是人，但是其负责的任务都已经是 AI 来完成，&amp;ldquo;每天坐在工位前的还是我，但是有价值的活都是 AI 在干了，我只是在看着它干活&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;以任务为中心&amp;rdquo; 的工作体系，将带来众多深远的影响，需要我们进一步探讨。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;一个人机共生、AI 作为工作同事的阶段正在到来。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题二十五：正在出现当中的 AI 员工&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 具备（泛化）交付工作的能力之后，这些具备工作能力的 AI，可以成为实际意义上的 &amp;ldquo;AI 员工&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 员工都具备哪些特点？AI 员工与人类员工的区别有哪些？哪些行业将率先拥有 AI 员工？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十六：组织中的 AI 员工&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;可以预见，在我们的各类组织（如公司、非营利组织、政府等）中，都会出现 AI 员工；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 员工将给组织的管理带来哪些变化？如 AI 员工的招聘、培训、考核，都会是什么样的？AI 员工将如何与人类员工分工协作？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 员工将如何改变组织，带来组织形态的哪些变化？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十七：广大的中小企业可以因为 AI 员工获得较之前更强的竞争能力吗？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;当前使用了 AI Agent 参与工作流程的中小企业，反馈他们认为自己获得了远超过当前人类员工人数的工作能力；广大的&lt;strong&gt;中小企业可以因为 AI 员工，获得较之前更强的竞争能力&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;中小企业竞争能力的增强，有可能提高初创企业创业成功的概率，可能使得更多大公司的核心员工成立自己的公司，可能使得某些经济领域的重要资源更广泛地分布。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 可能成为一个细颗粒度、高频、跨主体的经济感知-决策-执行层。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题二十八：AI 经济阶段的经济统计是怎么样的？数字层将如何影响经济统计？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;随着越来越多的经济活动以数字化的形式进行，越来越多的经济活动经由 &amp;ldquo;数字层&amp;rdquo; 执行，经济活动中那些物理世界的属性，将越来越多地体现为数字世界的属性；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&amp;ldquo;数字层&amp;rdquo; 的细颗粒度、高频、跨主体特点&lt;/strong&gt;，可能会为我们提供更丰富的经济统计工具，相应地提高经济统计的颗粒度、频次，并让我们可能更容易拥有全局的统计结果。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题二十九：AI 经济是否可以一部分地平抑经济周期？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;经济周期&lt;/strong&gt;的形成，与&lt;strong&gt;信息不完全、价格和数量调整摩擦、预期与金融放大&lt;/strong&gt;都有关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 &amp;ldquo;数字层&amp;rdquo; 成为经济活动的基础设施之后，&amp;ldquo;数字层&amp;rdquo; 对以上三个环节都能起到缓解和改善的作用：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 全面了解消费者和生产者等经济主体，也全面了解物理世界，可能降低经济状态空间的不可观测性，从而可能降低当前经济活动中信息不完全的程度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 可能实现微观层面的连续调节，把当前由人脑判断做出的调节档位提升数个数量级的精度，从而降低价格和数量调整的摩擦；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;数字层&amp;rdquo; 连接经济活动的全局，可能实现全局协调和跨期协调，可能降低当前经济活动中个体对于信号的主观放大带来的波动性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十：我们应该如何发挥好 &amp;ldquo;数字层&amp;rdquo; 的优势，尽量避免其潜在的弊端？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&amp;ldquo;数字层&amp;rdquo; 细颗粒度、高频、跨主体的特点，将为我们带来一个较现在颗粒度更细、频次更高、更容易得到全局信息的经济基础设施；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但同时，这些特点也带来一些潜在的风险，如高频执行的频次远超人脑可以反应的范畴，过去在金融量化系统中也曾造成过人脑来不及反应的 &amp;ldquo;闪崩&amp;rdquo;；如何增强 &amp;ldquo;数字层&amp;rdquo; 的稳定性，是需要多方共同努力的课题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十一：是否以及如何设计经济系统中新的政策工具？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;就已经开始显现的 AI 对就业的冲击，我们应该如何设计劳动力的 AI 培训、促进新岗位产生等缓冲机制？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更一般地，当前经济系统中的调节工具，即诞生于工业革命以来的财政工具和税收工具，能否适配 AI 经济的特点？如果不能完全适配的话，我们应该如何设计新的政策工具？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十二：如何设计社会财富再分配体系？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 AI 经济阶段，大量经济活动的成果积累在模型层和头部的应用层公司，社会财富的分配存在失衡的风险；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;同时，大部分劳动的价值被压缩；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何设计有效的社会财富再分配体系？这是我们需要面对的重大课题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;人类发展的一个历史规律是，那些能显著提高人类生产力和生活水平的技术进步，最终会扩散到全世界，遍布这个星球。AI 也是如此。世界各国会或先或后地进入 AI 在其整个经济活动中起重要作用的阶段。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;问题三十三：世界各国将以什么样的顺序进入 AI 经济阶段？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 大模型服务、AI 应用服务、AI 算力基础设施，将以什么样的顺序，先后抵达全球所有国家？世界各国将以什么样的顺序进入 AI 经济阶段？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十四：如何评价一个经济体的 &amp;ldquo;经济社会被 AI 赋能&amp;rdquo; 的程度？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们需要一套体系，&lt;strong&gt;来评价一个经济体的 &amp;ldquo;经济社会被 AI 赋能&amp;rdquo; 的程度；&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该体系初步的指标包括企业的 AI 使用率（特别是中小企业）、AI 在企业业务流程中的覆盖比例、Agent 部署密度、企业员工人均 AI 交互频次、居民人均 AI 交互频次等；仍需要进一步构建；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该评价体系可以让各经济体对于自己处在 AI 经济发展的哪一个相对位置，有更清晰的判断，便利于这些经济体制订自己的 AI 经济发展计划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;该评价体系也可用于国际组织评价全球不同国家地区的 AI 发展情况。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十五：什么是 &amp;ldquo;AI 充裕经济体&amp;rdquo;/&amp;ldquo;AI 充裕社会&amp;rdquo;？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于以上评价体系，我们可以建立 &amp;ldquo;&lt;strong&gt;AI 充裕经济体&lt;/strong&gt;&amp;rdquo; 和&lt;strong&gt; &amp;ldquo;AI 充裕社会&amp;rdquo;&lt;/strong&gt; 的概念。这样的经济体，是&lt;strong&gt;一个 AI 被充分、适当地使用，AI 充分赋能经济和社会发展的经济体，AI 可以为该经济体带来人类可欲的结果&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;是否 &amp;ldquo;AI 充裕&amp;rdquo;，可能成为下一个阶段评价一个国家竞争力的重要指标，也是评价 &amp;ldquo;发达国家 / 发展中国家&amp;rdquo; 的一个重要角度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;电力、算力、模型将成为各国家的战略资源。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十六：&amp;ldquo;AI 欠充裕经济体&amp;rdquo; 和 &amp;ldquo;AI 匮乏经济体&amp;rdquo;，应该采用什么样的发展和追赶策略？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 的发展需要&lt;strong&gt;能源、算力、数据、算法&lt;/strong&gt;四个层面的配合建设。一个经济体需要以稳定、充足、低成本的电力供应作为基础，在本地建设足够规模的算力中心，结合本经济体已经积累的互联网数据、各行业业务数据、政府数据，通过调用闭源或者开源基座模型服务，建设该经济体的 AI 能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;具体到某一个国家和地区，需要在能源、算力、数据、算法四个层面评估本国 / 本地区的基础和现状，制订合理、有效、前期成本可控的发展和追赶策略；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型研发、AI 应用研发、标准制定、平台治理可能都发生在 &amp;ldquo;AI 充裕国家&amp;rdquo;；&amp;ldquo;AI 欠充裕经济体&amp;rdquo; 和 &amp;ldquo;AI 匮乏经济体&amp;rdquo; 可通过模型本地化、建设区域算力节点来补齐 AI 能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十七：AI 经济会带来国际分工、国际供应链的哪些变化？不同国家占全球 GDP 的比例，将如何变化？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;传统国际分工是基于各国不同的技术差异、劳动力等要素禀赋差异，这些差异是国际分工的前提，也塑造了国际分工的形态；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 AI 经济阶段，全球 Agent 和机器人建立在同一个 &amp;ldquo;数字层&amp;rdquo; 之上，&lt;strong&gt;全球 Agent 和机器人的工作能力将趋同，传统国际分工的要素禀赋差异前提可能被改变&lt;/strong&gt;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在 AI 经济阶段，&amp;ldquo;&lt;strong&gt;按任务划分的经济活动的全球最优分配&lt;/strong&gt;&amp;rdquo;，是国际分工逻辑的可能性之一；&lt;strong&gt;不同国家在 &amp;ldquo;关键任务节点的不可替代性&lt;/strong&gt;&amp;rdquo;&amp;nbsp;可能成为国家之间分工的重要因素。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;国际分工变化之后，各国在全球 GDP 中占比的逻辑也会发生变化；以及，我们应该如何应对这种变化带来的影响？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十八：对于 AI 经济阶段，全球算力和能源需求的预估&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在以上背景下，全球算力需求将以什么样的速度增长？我们是否会遇到算力供给的瓶颈？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;激增的算力需求将给能源供应带来哪些变化？我们是否会遇到能源 / 电力供给的瓶颈？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题三十九：我们是否可能，以及如何设定 AI 与人的能力分工？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;目前我们看到的情况是，AI 可以把数据类、分析类的工作做得比人好，而人类在情感、感受、共情、审美、创造力等领域仍然保持绝对优势。这个局面能长期保持吗？或者说，&lt;strong&gt;基于神经网络的大语言模型，其思维能力的边界在哪里&lt;/strong&gt;？是否存在一些领域，AI 永远也追不上人脑的能力？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果有的话，这些领域是什么？如何定义这些领域？&lt;strong&gt;计算机的精确性和人脑的模糊性，是天然的划分标准之一吗？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果没有的话，&lt;strong&gt;我们是否应该、是否可能设定一条界限，让 AI 的能力停留在这条界限的一侧？如何设定这条界限？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;让人类保有&lt;strong&gt;价值设定、目标设定、判断力、创造力、情感交流、审美、对 AI 的监督 / 管理 / 最终控制权&lt;/strong&gt;，是否这条界限的一个答案？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;如何确保所有的 AI 大模型开发商和开发者，都遵循这条界限？&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;问题四十：&amp;ldquo;非稀缺经济&amp;rdquo; 实现后的闲暇消费和生活意义问题&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;AI 具备泛化地交付工作能力之后，人类会有可能拥有一个 &amp;ldquo;非稀缺经济&amp;rdquo;。在约一百年前，&lt;strong&gt;凯恩斯&lt;/strong&gt;敏锐地看到了这一点，在《我们后代在经济上的可能前景》中，他写道：&lt;strong&gt;&amp;ldquo;我们的天性 &amp;mdash;&amp;mdash; 包括我们所有的冲动和最深层的本能 &amp;mdash;&amp;mdash; 为了解决经济问题而进化发展起来的。如果经济问题得以解决，那么人们就将失去他们传统的生存目的&lt;/strong&gt;&amp;rdquo;。&amp;ldquo;经济问题、生存竞争，一直是人类首要的、最紧迫的问题 &amp;mdash;&amp;mdash; 不仅是人类，而且在整个生物界，从生命的最原始形式开始莫不如此&amp;rdquo;。&amp;ldquo;长久以来，我们都是被训练着去奋斗而不是去享受 &amp;hellip;&amp;hellip; 当他再也不能在传统社会的温床和他所珍视的那些风俗习惯中找到自己的根基时，这个问题就显得尤为严重。&amp;rdquo;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;ldquo;人类自从出现以来，第一次遇到了他真正的、永恒的问题 &amp;mdash;&amp;mdash; 当从紧迫的经济束缚中解放出来以后，应该怎样来利用他的自由？科学和复利的力量将为他赢得闲暇，而他又该如何来消磨这段光阴，生活得更明智而惬意呢？&amp;rdquo;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;凯恩斯也提出了具体的建议，他认为 &amp;ldquo;任何人如果想要生活得舒心畅意，那么他就必须得干一点工作。&amp;rdquo; 他甚至提出了 3 小时工作制：&amp;ldquo;3 小时一轮班或每周 15 小时的工作，也许会使上述问题在相当长一段时间内得以缓解&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;诚如凯恩斯所写，&lt;strong&gt;人基于千万年的遗传形成的生物性，在短期内是难以改变的，但是 AI 改变经济的节奏可能是快速的&lt;/strong&gt;。如果 &amp;ldquo;非稀缺经济&amp;rdquo; 到来，&lt;strong&gt;在工作之外，新的、能使人们在闲暇中获得满足感的活动是什么，对于人类群体的人生意义该如何定义&lt;/strong&gt;，以及如凯恩斯所考虑，是否应该设计新的工作时长机制以&lt;strong&gt;使人对于工作的生物性本能得到部分承接&lt;/strong&gt;，都是需要认真思考的经济、社会和哲学问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者王捷，中国初代 AI 投资人，完整经历了移动互联网各个发展和投资阶段， 2017 年以来主要从事 AI 行业投资，投资了摩尔线程、比亚迪半导体、万国数据、京东科技、开思时代、奇安信、明略科技等公司。作者邮箱 jie_wang7@sina.com，微信如下，欢迎交流，添加请说明工作/学习机构、职务信息。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibezJs5hKgvAnq6m4dDBleLtQVHNEooe08JQ2oZ6XLNw8KiciaribUMTUVyw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="1.0204081632653061" data-s="300,640" data-type="jpeg" data-w="1029" type="block" data-imgfileid="503526268" data-aistatus="1" data-original-style="width: 118px;height: 120px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/503f554b-adf8-44aa-bbbe-1d0b3edb8a9a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 30%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>三维空间太难懂？RoboTracer让机器人理解复杂空间指令，推理3D空间轨迹，开放世界也能精确行动</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 30 Dec 2025 20:24:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-10</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;tp=webp#imgIndex=0" alt="图片" data-ratio="0.5703703703703704" data-w="1080" data-backw="562" data-backh="321" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/3e7840c4-3ad6-4a50-a5b6-c98012fb7379/640.png" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;本文的主要作者来自北京航空航天大学、北京大学、北京智源人工智能研究院和中科院自动化研究所。本文的第一作者为北京航空航天大学博士生周恩申，主要研究方向为具身智能和多模态大模型。本文的共一作者兼项目负责人为北京智源研究院研究员迟程。本文的通讯作者为北京航空航天大学教授盛律和北京大学计算机学院研究员、助理教授仉尚航。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们希望具身机器人真正走进真实世界，尤其走进每个人的家里，帮我们完成浇花、收纳、清洁等日常任务。但家庭环境不像实验室那样干净、单一、可控：物体种类多、摆放杂、随时会变化，这让机器人在三维物理世界中「看懂并做好」变得更难。&lt;/p&gt;&lt;p&gt;想象一下你下班回到家，对家用服务机器人说： 「按从左到右的顺序给每盆花浇水；喷壶要在每朵花上方 1&amp;ndash;5 厘米处停住再浇，这样更均匀。」（如下图）&lt;/p&gt;&lt;section&gt;&lt;a href="https://mp.weixin.qq.com/s/GoOby4U9nUOEgIxw2NgPLQ"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZVbLkz0bMsfO3ibNSrkKAwFQiaL0qkbKQhMPFDibx53tBnFxbFd8zcI7tA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3469879518072289" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="201" data-imgfileid="503525422" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/45111ab2-f826-4e89-96b0-0b990794db58/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;对人来说这很自然，但对机器人来说，难点不在「浇水」本身，而在指令里隐含了大量空间约束：既有&lt;strong&gt;定性&lt;/strong&gt;的（从左到右、在上方），也有&lt;strong&gt;定量&lt;/strong&gt;的（1&amp;ndash;5 厘米）。在杂乱的开放世界场景中，让机器人稳定遵循这些约束，哪怕对目前最先进的视觉 - 语言 - 动作模型（VLA）也依然是挑战。&lt;/p&gt;&lt;p&gt;一个直接的突破口是：让视觉 - 语言模型（VLM）生成一条满足这些空间约束的 3D 位置序列 &amp;mdash;&amp;mdash; &lt;strong&gt;空间轨迹（Spatial Trace）&lt;/strong&gt;。它相当于一座桥梁：既能把「指令在 3D 空间中如何被理解与执行」的过程表达清楚，也能进一步用来指导机器人生成可执行的动作轨迹。但空间轨迹生成本质上非常困难，因为它需要在 3D 场景里进行&lt;strong&gt;多步、带真实尺度约束的推理&lt;/strong&gt;，并且每一步都要同时具备两种关键能力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3D 空间指代&lt;/strong&gt;：理解指令中的&lt;strong&gt;各种空间关系&lt;/strong&gt;，并在 3D 场景中&lt;strong&gt;准确指代定位相关物体&lt;/strong&gt;（例如按「从左到右」依次找到每盆花）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;3D 空间度量&lt;/strong&gt;：理解现实世界的&lt;strong&gt;绝对尺度并做计算&lt;/strong&gt;（例如估计花的物理高度，确定其上方 1&amp;ndash;5 厘米对应的具体 3D 位置）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;遗憾的是，现有很多 VLM 工作主要集中在 2D 空间推理或 2D 视觉轨迹生成：一方面往往&lt;strong&gt;弱化了轨迹生成最关键的「多步推理」过程，尤其缺少对中间关键对象的显式建模&lt;/strong&gt;，容易导致结果次优；另一方面输出多停留在 2D 像素坐标，&lt;strong&gt;缺乏 3D 指代定位与绝对尺度理解&lt;/strong&gt;。这也造成了 2D 视觉轨迹与 3D 空间轨迹之间的根本鸿沟。&lt;/p&gt;&lt;p&gt;为了解决这一问题，北京航空航天大学、北京智源人工智能研究院、北京大学等机构联合推出了具备 3D 空间理解与推理能力的多模态大模型 &amp;mdash;&amp;mdash;RoboTracer。RoboTracer 通过&lt;strong&gt;全参数微调（SFT）&lt;/strong&gt;强化空间信息的精准理解（空间感知 / 度量 / 指代），并进一步用&lt;strong&gt;强化学习微调（RFT）&lt;/strong&gt;提升推理与泛化能力，最终在&lt;strong&gt;开放世界场景中实现可用的 3D 空间轨迹生成&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZdjYfy48CH1aF2RdzibyTDY3foGVSdzprCrsb1edCeX4XsDqe1n5swgg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.35180722891566263" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="203" data-imgfileid="503525423" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/876890c5-35bc-4ad2-a9d6-386fa45f3dca/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.13660&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文标题：RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://zhoues.github.io/RoboTracer/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码仓库：https://github.com/Zhoues/RoboTracer&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;评测链接：https://huggingface.co/datasets/JingkunAn/TraceSpatial-Bench&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是真机实拍的机器人浇花过程，包含&lt;strong&gt;多步、带真实尺度约束的推理&lt;/strong&gt;：&lt;a href="https://mp.weixin.qq.com/s/GoOby4U9nUOEgIxw2NgPLQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f9cbd93b-6aa4-4276-94b1-d67410df387e/1767097050323.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;SFT 训练下的 RoboTracer 在空间理解 / 空间度量 / 空间指代任务中达到了 &lt;strong&gt;79.1% 的平均成功率&lt;/strong&gt;，刷新了当前最先进水平。而在研究者提出的高难度空间轨迹生成任务评测基准&lt;strong&gt;&amp;nbsp;TraceSpatial-Bench&lt;/strong&gt; 上，RFT 训练后的 RoboTracer 更是&lt;strong&gt;领先所有其他模型，比 Gemini-2.5-Pro 高出 36% 的平均准确率&lt;/strong&gt;，优势显著。&lt;/p&gt;&lt;p&gt;更关键的是，RoboTracer 直接做到「开箱即用」：可以&lt;strong&gt;灵活集成到不同类型的机器人上&lt;/strong&gt;，比如 UR5 机械臂、G1 仿人机器人等，在真实环境中完成&lt;strong&gt;复杂、动态、多步骤任务&lt;/strong&gt;，让机器人真正做到「听得懂、看得清、动得准」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RoboTracer 是什么？&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZNZFIvljLeqnQOO8icKu0DiaZuwJArJB6xRPoIzfPfibFRldSTxOQicXJWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.47494033412887826" data-s="300,640" data-type="png" data-w="838" type="block" data-backw="578" data-backh="275" data-imgfileid="503525432" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/6e23a344-3077-497d-a6f7-3a8a8b0e757d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;RoboTracer 是一个&lt;strong&gt;三维空间理解与推理能力&lt;/strong&gt;的多模态大模型，其拥有单独的图片编码器和&lt;strong&gt;支持任意多几何输入（绝对深度图，相机内参）的空间编码器&lt;/strong&gt;。该模型具备较完备的空间感知推理能力，不仅仅可以回答各种&lt;strong&gt;空间感知类问答&lt;/strong&gt;，无论是「哪个物体在左边？」这样的定性问题，还是「这个物体高度是多少？」这样的定量问题，并且还预测当前场景的尺度缩放因子；更厉害的是，它还可以基于 3D 空间指代和 3D 空间度量进行，&lt;strong&gt;复杂的组合式推理&lt;/strong&gt;，最终&lt;strong&gt;准确生成精确的空间轨迹&lt;/strong&gt;（如上图，逐一从左到右确定每一盆花的 3D 位置及其高度）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RoboTracer 的核心是什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么相较于以往的方法，RoboTracer 不仅可以精确的感知空间，而且又可以根据多个空间关系组合泛化进行带真实尺度约束的推理呢？其关键因素在于以下几点：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解耦 (u, v, d) 表达增强多任务学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;传统方法直接回归 (x, y, z) 坐标，往往要求模型强行根据单目图片预测复杂的相机几何信息（比如相机内参），导致训练难、精度低。RoboTracer 提出了一种符合具身场景的解法：&lt;strong&gt;利用 (u, v, d) 进行解耦表达&lt;/strong&gt;。这种表示法利用图像像素 (u, v) 和深度 d，结合已知的相机内参，轻松换算真实 3D 坐标。其核心优势在于：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 降低学习门槛&lt;/strong&gt;：不用让 VLM「硬学」复杂的相机几何信息，训练更简单，精度也更高。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 数据复用能力更强&lt;/strong&gt;：(u, v, d) 很容易投影到更低维的任务上 &amp;mdash;&amp;mdash; 去掉 d 就变成 2D 轨迹；只保留起点 / 终点，又能构造成 2D/3D 的空间指代数据。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通用空间编码器与尺度解码器提升绝对尺度感知&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;想要精准定位物体、测量距离，模型必须理解「真实世界的尺寸」。但很多只用 RGB 训练的 &lt;strong&gt;VLM 缺少绝对尺度概念&lt;/strong&gt;，因此距离 / 尺寸容易估不准。为了解决这一点，研究者加入两个关键模块：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 尺度解码器&lt;/strong&gt;：将 &amp;lt;SCALE&amp;gt; token&amp;nbsp;&lt;strong&gt;直接回归&lt;/strong&gt;成一个数值尺度因子，把「尺度不变的特征」与「真实世界的绝对长度」对应起来。相比分类损失，&lt;strong&gt;用回归损失监督&lt;/strong&gt;更能提升对三维真实尺度的感知。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 通用空间编码器&lt;/strong&gt;：借助前馈式三维度量几何模型提供的&lt;strong&gt;强几何先验&lt;/strong&gt;，显著增强模型的空间与尺度理解。它还能&lt;strong&gt;按需融合&lt;/strong&gt;不同几何信息（如相机内参、位姿、深度）：几何信息越多，空间表示越精细。该设计带来两点好处：（1）&lt;strong&gt;训练更灵活&lt;/strong&gt;：通过灵活输入增强，把不同数据集中带尺度标注的信息用起来，提升空间学习效果（2）&lt;strong&gt;推理更自适应&lt;/strong&gt;：无需重新训练或改结构，就能融合当前可用的几何信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SFT 增强感知，RFT 搭配过程奖励提升推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RoboTracer 采用两阶段训练策略，其中 SFT 阶段针对性地提升模型的单步 3D 空间理解 / 空间度量 / 空间指代能力；RFT 阶段不仅关注最终轨迹结果的奖励，还创新性地设计度量敏感过程奖励，这些奖励函数能够显式监督轨迹生成中涉及的关键中间感知步骤（如 3D 指代、3D 度量和尺度预测）的质量。最终，模型增强了&lt;strong&gt;多步、带真实尺度约束的推理&lt;/strong&gt;，实现了对复杂空间约束任务的空间轨迹规划。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;提出 TraceSpatial 数据集 &amp;nbsp;教一个多模态大模型从0到1学会生成空间轨迹&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZiaMhwvsbkrNlPUxn1aJSjRZeaiaFE0h2B8QrSyO7X3nWerWWcaIdaQyw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.4795180722891566" data-s="300,640" data-type="png" data-w="830" type="block" data-backw="578" data-backh="277" data-imgfileid="503525434" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/bfa9c211-6250-40c1-9864-6cc642aab910/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了支持前述的 SFT 和 RFT 训练，研究团队构建了一个大规模、高质量、带真实尺度的数据集 &amp;mdash;&amp;mdash;TraceSpatial，具有以下几个核心特点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;场景多样&lt;/strong&gt;：覆盖室内外和桌面环境，包含物体和末端执行器两种分别为中心的空间轨迹，后者包含 3 种不同的单臂 / 双臂机器人构型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;维度丰富&lt;/strong&gt;：包含大量尺度相关数据（占 48.2%），还附带详细的多步推理过程（最高有 9 步），为复杂空间轨迹生成提供支持。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;规模庞大&lt;/strong&gt;：共包含 450 万个样本、3000 万个问答对，目前最大 3D 空间数据集。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;精细标注&lt;/strong&gt;：每个物体都配有层级式描述，从「花」这类种类类别，到像「左数第一个盆花」这样的精确空间指代，确保在复杂场景中也能清晰用文字表述。同时包含大量绝对尺度的几何信息标注（比如相机内参、深度图）以支持灵活的输入增强。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;高质量筛选&lt;/strong&gt;：数据经过严格筛选，确保标注准确、语义清晰。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;易于扩展&lt;/strong&gt;：支持从多种来源生成空间轨迹数据，包括 2D 图像、3D 扫描数据和机器人操纵视频，具备高度扩展性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;RoboTracer 到底有多厉害&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;空间理解 / 空间度量 / 空间指代&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SFT 训练下的 RoboTracer 在空间理解 / 空间度量 / 空间指代任务中达到了 &lt;strong&gt;79.1% 的平均成功率&lt;/strong&gt;，取得了当前最先进水平，&lt;strong&gt;比 Gemini-2.5-Pro 高出 11% 的平均准确率&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZlV0IsBZia7hNLsBr48HBFkXqzK1jP7ib3o9qib5RSGPnlDzRudPcN9DbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3472222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="201" data-imgfileid="503525437" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/31ce6804-9a7b-45b8-b806-a7242204da01/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZLlf1wUqCH9yKbGccHPPQo5Je0yw9icgKxqgPtPHO3JublY1orlDcLmw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.29259259259259257" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="169" data-imgfileid="503525439" data-aistatus="1" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/3219a333-b102-452f-bddf-bd7ef9e88ea1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;空间轨迹评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RFT 训练后的 RoboTracer 在研究者们提出的高难度空间轨迹生成任务评测基准 &lt;strong&gt;TraceSpatial-Bench&lt;/strong&gt; 上更是领先所有其他模型，&lt;strong&gt;比 Gemini-2.5-Pro 高出 36% 的平均准确率&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZw5UcWKAKzggcSYXOxfhRdux0SkI5zXnG8jvbCCOYg0ia1nXoWiaPF2rw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.67601246105919" data-s="300,640" data-type="png" data-w="642" type="block" data-imgfileid="503525440" data-aistatus="1" data-original-style="width:287px;height:194px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/2138504c-ffad-40fc-a0f2-e20e0f13afa9/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;下面展示一些 RoboTracer 与其它模型输出结果的可视化样例，不难发现目前的 VLM 都理解空间关系并且生成 2D 轨迹，但是由于绝对深度预测不精确导致生成的空间轨迹往往浮空或者碰撞，而 RoboTracer 可以较为精确地预测，而且更多的几何输入预测结果更精确。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ2CuT3OOnDd7K4aMSBV5mDOTK8ck6pfaibXsLO9ds8gu7RicHESqQDBibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.35336538461538464" data-s="300,640" data-type="png" data-w="832" type="block" data-backw="578" data-backh="204" data-imgfileid="503525441" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/36b9660d-8cd2-4bfe-86a1-6aa9d276d490/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;仿真与真机实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在空间操控的机械臂仿真评测中，RoboTracer 的表现远超现有的视觉 - 语言 - 动作（VLA）系统。不仅在模拟环境中成功率遥遥领先，面对开放世界中需要&lt;strong&gt;多步、带真实尺度约束的推理的复杂任务，唯有 RoboTracer 能够完成&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZLuZiaApwc1EIu8WUU7LZPDn8umxxPzINtOUgNJDLmHPEib4Jf6k4aKXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.5828220858895705" data-s="300,640" data-type="png" data-w="652" type="block" data-imgfileid="503525442" data-aistatus="1" data-original-style="width:384px;height:224px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/300c0f66-b090-4129-9819-5895df75fbf4/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZnR65ib8icbLIlokZruSHzBkYC6AU5uBXib7LgVPic2sTLNjpH1GkshGJBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3259493670886076" data-s="300,640" data-type="png" data-w="632" type="block" data-imgfileid="503525443" data-aistatus="1" data-original-style="width:380px;height:124px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/74754fc8-9ee2-4f5d-8d59-b04faa753f59/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7ebdb0bd-8135-4a26-91d3-cf00cb1afd01/1767097339125.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/section&gt;&lt;p&gt;更多的实验结果，可视化展示（包括更多的杂乱场景下的真机 Demo 视频的空间轨迹生成结果）详见论文和主页。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>LSTM提出者点赞，引力波探测高效工具，国内团队开发DCL-xLSTM</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Tue, 30 Dec 2025 17:57:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-9</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwTtNEG628xTtPAp995MNnGaBKLkV0IFCUlRKZU7QWW2gonBdT7zXIfQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-ratio="0.7111111111111111" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="100027034" data-aistatus="1" data-original-style="null" data-index="1" src="https://image.jiqizhixin.com/uploads/editor/560ee32b-7fec-49ef-b3ad-cae33698bb96/640.jpeg" alt="图片" data-before-load-time="1767088607068" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑丨coisini&lt;/span&gt;&lt;/p&gt;&lt;p&gt;2015 年 9 月 14 日，人类首次直接探测到双黑洞并合引力波事件 GW150914，标志着引力波天文学迈入了新纪元。经过十年发展，基于空间的引力波探测器预计将观测到被透镜化的引力波事件，为宇宙学和基础物理学研究提供新机遇。&lt;/p&gt;&lt;p&gt;然而，目前最先进的透镜化引力波识别方法虽然精度较高，但计算成本昂贵。即使对单个事件进行完整参数估计也可能耗时数小时。这种计算成本将成为未来引力波巡天（GW surveys）的瓶颈。&lt;/p&gt;&lt;p&gt;特别是在毫赫兹频段，引力波波长常与透镜的史瓦西半径相当，波动光学效应显著。尽管传统的匹配滤波方法有效，但其需要大量计算资源。&lt;/p&gt;&lt;p&gt;最近，来自中国科学院大学、中国科学院力学研究所等机构的研究团队提出了一种针对引力波探测的长短期记忆网络（LSTM），称为双通道透镜化特征提取扩展长短期记忆网络（Dual-Channel Lensing feature extraction eXtended Long Short-Term Memory Network，DCL-xLSTM）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwzRcoIw76jHj3Of3jUjVkL4wpDflSHCKh7TV3kLRicC8BRTZrRG9eibDQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.32685185185185184" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027027" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/a3f65d63-5ccc-41ad-8430-d2e5aaa848c0/640.jpeg" alt="图片" data-before-load-time="1767088607028" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.21370&lt;/p&gt;&lt;p&gt;与传统循环架构不同，DCL-xLSTM 采用矩阵值记忆结构和记忆混合机制，能有效捕捉覆盖整个毫赫兹频段的振幅衍射模式。&lt;/p&gt;&lt;p&gt;LSTM 的提出者之一 Sepp Hochreiter 在去年 5 月推出了 xLSTM，将 LSTM 扩展到数十亿参数。现在他称赞「DCL-xLSTM 是很酷的 xLSTM 应用」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwyu0rDpuRTUZasEwE8au0PPwxjP5G74ll029bCd93ppZAVibXDYHujIQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.43796296296296294" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027028" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/53de269c-46e9-4d08-8bbd-156853e7298d/640.jpeg" alt="图片" data-before-load-time="1767088607011" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;方法概览&lt;/p&gt;&lt;p&gt;已有原理验证研究证明深度学习方法能以高精度区分引力波信号，近期更有研究表明：深度学习框架已成为识别透镜化引力波信号的一种极具前景的高速替代方案。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwgdiaUpfBXV506UDBXZcOtkvmYtYGGHiarGYAPj6BHHIqGXdHyjjPI43w/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=4" data-ratio="0.5148148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027029" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ba539197-e87d-4c2b-9dc5-5b615e468bf9/640.jpeg" alt="图片" data-before-load-time="1767088606852" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwu8Xks0sQEesVNxTOr1tz9G4PuXIibAcUxnX0E2LqydvEwwdPv35KWQg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.44537037037037036" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027030" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/2152dafb-bb89-4e3d-9023-30492f0da683/640.jpeg" alt="图片" data-before-load-time="1767088606836" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;研究团队首先构建了一个涵盖从波动光学到几何光学区域连续过渡特性的分类器。通过突破渐进极限的约束，数据集与模型能精确捕捉复杂的衍射诱导振幅调制，确保在 LISA 相关透镜质量范围内保持物理保真度。&lt;/p&gt;&lt;p&gt;其次，研究团队采用直接序列建模方法，充分利用频域振幅谱的完整分辨率。与基于二维图像的方法不同，该研究直接分析白化后的时延干涉测量通道 A 与 E 的应变数据，从而显式保留高频振荡调制特征，为模型识别提供稳健基础。&lt;/p&gt;&lt;p&gt;与传统 LSTM 相比，DCL-xLSTM 引入了基于矩阵的记忆结构和记忆混合机制，能够更好地保留长谱序列中复杂的衍射细节。这一设计增强了模型处理长程依赖关系的能力，同时保持了良好的线性计算复杂度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSw6gEK5VbPribhy2YEhLOVN1rDrp7mlElM4WeMzyX435cIoMoJrQtNYvA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=6" data-ratio="0.6731481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027031" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/74429708-5740-4f0c-9d14-406f8e927301/640.jpeg" alt="图片" data-before-load-time="1767088606801" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;实验评估&lt;/p&gt;&lt;p&gt;为评估 DCL-xLSTM 的分类性能，研究团队构建了包含 16000 个样本的平衡数据集，其中透镜化波形（N=8000）与非透镜化波形（N=8000）数量相等，并将样本划分为两个不同的质量区间，以测试网络在不同衍射条件下的灵敏度：高质量组代表波动光学效应显著的区域，信号畸变清晰可见；低质量组则对应衍射起始阶段，透镜化特征细微且波形偏离程度较低。&lt;/p&gt;&lt;p&gt;透镜效应通过两种标准透镜模型生成：点质量模型与奇异等温球体模型。为模拟真实观测条件，所有信号均经过白化处理，并基于 LISA 噪声模型注入高斯噪声。&lt;/p&gt;&lt;p&gt;DCL-xLSTM 实现了卓越的分类性能，在包括波动光学与几何光学过渡区在内的多种透镜质量与信噪比条件下均保持稳健的灵敏度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSww8jQFjoiapvgticPbiaJA1zO4T8bY6vbm8hPkqiblYqrbSqThjHvnlmoIg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=7" data-ratio="0.4685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027032" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/ccd8116d-a3fa-42ee-972e-3ae18e5d7894/640.jpeg" alt="图片" data-before-load-time="1767088606762" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;DCL-xLSTM 的 AUC（曲线下面积）达到 0.99 以上，在误报率低于 1% 时仍能保持超过 98% 的检出率。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/XLCp9HBkwLlbXtJJViaOFS3eich3fiaQDSwicXPl4P5NHiaibkEInYjdyau41qNuT91ZSr4S4BgVwau96BwrDbsYXqwA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-ratio="0.8870370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="100027033" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/0874bd6e-7e8d-44c7-a2f2-eb7fb95ea2d8/640.jpeg" data-sec-load-status="2" data-report-img-idx="0" alt="图片" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;总的来说，DCL-xLSTM 对信噪比、透镜类型及透镜质量的变化均表现出强稳健性。DCL-xLSTM 有望成为未来空间引力波探测的高效工具。&lt;/p&gt;&lt;p&gt;感兴趣的读者可以阅读论文原文，了解更多研究内容。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>腾讯混元开源翻译模型1.5，端侧可部署，效果超越商用API</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 30 Dec 2025 17:54:27 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-8</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;12月30日，腾讯混元宣布推出并开源翻译模型1.5，共包含两个模型：Tencent-HY-MT1.5-1.8B 和 Tencent-HY-MT1.5-7B，两个模型均支持 33 个语种互译以及5种民汉/方言，除了中文、英语、日语等常见语种，也包含捷克语、马拉地语、爱沙尼亚语、冰岛语等小语种。模型已在腾讯混元官网上线，通过开源社区也可以直接下载使用。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f369f465-36b1-45ba-b4ff-a19b6142ed19/1767088290213.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;HY-MT1.5-1.8B主要面向手机等消费级设备场景，经过量化，可支持端侧直接部署和离线实时翻译，仅需1GB内存即可流畅运行，并且在参数量极小的前提下，效果超过了大部分商用翻译API。模型在效率和性价比也表现突出，与主流商用翻译模型API对比，HY-MT1.5-1.8B 推理速度更快，处理50个tokens的平均耗时只有0.18秒，其他模型的时间在0.4秒左右。&lt;/p&gt;&lt;p&gt;HY-MT1.5-7B 模型效果相比前一版本有较大提升，是此前获得WMT25比赛30个语种翻译冠军模型的升级版，重点提升了翻译准确率，大幅减少了译文中夹带注释和语种混杂的情况，实用性进一步增加。&lt;/p&gt;&lt;p&gt;在部分用户实用场景下，混元翻译1.8B和7B两个尺寸模型同时使用，可以实现端侧和云侧模型的协同部署，提升模型的效果的一致性和稳定性。&lt;/p&gt;&lt;p&gt;在常用的中外互译和英外互译测试集Flores200、WMT25以及民汉语言的测试集中，Tencent-HY-MT1.5-1.8B全面超越中等尺寸开源模型和主流商用翻译API，达到Gemini-3.0-Pro这种超大尺寸闭源模型的90分位水平。在WMT25和民汉翻译测试集上，其效果仅略微差于Gemini-3.0-Pro，远超其他模型。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c8912057-3582-49a6-9600-935deef65312/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c4b2a59a-4c7c-4c48-b2a3-bf93c0c4d51a/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;HY-MT1.5系列模型在翻译质量与响应效率之间达到了出色的平衡。具体而言，HY-MT1.5-1.8B模型在FLORES-200质量评估中取得了约78%的分数，同时平均响应时间仅为0.18秒，超越主流商用翻译API，显示出明显的速度优势，凭借优化的模型设计和推理逻辑，其领先的效率使其高度适用于即时通讯、智能客服、移动翻译应用等高吞吐、实时翻译场景。&lt;/p&gt;&lt;p&gt;实用性是混元翻译模型长期追求的目标，针对各类场景，两个模型均实现了对术语库、长对话、带格式文本（例如网页）的翻译支持，更加全面。&lt;/p&gt;&lt;p&gt;首先是术语，腾讯混元翻译模型1.5具备强大的术语库自定义能力，用户可针对不同行业与专业场景（如医学、法律、金融、科技等）提前构建专属术语对照表，确保关键术语在翻译中保持高度一致与准确性。&lt;/p&gt;&lt;p&gt;这一功能有效弥补了小尺寸模型在处理专业领域文本时的词汇短板，使其在保障轻量化部署的同时，也能胜任高要求的行业翻译任务。用户可通过简单配置导入术语库，模型将在翻译过程中优先采纳用户定义的标准术语，从而提升专业文档、技术手册、合同文本等内容翻译的可靠性与权威性。&lt;/p&gt;&lt;p&gt;其次是上下文翻译。混元翻译模型模型具备先进的长文本与对话上下文理解能力，可基于前文语境持续优化后续翻译结果，显著提升长对话、多轮问答、连续段落等场景下的翻译连贯性与一致性。无论是会议记录、访谈内容、小说章节还是技术文档的长篇翻译，模型均能有效捕捉并保持上下文逻辑关系，避免出现指代不清、语义断裂或风格不统一的问题。该能力尤其适用于实时对话翻译、长篇文献翻译及多轮交互场景，助力用户在跨语言沟通与内容处理中获得更自然、准确的翻译体验。&lt;/p&gt;&lt;p&gt;第三是，带格式翻译能力，通过精准的指令遵循能力，混元翻译模型得以保持翻译前后的格式信息不变，让翻译结果更加准确实用。&lt;/p&gt;&lt;p&gt;为了直观展示混元Tencent-HY-MT1.5-1.8B的翻译能力，下图展示了与苹果手机自带离线翻译的结果对比：&lt;img src="https://image.jiqizhixin.com/uploads/editor/4cf88c69-7ca2-4ef4-afed-588efdfc80e2/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;技术上，HY-MT1.5-1.8B能够用小尺寸实现大尺寸模型的效果，得益于On-Policy Distillation（大尺寸模型蒸馏）策略的引入，让 HY-MT1.5-7B 作为 Teacher，实时引导 1.8B 的 Student 模型，让其避免死记硬背标准答案，通过纠正在预测序列分布时的偏移，让小模型从错误中学习，切实提升能力。&amp;nbsp;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a913bad6-6ebf-4bc1-84b2-6db6897e7b8b/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;腾讯混元翻译模型此前不仅在国际机器翻译比赛拿下30个第1名，也在首次开源一周内便登上了HuggingFace 模型趋势榜第一位。目前，混元翻译模型已经在腾讯内部多个业务场景落地应用，包括腾讯会议、企业微信、QQ浏览器、客服翻译等。此外，为了便于开发者使用，本次开源的模型已经在 Github 和 Huggingface 等开源社区上线，Arm、高通、Intel、沐曦等多个平台均支持部署。&lt;/p&gt;&lt;p&gt;【模型体验链接】&lt;/p&gt;&lt;p&gt;混元官网：https://hunyuan.tencent.com/modelSquare/home/list&lt;/p&gt;&lt;p&gt;github链接：&lt;u&gt;&lt;span class="15"&gt;https://github.com/Tencent-Hunyuan/HY-MT&lt;/span&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;huggingface链接：&lt;a href="https://huggingface.co/collections/tencent/hy-mt15"&gt;&lt;u&gt;https://huggingface.co/collections/tencent/hy-mt15&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>摩根士丹利为何连续押注？这家中国公司正在定义机器人产业的“确定性”新标准</title>
      <description>&lt;![CDATA[机器人产业正站在一次关键拐点前。]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Tue, 30 Dec 2025 16:45:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-29</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-29</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;机器人产业正站在一次关键拐点前。&lt;/p&gt;&lt;p&gt;在这样一个时间窗口里，顶级投行的判断，往往比热闹的发布更具参考意义。每一份重量级研究报告，其实都在提前描绘未来几年产业格局的轮廓。&lt;/p&gt;&lt;p&gt;2025年，摩根士丹利（Morgan Stanley）在先后发布的两份机器人产业深度报告中，罕见地连续两次重点聚焦同一家中国公司——智平方（AI² Robotics）。&lt;/p&gt;&lt;p&gt;一次，是将其列为定义行业底座的基础大模型代表；&lt;/p&gt;&lt;p&gt;另一次，则将其视为机器人商业化落地的标杆案例。&lt;/p&gt;&lt;p&gt;在大摩的研究体系中，这种“技术 + 落地”的双重定位并不常见。它所指向的，是一种在机器人行业里尤为稀缺的能力：技术领先与商业验证同时成立的确定性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型站位：不是“跟随硅谷路线”，而是全球 VLA&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;路线的定义者之一&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在&amp;nbsp;2025&amp;nbsp;年&amp;nbsp;12&amp;nbsp;月&amp;nbsp;5&amp;nbsp;日发布的最新报告《The Robot Almanac Vol.1: AI Gets Physical; Cambrian Explosion of Bots》中，摩根士丹利对全球机器人产业格局给出了明确判断：&lt;/p&gt;&lt;p&gt;中国已经在机器人与具身智能领域建立起领先优势，并且这一优势仍在持续扩大。&lt;/p&gt;&lt;p&gt;在这份定调行业走向的报告中，大摩关注的并不是“谁更会做机器人”，而是谁在构建下一代机器人的智能底座。&lt;/p&gt;&lt;p&gt;也正是在这一层，智平方与&amp;nbsp;Figure AI、Physical Intelligence&amp;nbsp;等公司一起，被列为全球机器人基础大模型（Foundation Model）的关键厂商。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/ed520dbf-6285-4b33-b691-3b9aae5a1cf3/1767149023021.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这意味着，大摩看重的不是单一产品能力，而是其在底层智能架构上的长期价值。&lt;/p&gt;&lt;p&gt;智平方是全球最早专注端到端 VLA 路线的创业公司之一。&lt;/p&gt;&lt;p&gt;与将感知、规划、控制拆分处理的传统路径不同，智平方从一开始就尝试在一个统一模型中，同时解决三个问题：空间理解、全身控制，以及长程任务推理。&lt;/p&gt;&lt;p&gt;其原创的全域全身具身大模型 GOVLA，并非只生成机械臂动作，而是首次实现了移动轨迹与全身控制的统一输出，让机器人能够在复杂真实环境中连续行动。&lt;/p&gt;&lt;p&gt;这一能力，使机器人不再只是“执行单个动作”，而是真正具备了完成完整任务的基础。&lt;/p&gt;&lt;p&gt;事实上，在具身基础大模型层面，智平方已多次走在国际同行之前。&lt;/p&gt;&lt;p&gt;从&amp;nbsp;2024&amp;nbsp;年&amp;nbsp;6&amp;nbsp;月率先发表&amp;nbsp;VLA&amp;nbsp;研究成果、引入&amp;nbsp;Mamba&amp;nbsp;架构推出&amp;nbsp;RoboMamba（GOVLA 0.0），到后续发布全球首个快慢系统深度融合的&amp;nbsp;FiS-VLA&amp;nbsp;模型（GOVLA 0.5），其性能相较国际标杆模型 π0&amp;nbsp;提升约&amp;nbsp;30%。在前面两个开源版本基础之上，目前，智平方已研发出更为强大的&amp;nbsp;GOVLA 1.0&amp;nbsp;版本。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/664def19-7098-4754-b883-40643269c479/1767149042695.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;这一系列成果，让智平方率先成为全球唯二、国内唯一实现开源的机器人模型创业公司，并获得图灵奖得主 Yann LeCun 的公开关注。&lt;/p&gt;&lt;p&gt;不难发现，在多个关键节点上，智平方并非简单跟随，而是直接参与了路线的形成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;商业验证：千台级订单，成为行业的分水岭&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;仅有技术突破，并不足以支撑机器人行业真正向前。&lt;/p&gt;&lt;p&gt;真正的考验在于：这些能力，能否转化为可交付、可复制的商业成果。&lt;/p&gt;&lt;p&gt;在 2025 年 9 月发布的《Humanoid Horizons: Closer to the Real World》中，摩根士丹利就已经将智平方视为真实商业落地的代表性公司。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f032027a-ffe6-4e26-8af7-2a12e5550c65/1767149059285.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;报告中特别提到的，是智平方与全球第三大面板厂惠科（HKC） 的合作——一笔 5 亿元人民币、超千台机器人的订单。&lt;/p&gt;&lt;p&gt;这不仅是当时中国人形机器人领域金额最大的一笔订单，也被大摩视为判断“机器人时代正在加速到来”的关键证据。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/9da3f5b3-954d-4210-8f35-d766fc895c74/1767149077547.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;与行业中常见的试点或展示不同，这笔订单具备明确的交付计划、明确的交付场景、明确的客户。&lt;/p&gt;&lt;p&gt;智平方的通用智能机器人 AlphaBot 2，已直接嵌入惠科的真实生产流程，并进入规模化部署阶段。&lt;/p&gt;&lt;p&gt;这一案例向市场释放出一个清晰信号：具身大模型驱动的通用机器人，已经具备产业化交付的现实基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“模型&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;×&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;硬件&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;×&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;场景”：跑通闭环，才是稀缺能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;智平方的价值，并不只体现在技术或订单本身。&lt;/p&gt;&lt;p&gt;更重要的是，它率先跑通了“模型 × 硬件 × 场景”的完整闭环。&lt;/p&gt;&lt;p&gt;在多个国际舞台上，智平方创始人兼 CEO 郭彦东博士反复强调：通用智能机器人的真正突破，来自“模型 × 硬件 × 场景”三位一体的系统能力，而非单点创新。&lt;/p&gt;&lt;p&gt;“Without AI, it’s just metal. Without hardware, it’s just code. Without scenarios, it’s just a demo.” 郭彦东博士这句话直指行业现实，也对应着智平方“仰望星空，脚踏实地”的实践路径。&lt;/p&gt;&lt;p&gt;在模型侧，智平方通过自研&amp;nbsp;GOVLA&amp;nbsp;大模型，为机器人提供理解物理世界和泛化操作能力的“通用大脑”；在硬件侧，智平方坚持面向量产的硬件设计，AlphaBot&amp;nbsp;系列具备&amp;nbsp;5&amp;nbsp;万小时无故障运行的工业级可靠性，自有产线已于&amp;nbsp;2025&amp;nbsp;年&amp;nbsp;9&amp;nbsp;月投产，具备千台年产能，并将在&amp;nbsp;2026&amp;nbsp;年扩展至万台规模；在场景侧，智平方选择具有技术复利的商业路径，在半导体制造、汽车制造、公共服务、新零售等真实场景中持续运行。&lt;/p&gt;&lt;p&gt;这三种能力并非孤立存在。&lt;/p&gt;&lt;p&gt;真实场景不断产生数据，反向优化模型；模型能力提升，又支持机器人进入更复杂的场景；&lt;/p&gt;&lt;p&gt;可靠的硬件，则确保这一循环可以被规模化复制。&lt;/p&gt;&lt;p&gt;正是这一完整闭环，解释了摩根士丹利为何在两份侧重点不同的报告中，最终都指向同一家公司。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;被连续引用，本质是对“确定性”的年终判断&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;站在&amp;nbsp;2025&amp;nbsp;年的终点回看，机器人产业的关键词，正在从“可能性”转向“确定性”。&lt;/p&gt;&lt;p&gt;在产业爆发前夜，资本用报告投票，投的从来不是概念，而是确定性。&lt;/p&gt;&lt;p&gt;在大摩的评估体系中，智平方同时具备技术路线的确定性与商业路径的确定性。&lt;/p&gt;&lt;p&gt;当机器人产业从“演示可行”迈向“商业可用”，决定最终格局的，不再是谁的故事更动听，而是谁已经把智能，稳定地带进了现实世界。&lt;/p&gt;&lt;p&gt;智平方被连续点名，并非偶然。&lt;/p&gt;&lt;p&gt;它所代表的，是一个在 2025 年已经逐渐清晰的判断：&lt;/p&gt;&lt;p&gt;中国具身智能企业，正在进入全球核心竞争区，并开始参与定义下一阶段的行业标准。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>吴恩达年终总结：2025是AI工业时代的黎明</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 30 Dec 2025 15:17:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-7</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/dd6edcfb-d9fc-41ef-b7a1-bde98860ed18/1767078789691.png" style="width: 700%;" class="fr-fic fr-dib"&gt;2025 年已经走到了尾声。&lt;/p&gt;&lt;p&gt;关注 AI 圈的读者们都知道，今年是各路 AI 巨头神仙打架的一年，是人才大战架构重组极其频繁的一年，是大模型军备竞赛出奇白热化的一年，也是 AI 基础设施建设如火如荼的一年&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;在这精彩绝伦的一年的结尾，我们的老朋友：斯坦福大学计算机科学客座教授，前百度 AI 负责人，前谷歌大脑负责人吴恩达老师，发表了今年的保留节目：一封信，和一篇 2025 的人工智能领域年度总结。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibegficwaHaFAZBnHv4Mic6OzEjGCOA171I4l2IQAjogKl42rIu1ZQSEyfA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.937037037037037" data-type="png" data-w="1080" data-width="1172" data-height="1098" data-imgfileid="503526044" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/1cf3e875-a2a7-475b-a5cd-16f9e5ae571e/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;年末寄语：三把金钥匙&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;元旦假期将至，学生们美妙的寒假以及春节假期也近在眼前。「永远不要停止学习」是假期前的老生常谈，尤其是希望在蓬勃进化的，高度竞争的人工智能领域内谋求发展机会的人。应当做什么，怎么做，吴恩达在今年的信中给出了他的见地。&lt;/p&gt;&lt;p&gt;以下是公开信全文：&lt;/p&gt;&lt;blockquote&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;亲爱的朋友们：&lt;/p&gt;&lt;p&gt;又一年，AI 以惊人的速度向前推进，为所有人 &amp;mdash;&amp;mdash; 包括刚进入这个领域的新手 &amp;mdash;&amp;mdash; 创造了前所未有的软件开发机会。事实上，许多公司现在最大的困扰之一，就是找不到足够多真正懂 AI 的工程师。&lt;/p&gt;&lt;p&gt;每年冬季假期，我都会留出一段时间来学习和动手构建项目，希望你们也能如此。这不仅能帮助我打磨已有技能、掌握新知识，也能实实在在地推动你的技术职业发展。&lt;/p&gt;&lt;p&gt;要真正具备构建 AI 系统的能力，我建议你做到三点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;系统地学习 AI 课程&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;持续动手构建 AI 系统&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;（可选）阅读研究论文&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我解释为什么这三点都如此重要。&lt;/p&gt;&lt;p&gt;我常听到一些开发者建议别人：「别学了，直接上手做就行。」这是非常糟糕的建议！除非你已经身处一个经验丰富的 AI 开发者社群中，否则在没有理解 AI 基础的情况下贸然动手，很容易导致你重复发明轮子，或者更糟糕的是，把轮子重新发明得一团糟。&lt;/p&gt;&lt;p&gt;举个例子，在面试中，我见过不少候选人：自己重新发明了一套标准的 RAG 文档切分策略；重复实现了已经成熟的 Agentic AI 评估方法；写出了结构混乱、难以维护的 LLM 上下文管理代码。如果他们提前上过几门相关课程，就会更清楚哪些「积木」已经存在于行业中。他们当然仍然可以选择从零实现这些模块，甚至发明出比现有方案更好的方法，但至少能避免浪费数周时间走弯路。&lt;/p&gt;&lt;p&gt;因此，结构化学习至关重要。&lt;/p&gt;&lt;p&gt;而且说实话，我个人觉得上课非常有趣。与其看 Netflix，我更愿意随时打开一门优秀 AI 讲师的课程来学习。&lt;/p&gt;&lt;p&gt;同时，仅仅上课是不够的。有许多重要的经验，只有通过亲手实践才能真正学到。学习飞机是如何运作的理论，对于成为一名飞行员当然非常重要，但从来没有人只靠上课就学会开飞机。在某个时刻，真正坐进驾驶舱是不可或缺的！好消息是：随着高度智能化（highly agentic）的编程助手出现，动手构建的门槛已经比以往任何时候都低。而当你开始学习 AI 的各种构建模块时，它们常常会激发你对「还能做些什么」的新想法。如果我一时找不到项目灵感，我通常会去上几门课，或者读一些研究论文。这样坚持一段时间后，我总会冒出一大堆新的项目想法。而且，说实话，我觉得「做东西」本身真的很有趣，也希望你能体会到这种乐趣！&lt;/p&gt;&lt;p&gt;最后，并不是每个人都必须这样做，但我发现如今就业市场上最强的一批候选人，几乎都会偶尔阅读研究论文。虽然在我看来，论文比课程难啃得多，但它们包含了大量尚未被翻译成更易理解形式的前沿知识。我会把读论文的优先级排在课程和实践之后，但如果你有机会提升阅读论文的能力，我仍然强烈建议你这样做。（你也可以看看我以前讲过的一段关于如何读论文的视频。）上课和动手构建对我来说很有趣，读论文则更像是一种「磨练」，但从论文中偶尔闪现的洞见，真的令人愉悦。&lt;/p&gt;&lt;p&gt;祝你度过一个美好的寒假，新年快乐。除了学习和创造，也希望你能多花时间陪伴亲人 &amp;mdash;&amp;mdash; 那同样非常重要！&lt;/p&gt;&lt;p&gt;Love，&lt;/p&gt;&lt;p&gt;Andrew&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;年终总结：AI工业时代的黎明&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2025年着实是精彩绝伦的一年。&lt;/p&gt;&lt;p&gt;作为每年的保留节目，吴恩达的年终总结都能带我们回顾全年最重要的人工智能事件和发展趋势。&lt;/p&gt;&lt;p&gt;2022年，是AI 的璀璨之年，生成文本、图像、视频、音乐和代码的系统即将到来，引发了关于创造力的未来问题的讨论。&lt;/p&gt;&lt;p&gt;2023年，是创新与焦虑的一年，生成式 AI 浪潮席卷了各行各业，其不断扩大的能力引发了智能机器可能会使人类过时的担忧。&lt;/p&gt;&lt;p&gt;2024年，是暴风雪般进步的一年，人工智能取得了突破性进展。智能代理系统提升了推理、使用工具和控制桌面应用程序的能力。小型模型迅速普及，其中许多比其前辈更强大且价格更低廉。&lt;/p&gt;&lt;p&gt;2025年，或将被铭记为 &lt;strong&gt;AI 工业时代的黎明。&lt;/strong&gt;让我们跟随吴恩达的视角，探索2025年最具代表性的AI大事。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6miberUOEHZPGSRyW20DLuXleIgwMlrhR8t2ggw87pFmWcIT8hXOb0CwKQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.6814814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526068" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2d1114c2-2934-425f-9964-c01d52546612/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;文章链接：https://www.deeplearning.ai/the-batch/issue-333/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;思考型模型解决更大的问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;去年年末，OpenAI 推出了首个推理模型 o1，将一种具备代理能力的推理工作流内嵌其中。今年 1 月，DeepSeek-R1 向世界展示了如何构建这种能力。结果是：数学与编程性能立刻提升，问题回答更准确，机器人能力更强，AI 智能体取得快速进展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibe4DmdkvNQ7qFMjdW1ngh2dPu73ef6ZuNeFOTf9vOhYyeqrNEaUiaibbIg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-type="jpeg" data-w="1080" data-width="1200" data-height="676" data-imgfileid="503526064" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/111d44b9-f69e-4b7b-9a4b-ff91aa7d3498/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 2025 年初，模型只有在被明确提示时才会执行推理策略。如今，大多数新的大语言模型都会默认这样做，从而在广泛任务上显著提升了性能。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;最早的一批推理模型&lt;strong&gt;通过 RL 训练&lt;/strong&gt;，专门用于正确求解数学问题、准确回答科学问题，生成能通过单元测试的代码。例如，o1-preview 在 AIME 2024 上比其非推理前身 GPT-4o 高出 43 个百分点，在 GPQA Diamond上高出 22 个百分点；在 Codeforces 编程题中，其表现位于人类竞技选手的 第 62 百分位，而 GPT-4o 仅为 第 11 百分位。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当推理模型&lt;strong&gt;学会使用诸如计算器、搜索引擎或 bash 终端等工具&lt;/strong&gt;时，表现会进一步提升。例如，在一项涵盖 100 个领域、考察多模态理解与技术专长的高难度测试中，带工具的 OpenAI o4-mini 达到 17.7% 的准确率，比不使用工具时高出 3 个多百分点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;机器人动作模型&lt;/strong&gt;也通过 RL 学会推理。例如，通过奖励 ThinkAct 达成目标位置，使其在机器人任务上的表现相较于不具备思考能力的模型（如 OpenVLA）提升了约 8%。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;推理模型还帮助智能体&lt;strong&gt;应对复杂问题&lt;/strong&gt;。例如，AlphaEvolve 使用 Google Gemini 反复生成、评估并修改代码，最终为现实世界问题产出了更快的算法。其中一个成果是，它提出了一个用于解释微生物耐药性的长期未解问题的假说；人类科学家几乎在同一时间独立提出并验证了相同假说。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推理能力显著提升了 LLM 的性能，但更优输出也伴随着成本。Gemini 3 Flash 在开启推理时运行 Artificial Analysis 的 Intelligence Index 基准共消耗 1.6 亿 tokens（得分 71），而关闭推理仅消耗 740 万 tokens（得分明显更低，为 55）。此外，生成推理 tokens 会延迟输出，这也给 LLM 推理服务商带来了更大的性能压力。不过，研究人员正在努力提高效率。Claude Opus 4.5 与 GPT-5.1 在高推理设置下取得了相同的 Intelligence Index 分数，但前者消耗 4800 万 tokens，后者则消耗 8100 万 tokens。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;巨额薪酬吸引顶尖 AI 人才&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;领先的 AI 公司展开了一场激烈的人才争夺战，用堪比职业体育明星级别的薪酬，从竞争对手那里挖走顶尖人才。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 月，Meta 发起大规模招聘&lt;/strong&gt;，为新成立的 Meta Superintelligence Labs 组建团队，向来自 OpenAI、Google、Anthropic 等顶级 AI 公司的研究人员开出高达数亿美元的待遇。作为回应，Meta 的竞争对手反过来从 Meta 及彼此之间挖走关键员工，使 AI 人才的市场价值被推至前所未有的高度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeTbUsgUuic9pgty58iatEIQv8JGia1VKQmt0VFoRHZia4mY3iaf9FsRsqdZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1200" data-height="676" data-imgfileid="503526066" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/771831a0-1a79-4592-bee4-b636197977ec/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;据《华尔街日报》报道，在成功招募 Alexandr Wang 及其核心团队成员之后，Meta 首席执行官 Mark Zuckerberg 列出了一份「心愿清单」。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;为了说服人们跳槽，Zuckerberg 甚至亲自登门拜访，有时还会带上自制的汤。这项努力成功招募了包括 OpenAI 的 Jason Wei 和 Hyung Won Chung 在内的人才，两人均为推理模型的核心研究者。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;《华尔街日报》称，曾与 OpenAI 前 CTO Mira Murati 共同创立 Thinking Machines Lab 的 Andrew Tulloch，最初拒绝了 Meta 提出的方案，其中包括价值 15 亿美元 的奖金。几个月后，他改变主意，加入了 Meta。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Meta 还聘请了曾主管 Apple AI 模型的 Ruoming Pang。据彭博社报道，其薪酬方案在数年内累计高达数亿美元。Meta 的报价超过了 Apple 除 CEO 之外最高层管理者的薪酬，而 Apple 选择不予匹配。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在这场人员流动中，Microsoft AI CEO Mustafa Suleyman 从 Google 带走了 20 多名研究人员和工程师，其中包括工程副总裁 Amar Subramanya。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Elon Musk 的 xAI 从 Meta 挖走了十多名 AI 研究人员和工程师。Musk 抨击竞争对手的报价「疯狂」，并强调自己公司「极端以能力为导向」的文化，以及股权更具增长潜力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;随着 2026 年的到来，AI 招聘格局已发生巨大变化。据《华尔街日报》报道，为了抵御猎头挖角，OpenAI 提供了比竞争对手更高比例的股票型薪酬，加快了新员工期权的归属进度，并发放高达 150 万美元 的留任奖金。&lt;/p&gt;&lt;p&gt;尽管 2025 年出现了关于 AI 泡沫的讨论，但对于计划投入数百亿美元建设 AI 数据中心的公司来说，高薪是完全理性的选择：&lt;strong&gt;如果你愿意在硬件上花这么多钱，为什么不拿出其中一小部分用于支付人才薪酬呢？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据中心建设狂潮席卷全球&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;头部 AI 公司纷纷宣布了庞大的建设计划，预计在未来几年内将豪掷数万亿美元，并消耗数吉瓦（GW）的电力。&lt;/p&gt;&lt;p&gt;仅今年一年，AI 行业的资本支出就突破了 3000 亿美元，其中大部分用于建设处理 AI 任务的新数据中心。这还仅仅是「前菜」，各大公司正在规划堪称宏伟的蓝图&amp;mdash;&amp;mdash;建设规模堪比小镇、能耗相当于中型城市的设施。据麦肯锡预测，为了建设足够的算力以满足预期的推理和训练需求，&lt;strong&gt;这场竞赛的成本到 2030 年可能高达 5.2 万亿美元&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9EricQXXByphb4tN0ha6mibevbpzMibI2ITAiajH1DVIhVnIfbqMEvwPiaIFZ62zlFWcaUAeNK4nzda2w/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=5" data-ratio="0.562962962962963" data-type="jpeg" data-w="1080" data-width="1200" data-height="676" data-imgfileid="503526065" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/351b599e-3e02-468f-a2c8-a4998e0b5595/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;： 1 月，OpenAI 启动了与甲骨文（Oracle）、软银（SoftBank）及阿联酋投资公司 MGX 合作的 5000 亿美元「星际之门」（Stargate）项目。公司最终宣布计划在全球建设 20 吉瓦的数据中心产能，并预测需求量将是该数字的 5 倍。OpenAI CEO 萨姆&amp;middot;奥特曼表示，希望最终能实现每周增加 1 吉瓦的产能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Meta&lt;/strong&gt;： 2025 年在基础设施项目上投入约 720 亿美元，高管表示该数字在 2026 年还将大幅上升。其 Hyperion 项目包括在路易斯安那州农村地区建设一个价值 270 亿美元、容量为 5 吉瓦的数据中心。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;微软&lt;/strong&gt;： 2025 年全球数据中心项目支出达 800 亿美元，其中包括位于威斯康星州和亚特兰大的设施，它们将通过专用光纤网络连接，作为一个巨大的超级计算机运行。公司还承诺将其在欧洲的云和 AI 产能扩展至 200 个数据中心。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;亚马逊&lt;/strong&gt;： 预计 2025 年基础设施支出将达 1250 亿美元，2026 年还将投入更多。其耗资 110 亿美元的「雷尼尔计划」（Project Rainier）是位于印第安纳州的一个 2.2 吉瓦数据中心，将运行 50 万块 Amazon Trainium 2 芯片。此外，亚马逊计划在 2025 年至 2029 年间斥资约 140 亿美元扩建澳大利亚的数据中心，并在德国投资约 210 亿美元。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Alphabet&lt;/strong&gt;（谷歌母公司）： 预计 2025 年基础设施支出高达 930 亿美元，高于此前预测的 750 亿美元。公司宣布了一项 400 亿美元的计划，到 2027 年在得克萨斯州增加 3 个数据中心。此外，还承诺在印度投入 150 亿美元，在德国宣布了约 60 亿美元的投资，并在澳大利亚、马来西亚和乌拉圭推出了新建或扩建项目。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;尽管存在对 AI 泡沫的担忧，但基础设施建设热潮正在为原本不温不火的&lt;strong&gt;经济带来实实在在的增长&lt;/strong&gt;。哈佛大学经济学家 Jason Furman 指出，2025 年上半年美国GDP的增长几乎全部来自数据中心和 AI 领域的投资。在此阶段，有证据支持这样一种观点：2025 年拉开了新工业时代的序幕。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体让代码编写更高效&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;编程已成为智能体工作流中具有最直接商业价值的应用场景。Claude Code、Google Gemini CLI、OpenAI Codex 以及其他应用，将「编程智能体」变成了 AI 巨头之间竞争最激烈的战场之一。为了留在牌桌上，规模较小的竞争对手也纷纷开发了自己的智能体模型。&lt;/p&gt;&lt;p&gt;当 2024 年首个开创性的智能体代码生成器 Devin 问世时，它将 SWE-Bench 编程挑战基准测试的最高水平（SOTA）从 1.96% 提升到了 13.86%。到了 2025 年，使用最新大语言模型的编程智能体已能常态化地完成超过 80% 的同类任务。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeK35E9SglyUDicxicliaUEeJpU21k20uVZNP8JZdBtPaqlT3JFd3TcO98g/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1200" data-height="676" data-imgfileid="503526067" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9c24f9e5-469e-4157-978a-877189a67228/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2024 年底，推理模型的出现立即提升了编程能力并降低了成本，因为推理能力使智能体能够规划任务，并将具体执行交给成本更低的模型去完成。到 2025 年底，Gemini 3 Pro、Claude Opus 4.5 和 GPT-5.2 已成为编程和智能体工作流领域的顶尖模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Z.ai 的 GLM-4.5 和月之暗面的 Kimi K2 成为开放权重模型中的热门选择，使自动编程类初创公司得以大幅削减成本。7 月发布的 Qwen3-Coder 提供了一个庞大的 4800 亿参数模型，该模型在超过 5 万亿 Token 的代码数据上进行了训练，性能几近匹敌 Claude Sonnet 4。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Anthropic 围绕 Claude 构建了一套智能体框架，打造出了 Claude Code 应用。该应用在 2 月一经推出便大受欢迎，确立了智能体编程系统应有的标准。OpenAI 随即做出回应，推出了基于其 GPT-5 系列编程专用版构建的 Codex 应用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型制造商与集成开发环境（IDE）开发者之间展开了一场拉锯战。这导致 Anysphere (Cursor) 和 Cognition AI (Windsurf) 等热门 IDE 提供商开始构建自己的模型。反之，Google 也构建了自己的 IDE&amp;mdash;&amp;mdash;Antigravity，并于 11 月首次亮相。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;智能体系统不断推高 SWE-Bench 这一热门编程基准测试的上限，促使研究人员寻找替代的方式来评估其性能。这些努力催生了 SWE-Bench Verified、SWE-Bench Pro、LiveBench、Terminal-Bench、𝜏-Bench 和 CodeClash 等新基准。&lt;/p&gt;&lt;p&gt;2025 年初，大多数观察家还认为智能体仅擅长生成常规代码、文档和单元测试，而在处理更高阶的战略性问题上，资深人类工程师和产品经理的表现依然更胜一筹。但到了年底，许多公司报告称已开始自动化资深级别的任务。Microsoft、Google、Amazon 和 Anthropic 均表示，他们自身&lt;strong&gt;越来越多的代码正由 AI 生成&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;更多细节，请参阅年度总结原文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语：去亲手构建未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回望 2025，我们似乎见证了一场关于「规模」的游戏。&lt;/p&gt;&lt;p&gt;在这一年，AI 终于脱离了单纯的算法竞赛，演变成一场涉及人才、算力、基建和能源的工业革命。从超大规模数据中心到能耗巨大的算力集群，科技巨头们正以前所未有的资源投入，加速实现通往 AGI 的技术跨越。&lt;/p&gt;&lt;p&gt;这种宏大的叙事往往让人感到渺小，甚至焦虑。当 AI 的进化速度以「天」为单位，当顶尖人才的薪酬变成天文数字，普通开发者和从业者的位置在哪里？吴恩达给出了答案。&lt;/p&gt;&lt;p&gt;虽然 &lt;strong&gt;2025 是 AI 变得最「重」的一年，但它也是 AI 开发变得最「轻」的一年&lt;/strong&gt;。推理模型的成熟和编程智能体的进化，极大地拉低了创造的门槛。正如吴恩达所言，现在是软件开发前所未有的黄金时代。巨头们负责铺设电网和铁路（基础设施），而每一位开发者、学生、研究者，则拥有了在这些轨道上建造飞船的权利。&lt;/p&gt;&lt;p&gt;最好的预测未来的方式，就是去亲手构建它。&lt;/p&gt;&lt;p&gt;祝你在即将到来的 2026 年，保持好奇，永远不要停止学习。&lt;/p&gt;&lt;p&gt;新年快乐！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>自回归因果注意力也能并行解码？上交联合UCSD突破LLM推理瓶颈，模型代码全开源</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Tue, 30 Dec 2025 15:10:36 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2025-12-30-6</link>
      <guid>https://www.jiqizhixin.com/articles/2025-12-30-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/950e0739-dcba-4de5-bf65-72c7b5ec349e/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在大语言模型（LLM）落地应用中，推理速度始终是制约效率的核心瓶颈。传统自回归（AR）解码虽能保证生成质量，却需逐 token 串行计算，速度极为缓慢；扩散型 LLM（dLLMs）虽支持并行解码，却面临训练成本高昂、质量下降及 KV 缓存兼容问题；投机解码（Speculative Decoding）则需额外引入草稿模型，系统复杂度大增。&amp;nbsp;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrPFgn1c6YEDBjYRWficeD0ZJdASXdsMaSpccIrlmlws6XERJ1akAlI0w/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-ratio="0.6617238183503243" data-s="300,640" data-type="gif" data-w="1079" type="block" data-imgfileid="503525749" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/05af4054-d57f-47f5-b758-5d9f1674056c/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-imgfileid="503525756" data-ratio="0.6617238183503243" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrNfKxdJMbVLpS0rqjvOib6ymQUHvz84HutAV9dm3otfYOMjqVVpIxjiag/640?wx_fmt=gif&amp;from=appmsg#imgIndex=2" data-type="gif" data-w="1079" type="block" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1d796c54-f8da-4ea8-affc-0e356a47e878/640.gif" data-order="1" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Jacobi Forcing Model 与 AR LLM 推理速度对比示意&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;近期，来自 UCSD Hao AI Lab 和上海交大 Deng Lab 的团队提出了一种突破性解决方案 &amp;mdash;&amp;mdash;Jacobi Forcing，该方案无需重构模型架构，即可将标准 AR 模型转化为原生因果并行解码器，在编码、数学等任务中实现最高 4 倍 wall-clock 提速和 4.5 倍 tokens-per-forward 提升，同时保持接近 AR 模型的生成质量，为 LLM 高效推理开辟了新路径。&lt;/p&gt;&lt;section&gt;&lt;img data-imgfileid="503525757" data-ratio="0.28425925925925927" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr3icibve6ibdSqcbUO94zVGzlDkaBBrsv8V1QUaMpq1EFsRRwqA76jRicPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/fab8be93-2d13-487e-99ae-b2aef243a409/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址: https://arxiv.org/pdf/2512.14681&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/hao-ai-lab/JacobiForcing&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型仓库：http://huggingface.co/JacobiForcing&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Jacobi Forcing 核心优势：破解并行解码的 &amp;quot;三元悖论&amp;quot;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jacobi Forcing 的创新之处在于打破了 &amp;quot;低代价、高速度、高质量&amp;quot; 的不可能三角，其核心优势体现在三大维度：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 原生因果架构，部署与训练成本低:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同于 dLLMs 的双向注意力机制，Jacobi Forcing 保留了 AR 模型的因果注意力结构，完美适配现有 KV 缓存复用机制和 AR 优化内核，可作为现有 AR 模型的 &amp;quot;即插即用&amp;quot; 替代方案，极大降低部署与训练成本。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 高效并行解码，速度提升显著：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过在模型自己生成的 Jacobi 解码轨迹做渐进蒸馏训练，模型能够快速在每轮前向传播中并行更新多个 token。结合多块并行解码（Multiblock decoding）和拒绝回收（Rejection recycling）策略，可同时维护多个解码块，缓存高质量 n-gram 片段重复利用，在编码任务中实现 181.8 TPS 的生成速度，远超 AR 基线的 39.8 TPS。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 质量损失极小，任务表现优异：&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对 AR 到扩散模型的预训练 - 后训练目标不匹配问题，Jacobi Forcing 设计了使用模型自己生成的数据做学习，通过渐进式一致性蒸馏损失和 AR 损失的联合优化，让模型在噪声环境下仍能生成贴近 AR 分布的高质量结果，学习高效且保持了 AR 模型的高质量特性。在 HumanEval 编码基准中，以 83.5% 的准确率实现 4 倍提速；在 GSM8K 数学任务中，91.4% 的解题率接近 AR 基线，速度提升 3.7 倍。&lt;/p&gt;&lt;section&gt;&lt;img data-imgfileid="503525763" data-ratio="0.7724137931034483" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrEO2TIsfCuXwSDiblCyIaeMciciaiay71ico66bOIgaorJuEaHvuXcqIOpzg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="870" type="block" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e27e478e-723b-437f-a271-e5b98af33cb7/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Jacobi Forcing 与 dllm 在速度，质量与训练成本上的对比图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Jacobi Forcing 技术路线：从训练到推理的全链路优化&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jacobi Forcing 以因果并行解码为核心目标，基于 Jacobi 解码框架进行深度优化，通过训练机制创新与推理策略升级的全链路设计，在保留 AR 模型因果骨干与 KV 缓存兼容性的同时，实现高效并行解码。&lt;/p&gt;&lt;p&gt;其技术路线具体细节如下：&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 技术基础：基于 Jacobi 解码的因果并行框架&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jacobi 解码是一种因果并行解码过程，核心逻辑是：在保留 AR 模型因果注意力机制的前提下，对一个块内的所有 token 进行并行迭代更新，直到所有 token 与贪心 AR 输出完全匹配（即达到 &amp;ldquo;定点&amp;rdquo; 状态）。这一过程形成了一条 &amp;ldquo;并行精炼轨迹&amp;rdquo;，既维持了因果依赖关系，又突破了逐 token 串行的限制。 此前的相关工作（如 CLLMs）已验证：通过在 Jacobi 轨迹上微调模型，可缩短迭代轨迹、提升解码速度，但存在一个关键局限：在大 block size 下由于上文噪声过多无法并行解码出更多的 token 数。Jacobi Forcing 在此基础上进一步推进，核心突破是：训练模型在含噪声的上文下，仍能生成贴近 AR 分布的高质量草稿，同时通过推理策略优化，最大化并行效率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 训练阶段优化：噪声感知的渐进式学习&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jacobi Forcing 首先利用自回归语言模型对提示词（prompt）集合执行 Jacobi 解码，采集从噪声块到干净定点的完整 Jacobi 解码轨迹。为使模型具备应对高噪声上文场景下的并行解码能力，Jacobi Forcing 设计渐进式噪声调度策略，以学习噪声块到干净定点的映射关系：具体而言，先为采集轨迹中的中间未收敛噪声块赋予噪声等级（噪声等级越高，与干净定点状态的偏差越大），再按 &amp;ldquo;低噪声&amp;rarr;高噪声&amp;rdquo; 的渐进式顺序对噪声块进行打包，构建训练序列，从而提升去噪任务的可学习性；其核心训练目标为将打包后的含噪声训练序列映射至全干净定点序列。为实现高效训练，Jacobi Forcing 进一步设计噪声感知注意力掩码，该掩码支持通过单次模型前向传播即可完成上述映射关系的学习。此外，为平衡并行解码效率与自回归（AR）生成质量，方案设计了加权双项联合损失函数：其一为渐进式一致性蒸馏损失，用于引导模型掌握任意噪声等级块到干净定点块的映射；其二为 AR 损失，确保模型生成质量与原始自回归模型保持一致。&lt;/p&gt;&lt;section&gt;&lt;img data-imgfileid="503525943" data-ratio="0.562962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvriawv7LPyFq9hDHH3IK7ibT2K6QqfaFCkmnk5H6HdmW9FxuRMTtoHicrsg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=5" data-type="gif" data-w="1080" type="block" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/7869da7d-d48d-4295-934d-9cdc170ef7a9/640.gif" data-order="2" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 训练数据打包与噪声感知注意力掩码图解&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 推理阶段优化：高效并行解码策略&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;训练后的 Jacobi Forcing 模型仍是标准 AR checkpoint，但通过针对性的推理策略，可最大化并行解码效率，核心包括 &amp;ldquo;高质量草稿利用 + 多块调度&amp;rdquo; 两大模块。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 高质量草稿挖掘与复用&lt;/strong&gt;：训练后模型的 Jacobi 解码轨迹呈现显著特性：轨迹中未收敛点包含大量高质量 n-gram，这些 n-gram 虽可能位置暂错，但内容与最终 AR 定点输出完全一致，且在迭代中保持稳定。基于此特性，推理时会缓存 n-gram 并在后续迭代中直接将这些缓存的 n-gram 作为候选草稿，减少迭代次数（见下图轨迹可视化：红色标注为可复用的高质量 n-gram）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrKahfnASg5XTln7RsOJf41uudvHiaOr9Xxx9WX5KKL1ibRBJr7tUMeLYQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.16203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503525766" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/191454b1-473c-41f7-917d-93baf157ba9d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 高质量草稿复用图解&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 多块并行调度&lt;/strong&gt;： 同时维护 K 个块（实验中 K=2 为最优），分为 &amp;ldquo;真实活跃块&amp;rdquo; 和 &amp;ldquo;伪活跃块&amp;rdquo;； 真实活跃块中的 token 会被验证并提交到 KV 缓存，成为后续块的因果前缀；伪活跃块会基于当前前缀进行 Jacobi 迭代更新，但暂不提交到 KV 缓存； 当真实活跃块收敛（所有 token 匹配定点），从伪活跃块中选择一个晋升为真实活跃块，基于更新后的完整前缀重新验证其所有 token。&lt;br&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvr9EvviaGOxk3AfZTadCiaVE09X3iccwbbeQAXSp4YDwEe0upCDHGbka0vg/640?wx_fmt=gif&amp;from=appmsg#imgIndex=7" data-ratio="0.562962962962963" data-s="300,640" data-type="gif" data-w="1080" type="block" data-imgfileid="503525767" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/ba5f3fa6-9a8f-4fca-a63e-4c9100100a86/640.gif" data-order="3" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 推理阶段优化策略图解&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实测表现：优于主流并行解码方案&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 A100 GPU 上的 7B 模型基准测试中，Jacobi Forcing 超越 dLLMs、投机解码等主流方案，展现出更优的速度 - 质量 trade-off。&lt;/p&gt;&lt;section&gt;&lt;img data-imgfileid="503525771" data-ratio="0.8652482269503546" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8L9eIe4cvYXicnfDf06cNvrzcicgYJDWzkkfes9CwkSSalbdFklFPvvaWX833BBvEB9gtQMtTdWqqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="846" type="block" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/69fe9e52-c6ca-485a-addc-6990867b08e0/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Jacobi Forcing 模型性能展示&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;无论是编码、数学等专业任务，还是通用文本生成场景，Jacobi Forcing 都能在保证结果可靠性的前提下，将推理速度提升一个量级，尤其适合对延迟敏感的工业级 LLM 应用。&lt;/p&gt;&lt;p&gt;Jacobi Forcing 的出现，不仅解决了 LLM 推理的效率瓶颈，更重新定义了因果模型的并行化可能。随着大模型应用向低延迟、高并发场景渗透，这种兼顾兼容性、高性能和高质量的解码方案，有望成为工业级 LLM 部署的首选技术，推动 AI 应用效率迈入新阶段。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
