<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>Sebastian Raschka万字年终复盘：2025，属于「推理模型」的一年</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:58:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fb81ab4c-43c5-47ad-a6bc-1be0d559462c/1767372891034.png" style="width: 700%;" class="fr-fic fr-dib"&gt;随着2025年的日历翻过最后一页，AI 领域再次证明了预测未来的难度。&lt;/p&gt;&lt;p&gt;在这一年，Scaling Law 并没有失效，但它的战场已经转移：从单纯的参数堆叠转向了推理侧的强化。DeepSeek R1 的横空出世，不仅打破了专有模型的神话，更让 RLVR 和 GRPO 算法成为了年度技术风向标。与此同时，我们在架构上看到了 MoE 与高效注意力机制的收敛，也在行业中目睹了「极限刷榜」带来的评估困境。&lt;/p&gt;&lt;p&gt;著名 AI 教育家与研究员 Sebastian Raschka 在他今年的年度总结中，以其一贯的「硬核工程视角」对 2025 年进行了全面复盘。从 DeepSeek 的成本经济学到推理模型的算法细节，从工具使用的演进到 AI 辅助编程的真实体验，Raschka 不仅梳理了技术脉络，还反思了人与 AI 的协作边界。&lt;/p&gt;&lt;p&gt;以下是 Sebastian Raschka 的博客原文：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LGfm3xFmTvoajA6OCRy19ia47jib2vmJGLicqiaRRGr1IRgqaBkOwWpMeIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4064814814814815" data-type="png" data-w="1080" data-width="1371" data-height="557" data-imgfileid="503526344" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e0dbd922-153f-4099-b22b-f3d7425d3c25/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="0 0 []"&gt;https://magazine.sebastianraschka.com/p/state-of-llms-2025&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;随着 2025 年接近尾声，我想回顾一下大语言模型（LLM）在本年度的一些最重要进展，反思现存的局限性和未解难题，并分享一些关于未来的想法。&lt;/p&gt;&lt;p&gt;正如我每年常说的那样，2025 年对于 LLM 和 AI 来说又是充满变数的一年，而且今年没有迹象表明这种进步正在饱和或放缓。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、推理之年：RLVR 与 GRPO&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想探讨的有趣话题很多，让我们按时间顺序从 2025 年 1 月开始说起。&lt;/p&gt;&lt;p&gt;Scaling 仍然有效，但它并没有真正改变 LLM 在实际应用中的表现或感觉（唯一的例外是 OpenAI 刚发布的 o1，它增加了推理轨迹）。因此，当 DeepSeek 在 2025 年 1 月发布 R1 论文，展示了类似推理的行为可以通过强化学习开发出来时，这意义非凡。（在 LLM 的语境下，推理意味着模型会解释其答案，而这种解释本身通常会带来答案准确性的提升。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lp4e3meiaLExm6gBeViavozaCaMdyRtxbvhKlAnvPY8aWia1lVwoe0gDZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9787037037037037" data-type="png" data-w="1080" data-width="1496" data-height="1464" data-imgfileid="503526345" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c7a7b942-af3e-440c-8ff2-db7d116b57ff/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：一个简短的回答和一个包含中间步骤的更长的回答，后者通常是推理模型生成的。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.1 DeepSeek 时刻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 因各种原因备受关注：&lt;/p&gt;&lt;p&gt;首先，DeepSeek R1 是作为开放权重模型发布的，其表现非常出色，足以媲美当时最好的专有模型（如 ChatGPT, Gemini 等）。&lt;/p&gt;&lt;p&gt;其次，DeepSeek R1 的论文促使许多人（尤其是投资者和记者）重新审视 2024 年 12 月发布的 DeepSeek V3 论文。这导致了一个修正后的结论：虽然训练最先进的模型仍然昂贵，但其成本可能比之前假设的低一个数量级，估计更接近 500 万美元，而不是 5000 万或 5 亿美元。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LhwBls2CmcZBdRcl9SRGiarXvicNvHicuEwnxyzJHwrXZniafNqsS4s6ibLA/640?wx_fmt=jpeg#imgIndex=3" data-ratio="0.18888888888888888" data-type="png" data-w="1080" data-width="1456" data-height="351" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5I76ibsxkINcEUXNtPYWYcXkfVsWMAHu2xS3NHiaqianfPFpUDIHjBCuA/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1456" data-cropy1="42.82352941176471" data-cropy2="317.3979238754326" data-imgfileid="503526346" data-aistatus="1" data-original-style="width: 578px;height: 109px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/35c9c5f4-a0ee-4ae7-971a-925272beec72/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：来自 DeepSeek V3 论文 的表格，估计训练 6710 亿参数 DeepSeek V3 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 的补充材料估计，在 DeepSeek V3 基础上训练 R1 模型的成本仅需额外的 29.4 万美元，这再次远低于所有人的预期。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LypJzibIqWMIibn7jhS6gXUEqMC3mHKJCPlBoN9AK9zJCQBhfGaDdCCFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.21203703703703702" data-type="png" data-w="1080" data-width="1358" data-height="288" data-imgfileid="503526348" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d993acdd-ee64-4cce-ad31-a8b16fac9840/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：来自 DeepSeek R1 论文补充材料的表格，估计在 DeepSeek V3 基础上训练 R1 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;当然，关于 500 万美元的估算有许多注意事项。例如，它仅涵盖了最终模型运行的算力信用成本，并未计入研究人员的薪水以及与超参数调整和实验相关的其他开发成本。&lt;/p&gt;&lt;p&gt;第三，也是最有趣的一点，该论文提出了带有可验证奖励的强化学习 (RLVR) 配合 GRPO 算法，作为一种新的（或至少是改进的）算法方法，用于开发所谓的推理模型并在后训练阶段改进 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LRTPlWqqflKSwPibDODO19NNYk5dmDOxSicQRzVnofHvZhc3C42lQbmcw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.875" data-type="png" data-w="1080" data-width="1456" data-height="1274" data-imgfileid="503526349" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f4f8531a-ed73-4938-8c52-a7ea832864cf/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4：强化学习应用的广泛概述及其时机。在这一概述中，我跳过了许多细节，但有兴趣的读者可以在我的《LLMs 推理的强化学习现状》一文中阅读更多内容。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在此之前，像监督指令微调 (SFT) 和基于人类反馈的强化学习 (RLHF) 这样的后训练方法（它们仍然是训练流程的重要组成部分）一直受限于昂贵的书面回复或偏好标签。（当然，人们也可以用其他 LLM 合成生成这些数据，但这有点像「先有鸡还是先有蛋」的问题。）&lt;/p&gt;&lt;p&gt;DeepSeek R1 和 RLVR 的重要性在于，它们允许我们在大量数据上对 LLM 进行后训练，这使它们成为通过在后训练期间扩展算力来改进和解锁能力的绝佳候选者（假设有可用的算力预算）。&lt;/p&gt;&lt;p&gt;RLVR 中的 V 代表「可验证」，意味着我们可以使用确定性方法来分配正确性标签，而这些标签足以让 LLM 学习复杂的问题解决能力。（典型的类别是数学和代码，但也有可能将此想法扩展到其他领域。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L8qmOyFvp2nZibke3IPXUx629WVtUMFHEbTtFzJNDlcYImjx79XVWA2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5361111111111111" data-type="png" data-w="1080" data-width="1082" data-height="580" data-imgfileid="503526350" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e6db5b0d-853f-4f20-96a2-30fc906a7fa1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图5：可验证奖励的一个简单示例。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我不想在这里过于纠结技术细节，因为我想在这篇年度回顾文章中涵盖其他方面。关于推理 LLM 和 RLVR，完全可以写整篇文章或整本书。例如，如果您有兴趣了解更多，可以查看我之前的文章。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上所述，结论是：今年的 LLM 发展本质上是由使用 RLVR 和 GRPO 的推理模型主导的。 基本上，继 DeepSeek R1 之后，每一个主要的开放权重或专有 LLM 开发商都发布了其模型的推理（通常称为「思考/Thinking」）变体。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.2 LLM 关注重点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我要简洁地总结每一年 LLM 开发的关注重点（除了单纯扩展架构和预训练算力之外），我的列表会是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2022: RLHF + PPO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2023: LoRA SFT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2024: 中期训练 (Mid-Training)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2025: RLVR + GRPO&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;预训练仍然是一切的必要基础。除此之外，RLHF（通过 PPO 算法）当然是早在 2022 年带来最初 ChatGPT 模型的功臣。&lt;/p&gt;&lt;p&gt;在 2023 年，重点大量集中在 LoRA 和类 LoRA 的参数高效微调技术上，用于训练小型自定义 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lb3le591ibg3TBNr3SsxooOTJu42nl8Lc9nulFDXquv80XvRzVskk4rA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.36018518518518516" data-type="png" data-w="1080" data-width="1456" data-height="524" data-imgfileid="503526351" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9488821f-174a-4165-a48f-4b6b461d8c6e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 6：近年来专有和开源权重 LLM 开发的一些关注领域。请注意，这是累积性的，意味着例如 RLHF + PPO 仍然相关且被使用。然而，它已不再是讨论的热点话题。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;接着，在 2024 年，所有主要实验室开始通过关注合成数据、优化数据混合、使用特定领域数据以及增加专门的长上下文训练阶段，使其（预）训练流程更加复杂。我在当时的 2024 年文章中总结了这些不同的方法（当时我将这些技术归类为预训练，因为「中期训练」这个术语当时还没被创造出来）：&lt;/p&gt;&lt;p&gt;当时，我认为这些是预训练技术，因为它们使用相同的预训练算法和目标。今天，这些紧随常规通用数据预训练之后的、稍微更专业化的预训练阶段，通常被称为「中期训练」（作为常规预训练和包括 SFT、RLHF 以及现在的 RLVR 在内的后训练之间的桥梁）。&lt;/p&gt;&lt;p&gt;那么，你可能会问，接下来是什么？&lt;/p&gt;&lt;p&gt;我认为明年我们会看到对 RLVR 的（更多）关注。目前，RLVR 主要应用于数学和代码领域。 下一个合乎逻辑的步骤是，不仅使用最终答案的正确性作为奖励信号，还要在 RLVR 训练期间评判 LLM 的解释。这在过去多年里一直以「过程奖励模型」的研究标签存在。然而，它尚未取得超级成功。例如，引用 DeepSeek R1 论文：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;4.2. 不成功的尝试 [...] 总之，虽然 PRM 展示了良好的能力来对模型生成的前 N 个响应进行重新排序或辅助引导搜索 (Snell et al., 2024)，但在我们的实验中，与其在大规模强化学习过程中引入的额外计算开销相比，其优势是有限的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;然而，看看上个月发布的最新 DeepSeekMath-V2 论文（我在之前的文章《从 DeepSeek V3 到 V3.2：架构、稀疏注意力和 RL 更新》中讨论过），我认为未来我们会看到更多将「解释评分」作为训练信号的做法。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://sebastianraschka.com/blog/2025/technical-deepseek.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前对解释进行评分的方法涉及第二个 LLM。这引出了我看到的 RLVR 的另一个方向：扩展到数学和代码以外的其他领域。&lt;/p&gt;&lt;p&gt;所以，如果你今天问我如果不展望 2026 年和 2027 年会看到什么，我会说：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2026: RLVR 的扩展和更多的推理时扩展&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2027: 持续学习&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了上述的 RLVR 扩展，我认为 2026 年将会有更多关注点放在推理时扩展上。推理时扩展意味着我们在训练后，让 LLM 生成答案时花费更多的时间和金钱，但其效果非常显著。&lt;/p&gt;&lt;p&gt;推理扩展并不是一个新的范式，LLM 平台已经在底层使用了某些技术。这是延迟、成本和响应准确性之间的权衡。然而，在某些应用中，准确性比延迟和成本更重要，极端的推理扩展完全是值得的。例如，正如最近的 DeepSeekV2-Math 论文所示，它将模型在具有挑战性的数学竞赛基准测试中的表现推向了金牌水平。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lgo4kxXoySblp3wm7ZrE6jXu78K1U8iaX6JllOCQctk68Lcw1qNrD0Mw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526352" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/079ab775-78ff-4af5-9402-9ec440e6d46b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 7：两种推理时扩展方法的结合：自一致性与自精炼。额外的自精炼迭代可以提高准确性。该图来自 DeepSeekMath-V2 论文。自一致性与自精炼在《从零构建推理模型》一书的第 4 章和第 5 章中有详细说明。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;今年同事之间也有很多关于持续学习的讨论。简而言之，持续学习是指在不从头开始重新训练的情况下，在数据或知识上训练模型。 这并非新想法，我也好奇为什么今年它被提及这么多次，因为目前在持续学习方面并没有任何新的或实质性的突破。&lt;/p&gt;&lt;p&gt;持续学习的挑战在于灾难性遗忘（正如持续预训练的实验所示，学习新知识意味着 LLM 在某种程度上正在遗忘旧知识）。 不过，既然这看起来是一个如此热门的话题，我确实期望在未来几年在最小化灾难性遗忘和使持续学习方法开发成为重要进展方面取得更多进步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、GRPO：年度研究宠儿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在昂贵的 LLM 时代，学术研究近年来一直颇具挑战性。当然，尽管（或者正因为）预算较少，学术界仍然可以做出重要的发现，并成为主流和 LLM 进步及突破的关键支柱。近年来的流行例子包括 LoRA（2021 年的大型语言模型低秩适应）及其相关的参数高效微调方法。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LA631P3NNEmRQdJYWhaANufgibNMduQNOORWIHjiamrUu4GYZmVMpUBrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8175925925925925" data-type="png" data-w="1080" data-width="1456" data-height="1190" data-imgfileid="503526353" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ae1ea1db-0f96-4f41-a2b2-0df356415252/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8：基于代码的 LoRA 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;另一个是 DPO（直接偏好优化：你的语言模型秘密地是一个奖励模型）及其相关的无奖励模型对齐方法，作为基于人类反馈的强化学习的替代方案。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L49PyWufJKTYcKleM4a242icoKynL9iangpUp1xpeLcthhibChbelZlycQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8518518518518519" data-type="png" data-w="1080" data-width="1456" data-height="1240" data-imgfileid="503526354" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c287f634-ddac-4a31-8834-33b92a91e666/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9：基于代码的 DPO 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在我的圈子里，今年的研究亮点是 GRPO。虽然它是在 DeepSeek R1 论文中介绍的，而非源自学术界，但它仍然让研究人员度过了令人兴奋的一年：RLVR 和 GRPO 在概念上都很有趣，而且根据规模不同，进行实验的成本并不令人望而却步。&lt;/p&gt;&lt;p&gt;因此，今年我在 LLM 研究文献中看到了许多对 GRPO 的数学改进（来自公司和学术研究人员），这些后来被采纳进了最先进 LLM 的训练流程中。例如，其中包括以下改进：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Olmo 3：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;零梯度信号过滤 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;主动采样 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Token 级损失 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无 KL 损失 (DAPO by Yu et al., 2025 和 Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Clip higher (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;截断重要性采样 (Yao et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无标准差归一化 (Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;DeepSeek V3.2：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;带有特定领域 KL 强度的 KL 调优（数学领域为零）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重新加权的 KL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Off-policy 序列掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留 top-p / top-k 的采样掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留原始 GRPO 优势归一化&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我可以确认，这些 GRPO 的技巧或修改在实践中具有巨大的影响。例如，采用了其中一些或多项修改后，糟糕的更新不再破坏我的训练运行，我也不再需要定期重新加载检查点。&lt;/p&gt;&lt;p&gt;即便是非常短的运行，我在采用这些技巧时也观察到了巨大的收益：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LG0z49N20icw8aZmCPlrg38v6b50RXiaia5icw5tZB2aISzTVlLYpY78o3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.28888888888888886" data-type="png" data-w="1080" data-width="1456" data-height="421" data-imgfileid="503526356" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/51928105-7550-4bb2-9271-f9f161b99223/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10：我从零开始的 GRPO 训练代码部分结果，该代码可在 GitHub 上获取&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;无论如何，如果你想尝试一下，我在「从头构建推理模型」的代码库中有一个原生 GRPO 脚本。（我很快会添加更多包含相应修改的消融研究。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、LLM 架构：岔路口？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说到 LLM 架构，最先进的模型仍然使用老式的解码器风格 Transformer。然而，今年，开放权重 LLM 或多或少都收敛于使用混合专家 (MoE) 层，以及至少一种「效率调整」的注意力机制：分组查询注意力 、滑动窗口注意力或多头潜在注意力。&lt;/p&gt;&lt;p&gt;除了这些相当标准的 LLM 架构外，我们还看到了针对注意力机制的更激进的效率调整，旨在随序列长度线性扩展。这方面的例子包括 Qwen3-Next 和 Kimi Linear 中的 Gated DeltaNets，以及 NVIDIA Nemotron 3 中的 Mamba-2 层。&lt;/p&gt;&lt;p&gt;无论如何，我不想在这里深入太多细节，因为如果您想了解更多，我有一篇完整的 1.3 万字且最近更新的文章专门讨论这些架构：大型 LLM 架构比较&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LDjr3AVbCichiclibbibn5UjjYP6EAtjtPmkjo1IF8JyuLxgwS32BhhWolw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="1.3712962962962962" data-type="png" data-w="1080" data-width="1167" data-height="1600" data-imgfileid="503526357" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/a31ab06a-5774-46c5-af13-be1d9b417128/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 11：大型 LLM 架构对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我的预测是，我们将继续基于 Transformer 架构构建至少几年，至少在最先进的建模性能方面是这样。 同时，我确实认为我们会看到越来越多像 Gated DeltaNet 和 Mamba 层这样的效率和工程调整，因为在 LLM 训练、部署和使用的规模下，从财务角度来看，这对那些仍在为服务 LLM 烧钱的公司来说是有意义的。&lt;/p&gt;&lt;p&gt;这并不意味着没有其他替代方案。正如我在《超越标准 LLM》中所写，文本扩散模型是一种有趣的方法。目前，它们属于实验性研究模型类别，但 Google 分享说他们将发布 Gemini Diffusion 模型。它在建模质量上不会与其最先进的产品相抗衡，但对于低延迟要求的任务（如代码补全），它将非常快且具吸引力。&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，两周前，开放权重的 LLaDA 2.0 模型发布了。其中最大的一个拥有 1000 亿参数，是迄今为止最大的文本扩散模型，与 Qwen3 30B 相当。（是的，它并没有推动整体的最先进水平，但在扩散模型领域仍是一个值得注意的版本。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、这也是推理扩展和工具使用的一年&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过扩展训练数据和架构来改进 LLM 是一个既定公式，且（仍然）持续奏效。然而，特别是在今年，这已不再是「唯一」足够的秘诀。 我们在 GPT 4.5（2025 年 2 月）上看到了这一点，据传它比 GPT 4（以及后来发布的 GPT 5）大得多，但单纯的Scaling 通常不是最明智的前进方式。GPT 4.5 的能力可能比 GPT 4 更好，但增加的训练预算被认为是「性价比低」。&lt;/p&gt;&lt;p&gt;相反，更好的训练流程（更加关注中期和后训练）和推理扩展推动了今年的大部分进步。 例如，如前所述，在谈论达到金牌级数学表现的 DeepSeekMath-V2 时，推理扩展是我们可以利用的杠杆之一，让 LLM 按需解决极其复杂的任务（GPT Heavy Thinking or Pro 是其他例子；由于高延迟和成本，将这些用于所有事情是没有意义的，但在某些例子中，如具有挑战性的数学或编码问题，高强度的推理扩展是有意义的。）&lt;/p&gt;&lt;p&gt;另一个重大改进来自以工具使用为核心的 LLM 训练。如您所知，幻觉是 LLM 最大的问题之一。可以说，幻觉率一直在改善，我认为这很大程度上归功于上述的工具使用。例如，当被问及谁赢得了 1998 年 FIFA 世界杯时，LLM 不再尝试死记硬背，而是可以通过工具使用传统的搜索引擎，并从该主题的可信网站（例如本例中的 FIFA 官方网站）选择和抓取此信息。数学问题也是如此，使用计算器 API 等等。&lt;/p&gt;&lt;p&gt;例如，OpenAI 的 gpt-oss 模型是今年发布的早期开放权重模型之一，其开发时就特别考虑了工具使用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LElNRkjgywwZAA1LZxvDhyIvBQw9zicricPN0VYq3nDwEa9ukJe8r91Dg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.7416666666666667" data-type="png" data-w="1080" data-width="1456" data-height="1080" data-imgfileid="503526358" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/35d51828-d87b-490a-8483-b0d8b0178702/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 12：来自 gpt-oss 模型卡片论文的注释表格.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;遗憾的是，开源生态系统尚未完全赶上，许多（如果不是大多数）工具仍然默认在非工具使用模式下运行这些 LLM。一个原因是这是一个较新的、不断发展的范式，工具需要适应。另一个原因也是这是一个更难解决的问题，出于安全考虑（给予 LLM 无限制的工具使用访问权限可能会带来潜在的安全风险或对系统造成其他形式的破坏。我认为应该始终问的一个明智问题是：你会信任一个新实习生拥有这种级别的系统访问权限来做这件事吗？）&lt;/p&gt;&lt;p&gt;我确实认为，在未来几年，当在本地使用 LLM 时，启用和允许工具使用将变得越来越普遍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、年度词汇：Benchmaxxing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我必须选一个词或趋势来描述今年的 LLM 发展，那将是「极限刷榜 (Benchmaxxing)」。 在这里，Benchmaxxing 意味着过度关注推高排行榜的分数，有时甚至到了基准测试表现本身成为目标，而不是作为通用能力的代理指标的地步。&lt;/p&gt;&lt;p&gt;一个突出的例子是 Llama 4，它在许多既定基准测试中得分极高。然而，一旦用户和开发者上手使用，他们就意识到这些分数并不能反映真实世界的能力和实用性。 正如那句流行语所说，如果测试集是公开的，它就不是真正的测试集。而如今的问题是，测试集数据不仅（有意或无意地）是训练语料库的一部分，而且在 LLM 开发过程中经常被直接优化。&lt;/p&gt;&lt;p&gt;过去，即使公共测试集的基准分数虚高，至少模型排名仍然保持不变。例如，参见下方 2019 年论文《ImageNet 分类器能泛化到 ImageNet 吗？》中的注释图。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LQiaIscKgRkvX6XoNzlyy7Buqfp4Im1F3G3Jsibm0y8df3xZD2SxCWsRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6351851851851852" data-type="png" data-w="1080" data-width="1388" data-height="882" data-imgfileid="503526359" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/9fbf55b9-b295-43d6-acc8-069df620e25a/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 13：来自 2019 年论文《Do ImageNet Classifiers Generalize to ImageNet?》的标注图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 LLM 开发中，这已经到了基准数字不再是值得信赖的 LLM 性能指标的地步。 然而，我确实认为基准测试仍然是 LLM 必须跨越的必要门槛。即，如果我看到一个 LLM 在基准 Y 上的得分低于 X，我就已经知道它不是一个好的 LLM。然而，如果它在基准 Y 上的得分高于 X，这并不意味着它比另一个在同一基准上得分高于 X 的 LLM 好多少。&lt;/p&gt;&lt;p&gt;另一个需要考虑的方面是，图像分类器只有一个工作，即分类图像。然而，LLM 用于许多不同的任务：翻译文本、总结文本、编写代码、头脑风暴、解决数学问题等等。评估图像分类器（有明确的指标如分类准确率）比评估 LLM 在确定性和自由形式任务上的表现要简单得多。&lt;/p&gt;&lt;p&gt;除了在实践中尝试 LLM 并不断生成新的基准测试外，遗憾的是，这个问题没有解决方案。 顺便说一句，如果你好奇了解 LLM 评估的主要类别，你可能会喜欢我的文章《从头理解 LLM 评估的 4 种主要方法》。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、AI 用于编码、写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然这个问题经常出现，我想分享一下我对 LLM 取代人类进行某些类型任务（甚至工作）的看法。 从高层次来看，我将 LLM 视为赋予某些职业的人们「超能力」的工具。我的意思是，当 LLM 被用好时，它们可以使个人效率大幅提高，并消除日常工作中的许多摩擦。这范围从相对平凡的任务（如确保章节标题的大小写一致）到在大型代码库中查找复杂的错误。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.1 编码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，我仍然自己编写大部分我关心的代码。「我关心的」是指在那些我理解代码且代码正确性至关重要的上下文中。例如，如果我设置一个 LLM 训练脚本，我会实现并仔细检查训练逻辑。这是为了 a) 确保它在做我认为它应该做的事情，以及 b) 保留我在该任务中的知识和专业技能。然而，我现在使用 LLM 来添加周围更平凡的代码，例如添加命令行 argparse 样板代码，以便我可以更方便地从命令行使用我自己的代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LMWf8Vp5AoXZKpSbGtVlHVVHJNFOg0qFNZDJJSx8PTz0zGAaox7KTHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.6666666666666667" data-type="png" data-w="960" data-width="960" data-height="1600" data-imgfileid="503526360" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/950d2605-f1a7-4ce2-bdcc-feb90ce3cf4b/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 14：使用提示「为 training-script.py 添加 argparse 以支持所有超参数选项」向训练脚本添加命令行参数的例子。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但我也越来越多地依靠 LLM 来发现问题、建议改进或对想法进行健全性检查。同时，我想了解我正在构建什么，作为个人目标，我旨在加深我的知识和技能，并继续增长我的专业知识。&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，LLM 对于我核心专业知识之外的任务非常有价值。它们让我自动化了一些我本来没有时间或精力去处理的事情。一个例子是我最近写的一个工具，用于将我的 Substack 文章提取并备份为 Markdown。（我在 Markdown 中起草所有内容，但我经常直接在 Substack 编辑器中编辑和扩充文章，所以我的本地草稿并不总是最新的）。LLM 还帮助我清理了网站上的 CSS，这些 CSS 积累了多年的重复和不一致。今年有很多类似的案例我使用了 LLM。&amp;nbsp;&lt;/p&gt;&lt;p&gt;简而言之，我认为这里的诀窍是识别何时使用以及何时不使用 LLM。以及如何以一种有助于你增长专业知识同时也令人感到满足的方式使用 LLM。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.2 代码库和代码库&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 在编写代码方面变得更好了，但尽管我听到其他人这么说，我不认为代码是或将变得短暂或过时。LLM 赋予人们超能力来生成某些编码项目，这些项目如果由他们自己创建，将需要大量精力。 然而，纯粹由 LLM 生成的代码库并不能取代专家精心制作的代码库。这些专家代码库甚至可能是由人类编码员自己使用 LLM 创建的。但关键点在于，该领域的专家投入了大量时间和精力来创建、测试和完善它。其他人要复制它需要大量工作，所以如果它存在，为什么不采用它呢？&lt;/p&gt;&lt;p&gt;简而言之，我认为一个学习了良好设计模式和权衡取舍、并在职业生涯中研究、见过并构建了许多平台的专家全栈 Web 开发人员，将能够构建比一个随机提示 LLM 构建平台的人更好的平台。 很棒的是，一个随机的人现在可以构建一个平台，即使它不是最好的。然而，使用和提示 LLM 只能让那个人走这么远，平台的质量可能会停滞不前。因此，如果这个人真的关心改进平台，深入研究这里，学习其他人如何构建平台，并带着更多的知识回来更有效地使用 LLM 来指导和改进平台设计，将是一个好主意。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.3 技术写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与编码类似，我不认为 LLM 会使技术写作过时。写一本好的技术书籍需要数千小时和对主题的深刻熟悉。这个过程可能涉及 LLM 来提高清晰度、检查技术正确性、探索替代方案或运行小型实验，但核心工作仍然取决于人类的判断和专业知识。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lv2KFlI8vykxJPX6QTmGefhUaV8rvib3T4k5Q4vvAoWfjS320znibjf7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="1.499531396438613" data-type="png" data-w="1067" data-width="1067" data-height="1600" data-imgfileid="503526362" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/7b4a580c-7dbf-43cb-aacf-4fd2da543603/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp;图 15：一个非分阶段的例子，其中 LLM 只是帮助我找到并修复了前一篇文章中的错误。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;是的，LLM 可以让技术书籍变得更好。它们可以帮助作者发现错误、扩充参考文献，并通常减少花在平凡任务上的时间。这释放了更多时间用于真正需要创造力和经验的深度工作。&amp;nbsp;&lt;/p&gt;&lt;p&gt;从读者的角度来看，我也不认为 LLM 取代了技术写作。使用 LLM 了解一个主题对于快速提问和初学者级别的解释非常有效。然而，当你想要建立更深层次的理解时，这种方法很快就会变得混乱。&lt;/p&gt;&lt;p&gt;在那一点上，与其可能浪费数小时自己试图过滤 LLM 关于你试图学习但（尚）不是专家的主题的回复，通常遵循专家设计的结构化学习路径更有意义。（专家可能使用了也可能没有使用 LLM。）&lt;/p&gt;&lt;p&gt;当然，在参加课程或从书中学习时，使用 LLM 来澄清问题或探索旁支路径仍然非常有意义。让它设计测验或练习来实践知识也很棒。&lt;/p&gt;&lt;p&gt;总的来说，我认为 LLM 对作者和读者来说都是净收益。 但我也认为这里的诀窍是学会识别何时使用以及何时不使用 LLM。例如，主要的缺点是，当一个话题变得困难时，人们很容易立即使用 LLM，因为先自己努力解决问题通常会带来更强的学习效果。&lt;/p&gt;&lt;p&gt;我看待研究的方式也差不多。LLM 对于查找相关文献、发现数学符号中的问题和建议后续实验非常有用。但让一位人类研究员坐在驾驶座上仍然是有意义的。 也许这里的经验法则是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书完全由人类生成，它可能还有进一步改进的空间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书可以通过仅仅提示 LLM 生成，那么它可能不够新颖和/或不够深刻。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;6.4 LLM 与职业倦怠&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 仍然相当新且在不断发展，我认为过度使用 LLM 也有一个较少讨论的缺点。例如，我认为如果模型做了所有的操作，而人类主要是在监督，工作可能会开始让人感到空虚。&lt;/p&gt;&lt;p&gt;当然，有些人真的喜欢专注于管理系统和编排工作流程，这是一个完全有效的偏好。但对于那些喜欢亲手做事的人来说，我认为这种工作模式可能会加速职业倦怠。（这对于那些期望因为有了 LLM 而能更快获得更多结果的公司来说尤其如此。）&lt;/p&gt;&lt;p&gt;与难题搏斗并最终看到它成功，有一种特别的满足感。当 LLM 一次性搞定解决方案时，我没有同样的感觉。我想这类似于烹饪（这只是我想到的，我不是一个好厨师）。如果你喜欢做披萨，使用预制的面团只加配料可能会消除很多乐趣，烹饪变成了达到目的的手段。这不一定是坏事，但我认为如果你在较长一段时间内（几个月或几年）每天做很多小时这样的工作，我能看到它会让人感到空虚并最终导致倦怠。 所以，一个自私的观点是写代码也比读代码更有趣。你可能会同意，创建 Pull Request 通常比审查它们更有趣（当然，这对每个人来说并不都是真的）。&lt;/p&gt;&lt;p&gt;也许一个很好的、理想化的（但并非完美的）类比，说明我们应该如何以可持续的方式使用 AI，就是国际象棋。&amp;nbsp;&lt;/p&gt;&lt;p&gt;国际象棋引擎在几十年前就超越了人类棋手，但人类进行的职业国际象棋仍然活跃且繁荣。我不是国际象棋专家，但我觉得这项游戏可能甚至变得更加丰富和有趣了。&lt;/p&gt;&lt;p&gt;根据我听到的（例如，基于 Kasparov 的《Deep Thinking》一书和以 Magnus Carlsen 为特色的播客），现代棋手一直在使用 AI 来探索不同的想法，挑战他们的直觉，并以前所未有的深度分析错误。&lt;/p&gt;&lt;p&gt;我认为这是一个有用的模型，可以用来思考智力工作其他形式中的 AI。如果用得好，AI 可以加速学习并扩展一个人可以合理承担的工作。我认为我们应该更多地把它视为合作伙伴而不是替代品。 但我也认为，如果 AI 被用来完全外包思考和编码，它就有可能破坏动力和长期技能发展。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LJmeDUugQnicvCtHxDPr3g1edcTd9R4AXG7qUsaziariaFjqD8mNrUC7Ew/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526363" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/033a26a8-67d5-4a5b-bf2d-7d9b1ba1e8a0/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 16：LLMs 降低了入门门槛，使程序员（无论是初学者还是专家）更加高效。然而，在我们即将结束 2025 年之际，我认为仍然值得投资成为专家，因为这样你将能从 LLMs 中获得更多的价值，并能够交付更出色的结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7、优势：私有数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 的通用编码、知识问答和写作能力在不断提高。这很大程度上是因为由于训练流程和范式（例如 RLVR）以及推理扩展和工具使用的改进，Scaling 仍然提供了正向的投资回报。&lt;/p&gt;&lt;p&gt;然而，这将在某个时刻开始趋于平稳（类似于我们在 GPT 4 到 GPT 4.5 开发中看到的），除非我们继续发明新的训练方法和/或架构（目前，还没有人知道这些可能是什么样子的）。&lt;/p&gt;&lt;p&gt;LLM 目前能够解决许多通用任务和低垂的果实。但要将它们确立在某些行业中，就需要更多的领域专业化。我认为 LLM 提供商会很乐意获得高质量的、特定领域的数据。目前看来，这将是一个挑战。&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，似乎大多数接触过的公司都拒绝了此类交易，恰恰是因为数据是专有的并且是其业务差异化的核心。（我从多个来源听到了这一点，还有一篇关于此主题的 The Information 文章。）&amp;nbsp;&lt;/p&gt;&lt;p&gt;在我看来，这完全说得通。我认为将有价值的专有数据（有一天可能会给公司带来优势）卖给 OpenAI 或 Anthropic 可能有点短视。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LPxp0fnU6IHnWXZEvkMUb3JNsLOvUebib7DibTchs39GH8ylYymtpyLPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.45092592592592595" data-type="png" data-w="1080" data-width="1456" data-height="657" data-imgfileid="503526364" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/31132ae5-d478-424b-9a69-6caa2846fcd2/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 17：可用于训练领域专用 LLMs 的数据领域和类型示例，但在这些情况下将数据出售给外部方可能会引起担忧。(我不是法律专家，这也不构成法律建议，但我可以想象，如果是一个纯本地的 LLM，不会离开公司的安全服务器，那么在患者健康数据上训练模型与开发其他使用该患者健康数据的内部软件并无不同。)&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;目前，LLM 开发在大规模上极其昂贵且具有挑战性，这就是为什么只有少数大公司开发最先进的 LLM。然而，我认为 LLM 开发正变得越来越商品化，因为 LLM 开发者频繁在雇主之间轮换，最终将被更大的金融机构、生物技术公司和其他有预算开发利用其私有数据的具有竞争力的内部 LLM 的公司聘用。&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些 LLM 甚至不必完全从头开始训练；许多最先进的 LLM 如 DeepSeek V3.2、Kimi K2 和 GLM 4.7 正在发布，可以进行调整和进一步的后训练。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8、从头构建 LLM 和推理模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你可能想知道我今年都在忙些什么。我的重心几乎完全放在了 LLM 相关的工作上。去年，我决定成为一名独立人士并创办了自己的公司，主要是为了有更多时间从事我自己的研究、书籍撰写、Substack 写作以及行业合作。&lt;/p&gt;&lt;p&gt;作为一名独立研究员，咨询项目是维持这种工作模式可持续的一部分。这不仅涵盖了日常开销（从食品杂货到健康保险），还包括一些不太显眼的成本，比如用于上述实验的云端算力费用。&lt;/p&gt;&lt;p&gt;随着时间的推移，我的目标是进一步减少咨询工作，将更多时间花在长篇研究和写作上，特别是我在这里分享的技术深度文章。&lt;/p&gt;&lt;p&gt;我很幸运，许多公司都联系我提供全职职位。如果独立这条路走不通，那将是一个可行的选择，但目前，我计划保持独立。&lt;/p&gt;&lt;p&gt;如果你觉得我的工作有用，并且在能力范围内，订阅我的 Substack 或购买我的一本书，确实有助于使这类工作变得可持续，我真心感谢大家的支持。&lt;/p&gt;&lt;p&gt;今年我的个人高光时刻之一是收到了关于我的书《从头构建大语言模型》 (Build A Large Language Model (From Scratch))的积极反馈。我收到了来自世界各地公司和大学读者的许多深思熟虑的留言。&lt;/p&gt;&lt;p&gt;这些反馈涵盖了广泛的用例：从大学教授将其作为主要教科书来教授 LLM 原理，到前学生用它准备面试并获得新职位，再到工程师依靠它作为在生产环境中实施自定义 LLM 的踏板。&lt;/p&gt;&lt;p&gt;得知这本书现在已经被翻译成至少九种语言，我也感到非常兴奋。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LXnVK0ap4icfhKtB43uZFxpWSicSRr3NUjdjAibrrRnu61WdnOFWoXU8LQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.7694444444444445" data-type="png" data-w="1080" data-width="1456" data-height="1120" data-imgfileid="503526365" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/b42684b8-231a-4273-b0d9-702e56a9d75c/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 18：构建一个大型语言模型（从头开始）翻译成不同语言。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;许多读者还问是否会有第二版，涵盖更新、更高级的主题。虽然我也考虑过这一点，但我对降低这本书的易读性持谨慎态度。例如，用更复杂的变体（如一些较新的 DeepSeek 模型中使用的多头潜在注意力）来替换标准的多头注意力，会大大提高准入门槛。&lt;/p&gt;&lt;p&gt;相反，目前我倾向于保持这本书的原样，因为它非常适合那些想入门 LLM 的人。对于对更高级材料感兴趣的读者，作为后续，我在这一年中向该书的 GitHub 代码库添加了大量的补充材料。我计划随着时间的推移继续扩展这些材料。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LHWmph5p8XvASuoIFxeQ3ZGjACkW5KnHMlGX1y4yq4gu2CwC0FiaxSZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="1.3546296296296296" data-type="png" data-w="1080" data-width="1178" data-height="1596" data-imgfileid="503526366" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/c0f2302c-4fda-4dc6-876c-1b2b25f6a5b4/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 19：我今年为《从零构建大型语言模型》（From Scratch）仓库添加的一些附加内容摘录。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，正如你可能知道的，我目前正在撰写续作《从头构建推理模型》。&lt;/p&gt;&lt;p&gt;第一本书《从头构建大语言模型》侧重于核心的大语言模型架构和预训练的基础知识。&lt;/p&gt;&lt;p&gt;[图片]&lt;/p&gt;&lt;p&gt;&lt;sup&gt;图 20：展示这两本从零开始的书籍如何相互关联的示意图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这本关于推理模型的书则紧接第一本书的内容。它从一个预训练好的基础模型开始，探索专门旨在提高推理能力的推理时扩展方法和强化学习技术。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LaNVxIytDmkdu3lwIcibBj66lUeicfHV7x21PyHayGMRhibBUowe1zbbqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.8203703703703704" data-type="png" data-w="1080" data-width="1456" data-height="1194" data-imgfileid="503526369" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/e3300f54-90ce-498d-b483-94878212d1c3/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 21：《从零构建推理模型》（早期访问版）的摘录.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;除了这个 Substack 博客，我正在努力撰写这本关于推理的书。在许多方面，我认为这是我迄今为止构思最周密、打磨最精细的一本书。&lt;/p&gt;&lt;p&gt;目前，我估计每一章大约花费 75-120 小时。如果你好奇的话，我估计具体的时间分配通常如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;3-5 小时： 头脑风暴和修改选题&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 构建内容结构&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;20 小时： 编写初始代码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 运行额外实验并阅读最新文献以获取更多见解&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 制作图表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10 小时： 撰写初稿文本&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 重写和润色章节&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 制作练习题加上运行实验&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2-5 小时： 整合编辑和读者的建议&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前，我已经完成了第 6 章的一半，该章实现了用于训练推理模型的带有可验证奖励的强化学习代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LeiasrFI3kzZxIA9LPtzq8hzI7I8iaInogJ2qEX3icsPDaGFveKgQLjfBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.7101851851851851" data-type="png" data-w="1080" data-width="1456" data-height="1034" data-imgfileid="503526370" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/297e6a06-c7f1-4a4a-b835-2b5e67110876/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 22：第 6 章和第 7 章中关于可验证奖励的强化学习实验的初步结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;《从头构建推理模型》是一项非常艰巨的工作，但我完全乐在其中！我希望你和其他读者会发现它像《从头构建大语言模型》一样有用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9、2025 年的惊喜与 2026 年的预测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想用一些主要的收获来结束这篇文章，重点关注我认为对我来说有点令人惊讶的事情，以及我对 2026 年的预测。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9.1 2025 年值得注意和令人惊讶的事情&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;让我们从 2025 年的惊喜开始。如果你在 2024 年早些时候问我，这些可能是我没想到的发展：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;几个推理模型已经在主要数学竞赛中达到金牌级表现（OpenAI 的一个未命名模型、Gemini Deep Think 和开放权重的 DeepSeekMath-V2）。我对这种事情的发生并不感到惊讶，但我很惊讶这在 2025 年就已经发生了，而不是 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Llama 4（或一般的 Llama）在开放权重社区中几乎完全失宠，Qwen 在受欢迎程度上已经超过了 Llama（根据 Nathan Lambert 的 ATOM 项目报告的下载量和衍生品数量衡量）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Mistral AI 在 2025 年 12 月宣布的最新旗舰 Mistral 3 模型使用了 DeepSeek V3 架构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;除了 Qwen3 和 DeepSeek R1/V3.2 之外，许多额外的竞争者出现在最先进开放权重模型的竞赛中，包括 Kimi、GLM、MiniMax 和 Yi。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更便宜、高效的混合架构已经成为领先实验室的更大优先事项（Qwen3-Next、Kimi Linear、Nemotron 3），而不是由单独的实验室开发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;OpenAI 发布了一个开放权重模型（gpt-oss，我今年早些时候写了一篇关于它的独立文章）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MCP（加入 Linux 基金会）已经成为代理式 LLM 系统中工具和数据访问的标准（目前）；我原本预计生态系统在 2025 年会保持更加碎片化，直到至少 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;9.2 2026 年预测&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们可能会看到一个工业规模、面向消费者的扩散模型，用于廉价、可靠、低延迟的推理，Gemini Diffusion 可能会率先推出。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开放权重社区将缓慢但稳定地采用具有本地工具使用和日益增强的代理能力的 LLM。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;RLVR 将更广泛地扩展到数学和编码以外的其他领域（例如化学、生物学等）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;经典的 RAG 将慢慢淡出作为文档查询的默认解决方案。与其在每个文档相关的查询上使用检索，开发人员将更多地依赖更好的长上下文处理，特别是随着将会有更好的「小型」开放权重模型出现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大量的 LLM 基准测试和性能进步将来自于改进的工具和推理时扩展，而不是来自于训练或核心模型本身。看起来 LLM 正在变得更好，但这主要是因为周围的应用正在改进。同时，开发人员将更多地专注于降低延迟，并使推理模型在不必要时减少推理 Token 的消耗。别误会，2026 年将进一步推动最先进水平，但今年的进步比例将更多地来自推理端，而不仅仅是训练端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后总结，我认为如果说 2025 年有一个元教训，那就是 LLM 的进步不再是关于单一的突破，而是通过多个独立的杠杆在多条战线上进行改进。这包括架构调整、数据质量改进、推理训练、推理扩展、工具调用等等。 同时，评估仍然很困难，基准测试是不完美的，关于何时以及如何使用这些系统的良好判断仍然至关重要。&lt;/p&gt;&lt;p&gt;我希望 2026 年我们继续看到有趣的改进，但也希望我们了解改进来自何处。这既需要更好和更一致的基准测试，当然也需要透明度。&lt;/p&gt;&lt;p&gt;谢谢阅读！&lt;/p&gt;&lt;p&gt;Cheers, Sebastian&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5beSNXduviaPh5O08SOVvMAEOVUiaZqfrDN74M5rqYia6YE0L3ibDeiaSXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1456" data-height="970" data-imgfileid="503526372" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/cfed2d35-1bfa-4b46-add0-e3c5b0e2cefc/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;附赠：LLM 研究论文精选列表（2025 年 7 月至 12 月）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今年 6 月，我曾分享了一篇附赠文章，其中包含了我为付费订阅者（是你们让这个 Substack 博客得以维持）精心挑选并收藏的研究论文列表。&lt;/p&gt;&lt;p&gt;以同样的方式，作为对所有好心支持者的感谢，我在下面准备了一份列表，列出了我在 2025 年 7 月至 12 月期间收藏并归类的所有有趣的研究文章。我略读了这些论文的摘要，但只详细阅读了其中很小的一部分。不过，我仍然喜欢不断收集这些有条理的列表，因为在进行特定项目时，我经常会回过头来查阅其中的某一组论文。&lt;/p&gt;&lt;p&gt;然而，鉴于目前这篇文章的篇幅已经非常巨大，我将这份列表分享在一篇单独的文章中，链接如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>KAN作者刘子鸣：AI还没等到它的「牛顿」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:45:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1c023bee-dd43-4080-8124-a33dfa63ca35/1767372187912.png" style="width: 700%;" class="fr-fic fr-dib"&gt;大家新年快乐！今天和大家分享 KAN 作者刘子鸣最新发布的一篇博客。&lt;/p&gt;&lt;p&gt;过去的一年，我们见证了 Scaling Laws 持续发力，模型能力不断刷新天花板。虽然 AI 社区从未停止对可解释性的探索，但在工程进展如此迅猛的当下，我们对模型内部机制的理解，似乎总是慢了半拍。&lt;/p&gt;&lt;p&gt;刘子鸣在博客中，借用科学史提出了一个发人深省的观点：如果参照物理学的发展史，&lt;strong&gt;今天的 AI 可能还远未在这个时代的「牛顿力学」时刻，而是仍处于「第谷（Tycho）时代」&lt;/strong&gt;，一个拥有大量观测和实验，却尚未来得及系统性总结规律的早期阶段。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526556" data-ratio="1.0787037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVydCiaASeS1zapMI5GD3fd59tlyBCbNQfbbrCiaaw9888j9thmPRNibJJPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3ece9a6d-fcae-45cb-b21a-ced28a27fb4c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们拥有海量的实验数据和强大的模型，却缺乏对底层现象的系统性梳理。他指出，为了追求短期性能指标，AI 领域跳过了「理解」这一关键步骤，这实际上是在背负高昂的「认知债务」。&lt;/p&gt;&lt;p&gt;更为矛盾的是，当前的学术发表机制往往偏爱「完美的故事」或「巨大的性能提升」，导致大量像「第谷的观测记录」那样碎片化但极具价值的「AI 现象学」工作被忽视。&lt;/p&gt;&lt;p&gt;为此，刘子鸣呼吁建立一种「平易近人的现象学」：&lt;strong&gt;不以即时应用为导向，回归到用 Toy Model（玩具模型）进行可控的、多视角的假设驱动探索&lt;/strong&gt;。他宣布将身体力行，通过博客分享「半成品」的实验笔记，并计划在清华大学开设相关课程，邀请社区共同偿还这笔认知债务，推动 AI 从「炼丹」走向真正的物理学。&lt;/p&gt;&lt;p&gt;明星数据科学家 Jeremy Howard 也在评论区表示赞同，长期以来「实验性观察」几乎无法在 AI/ML 期刊和会议上发表，这种现象无疑阻碍了该领域的发展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyfwV2mmL3HK0JibYYJZPjnSVFomHx9k2gDIk8Tasyk1nwxYMDaGR8bng/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526557" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e2b0f798-3a38-431c-aa7a-15f6138ecbef/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 物理学需要思维模式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大家都知道，物理学领域主要沿着「第谷 &amp;mdash; 开普勒 &amp;mdash; 牛顿」这一科研范式发展，而如果借用这一类比来理解 AI 的发展阶段，那么&lt;strong&gt;今天的 AI 研究很大程度上仍然停留在「第谷阶段」，即以「实验与观察」为主的阶段&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;但即便是在「观察」这一层面，业界目前所做的事情也极其原始：大多数人关注的仍然只是少数几个基于性能的指标调优。这背后，源于物理学与 AI 在目标上的根本差异。&lt;/p&gt;&lt;p&gt;物理学的目标是通过「理解世界来改变世界」，其中「理解」本身占据着核心地位。因此，这个领域对那些能够提供洞见即便（暂时）没有实际用途的工作，也具有极高的容忍度。&lt;/p&gt;&lt;p&gt;相比之下，AI 的目标则是「直接改变世界」，近些年 Scaling Laws 的盛行使得整个领域得以跳过「理解」这一阶段，直接进入对 AI 本身进行改造和强化。但这似乎构成了一种&lt;strong&gt;认知债务（cognitive debt）&amp;mdash;&amp;mdash; 这种债务迟早是要偿还的，如果不是现在，那也会是在未来&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，现在就谈论 AI 的「牛顿力学」阶段还为时过早，即使是在基础现象学层面，仍处于非常早期的阶段。AI 的现象学可以是相对宏观的 &amp;mdash;&amp;mdash; 连接不同的模型，例如涌现与 Scaling laws，也可以更微观 &amp;mdash;&amp;mdash; 聚焦于训练动态，例如 Grokking、双下降（double descent）或稳定性边缘（edge of stability）&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;我们首先需要发现更多现象，只有这样，我们才会有动力去建立模型，并发展理论来研究它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么 AI 现象学如此难以发展？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么 AI 现象学的发展如此困难？一个原因是&lt;strong&gt;论文发表文化在其中扮演了重要角色&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;总结来看，当前可发表的工作往往只有两类：在性能上有显著提升的工作（在这种情况下，现象学似乎「没有必要」），或者拥有一个足够吸引人的「故事」。&lt;/p&gt;&lt;p&gt;而所谓「好故事」，通常有两种形式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;普适性（Universality）&lt;/strong&gt;：该现象必须在大量不同设定中都能被验证，稳定性边缘（edge of stability）就是一个例子。但这类工作对投稿的要求极高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;惊奇性（Surprise）&lt;/strong&gt;：现象必须足够反直觉、足够出人意料。这种情况非常罕见，也高度不可预测，grokking 就是代表性案例。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这也解释了为什么 AI 领域中被反复引用的现象学例子如此之少。在「AI 物理学」仍处于如此早期阶段的情况下，却对现象学提出了过高的期望，反而抑制了它的发展。&lt;/p&gt;&lt;p&gt;朱泽园所写的《大语言模型的物理学》是一项非常出色的工作，但从我与朋友们的交流来看，大家普遍的感受是：这很有意思，但不知道如果自己想进入这个领域，该从哪里开始。&lt;/p&gt;&lt;p&gt;同样的情况也出现在我们自己的工作《叠加导致稳健的神经缩放》《 Superposition Leads to Robust Neural Scaling》中。很多人好奇这样的「故事」是如何被构思出来的。&lt;/p&gt;&lt;p&gt;我无法代表整个 AI 物理学领域的整个研究群体，但从个人经验来看，我花费了大量时间去「包装」一个故事 &amp;mdash;&amp;mdash; 这既「浪费」自己的时间，也在无形中拉大了与读者之间的距离。&lt;/p&gt;&lt;p&gt;更重要的是，能够被包装成故事的现象极其稀少。许多我个人觉得非常有趣的现象，因为无法整理成一篇论文，最终只能被随意丢弃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;迈向更易理解的现象学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因此，我倡导一种更易于接近、更具包容性的现象学研究方式。这种方法将比当前的 AI 现象学更宽容，也更接近物理学中现象学的精神。它应当：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不以即时可用性为导向；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不被要求包装成一个完整的「故事」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不限制分析工具，只要它们在描述、预测上是有效的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;同时，它将强调：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可控性&lt;/strong&gt;：使用玩具模型来简化和抽象现实场景，使得结果能够用最少的资源复现（理想情况下，一台笔记本加一个 CPU 就足够了）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多视角刻画&lt;/strong&gt;：从尽可能多的角度和指标来描述研究对象 &amp;mdash;&amp;mdash; 就像「盲人摸象」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;好奇心或假设驱动的探索&lt;/strong&gt;：现象应当能够带来新的洞见，定性结果已经足够，定量结果当然更好。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;这种「可接近的现象学」也许不容易发表在主流 AI 会议上，但它对于社区建设具有极高价值。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;比如，研究者 A 发现了一个现象（关键在于把它公开出来），B 将其与自己此前观察到的现象联系起来，C 将二者统一，D 进行理论分析，E 再将这些洞见转化为算法改进。最终，这五个人可以一起写一篇论文。&lt;/p&gt;&lt;p&gt;但在传统模式下，A 可能只会在一个很小的圈子里合作。就我对 AI 物理学社区的理解，目前这个领域仍然高度碎片化，往往按应用领域分割。例如，做视觉的研究者通常只与其他视觉研究者合作，他们的直觉也主要由视觉任务塑造。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那我们能够做什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就我个人的经验来看，我是先从写博客开始的，开始以博客文章的形式，分享我们自己的「AI 现象学」研究。读者应当抱有这样的预期：这是同事在分享阶段性结果 &amp;mdash;&amp;mdash; 工作可能并不完整，但原始数据和思考过程会被透明地呈现出来。&lt;/p&gt;&lt;p&gt;目标有三点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是迫使自己记录观察结果&lt;/strong&gt;：正如前面所说，无法写成论文的现象往往会被丢弃。这个尝试部分受到苏剑林博客的启发 &amp;mdash;&amp;mdash; 他的博客更偏向数学原理，而我的将更强调实验观察（现象学）、「物理直觉」，以及在必要时提供一些（半）定量分析，为未来的数学研究提供问题和直觉。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;二是吸引志同道合的研究者与学生&lt;/strong&gt;：如果你对这些问题感兴趣，欢迎联系我，一起探索。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;课程准备&lt;/strong&gt;：我计划在清华大学开设一门《Physics of AI》课程。这些博客文章（及配套代码）未来可能会成为课程材料。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么对于你来说，该如何开始：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是找到你真正关心的问题&lt;/strong&gt;：例如，研究扩散模型损失函数的参数化方式，或复现已有现象（如 Grokking）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义一个简单的玩具模型&lt;/strong&gt;：例如，李天宏与何恺明的 JIT 论文使用一个二维螺旋数据集来研究损失参数化。而理解 grokking 的最好方式就是自己亲手训练一个模加任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;致力于彻底理解这个玩具模型&lt;/strong&gt;：这是最困难的一步。由于发表文化的影响，我们往往急于从玩具模型跳到更真实的模型。一旦玩具模型给出了「正向结果」，我们就会立刻离开。这是一种监督式使用玩具模型。而我认为，玩具模型在无监督使用时，才能真正展现其力量。既然是玩具，就应当以孩童般的好奇心去对待它，反复把玩，从所有可能的角度理解它（就像盲人摸象）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，我无法保证这些洞见会立刻转化为性能提升，但我相信：如果整个领域持续积累这样的理解，最终一定会发生一次类似渗流（percolation）的相变。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/ZimingLiu11/status/2006810684546494522&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://kindxiaoming.github.io/blog/2025/physics-of-ai/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>自回归也能做强视觉模型？NEPA开启「下一嵌入预测」时代，谢赛宁参与</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:41:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/80ddf4c3-cd2b-4aaa-9742-a7a969aaff98/1767371980146.png" style="width: 700%;" class="fr-fic fr-dib"&gt;众所周知，LeCun 不喜自回归，并且还提出了一种名为联合嵌入预测架构（JEPA）的新方向，并且该方向也一直在有&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651008220&amp;idx=1&amp;sn=5619349cb36b173f01dd8503866bfea9&amp;scene=21#wechat_redirect" target="_blank"&gt;新成果&lt;/a&gt;涌现。&lt;/section&gt;&lt;p&gt;然而，自回归模型的成功也是有目共睹的，尤其是在语言领域。那么，生成式预训练在自然语言上的成功能否在视觉领域重现呢？&lt;/p&gt;&lt;p&gt;近日，密歇根大学、纽约大学、普林斯顿大学和弗吉尼亚大学的一个联合研究团队对此给出了肯定答案。&lt;/p&gt;&lt;p&gt;只不过，他们不是训练模型输出用于下游任务的特征，而是让它们生成嵌入（embeddings）以直接执行预测任务。可以说，这是从学习表征（learning representations）到学习模型（learning models）的一种范式转变。&lt;/p&gt;&lt;p&gt;具体而言，模型会通过因果掩码（causal masking）和停止梯度（stop gradient），以过去图块嵌入为条件，学习预测未来的图块嵌入。类似于下一 token 预测，该团队将这种方法称为&lt;strong&gt;下一嵌入预测自回归（Next-Embedding Predictive Autoregression）&lt;/strong&gt;，简称&amp;nbsp;&lt;strong&gt;NEPA&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21Tl60htjCibLb86l6ztHwZ5ibu1HPtRBWPOHE1oC0KCzzVxkbV70pJhiaeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2363238512035011" data-s="300,640" data-type="png" data-w="914" type="block" data-imgfileid="503524697" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/28d28fa9-f4b4-4ece-b30b-b39829acf0af/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Next-Embedding Prediction Makes Strong Vision Learners&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.16922v1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址：https://sihanxu.me/nepa/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/SihanXU/nepa&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址：https://huggingface.co/collections/SixAILab/nepa&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该论文目前正是 alphaXiv 上热度第一的论文。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TRNiccU8mL773Yia5o5LyEPiciaTSoQURXJsiaGJZslKh4RYUiczEeJSJ1ZOQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.42592592592592593" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503524703" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/af5e5d14-37e9-4b30-a8a5-3ca1a997ba8d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;本文第一作者为 Sihan Xu，密歇根大学博士生，导师是密歇根大学电气工程与计算机科学系正教授 Stella X. Yu；这项研究的部分工作是其在纽约大学访问期间完成。纽约大学著名研究科学家谢赛宁也在作者名单中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视觉预训练是计算机视觉的核心议题之一。自监督学习也已成为现代视觉预训练方法的基石，使得无需人工标签即可训练可扩展的视觉学习器。&lt;/p&gt;&lt;p&gt;其核心目标是学习表征（learn representations）：优化模型，从而将原始像素映射到固定维度的表征，这些表征随后可被使用或针对下游任务进行微调。&lt;/p&gt;&lt;p&gt;这一哲学统一了基于实例判别（instance discrimination）、自蒸馏（self-distillation）和掩码重建（masked reconstruction）的方法。&lt;/p&gt;&lt;p&gt;其目标是学习能够被各种规模的下游模块（从轻量级的特定于任务的头到诸如视觉 - 语言模型等大型级联系统）所使用的视觉表征。&lt;/p&gt;&lt;p&gt;现代自然语言处理的成功则建立在一个根本不同的范式之上。&lt;/p&gt;&lt;p&gt;语言模型的预训练目标并不是作为特征提取器；而是作为生成式和预测式系统。其目标不是生成句子的静态嵌入，而是通过一个简单的因果目标（causal objective）对数据分布本身进行建模。&lt;/p&gt;&lt;p&gt;这种训练会迫使模型内化语言中的语义和条件依赖关系。推理不再是一个「编码&amp;rarr;解决任务」的两阶段过程，而是由模型本身执行的单一预测计算。&lt;/p&gt;&lt;p&gt;这一区别至关重要，涉及根本。它表明：&lt;strong&gt;生成式预测&lt;/strong&gt;（而非表征学习）可能提供了一条扩展预训练的直接途径。&lt;/p&gt;&lt;p&gt;最近的一系列研究已经转向了这一哲学。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;早期的像素级生成式预训练（iGPT）展示了可迁移的特征，但在处理超长序列和弱语义对齐方面表现一般。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;JEPA 超越了像素层面，通过预测潜在目标（latent targets）来更紧密地与语义结构对齐。然而，JEPA 依然是通过从动量编码器（momentum encoder）回归到潜在目标来进行训练，而不是将生成式预测作为自监督目标。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于这些观察，Sihan Xu 等人想知道：&lt;strong&gt;极简的因果预训练是否也能产生强大的视觉学习器。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体来说，图像被分解为图块（patches），这些图块再被映射为图块级嵌入的序列。然后训练一个因果 Transformer，在给定所有先前嵌入的情况下预测下一个嵌入，这与语言模型中的「下一 Token 预测」范式非常近似。&lt;/p&gt;&lt;p&gt;基于这些观察，Sihan Xu 等人想知道：极简的因果预训练是否也能产生强大的视觉学习器？&lt;/p&gt;&lt;p&gt;具体来说，图像被分解为图块（patches），这些图块再被映射为图块级嵌入的序列。然后训练一个因果 Transformer，在给定所有先前嵌入的情况下预测下一个嵌入，这与语言模型中的「下一 Token 预测」范式非常近似。&lt;/p&gt;&lt;p&gt;该团队对目标嵌入使用停止梯度（stop-gradient）以创建一个稳定的预测任务。这种形式是刻意保持极简的。它不需要像素级解码器、不需要离散的视觉 Tokenizer（分词器），也不需要对比学习中常见的工程化数据增强、负样本对或动量编码器。整个学习信号源于模型在嵌入空间中预测未来的能力。&lt;/p&gt;&lt;p&gt;于是乎，一个新的模型家族诞生了：&lt;strong&gt;下一嵌入预测自回归（NEPA）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一嵌入预测自回归（NEPA）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;整体来看，NEPA 方法是极简主义的。如果说现在的视觉模型都在比拼谁的装备更复杂（动量编码器、解码器、离散 Tokenizer&amp;hellip;&amp;hellip;），那么 NEPA 就是那个穿着白 T 恤走进战场的选手。它的核心哲学非常简单：像 GPT 预测下一个词那样，去预测图像的下一个「特征块」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TnFonJO3BcWgtt1mEpJI5DBeeqUUkTyo2BuOib64hOK3m7uPECYrXDJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8323494687131051" data-s="300,640" data-type="png" data-w="847" type="block" data-imgfileid="503524698" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/41714c99-1adc-47cd-98b3-3808c4d9b098/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其核心思路可以总结如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;切块与编码：首先，把一张图切成若干小块（Patch），每一块通过编码器变成一个向量（Embedding）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;预测未来：观看前面的块，猜下一块长什么样。这和语言模型（LLM）的「下一词预测」相似，只不过这里处理的是连续的数学向量，而不是离散的词。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;防止「作弊」：为了防止模型偷懒（比如输出一样的结果），作者借用了 SimSiam 的经典招数：&lt;strong&gt;停止梯度（Stop-Gradient）&lt;/strong&gt;。简单说，就是让作为「标准答案」的那个目标向量保持静止，不参与反向传播。这就像是射箭时，靶子必须固定，不能让你把靶子移到箭射中的地方。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;具体到架构设计上，他们采用了一个带有因果注意力掩码的标准视觉 Transformer（ViT）主干网络。&lt;/p&gt;&lt;p&gt;与像素级重建方法不同，该方法不需要单独的解码器。该 Transformer 直接根据过去的图像块嵌入来预测未来的图像块嵌入，使用单个主干网络同时进行上下文编码和预测，这与自回归语言模型类似。图像通过一个二维卷积（Conv2d）图像块嵌入层被分割成不重叠的图像块，并在输入到 Transformer 之前添加可学习的位置嵌入。&lt;/p&gt;&lt;p&gt;他们采用了带有层归一化（LayerNorm） 的预归一化设计，并对输出特征应用最终的层归一化。&lt;/p&gt;&lt;p&gt;为了提高稳定性和可扩展性，该团队该结合了受 DINOv3 和视觉大语言模型 VisionLLaMA 启发的现代训练和归一化方法，如图 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TvtynlmVyjdNbnUQJ8cBTcj2znKrDxX3DxonMB9WG0443Tv13ibs5p9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0035545023696681" data-s="300,640" data-type="png" data-w="844" type="block" data-imgfileid="503524699" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/72fe0ab4-3387-49b0-8b9f-11d165f64048/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些模型设计有助于训练，但与核心框架无关，感兴趣的读者可参阅原论文以及相关论文。&lt;/p&gt;&lt;p&gt;训练好之后怎么用呢？换个「头」就行。下面是两个例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分类&lt;/strong&gt;：取出最后一个预测出来的嵌入向量，接个简单的分类头，就能识别这是猫还是狗。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分割&lt;/strong&gt;：接一个 UPerNet 头。有趣的是，虽然训练时是「只看过去」的单向预测，但在做分割这种需要全局信息的任务时，可以解除封印，开启双向注意力（Bidirectional Attention），让模型看清全图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总之，NEPA 证明了，只要你有一个好的预测目标，就不需要那些花里胡哨的架构，一个标准的 Transformer 加上「防坍塌」技巧，就能成为顶级的视觉学习者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在量化性能方面，NEPA 展现出了与 SOTA 方法相媲美甚至更优的实力。&lt;/p&gt;&lt;p&gt;仅在 ImageNet-1K 上进行预训练，NEPA 的 ViT-B 和 ViT-L 模型分别达到了 83.8% 和 85.3% 的 Top-1 准确率，这一成绩优于 MoCo v3、BEiT，并与 MAE 和 JEPA 处于同一水平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TRVLkoJYcxnpXAFBjofpDlROJ65l161AHn76pdtdbHibcuReFAY2g9qw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.44351851851851853" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524701" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d52d992f-c7c5-4b3b-bfe6-12fbfc5ecb2f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更重要的是，尽管预训练过程中从未涉及像素重建，NEPA 依然表现出了强大的迁移能力，在 ADE20K 语义分割任务上分别取得了 48.3% 和 54.0% 的 mIoU，证明了纯粹的嵌入预测足以学习到处理密集预测任务所需的丰富语义特征。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TqmjpE8gia2aXTDSOP3ozkNXXNEzeVyfeaT1AFZWjGDics64ibs0rT8Ribw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524700" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d7f40ce3-acf1-4cbd-a058-94a2c8b4e43c/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;最后，通过对模型内部注意力和嵌入的可视化分析，研究揭示了 NEPA 的有效性来源。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TUjhgpVP5uuXGIF9ib4S3NaJQibG5p9gjibibE68m8LetLCC7ArVc0lP2yQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524702" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/4a62b361-b7fd-4da0-b006-45d9c7eb1bd5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可视化结果显示，模型自动学会了长距离且以对象为中心的注意力模式，能够忽略背景干扰，将注意力集中在语义相关的区域。同时，预测出的嵌入向量在语义上与属于同一物体的其他图块高度相似，表明模型并非死记硬背局部纹理，而是真正理解了物体层面的结构。&lt;/p&gt;&lt;p&gt;这种通过简单的「下一嵌入预测」所习得的全局语义依赖，不仅验证了该方法的有效性，也为跨模态的统一预训练范式提供了一种无需复杂手工设计的通用视角。&lt;/p&gt;&lt;p&gt;消融实验和更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>「辍学创业」的风再次席卷硅谷，但真正的变量从来不是学位</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:37:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/94b1d6ec-0ad2-491f-94f9-bba80473d27e/1767371655483.png" style="width: 700%;" class="fr-fic fr-dib"&gt;在 80、90 后的成长记忆里，「辍学创业，成为亿万富翁」这类故事流传甚广。&lt;/p&gt;&lt;p&gt;理性分析后都知道，这里面有幸存者偏差，也有个体差异 &amp;mdash;&amp;mdash; 盖茨、扎克伯格都是哈佛级别，随时能回去拿学位；乔布斯也没有完全离开校园，而是以旁听生的身份自由选课。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyyJ0DGHyShpDgwP0zscmCDdlEkOeibPNtbOiamcIbpVeAa8bPibHFqhm9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526545" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/96c6c54c-7ad5-4924-ae5d-b4c362922ede/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但没想到，最近，这股风又刮回来了。在硅谷，「辍学创业」正成为一个值得强调的正向标签。&lt;/p&gt;&lt;p&gt;这一趋势在 Y Combinator 的 Demo Day 上体现得尤为明显：越来越多的创始人在一分钟路演中主动强调自己的辍学身份。&lt;/p&gt;&lt;p&gt;Moxxie Ventures 创始人兼普通合伙人 Katie Jacobs Stanton 表示：「据我所知，YC 并未正式追踪辍学数据，但从近几批学员的情况来看，有太多创始人会特意强调自己从大学、研究生院甚至高中辍学的经历。辍学本身已成为一种资历，体现出创业者对事业的坚定信念和投入。我认为在风投圈，这被视为相当正面的特质。」&lt;/p&gt;&lt;p&gt;这些人的辍学动机不难理解：留在学校完成学业，可能意味着错过 AI 创业周期中最关键的窗口期。创办 Scale AI 的 Alexandr Wang、Lucy Guo 就是其中代表。&lt;/p&gt;&lt;p&gt;一位投资人表示，「大家普遍有一种紧迫感，或许还有错失恐惧症（FOMO）。现在的算盘很简单：要么完成学业，要么直接开始做产品。」&lt;/p&gt;&lt;p&gt;这种焦虑正催生极端案例。一位顶尖大学的教授近期透露，一名学生在最后一个学期放弃了学位。这位学生深信，拥有文凭反而会降低他获得融资的机会。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVydCwPkHBlP50wiaKI2icZxkduWicCyeqb7bamE8CjdIuzV5ceR6kibp6Brw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526546" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d5a1318d-a0db-4380-9c0d-189cf2b78241/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不过，也有投资人认为市场并没有如此极端。负责 General Catalyst 种子轮投资策略的 Yuri Sagalov 表示，风投其实没那么执着于「辍学」这个标签，尤其是对于即将毕业的学生：「对于大四才辍学的人，我从来没觉得他们和顺利毕业的人有什么本质区别。」&lt;/p&gt;&lt;p&gt;Sagalov 认为，即便是技术天才能够在没有正规教育的情况下创业，大学提供的社交网络和学校品牌仍然具有价值 &amp;mdash;&amp;mdash; 即使创始人最终没有拿到文凭。他说：「你依然能获得大部分社交价值&amp;hellip;&amp;hellip; 因为你可以标注自己曾就读于那所学校。大多数人在 LinkedIn 上看你的履历时，并不会太在意你是否真正毕业。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyPmsyjDBVL2WmIuS1yhFQW75qq6NvibqS1mfZE0lDRMO9D6ZFtZhFibrQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0333333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526547" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/76a11474-9b4a-49a8-92db-7f54d3db19e3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;尽管如今许多投资人认为创业者可以不要大学文凭，但并非所有风投都认同年轻创始人在当前市场具有优势。FPV Ventures 联合创始人 Wesley Chan 对投资辍学者并不那么热衷，因为他更看重一种大多数年轻创始人尚未具备的特质：智慧。Chan 认为，这种智慧通常存在于「更年长的创始人，或那些经历过挫折、身上带着伤疤的人」身上。&lt;/p&gt;&lt;p&gt;当然，需要指出的是，尽管许多引领 AI 浪潮的创始人都是年轻人，但大多数仍然选择完成学业。例如，Cursor 的 CEO Michael Truell 毕业于 MIT，而 Cognition 的联合创始人 Scott Wu 则毕业于哈佛大学。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVykyrFvXUtQZxytX4RdVrMeiaR2gOS1VkzgbbUyCVgx9j0psnZWQA5M5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526548" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/dba2aef9-242e-405e-b9ae-fa8f15f3bbc6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyaG0YpZk6e5k73wrwQ86KxPyssgqwvot9lu5SqPElia9zxNG3T0U1QMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.36018518518518516" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526549" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4086ffd1-e465-438a-95b5-51a2bee59aaf/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;也有人指出，今天所说的「辍学」其实和早些年已经完全不一样了，那些「辍学」的人只是换了个地方，还是继续做原来的事情，而且是在资源更丰富的工业实验室。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyTSTXvcR5pvthe36ibVG9ib0jyK2hWymZWkx83sPS0k2IzJRSL8VzHxQQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.387037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526550" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/689ebafe-794b-4636-8e9b-4aac28483f45/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;所以归根结底，「辍学」永远只是表象。真正决定成败的，是创始人能否在正确的时间窗口、用正确的资源、做正确的事。无论是拿着文凭走出校门，还是中途转身投入创业，学位从来都不是核心变量 &amp;mdash;&amp;mdash; 能力、判断力、时机，以及能否接入真正有价值的人脉和资源网络，才是。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://techcrunch.com/2025/12/31/college-dropout-has-become-the-most-coveted-startup-founder-credential/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让模