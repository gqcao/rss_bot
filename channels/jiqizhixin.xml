<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>流动匹配重塑分子生成：PropMolFlow 实现性质引导下的高保真三维分子设计</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Mon, 26 Jan 2026 10:22:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-26</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-26</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;在生活、研究之中，我们触手可及的每一个物品，无论是可见或是不可见，组成它的化合物，在最初都只是分子猜测。在数目庞大的备选库中，找到合适的组合满足需求，这种费时费力的劳动在 AI 的帮助下已经渐渐成为了历史。&lt;/p&gt;&lt;p&gt;流匹配方法近年来在无条件分子生成领域取得了领先（SOTA），超越了基于分数的扩散模型，但它还无法满足在属性引导方面的需要。&lt;/p&gt;&lt;p&gt;来自佛罗里达大学（University of Florida）与纽约大学（New York University）等的团队开发出一种新方法&amp;nbsp;PropMolFlow，它结合了五种不同的性质嵌入方法，能够以约 10 倍速度生成分子候选物，且不影响结果的准确性和化学效度。&lt;/p&gt;&lt;p&gt;相关研究内容以「PropMolFlow: property-guided molecule generation with geometry-complete flow matching」为题，于 2026 年 1 月 22 日发布在《Nature Computational Science》。&lt;/p&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s43588-025-00946-y&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重写生成路径&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;PropMolFlow 构建在&amp;nbsp;FlowMol&amp;nbsp;架构之上，通过对 NN 参数化的条件速度场积分生成样本。在这一框架中，模型不再学习逐步去噪，而是&lt;strong&gt;直接学习一个时间连续的速度场&lt;/strong&gt;，描述分子从初始噪声分布演化到目标分布的全过程。&lt;/p&gt;&lt;p&gt;这其中大致可分为三点：&lt;/p&gt;&lt;ol start="1"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;SE(3) 等变的速度场建模&lt;/strong&gt;&amp;nbsp; 模型在原子坐标与特征空间中构建严格满足旋转、平移等变性的向量场，确保生成过程中几何一致性不被破坏。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;性质条件作为状态变量嵌入流场&lt;/strong&gt;&amp;nbsp; 与&amp;ldquo;后验引导&amp;rdquo;不同，性质向量被直接作为条件输入参与速度场预测，意味着&lt;strong&gt;性质在每一个时间点都影响分子演化方向&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;确定性推理路径&lt;/strong&gt;&amp;nbsp; 流匹配允许使用常微分方程（ODE）求解，生成过程不再是随机采样，而是稳定、可控的连续演化。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在所有结构指标上，PropMolFlow 始终优于基线模型。由于流动匹配路径更短且具有确定性路径且传输最优，PropMolFlow 只需 100 步就能完成所需任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;QM9 数据集测试&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队认识到，如果生成的分子在化学上无意义或未达到目标特性&amp;mdash;&amp;mdash;即满足特定需求的所需特性&amp;mdash;&amp;mdash;速度是无用的，因此他们通过与其他模型比较来测试 PropMolFlow 的准确性。&lt;/p&gt;&lt;p&gt;他们将重点放在对 PropMolFlow 生成的，具有靶向性质、分子结构效度和推断速度分子的能力上。团队主要通过使用密度泛函理论验证生成分子，这是一种基于物理的量子化学方法，能够从基本原理计算分子性质&amp;mdash;&amp;mdash;独立于任何机器学习模型。&lt;/p&gt;&lt;p&gt;表 1：PropMolFlow 在属性比对方面的性能。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLmFicnqVlYiaoFLrJia2Siab4tmoYhpAeF4vEXVUIQAUlluStib6gVO1Ksiaepo4HpnibRwa7Uggwzqpk6lA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5932432432432433" data-type="png" data-w="740" data-width="740" data-height="439" data-backw="546" data-backh="324" data-imgfileid="100027239" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/91573aac-1e35-44a3-b1ae-ce1b048406e4/640.png" alt="图片" data-before-load-time="1769394096676" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;PropMolFlow 在与 SOTA 模型竞争中取得了良好的表现。据相关报道，PropMolFlow 生成的分子具有正确的键模式和合适的几何形状，超过90%。同时，PropMolFlow能够实现科学家所追求的分子性质，在多种分子性质上表现优于现有最佳方法，且计算速度更快。&lt;/p&gt;&lt;p&gt;此外，论文中还提到，当目标性质偏离训练分布时，扩散模型往往出现构型塌缩，而 PropMolFlow 的结构统计分布仍与真实分子高度一致。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;利用性质引导的分子生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;凭借在几分钟内生成数千个化学有效、针对性质的候选物的能力，研究人员可以更快地进行迭代。PropMolFlow 展现的速度与精度结合更能突显产物的强性质比对性，其外推能力也可借由主动学习或强化学习框架来进一步提升。&lt;/p&gt;&lt;p&gt;不过，目前 PropMolFlow 还无法保证它的产物具有足够的稳定性。团队表示，包括上述问题在内的挑战，已经在尝试引入新技术解决。在当前分子生成模型逐渐走向真实设计场景的背景下，这种&lt;strong&gt;结构&amp;mdash;性质&amp;mdash;效率同时成立&lt;/strong&gt;的系统，具备继续向前扩展的价值。&lt;/p&gt;&lt;p&gt;相关报道：&lt;em&gt;https://phys.org/news/2026-01-scientists-molecules-discovery.html&lt;/em&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谷歌、Anthropic双重围剿下的OpenAI，正面临「生死抉择」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 25 Jan 2026 21:17:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-25-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-25-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;进入到 2026 年，OpenAI 在关注消费级产品（如 ChatGPT、社交应用）之外，开始将一部分重心转向企业级市场。&lt;/p&gt;&lt;p&gt;上周五，我们报道了 OpenAI 正在考虑转变商业模式，不满足于只收软件使用费，还想在客户发财时抽成。详细内容请参考《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651013577&amp;idx=1&amp;sn=36d7bce9f141ffe8af118b85aba6af22&amp;scene=21#wechat_redirect" target="_blank"&gt;OpenAI：以后大家用 AI 赚的钱，我可能要抽成&lt;/a&gt;》&lt;/p&gt;&lt;p&gt;今日，据外媒 The Information 最新报道，OpenAI 传递出了清晰的战略转型信号，表明其正全方位发力企业端业务，力求为商业客户提供深度支持。&lt;/p&gt;&lt;p&gt;事情是怎样的呢？我们接着往下看。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;OpenAI 战略重心转移，进一步押注企业市场&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去的 2025 年，OpenAI 最引人注目的动作大多集中在消费级产品上，包括 GPT‑5 系列模型、Sora 2、ChatGPT Atlas 浏览器等。今年晚些时候，OpenAI 预计还将发布一款由前苹果设计总监 Jony Ive 参与设计的 AI 硬件设备，据悉可能是可穿戴设备。&lt;/p&gt;&lt;p&gt;不过就在上周，OpenAI CEO 奥特曼在旧金山召集了一场由迪士尼 CEO 鲍勃・艾格及其他企业高管参与的聚会，传达出了进一步服务企业用户的意向。&lt;/p&gt;&lt;p&gt;据一位知情人士透露，奥特曼告诉与会者，&lt;strong&gt;OpenAI 可以成为满足他们所有 AI 需求的一站式商店，从对话机器人 ChatGPT 到编程工具 Codex，再到自动化工作流模型。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;另一位知情人士表示，此次聚会还旨在&lt;strong&gt;预热 OpenAI 专门针对大型公司的一项新方案，协助它们进行大规模的 AI 转型&lt;/strong&gt;，将 AI 整合进客户服务、旧应用代码改写、企业数据组织等各类业务运营中。&lt;/p&gt;&lt;p&gt;此外，这项新方案还旨在统一企业的 AI 使用力度，其中可能包括将 OpenAI 的各种产品打包，以便企业客户更轻松地追踪其开支。不过，相关具体细节尚未披露。&lt;/p&gt;&lt;p&gt;OpenAI 在企业市场展开的更多动作，其背后&lt;strong&gt;希望将企业客户从劲敌 Anthropic 手中争取过来&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;过去一段时间，Anthropic 的编程和办公自动化工具 Claude Code 以及 Cowork 引起了业界的广泛关注。&lt;/p&gt;&lt;p&gt;去年推出的 Claude Code，具备强大的编写和修改代码的能力。据一家每月在 OpenAI 和 Anthropic 上投入数百万美元的初创公司 CEO 称，对某些客户而言，这比员工用于常规任务和搜索的聊天机器人更能提高生产力。&lt;/p&gt;&lt;p&gt;最新产品 Cowork 掀起了一场打工人的革命。它不再像 Claude Code 一样专门面向程序员，而是把大模型与智能体能力推进到电脑桌面上，可以解决大部分人的工作问题。&lt;/p&gt;&lt;p&gt;相反，OpenAI 的某些产品（如处理电子表格等知识工作的智能体）表现未能达到预期。&lt;/p&gt;&lt;p&gt;就在昨天，奥特曼发推表示：「从下周开始的接下来一个月，我们将会发布很多与 Codex 相关的激动人心的东西。」这预示着 OpenAI 对标 Claude Code 的编程工具即将迎来升级。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9iaziaQArglnPrOia8eiblrgo6iaUpShLicSugwkG4VmTrn1cFOIXgA24DYFfNhh0B9WEJRVlGNibEquAHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.6698872785829308" data-s="300,640" data-type="png" data-w="621" type="block" data-imgfileid="503530006" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/402153f6-210a-4c87-8beb-8d19b8275817/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;OpenAI 也一直在为 ChatGPT 添加协作以及其他更多办公功能，并推出了针对特定行业的垂类产品，比如医疗的 ChatGPT Health。&lt;/p&gt;&lt;p&gt;与此同时，OpenAI 在过去一年还重组了销售模式：由一名销售人员向客户推销多种产品，而非由多名代表分别推销不同的产品。前段时间从 Thinking Machines Lab 挖回来的顶级人才 Barret Zoph 将专门负责面向企业客户的 AI 商业化业务，以期占领更多企业市场。&lt;/p&gt;&lt;p&gt;目前，OpenAI 约 40% 的收入来自企业客户。OpenAI CF Sarah Friar 周三在达沃斯表示，&lt;strong&gt;到今年年底，约 50% 的业务将来自企业客户。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生成式 AI 流量：从一家独大到群雄逐鹿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 发力企业市场的另一大原因，是其自身生成式 AI 的流量面临着谷歌 Gemini 等其他大模型竞品的紧紧追赶。&lt;/p&gt;&lt;p&gt;今天，有 X 博主发帖称，「谷歌迟早会抢光 OpenAI 的饭碗，而且速度会比人们想象的还要快。奥特曼这下麻烦大了。」&lt;/p&gt;&lt;p&gt;这位博主展示了一张出自 Similarweb 的生成式 AI 流量份额的变化趋势图表，直观地反映出了该领域正从「一家独大」走向「群雄逐鹿」。&lt;/p&gt;&lt;p&gt;我们首先看到，&lt;strong&gt;OpenAI 的领先地位正在被蚕食&lt;/strong&gt;。12 个月前，OpenAI 占据绝对的市场统治地位，份额接近 90%。随着时间推移，其份额持续下降，到现在已经降至 65% 左右。虽然它仍然保持第一，但市场份额一路走低。&lt;/p&gt;&lt;p&gt;其次，&lt;strong&gt;谷歌 Gemini 成为最大的挑战&lt;/strong&gt;者。12 个月前，它的存在感还非常低，但现在的份额已经跃升至第二位，占据了约 20% 的市场。这说明，谷歌正在凭借其强大的生态集成能力迎来爆发式增长，并迅速抢占流量份额。&lt;/p&gt;&lt;p&gt;接着是&lt;strong&gt;第二梯队的崛起&lt;/strong&gt;，包括 DeepSeek、Meta、Claude、Perplexity 和 Grok ，虽然单拎出来份额较小，但它们也在稳步蚕食原本属于 OpenAI 的空间。&lt;/p&gt;&lt;p&gt;最后是更多垂直领域的工具加入竞争，包括 Manus、Huggingface 等，用户有了更多样性的入口选择。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9iaziaQArglnPrOia8eiblrgo6ocDRXw70Q1oAByHzk6YCrdsciabMwvoZNMiaibFQ2yyLTaDprnicUt60zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.0212962962962964" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530009" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/afe3ee60-5e5c-4998-bc36-45ebc1c67355/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在评论区，还有人指出了更多问题，包括高净值客户的流失，「从客户价值的角度来看，OpenAI 其实处于垫底水平。相比之下，大多数 Claude 用户每个月的开销都在 200 美元左右。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9iaziaQArglnPrOia8eiblrgo68HxQFrgWEibNyx9ibrNAMukhDhBmCBRBBRZq29WwU2icwhA8NPfTuPwKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.4564814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530010" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/21d4282e-31fe-4272-9a04-f1c163f799c9/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;在同样出自 SimilarWeb 的另一张图表中，展示了 2025 年&lt;strong&gt;各大模型厂商的每月独立访客（MUV）的增长数据，以及市场渗透率变化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其中 ChatGPT 每月独立访客（MUV）增长达 3060 万，渗透率从 1 月的 71% 增长到 11 月的 77.3%；谷歌 Gemini 增长了 1420 万月活， 渗透率从 15.1% 跃升至 24.2%，增幅最大；Grok 渗透率也从 0.2% 飙升至 6.7%；Claude 的 MUV （320 万）和渗透率（5.3%）也在稳步增长。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9iaziaQArglnPrOia8eiblrgo6eeI5pfx16AfZypyqfic510Coj3FP4aOlGVUEG4icsqyO4ibxynCwa5ELw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.4490740740740742" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503530011" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e8d6bc2a-12b7-4706-8427-7ff5f3d43fff/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;一方面是流量红利消退，一方面要面对谷歌、Anthropic 等强劲的竞争对手，OpenAI 似乎走到了不得不转型的十字路口。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.theinformation.com/articles/openai-aims-lure-businesses-anthropic?rc=jn0pp4&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/venturetwins/status/2014739492389978274&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Mayhem4Markets/status/2015172827289161992&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>没博士没论文，这些人靠什么「野路子」杀进OpenAI等顶级AI大厂？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 25 Jan 2026 21:14:33 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-25-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-25-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文&lt;/section&gt;&lt;p&gt;许多人梦想进入像 OpenAI 这样的前沿实验室从事研究工作，然而对于那些缺乏传统学术背景，比如没有发表过论文或知名导师推荐的人来说，这条路似乎格外艰难。&lt;/p&gt;&lt;p&gt;最近，OpenAI 资深研究科学家 Noam Brown 在 X 上分享了几个真实故事，证明了通过个人努力和巧妙策略，即使没有传统学术履历，也能获得机会。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Keller Jordan：从改进他人论文开始&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Keller Jordan 从加州大学圣地亚哥分校毕业时，简历上没有任何论文发表记录。当时他在一家做 AI 内容审核的初创公司工作。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadibNAfgkH2UeT1xZwXuhSicN0I5wC50ia8OvcvhxRcR5iao35AAeT2Ip4OQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1" data-type="png" data-w="400" data-width="400" data-height="400" data-imgfileid="503529701" data-aistatus="1" data-original-style="width:206px;height:206px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/accaad7e-6df6-4b77-89dc-a13c87a18cca/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;按照常规路径，想进入 OpenAI 这样的顶尖实验室，至少需要名校博士学位，外加几篇顶会论文，最好还有业内知名学者的推荐，而 Keller 什么都没有。&lt;/p&gt;&lt;p&gt;但他做了一件关键的事，主动联系了当时在谷歌工作的研究员 Behnam Neyshabur，向对方展示了一个改进其最新论文的想法。这次「冷接触」获得了积极回应。Behnam 同意指导他，最终合作完成了一篇 ICLR 论文。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadtDTNAdQ4hyePTtRyFBuSF8T0CUUnzFygqtbmQHKLdezyr31Y97t0CA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8542056074766355" data-type="png" data-w="1070" data-width="1070" data-height="914" data-backw="578" data-backh="494" data-imgfileid="503529702" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e2c2b4c2-cf28-47f4-9730-c03ce685e0bc/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Noam Brown 在帖子中强调，如今 AI 研究越来越封闭，公开项目越来越少，但「改进他人已发表的工作」仍是展示个人能力的绝佳方式。这种方法能让实验室内部人士看到你的潜力，并愿意为你争取面试机会。&lt;/p&gt;&lt;p&gt;然而，Keller 真正吸引 OpenAI 注意的，是他发起的 NanoGPT speed run 项目。这个项目基于 Andrej Karpathy 的 nanoGPT 框架，旨在优化训练一个 124M 参数的 Transformer 模型，以达到特定验证损失目标，同时最大化 token 利用效率。&lt;/p&gt;&lt;p&gt;GitHub 地址：https://github.com/KellerJordan/modded-nanogpt&lt;/p&gt;&lt;p&gt;Keller 将所有工作公开文档化，包括代码、实验过程和结果测量，这在社区中引起了广泛关注。Andrej Karpathy 在社交媒体上转发了这个项目，并称赞「干得漂亮」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadJcuPK1cqrsoSqibn0WNBSm5lcYcjqHp761ctpEjtn7x7F8QmiclNeGDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6850094876660342" data-type="png" data-w="1054" data-width="1054" data-height="722" data-backw="578" data-backh="396" data-imgfileid="503529703" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/8eda64d9-b838-45e4-92bf-2fb8213075e9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;正如 Chayenne Zhao 所说，「别再问怎么才能在 OpenAI 找到工作了，直接开始宣传你的成果吧。Keller 没等什么许可，他直接打破了纪录，让人无法忽视。只有当你拥有真正可扩展的工作成果时，陌生邮件才有效。如果你没有公开开发项目，没有追求效率记录，你在这个市场里就不存在。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadENWV64a9YUT8J0hcXUPFYfgy36RImVic4wuXcevCQH9dHXRL6XnU9zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.31368821292775667" data-type="png" data-w="1052" data-width="1052" data-height="330" data-imgfileid="503529704" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1752d973-eb94-4bb0-b775-a0b870fed320/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Sholto Douglas：一个GitHub提问成敲门砖&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;类似成功并非孤例。Sholto Douglas 原本在麦肯锡工作，但坚信 AI 将会爆发，于是开始利用业余时间做自己的 AI 项目。每天晚上 10 点到凌晨 2 点，他都在进行独立研究。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadY7AETxcRAISBdcsdzp9f5dvmKWrIag06VeMXQKWswTFaTtX1wibUnzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.19238095238095237" data-type="png" data-w="1050" data-width="1050" data-height="202" data-backw="578" data-backh="111" data-imgfileid="503529705" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b9c3f438-ba93-4ab2-ab2d-2d891661a3fd/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他在 JAX 的 GitHub 上提出的深刻问题引起了谷歌工程师 James Bradbury 的注意。Bradbury 后来回忆：「我以为我认识世界上所有会问这些问题的人，你到底是谁？」这个意外的发现为 Sholto 赢得了 Google DeepMind 的面试机会。&lt;a href="https://mp.weixin.qq.com/s/bkTWmDObs4jdKsFRvOtQMg"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/10a4838a-1cd8-45c1-8486-d5ca052bc8c4/1769346788405.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Sholto 在 X 上并不活跃，也没有什么亮眼的第一作者论文，进入 AI 领域仅一年半左右，但业内人士都知道他是 Gemini 成功背后最重要的人物之一。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadBKcc7WmjtX2iaEUe7ib8GwyOqSd6dEftFyzbN3dksBJBQs33U55v6uqA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.2704761904761905" data-type="png" data-w="1050" data-width="1050" data-height="284" data-backw="578" data-backh="156" data-imgfileid="503529710" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/81df8c6f-7a1b-42da-8a58-3f82f26ac82f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这印证了 Karpathy 的一个观察：真正改变 AI 的人往往隐藏在组织深处，他们不活跃于社交媒体，不上播客节目，甚至可能不再发表论文，但他们正在直接发明和构建奇迹。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadYB7szcFQRiczwcZBz0PEtcWj6ssm6VvIeGdbMsV2zEcHn1LZn9sxSYQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3880597014925373" data-type="png" data-w="1072" data-width="1072" data-height="416" data-backw="578" data-backh="224" data-imgfileid="503529711" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/d6aefbc5-5cc9-4229-9ae7-a5a58c59aebe/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Andy L. Jones：一篇自发表论文打动Anthropic&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Andy L. Jones 是一位半退休的量化交易员，他写了一篇论文，比较预训练规模和测试时计算规模的影响，这还是在测试时计算没火起来之前。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadjXR4ZERs53C8sDxJfPo2QoiaQak3XOLlaeqW4cVu3kUxAQqdfmRCflg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1" data-type="png" data-w="400" data-width="400" data-height="400" data-imgfileid="503529712" data-aistatus="1" data-original-style="width:208px;height:208px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/29a92f7f-99bc-4ddd-8ca5-064302b5b565/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;xAI 联合创始人 Igor Babuschkin 专门发帖表示，他不断回顾 Andy L. Jones 的精彩论文《Scaling Scaling Laws with Board Games》，说它展示了 MCTS 训练计算量与推理计算量之间相互权衡，增加 10 倍的 MCTS 步骤几乎等同于 10 倍的训练量。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadyWzpszAViaV2Lrs3b9a1CQc5iaTtBMTnd9lol0Fuj30uAiaj3Vkzcag5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.0472589792060492" data-type="png" data-w="1058" data-width="1058" data-height="1108" data-backw="578" data-backh="605" data-imgfileid="503529713" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/69618fe9-e993-41cc-8094-01ac85a0ae96/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Noam Brown 指出，这篇论文的亮点不在于它在某个基准测试上达到了最先进的性能，而在于 Andy 做出了聪明的设计选择，编写了 GPU 加速的环境，并进行了仔细的消融实验。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadlziaiaicZtzDSekVaEtmlofZJmuuBGvylNptaCC10eYyCb4nvCSCLcMvg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3783783783783784" data-type="png" data-w="1036" data-width="1036" data-height="392" data-backw="578" data-backh="219" data-imgfileid="503529714" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/48c1b6e6-d674-4005-aed6-816a314d8f15/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2104.03113&lt;/p&gt;&lt;p&gt;更重要的是，他选择了自行发表。现在，Andy 已经加入了 Anthropic。&lt;/p&gt;&lt;p&gt;这也说明，论文的质量远比发表的地方重要。如果你的工作设计巧妙、实验严谨、见解独到，即便是自行发表也能得到认可，顶尖实验室的招聘者看重的是解决问题的能力和研究的深度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Kevin Wang：本科生也有机会，但标准很高&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 等实验室也会直接从本科生中招聘研究员，但门槛确实很高。&lt;/p&gt;&lt;p&gt;Kevin Wang 就是一个例子。他获得了导师的强烈推荐，并且是 NeurIPS 2025 一篇论文的第一作者。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadVTtVh7gqHXXRKlonZciaSGdIQMkWYcaSiaWrRGImeQaHkPkldyXibpmOA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="1" data-type="png" data-w="400" data-width="400" data-height="400" data-imgfileid="503529715" data-aistatus="1" data-original-style="width:228px;height:228px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/6c6a04e5-605d-4437-937a-325e730eb81c/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Noam Brown 坦言，NeurIPS 上有很多质量一般的论文，但他们能看出 Kevin 这篇是真正优秀的。事实证明，Kevin 加入 OpenAI 后，他的论文从 5290 篇投稿中脱颖而出，成为仅有的 4 篇最佳论文之一。&lt;/p&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2503.14858&lt;/p&gt;&lt;p&gt;Noam Brown 特别提到，导师的推荐在这里起了很大作用，因为仅凭简历甚至论文来评估一个研究者的潜力是很困难的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadg5aIv66k7kunTh5lH4XzAFRcmH6ib7SEo8UnhJxu23EqkWF8hg4m7yg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.38519924098671726" data-type="png" data-w="1054" data-width="1054" data-height="406" data-backw="578" data-backh="223" data-imgfileid="503529716" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/bee9864c-8052-411f-b36d-6a4d338564a0/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这说明，如果你还在读本科或研究生，与导师建立良好的关系、做出高质量的研究工作，获得导师的认可和推荐，也是一条可行的路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;特殊的时代，特殊的机会&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在分享的最后，Noam Brown 谈到了一个更深层的问题：薪酬。&lt;/p&gt;&lt;p&gt;他认识一些人选择做量化交易来赚钱，但五年后却开始质疑自己在做什么。他认为，现在是历史上一个特殊的时刻，在 AI 研究领域，你不仅能够积极地引导当今最重要的科技发展方向，&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;同时也能获得不错的报酬。&lt;/span&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadCVibOKZ7OeGicM5pVrXTz5pzc81sbu1PhtGb2G5ox2ca3rPowVVribriaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.49333333333333335" data-type="png" data-w="1050" data-width="1050" data-height="518" data-backw="578" data-backh="285" data-imgfileid="503529717" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/5aa322ea-cf7a-42c2-8024-a756e379a39a/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;进入顶尖 AI 实验室的路径不是唯一的，也不是封闭的。&lt;/p&gt;&lt;p&gt;知名博主 Yuchen Jin 补充道：StabilityAI 创始人 Emad 曾透露，Stability AI 的 80 名研究者和工程师中，只有 16 人有博士学位，其中很多人是直接从 X 平台上被招聘的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadJvOnKWcrgPI17NcP0JM1z4D1ic6ggicY6Nj8Ozeo0XwpSZlrsV7ibEXCA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.7871939736346516" data-type="png" data-w="1062" data-width="1062" data-height="836" data-backw="578" data-backh="455" data-imgfileid="503529718" data-aistatus="1" data-original-style="width: 100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/aa121ea8-1a6f-4a79-80c8-06407afe17a9/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;你不需要博士学位就能成为优秀的研究员或工程师，你只需要「just do things」，主动展示能力、做有影响力的独立项目、在开源社区贡献有深度的想法、通过改进现有工作证明实力。&lt;/p&gt;&lt;p&gt;机会永远留给那些有准备、敢行动的人。&lt;/p&gt;&lt;p&gt;最后，用电影《当幸福来敲门》一句经典台词共勉：You want something. Go get it.（想要什么就去争取，无需多言。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadBYmdYbaGN0mCBmyTJDCWys7VDImjxWQCQAtOJsnksZxjDLIj5wFRicg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=15" data-ratio="0.9757914338919925" data-type="jpeg" data-w="1074" data-width="1074" data-height="1048" data-backw="578" data-backh="564" data-imgfileid="503529719" data-aistatus="1" data-original-style="width: 100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/14ccd323-1cd0-440e-8ca4-7aeb667a336f/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/polynoamial/status/2014084431062114744&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/GenAI_is_real/status/2014104440408776865&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2014099420091199975?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>17岁高中生用AI解决数学界难题，陶哲轩、Jeff Dean点赞</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 25 Jan 2026 21:10:29 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-25-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-25-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文&lt;/section&gt;&lt;p&gt;你的童年我的童年好像不一样。&lt;/p&gt;&lt;p&gt;我的 17 岁，是坐在教室里苦哈哈地刷数学卷子；而这个名叫 Enrique Barschkis 的高中生，利用课间休息时间，成功解决了困扰数学家多年的埃尔德什第 347 号问题。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDA4leWqqJ1on8LedQZvqbJ719BVOINBibRP2GlvNERAxo2Y2CWlGrxXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.3043478260869565" data-type="png" data-w="1058" data-width="1058" data-height="1380" data-backw="578" data-backh="754" data-imgfileid="503529902" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/91dcb88e-f64c-4da7-a80f-ea616bd2e904/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;这一成就不仅在社交平台 X 上引发热议，更得到了谷歌首席科学家 Jeff Dean 的盛赞。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;什么是埃尔德什第 347 号问题？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;埃尔德什第 347 号问题，最初由埃尔德什和格雷厄姆在 1980 年提出，核心问题是：是否存在一个整数序列，其中相邻项的比值趋近于 2，并且对于该序列的任何余有限子序列，其有限子集和构成的集合在自然数中的密度都是 1？&lt;/p&gt;&lt;p&gt;这个问题触及了数论中完全序列理论的核心，其难度在于需要在严格的增长率限制下，保证几乎所有足够大的正整数都能表示为序列中某些项的和。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDq38V9aO9sOhIicaIicA32xqXg7eBNXg07VBncDKffcJoibMOWiaj0FXx7A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.37592592592592594" data-type="png" data-w="1080" data-width="1786" data-height="672" data-backw="578" data-backh="217" data-imgfileid="503529903" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1d91bd6b-9190-4ef3-8435-e27fb059b7fc/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;去年 10 月，著名数学家、菲尔兹奖得主陶哲轩在 Erdős 问题网站的讨论区里，用 ChatGPT 搜索相关文献，找到了一篇 Burr 和 Erdős 的旧论文。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDtrhZiaek53vcAVZURorK67J45VxpHYdpCZOOTZNA6O2d2MicA5wKmF0Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.18333333333333332" data-type="png" data-w="1080" data-width="1716" data-height="314" data-backw="578" data-backh="106" data-imgfileid="503529904" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1a4f065d-4e56-4d61-bd54-b010791aa83b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;然而数学家沃特很快发现，那篇论文中的结果使用的是相邻两项的比值条件，与本问题要求的相邻项比值条件略有不同。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDQicd4umshibmhEc4NjJYwJaPlExiaVojK7HnyjETPia8dF7IibS8Iv9hjrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.27870370370370373" data-type="png" data-w="1080" data-width="1650" data-height="460" data-backw="578" data-backh="161" data-imgfileid="503529905" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/0a288d7c-2945-4631-8389-57d8c65f6d63/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;陶哲轩提出了一个巧妙的构造思路：将序列分成若干个区块，每个区块长度缓慢增长，通过精心设计每个区块内的元素比例和区块之间的连接，使得序列既满足比值趋近于 2 的要求，又能保证其子集和覆盖几乎所有自然数。这个想法基于一种类似进位制的表示方法，通过在每个区块末尾添加调整项，为数的表示提供足够的灵活性。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDUuRVfaFJdF1SfSlVa7ib0oLkGAzQY8ryxZUv6oAbjKwy6Ay9VeiaCscg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.8944444444444445" data-type="png" data-w="1080" data-width="1738" data-height="1554" data-imgfileid="503529907" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/09ac4a85-0693-4f27-82ed-5eef91a2dc96/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;17 岁少年完成完整证明&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这个构想在讨论区挂了三个月，直到 2026 年 1 月 21 日晚上，这个 17 岁的高中生 Enrique 发帖宣布：他完成了完整的证明。&lt;/p&gt;&lt;p&gt;他在陶哲轩和沃特的思路基础上，构造了一个具体的序列：将序列分成若干区块，第 n 个区块的长度大约是对数的对数级别增长，区块内部由几何级数构成，区块之间通过精心设计的调整项连接。这种构造确保了相邻项比值在整体上趋近于 2，同时通过「进位调整」机制，使得几乎所有正整数都能表示为序列中某些项的和。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDPVfHqDM9JW3nR1YrofoiaABqCzWuadv0XkKFicd9NZxCickfictsfYJX3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.39444444444444443" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="228" data-imgfileid="503529908" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/57f1deb8-448a-4103-8848-5284ffc7fead/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;他还使用人工智能工具 Aristotle 将这个证明完全形式化为 Lean 语言代码，这是数学证明可以被计算机严格验证的形式。&lt;/p&gt;&lt;p&gt;陶哲轩在看到 Enrique 的证明后评论道：「干得漂亮！你处理 k 随 n 缓慢增长的方式在我看来是合理的，而且很高兴看到 Lean 确认了所有各种簿记和边界情况。」&lt;/p&gt;&lt;p&gt;他随即询问：「创建非形式证明时使用了 AI 工具吗？」Enrique 坦诚地回答，他使用了 GPT Codex 来编写 LaTeX 代码并改进部分内容，同时得到了数学家 Bartosz Naskręcki 的大量帮助。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDTWDdt8rPTEDjib5kLIssunt0y3mJpbpTfLA1xHZ5akjVVGJmic17C4DA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3638888888888889" data-type="png" data-w="1080" data-width="1688" data-height="614" data-backw="578" data-backh="210" data-imgfileid="503529909" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/4309c9d1-1d11-4e7a-9f37-c962aad4b407/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Bartosz Naskręcki 随后转发并评论：「Enrique 几周前给我发邮件，随意聊了聊椭圆曲线离散对数问题。我们用模型和 Aristotle 测试了他的许多想法。我为他感到非常自豪，在高中课间休息的间隙，他在 17 岁时就开辟了通往数学前沿的道路！我的建议只包含适度的提示和鼓励。Enrique 理应获得全部荣誉，他的勇气和热情值得赞扬。好运，伙计 &amp;mdash;&amp;mdash; 向星辰进发！」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD3U5F2S7D9RC3MKcwKiaENBUvtVA9dxbnGEmrlSiaia5rfS2AShaYOwJZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.425891181988743" data-type="png" data-w="1066" data-width="1066" data-height="454" data-backw="578" data-backh="246" data-imgfileid="503529910" data-aistatus="1" data-original-style="width: 100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/b486f88a-c28f-4fec-9b81-325c325a72a5/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;谷歌的 Jeff Dean 也转发了这条消息：「爱看这种事，17 岁的 Enrique 解决了一个有趣的数学问题，与陶哲轩讨论，并感谢 Bartosz Naskręcki 给予的『 大量帮助 』，而 Bartosz 说他实际上提供的帮助很少。这种广泛分享荣誉的本能真是太棒了！」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD0f6IWgiaFtahmRe2bdXVia01UZXwicnHmpuoxacoFBLUfYRPh84HWxm9Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.32645403377110693" data-type="png" data-w="1066" data-width="1066" data-height="348" data-backw="578" data-backh="189" data-imgfileid="503529911" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/00789973-9109-49d6-8f08-d7b95f08a765/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;目前 Erdős Problems 网站已经将问题 &lt;a data-topic="1" href="javascript%3A;"&gt;#347&lt;/a&gt; 标记为「肯定解决」，这意味着 Enrique 的解决方案得到了数学社区的认可。&lt;/p&gt;&lt;p&gt;这件事的意义远不止一个少年解决了一道难题那么简单。它标志着数学研究正在进入一个新阶段：年轻研究者借助 AI 工具，能够更快地触及学科前沿。&lt;/p&gt;&lt;p&gt;随着 AI 工具的不断进步，类似的突破可能会越来越多。未来的数学研究，或许将是人类创造力与人工智能计算力深度融合。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/JeffDean/status/2014195425277100251&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.erdosproblems.com/forum/thread/347&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>国内首篇！融合语言模型的多模态触觉传感器，推动机器人触觉迈向人类水平</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 25 Jan 2026 21:07:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-25-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-25-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/ab33701e-769c-4ac5-a7ef-af0fa84d890c/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="30"&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"data-path-to-node":"30","style":"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;论文第一作者为清华大学博士、南洋理工大学博士后李寿杰，清华大学博士生吴同和人工智能硕士生徐建乐。论文通讯作者包括清华大学深圳国际研究生院副教授丁文伯，大连理工大学教授解兆谦，新加坡国立大学助理教授吴昌盛和香港城市大学教授于欣格。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-path-to-node="5" data-pm-slice="0 0 []"&gt;随着机器人技术从「预设程序执行」向「具身智能交互」跨越，触觉感知作为理解物体属性、实现精细操作的核心感测方式，其重要性日益凸显，但当前系统在感知维度、分辨率及信号解读能力上仍远逊于人类，导致机器人往往处于「有感无知」的状态。&lt;/p&gt;&lt;p&gt;在此背景下，&lt;strong&gt;清华大学深圳国际研究生院丁文伯团队&lt;/strong&gt;联合无界智航（Xspark AI）及多所国内外科研机构，从鸽子卓越的多光谱视觉和非成像感知机制中获得灵感，研发出了一种仿生多模态触觉传感器 &lt;strong&gt;SuperTac&lt;/strong&gt;。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;该系统将多光谱成像、摩擦电感测与惯性测量融为一体，并通过构建 &lt;strong&gt;8.5B&amp;nbsp;&lt;/strong&gt;参数的触觉语言模型 &lt;strong&gt;DOVE&lt;/strong&gt;，实现了触觉信号从底层感知到高层语义推理的突破。&lt;/p&gt;&lt;p data-path-to-node="6"&gt;相关成果作为封面元素发表于&lt;strong&gt;《Nature Sensors》&lt;/strong&gt;第一期，也是国内以第一单位在该期刊发表的首篇，标志着机器人触觉感知向「人类水平」迈出了关键一步。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad6WQMrZTI1XAKW1XHVqmfs8M9aVDT5mzgfs1FbpVCSscY7icZPTcTrQA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=1" data-ratio="0.39061032863849765" data-s="300,640" data-type="png" data-w="1065" type="block" data-imgfileid="503529676" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/6b2282e2-647c-40c9-89d6-2d1752332e9f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;论文标题：Biomimetic multimodal tactile sensing enables human-like robotic perception&lt;/li&gt;&lt;li&gt;论文链接：https://www.nature.com/articles/s44460-025-00006-y&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad1427iaq6cvXCNEPRVOE5hULKF34jUxJFgHuYUSb32t80oVlqlH0rStw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="1.3318181818181818" data-s="300,640" data-type="png" data-w="440" type="block" data-imgfileid="503529685" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d8f3dde5-483d-42f5-a1db-49702ebc50c8/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="7"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1 Nature Sensors 第一期封面图，SuperTac 作为核心元素在封面上进行了展示（右下角）&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="8"&gt;&lt;strong&gt;一、仿生逻辑：从鸽子眼球到多模态感知架构&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="9"&gt;鸽子拥有自然界最复杂的感知系统之一，SuperTac 的硬件设计对应了其生物学特征。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadW2nfuFXiaPWEtskMWYt05YSItj1mbWYbEFmmS7jibaZHzgCHck5y7H2A/640?wx_fmt=jpeg#imgIndex=3" data-ratio="1.0481751824817518" data-s="300,640" data-type="png" data-w="685" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiaddnRaIXGFticUVu4ttKnMAv0EKD7P68icVicajUopu6pcncYEQgSjiawoVg/640?wx_fmt=png&amp;amp;from=appmsg" data-cropx2="685" data-cropy1="9.750889679715304" data-cropy2="726.4412811387901" data-imgfileid="503529689" data-aistatus="1" data-original-style="width: 562px;height: 588px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/292a36b0-bea8-451f-9e66-425b487bc7f9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="10"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 2 仿生学设计：受鸽眼启发的高分辨率多模态触觉传感器&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="11"&gt;&lt;b data-index-in-node="0" data-path-to-node="11"&gt;多光谱视觉的迁移：从视锥细胞到多通道相机&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="11"&gt;鸽子的视网膜包含多种视锥细胞，不仅能感知可见光，还拥有人类不具备的紫外线（UV）感知能力。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;SuperTac 集成了小型化的多光谱成像模块，覆盖了从紫外（390 nm）、可见光（400–700 nm）到近红外（940 nm）及中红外（5.5–14.0 μm）的超宽频段。&lt;/p&gt;&lt;p data-path-to-node="11"&gt;通过引入超宽频段成像，机器人能够在单一交互中同时解析热辐射、荧光位移等深层物理信息，实现了对物体形状、纹理、颜色和温度的全面表征。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;&lt;b data-index-in-node="0" data-path-to-node="12"&gt;非成像感知的映射：从地磁感应到 TENG / IMU&lt;/b&gt;&lt;/p&gt;&lt;p data-path-to-node="12"&gt;鸽子能通过视网膜中的隐花色素等分子感知地磁场，这是一种不依赖图像的物理感知。SuperTac 在 1 mm 厚的皮肤内嵌入了摩擦纳米发电机（TENG）和惯性测量单元（IMU）。&lt;/p&gt;&lt;p data-path-to-node="12"&gt;TENG 利用接触起电原理，根据不同物体的电负性差异识别材质（准确率 95%），并实现 15 cm 内的接近觉感知。IMU 模拟生物的本体感受，捕捉 0–60 Hz 的振动及碰撞信号。通过将摩擦电与惯性信号与光场调制耦合，传感器无需密集电极阵列即可扩展出对材质极性、震动及空间姿态的感知能力。&lt;/p&gt;&lt;p data-path-to-node="13"&gt;&lt;strong&gt;二、核心机制：光场调制的「智能感知层」&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="14"&gt;SuperTac 的核心竞争力在于其厚度仅为 1 mm 的光场调制多层感知皮肤。皮肤最外层的导电层采用透明的 PEDOT:PSS，通过丝网印刷技术在具有优异拉伸性能的 TPU 薄膜上形成涡旋线电极设计。这种涡旋设计能提供均匀的电学信号，结合摩擦起电机制，使皮肤在接触不同电负性物体时产生截然不同的电学反馈，从而实现高精度的材质分类与 15 cm 范围内的接近觉探测。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad2nJyLwdwibakxQR0XbMjSaIuvTSFey2EFicyPPQGp7QQ2Ulqy8ibQoapw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.7167883211678832" data-s="300,640" data-type="png" data-w="685" type="block" data-imgfileid="503529691" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5e308593-0eb0-4a45-81b0-f5d8c1b790e8/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="15"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 3 多光谱机理&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="16"&gt;在导电层之下，单向透视反射层充当了光学开关，其透明度受两侧光强差调节。当内部 LED 开启形成「触觉模式」时，内侧光强占据主导，反射层变为不透明状态，CMOS 单元聚焦捕捉皮肤表面的微观纹理与形变；当内部光源关闭，反射层随之变为透明，允许外部可见光透射，使传感器能够直接获取物体的 RGB 颜色信息。&lt;/p&gt;&lt;p data-path-to-node="16"&gt;紧邻其下的紫外荧光标记层则利用在近红外波段不可见但在紫外光下激发的荧光标记，实现了形变监测与物体纹理检测的解耦，确保在复杂抓取过程中能够同步捕捉切向滑动与表面细节。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadPnkIrcGxPcy4mBgK3OvswSohxeiaYPaUItzRGO2ickJRTOLFkqdhgCgg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=5" data-ratio="1.167883211678832" data-s="300,640" data-type="png" data-w="685" type="block" data-imgfileid="503529692" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4c01cdbe-6a8b-4b07-9476-ce3d206511f8/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="17"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 4 相关测试指标&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="18"&gt;&lt;strong&gt;三、触觉语言大模型：8.5B 参数背后的多模态融合架构&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="19"&gt;为了构建跨模态物理信号与自然语言空间的统一表征对齐，DOVE 采用了分层架构设计，其底层骨干由预训练的大语言模型 Vicuna 构成，为系统提供了强大的语言理解与逻辑推理基础。&lt;/p&gt;&lt;p data-path-to-node="19"&gt;为了处理极其复杂的触觉输入，系统并行集成了四组预训练的 CLIP（对比语言—图像预训练）模型作为模态编码器，将图像化的触觉特征（包括颜色、纹理、温度和材质信号）提取为深层特征向量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad3qsVhtWvnRwBYNq6hEN1YKzoft4l4GJdG9CsRb71xAKQZk6yzMA3BA/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.4601851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529693" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/a443c0f4-7161-4773-ad6c-4dd4a4836a8e/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="20"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 5 触觉语言大模型 DOVE&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="21"&gt;DOVE 的训练通过三阶段策略实现从底层感知到高层认知的递进：首先利用 CLIP 将异构传感器信号转化为通用的图像表征；随后通过投影层将触觉特征精准对齐至语言模型空间；最后针对 Vicuna 骨干网络进行微调，使其能够结合常识对触觉指令进行复杂推理。&lt;/p&gt;&lt;p data-path-to-node="22"&gt;&lt;strong&gt;四、应用场景：从物理触碰到语义逻辑的跃迁&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="23"&gt;SuperTac 提供的多模态底层数据通过 DOVE 模型的深度解析，成功实现了从单纯的「物理感知」向高层「语义认知」的跨越，赋予了机器人类人的具身交互能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadLgrVb9ptxcOS2js0Bum5ojbkuVu7JL5pGpJcbcDb0MysoFRqSiaMSEw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=7" data-ratio="0.487962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529694" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9d82a0a2-8e33-4dfa-927e-31ee11bbeb1b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="24"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 6 SuperTac + DOVE 的应用场景&lt;/sup&gt;&lt;/p&gt;&lt;p data-path-to-node="25"&gt;在基础的识别维度，DOVE 能够实时融合传感器采集的异构多模态数据，为操纵目标建立起全方位的「物理画像」。例如，在抓取实验中，面对一个未知杯子，DOVE 能准确地将其感官印象转化为人类可理解的语言：「黄色，室温，表面具有规律排布的凸起纹理，判定为金属材质」。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;最高层级的应用体现在常识指引下的功能决策与推理。DOVE 不仅解析当前的物理数据，还能将实时的触觉反馈与预训练的大模型常识相结合，从而推断物体的潜在功能并做出逻辑决策。&lt;/p&gt;&lt;p data-path-to-node="26"&gt;在极具挑战性的垃圾分拣任务中，这一能力得到了充分验证：当机器人接触到乱序堆放的杂物时，DOVE 能够根据触觉反馈进行逻辑建模。例如，它会推论道：「该物体具有典型的 PET 物理特征，结合其轻薄的结构，判定为废弃的塑料饮料瓶；基于环保常识，建议将其放入可回收垃圾桶」。&lt;/p&gt;&lt;p data-path-to-node="27"&gt;&lt;strong&gt;五、未来方向&lt;/strong&gt;&lt;/p&gt;&lt;p data-path-to-node="28"&gt;本研究为机器人触觉提供了多个富有前景的发展方向：硬件方面通过传感器微型化、低功耗芯片及高集成封装，提升机器人手内操作的灵活性并解决高负载下的散热稳定性难题；认知层面则依托 DOVE 模型的模态无关框架，通过优化传感器配置与专用数据集来持续增强系统的泛化能力，从而为实现自然、高效的人机交互奠定坚实基础。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad30Nwt5w7sqzibOVQGagHWNl3VicibGCR9Z4w4WLREmEB7ibiciagrflxgR9w/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=8" data-ratio="1.3212616822429906" data-s="300,640" data-type="png" data-w="856" type="block" data-imgfileid="503529696" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/74cd39be-80a0-49cc-a83c-bb9ae4eee500/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p data-path-to-node="29"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图 7 安装 SuperTac 的灵巧手&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>谷歌用一堆不赚钱的AI小玩意，给科技圈上了一课</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 25 Jan 2026 21:02:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-25-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-25-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜杨文&lt;/section&gt;&lt;p&gt;《庄子・人间世》中有这样一则小故事：&lt;/p&gt;&lt;p&gt;南伯子綦在商地的山丘游玩时，见到一棵异常高大的树，树冠能遮蔽上千辆马车。他本以为此树必有奇特用处，却发现它的细枝弯曲不能做栋梁、树根开裂不能做棺椁、树叶舔之烂嘴、气味嗅之让人癫狂三日。&lt;/p&gt;&lt;p&gt;子綦由此发出感慨：此果不材之木也，以至于此其大也。翻译过来就是，这棵树正因 「毫无用处」，才不会被砍伐，得以长成这般参天巨木。&lt;/p&gt;&lt;p&gt;而当我在谷歌 Arts &amp;amp; Culture 网站闲逛时，发现这家科技巨头深得庄子「&lt;strong&gt;无用之用，方为大用&lt;/strong&gt;」的精髓。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0GLalpK0NCYib9gIIJky90QcPpSjPIbzkqkicESaWUcwQb00O6eVVlaEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4777777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="276" data-imgfileid="503529187" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/edc09acb-5f43-4f86-b7ee-d8c6f50c651b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;链接：https://artsandculture.google.com/&lt;/p&gt;&lt;p&gt;谷歌的这些艺术实验项目，若从商业角度看，实在说不上有什么直接价值。&lt;/p&gt;&lt;p&gt;既不能像搜索引擎那样为公司带来广告收入，也不像云服务那般能创造现金流，甚至连用户停留时间恐怕也难以企及主流产品的零头。&lt;/p&gt;&lt;p&gt;但&lt;strong&gt;正是这些看似没啥用的项目，却藏着谷歌最真诚的人文坚守&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;今天再次进入这个网站，又发现了不少有意思的新东西。&lt;/p&gt;&lt;p&gt;比如 2025 年新推出的 Botanic Atlas 项目，这是个交互式的世界植物地图，收录了超过 3 万种植物的标本，我们可以在地图上看到它们分布在哪儿，还能了解相关知识。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0erovTLicIOgESY59bRlpTDUWp6IJUtZhcTByLRicUljjaW4L1D0xLYibg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.7490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="433" data-imgfileid="503529190" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8b474b41-9f0c-44b5-b122-1fe3222b6676/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Learning Light 是个虚拟灯光工作室，在虚拟场景里展示光线怎么打、照明原理是什么，通过各种教程和互动工具来琢磨光在艺术和设计中的门道。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0tH2zzed2ibDSyO8fQfZzmA8zCspLCzYFpFLgia5z6m6V05IHx6zQ6fSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5333333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="309" data-imgfileid="503529192" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/da75e003-fd09-439f-885d-9d1410419733/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Sparky 这个项目则是把日常物品拼成各种脑洞大开的发明，然后 AI 生成可视化原型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0r1soaY51y0JIJibSJGe8iczibtibibeUwDibL4JGrpa3kqPpYJafYc3Lx8Kg/640?wx_fmt=jpeg#imgIndex=4" data-ratio="0.5474613686534217" data-s="300,640" data-type="jpeg" data-w="906" type="block" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0b52254Cy7fj0p005jyl6wTtsUmJkysoiaCdyxXypO1llsgVcD4S8OhA/0?wx_fmt=png&amp;from=appmsg" data-cropx2="906.7615658362989" data-cropy1="90.67615658362989" data-cropy2="586.1565836298932" data-imgfileid="503529193" data-aistatus="1" data-original-style="width: 560px;height: auto !important;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7b15510b-a4f5-49dc-9be1-1c5c82d0c103/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些新实验延续着谷歌一贯的风格，用技术去拓展人们感知文化的方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一张电影截图，AI 找到 100 年前的同款配色&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;先来说说 Art Palette 这个颇具诗意的工具。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0cicj5eR7uFEhm2LR4rRTNXh0oj56RiaXbK8HTwBUjsk0mCUTMkO7dApQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.3824074074074074" data-type="png" data-w="1080" data-width="1926" data-height="736" data-backw="578" data-backh="221" data-imgfileid="503529197" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4ea30c3e-f922-443e-892c-0656a5d5c8e2/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;链接：https://artsandculture.google.com/experiment/art-palette/0AEvw1CK-6lCCA&lt;/p&gt;&lt;p&gt;它的玩法很简单。我们上传一张照片，或者直接在调色板上选择五种颜色，系统便会从全球 1500 多家文化机构的海量藏品中，找出与这些颜色匹配的艺术作品。&lt;/p&gt;&lt;p&gt;年纪越大，越喜欢那些花花绿绿的颜色。&lt;/p&gt;&lt;p&gt;我们上传一张电影《隔壁房间》经典剧照，移动取色器选中五种颜色，点击「View Artworks For This Palette」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0Cfct1bVpDpjPyKnzibgA30cibiaYLoZnkjqffcvMhCc0Vxbj3PkkkyCYw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5592592592592592" data-type="png" data-w="1080" data-width="2844" data-height="1590" data-backw="578" data-backh="323" data-imgfileid="503529199" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9c7b4b79-a4d3-4a47-a78e-b7782f4869c5/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;页面立马跳出一堆与这五种颜色相匹配的画作，每幅画作下方都标注着色卡，点击这些画作还能看到画作名称、作者、创作时间、收藏的博物馆等介绍信息。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/229dbf62-480a-4538-a324-a2c934901de3/1769345856814.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;如果我们不小心点到「Explore related content」，还能看到同时期的艺术作品。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0HIXkdLx1rdMlHThCIa7xQnUU4K2hfxMtqTRZl36cFa2doz52SdRH2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.5592592592592592" data-type="png" data-w="1080" data-width="2868" data-height="1604" data-imgfileid="503529226" data-aistatus="1" data-original-style="height: auto !important;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/791f9739-fafd-4877-9fed-9579605b172e/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;再比如，我们继续丢给它一张《爱乐之城》的剧照，AI 立马匹配出相关配色的作品。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ05RibqwagssvIwBDp5IL7eMZ2OPoNoHWFVtQcqR6Iu8yBBFZBbQZhfyg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5694444444444444" data-type="png" data-w="1080" data-width="2794" data-height="1592" data-backw="578" data-backh="329" data-imgfileid="503529230" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/f7b6c829-852f-4a9a-9926-d4ad68991beb/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这个看似简单的功能背后，是计算机视觉算法对每件作品色彩的精确提取和机器学习模型对色彩空间的智能映射。&lt;/p&gt;&lt;p&gt;实际使用时会发现，它能揭示出一些隐秘的联系。比如梵高的《鸢尾花》居然和 16 世纪的波斯细密画、莫奈的睡莲在色彩上有着某种共鸣；家里的沙发配色方案可能恰好呼应着某幅文艺复兴时期的肖像画。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0yeDNLN2LRG2qz3BCVC8dN2YKuedpwQHmuHV9FS9ZzY5jxXtzS4w3aw/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=9" data-ratio="0.7620370370370371" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-backw="578" data-backh="441" data-imgfileid="503529250" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/bc4844ce-82cd-4524-930f-3aa068acebcf/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;测评下来，Art Palette 的准确度相当高，匹配结果往往出人意料却又在情理之中。&lt;/p&gt;&lt;p&gt;此外，该工具还可以与其他项目进行联动。&lt;/p&gt;&lt;p&gt;比如随意打开其中一幅作品，选择「PoemPostcard」按钮，就可以跳转至这个新项目，从十四行诗、自由体诗、打油诗等 6 种诗歌形式中选择喜欢的，AI 就能自动生成一首诗歌。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/add63684-7a0c-4fca-a451-6af71135fee4/1769345885342.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;或者选择「ArtRemix」按钮，谷歌的 AI 图像生成模型 Imagen 会根据描述性的文字提示，随机生成这幅画的一个全新版本。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/3677db4e-58a9-4367-8f8c-9ce6a50deac8/1769345895542.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;当然，我们也可以点选初始提示词中高亮部分，来替换提示词里对应的那部分内容，想改哪里就点哪里，改提示词就能改生成结果。改好提示词后，点那个箭头按钮就开始混搭。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ03c0caggD0uHaNNJIGdDVQ5icGbHYnaTF8bfqabUFic9zWfZgbnSmic04A/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.5342592592592592" data-type="png" data-w="1080" data-width="2122" data-height="1134" data-backw="578" data-backh="309" data-imgfileid="503529258" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/8230115c-68d5-42d9-8be5-5f557888ca18/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;请勿触摸艺术品？谷歌偏要把它做成游戏&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Don&amp;#39;t Touch the Art 则是一款充满幽默感的小游戏。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0FRBkvUHkVxfrWKibDsq4khnG2GpsskQtLFLicmjmnpofJYnXibiaZH3rZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.45092592592592595" data-type="png" data-w="1080" data-width="2414" data-height="1088" data-backw="578" data-backh="261" data-imgfileid="503529259" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/551aaba1-0310-4362-b2f8-7090a6cb2ff0/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;链接：https://artsandculture.google.com/experiment/don-t-touch-the-art/EwElh6DBf5inTA&lt;/p&gt;&lt;p&gt;它的设计理念颇为反讽。在现实中，我们总是被提醒「请勿触摸艺术品」，而这个游戏把这条禁令变成了游戏机制。&lt;/p&gt;&lt;p&gt;我们扮演一个在画廊中自由落体的人，目标就是尽可能长时间地下落而不碰到任何艺术品。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/217e1c4c-0ed9-4826-ab17-b68cf38067c0/1769345913847.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;游戏借鉴了那些儿童玩具 Window Walker（也叫吸盘爬窗小人，那些用吸盘在玻璃上慢慢爬的小塑料人偶）的创意，把严肃的博物馆规则转化成了轻松的娱乐体验。&lt;/p&gt;&lt;p&gt;尤其是与华盛顿国家美术馆合作的版本，我们会在躲避达芬奇、委拉斯凯兹等大师作品的过程中，反复观看这些杰作，无形中完成了一次艺术教育。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7fb95546-fae0-4e99-878a-9414815cba47/1769345926268.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这个实验的妙处在于，它用游戏化的方式消解了艺术的距离感。玩了几轮之后，我们会发现自己不自觉地开始注意画作的细节、构图和色彩，因为只有这样才能在游戏中走得更远。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;原来画作也有「专属 BGM」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「One Sound，Two Frames」是一个探索视听联觉的创意游戏。游戏播放一段 AI 生成的音乐，然后我们从两幅画作中选出「灵感来源」。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ01H02ibzTYxrEq4rpsE7OmDEnFJ8cF6xOdBicz9xfDib4uvqfTGxOo2qbg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.4777777777777778" data-type="png" data-w="1080" data-width="2414" data-height="1154" data-backw="578" data-backh="276" data-imgfileid="503529270" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/51ce8893-b351-4520-8588-f4219358dc25/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;链接：https://artsandculture.google.com/experiment/one-sound-two-frames/IQFz5C4K_sgFpg&lt;/p&gt;&lt;p&gt;这个实验背后的技术颇为复杂，系统先用 AI 分析画作，生成描述，再用 Gemini 将视觉描述转化为音乐描述，最后交给 Lyria 生成音乐。&lt;/p&gt;&lt;p&gt;随着关卡推进，两幅画作会越来越相似，挑战也越来越大。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fbc723d6-177a-49c3-9c09-18a16431a923/1769345940861.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这个由谷歌 Arts &amp;amp; Culture Lab 驻场艺术家 Emmanuel Durgoni 与 DeepMind 研究工程师 Timo Denk 合作的项目，模糊了视觉艺术与听觉艺术的边界。&lt;/p&gt;&lt;p&gt;AI 能如此细腻地捕捉画作的「情绪」和「氛围」，并转化为音乐语言。游戏的设计非常用心，音乐生成的质量出人意料地高，有时候即便猜错了，也会觉得另一种匹配同样合理，这恰恰说明了艺术阐释的开放性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;画技烂到爆，但 AI 给配的音乐居然还挺好听&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Musical Canvas 则是一个「给画配乐」的工具。&lt;/p&gt;&lt;p&gt;这是由驻场艺术家 Simon Doury 创作的实验，把绘画和音乐创作合二为一，让即便没有音乐基础的人也能体验作曲的乐趣。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ07O3HGrToicMiaC7xIiaK8C7ibQXsd46lHsSvUGvsD4uFeA2ZZicf9rRsYAA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.39166666666666666" data-type="png" data-w="1080" data-width="2418" data-height="948" data-backw="578" data-backh="227" data-imgfileid="503529272" data-aistatus="1" data-original-style="width: 100%;height: auto !important;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/c6baa3a2-5436-4cfe-a900-df03c95e3dad/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;链接：https://artsandculture.google.com/experiment/musical-canvas/6AF2kMdrQhI4tQ&lt;/p&gt;&lt;p&gt;我们在数字画布上随意涂鸦，Gemini 会即时评价该作品，然后用 MusicLM 生成一段与之匹配的配乐。&lt;/p&gt;&lt;p&gt;画技实在有限，但 AI 生成的音乐还是蛮好听的，也符合涂鸦的氛围。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/c3eb2ad5-035d-4b00-942f-e01e1d28fac9/1769345957682.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;我们还可以添加视觉滤镜，比如「像素化」会让音乐带上 8-bit 游戏的风格，「老电影」滤镜则会增添黑胶唱片般的质感。&lt;a href="https://mp.weixin.qq.com/s/OqBFToP43yHTtYH9Gqj7OA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/402ccf24-283f-415a-87bd-ba29fa840e84/1769345967834.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Musical Canvas 的乐趣在于它的不可预测性，我们永远不知道下一笔会带来什么样的音乐变化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;谷歌的人文坚守&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将这些项目串联起来看，我们会发现它们有一个共同点，都是在&lt;strong&gt;用技术消解艺术与大众之间的隔阂&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;回到开头那棵栎树的故事。谷歌的 Arts &amp;amp; Culture 实验项目，何尝不是另一种「不材之木」？&lt;/p&gt;&lt;p&gt;在商业价值至上的科技世界里，它们显得格格不入，&lt;strong&gt;不向用户收费，也不在网站上直接投放广告&lt;/strong&gt;，既不产生利润，也不符合增长逻辑。它们存在的意义，似乎只是为了探索技术与文化结合的可能性，为了让更多人能以自己喜欢的方式接触艺术。&lt;/p&gt;&lt;p&gt;它们不急于证明自己的价值，不焦虑于用户留存率，只是安静地生长，等待那些愿意驻足的人。&lt;/p&gt;&lt;p&gt;当我们在这些实验中找到灵感、收获快乐、拓展认知时，会发现这种「无用」恰恰是最大的「有用」。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;在这个万物皆需变现的时代，谷歌用这些艺术实验告诉我们，&lt;strong&gt;不以功利为目的，反而能抵达更深远的意义&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;谢谢谷歌的「不务正业」，还愿意为这些不赚钱的 AI 艺术实验「浪费」时间。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>拒绝Reward Hacking！港科联合快手可灵提出高效强化学习后训练扩散模型新范式</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sun, 25 Jan 2026 20:54:36 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-25</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-25</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/02310e76-9d32-4011-8fe3-91b704ec4085/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在使用强化学习（RL）微调扩散模型（如 Stable Diffusion, Flux）以对齐人类偏好时，我们常面临一个棘手的 &amp;ldquo;两难困境&amp;rdquo;：追求高奖励会导致图像质量崩坏（即 Reward Hacking），而为了防止崩坏引入的 KL 正则化又会严重阻碍模型的探索和收敛。&lt;/p&gt;&lt;p&gt;最近，来自于&lt;strong&gt;香港科技大学，快手可灵 AI，港中文以及爱丁堡大学的研究团队&lt;/strong&gt;提出了一种&lt;strong&gt;全新的框架 GARDO&lt;/strong&gt;。它通过门控自适应正则化和多样性感知优化，成功在防止 Reward Hacking 的同时，实现了高效的样本探索和多样性生成。研究工作已经全面开源。&lt;/p&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;论文第一作者何浩然是香港科技大学博士生，研究方向包括强化学习和多模态基础模型等，研究目标是开发下一代可扩展强化学习后训练算法。通讯作者为香港科技大学电子及计算机工程系、计算机科学与工程系助理教授潘玲。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadOTdz9hGtaWiaESVKicr4alZI5iaCf1h9pibx2aic2lJmfg81081MZ1EUaCQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2324074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529608" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/9e72129f-482c-443b-b4c5-7e1097fbeef6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：GARDO: Reinforcing Diffusion Models without Reward Hacking&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://tinnerhrhe.github.io/gardo_project&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.24138&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;背景与动机：RL 后训练中的陷阱&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;强化学习（RL）在视觉领域的后训练中展现出了不错的效果，逐渐成为当前研究的热点。最近半年，如 flow-grpo，dancegrpo 以及 DiffusionNFT 等工作受到了大家广泛关注。&lt;/p&gt;&lt;p&gt;然而，在视觉任务中，定义一个完美的 &amp;ldquo;奖励函数（Reward Function）&amp;rdquo; 极其困难。我们通常使用的是一个代理奖励（Proxy Reward），例如 ImageReward、Aesthetic Score 或者 OCR 识别率。&lt;/p&gt;&lt;p&gt;这就导致了一个典型的问题：Reward Hacking。当模型过度优化这个代理奖励时，它会找到奖励模型的漏洞（Out-of-Distribution, OOD 区域）。结果就是，代理分数（Proxy Score）极高，但生成的图像充满了噪点、伪影，甚至完全失去了真实感。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadq1l98BWrJIDQP9aTD0AZZ0G0mDzD8HDW7PkUt06OjRe2JcYUZIhRbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.43796296296296294" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529609" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/2fcd83d3-5f4d-4ed0-9cc1-9b5aa1c65351/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Reward Hacking 定义&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;下面展示文生图出现 hacking 的例子：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadibIicudpicLicxJXRSXr8LrjtSE8T3YPEkTKJ8tp2icjts2Z71drTmjic1ibA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8666666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529610" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/24511eaa-7ab1-41ca-bfdb-a7069dee27b5/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;为了解决这个问题，传统方法（如 DPOK, Flow-GRPO）通常引入 KL 散度正则化，强迫微调后的策略 &amp;pi;_&amp;theta; 不要偏离原始参考策略 &amp;pi;_ref 太远。但研究团队发现，这种 &amp;ldquo;一刀切&amp;rdquo; 的 KL 正则化带来了新的问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;样本效率低&lt;/strong&gt;：RL 目标函数会被 KL 惩罚项的 &amp;pi;_ref 拖后腿，学习速度变慢。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;阻碍探索&lt;/strong&gt;：&amp;pi;_ref 本身通常是次优的，强制 &amp;pi;_&amp;theta; 贴近它会阻止模型探索那些参考模型 &amp;pi;_ref 未发现的高奖励区域。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;核心问题来了，能否在不牺牲样本效率和探索能力的前提下，防止 Reward Hacking？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GARDO：门控、自适应与多样性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了打破上述困境，作者提出了&amp;nbsp;&lt;strong&gt;GARDO (Gated and Adaptive Regularization with Diversity-aware Optimization) 框架&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadaDIRMHgezlBOyzELMb71ckeNibiaAyy1gTohB6pCiaS6icpIss0OM8kwjg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.37592592592592594" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529617" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f6063c3b-520a-4bf7-93c9-6a426a4c5b2f/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; GARDO 方法概览图&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;KL-regularized RL 的最优解可以写成：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadn6G7MdYe24OD3GJicEJ8pWicSd0VQfHt2ISbOBgvz6rcKx47icNwfHsaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.22580645161290322" data-s="300,640" data-type="png" data-w="930" type="block" data-imgfileid="503529611" data-aistatus="1" data-original-style="width: 238px;height: 54px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d4a24677-24a8-437e-9efd-352f01410cd5/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadpMX5Dv5uP8SY08UHetSmhoY7ss0EVJyGcElAwmf27hhj7PDiaX6WcMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.6625" data-s="300,640" data-type="png" data-w="160" type="block" data-imgfileid="503529612" data-aistatus="1" data-original-style="width: 39px;height: 26px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/53e428c3-08de-40b6-bd1b-be8c76ef8e3b/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 5.5%;"&gt;很大程度上由 &amp;pi;_ref (x) 和代理奖励函数 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadSN4KMJQ3xsuQgxaHCxVFhbqbEZRsic0pjTia9d9BWPhHc7qljibbBK54w/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.7868852459016393" data-s="300,640" data-type="png" data-w="122" type="block" data-imgfileid="503529613" data-aistatus="1" data-original-style="width: 33px;height: 26px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/d6852990-932a-49f5-9209-1567cddee93a/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 4.4%;"&gt;&amp;nbsp;决定。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadYLiaA50npxAKwlRFMG9NmNJfcLHxXtRiaLiaAzWK7wic9a17HjECWM152Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.3685185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529615" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/2d29ad6b-9a5d-4d89-b7c7-c8dff2a83ef5/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;基于上述观察，GARDO 的框架基于三个核心洞察：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;洞察一：正则化不需要 &amp;ldquo;雨露均沾&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法：门控 KL 机制 (Gated KL Mechanism)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;根据定义 1，只有当模型 &amp;pi;_&amp;theta; 生成的样本落在代理奖励不可靠的区域（即 OOD 区域）时，才真正需要 KL 正则化。对于那些既高质量又在分布内的样本，施加惩罚只会阻碍学习。&lt;/p&gt;&lt;p&gt;GARDO 引入了不确定性估计（通过奖励模型集成 ranking 差异来衡量）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadEAicnKKedWsmWuyWp7YrRTvAL6nKXelicxBdElX15n78pPHicC7feshDw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.1275797373358349" data-s="300,640" data-type="png" data-w="1066" type="block" data-imgfileid="503529618" data-aistatus="1" data-original-style="width: 356px;height: 45px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/88a228fd-eeba-4901-94f6-250e3c3e6a88/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;其中 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad3yiaYicW8zuMB0iaiatibVPw9AcK56ykqtzibhlibMSibsqXza7Libticyst2Hfg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.18394648829431437" data-s="300,640" data-type="png" data-w="598" type="block" data-imgfileid="503529619" data-aistatus="1" data-original-style="width: 163px;height: 30px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/21db95a0-852d-4133-a515-5bd68e6f947b/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 23.19%;"&gt;计算的一个 batch 里的胜率。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;做法：只对那些具有高不确定性 （Reward Model 拿不准，可能是 Hacking）的样本施加 KL 惩罚。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;效果：实验发现，仅对约 10% 的高不确定性样本进行惩罚，就足以有效防止 Reward Hacking，让其余 90% 的样本自由探索。从而实现在不牺牲样本效率的情况下，有效抑制 hacking 现象的出现。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;洞察二：静态的 &amp;pi;_ref 会限制 RL 优化的上限&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法：自适应正则化目标 (Adaptive Regularization Target)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果 &amp;pi;_ref 一直不变，随着 &amp;pi;_&amp;theta; 的变强，KL 惩罚会主导整个 learning Loss，导致优化停滞。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;做法：定期更新 Reference Model &amp;pi;_ref（将其重置为当前的策略）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;效果：这就像给模型设立了动态更新的 &amp;ldquo;锚点&amp;rdquo;，既保证了训练的稳定性，又允许模型持续进化，探索更广阔的空间。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;洞察三：RL 容易 mode collapse，需要鼓励多样性生成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;方法：多样性感知优势重塑 (Diversity-Aware Advantage Shaping)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RL 训练容易导致 Mode Collapse（模式坍塌），即模型发现一种高分画法后就只会画这一种。这不仅降低了生成质量，也加剧了 Reward Hacking。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;做法：利用 DINOv3 提取特征，计算样本在特征空间中的稀疏度作为 &amp;ldquo;多样性分数&amp;rdquo;。将此分数以乘法形式作用于优势函数（Advantage）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad7WGghbIWjpV44iaicGSQNFLQV6Iq6vxgU8cBXb9TWicCNMsiauMJKxrkeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.17685589519650655" data-s="300,640" data-type="png" data-w="916" type="block" data-imgfileid="503529620" data-aistatus="1" data-original-style="width: 477px;height: 84px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/f90e5d7e-1956-4182-8dea-20bdfe77fc04/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;注意：只奖励那些既有正向优势（高质量）又具有高多样性的样本，防止模型为了多样性而生成乱七八糟的东西。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;研究团队在高斯混合分布（预训练分布）上训练了一个包含三层 MLP 的扩散模型，目标是捕捉奖励景观中所示的多模态高奖励聚类。使用较大 KL 系数 &amp;beta; 的传统强化学习方法约束过强，无法提升奖励。与之相对，过小的 &amp;beta; 则会导致严重的模式坍缩。团队提出的多样性感知优化方法单独使用时，已成功捕捉到多模态聚类，包括参考策略 &amp;pi;_ref 中概率密度最低的中心聚类。而团队提出的完整的 GARDO 框架则能同时实现奖励最大化并发现所有高奖励聚类。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadMzaZ6jkBqibePITcmQBoZQqCRvaa4UxPH3odSavVdU4iaxAzTdkGelbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.375" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529621" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/40721674-b2b8-4270-9038-24d5bd571b8c/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验结果：全方位的提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作者在 SD3.5-Medium 和 Flux.1-dev 等多个基底模型上，针对不同的奖励任务（GenEval, OCR, Aesthetic 等）和不同的 RL 算法（flow-grpo，DiffusioNFT 等）进行了广泛实验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定量评估&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;相比于 Flow-GRPO 等基线方法，GARDO 展现了显著的优势：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;拒绝 Hacking&lt;/strong&gt;：在 OCR 等易被 Hack 的任务中，GARDO 在保持高识别率的同时，图像质量指标（如 Aesthetic, PickScore）没有下降，甚至有所提升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;样本效率&lt;/strong&gt;：学习曲线显示，GARDO 能够以更少的步数达到更高的奖励水平。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;泛化性&lt;/strong&gt;：在未见过的测试指标上（Unseen Metrics），GARDO 表现出极强的鲁棒性。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadtsXf9G6HxE92rnI2FMHSZoIjMT5ricgjIrdUyBKqXbaibRiaLjXnicAYkQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.387037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529622" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/c7dd54cd-d0f2-4d34-913e-664e6eb9887d/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; GARDO 和 baseline 在不同 metric 上的表现。训练优化代理任务黄色高亮。&lt;/sup&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadoZ30FKkIA9kjO4Rc7CIVa81dQicBXg3NK7eGXiatusn1icL5FYuJc4qmA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.2851851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529623" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/cfb61a12-d18a-48f1-a7ca-83a6e6bb0596/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;涌现能力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最令人印象深刻的是 GARDO 激发了模型的涌现能力（Emergent Behavior）。&lt;/p&gt;&lt;p&gt;在极具挑战性的 &amp;ldquo;数数任务&amp;rdquo;（生成特定数量的物体）中，基底模型和传统 RL 方法很难生成超过 9 个物体。&lt;/p&gt;&lt;p&gt;而 GARDO 成功学会了生成 10 个甚至 11 个物体。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadIgcMEElkibaAK802s80rkKB5k8vzhd3hbVAbXPicsH6qiaIdQicC432VxQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.45740740740740743" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529624" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/e8f12241-1bd8-4bd3-8a23-2a3985cf7a95/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;GARDO 针对扩散模型 RL 后训练中的痛点，提出以下解决方案：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;拒绝盲目正则化 &amp;rarr;&amp;rarr; 门控 KL（只惩罚不可靠的）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;拒绝静态锚点 &amp;rarr;&amp;rarr; 自适应更新（不断提升上限）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;拒绝模式坍塌 &amp;rarr;&amp;rarr; 多样性感知（鼓励百花齐放）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这项工作证明了：在视觉生成的强化学习中，精准的控制比强力的约束更重要。对于希望利用 RL 进一步释放扩散模型潜力的研究者和开发者来说，GARDO 提供了一个极具价值的通用框架。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>估值35亿美元，LeCun创业公司官宣核心方向，掀起对Next-token范式的「叛变」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 24 Jan 2026 20:42:56 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-24-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-24-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;自从图灵奖得主 Yann LeCun 离开 Meta 创立 AMI Labs（Advanced Machine Intelligence） 以来，这家新公司便引发了业界的高度关注。本周，他们终于确认了核心方向：&lt;strong&gt;开发所谓的「世界模型（world models）」，以此构建能够理解现实世界的智能系统。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5gwEYbRp4CHArBHMOYTmZEhdNAziav39lmsHb9cKic6ia7wLn6H83VEibBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.38425925925925924" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529990" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/126849b0-0f47-4681-8a04-2a8f752e494f/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 官网地址：https://amilabs.xyz/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;一直以来，LeCun 都对现有大语言模型的发展持怀疑态度，认为仅靠预测下一个 token 的生成式模型无法真正做到理解现实世界。他提出了&lt;strong&gt;世界模型这一不同路径&lt;/strong&gt;，一种能够准确反映现实动态的新型人工智能架构。这类全新的智能系统，应同时具备四项关键能力：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;理解真实世界；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;拥有持久记忆；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;能够进行推理与规划；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;可控且安全。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一愿景背后，直指当前大模型路线的一个核心局限。&lt;/p&gt;&lt;p&gt;现实世界的数据主要来自摄像头与各类传感器，其特征是连续、高维且充满噪声。过去几年中，基于自监督学习、以预测未来为目标的生成式模型，在语言领域取得巨大成功。然而，当这一路径被直接套用到真实世界的感知数据上时，却会遭遇根本性挑战，因为现实世界中，大量细节本身就是不可预测的。&lt;/p&gt;&lt;p&gt;AMI Labs 给出的答案是：&lt;strong&gt;不再执着于逐像素生成现实，而是构建世界模型&lt;/strong&gt;，让模型学会对真实世界传感器数据进行抽象建模，过滤掉不可预测的噪声信息，并在更高层次的表征空间中进行预测与推理。&lt;/p&gt;&lt;p&gt;在此基础上，AMI Labs 进一步提出带动作条件的世界模型（action-conditioned world models）。这种模型能够预估智能体采取某个行动后可能带来的结果，并在安全约束之内规划行动序列，从而完成具体任务。&lt;/p&gt;&lt;p&gt;这也意味着，其目标不只是理解世界，而是让 AI 能够在真实世界中可靠地行动。&lt;/p&gt;&lt;p&gt;因此，AMI Labs 的应用方向也高度聚焦在对可靠性、可控性和安全性要求极高的领域，包括工业流程控制、自动化系统、可穿戴设备、机器人与医疗健康等场景。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn522LKFzEVwJ4c3v5U7e9PszYVxwEnZHG4cN53ibYAjjkibHYTNaz1Kc5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5722222222222222" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529991" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e727b0dc-2e44-485c-9453-a50ed9c7eb4c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;值得一提的是，在业界另一条技术路线中，LeCun 也开始发挥更广泛的影响力。近日，硅谷初创公司 Logical Intelligence 任命 Yann LeCun 为其技术研究委员会创始主席。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5glYicB6HiaV9EpnMVjq6icQbrgicsAicrOicb0wfibKf3a6rMQIJwoAWB4PjQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.2712962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529992" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/775e29c1-6ebc-4b51-a95b-6825ea15ee71/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;近日，该公司推出了一款名为 Kona 的能量 - 推理模型，并宣称其性能比 OpenAI 的 GPT-5 和谷歌的 Gemini 等大语言模型更准确，功耗也更低。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Kona 走的技术路线也是不同于 next token 预测范式，而是一种基于能量的推理模型（EBRM）&lt;/strong&gt;，它通过根据约束条件进行评分来验证和优化解决方案，从而找到能量最低（最一致）的结果。&lt;/p&gt;&lt;p&gt;有意思的是，这一路线与 Yann LeCun 长期以来倡导的思路高度一致。LeCun 多次批评大语言模型依赖 next-token 预测的方式本质上是在猜答案，而真正的智能应建立在目标驱动与能量最小化的机制之上，让模型在约束与物理一致性的框架中寻找最优解。&lt;/p&gt;&lt;p&gt;无论是 Logical Intelligence 的能量推理模型，还是 AMI Labs 正在推进的世界模型，本质上都指向同一个方向：跳出语言生成范式，转向能够理解、预测并作用于真实世界的智能系统。&lt;/p&gt;&lt;p&gt;而这背后，或许正是 LeCun 选择离开 Meta 的重要原因之一。&lt;/p&gt;&lt;p&gt;在他看来，如今整个 AI 行业几乎被大语言模型所占据。在硅谷，所有公司都在做同一件事，挖同一条战壕，彼此争夺工程师，却很少有人敢真正走一条不同的路，因为一旦偏离主流方向，就可能在竞争中落后。&lt;/p&gt;&lt;p&gt;Meta 同样选择了全面押注大语言模型。这或许是一个合理的商业决策，但并不是 LeCun 所感兴趣的研究方向。&lt;/p&gt;&lt;p&gt;在他看来，如果一个系统无法提前预测自身行为可能带来的后果，就无法构建真正的智能体系统（agentic systems）。&lt;/p&gt;&lt;p&gt;正如人类在现实世界中行动，是因为能够预见行为的结果，并据此进行规划与决策，这种能力，才是智能的基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;顶尖科学家入局，「世界模型」赛道吸引 VC 争抢&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;构建连接 AI 与现实世界的基础模型，已经成为当下 AI 领域最令人兴奋的探索方向之一。无论是否已经拥有成熟产品，这一赛道都正在吸引顶尖科学家和资金雄厚的投资者持续加码。&lt;/p&gt;&lt;p&gt;比如由 AI 先驱李飞飞创立的 World Labs，在结束隐形融资阶段后不久便跻身「独角兽」行列，而在其推出首款产品 Marble&amp;mdash;&amp;mdash; 能够生成符合物理规律的 3D 世界后，更是估值飙升，成为资本新宠。&lt;strong&gt;据报道，目前该公司正在洽谈新一轮融资，估值达 50 亿美元。 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;毫无疑问，风投机构（VC）也同样渴望投资 LeCun，这也进一步佐证了前段时间传出的，关于 &lt;strong&gt;AMI Labs 可能正以 35 亿美元估值进行融资&lt;/strong&gt;传言的可信度。&lt;/p&gt;&lt;p&gt;据报道，正在与这家初创公司洽谈的风投机构包括 Cathay Innovation、Greycroft，以及 LeCun 担任顾问的 Hiro Capital。此外，其他潜在投资者还包括 20VC、Bpifrance、Daphni 和 HV Capital。&lt;/p&gt;&lt;p&gt;其实无论谁出资，投资者或许需要注意一个重要细节：正如 LeCun 所明确指出的，他是 AMI 的执行董事长，而非首席执行官（CEO）。实际上，这一职位是由 Alex LeBrun 担任，他此前是 Nabla 的联合创始人兼首席执行官，而 Nabla 是一家在巴黎和纽约均设有办事处的医疗 AI 初创公司。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5mPnw7CGRVRLo1jnAO8T0fvticcSafFneK4MPtFpKWoe7yNw2HnyPvSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.9916666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529995" data-aistatus="1" data-original-style="width:437px;height:433px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1e366986-b93d-48a9-8183-07b133f54dbf/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;Alex LeBrun 之所以从 Nabla 转任 AMI，源于 Nabla 去年 12 月宣布的一项合作项目。据悉，Nabla 致力于开发用于临床护理的 AI 助手，而 LeCun 一直是其顾问。因此，作为交换，Nabla 获得了对 AMI 世界模型的「优先访问权」，其董事会也支持 Alex LeBrun 从 CEO 转任首席 AI 科学家兼董事长，从而为他在 AMI 担任新职务铺平了道路。&lt;/p&gt;&lt;p&gt;作为 AMI Labs 的 CEO，LeBrun 身边有着许多熟悉面孔。此前，他创办的上一家公司 Wit.ai 被 Meta 收购后，他便在 LeCun 的领导下在 Meta 的 AI 研究实验室 FAIR 工作。此外，据传去年 12 月卸任 Meta 欧洲区副总裁一职的 Laurent Solly 也将加入 AMI Labs。&lt;/p&gt;&lt;p&gt;其实，AMI Labs 与 Meta 之间的人才重叠可能远不止于此。&lt;strong&gt;据 LeCun 透露，前雇主 Meta 很可能成为 AMI 的首个客户&lt;/strong&gt;。不过，他也曾公开批评过 Meta 在 Mark Zuckerberg 领导下所做出的部分战略选择。&lt;/p&gt;&lt;p&gt;甚至，从更广泛的角度来讲，在外界看来，&lt;strong&gt;AMI Labs 是对大语言模型 (LLM) 的一种逆向投资&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;在 LeCun 看来，LLM 的局限性包括幻觉等问题，而这在医疗等领域是一个严重隐忧，LeBrun 对此也深有体会，他曾在接受媒体采访时提到，他接受这份工作的一个重要原因是希望将世界模型应用于医疗健康领域。&lt;/p&gt;&lt;p&gt;「医疗健康是我的心血之作，我们也清楚目前哪些问题我们无法解决，我们希望 AI 的这一新兴分支能够帮助我们在医疗健康领域超越目前的局限。」&lt;/p&gt;&lt;p&gt;不过，这家初创公司也将目光投向了其他高风险的应用领域。&lt;/p&gt;&lt;p&gt;正如官网所宣称的那样：「AMI Labs 将致力于推进 AI 研究，并开发那些对可靠性、可控性和安全性要求极高的应用，特别是在工业过程控制、自动化、可穿戴设备、机器人技术、医疗健康以及更多领域。」&lt;/p&gt;&lt;p&gt;该初创公司计划将其技术授权给行业合作伙伴以用于实际应用，但同时也表示，计划「通过公开出版物和开源项目，与全球学术研究界」共同构建 AI 的未来。&lt;/p&gt;&lt;p&gt;LeCun 表示，他计划保留在纽约大学（NYU）的教授职位，他目前在那里每年教授一门课程，并指导博士生和博士后研究员。&lt;/p&gt;&lt;p&gt;这意味着这位出生于法国的研究人员将继续常驻纽约，但他也透露，AMI Labs「将成为一家总部位于巴黎的全球性公司」。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://techcrunch.com/2026/01/23/whos-behind-ami-labs-yann-lecuns-world-model-startup/&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/rohanpaul_ai/status/2014731323638997011&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>挑战Claude Code？OpenAI Codex发布月将至，今先揭秘智能体循环</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 24 Jan 2026 20:38:50 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-24-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-24-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;p&gt;刚刚，OpenAI CEO 山姆・奥特曼发了一条推文：「从下周开始的接下来一个月，我们将会发布很多与 Codex 相关的激动人心的东西。」他尤其强调了网络安全这个主题。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529974" data-ratio="1.6698872785829308" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5wChp1spqkWWBibGbV14uUvnLwvVhnYksCbAicaT0MkKFp0WY3CiapqgrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="621" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/cd501859-163b-4ecb-bc82-bd35103a9ec9/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;当然，和奥特曼的很多推文一样，这条推文也收获了网友的各式各样的评论：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5krPSZxjGL9XYBaukh1tVcyGbUqoOsfTsWX3MOux8C1TriaYznz0ycmQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.2866779089376054" data-s="300,640" data-type="png" data-w="593" type="block" data-imgfileid="503529973" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ff550d55-54cf-4989-b168-c4db8d88896f/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5fvXibjZYtUwtGxFndqJdjkTADYh73NoPg7MVTqu6JSKick6ThmG3gdtw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.2505592841163311" data-s="300,640" data-type="png" data-w="447" type="block" data-imgfileid="503529972" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/0a2ce45a-7bcc-4392-843c-cc0ac8103881/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5jv66O86b3AkbQZ6sdgzXgYYDIPy6wOjR48AWwSUb7t6Dq3VzkMYvpQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.21442495126705652" data-s="300,640" data-type="png" data-w="513" type="block" data-imgfileid="503529975" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2e9de98a-7a46-4aa1-b236-05a60c9d7453/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;似乎是响应奥特曼的 Codex 发布预告，OpenAI 官方也发布了一篇技术博客，以「&lt;strong&gt;揭秘 Codex 智能体循环&lt;/strong&gt;」为题，深入揭秘了 Codex CLI 的核心架构 &amp;mdash;&amp;mdash; 智能体循环（Agent Loop）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5atF8ZEa9IepHyqe7OwScZkxfwhmdPVQOCibozsN8cXuUI44PKSprtHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.2238648363252376" data-s="300,640" data-type="png" data-w="947" type="block" data-imgfileid="503529976" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b95eb7ce-c7f5-4202-a382-cacf88ec2f97/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;博客地址：https://openai.com/index/unrolling-the-codex-agent-loop/&lt;/p&gt;&lt;p&gt;具体来说，其中详细介绍了它如何通过 Responses API 协调用户指令、模型推理与本地工具执行（如 Shell 命令），并重点阐述了通过保持「提示词前缀一致」来触发缓存优化性能，以及利用自动压缩技术管理上下文窗口，从而在保证数据隐私（ZDR）的前提下，实现安全、高效的自动化软件开发。&lt;/p&gt;&lt;p&gt;下面我们就来详细看看这篇博客的内容。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;揭秘 Codex 智能体循环&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Codex CLI 是 OpenAI 的跨平台本地软件智能体，可以生成相当高质量的软件变更。&lt;/p&gt;&lt;p&gt;OpenAI 表示：「自今年 4 月首次发布 CLI 以来，我们在构建世界级软件智能体方面积累了大量经验。」&lt;/p&gt;&lt;p&gt;为了分享这些见解，OpenAI 推出了这个系列博客，本文即是第一篇。&lt;/p&gt;&lt;p&gt;在这个系列中，OpenAI 将探讨 Codex 的工作原理以及那些来之不易的教训。（如果您想更深入地了解 Codex CLI 的构建细节，请查看 OpenAI 的开源仓库：。OpenAI 的许多设计决策细节都记录在 GitHub 的 Issue 和 Pull Request 中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5Dbm37j5X2icuwXib98l2JtaZ1sGLXeYAvMWN5xibDocdDDgmjpoB4hVCA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5083333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529977" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/68388fdd-9a02-4f67-9fed-b870abc22811/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;仓库地址：https://github.com/openai/codex&lt;/p&gt;&lt;p&gt;第一篇，OpenAI 将聚焦于&lt;strong&gt;智能体循环（Agent Loop）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这是 Codex CLI 的核心逻辑，负责协调用户、模型以及模型为执行软件任务而调用的工具之间的交互。&lt;/p&gt;&lt;p&gt;OpenAI 表示：「我们希望这篇文章能让您清晰地看到 OpenAI 的智能体（harness）在利用 LLM 时所扮演的角色。&lt;/p&gt;&lt;p&gt;在开始之前，先简要说明一下术语：在 OpenAI，「Codex」涵盖了一系列软件智能体产品，包括 Codex CLI、Codex Cloud 和 Codex VS Code 扩展。本文重点讨论 Codex Harness，它提供了支持所有 Codex 体验的核心智能体循环和执行逻辑，并通过 Codex CLI 呈现。为了方便起见，下文中将交替使用「Codex」和「Codex CLI」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能体循环&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;每个 AI 智能体的核心都是所谓的「智能体循环」。智能体循环的简化图示如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5dwe7xwg5V3bnKGT00t7NXmbOGicGVibOmWtW9yBb5PwgibVL5LHB7fm4Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.46140939597315433" data-s="300,640" data-type="png" data-w="596" type="block" data-imgfileid="503529978" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/958368e5-c2df-44ec-8945-e08ffcfb5ae9/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;输入&lt;/strong&gt;：智能体获取用户的输入，并将其整合到为模型准备的一组文本指令中，这被称为提示词。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推理（Inference）&lt;/strong&gt;：下一步是查询模型。OpenAI 将指令发送给模型并请求其生成回复。在推理过程中，文本提示词首先被转化为一系列输入 Token（映射到模型词汇表的整数）。这些 Token 被用来对模型进行采样，生成新的输出 Token 序列。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解码&lt;/strong&gt;：输出 Token 被转换回文本，成为模型的回复。由于 Token 是增量生成的，这种转换可以随着模型的运行同步进行，这就是为什么许多 LLM 应用会显示流式输出。在实践中，推理通常被封装在处理文本的 API 之后，隐藏了 Token 化的细节。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;决策&lt;/strong&gt;：作为推理步骤的结果，模型要么 (1) 针对用户的原始输入生成最终回复，要么 (2) 请求 工具调用（Tool Call）（例如，「运行 ls 并报告输出」）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;执行与重试&lt;/strong&gt;：在情况 (2) 下，智能体执行工具调用并将输出附加到原始提示词中。该输出用于生成新的输入以重新查询模型；智能体随后可以考虑这些新信息并再次尝试。&lt;/p&gt;&lt;p&gt;这个过程会一直重复，直到模型停止发出工具调用，而是为用户生成一条消息（在 OpenAI 模型中称为助手消息 / Assistant Message）。在许多情况下，这条消息会直接回答用户的原始请求，但也可能是对用户的一个后续提问。&lt;/p&gt;&lt;p&gt;由于智能体可以执行修改本地环境的工具调用，其「输出」并不局限于助手消息。在很多情况下，软件智能体的主要输出是它在您机器上编写或编辑的代码。尽管如此，每个轮次（Turn）总是以助手消息结束（例如「我已经添加了你要求的 architecture.md」），这标志着智能体循环的终止状态。从智能体的角度来看，它的工作已经完成，控制权交还给用户。&lt;/p&gt;&lt;p&gt;图中所示的从「用户输入」到「智能体回复」的过程被称为对话的一个轮次（Turn）（在 Codex 中称为 Thread）。一个对话轮次可以包含模型推理和工具调用之间的多次迭代。每当您向现有对话发送新消息时，对话历史记录都会作为新轮次提示词的一部分，其中包括之前轮次的消息和工具调用。&lt;/p&gt;&lt;p&gt;这意味着随着对话的进行，用于模型采样的提示词长度也会增加。&lt;/p&gt;&lt;p&gt;长度非常重要，因为每个模型都有上下文窗口，即单次推理调用中可以使用的最大 Token 数（包括输入和输出）。你可以想象，智能体在一个轮次中可能会决定进行数百次工具调用，从而耗尽上下文窗口。&lt;/p&gt;&lt;p&gt;因此，&lt;strong&gt;上下文窗口管理&lt;/strong&gt;是智能体的众多职责之一。&lt;/p&gt;&lt;p&gt;现在，让我们深入了解 Codex 是如何运行智能体循环的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型推理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Codex CLI 通过向 Responses API 发送 HTTP 请求来运行模型推理。OpenAI 将检查信息如何流经 Codex，并利用 Responses API 驱动智能体循环。&lt;/p&gt;&lt;p&gt;Codex CLI 使用的 Responses API 端点是可配置的，因此它可以与任何实现了 Responses API 的端点配合使用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;使用 ChatGPT 登录 Codex CLI 时，端点为&amp;nbsp;https://chatgpt.com/backend-api/codex/responses。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用 OpenAI 托管模型的 API 密钥认证时，端点为&amp;nbsp;https://api.openai.com/v1/responses。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;运行 codex --oss 以配合 ollama 或 LM Studio 使用 gpt-oss 时，默认指向本地运行的&amp;nbsp;http://localhost:11434/v1/responses。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;也可以配合云服务商（如 Azure）托管的 Responses API 使用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;接下来，让我们探索 Codex 如何为对话中的第一次推理调用创建提示词。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建初始提示词&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为终端用户，你在查询 Responses API 时并不会逐字指定用于采样的提示词。相反，你会在查询中指定各种输入类型，而 Responses API 服务器决定如何将这些信息结构化为模型设计的提示词。你可以将提示词看作一个「项目列表」。&lt;/p&gt;&lt;p&gt;在初始提示词中，列表中的每个项目都关联一个角色（Role）。角色指示了相关内容的权重，取值如下（优先级从高到低）：system（系统）、developer（开发者）、user（用户）、assistant（助手）。&lt;/p&gt;&lt;p&gt;Responses API 接收包含多个参数的 JSON 负载。OpenAI 重点关注这三个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;instructions&lt;/strong&gt;：插入模型上下文的系统（或开发者）消息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;tools&lt;/strong&gt;：模型在生成回复时可能调用的工具列表。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;input&lt;/strong&gt;：输入给模型的文本、图像或文件列表。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 Codex 中，instructions 字段读取自～/.codex/config.toml；否则使用模型自带的 base_instructions（例如 gpt-5.2-codex_prompt.md）。&lt;/p&gt;&lt;p&gt;tools 字段是符合 Responses API 架构的工具定义列表。对于 Codex，这包括 CLI 提供的工具、API 提供的工具以及用户通过 MCP（模型上下文协议） 服务器提供的工具。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5wr9Q3iabeodfnelAhuwyzLFSGI25q7sXMyZoNEia6shwJDib1oz03JZ3Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.4655172413793103" data-s="300,640" data-type="png" data-w="928" type="block" data-imgfileid="503529979" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/5a2d4e6f-da6e-4d0d-9083-45690ab79661/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;最后，JSON 负载的 input 字段是一个项目列表。Codex 在添加用户消息之前，会在 input 中插入以下项目：&lt;/p&gt;&lt;p&gt;1. 一条 role=developer 的消息，描述仅适用于 tools 部分定义的 Codex 提供之 shell 工具的沙箱环境。也就是说，其他工具（如 MCP 服务器提供的工具）不受 Codex 沙箱限制，需自行负责执行安全准则。该消息是根据模板构建的，其中关键内容来自捆绑在 Codex CLI 中的 Markdown 片段，如 workspace_write.md 和 on_request.md：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5gj7gRJDB7vecScO40mCZMNZh9GwibmScXesSyVesSLp0xgeVOOxM6XQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.18549511854951187" data-s="300,640" data-type="png" data-w="717" type="block" data-imgfileid="503529980" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/25b3fabc-5233-41a4-9ce1-80d0fb315496/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;2.（可选）一条 role=developer 的消息，其内容是从用户的 config.toml 文件中读取的 developer_instructions 值。&lt;/p&gt;&lt;p&gt;3.（可选）一条 role=user 的消息，其内容是「用户指令（User Instructions）」，这些指令并非来源于单一文件，而是从多个来源汇总而来的。通常，更具体的指令会出现在后面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;$CODEX_HOME 中 AGENTS.override.md 和 AGENTS.md 的内容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;受限于一定大小（默认为 32 KiB），在从当前工作目录（CWD）的 Git / 项目根目录到 CWD 自身的每个文件夹中查找：添加任何 AGENTS.override.md、AGENTS.md 或 config.toml 中 project_doc_fallback_filenames 指定的文件内容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果配置了任何 Skills：关于 Skill 的简短序言、每个 Skill 的元数据、关于如何使用 Skill 的章节&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;4. 一条 role=user 的消息，描述智能体当前运行的本地环境。这指定了当前工作目录和用户的 Shell：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5gRxw59qULb3QsB5LO3HdlBbtNXVBsanDhEuWSMeFEBqkuNqVq7QxRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.29916897506925205" data-s="300,640" data-type="png" data-w="361" type="block" data-imgfileid="503529981" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/86e2400d-98d1-4042-a7b3-21156cb68114/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;一旦 Codex 完成上述所有初始化输入的计算，它就会附加用户消息以开始对话。&lt;/p&gt;&lt;p&gt;之前的例子集中在每条消息的内容上，但请注意，input 的每个元素都是一个具有 type、role 和 content 的 JSON 对象，如下所示：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5CbMJ5qahlStAd8vUzYypE3amRTibl1sWiaJZy2S5N7Zib8FC9PeoafzoQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5632798573975044" data-s="300,640" data-type="png" data-w="561" type="block" data-imgfileid="503529982" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/bbb547cd-b4aa-4f4e-a6d4-dd6244bbd714/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;一旦 Codex 构建好发送给 Responses API 的完整 JSON 负载，它就会发出带有 Authorization 标头的 HTTP POST 请求，该标头取决于～/.codex/config.toml 中 Responses API 端点的配置方式（如果指定了额外的 HTTP 标头和查询参数，也会一并添加）。&lt;/p&gt;&lt;p&gt;当 OpenAI Responses API 服务器收到请求时，它会使用 JSON 按如下方式推导出模型的提示词（当然，自定义的 Responses API 实现可能会有不同的选择）：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5Y7mypzATEyddHG5q95jBNlbUu0Gf31iaz5gXjNm1Nk2TBkgNgzwuJ2A/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5985037406483791" data-s="300,640" data-type="png" data-w="802" type="block" data-imgfileid="503529984" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/6464e1ff-78ec-4ca8-96f8-d1ce2bdd8745/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如你所见，提示词中前三项的顺序是由服务器而非客户端决定的。即便如此，在这三项中，只有 system 消息的内容也受服务器控制，因为 tools 和 instructions 是由客户端决定的。紧随其后的是来自 JSON 负载的 input 以完成提示词。&lt;/p&gt;&lt;p&gt;既然有了提示词，OpenAI 就可以开始采样模型了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一轮对话&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对 Responses API 的这个 HTTP 请求启动了 Codex 对话的第一个「轮次」。服务器以服务器发送事件（SSE）流的形式进行回复。每个事件的数据都是一个 JSON 负载，其 type 以 response 开头，可能类似于这样（事件的完整列表可以在 OpenAI 的 API 文档中找到）：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5tt0o4whYwnEyZemycNR6ySx2EwGNHqhSo2PJqsbzIwiaic97SjMAz74g/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.29237947122861585" data-s="300,640" data-type="png" data-w="643" type="block" data-imgfileid="503529983" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/8ffa4978-26cb-45bb-842a-98c11d8c1c66/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Codex 消费这些事件流，并将它们重新发布为可供客户端使用的内部事件对象。像 response.output_text.delta 这样的事件用于支持 UI 中的流式显示，而像 response.output_item.added 这样的事件则被转换为对象，附加到后续 Responses API 调用的 input 中。&lt;/p&gt;&lt;p&gt;假设对 Responses API 的第一个请求包含了两个 response.output_item.done 事件：一个类型为 reasoning（推理），一个类型为 function_call（函数调用）。当 OpenAI 再次使用工具调用的结果查询模型时，这些事件必须体现在 JSON 的 input 字段中：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5dicoCqr5Vu8FHLVrDyVEhDEI3EdGPjTrNUeEyuf2b5t2LxlzEJpyRrw/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.7301204819277108" data-s="300,640" data-type="png" data-w="830" type="block" data-imgfileid="503529985" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/f765b772-1eb5-48f9-8ada-aa250a8bcb42/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在随后的查询中，用于采样模型的提示词将如下所示：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5xl0PmvGQ0SmvXjT4xkPKPqHOooQ2uIaVn7eyfEQH97VB34p0E18z1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.3877805486284289" data-s="300,640" data-type="png" data-w="802" type="block" data-imgfileid="503529987" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/9990af80-0df8-4c7f-8906-5eee2a61d095/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;特别要注意的是，旧提示词是新提示词的精确前缀。这是有意为之的，因为这使得后续请求更加高效，因为它使 OpenAI 能够利用&lt;strong&gt;提示词缓存&lt;/strong&gt;（Prompt Caching）（OpenAI 将在下一节关于性能的内容中讨论）。&lt;/p&gt;&lt;p&gt;回顾 OpenAI 的第一张智能体循环图，OpenAI 看到在推理和工具调用之间可能存在多次迭代。提示词可能会持续增长，直到 OpenAI 最终收到一条 Assistant 消息，表明该轮次结束：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5Hfo8XjXPjZliczVTZEpH9zTHlakEZ27ib8P0GeiaukSx6Q3ia7bcUESvNA/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.08066581306017925" data-s="300,640" data-type="png" data-w="781" type="block" data-imgfileid="503529986" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/98624025-7f63-484b-965d-db4bc2725c5c/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在 Codex CLI 中，OpenAI 将 Assistant 消息呈现给用户，并聚焦编辑器以向用户表明轮到他们继续对话了。如果用户回复，则前一轮的 Assistant 消息以及用户的新消息都必须附加到 Responses API 请求的 input 中，以开始新轮次：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5ASHjBuDMr8pucM8McVhibqjv3QD0GVUsvOqFVzD5Gw04s62eIf4G5CA/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.8942857142857142" data-s="300,640" data-type="png" data-w="700" type="block" data-imgfileid="503529988" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/b31484de-93e0-4947-93f6-ce9af67cd86f/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;再一次，由于 OpenAI 正在继续对话，OpenAI 发送给 Responses API 的输入长度会不断增加：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9ZIK7vDox8JI3Lianicq7rn5AK0JmvFU82a7BicUyNDCxzTsGZD5tpzl4tClHd0lut92aRz1Thnwx5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.5087281795511222" data-s="300,640" data-type="png" data-w="802" type="block" data-imgfileid="503529989" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/83e6fa94-c308-4203-8001-4f59c57b712a/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;让 OpenAI 来看看这种不断增长的提示词对性能意味着什么。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;性能考虑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你可能会问自己：「等等，&lt;strong&gt;智能体循环在对话过程中发送给 Responses API 的 JSON 量难道不是呈二次方增长吗？&lt;/strong&gt;」&lt;/p&gt;&lt;p&gt;确实如此，虽然 Responses API 确实支持一个可选的 previous_response_id 参数来缓解这个问题，但 Codex 目前并未使用它，主要是为了保持请求完全无状态，并支持零数据保留（ZDR）配置。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;避免使用 previous_response_id 简化了 Responses API 提供者的工作，因为它确保了每个请求都是无状态的。这也使得支持选择零数据保留（ZDR）的客户变得简单，因为存储支持 previous_response_id 所需的数据会与 ZDR 冲突。请注意，ZDR 客户并不会失去从前几轮的专有推理消息中受益的能力，因为相关的 encrypted_content 可以在服务器上解密。（OpenAI 会保留 ZDR 客户的解密密钥，但不会保留其数据。）有关 Codex 支持 ZDR 的相关更改，请参见 PR #642 和 #1641。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;通常，采样模型的成本远高于网络传输的成本，因此采样是 OpenAI 提高效率的主要目标。这就是为什么提示词缓存如此重要，因为它使 OpenAI 能够重用之前推理调用的计算结果。当 OpenAI 命中缓存时，采样模型的时间复杂度是线性的而非二次方的。&lt;/p&gt;&lt;p&gt;OpenAI 的提示词缓存文档对此进行了更详细的解释：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;缓存命中仅适用于提示词内的精确前缀匹配。为了获得缓存收益，请将静态内容（如指令和示例）放在提示词的开头，并将变量内容（如用户特定信息）放在末尾。这也适用于图像和工具，它们在请求之间必须完全一致。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;考虑到这一点，让 OpenAI 看看哪些类型的操作会导致 Codex 中的「缓存未命中」：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在对话过程中更改模型可用的工具。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更改 Responses API 请求的目标模型（实际上，这会改变原始提示词中的第三项，因为它包含模型特定的指令）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更改沙箱配置、批准模式或当前工作目录。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Codex 团队在 Codex CLI 中引入可能破坏提示词缓存的新功能时必须保持严谨。例如，OpenAI 最初对 MCP 工具的支持引入了一个 Bug，即 OpenAI 未能以一致的顺序排列工具，导致了缓存未命中。&lt;/p&gt;&lt;p&gt;请注意，&lt;strong&gt;MCP 工具可能特别棘手&lt;/strong&gt;，因为 MCP 服务器可以通过 notifications/tools/list_changed 通知随时更改它们提供的工具列表。在长对话中间响应此通知可能会导致昂贵的缓存未命中。&lt;/p&gt;&lt;p&gt;如果可能的话，对于对话中发生的配置更改，OpenAI 通过在 input 中附加一条新消息来反映更改，而不是修改之前的消息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如果沙箱配置或批准模式发生变化，OpenAI 会插入一条新的 role=developer 消息，格式与原始的 &amp;lt;permissions instructions&amp;gt; 项目相同。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果当前工作目录发生变化，OpenAI 会插入一条新的 role=user 消息，格式与原始的 &amp;lt;environment_context&amp;gt; 相同。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了性能，OpenAI 竭尽全力确保缓存命中。此外，OpenAI 还必须管理另一个关键资源：上下文窗口。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;上下文管理与压缩&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenAI 避免耗尽上下文窗口的总策略是：&lt;strong&gt;一旦 Token 数量超过某个阈值，就对对话进行压缩（Compaction）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体来说，OpenAI 用一个代表对话的小型新项目列表替换 input，使智能体能够在理解迄今为止发生的事情的情况下继续工作。早期的压缩实现需要用户手动调用 /compact 命令，该命令会使用现有对话加上自定义的总结指令来查询 Responses API。Codex 将生成的包含总结的 Assistant 消息作为后续对话轮次的新 input。&lt;/p&gt;&lt;p&gt;自那以后，Responses API 已演进为支持一个特殊的 /responses/compact 端点，该端点能更高效地执行压缩。它返回一个项目列表，可用于替代之前的输入以继续对话，同时释放上下文窗口。此列表包含一个特殊的 type=compaction 项目，带有一个不透明的 encrypted_content 项，它保留了模型对原始对话的潜在理解（latent understanding）。&lt;/p&gt;&lt;p&gt;现在，当超过 auto_compact_limit 时，Codex 会自动使用此端点来压缩对话。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下期预告&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本博客介绍了 Codex 智能体循环，并详细讲解了 Codex 在查询模型时如何构建和管理其上下文。在此过程中，OpenAI 强调了适用于任何在 Responses API 之上构建智能体循环的开发者的实际考虑因素和最佳实践。&lt;/p&gt;&lt;p&gt;虽然智能体循环为 Codex 提供了基础，但这仅仅是个开始。&lt;/p&gt;&lt;p&gt;在接下来的文章中，OpenAI 表示将深入探讨 CLI 的架构，探索工具调用的具体实现方式，并详细了解 Codex 的沙箱模型。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>不止于Prompt：揭秘「神经网络可重编程性」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 24 Jan 2026 20:31:39 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-24-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-24-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/5a534c14-8160-4c3a-a7f2-dbb18aedf105/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;从模型重编程（Model Reprogramming），到参数高效微调（PEFT），再到当下大模型时代的 Prompt Tuning ，Prompt Instruction 和 In-context Learning，研究者和从业人员不断地探索一个核心问题：&lt;strong&gt;在尽量不改动模型参数的前提下，如何最大化地复用预训练模型的能力？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;过去几年，这类方法在不同社区中以各自独立的形式快速发展 &amp;mdash;&amp;mdash; 有的来自对抗鲁棒性与迁移学习，有的服务于下游任务适配，有的则成为大模型对齐与应用的基础工具。然而，这些看似分散的技术路线，背后是否存在一个更统一、更本质的理论视角？&lt;/p&gt;&lt;p&gt;近期，来自墨尔本大学可信赖机器学习与推理（TMLR）研究小组和 IBM AI 研究所的研究者系统性地提出了「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;神经网络可重编程性（Neural Network Reprogrammability）&lt;/strong&gt;」这一统一主题，在最近的一篇 survey 中，将模型重编程，Prompt Tuning、Prompt Instruction 和 In-context Learning 纳入同一分析框架，从操纵位置、操纵类型、操纵算子和输出对齐四个维度进行了系统梳理与对比。同时，该团队也在 &lt;strong&gt;AAAI 2026&lt;/strong&gt; 上带来同名 Tutorial，帮助研究者与工程实践者全面理解这一正在重塑模型使用范式的关键能力。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKthhaZfstBYEWww653MgCZW9vHj5tRISAbqJNFiakkxQApOvIRVHmhXg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3314814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529488" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/53b2cd60-6877-4527-b26c-26fd91096cf1/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Tutorial 标题：Neural Network Reprogrammability: A Unified Framework for Parameter-Efficient Foundation Model Adaptation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文标题：Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Arxiv: https://arxiv.org/pdf/2506.04650&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GitHub: https://zyecs.github.io/awesome-reprogrammability/tutorial-AAAI26/&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;1. 模型训练范式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在本文中，我们认为随着预训练模型（pre-trained model）规模的增长，其适配下游任务（downstream tasks）的范式已经发生了根本性转变：从传统的基于模型参数调整的适配（图 1a）转变为了基于模型可重编程性的适配（图 1b）。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKyEJAkSFh7ibv8HVWLicS5icKzCwqalF8M6cbA8fhKKIz91BibicQz1RY8dQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5055555555555555" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529489" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/021808a1-c747-4f2d-965b-9c4dbad23995/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;传统适配技术（parameter-centric adaptation, PCA）通过重新训练预训练模型，&lt;strong&gt;修改模型内部参数&lt;/strong&gt;，使其适用于新的下游任务。例如，将 ImageNet 预训练的图像分类器应用于猫狗分类任务时，需要至少改变分类头，甚至重新训练其他层的参数，即我们通常所说的 fine-tuning，本质上改变了模型学习到的内部表征（representation），并需要为每个下游任务维护一份新的参数拷贝。&lt;/p&gt;&lt;p&gt;新兴适配技术（基于模型可重编程性的适配，reprogrammability-centric adaptation, RCA）则采用了一种不同的理念：保持模型参数冻结，转而&lt;strong&gt;策略性地修改任务呈现的方式&lt;/strong&gt;，通过精心设计下游任务的输入变换（包括模型输入（input）、提示（prompt）或上下文信息（context）），以及模型输出对齐方式（output）来使其兼容下游任务，使用极少量可训练参数（甚至完全不引入新参数），在不触及模型权重的情况下「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;重编程&lt;/span&gt;」预训练模型的行为。&lt;/p&gt;&lt;p&gt;核心转变体现在&lt;strong&gt;理念上的转换&lt;/strong&gt;：从「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;修改模型以适应任务&lt;/strong&gt;」转向「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;修改任务以适应模型&lt;/strong&gt;」，从而使我们能以最小的计算开销在不同任务中重复使用预训练模型，同时保持其原有能力。同一个冻结的模型仅通过改变与其「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;对话」的方式，就能处理多种不同的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 可重编程性范式的效率优势&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体实验数据表明（图 2），相较 PCA，RCA 在参数效率上有明显优势。将 ImageNet 预训练的视觉 Transformer（ViT-B/32）适配到遥感图像分类任务（EuroSAT）。柱状图显示不同 fine-tune 策略的参数需求：从左到右分别对应 fully fine-tune 到逐步减少可训练层数的各种配置，训练参数量随之下降。但即便是最轻量的 PCA 方案仍需要大量参数。&lt;/p&gt;&lt;p&gt;形成对比的是，&lt;strong&gt;红色虚线&lt;/strong&gt;显示 RCA 需要的训练参数始终比任何 PCA 配置少 2-3 个数量级。这些参数用于输入变换和输出对齐，而不是修改预训练模型的内部权重。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKpDVb56yxjO5qicxEoyqbEzO8LDXSJBdbphS2c8pkpUIj8yXzA2adx5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7064814814814815" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529490" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/63a68e04-7a94-40dc-9a0e-220a98936494/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;这表明，在可以实现 comparable performance 前提下，RCA 的参数效率更高，使得在资源受限环境中适配大模型成为可能，并支持同时适配多个任务而不会出现灾难性遗忘。在预训练模型规模与能力不断提升、获取方式日趋不透明（如商业模型仅提供 API 接口）的背景下，RCA 的优势愈发突出。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 可重编程性范式的「&lt;/strong&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;多种称谓」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;然而，我们发现相似甚至相同的模型适配方法在不同研究社区却有着截然不同的命名：NLP 社区常称之为「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;prompt tuning」，而 ML 文献中研究者更倾向于使用 「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;model reprogramming」指代这类方法。经验上，这种术语混乱也经常引发 「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;哪种方法更优」、&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;为何不比较其他方法」&lt;/span&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;等争论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;核心问题在于：prompt tuning，model reprogramming，甚至 in-context learning 真的代表不同的模型适配方法吗？答案是否定的。尽管表现形式各异，这些方法实质上都利用了神经网络的同一固有属性 -- neural network reprogrammability （神经网络&lt;strong&gt;可重编程性&lt;/strong&gt;，图 3）。基于这一认识，我们提出统一框架来连接三个独立发展的研究领域，并系统性地描述和归类这些适配方法。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKAwib5hdtiacl6aByiaUq1fupXxLAyIKHBawB6O8y1qJZ7yiaekufssrJDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5101851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529492" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3264161f-ca68-43a3-864b-a1fdfc57db0d/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键点 1. 可重编程性的普适性。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;它具备架构无关性和模态无关性，跨越三个核心维度：适配方法，预训练模型架构（单模态类型、多模态模型、专门架构），以及数据类型（图像、文本、音频、图结构等） -- 无论具体实现细节如何，&lt;strong&gt;围绕模型接口的信息操作&lt;/strong&gt;（information manipulation at model&amp;rsquo;s interfaces）这一共同的底层原理，我们都能将任意预训练模型适配到任意下游任务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. 可重编程性范式的首次提出（ICLR 2019）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么什么是 reprogrammability 呢？下面这张图片展示了从神经网络对于对抗样本的脆弱性（sensitivity to adversarial examples）向可重编程性（reprogrammability）的演进。图片来自文章《Adversarial reprogramming of neural networks》由 G. F. Elsayed, I. Goodfellow, and J. Sohl-Dickstein. 发表于 ICLR 2019.&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKxLrVLcyd1m11oiayic31960YHicicYwoBxibIo4LwpYc6lpNkMCXLWpHEIw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.20185185185185187" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529494" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d6201345-6572-4d13-b21a-185e9cc021c1/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;左侧（传统对抗样本 adversarial example）：展示了经典对抗攻击，在熊猫图像上添加不可察觉的噪声，就能使 ImageNet 分类器将其错分为长臂猿，置信度高达 99.3%，尽管图像在人眼看来没有变化。&lt;/p&gt;&lt;p&gt;右侧（对抗重编程 adversarial reprogramming）：展示了如何将这种脆弱性转化为建设性用途。我们不仅欺骗模型，同时将其「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;重编程」以执行完全不同的任务：&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;（a）&lt;/span&gt;展示了一个黑白格图像的计数任务，我们可以人为将不同的动物类别映射到方块数量类别（1-10 个方块）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;（b）&lt;/span&gt;展示了「对抗程序」（adversarial program） -- 精心设计的噪声，充当指导模型行为的指令（可以理解为 prompt）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;（c）&lt;/span&gt;将（a）和（b）结合后，仅在 object recognition 任务上预训练的 ImageNet 分类器被「重编程」以执行方格计数任务，可以输出「4 个方格」的预测结果（从源域的「虎鲨」类映射得到）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;关键点 2. 巧妙利用神经网络的敏感性。&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;由对抗样本发现的神经网络敏感性（理论背景包括决策边界的不连续性等），正是可重编程性的基础。我们不再将这种敏感性仅视为安全缺陷，而是建设性地利用它，在不重新训练的情况下将预训练模型重定向到新的任务。精心设计的 program/prompt 可以将神经网络感知的弱点转化为高效的适配机制。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKSKe3tNiawheo7zPhNb7laV4uMkLbicHZ7JHh1jY72jSSjBCR7g77jKUw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.425" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529495" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d69d9eba-e8c8-4f0e-8e4c-4c4d2a171fbf/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;5. 可重编程性范式的数学表达&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如上，我们给出 neural network reprogrammability 统一框架的定义，涵盖了文章中讨论的各类模型适配方法。定义如下：&lt;/p&gt;&lt;p&gt;给定源域（source domain）上预训练的模型&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKNwbMzxBMRcgbYa1snbNhXcdpCatOTAH8IcpUuUxtyzd8SrRshyXLgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.4350282485875706" data-s="300,640" data-type="png" data-w="354" type="block" data-imgfileid="503529497" data-aistatus="1" data-original-style="width:52px;height:23px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5e5383d8-160b-4007-ad35-af336b783700/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dii" style="width: 7.06%;"&gt;，该模型从源域输入空间&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKo3M6HibHmCznRXFFia4UUs0S1zxP41GMyPUiabKHS9lT5xo7pjrZMMjWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.85" data-s="300,640" data-type="png" data-w="200" type="block" data-imgfileid="503529498" data-aistatus="1" data-original-style="width:29px;height:25px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/2513e3eb-0521-4d27-9c35-b8e0dc19a01d/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 3.76%;"&gt;映射到源域输出空间&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKrABG7Gg4ibs7tZ3zEp20qjIpSJ2t6icoANk2AKVLtZ6qTA0H6ZI709QA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.794392523364486" data-s="300,640" data-type="png" data-w="214" type="block" data-imgfileid="503529499" data-aistatus="1" data-original-style="width:31px;height:25px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/92d96cde-ef65-4350-bee5-aa2fcf982e37/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 4.86%;"&gt;。神经网络可重编程性使这个固定模型（参数不再改变）能够通过两个&lt;strong&gt;可配置&lt;/strong&gt;的变换在&lt;strong&gt;完全不同&lt;/strong&gt;的目标域（target domain）实现由该域输入 / 输出空间&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKziaAsjbKibUDffZlSBW2c8zhLFz1wG9GCkhBGWibyNIcpWqysialG5Y8rA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.40594059405940597" data-s="300,640" data-type="png" data-w="404" type="block" data-imgfileid="503529500" data-aistatus="1" data-original-style="width:56px;height:23px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/b64ddcbe-2a6e-40e3-aa74-2ffa98aab49d/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 7.15%;"&gt;定义的目标任务：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;输入操作（input manipulation）&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK9Rv3rXR1ma7Ih2xssdSxqjWibRGRiaqA7MxWMW4P1cpYPDYuCcYZaZIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.3053435114503817" data-s="300,640" data-type="png" data-w="524" type="block" data-imgfileid="503529501" data-aistatus="1" data-original-style="width:65px;height:20px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/576fbdd7-dda3-4c61-a9dd-5668eb6e8d1f/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 9.99%;"&gt;该变换将目标任务的输入转换为预训练模型可处理的格式，这可能是通过添加可学习的 prompt、拼接 demonstration examples 或应用 adversarial perturbation 到目标样本上。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出对齐（output alignment）&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKMV5fkKldO91iauqOwaXegBgJbicicKxyEduB0vwP6iatXpYM6AK2h9lX6g/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.3383458646616541" data-s="300,640" data-type="png" data-w="532" type="block" data-imgfileid="503529502" data-aistatus="1" data-original-style="width:70px;height:24px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/3d0c8566-a446-4c9d-b2fc-6a06090718d2/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 10.74%;"&gt;该变换将预训练模型的源域预测映射到目标任务的输出格式。这可能涉及到 label mapping, structured parsing 或 linear projection 等。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;将这两个变换与预训练模型结合，我们得到重编程后的预训练模型&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKWmmiaAwXbEE9qCK6drVLSSJ1872EqoPR957tH4Y0luyK2GibUmIiafo5Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.25076452599388377" data-s="300,640" data-type="png" data-w="654" type="block" data-imgfileid="503529503" data-aistatus="1" data-original-style="width:110px;height:28px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/8792d7ad-1d63-4ff7-b906-f48896cc2c2d/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 15.49%;"&gt;。这个看似简单的复合函数可以描述上述模型适配技术的本质，这些看似不同的方法实际上只是同一基本原理的不同实例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6. 可重编程性范式的具体案例&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;以视觉 - 语言模型（Vision-Language Model）为例，说明三种可重编程方法在实现上的差异（如图 4 所示）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;（4a） model reprogramming （MR）&lt;/strong&gt;：主要在模型&lt;strong&gt;原始输入层&lt;/strong&gt;操作。可学习的扰动直接添加到输入图像上。模型通过图像和文本编码器处理这些修改后的输入，需要&lt;strong&gt;输出对齐&lt;/strong&gt;将模型的原始预测映射到新的目标任务。这种方法适用于可访问模型的输入和输出，但对内部模型组件控制有限的情况。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;（4b） prompt tuning （PT）&lt;/strong&gt;：主要在&lt;strong&gt;中间表示层&lt;/strong&gt;操作。可学习的 tokens 或嵌入（embedding）被插入到模型的内部层（包括图像编码器和文本编码器）。这些「软提示」可以在嵌入层（embedding layer）或隐藏层（hidden layers）进行前置或插值，在保持核心参数冻结的同时允许对模型内部处理进行更直接的控制。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;（4c） prompt instruction （PI）&lt;/strong&gt;：通过&lt;strong&gt;上下文演示（contextual demonstration）&lt;/strong&gt;操作。该方法不使用可学习参数，而是提供多个示例图像和明确的文本指令来引导模型行为。模型从提供的演示中「上下文」学习任务，无需任何参数更新。该方法的有效性主要在 LLMs 和 large vision-language model/multi-modal LLMs 上可观察到。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;操作位置&lt;/strong&gt;：输入空间 （MR） &amp;rarr; 嵌入 / 隐藏空间 （PT） &amp;rarr; 输入空间 （PI）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数需求&lt;/strong&gt;：可学习扰动 （MR） &amp;rarr; 可学习 tokens（PT） &amp;rarr; 无新参数 （PI）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;访问要求&lt;/strong&gt;：输入访问 （MR） &amp;rarr; 白盒访问 （PT） &amp;rarr; API 级访问 （PI）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本质上，三种方法都实现了相同目标 -- 将冻结模型重新用于新任务 -- 通过计算图中的不同路径实现。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKEoUltQibKhmfORt2TpvbyEslh3KxiajaibkeqglwhuRSeNqQEIicibRKxaQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.4398148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529504" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/caf6085b-cfd1-45f9-b609-5ebb47ff12d7/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;Neural network reprogrammability 如何在不同模态和任务中具体实现呢？&lt;/p&gt;&lt;p&gt;（a） model reprogramming for 图像分类任务（图 5a）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;输入操纵：目标图像经过调整大小并与可学习扰动模式 &amp;lambda; 结合。这将目标任务输入转换为预训练分类器可处理的格式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;预训练模型：冻结的图像分类器 （如 ResNet, ViT） 处理操纵后的输入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出对齐：将分类器的原始类别预测转换到目标任务的标签空间（不同类别，可能不同数量的类别）。即实现了 Label Mapping 步骤，不需要额外的训练参数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练：仅通过反向传播优化扰动参数 &amp;lambda;，模型权重保持冻结。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;（b） prompt tuning for 文本生成任务（图 5b）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;输入操纵：可学习的 prompt tokens &amp;lambda; 通过拼接操作前置到目标文本输入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;预训练模型：冻结的 language generator（如 GPT）处理提示增强的输入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出对齐：因为模型已经在目标文本空间输出，无需额外转换。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练：仅优化提示参数 &amp;lambda;，保持生成器完全冻结。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKVTjf28AIQhR2L3sPDiaicwKPXEGT47noEHhbHib5AQdw70uxMsqWzMRnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5351851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529505" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/a2cdd8eb-28a4-44a6-9279-da09ee29ff23/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;关键点 3. 数学框架下的一致性。 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管操纵不同模态（视觉 vs 语言）、任务类型（分类 vs 生成）并使用不同的输入操纵策略（加性扰动 vs 连接提示），两种方法都遵循完全相同的数学框架。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7. 基于可重编程性范式，归纳现有方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于这个特性，我们进一步提出了一个分类法（taxonomy），将过往的研究工作组织为跨四个维度的连贯结构，并展示了 neural network reprogrammability 这一框架的泛用性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;操纵位置：定义输入操纵发生在预训练模型的哪个接口，包括原始输入空间（input space），嵌入空间（embedding space），以及隐藏空间（hidden space）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;操纵类型：定义输入操纵的类型，分为可优化（learnable）和固定（fixed）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;操纵算子：定义输入操纵如何被应用到目标数据（target input）上，包括加性（additive）、拼接（concatenative）、参数化（parametric）算子&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出对齐：定义是否模型输出需要进行额外操作以对齐目标任务（target output），包括恒等映射 （identity mapping）、结构变换（structural alignment）、统计变换（statistical alignment）、线性变换（linear alignment）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对应地，MR，PT 和 PI 对应的研究方法可以被系统归类，如表格 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKo3p4ibP5s269JSLskDBfQ9tqHcdDBiceojztb852a2ribqckTN5twP8JQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.42314814814814816" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529506" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/d6539237-411e-45fa-b195-e6bbc7a19e7d/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;8. 如何用可重编程性范式来理解 In-context learning 和 Chain-of-Thought Reasoning&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKtzavdST55JRHNZokVraSQIOCDIKRMx4zqho374CgutdiaEHnQ25JV5A/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.387037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529510" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/be8059d0-1600-41b7-97cd-447896ec488d/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;特别地，LLM 的上下文学习 in-context learning （ICL） 在该框架下可以描述为&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;固定输入操纵：无训练参数，依赖人为设计的 demonstration examples&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;原始输入空间操纵：demonstration example 直接与模型的 text query 拼接&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;拼接操纵算子：demonstration example 通过拼接操作&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;隐式输出对齐：无需额外显式映射，预训练模型直接生成目标输出或依靠模型自身能力对输出进行基于规则的格式、结构调整（见下图示例，ChatGPT 可以直接对模型输出的 natural language 进行格式限制，e.g., bullet list, LaTeX）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKibHIrfaLl7jhm6ibVQguIfZUSsD6OgJ5KjQib1g0Zxvq3eD4M2mEhaU5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.5092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529507" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/dea20abf-9534-49a9-89aa-94fa888903f1/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;因此，模型通过这些示例在「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;上下文」中学习目标任务的模式，且无需任何参数更新。Demonstration examples 本质上是一种输入操纵，通过策略性构造输入，从而重编程模型行为。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKMcUmr6beXockcfTyyxWMgvOaEVO5A989cI610KuITl5zvH3ZtahseQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.4148148148148148" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529508" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/f0036c53-8ed6-4985-83df-5904ede6e4ae/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;对应地，思维链推理（Chain-of-Thought Reasoning）可被认为是一种通过融入结构化、与输入样本特定相关的（sample-specific）「&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"margin-left: 8px;margin-right: 8px;line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;推理形式」的输入操纵。&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;输入操纵：具备增强的上下文信息，不仅包含输入 - 输出对，还包含&lt;strong&gt;明确的中间推理步骤&lt;/strong&gt;。例如，解决数学问题时，CoT 会包含「问题 -&amp;gt; 第一步计算 -&amp;gt; 第二步计算 -&amp;gt;&amp;hellip;-&amp;gt; 最终步骤」的完整推理过程。另外，每个目标输入 query 都会触发模型生成与&lt;strong&gt;该具体 query 匹配&lt;/strong&gt;的推理链。比如解决「23&amp;times;47=?」时，模型会生成针对这两个具体数字的逐步计算过程，而不仅是通用的乘法公式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;输出对齐：由于模型输出完整的推理序列（「首先计算 23&amp;times;40=920，然后计算 23&amp;times;7=161，最后 920+161=1081」），因此需要结构化、基于规则的解析机制（structural alignment）从这个推理文本中提取最终数值答案。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;9. 资源分享：Awesome Neural Network Reprogrammability 资源库&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了方便社区追踪这一飞速发展的领域的最新进展，我们维护了一个 Awesome 风格的资源库，收录并持续更新 Neural Network Reprogrammability 领域的最新论文和代码实现。希望这个资源库能让你少走弯路！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;GitHub: https://zyecs.github.io/awesome-reprogrammability/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你正在做相关方向，欢迎在 GitHub 上 star 支持，或者来仓库一起补全与更新！&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>1月28日，直播预约！来聊聊具身评测中的科学与乱象</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 24 Jan 2026 20:23:32 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-24-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-24-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD91ejQabpM8dh70KoznYia0L1xXmDrmXlX1RJrD0IhDFvy26mdTGGYjQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.562962962962963" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD91ejQabpM8dh70KoznYia0L1xXmDrmXlX1RJrD0IhDFvy26mdTGGYjQ/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="549" data-cropsely2="309" data-imgfileid="503529964" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/868ccbfe-4ebd-4379-8aca-3ec2cd126bd9/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;过去一年，我们几乎每周都能看到各种惊艳的机器人 Demo：机器人会叠衣服了、会做咖啡了、会跳各种舞了。但在繁荣的背后，有一个问题越来越频繁地被提起，那就是：&lt;strong&gt;我们到底怎么判断一个具身模型是真的进步了&lt;/strong&gt;&lt;strong&gt;？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具身评测是具身智能产业发展的&amp;ldquo;度量衡&amp;rdquo;，是技术从实验室走向产业化的必经之路。&lt;/p&gt;&lt;p&gt;但一走出实验室，面对真实世界的复杂、多变和不确定性时，那些号称接近完美的成功率往往会瞬间&amp;ldquo;缩水&amp;rdquo;。&amp;ldquo;刷榜容易，落地难&amp;rdquo;，成为了悬在具身智能商业化路上的达摩克利斯之剑。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;1月28日（下周三）晚19:00&lt;/strong&gt;，直播即将开启。&lt;/p&gt;&lt;p&gt;本次圆桌对话由&lt;strong&gt;机器之心创始人兼CEO 赵云峰&lt;/strong&gt;主持，特邀四位产业与学术专家：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;范浩强，Dexmal 原力灵机Co-Founder&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;李永露，上海交通大学副教授、上海创智学院全时导师&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;沈宇军，蚂蚁灵波科技首席科学家&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;赵行，星海图联合创始人、清华大学助理教授&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;共同深入探讨具身智能评测的真实现状与核心挑战。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDY22wadPMwbFWPs8x5xdzlLCCCSvPCwhyXkxibpcSUca6aiayoJvvkqPQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.7777777777777777" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDY22wadPMwbFWPs8x5xdzlLCCCSvPCwhyXkxibpcSUca6aiayoJvvkqPQ/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="555" data-cropsely2="986" data-imgfileid="503529963" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/56c4528a-6b71-4cf5-9894-f68e45c26085/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;圆桌嘉宾&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDAlZYrZagBXKM7FiaGulia4j8CHw9dpPAkqoraK15Ib6AHE7yvkhgVNBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1" data-s="300,640" data-type="png" data-w="785" data-imgfileid="503529949" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b16caec3-21d2-47e6-b69f-d759d45fec7f/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;范浩强 | Dexmal 原力灵机Co-Founder&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;范浩强毕业于清华姚班，高二时即作为第6号员工加入旷视团队，曾任旷视研究院助理院长，主导多项CV（计算机视觉）技术从实验室到千万级产品的转化，擅长软硬结合交叉领域技术。其核心学术成果在CVPR、ICCV、AAAI等国际顶级学术会议上多次发表，研究方向覆盖人脸识别、活体检测、3D 重建、计算摄影等多个领域。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDbYKYYXGWib05Kg15U0j3DRiceXRIAtBibsTdgxmY85khpLZeK60hplCnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1" data-s="300,640" data-type="png" data-w="1080" data-imgfileid="503529951" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b9f96794-b49c-4629-9b98-463f11cb1a6e/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;李永露 |&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;上海交通大学副教授、上海创智学院全时导师&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;李永露博士，上海交大副教授、上海创智学院全时导师，博导，研究具身智能、物理推理、行为理解。在TPAMI、CVPR、NeurIPS、CoRL等发表成果50余篇，引用100+论文8篇，获ICRA 2025 Best Paper Award（HRI，独立通讯），开源项目获Github star 1.3万+；代表工作HAKE（引用1.48k+，Github Star 2.18k+，官网全球访问16.8万+次）、AlphaPose（引用780+，Github Star 8.3k+）。任NeurIPS、ICLR Area Chair，上海交大ACM班《计算机视觉》课程教师， VALSE EACC，中国人工智能学会-具身智能专委会副秘书长。主持、参与多项国家级项目，如青基、科技部重点研发计划等。获上海市海外高层次人才、中国人工智能学会吴文俊人工智能科学技术奖-优秀博士学位论文、蚂蚁Intech奖、WAIC云帆奖-璀璨明星、明日之星、AI100青年先锋、世界互联网大会领先科技奖、NeurIPS&amp;rsquo;20/21杰出审稿人、百度奖学金、华人AI新星百人等。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD7SEaoRbmUqh4J6ucoWjpXXVqKlUkuZVRZwNPhxRQSoLREdW6eG0kFw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1" data-s="300,640" data-type="png" data-w="480" data-imgfileid="503529948" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/afaf25b6-d459-423b-b3ec-06dc07a6e658/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;沈宇军 | 蚂蚁灵波科技首席科学家&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;沈宇军，博士毕业于香港中文大学，研究方向是计算机视觉和生成模型，现任蚂蚁灵波科技首席科学家，努力探索计算机视觉在机器人行业的落地之路。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDWGx61BwxGIAvuqA751L0v5Z2M15YbpI7e6NvXtMIdNLRRCHTwKu4Hg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1" data-s="300,640" data-type="png" data-w="851" data-imgfileid="503529954" data-aistatus="1" data-original-style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/dde92642-8f47-4e00-99bc-7eae48d3b0b1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;赵行 | 星海图联合创始人、清华大学助理教授&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;赵行博士毕业于美国麻省理工学院MIT，后于谷歌无人车项目Waymo担任研究科学家。赵行长期致力于机器人学习和自动驾驶的研究。曾获机器人学习顶会CoRL 2023最佳系统论文奖提名，ICCP最佳论文奖，麻省理工科技评论&amp;rdquo;35岁以下创新35人&amp;rdquo;，世界人工智能大会最高奖项&amp;ldquo;SAIL之星&amp;rdquo; 奖等荣誉。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&amp;nbsp;直播预约&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;直播主题：&lt;/strong&gt;&lt;strong&gt;「聊聊具身评测：科学与乱象」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;直播时间：&lt;/strong&gt;&lt;strong&gt;1月28日 19:00 - 20:00&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;直播预约：&lt;/strong&gt;&lt;a href="https://mp.weixin.qq.com/s/ZofR4pwm6zUEPsmwvO_EgA"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/db11a792-9f20-4abc-904b-a4e7c2196bf3/1769257343860.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;section&gt;&lt;p data-pm-slice='3 3 ["para",{"tagName":"section","attributes":{"style":"font-size: 14px; color: rgb(67, 65, 65); letter-spacing: 1px; line-height: 2; padding: 0px; box-sizing: border-box; font-style: normal; font-weight: 400; text-align: justify;","data-pm-slice":"0 0 []"},"namespaceURI":"http://www.w3.org/1999/xhtml"},"para",{"tagName":"section","attributes":{"style":"color: rgb(0, 0, 0); text-align: left; padding: 0px 10px; box-sizing: border-box;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;strong&gt;我们不见不散！&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>LeCun、谢赛宁团队重磅论文：RAE能大规模文生图了，且比VAE更好</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 24 Jan 2026 20:20:28 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-24-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-24-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;p&gt;在文生图模型的技术版图中，VAE 几乎已经成为共识。从 Stable Diffusion 到 FLUX，再到一系列扩散 Transformer，主流路线高度一致：先用 VAE 压缩视觉信息，再在潜空间中完成生成。这条路径被反复验证、规模化扩展，也几乎没有再被认真挑战过。&lt;/p&gt;&lt;p&gt;但挑战者其实早已到来，它就是谢赛宁团队提出的&lt;strong&gt;表征自编码器（RAE）&lt;/strong&gt;，详见我们去年十月的报道《&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650995317&amp;idx=1&amp;sn=893a75b049fe049a6e9b9ea46e3049cb&amp;scene=21#wechat_redirect" target="_blank"&gt;VAE 时代终结？谢赛宁团队「RAE」登场，表征自编码器或成 DiT 训练新基石&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;现在，RAE 方向又诞生了一项新的重磅成果。并且是来自 Rob Fergus、Yann LeCun 以及谢赛宁三位业内知名学者领导的一个联合团队。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDytx4rsv4EbvYWYkcaX1RNR9m2iatCITWUHXvGRLfR0CtprUFYdalCQw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2037037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529931" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/c2dae336-1760-4ff8-b868-a6570dfc379b/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2601.16208v1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/ZitengWangNYU/Scale-RAE&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目页面：https://rae-dit.github.io/scale-rae/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;他们解答了一个更加基础的问题：&lt;strong&gt;我们真的需要 VAE 才能做好大规模文生图吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇工作给出的答案颇为激进。该团队系统性地扩展了「表征自编码器」这一思路，在冻结的语义表征编码器之上构建扩散模型，从 ImageNet 一路扩展到大规模自由文本生成场景。&lt;/p&gt;&lt;p&gt;结果显示，在从 5 亿到近百亿参数的多个尺度上，&lt;strong&gt;RAE 不仅在预训练阶段全面优于当前最强的 VAE 方案，还在高质量数据微调时展现出惊人的稳定性&lt;/strong&gt;，而 VAE 模型却在短短 64 个 epoch 后出现灾难性过拟合。&lt;/p&gt;&lt;p&gt;可以说，这篇论文释放出了一个相当具有颠覆性的信号：当理解与生成共享同一套语义表征空间时，扩散模型的复杂工程设计反而可以被大幅削减。更进一步，这个思路或许有望打开&lt;strong&gt;多模态统一模型&lt;/strong&gt;的想象空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;架构设计：以表征自编码器重塑潜空间&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在传统的潜向扩散模型（LDM）中，VAE 的作用是将图像压缩进一个极低维度的空间。然而，RAE 采用了截然不同的逻辑：它直接耦合一个预训练且冻结的视觉表征编码器（如 SigLIP-2），并仅训练一个轻量化的 ViT 结构解码器用于像素重建。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDQuDGRdkdCibBcKyTCln4niagzib6oN9qibW8r7W0Nvj8p2X162ibQoWZDLg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3675925925925926" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529932" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/b4f06b2f-6ddc-40c7-bde3-a05f03c455bf/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;以研究中采用的 SigLIP-2 So400M 为例，它会将一幅图像转化为 16&amp;times;16 个 token，每个 token 的维度高达 1152。这一维度远超主流 VAE 方案（通道数通常小于 64），为生成过程提供了极高保真度的语义起点。为了将这一思路从 ImageNet 推广至复杂的文本生成场景，研究团队进行了三项深度的架构探索。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;超越规模的数据组成策略&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究发现，单纯增加数据量并不能让 RAE 完美处理文生图任务。团队构建了一个包含约 7300 万条数据的大规模数据集，涵盖了 Web 图像、由 FLUX.1-schnell 生成的高美感合成图像以及专门的 RenderedText 文本渲染数据。&lt;/p&gt;&lt;p&gt;实验数据揭示了一个关键的技术细节：虽然在 Web 规模数据上训练能提升模型对自然图像的泛化能力，但对于「文本渲染」这一特定领域，数据的组成比例至关重要。&lt;/p&gt;&lt;p&gt;如表 1 所示，若缺乏针对性的文本渲染数据，解码器即使在数千万张 Web 图片上训练，也无法还原出清晰的字形细节。只有引入了文本专项数据后，其在 Text 域的 rFID 分数才出现了质的飞跃。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDYGS27TtuBdhOgLCJe3QjceC7VzP1NuJLKiaJ2VCP2OXFUyTIGFIHibGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5287221570926143" data-s="300,640" data-type="png" data-w="853" type="block" data-imgfileid="503529934" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9b98b8d7-c08e-4215-9222-e76765707fe1/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;除了数据组成，研究团队还对比了不同视觉编码器作为 RAE 后端的重建质量。如表 2 所示，在 ImageNet、YFCC 以及文本（Text）这三个维度上，RAE 方案展现出了极具竞争力的保真度。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDcUHGLicoacXSqzpnMBXQaYjz0krGnv1Yg2jaKE7tzKpsx5b1IjeOP1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.523943661971831" data-s="300,640" data-type="png" data-w="1065" type="block" data-imgfileid="503529935" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/f46b0507-8168-4eec-8bcb-b70c40e927c9/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDjnibricdgIKpnqUDl7OwPiaBqd9ctX8JPDkpjiahEas36GYNUKBzhqx8vA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529937" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/425bccc9-c3a3-4af7-a637-87594955f7db/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;虽然 RAE 在绝对重建指标上目前还稍逊于顶尖的 FLUX VAE，但它已经全面超越了此前文生图领域的标杆 SDXL VAE。实验进一步发现，基于自监督学习（SSL）训练的 WebSSL ViT-L 编码器在图像重建任务中比 SigLIP-2 表现更优。这证明了 RAE 框架具备极佳的通用性，能够适配不同预训练目标的视觉编码器。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;潜空间维度相关的噪声调度&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;由于 RAE 操作的是极高维度的语义表征，传统的扩散模型噪声调度方案会因为维度灾难而失效。为了解决这一数学难题，研究团队引入了维度敏感的&lt;strong&gt;噪声调度平移（Noise Schedule Shift）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;其核心逻辑是根据有效数据维度 m（即 token 数量 N 与通道维度 s 的乘积）对基础调度 t_n 进行重缩放。其计算公式如下：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD9oTf42GucibZv0NYKzibSibZTeKDic6Wg80MUfcOkXnwDVmuSzln4KG68g/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.17958412098298676" data-s="300,640" data-type="png" data-w="529" type="block" data-imgfileid="503529936" data-aistatus="1" data-original-style="width: 302px;height: 54px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d65185ed-5319-4d0e-be8c-b14a760d114e/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 &amp;alpha; 是比例因子，n 为参考基准维度。实验证明，应用这一平移变换对模型收敛至关重要，不带平移的模型在 GenEval 上的表现甚至不及带平移模型的一半。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;大模型时代的结构化减法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 RAE 最初针对 ImageNet 的设计中，为了增强模型能力，曾引入过复杂的「宽扩散头（DiT^DH）」以及「噪声增强解码（Noise-augmented decoding）」。然而，这篇论文通过严谨的消融实验发现，当扩散 Transformer（DiT）的规模扩展至十亿参数以上时，这些复杂设计反而成了冗余。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDZA41DX4O5sh1jMUBSUWUdmht7xoeGViaoL20Kmia1ogcKne2O9a5Rg1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.171951219512195" data-s="300,640" data-type="png" data-w="820" type="block" data-imgfileid="503529938" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/58f1e904-c8e0-41a1-8013-ec23f2f84e2b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构冗余&lt;/strong&gt;：DiT^DH 这种窄骨干配合宽头的设计在 0.5B 规模下能带来 11.2 的 GenEval 提升，但当 DiT 扩展至 2.4B 以上时，其增益会迅速消失。这是因为大模型本身的隐藏维度（d&amp;ge;2048）已经天然覆盖了 RAE 的潜空间需求。&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练简化&lt;/strong&gt;：原本用于缩小训练与推理分布差距的噪声增强解码，在训练后期（约 120k 步后）提供的增益也趋于零。这表明在大规模预训练下，模型能够自行学习到足够健壮的潜流形，从而摒弃繁琐的正则化手段。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;实验表现：从极速收敛到无惧过拟合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在从 0.5B 到 9.8B 参数的多个 DiT 尺度上，将 RAE 与目前最先进的 FLUX VAE 进行了系统性对比。&lt;/p&gt;&lt;p&gt;在相同的算力与数据条件下，RAE 展现出了显著的收敛速度优势。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDHRiby7gmw5P0Lbqb3zT8Wk5a24sNpjgtJdeia1ej989GAvTeUB5wrYZQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.682741116751269" data-s="300,640" data-type="png" data-w="788" type="block" data-imgfileid="503529939" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/c471d511-69db-4a83-a43e-a5004700c76a/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在 1.5B LLM 与 2.4B DiT 的基准测试中，RAE 达到同等生成质量所需的时间仅为 VAE 的四分之一左右。在 GenEval 评测中实现了 4.0 倍加速，在 DPG-Bench 上更是达到了 4.6 倍加速。&lt;/p&gt;&lt;p&gt;这种由 RAE 带来的效率提升与性能增益，在模型规模扩展过程中表现出了极强的鲁棒性。研究团队通过图 5 系统性地评估了 DiT 规模以及 LLM 骨干规模对最终生成效果的影响。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDn3KAQP5cP9MekoEzS09JQUpaNLeAj9OeBBkdRdMibIc4246FYX8lvvw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.1502890173410405" data-s="300,640" data-type="png" data-w="865" type="block" data-imgfileid="503529941" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2bc77f0a-4b97-4dbe-b947-dccf54f1a242/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在 0.5B 到 9.8B 参数的所有 DiT 尺度下，RAE 均能稳定且大幅度地优于 VAE 方案。即便是在 DiT 隐藏维度仅略大于 RAE 潜空间维度的 0.5B 小模型上，这种优势依然清晰可见。此外，当 LLM 骨干从 1.5B 升级至 7B 时，RAE 模型能够更好地利用更丰富的文本表征，从而获得进一步的性能跨越。&lt;/p&gt;&lt;p&gt;这一发现极具启发意义。以往研究往往认为 LLM 规模的增加对文生图任务的增益有限，但本论文通过微调 LLM 骨干，证明了当生成与理解在同一个语义潜空间中对齐时，更大的语言模型确实能释放出更强的生成潜力。&lt;/p&gt;&lt;p&gt;而在针对高质量数据集（如 BLIP30-60k）进行的精细化微调中，RAE 与 VAE 方案的表现分化更是令人震惊。传统的 VAE 模型在训练至 64 个 epoch 左右后，会发生灾难性的过拟合，性能指标呈断崖式下跌。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDe8b2Go73N3LcbS25zTIJ7iclEticnMPlAjjiaLfI8oYyB28ibJLFV5ibugg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.6821808510638298" data-s="300,640" data-type="png" data-w="752" type="block" data-imgfileid="503529940" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c172421a-fe15-482b-b1b1-e3af839436c3/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;损耗曲线显示 VAE 的 Loss 会迅速跌至近乎为零，这意味着模型正在机械地死记硬背训练样本。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoDtyBskek0Ym1ytpLKNKWeKHKNibiaOonDRx69c0wEZJoicd8CibQpEVXz3A/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.5990740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529942" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/10273935-fe63-404a-a347-8398d339f2db/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;相比之下，RAE 表现出了极强的鲁棒性。即使持续微调至 256 个甚至 512 个 epoch，RAE 依然能保持稳定的生成质量。这种「天然」的防过拟合特性，或许得益于高维语义空间提供的隐式正则化作用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;迈向多模态统一的新可能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RAE 的意义不仅在于生成，它还让&lt;strong&gt;理解与生成&lt;/strong&gt;在同一套语义特征空间中运行。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibaia3E2vEv1GKq10C6JGAoD3cLJibI2icibO3hAFzY7GbxROOObB5GLbKPj5qQxO6CjwfIc0byllianHA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6916666666666667" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529943" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c7e140fe-6077-4b18-b399-4183bfc5460e/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;理解能力保全&lt;/strong&gt;：实验结果显示，在加入生成训练后，模型在 MME、MMMU 等视觉理解榜单上的性能保持完好，甚至略有提升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;潜空间测试时缩放（TTS）&lt;/strong&gt;：得益于共享表征，LLM 无需将图像解码为像素，即可直接对扩散模型生成的潜变量进行「理解」和「打分」。通过这种 Best-of-N 策略，模型能显著提升生成图像与提示词的匹配度。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;文生图技术栈的下一站&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇论文为大规模文生图提供了一个全新的基础范式。&lt;/p&gt;&lt;p&gt;通过将 RAE 扩展至百亿参数规模，该团队证明了：我们不仅不需要 VAE 来实现高质量生成，甚至可以利用 RAE 获得更快的收敛速度、更高的训练稳定性和更好的多模态统一潜力。&lt;/p&gt;&lt;p&gt;当理解与生成不再需要依靠两个互不相通的潜空间（如 CLIP 与 VAE）来回切换时，扩散模型真正开始学会以「视觉语义」的角度去构建世界。&lt;/p&gt;&lt;p&gt;RAE 的成功，标志着潜向扩散模型正在从繁复的结构堆砌回归到更简洁、更本质的语义建模。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
