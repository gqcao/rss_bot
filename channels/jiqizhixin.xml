<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>AAAI杰出论文来了！港科大、同济、浙师大等国内高校获奖</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 16:56:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-10</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-10</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;span data-pm-slice="0 0 []"&gt;编辑｜张倩、陈陈&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;刚刚，AAAI 2026 官网公布了今年的「杰出论文」（相当于最佳论文）奖项，共有 5 篇论文获奖，其中有三篇由华人团队主导，作者来自香港科技大学（广州）、西湖大学、浙江大学、同济大学、浙江师范大学、香港城市大学等多所国内高校。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;AAAI 由国际人工智能促进协会主办，是人工智能领域历史最悠久、涵盖内容最广泛的国际顶级学术会议之一，也是中国计算机学会（CCF）推荐的 A 类国际学术会议，每年举办一届。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;AAAI 2026 于 1 月 20 日至 27 日在新加坡举行，总投稿数为 23,680 篇，录用论文 4,167 篇，接收率为 17.6%。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;以下是获奖论文的具体情况。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;论文 1：ReconVLA: Reconstructive Vision-Language-ActionModel as Effective Robot Perceiver&lt;/strong&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadMdeaicOGxibIicda51jU47HzpCBNsk9iaicCR8Xyxx52WzUnib6B3MnvS9YQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.31574074074074077" data-type="png" data-w="1080" data-width="1436" data-height="454" data-imgfileid="503529664" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/2dda3b76-4ac5-4972-a6ae-f927502255d5/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Wenxuan Song, Ziyang Zhou, Han Zhao, Jiayi Chen, Pengxiang Ding, Haodong Yan, Yuxin Huang, Feilong Tang, Donglin Wang, Haoang Li&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：香港科技大学（广州）、西湖大学、浙江大学、莫纳什大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2508.10333&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页：https://zionchow.github.io/ReconVLA/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;近年来，视觉 &amp;mdash; 语言 &amp;mdash; 动作（VLA）模型的进展，使机器人智能体能够将多模态理解与动作执行相结合。然而，实证分析发现，现有的 VLA 模型在将视觉注意力分配到目标区域时仍然存在明显困难，其注意力往往呈现分散状态。&lt;/p&gt;&lt;p&gt;为引导视觉注意力在正确目标上的有效 grounding ，作者提出了 ReconVLA，一种采用隐式对齐范式的重建式 VLA 模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadTtXzNWgLOlGlia1EgbKIUafiaLDUPicibWbFaCkIBdlK8bBomdLyEMQbibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.575925925925926" data-type="png" data-w="1080" data-width="1742" data-height="1004" data-imgfileid="503529665" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/ade07d01-3c78-4529-8c5c-2e5ff146d62a/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;该方法以模型的视觉输出为条件，引入扩散 Transformer 来重建图像中的注视区域（gaze region），而这一注视区域正对应于被操作的目标物体。通过这一过程，VLA 模型被促使学习更加细粒度的表征，并能够准确分配视觉注意力，从而更充分地利用任务相关的视觉信息，完成精确操作。&lt;/p&gt;&lt;p&gt;此外，作者构建了一个大规模预训练数据集，包含来自开源机器人数据集的十万余条轨迹和两百万条数据样本，进一步提升了模型在视觉重建任务上的泛化能力。大量仿真与真实环境中的实验结果表明，论文提出的隐式对齐方法具备明显优势，在精细操作能力和泛化表现上均有出色表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文 2：LLM2CLIP: Powerful Language Model Unlocks Richer Cross-Modality Representation&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadWGC49xrbyKeyQyTZvBuTMbVKgVIf5etj4UFgFicT5VUW8lKj19CHhPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.75" data-type="png" data-w="1080" data-width="4096" data-height="3072" data-imgfileid="503529671" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/15a34aa0-da29-4e2a-b6f8-5e11bd9f8859/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Usman Naseem, Chunyu Wang, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu, Liang Hu&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：同济大学、微软、麦考瑞大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2411.04997&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文主页：https://microsoft.github.io/LLM2CLIP/&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;CLIP 是一种具有奠基意义的多模态模型，它通过在数十亿规模的图像 &amp;mdash; 文本配对数据上进行对比学习，将图像与文本映射到同一表示空间。&lt;/p&gt;&lt;p&gt;受到 LLM 迅猛发展的启发，作者探讨了如何利用 LLM 更强的语言理解能力与广泛的世界知识来进一步增强 CLIP，尤其是在处理冗长且结构复杂的描述文本时的表现。为此，他们提出了一种高效的微调框架，&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650944638&amp;idx=4&amp;sn=35b3ffc2ae3cf40588b822990a0b815c&amp;scene=21#wechat_redirect" target="_blank"&gt;将 LLM 嵌入到预训练的 CLIP 中&lt;/a&gt;，而训练成本几乎与常规的 CLIP 微调相当。具体而言，该方法首先将 LLM 转化为适配 CLIP 场景的「嵌入化」形式，随后通过一个轻量级适配器将其与预训练的 CLIP 视觉编码器耦合，该适配器仅需在数百万规模的图像 &amp;mdash; 文本对上进行训练。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad6ZwFUqOWfrp6P2Smmd3NxnjFByZ1owPZMpLGKb2SqSIUPEu0Kibic2ibQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0626398210290828" data-type="png" data-w="894" data-width="894" data-height="950" data-imgfileid="503529670" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/85874bce-e767-4b87-b750-cb4a8b60de0f/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;借助这一策略，作者在无需大规模重新训练的前提下，相较于 EVA02、SigLIP-2 等当前最先进的 CLIP 变体，取得了显著的性能提升。经 LLM 增强后的 CLIP 在多种下游任务上均表现出稳定改进，包括线性探测分类、同时支持短文本与长文本（英文及多语言）的零样本图像 &amp;mdash; 文本检索、零样本与有监督的图像分割、目标检测，以及作为多模态大模型基准中的分词器使用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文 3：Model Change for Description Logic Concepts&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Ana Ozaki, Jandson S Ribeiro&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：奥斯陆大学、卡迪夫大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：暂无&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该论文虽已获奖，但目前还未公开发布。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadICSpTe2YTIteGv3juNPTUGJmrctwPho08JdH2gn8YNWTOszjOT06cw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.31296296296296294" data-type="png" data-w="1080" data-width="1706" data-height="534" data-imgfileid="503529669" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/6a226957-810b-42c9-abd7-18c12e552de3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;论文 4：Causal Structure Learning for Dynamical Systems with Theoretical Score Analysis&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadHpfjue4ickHH4ZN3TTgfNT6KsutSPxNE9mGTXxzSb1z6xMy9iacIuhog/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.21574074074074073" data-type="png" data-w="1080" data-width="1308" data-height="282" data-imgfileid="503529668" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/b9239d3e-d7f5-4f93-86f9-f1d88fefb1fb/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Nicholas Tagliapietra, Katharina Ensinger, Christoph Zimmer, Osman Mian&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：博世 AI 中心团队、德国达姆施塔特工业大学、德国医学 AI 研究所 IKIM 等&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.14361&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现实世界中的系统通常按照其内在的因果关系在连续时间中演化，但这些动态机制往往是未知的。现有用于学习此类动态的方法通常存在两类问题：要么对时间进行离散化处理，在面对不规则采样数据时性能较差；要么忽略了系统背后的因果结构。&lt;/p&gt;&lt;p&gt;为此，本文提出 CADYT，一种用于动力系统因果发现的新方法，可以同时解决上述两大挑战。不同于当前主流将问题建模为离散时间动态贝叶斯网络的因果发现方法，该研究建模基础是基于差分的因果模型，这种模型对连续时间系统的刻画只需更弱的假设，更符合真实系统的连续演化特性。&lt;/p&gt;&lt;p&gt;CADYT 采用精确的高斯过程推断来建模连续时间动力学，从而在建模层面更贴近系统的真实生成过程。在算法设计上，本文提出了一种可落地的实现方案：通过结合马尔可夫条件与最小描述长度（MDL）原则，采用贪心搜索策略来识别系统的因果结构。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadnxnibdObtOowtmABR3cFibRIoXcNdlmFse1YfJfSLiafRMGMGF2QeGUaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6072507552870091" data-type="png" data-w="993" data-width="993" data-height="603" data-imgfileid="503529667" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/8dc26bbd-8943-4910-ba5f-accb04b59ab5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; CADYT 能够从连续时间动力系统的轨迹数据中，发现未知的因果结构。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;实验结果表明，无论是在规则采样还是不规则采样的数据场景下，CADYT 都显著优于现有的先进方法，能够恢复出更接近真实底层动力学机制的因果网络结构。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;论文 5：High-Pass Matters: Theoretical Insights and Sheaflet-Based Design for Hypergraph Neural Networks&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这篇获奖论文同样还没有放出论文链接，但从附录论文中，我们获悉了作者机构信息。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadeYKO8MUgwe57cibKicFwIiarykRWkqm9lfSTDpMrbsCGXaT1kpJRGiaKKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.33611111111111114" data-type="png" data-w="1080" data-width="1419" data-height="477" data-imgfileid="503529666" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ec7e50d0-acd5-4527-bd0b-d7749ba7a25c/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;作者：Ming Li, Yujie Fang, Dongrui Shen, Han Feng, Xiaosheng Zhuang, Kelin Xia, Pietro Lio&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;机构：浙江师范大学、香港城市大学、南洋理工大学、剑桥大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：暂无&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://aaai.org/about-aaai/aaai-awards/aaai-conference-paper-awards-and-recognition/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Meta新模型要来了，但Llama 4的锅谁来接？1300多位作者的联合报告来了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 16:53:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;路透社最新消息，&lt;strong&gt;Meta 新成立的 AI 团队本月已在内部交付了首批关键模型&lt;/strong&gt;。据悉，该消息来自 Meta 公司的 CTO Andrew Bosworth，他表示该团队的 AI 模型「非常好」（&lt;strong&gt;very good&lt;/strong&gt;）。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;媒体在去年 12 月报道称，Meta 公司正在开发一款代号为 &lt;strong&gt;Avocado&amp;nbsp;&lt;/strong&gt;的文本 AI 模型，计划于第一季度发布；同时还在开发一款代号为 &lt;strong&gt;Mango&amp;nbsp;&lt;/strong&gt;的图像和视频 AI 模型。Bosworth 并未透露哪些模型已交付内部使用。&lt;/section&gt;&lt;section&gt;&lt;br&gt;&lt;/section&gt;&lt;section&gt;有意思的是，就在这篇报道的前些天，一篇技术报告《&lt;strong&gt;Llama 4 家族：架构、训练、评估和部署说明&lt;/strong&gt;》在 arXiv 悄然上线，其中全面回顾了 Meta Llama 4 系列模型宣称的数据和技术成就。&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadhZqPicWzlQqkzDzDftPDzFcCtFvooqY4OKiauKs8MwicpvxVpufUZW0gw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.22870370370370371" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529630" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d9dd64b1-ab91-4fea-9c57-3dbfa97a4817/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;报告标题：The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;报告地址：https://arxiv.org/abs/2601.11659v1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要说明，上传这篇报告的作者是 Meta 一位机器学习工程师 Arthur Hinsvark，但这篇报告却并未明确标识来自 Meta。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad0Sa5IrTOAc9KsCzoEE6LdLD32RQrhD68u7Et193DoxvQjFPdib0dvSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.41759259259259257" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529632" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e44ed63f-e241-4e15-8b66-25be0acbb6ef/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;尽管如此，这篇报告还是将 Llama 4 项目的所有参与者都加入到了作者名单中 &amp;mdash;&amp;mdash; 超过 1300 名，足足 5 页！因此，我们可以大体上认为这份报告就是来自 Llama 4 团队，尽管其中不少人现在已经从 Meta 离职，比如前 Meta FAIR 团队研究总监&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651010344&amp;idx=1&amp;sn=ab18804d6c48b67537758c869b3ba649&amp;scene=21#wechat_redirect" target="_blank"&gt;田渊栋&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;值得注意的是，这篇报告的引言有一段明确说明：「本文档是对公开材料的独立调查。报告的基准数值归因于模型卡，除非另有说明；应将它们视为开发者报告的结果，并对评估工具、提示工程和后处理持通常的保留态度。」&lt;/p&gt;&lt;p&gt;也就是说，这篇报告整体回顾了 Meta 公布的各种 Llama 4 相关材料，尤其是其宣称的一些数据。但没有明确解释其在实际应用中表现明显不及预期的原因。想要了解相关背景的读者可参阅：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963634&amp;idx=1&amp;sn=4935ed3758561c8ee8366adce6b3be1f&amp;scene=21#wechat_redirect" target="_blank"&gt;Meta Llama 4 被疑考试「作弊」：在竞技场刷高分，但实战中频频翻车&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=1&amp;sn=2e63fcbf091cef43ae9fbf61aecc15a2&amp;scene=21#wechat_redirect" target="_blank"&gt;Llama 4 在测试集上训练？内部员工、官方下场澄清，LeCun 转发&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不过，该报告也不是完全没有提到相关原因，仔细阅读的话，我们能在行文中看到一些端倪，其中主要的讨论点集中在部署限制和榜单争议上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构能力与实际部署的差距（尤其是上下文长度）：&lt;/strong&gt;论文反复强调了一个「经常出现的操作主题」：模型的架构支持能力与实际服务中提供的能力之间存在差距。虽然 Scout 在架构上设计为支持 10M 上下文长度，但在实际部署中（如 Cloudflare 或 AWS），由于显存和 KV 缓存的硬件成本限制，服务商往往将可用上下文限制在 128K 或 1M。这意味着用户在实际使用托管服务时，可能无法体验到模型宣称的全部长上下文能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;榜单成绩与发布版本的差异：&lt;/strong&gt;论文提到了关于 LMArena 排行榜的争议。Meta 在榜单上提交的 Maverick「实验性聊天」变体与公开发布的版本不完全相同。这导致了外界批评其「操纵基准测试」（gaming AI benchmarks）。这也解释了为什么用户使用公开发布版本时的体验可能与某些榜单上的高分表现不一致。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;营销话术与技术指标的区别：&lt;/strong&gt;论文明确指出，发布公告中的某些声称（例如 Scout 是「同类最佳」或强调性价比）属于「面向营销的主张」（marketing-facing claims），应当与严谨的模型卡基准测试结果分开解读。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些细节似乎暗示了这份报告是 Meta Llama 团队对于 Llama 4 系列模型备受社区广泛批评（数据亮眼但能力很差）的最终回应。&lt;/p&gt;&lt;p&gt;对于这些说明，不知道你怎么看？&lt;/p&gt;&lt;p&gt;具体到内容上，这篇技术报告的内容仅有 15 页，其中 1300 多位作者的名单就足足占了 5 页，再去掉一页参考文献，实际内容仅有 9 页。其中，Meta Llama 团队总结了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;已发布的模型变体（Scout 和 Maverick）以及更广泛的系列模型背景，包括预览版的 Behemoth 教师模型；&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadDX5LAQficZDN0Pu7picBR2ibN108fKuEzKC28UlEnHu8nseVN6B2d3CIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6961429915333961" data-s="300,640" data-type="png" data-w="1063" type="block" data-imgfileid="503529631" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d62d6412-8b9c-4c96-963c-9ce538f0b10a/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;超越高级 MoE 描述的架构特征，涵盖路由 / 共享专家结构、早期融合多模态，以及针对 Scout 报告的长上下文设计元素（iROPE 和长度泛化策略）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练披露，跨越预训练、用于长上下文扩展的中期训练（mid-training），以及发布材料中描述的后训练方法（轻量级 SFT、在线 RL 和轻量级 DPO）；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开发者报告的基础和指令微调检查点的基准测试结果；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在主要服务环境中观察到的实际部署限制，包括特定于提供商的上下文限制和量化打包。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，这份报告还总结了「与再分发和衍生命名相关的许可义务，并回顾了公开描述的安全措施和评估实践。其目的是为需要关于 Llama 4 精确、有来源依据事实的研究人员和从业者提供一份紧凑的技术参考。」&lt;/p&gt;&lt;p&gt;更多详情请参阅原报告。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://www.reuters.com/technology/metas-new-ai-team-has-delivered-first-key-models-internally-this-month-cto-says-2026-01-21/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>金山云星流全面升级 以智算穿越云上AI新周期</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 22 Jan 2026 16:47:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;当前，人工智能产业迈入以&amp;ldquo;云+AI&amp;rdquo;为核心驱动力的新周期，生成式AI加速规模化落地，产业重心正从模型训练阶段向推理环节转移，带动推理市场迎来指数级增长。麦肯锡报告预测，2028年全球AI推理市场规模将达1500亿美元，2025-2028年复合年增长率超40%。而智算作为承接推理爆发的核心基础设施，将迎来前所未有的市场增量空间。&lt;/p&gt;&lt;p&gt;在2026年1月21日举办的金山云年度Tech Talk上，金山云高级副总裁刘涛表示，智算平台金山云星流已完成从资源管理平台向一站式AI训推全流程平台的战略升级。从训推平台、机器人平台到模型API服务，升级后的金山云星流平台构建了从异构资源调度、训练任务故障自愈到机器人行业应用支撑、模型API服务商业化落地的全链路闭环。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实现三维进阶 智算云AI势能全释放&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管各行各业大规模应用AI还处于早期探索阶段，但定位行业助力者的金山云，多年来持续打磨全栈AI能力。从2023年的智算网基础设施，到2024年智算云的平台化和Serverless化，再到2025年的一站式AI训推全流程平台，通过提升平台效率、突破行业边界、加速推理布局，金山云为迎接AI应用爆发做好了充分准备。&lt;/p&gt;&lt;p&gt;在平台效率方面，金山云星流训推平台提供从模型开发、训练到推理的完整生命周期管理，具备开发、训练、推理和数据处理四大模块能力，通过降低多模块协同复杂度，能实现&amp;ldquo;开箱即用&amp;rdquo;的AI开发体验。自研的GPU故障自愈技术结合任务可观测性设计，可实时监控硬件健康状态与任务进程，自动触发故障迁移与任务重调度，降低算力中断风险，保障长周期训练任务稳定运行。&lt;/p&gt;&lt;p&gt;作为面向机器人开发与落地的全链路云原生平台，金山云星流机器人平台深度融合数据采集、存储、标注、模型开发、训练、部署与仿真等核心环节，打造具身场景专属的数据、模型、仿真一体化引擎。平台率先实现具身智能数据工程领域采集、标注、管理的全链路闭环，可高效服务具身智能行业模型训练、仿真应用场景分析等核心需求，助力客户快速完成从算法研发到真实场景部署的全流程落地，最终推动机器人产业的智能化升级。&lt;/p&gt;&lt;p&gt;面向大模型应用开发者和企业用户，金山云星流平台模型API服务提供高可用、易集成的模型调用与管理能力，覆盖模型调用的全生命周期。该服务支持高并发推理与多模型管理，能够帮助用户高效接入多种模型资源，助力大模型应用落地。目前，金山云星流平台模型API服务已积累诸多行业客户。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生态优势凸显 AI落地价值再跃升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;AI需求强劲，金山云关于智算云潜力巨大的判断得到印证。国际权威机构英富曼（Omdia）数据显示，2025年上半年中国AI云市场（涵盖IaaS、PaaS、MaaS全链条）规模已达223亿元，其中生成式AI（GenAI）带来AI云市场的爆发，2025年预计增长148%，到2030年将达1930亿元规模。&lt;/p&gt;&lt;p&gt;得益于在智算云领域的前瞻性布局和技术能力建设，智算云已经成为金山云业务的&amp;ldquo;新底色&amp;rdquo;。&lt;/p&gt;&lt;p&gt;在生态内，作为唯一战略云平台，公司持续为生态企业提供优质服务，夯实智算需求的快速响应能力；在生态外，金山云不仅成功支撑了互联网行业头部客户大规模推理算力需求，还在通用模型公司、具身智能等领域实现突破。这些经过生态内业务和行业头部客户验证过的落地能力，都会沉淀在金山云中，成为对外提供可持续稳定云服务的坚实基础。&lt;/p&gt;&lt;p&gt;与此同时，金山云星流平台的模型生态也在持续丰富。目前，平台已支持近40种不同模型，包括DeepSeek、Xiaomi MiMo、Qwen3、Kimi等。客户通过一站式访问，即可高效接入多种模型，在畅享稳定高效云服务的同时，更加聚焦AI业务创新和价值创造。&lt;/p&gt;&lt;p&gt;人工智能浪潮汹涌澎湃，新场景与新应用正驱动AI技术和产品持续进化，给云计算带来无限发展空间。金山云将始终围绕客户核心需求，携手生态伙伴，深入不断变化的真实应用场景，稳步推动AI价值落地。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Future Tech | 16支AI新锐齐聚数码港，FT Demo Day第二期引爆湾区创新浪潮</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 22 Jan 2026 16:45:57 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;1月15日下午，由世界人工智能大会下子品牌&lt;strong&gt;Future Tech第二期Demo Day项目路演&lt;/strong&gt;在香港数码港成功举办。作为WAIC全年创投生态的重要一环，本次活动以&amp;ldquo;智联湾区 创见未来&amp;rdquo;为主题，汇聚了来自全国各地的16支优秀AI初创团队，集中展示了人工智能在数字孪生、法律服务、医疗健康、智能制造、低空经济、认知科技等前沿领域的创新成果与实践路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;创新生态启航：从年度盛会到全年伙伴&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;活动伊始，主持人介绍了WAIC Future Tech平台的定位与使命：它不仅承载着世界人工智能大会的基因，更旨在成为&lt;strong&gt;全年陪伴初创企业成长的全周期伙伴。&lt;/strong&gt;作为一个系统化的创新加速平台，其核心使命是通过高频路演、精准资源对接与全生态服务，切实回应并解决初创企业在发展初期的关键痛点&amp;mdash;&amp;mdash;&lt;strong&gt;曝光难、融资难、落地难。&lt;img src="https://image.jiqizhixin.com/uploads/editor/7d397ae0-0925-4529-8f05-fab7e974514a/%E5%9B%BE%E7%89%8710.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;自2024年启动以来，Future Tech已逐步构建起一个&lt;strong&gt;跨地域、跨领域的创新生态&lt;/strong&gt;，持续推动技术、资本与场景的高效链接。&lt;strong&gt;2026年，Future Tech将持续深化&amp;ldquo;创新加速器&amp;rdquo;角色&lt;/strong&gt;，拓展全年活动矩阵，强化产业对接与出海支持，助力更多优质项目走向国际舞台，真正实现&lt;strong&gt;&amp;nbsp;&amp;ldquo;全年孵化、全程赋能&amp;rdquo;&amp;nbsp;&lt;/strong&gt;的平台愿景。&lt;br&gt;&lt;br&gt;&lt;strong&gt;湾区联动：生态共建助力创新落地&lt;img src="https://image.jiqizhixin.com/uploads/editor/04d4fe78-320f-490d-9818-c7e354639ed6/%E5%9B%BE%E7%89%879.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;活动现场，&lt;strong&gt;数码港大湾区及内地事务总监苏婕女士&lt;/strong&gt;分享了数码港作为香港科创枢纽的生态布局。她提到，数码港以生态系统方式连接大学、加速器、政府与大企业，尤其在人工智能、区块链、低空经济等领域，提供算力支持、监管沟通、出海对接等全方位服务，助力初创企业拓展场景、走向全球。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f7341d5f-777c-462d-a3f6-95c206dbcbba/%E5%9B%BE%E7%89%878.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;亚洲人工智能初创大赛创办人、香港人工智能创新协会秘书长黄乐彤女士&lt;/strong&gt;随后介绍了大赛如何成为&amp;ldquo;未来独角兽的跳板&amp;rdquo;。她表示，大赛以&amp;ldquo;人工智能赋能全球未来&amp;rdquo;为宗旨，通过&amp;ldquo;一港币创投基金&amp;rdquo;、政策对接、资本链接、出海支持等组合拳，推动项目从技术走向市场。香港站已征集118个项目，全国累计征集近800个，展现出强劲的创新活力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;路演聚焦：16个项目展现AI赋能百业&lt;/strong&gt;&lt;br&gt;&lt;br&gt;在随后的路演环节中，16支团队依次登场，展现了AI技术在不同垂直领域的深度应用与商业探索：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bcaca7a8-6eb4-4978-b7a5-8e810a83ef72/%E5%9B%BE%E7%89%877.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;strong&gt;&amp;nbsp;数晨科技&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;提出&amp;ldquo;AI数字实体操作系统&amp;rdquo;，致力于打破数据孤岛，构建全域数字孪生基座，让数据回归价值主体。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1a720fd4-c875-4506-b6ab-fedd7cbdc0a9/%E5%9B%BE%E7%89%876.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;智法数科&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;香港首家专注于跨境法律及合规AI应用的科创企业，为全球企业、金融机构和律师事务所提供法律合规智能体产品服务及解决方案。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b2aba096-d6df-46ec-9a68-e13ed7528f33/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;问律AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聚焦智能合同审查，为企业提供高效、低成本的合规风控解决方案。&lt;img src="https://image.jiqizhixin.com/uploads/editor/9405ecf6-3653-4dee-b534-23543b7809cf/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;睿法智行&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推出&amp;ldquo;婚姻宝AI助手&amp;rdquo;，以温情技术赋能个人法律咨询，让专业服务触手可及。&lt;img src="https://image.jiqizhixin.com/uploads/editor/b020ac5c-3ab2-41e2-abf6-9f3934b5659d/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;0x Limited&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;构建多模态医学大模型，临床决策能力媲美资深医师，已服务全球超70万健康咨询。&lt;img src="https://image.jiqizhixin.com/uploads/editor/911e122c-f49e-4784-9f0c-8441a30cf11b/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Meddcom AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首家入选香港大学数字健康实验室的AI4Health-To C团队，应用在疾病预测、个性化健康管理、合理用药等领域，并利用区块链技术解决医疗数据隐私问题，为用户和患者打造第一张&amp;ldquo;健康名片&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/aea530d4-6cce-4418-9cb6-0fc3d4038288/%E5%9B%BE%E7%89%871.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;JustAI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;推出AI内容营销助手，帮助中小商家高效打造品牌内容，获取精准流量。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f1cc48a1-b7ae-4996-8cf3-9f821fc5de93/%E5%9B%BE%E7%89%8710.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;虚空博弈&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;尝试&amp;ldquo;量化直觉&amp;rdquo;，将博弈论与AI结合，提升决策质量，探索认知科学新边界。&lt;img src="https://image.jiqizhixin.com/uploads/editor/3d21fea3-658a-42b0-aa45-64813d7609d1/%E5%9B%BE%E7%89%879.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;章节零一&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;打造&amp;ldquo;可信可追溯的商业分析智能体&amp;rdquo;，助力企业基于真实数据做出精准决策。&lt;img src="https://image.jiqizhixin.com/uploads/editor/4fa728ec-a0b6-4f73-b16f-92cb4169ec19/%E5%9B%BE%E7%89%878.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Atrust（小A）&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;构建基于信任的私域电商AI合伙人，通过情感化交互实现高客单价转化。&lt;img src="https://image.jiqizhixin.com/uploads/editor/66148a2f-6e07-445f-ab0f-917d2e8258de/%E5%9B%BE%E7%89%877.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;推敲AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;专注室内设计智能平台，通过AI生图、改图与全流程辅助，提升设计效率与原创性。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5ab7da6e-c8cc-4bcb-9b5e-7c11be87fe16/%E5%9B%BE%E7%89%876.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AI SEMI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以AI赋能半导体制造，其&amp;ldquo;AI OPC&amp;rdquo;技术将光刻校正效率提升数十倍，成本降低超95%。&lt;img src="https://image.jiqizhixin.com/uploads/editor/ecc11d39-6b85-4c24-80f7-70c7e313cdb1/%E5%9B%BE%E7%89%875.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Alpha AI&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;将自动驾驶无人机与AI视觉结合，实现楼宇、桥梁、斜坡的自动化巡检与损伤智能评估。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c1454471-def9-4268-b21f-74e63c3512e4/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;OneOneTalk&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;构建人类成长系统&amp;rdquo;，从个性化语伴到全场景认知升级OS，推动AI个性化教学。&lt;img src="https://image.jiqizhixin.com/uploads/editor/cbb8c5bb-adc6-4291-bc2a-57359da37e6c/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;DT Master&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聚焦可持续AI风险和合规，帮助企业高效应对出海中的ESG、数据，AI 与法律合规挑战。&lt;/p&gt;&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/bba3e325-0f6b-4e47-95c2-3728948b7b6b/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;派晨智能&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;展示AI漫剧智作平台，将动漫制作周期从数周缩短至数天，推动内容产业降本增效。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>WAIC CONNECT | 沪港联动激活产业新引擎，两地各界共筑AI+多元应用新生态</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>新闻资讯</author>
      <pubDate>Thu, 22 Jan 2026 16:25:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;2026年1月16日，世界人工智能大会（WAIC）旗下的精准产业对接平台&amp;mdash;&amp;mdash;WAIC CONNECT走进香港科学园，成功举办了&lt;strong&gt;&amp;ldquo;激活产业新引擎&amp;mdash;&amp;mdash;AI+文商体旅育创新对接会&amp;rdquo;&lt;/strong&gt;。本次活动作为WAIC 2026全球启动的重要序章，以&amp;ldquo;沪港联动&amp;middot;场景落地&amp;middot;生态共建&amp;middot;企业出海&amp;rdquo;为核心主题，汇聚了来自沪港两地政府、学术界、产业界及教育界的数十位领军人物，共同探索人工智能在文、商、体、旅、育等多元场景下的深度应用与商业闭环。&lt;img src="https://image.jiqizhixin.com/uploads/editor/328a4127-7d7f-4049-84e1-3fbf4f6022e5/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深化沪港合作，打造超级连接器&lt;/strong&gt;&lt;br&gt;&lt;br&gt;当前，人工智能产业正从技术爆发期迈向场景落地的深水区。&lt;strong&gt;东浩兰生会展集团副总裁张荣健先生&lt;/strong&gt;在致辞中指出，WAIC CONNECT致力于成为AI商业化的&amp;ldquo;超级连接器&amp;rdquo;，其核心使命在于解决技术创新与产业转型之间的供需错配。大会通过汇聚全球顶尖AI解决方案，并深入洞察&amp;ldquo;文商体旅育&amp;rdquo;核心场景的真实痛点，旨在打破地域界限，实现技术供给与市场需求的高效精准匹配，为产业升级注入强劲动力。与会嘉宾高度认同这一愿景，一致认为香港凭借其国际化营商环境与背靠祖国大市场的独特优势，无疑是AI企业出海与生态共建的最佳战略支点。沪港两地的紧密联动，必将产生协同效应，为区域乃至全球的AI产业发展带来新的增长极。&lt;img src="https://image.jiqizhixin.com/uploads/editor/da9636ff-1670-4be7-afa6-8e222e4441ab/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 张荣健 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;随后，&lt;strong&gt;香港生产力促进局机械人及人工智能部总经理冯国辉先生&lt;/strong&gt;致辞表示，作为最早系统推动AI研发的单位，生产力局正积极配合特区政府将香港打造为全球AI枢纽，通过自主研发的&amp;ldquo;天工开物&amp;rdquo;平台及&amp;ldquo;全民AI行动&amp;rdquo;，解决企业在人才、隐私及整合上的挑战。目前，该局已完成及正在推行超过100个AI项目，并推出多项培训课程，旨在通过培训赋能与技术支持，协助企业利用香港优势成功出海。&lt;img src="https://image.jiqizhixin.com/uploads/editor/5b5d983c-9905-43fa-b9c1-ea8b9aea9c4b/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 冯国辉 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重磅项目启动，聚焦前沿实践&lt;/strong&gt;&lt;br&gt;&lt;br&gt;活动现场举行了多项重磅发布仪式。在东浩兰生会展集团、香港生产力促进局、香港人工智能和机器人学会及浙港澳数字教育学校联盟代表的共同见证下，&lt;strong&gt;&amp;ldquo;WAIC CONNECT香港工作站-校园AI应用项目招募计划&amp;rdquo;&lt;/strong&gt;正式启动。此举标志着大会在推动AI教育普及和发掘青年创新人才方面迈出了关键一步，并将有效促进沪港两地AI教育资源的深度融合与协同发展，为香港校园注入前沿科技活力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/a327eec5-2ed7-4add-b6c5-14d3cdd3fc04/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;随后，知名导演丁子峻、中华基督教会基慈小学赵洁华校长、中华基督教会长洲堂锦江小学叶昌锐校长、WAIC CONNECT及WAIC CONNECT香港工作站代表等共同发布了&lt;strong&gt;&amp;ldquo;AI电影进校园&amp;rdquo;&lt;/strong&gt;项目成果。该项目以公益影展形式走进校园，聚焦&amp;ldquo;从经典到现代&amp;rdquo;的动画发展脉络，让传统文化在数字时代焕发新活力。通过导演的亲身分享，项目引导学生直观感受科技与艺术的碰撞，培养兼具文化底蕴与科技思维的创新意识。此次活动由上海美术电影制片厂、WAIC CONNECT香港工作站、上海香港联会共同支持，展示了科技赋能人文教育的无限可能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;多维场景解构，共探商业新机&lt;/strong&gt;&lt;br&gt;&lt;br&gt;在主旨演讲环节，四位嘉宾从不同维度剖析了AI的赋能路径。&lt;/p&gt;&lt;p&gt;香港人工智能和机器人学会常务理事、香港城市大学计算学院林静博士解读了香港的出海战略，指出&lt;strong&gt;香港正从资本金融中心转变为全产业链的出海赋能平台&lt;/strong&gt;，利用其国际化优势，为企业提供合规保护与标准对接，并联合生态伙伴补齐企业走向国际市场的&amp;ldquo;最后一公里&amp;rdquo;。&lt;img src="https://image.jiqizhixin.com/uploads/editor/ff6e9f3f-53a2-4844-8bd3-3193163ea835/%E5%9B%BE%E7%89%872.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 林静 博士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;上海市城市更新研究会副秘书长、金砖财经CEO尤优提出了&lt;strong&gt;&amp;ldquo;场景营城&amp;rdquo;&lt;/strong&gt;理念，强调城市更新是国家重大转型战略。他介绍了上海在城市更新中的巨大投入与立法保障，并通过绿地外滩中心等案例，阐述了如何通过资本、资产与IP的共创，将城市更新打造为AI企业的超级场景平台。&amp;nbsp;&lt;img src="https://image.jiqizhixin.com/uploads/editor/912a278a-12d9-4c6c-b05c-e1fc03664ad8/%E5%9B%BE%E7%89%873.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 尤优 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;随后，绿地控股集团上海房地产事业部市场营销部副总经理王楠女士以&amp;ldquo;绿地外滩中心&amp;rdquo;为例，展示了&lt;strong&gt;上海未来的超级应用场景&lt;/strong&gt;。她介绍该项目作为上海最大的城市更新地标，汇聚了金融与科创巨头，正通过绿地国际会议中心等多元载体，积极寻求与AI企业在产品发布、资源链接及数字化生态等方面的深度合作。&amp;nbsp;&lt;img src="https://image.jiqizhixin.com/uploads/editor/82fa6364-03fc-40ae-b622-cfa2d051c382/%E5%9B%BE%E7%89%874.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 王楠 女士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;浙港澳数字教育学校联盟、香港教育评议会主席蔡世鸿先生分享了&lt;strong&gt;&amp;ldquo;智教融合&amp;rdquo;&lt;/strong&gt;的思考。他提出要培养&amp;ldquo;AI时代的一代宗师&amp;rdquo;，借鉴《一代宗师》中&amp;ldquo;见自己、见天地、见众生&amp;rdquo;的三个境界，阐述了利用AI辅助适应生活、在社会中生存乃至引领发展的教育目标，并强调需重点培养学生提问、解决问题及创新等六大能力。&lt;img src="https://image.jiqizhixin.com/uploads/editor/50f0b68d-9ae1-4f9b-8bff-3aff6e9095ea/%E5%9B%BE%E7%89%871.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 蔡世鸿 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;四位嘉宾的分享涵盖了政策解读、空间重塑、商业地标及教育实践等多个维度，为现场企业拥抱AI时代提供了全方位的战略指引。&lt;br&gt;&lt;br&gt;&lt;strong&gt;跨界圆桌对话，激荡思想火花&lt;/strong&gt;&lt;br&gt;&lt;br&gt;当导演遇到AI，当足球遇上大数据，当社区治理迈向智慧化，当传统制造迈向数智化，会产生怎样奇妙的化学反应？两场高水平的圆桌论坛将活动推向高潮。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;&amp;ldquo;AI科技赋能到生态共建&amp;rdquo;&lt;/strong&gt;圆桌讨论中，知名导演丁子峻、前女足国门赵丽娜、全球女性成长基金会、香港区潮人联会副会长蔡晓莹、杭州灵核数智CEO陈弘旋等嘉宾，立足影视、体育、社区、制造等不同赛道，围绕&amp;ldquo;赋能&amp;rdquo;与&amp;ldquo;生态&amp;rdquo;两大关键词，共同探讨了AI如何渗透到各行各业的毛细血管，以及不同领域如何打破壁垒、实现协同共生。&lt;img src="https://image.jiqizhixin.com/uploads/editor/f50640a1-e5f2-4ab1-8855-a261c53e2aa6/%E5%9B%BE%E7%89%872.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;/p&gt;&lt;p&gt;知名导演丁子峻率先从文娱行业的视角切入，他并不认为AI是对演艺行业的冲击。回顾自己1998年在香港投身互联网行业的经历，他指出互联网思维与当下的AI技术有着相通的文化内核。丁子峻导演强调，从皮影戏到传统动漫，再到如今的数字电影，技术工具在变，但文化的审美与传承这一&amp;ldquo;基本功&amp;rdquo;从未改变。作为电影人，AI并非洪水猛兽，不懂它才是冲击，懂了它便是赋能。他目前正致力于通过大数据模型与影视创作的结合，探索一种&amp;ldquo;文化转世&amp;rdquo;的可能&amp;mdash;&amp;mdash;&lt;strong&gt;让IP与故事在不同的技术形态中获得&amp;ldquo;Next Life&amp;rdquo;，因为未来的方向掌握在人类的认知与手中，AI只会让电影变得更好。&lt;img src="https://image.jiqizhixin.com/uploads/editor/c633627f-7d65-4b59-900e-a7bc7b1b83ce/%E5%9B%BE%E7%89%873.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;丁子峻 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;前女足国门赵丽娜则从专业运动员的视角出发，提出了体育领域对&amp;ldquo;落地性、个性化、普适性&amp;rdquo;的迫切需求。她强调，&lt;strong&gt;AI不仅需要辅助职业球员进行精准备战与损伤康复，更应通过轻量化、零门槛的工具，成为乡村校园足球的&amp;ldquo;公益教练&amp;rdquo;，&lt;/strong&gt;让资源匮乏地区的孩子也能通过手机摄像头获得科学的动作纠错，跨越数字鸿沟，实现科技向善。&lt;img src="https://image.jiqizhixin.com/uploads/editor/1c414908-ecf8-406e-80da-af23ce5f2f6d/%E5%9B%BE%E7%89%874.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;赵丽娜 女士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;香港区潮人联会副会长蔡晓莹女士深情讲述了科技背后的温度。她分享了社区儿童智能守护平台成功找回走失儿童的案例，以及帮助基层妇女通过技能培训实现灵活就业的故事。她认为，&lt;strong&gt;AI进入社区必须&amp;ldquo;克制&amp;rdquo;且&amp;ldquo;贴心&amp;rdquo;，在尊重隐私的前提下，解决双职工家庭看护难、信息甄别难等真实痛点。&lt;/strong&gt;她强调，科技应隐于幕后，让温度留在台前，真正走进社区的烟火气中。&lt;img src="https://image.jiqizhixin.com/uploads/editor/76e885e5-75eb-40d8-aeea-46e54d7de965/%E5%9B%BE%E7%89%875.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;蔡晓莹 女士&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;灵核数智创始人陈弘旋则结合制造业实践指出：AI已从单点技术升级为推动企业系统性变革的核心引擎，其关键在于通过&amp;ldquo;沉淀技能、学习内化、重塑流程、复制扩张&amp;rdquo;将AI转化为能沉淀企业技能、持续进化、可复制、可升级的AI数智员工。灵核数智聚焦业务前端，让&lt;strong&gt;&amp;ldquo;AI数智员工先干活&amp;rdquo;&lt;/strong&gt;，在真实业务中自动捕捉并结构化沉淀企业高价值隐性知识，构建持续进化的数字化知识体系，并通过7&amp;times;24小时学习整合内外部高价值经验，推动人机协同决策。随着AI数智员工深度参与需求洞察、研发设计、生产制造与交付服务，企业业务全链条得以重塑，产品迭代更快、质量更稳、试错成本更低。同时，AI数智员工还能承载并快速复制成熟经验，支撑企业多工厂乃至全球化扩张，实现高效稳定落地。面向未来制造业，真正的挑战已从&amp;ldquo;能生产&amp;rdquo;转向&amp;ldquo;造好产品&amp;rdquo;，而持续的技术创新与高效的创意转化能力，将成为企业赢得市场的关键。&lt;img src="https://image.jiqizhixin.com/uploads/editor/69e182db-7b7c-438d-8928-0ef66d11b460/%E5%9B%BE%E7%89%876.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/sup&gt;&lt;sup&gt;陈弘旋 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;嘉宾们的精彩对话揭示了生态共建的核心逻辑：无论是在艺术的创作、激烈的赛场，还是温暖的社区与严苛的产线，AI只有成为真实场景中可信赖的伙伴，才能激发出最大的社会价值。&lt;/p&gt;&lt;p&gt;而在&lt;strong&gt;&amp;ldquo;AI科技赋能到教学共建&amp;rdquo;&lt;/strong&gt;圆桌对话中，郑家宝、郭文钊、尹淑芬、梁文祺、吕浩荣、朱嘉添六位来自香港知名中小学的校长，在主持人吕斯恬先生的引导下，围绕AI科技如何赋能教学共建展开了深度探讨。&lt;img src="https://image.jiqizhixin.com/uploads/editor/293964fb-ece3-4bb7-835e-81a4a84ed06f/%E5%9B%BE%E7%89%877.png" style="width: 70%;" class="fr-fic fr-dib"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/4367db5d-8b78-4b04-a580-cb6cb00a4de2/%E5%9B%BE%E7%89%878.png" style="width: 50%;" class="fr-fic fr-dib"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 吕斯恬 先生&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;嘉宾们一致认为，AI不仅是提升效率的工具，更是推动教育模式变革的核心动力。在实践层面，校长们分享了各自学校的丰硕成果：从&amp;ldquo;AI电影进校园&amp;rdquo;的跨学科尝试，到利用AI实现&amp;ldquo;因材施教&amp;rdquo;与&amp;ldquo;个性化学习路径&amp;rdquo;的探索，再到建立&amp;ldquo;个人成长档案&amp;rdquo;以全面追踪学生成长历程，学校正逐步实现从&amp;ldquo;千篇一律&amp;rdquo;到&amp;ldquo;量身定制&amp;rdquo;的转变。展望未来，校长们呼吁&lt;strong&gt;教育界与业界紧密合作，研发本地化AI模型，并着重提升教师的AI素养与伦理意识，&lt;/strong&gt;让技术真正服务于&amp;ldquo;立德树人&amp;rdquo;的教育本质，培养兼具科技思维与人文关怀的未来人才。&lt;br&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5f07d713-e6d1-429e-9ce8-2b977ec76119/%E5%9B%BE%E7%89%879.png" style="width: 70%;" class="fr-fic fr-dib"&gt;本次WAIC CONNECT香港站的成功举办，不仅为沪港两地产业界搭建了高效的对接桥梁，更为AI技术的场景落地描绘了清晰蓝图。从文娱体商的跨界融合，到智慧教育的深耕细作，我们看到了&amp;ldquo;生态共建&amp;rdquo;的无限可能。未来，WAIC将继续致力于推动AI技术与生活场景的深度融合，让科技真正服务于人，温暖社会。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>剑桥与北航等设计可穿戴设备+LLM，融合肌肉振动、脉搏与大模型推理的无声语音系统</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>ScienceAI</author>
      <pubDate>Thu, 22 Jan 2026 14:09:15 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p data-pm-slice="0 0 []"&gt;编辑丨&amp;amp;&lt;/p&gt;&lt;p&gt;智能可穿戴设备的研发与设计，往往会伴随着人文关怀的色彩。这些功能各异的系统在各自的领域往往能强有力的技术支持，而 AI 的搭载能协助捕捉更细节的生物信号，完成更精细的操作。&lt;/p&gt;&lt;p&gt;来自英国剑桥大学与北京航天大学等多所高校的实验团队介绍了一套由人工智能驱动的智能喉咙（IT）系统，将喉部肌肉震动与动脉脉冲信号与&amp;nbsp;LLM&amp;nbsp;相结合，实现流畅且情感表达的交流。该系统在与无名中风患者的测试中，实现了 4.2%的单词错误率，2.9%的句子错误率。&lt;/p&gt;&lt;p&gt;相关研究内容以「Wearable intelligent throat enables natural speech in stroke patients with dysarthria」为题，于 2026 年 1 月 19 日刊登于《Nature Communications》。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNibWRoLj1XD44K6r5tv7RpjagKsLN4Df6c6c25xhatcNYU6ThM7ToaFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3410041841004184" data-type="png" data-w="956" data-width="956" data-height="326" data-backw="546" data-backh="186" data-imgfileid="100027217" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/5ea75b82-4f80-4be5-a9df-ac913819d664/640.png" alt="图片" data-before-load-time="1769062126816" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;论文链接：&lt;em&gt;https://www.nature.com/articles/s41467-025-68228-9&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解读身体正在说什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对中风、ALS 或帕金森患者而言，语言并不是&amp;ldquo;消失了&amp;rdquo;，而是被困在身体里。他们仍然能组织语义、仍然有情绪、仍然知道自己想说什么，但声音无法稳定、连续地被表达出来。&lt;/p&gt;&lt;p&gt;过去几十年，辅助交流技术（AAC）始终在尝试弥合这道鸿沟，但实际上真正缺失的是一种既贴近身体、又理解语言本身的系统。上述团队所提出的 IT 系统就弥补了这其中的缺陷。&lt;/p&gt;&lt;p&gt;该系统能够捕捉喉部肌肉的外部振动和颈动脉脉搏信号，实时整合无声语音和情绪状态分析。此外，其还能生成个性化、符合语境的句子，准确反映患者的意图。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNLJtSiap8IjxhFJorUTdUxRWI6PtlNftQMNGIcfQFsXTSAoVWtQXVjiaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.37518248175182484" data-type="png" data-w="685" data-width="685" data-height="257" data-backw="546" data-backh="205" data-imgfileid="100027215" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4780a33f-b99c-461c-8cca-702607739ade/640.png" alt="图片" data-before-load-time="1769062128473" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：为中风构音障碍患者开发的 IT 示意图。&lt;/p&gt;&lt;p&gt;这个系统所搭配的柔性智能颈环核心是&lt;strong&gt;印刷在弹性织物上的石墨烯应变传感器&lt;/strong&gt;，可检测低至&amp;nbsp;&lt;strong&gt;0.1% 的微小应变&lt;/strong&gt;，频率范围覆盖无声发音相关的快速肌肉活动。通过各向异性结构与隔离层，这个颈环对细微应变的响应超过了&amp;nbsp;&lt;strong&gt;10%&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNJrPJBTCpgWHibcLzFw7RcOYJbOA7YaDf06QJRty2ib7yENMuQwuz9U1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.8992700729927007" data-type="png" data-w="685" data-width="685" data-height="616" data-backw="546" data-backh="491" data-imgfileid="100027216" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c1f6f13a-e472-4311-9eb4-1a3b43c137c7/640.png" alt="图片" data-before-load-time="1769062128921" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：IT 的硬件与数据收集。&lt;/p&gt;&lt;p&gt;此外，IT 系统选择了一条更接近真实语言的路线，它能以约&amp;nbsp;&lt;strong&gt;100 ms&lt;/strong&gt; 为时间尺度进行 token 预测，不再强制分词或分句。用户可以连续&amp;ldquo;默念&amp;rdquo;，系统持续输出语言流的同时，还能通过&lt;strong&gt;知识蒸馏&lt;/strong&gt;将模型计算延迟降低&amp;nbsp;&lt;strong&gt;76%&lt;/strong&gt;，保证整条链路足够快，避免&amp;ldquo;人已经想完一句话，系统还在反应上一句&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解码与 LLM 代理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除此之外，团队还将&amp;nbsp;DFT 频率提取纳入解码流程之中，这种方法使端到端神经网络能够自动提取最相关特征，以进行无需手动特征工程的情感分类。结果显示 DFT 在解码准确性方面有显著提升。最优模型是带有 DFT 的 1D 卷积神经网络，准确率达到 83.2%。&lt;/p&gt;&lt;p&gt;在临床观察中，团队观察到即使是无声默念短语，也会导致肌肉疲劳等现象，让发声出现偏差。为了减少相应的体力损失与保留预期信息，团队引入了智能扩展选项，允许患者表达简洁的符号，这些符号会自动丰富为完整且符合上下文的句子。&lt;/p&gt;&lt;p&gt;而为了确保句子自然且连贯，他们引入了两个基于GPT-4o-mini AP I的 LLM 代理：符号合成代理（TSA）和句子扩展代理（SEA）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/mmbiz_png/XLCp9HBkwLlMXicuPY3icjTp7MfcicPwiaNNhKXmEt4AZUQkKqVnFRugdibQKy0icpic6KBrkhiaHiadZ3QSv1Ugn62sQfw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="1.0277372262773723" data-type="png" data-w="685" data-width="685" data-height="704" data-backw="546" data-backh="561" data-imgfileid="100027218" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/06dfab39-2fcb-49c1-8c3a-3ef6a6145b71/640.png" alt="图片" data-before-load-time="1769062129071" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;图示：LLM 代理框架与性能评估。&lt;/p&gt;&lt;p&gt;TSA 将 token 标签直接合并为患者无声表达的词语，并将它们组合成句子；而 SEA 则利用情绪标签和客观信息，将这些基本句子扩展为连贯、个性化的表达。这两个代理生成的句子都会被发送到开源的文本转语音模型，并以匹配后的语音进行播放。在实际应用中，用户完成无声表达与句子播放之间的延迟大约为 1 秒。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能发声&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;全面的分析和用户反馈肯定了 IT 在流畅度、准确性、情感表达和个性化方面的高绩效。该系统的成功来自于其能够捕捉高质量信号的超灵敏纺织应变传感器，高分辨率的标记化分割技术使用户能够无表达延迟地进行连续沟通。&lt;/p&gt;&lt;p&gt;该系统采用的 LLM 代理的集成实现了智能纠错和上下文适应，实现了卓越的解码准确率，用户满意度提升了55%。&lt;/p&gt;&lt;p&gt;这只是个开始。团队还在积极扩大研究队列，纳入更多构音障碍患者，并计划扩大语言数据库，实现更高的覆盖率。硬件与软件的升级也同样在他们的准备之中。团队表示，他们希望自己的成果能协助有关病患改善他们的生活质量。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>拒绝成为落后的开发者：用TRAE Skills构建你的10倍效能工具箱</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 12:57:09 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜Panda&lt;/section&gt;&lt;p&gt;现在的 AI 编程领域，什么概念最热？毫无疑问是 Skill。&lt;/p&gt;&lt;p&gt;在 X 上，一些分享 Skill 的帖子轻轻松松就能获得数十万的浏览量。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529549" data-ratio="1.2828125" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKrfq4BjXFibxkFcpUnt7kINuhKhb216Ud40iblmWUqXTHer07O7n4qZicw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=1" data-type="gif" data-w="640" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/908b0309-1b4b-4455-9248-a39480d74025/640.gif" data-order="0" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 图源：X 用户 @omarsar0、@vista8、@bozhou_ai、@yanhua1010 等&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;原因很简单，Skill 的出现标志着 AI 协作正式进入了「&lt;strong&gt;经验资产化&lt;/strong&gt;」的新阶段。在 2026 年的今天，我们正处于泛化工作场景的生产力拐点。Skill 不再仅仅是程序员的提效工具，它正在成为一种通用的专业能力协议。过去那些高度依赖个人经验、难以量化的&lt;strong&gt;&amp;nbsp;SOP（标准作业程序）&lt;/strong&gt;，现在可以通过一个 SKILL.md 文件实现标准化的封装与跨场景的移植。&lt;/p&gt;&lt;p&gt;这意味着，无论是个人的知识管理逻辑，还是复杂的行业调研流程，都可以像安装插件一样迅速注入给 AI。这种转变将 AI 从一个通用的「对话者」变成了拥有特定领域直觉的「专业执行者」，从而彻底打破了专家经验的传播壁垒。当个人的数字化直觉能够被大规模复刻与分发，全行业的生产力爆发便有了可落地的基石。&lt;/p&gt;&lt;p&gt;与此同时，Skill 本身以及使用它们的方式也在同步进化。比如前些天，Vercel 创始人 Guillermo Rauch 推出了所谓的「AI skill 的 npm」，让用户仅需一个简单命令 npx skills add [package]，就能为自己的 AI 智能体轻松注入专业能力。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKrdadKC2I6CXjb1DYwkOjQ1Iic9PwjspQgqicMkDgZtUuUHn9OjPibMcKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="1.0882723833543506" data-s="300,640" data-type="png" data-w="793" type="block" data-imgfileid="503529547" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/7ce5b61d-1914-4b0c-9bdb-2b608b0bba73/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;看得出来，趋势很明显：Skill 正在成为 AI 编程甚至日常工作流程的标配。&lt;/p&gt;&lt;p&gt;AI 大牛 Andrej Karpathy 在近期的一则超 1600 万浏览的推文中也指出，现在出现了一个全新的「&lt;strong&gt;可编程抽象层&lt;/strong&gt;」需要去掌握。这个层级不仅包含传统的代码逻辑，更涉及智能体、子智能体、提示词、上下文、内存、权限、工具以及重要的&amp;nbsp;&lt;strong&gt;Skill&lt;/strong&gt;。他认为，如果程序员无法通过整合这些在过去一年里涌现的工具来实现 10 倍效能的提升，那本质上就是一种「技能问题（skill issue）」。在他看来，一种强大的「外星工具」已经交到了人类手中，但它没有附带说明书，所有人都在这场 9 级地震中摸索着如何操控它。他还感叹道：「作为一个程序员，我从未感到如此落后。这个职业正经历着剧烈的重构，程序员直接贡献的代码比例正变得越来越稀疏。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKRZPoNLDicZvygk3MVWpmQrfcwyUawogJpsicVmmymZS0ibWtGztGRicbnA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.3044585987261146" data-s="300,640" data-type="png" data-w="785" type="block" data-imgfileid="503529548" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/a682d446-8c66-4266-9576-f9bb287185bc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些趋势和感叹的背后，反映了 AI 工具从「助理」向「数字员工」的本质转变。开发者们关注的重点已经从零散的提示词编写转向了构建可复用的智能体工作流。&lt;/p&gt;&lt;p&gt;在这个背景下，字节跳动旗下的 AI 工程师产品 TRAE 迅速进化，正式上线了其 Skill 功能。&lt;/p&gt;&lt;p&gt;它深度兼容了这种「技能封装」的范式，允许用户通过一个简单的 SKILL.md 文件，将复杂的指令、脚本和资源封装成可复用的专业技能包。而且它更加易用，&lt;strong&gt;0 代码基础也可轻松上手&lt;/strong&gt;。我们可以这样类比，如果说 Vercel 的 Skills 软件包定义了 AI 技能的分发标准，完成了「npm 时刻」的跨越，那么 TRAE 对 Skill 的深度集成就是 &lt;strong&gt;AI 编程的「OS（操作系统）原生集成」时刻&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这意味着，当 Karpathy 还在呼吁开发者们撸起袖子去迎接重构时，TRAE 已经为开发者提供了一个现成的技能脚手架，帮助大家从繁琐的代码搬运中解脱出来，转而去构建那个更具想象力的「抽象层」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;究竟什么是 Skill？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单来说，Skill 可以被理解为一个「&lt;strong&gt;专业技能包&lt;/strong&gt;」。它的物理形态是一个名为 SKILL.md 的 Markdown 文件，通常存放在项目根目录下的 ./trae/skills 路径中。这个文件就像是一份给 AI 智能体的「按需读取手册」，里面记录了完成特定领域任务所需的详细指令、自动化脚本以及模板资源。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKWPrwiaz06bIEF1xeok32Q0m5RpK9uv421MHD1zaYKkf8upS0Cy1rwvQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0343601895734598" data-s="300,640" data-type="png" data-w="844" type="block" data-imgfileid="503529550" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/1411544f-7654-4ee6-ab37-c7471ac7b2f6/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 我们在 TRAE 中为某个项目配置的一些 Skill&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;可以看到，一个 Skill 的典型结构是这样的，其中仅有 SKILL.md 文件是必需的，其它都是可选的，具体会根据你的 Skill 需要来决定：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK041B2cZDw38sLhsQTIa5Jvn9a6DAj9JhvXNM4yt3l6TiacAavaF7p1g/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.49676584734799484" data-s="300,640" data-type="png" data-w="773" type="block" data-imgfileid="503529551" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/b5bed77f-5deb-4ee2-9663-846b8d41bd90/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;下图展示了来自 Anthropic 官方的 frontend-design（前端设计）Skill，这就是一个仅有单个 SKILL.md 文件（这里没考虑许可证）的 Skill：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKFxNmHdtAB9JctibhAo8PTYy5w5V9omMveG6mVy3P43DWlhq6Ojia8Ojg/640?wx_fmt=png#imgIndex=6" alt="长图滚动查看" data-ratio="2.137962962962963" data-w="1080" data-aistatus="1" data-original-style="width: 1048.45px;height: auto;display: block;border-radius: 4px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/40f48b2d-5a07-4eb0-8e60-e8bdbb66d5ec/640.png" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可以看到，一个 SKILL.md 文件通常由元数据（名称、描述、证书）和具体提示词构成。&lt;/p&gt;&lt;p&gt;也就是说，Skill 本质上也还是提示词，那么我们为什么不直接使用提示词，而要使用 Skill？&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术逻辑：从「全量加载」到「按需调用」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Skill 的出现解决了当前 AI 编程中的一个核心痛点：&lt;strong&gt;Token 消耗与任务专注度的平衡&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;传统的 Rules 文件通常采用全量加载模式。只要用户开启对话，Rules 中的所有指令都会持续占用上下文窗口。随着指令集的增加，这会导致宝贵的 Token 被大量浪费，甚至干扰智能体对当前任务的判断。&lt;/p&gt;&lt;p&gt;Skill 则引入了&lt;strong&gt;动态调用机制&lt;/strong&gt;。智能体只有在识别到当前任务与 Skill 的触发条件匹配时，才会主动加载相关的指令包。这种「即插即用」的设计既节省了 Token 消耗，也确保了智能体在执行具体任务时能够保持极高的专注度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;差异化定位：Skill vs. 其他功能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了更精准地使用 Skill，我们需要明确它在 TRAE 协作体系中的定位：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;与普通提示词（prompt）的区别：提示词通常是单次使用的。当你发现自己在对话中反复输入同一段指令时，这就意味着效率的损耗。Skill 将这种重复性的 Prompt 提取出来，转变为 SKILL.md 中的标准指令。它让原本飘忽不定的对话逻辑变成了可以被智能体反复调用的专业技能包。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;与 Rules 的区别：Rules 适合存放全局偏好，例如代码规范、语言习惯或排版设置。Skill 则用于封装具体的工作流，当同一个提示词被输入超过三次时，它就应该被沉淀为一个 Skill。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;与 Context 的区别：Context 属于被动读取的知识库，智能体无法自主决定何时调用，且会持续占用上下文空间。Skill 是结构化的主动指令，能够根据意图识别自动触发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;与 Sub agent 的区别：Sub agent 定义的是具体的专家角色，而 Skill 是这些专家可以共享的技能组件。一个成熟的 Skill 具有极强的可移植性，可以在不同的智能体之间自由组合与复用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;很显然，&lt;strong&gt;Skill 正将分散的、碎片化的提示词经验转化为标准化的「数字资产」&lt;/strong&gt;。通过这种模块化的封装，开发者不仅可以沉淀个人的工作 SOP，还能在社区中快速获取并复用顶尖专家的专业能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一手实测 TRAE Skills：10 倍效能真的来了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Andrej Karpathy 提到的「10 倍效能革命」究竟如何落地？在掌握了 Skill 的技术原理之后，我们需要将其带入真实的开发场景中进行验证。&lt;/p&gt;&lt;p&gt;目前，最新版本的 TRAE 已实现了对 Skill 的全量支持。接下来，让我们将深入多个实际场景，看看 Skill 可以如何通过结构化的 SOP，帮助开发者和普通用户实现能力破局。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;秒级上手，让 TRAE 成为你的 AI 技能装配工厂&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要使用 Skill，首先当然是配置 Skill。现在这种「技能包」模式正在全网范围内爆火，无论是 GitHub 上的开源仓库还是开发者社区的讨论，大家都在尝试通过 Skill 沉淀专业经验。也因此，我们能在网上找到大量可用资源，比如 Anthropic 的官方 Skill 库 anthropics/skills 或者是各类 Awesome 库。与此同时，目前，凭借极&lt;strong&gt;强的生态兼容性、自然语言驱动的极简门槛、高度结构化的能力封装&lt;/strong&gt;等核心优势，TRAE 也正在全网走红。&lt;/p&gt;&lt;p&gt;具体来说，要在 TRAE 中使用一个 Skill，只需将其文件夹放到项目文件夹的 .trae/skills 目录下即可。&lt;/p&gt;&lt;p&gt;是的，就这么简单！&lt;/p&gt;&lt;p&gt;更妙的是，TRAE 对自然语言的支持让创建 Skill 变得极其简单，即便是 0 代码基础也能快速上手。你只需对 TRAE 描述你的需求，它就能自动为你编写一个 Skill。比如下面展示了我们让 TRAE「写一个用于编写 Chrome 插件的 Skill」的全过程：&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/6e1d61b2-7143-4ea9-9da9-41e49afbf478/1769057640900.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;可以看到，TRAE 会自动调用一个默认配置的 Skill「skill-creator」来完成该任务。速度也非常快，这里仅用时 50 秒。下面来看看这个被自动命名为 chrome-extension-developer 的 Skill 质量如何：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK7ZibdQ5sNWM1xk6RadIsQ1IicILkXS2bQF13yrfEUYof51PgCHpx58dA/640?wx_fmt=png#imgIndex=7" alt="长图滚动查看" data-ratio="2.2326454033771106" data-w="1066" data-aistatus="1" data-original-style="width: 1048.45px;height: auto;display: block;border-radius: 4px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/22dce335-7a2b-4371-92e6-8943fcfe9fec/640.png" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;看得出来，这个由 TRAE 生成的 Skill 展现了极高的工程化水准。它没有停留在宽泛的概念描述层面，而是相当精准地捕捉到了 Chrome 插件开发从 Manifest V2 转向 V3 过程中的核心痛点。具体而言，它将复杂的 Manifest V3 开发 SOP 拆解为可执行、可验证的指令集。有了这个技能包，即便是插件开发的新手，也能在 TRAE 的辅助下写出符合谷歌官方最新标准的工业级代码。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实战见真章，Skill 能让 AI 真正拥有专家执行力&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;有了 Skill，当然要用起来。在 TRAE 中，调用 Skill 的方法也非常简单。正如我们前面创建 chrome-extension-developer Skill 时一样，TRAE 会根据当前的任务需求自动选择调用合适的 Skill，当然开发者也可以在提示词中显式指示 TRAE 使用哪些 Skill。&lt;/p&gt;&lt;p&gt;下面我们就先使用 TRAE 构建的这个 Skill 来编写一个非常实用的 Chrome 插件：&lt;/p&gt;&lt;p&gt;编写一个 Chrome 插件，它能将当前网页导出为 Markdown 文件，将网站链接等数据保存在元数据区域。&lt;/p&gt;&lt;p&gt;接入了 GPT-5-medium 的 TRAE 很快完成了任务，耗时仅仅 2 分钟。&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/50ebcbd0-b591-4641-a428-f803865701aa/1769057664925.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;展开其思考过程，可以看到即使我们这里并没有明确说明是否使用 Skill，TRAE 依然根据任务需求选择了刚刚创建的 Skill，从而确保了输出代码的质量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLtRk5ozIibTtdo5l5LwfiaP07QAXiaQ39v3wOiaPp3FF9HDic0waWRspWIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5867768595041323" data-s="300,640" data-type="png" data-w="726" type="block" data-imgfileid="503529552" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/e162b11a-f957-4c1f-bb5d-fb8e7f915ade/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;至于结果，可以说是相当令人满意：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKdIBrZQq76Lp7GN3xPfhWOWjPR5dFZJl586JfD1pHP7jZP1T4ziaWKfQ/640?wx_fmt=gif&amp;from=appmsg#imgIndex=9" data-ratio="0.5393883225208527" data-type="gif" data-w="1079" type="block" data-imgfileid="503529558" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/69a58863-fdee-4007-ac50-7e34e5fb6574/640.gif" data-order="1" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;当然，我们也可以直接下载网络上开源的 Skill，将已有的成功经验化为己用。&lt;/p&gt;&lt;p&gt;比如这里，我们就将 Anthropic 官方在 skills 库中发布的所有 Skill 都集成到了当前的项目中。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKBkqxUgFZ7udTsFfETeQlEibe2WickdQffV9DU0SkBZVRt3sj7kr5IibEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="2.003731343283582" data-s="300,640" data-type="png" data-w="268" type="block" data-imgfileid="503529555" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/835e3480-5cc4-4d87-8494-bd88d09ff9bb/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;我们注意到其中有一些用于文档处理的 Skill。值此 DeepSeek-R1 模型诞生一周年之际，我们就用其技术报告做做实验。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;下载并解读这个 PDF 文档：https://arxiv.org/pdf/2501.12948 ，将内容整理成一份内容详实有深度、图表丰富且悦目的 PPT。你可以使用 pdf skill 提取里面的图表来使用，并使用 pptx 来生成 PPT。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/36988588-bb48-47ef-9abd-3442bbb84170/1769057693039.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;执行过程中，我们看到其接连调用了 pdf 和 pptx 两个 Skill，至于最后得到的结果，虽然和我们提示词中提到的「悦目」尚有差距，但这反映了当前 AI 绘图与排版技能的一个通用逻辑。Skill 目前更侧重于逻辑结构的自动化与功能实现，而对于极具主观性的「审美偏好」，仍需要用户通过更细致的视觉设计 Skill 或手动微调来完成最后的磨皮。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKhaibAVUUbZUIKpcTWSXZTFPibhzy0XG3AGlwe5tfyeCWjNYD7utrHiawA/640?wx_fmt=gif&amp;from=appmsg#imgIndex=11" data-ratio="0.75" data-type="gif" data-w="1080" type="block" data-imgfileid="503529557" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/738c08ad-f82e-4699-97ab-7409269668fc/640.gif" data-order="2" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;SKill 的玩法还不止于此，如果你觉得在 GitHub 寻找你想要的 Skill 也过于麻烦，没有关系，你完全可以创建一个 Skill，让 TRAE 为你寻找并下载合适的 Skill。&lt;a href="https://mp.weixin.qq.com/s/WNvEhNUv0BaZaW-W_Tec4A"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/101626f8-9056-4cab-88b1-507df994ad53/1769057713424.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;可以看到，TRAE 调用 skill-creator 创建了一个名为 skill-finder 的 Skill。根据描述，这个 Skill 会执行 5 步任务：分析需求&amp;rarr;搜索 GitHub&amp;rarr;验证&amp;rarr;下载安装&amp;rarr;确认。看起来符合我们的需求。下面就来试试看，直接上一个比较复杂的任务：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;编写一个展示洛阳从古至今历史的动态网页，里面要有一个时间轴，让用户可以滑动选取时间，根据所选时间，下面的介绍部分也会随之变化，加入一些文物或遗址的照片增强说明。使用莫兰迪色系。开始任务前先使用 skill-finder 配置相关 Skill。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这一次 TRAE 执行了 5 分钟，期间它成功使用了 skill-finder，找到并下载了 web-design-guideline 和 vercel-deploy 两个 Skill。之后，TRAE 完成了内容的检索，并在 web-design-guidelines 的指导下，完成了网页的构建。但最终结果却并不很好，尤其是图片 &amp;mdash;&amp;mdash; 要么货不对板，要么就根本无图。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK1CHgv2qicGQ6nImy8eIZS5Z9mbZibDqAvVl5iaPO1XnSJmNibUVhYN0j2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.5231481481481481" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529556" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/92127218-530b-4aaa-8f1c-153af27ba753/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;但没有关系，我们还可以继续与 TRAE 互动，细化需求，让其进行改进：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;生成的结果网页中的图片有问题，而且每段历史的描述内容过于浅显。请修复问题，寻找切实可用的图片（最好下载到本地），并丰富内容描述，比如哪些时段诞生了哪些名人等。首先，使用 skill-finder 寻找能帮你完成这个任务的 skill，比如用于深度研究或图片下载的 Skill。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这一次，又执行了 5 分钟，所得到的结果已经勉强可用了。这里我们可以感受到，TRAE 开始展现出某种「自我驱动」的特质。虽然第一版结果存在数据源抓取的偏差，但这种「发现问题、寻找技能、自我修复」的闭环，才是 10 倍效能提升的真髓所在：它将开发者的工作重心从「修 Bug」转移到了「定义工作流」的高度。&lt;/p&gt;&lt;p&gt;当然我们也还可以继续让 TRAE 进行调整，比如更加细化历史分段、保证每一段的文本描述不低于 3000 字等等，但我们这里的体验展示就到此为止了。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKPicKn23jwX22P20NVemBpTAiccrQVBqlhZfGicZ1ibRWibUZGTpoGMOfEhw/640?wx_fmt=gif&amp;from=appmsg#imgIndex=13" data-ratio="0.5244755244755245" data-type="gif" data-w="1001" type="block" data-imgfileid="503529559" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/4905e4d6-8ecc-4179-88e8-206ec2f41549/640.gif" data-order="3" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;整体体验下来，我们感觉 TRAE 对 Skill 的集成虽还不能说完美，比如如果使用视频下载 Skill，还需要一些手动验证，但也展现了极高的成熟度。&lt;strong&gt;即便对于完全不懂编程的小白用户，只要能够清晰地描述自己的业务 SOP，就能通过 TRAE 快速封装出属于自己的技能组合，进而提升效率。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单畅想一下，Skill 不仅可以成为 Vibe Coder 们的得力工具，也完全可以作为用户手中的个人数字管家。通过配置特定的技能包，你可以让 TRAE 扫描并清理下载文件夹，根据文件类型或者 AI 对内容的理解进行智能重命名与归类。对于习惯使用 Obsidian 的知识管理爱好者，Skill 可以自动将杂乱的网页剪藏转化为带有标准 YAML 区块和双链规范的 Markdown 笔记。无论是将长视频文案转化为适合社交媒体分发的短贴，还是通过上传 CSV 格式的银行流水生成月度消费趋势报告，用户都可以借助 Skill 实现高效的机器执行力。而 TRAE 正是一个可用于实现这一点的称手工具。&lt;/p&gt;&lt;p&gt;心动了吗？为了庆祝周年并降低 Skill 功能的使用门槛，官方从 1 月 14 日起为 TRAE 国际版用户发放了丰厚的 Fast Request 权益。这基本相当于赠送了一个月以上的 Pro 会员额度。其中 Free 用户增加 600 次，Pro 用户增加 800 次，而且在权益期内，包括 GPT 5.2 在内的所有顶级模型均可免费使用。&lt;/p&gt;&lt;p&gt;领取流程极其简单，大家只需登录官网 trae.ai 或者在 IDE 顶部的活动横幅点一下即可。这种好机会建议大家快去尝试，构建属于你自己的专业技能包。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从指令搬运到专业资产的沉淀&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Andrej Karpathy 所描述的那个全新的「可编程抽象层」正在变得日益清晰。在这个层级中，Skill 是一套被标准化封装的行业智慧，它标志着 AI 工具正从通用的生成模型演变为具备特定领域 SOP 的专业执行者。&lt;/p&gt;&lt;p&gt;当个人或团队的经验可以被打包并像 npm 包一样自由分发与复用时，个体的创造力将被无限放大。很明显，Skill 正在确立一种全新的协作标准。字节跳动 TRAE 在 SOLO 模式中的深度集成，为这种范式的落地提供了一个高效的试验场。&lt;/p&gt;&lt;p&gt;对于开发者而言，现在正是将那些重复的、高价值的工作流程沉淀为 SKILL.md 的最佳时刻。在 2026 年的 AI 浪潮中，掌握并构建属于自己的「技能库」，将是应对职业重构、实现 10 倍效能提升的核心竞争力。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>第一梯队的大模型安全吗？复旦、上海创智学院等发布前沿大模型安全报告，覆盖六大领先模型</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 12:48:25 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/b41b408d-c6af-4664-ba3c-65317398e3dd/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p data-pm-slice="2 2 []"&gt;随着大语言模型加速迈向多模态与智能体形态，传统以单一维度为主的安全评估体系已难以覆盖真实世界中的复杂风险图景。在模型能力持续跃升的 2026 年，开发者与用户也愈发关注一个核心问题：&lt;strong&gt;前沿大模型的安全性，到底如何？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于这一背景，&lt;strong&gt;复旦大学、上海创智学院、迪肯大学与伊利诺伊大学厄巴纳 &amp;mdash; 香槟分校的研究团队联合发布&lt;/strong&gt;本次安全评测报告，面向 &lt;strong&gt;GPT-5.2、Gemini 3 Pro、Qwen3-VL、Grok 4.1 Fast、Nano Banana Pro、Seedream 4.5&lt;/strong&gt; 六大前沿模型，构建了一套覆盖&lt;strong&gt;语言、视觉语言与图像生成&lt;/strong&gt;三大核心场景的统一安全评测框架，对当前主流大模型的安全能力进行了系统性、全景式刻画。在评测设计上，融合了四大关键维度，形成多层次、立体化的安全评估体系：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;基准评测&lt;/strong&gt;，系统整合 ALERT、Flames、BBQ 等&lt;strong&gt; 9 个国际主流安全基准&lt;/strong&gt;，全面刻画模型在标准风险分布下的基础安全能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;对抗评测&lt;/strong&gt;，覆盖&amp;nbsp;&lt;strong&gt;30 种代表性黑盒越狱攻击方法&lt;/strong&gt;，包括语义伪装、代码混淆与长程多轮诱导等复杂攻击形态，真实还原高强度对抗场景；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多语言评测&lt;/strong&gt;，支持&lt;strong&gt; 18 种语言&lt;/strong&gt;，系统检验模型安全机制在跨语种环境下的稳定性与迁移能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;合规性评测&lt;/strong&gt;，面向&lt;strong&gt;欧盟《AI 法案》、美国 NIST RMF、新加坡 MAS FEAT 及中国《生成式人工智能管理办法》&lt;/strong&gt;等核心监管框架，评估模型在全球治理体系下的合规适配水平。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过全方位的安全评测，本报告揭示了前沿大模型&lt;strong&gt;在不同应用场景、威胁模型与监管语境下的安全边界&lt;/strong&gt;，为产业落地与政策制定提供一定参考。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0CgYGicoDmq5oWZ6XZrxJDNExEoL6zAGe2vicxYykVYh5LK9KSHUIc2vA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503529084" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/751d79be-c344-4867-9e0c-f434c227c1b3/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文链接: https://arxiv.org/pdf/2601.10527&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页: https://xsafeai.github.io/AI-safety-report/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Github链接: https://github.com/XSafeAI/AI-safety-report&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace链接: https://huggingface.co/papers/2601.10527&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;声明&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;本报告是一项基于公开方法与统一框架开展的学术性安全评测研究，旨在为前沿大模型的安全能力提供系统性认知参考，而非任何形式的监管裁定或合规结论。评测结果具有明显的&lt;strong&gt;时效性与场景依赖性&lt;/strong&gt;，应主要用于推动安全评估体系的透明化与持续改进，而不宜被解读为简单的模型排名或舆论定性依据。&lt;/p&gt;&lt;p&gt;本报告选取的评测对象均为当前&lt;strong&gt;通用能力处于第一梯队的前沿模型&lt;/strong&gt;。我们亦对其他模型进行了探索性测试，其整体安全表现普遍低于本报告所纳入的模型，但未在正文中展开呈现。另需说明的是，由于 API 使用成本因素，本次研究未覆盖 Claude 系列模型。&lt;/p&gt;&lt;p&gt;受限于资源与周期，本报告的评测规模仍然有限，难以全面覆盖真实世界中的所有风险形态，相关结论不可避免具有一定的局部性与阶段性，&lt;strong&gt;应被视为学术参考而非最终结论。&lt;/strong&gt;&lt;/p&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;全方位安全评测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;报告的主要发现如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;基于静态安全基准的评测会普遍高估安全性，&lt;strong&gt;在真实越狱攻击下没有模型具备可靠的防御能力&lt;/strong&gt;，即使 GPT-5.2 在最坏情况下的安全率也仅约 6%，其他模型接近于 0%；多轮自适应攻击和跨语言场景成为当前最大的安全短板。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不同模型呈现出明显的 &amp;ldquo;&lt;strong&gt;安全人格&lt;/strong&gt;&amp;rdquo; 差异：GPT-5.2 为全能内化型，Qwen3-VL 为准则合规型，Gemini 3 Pro 为伦理交互型，Grok 4 Fast 为自由效率型；在文生图模型中 Nano Banana Pro 整体最稳，为柔性重塑型，Seedream 4.5 为坚实屏障型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;安全能力排行&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ0oIWlp43Foicia3a3BdbAbB3syaC7wh3YHx0ibncA0sGQwU8gTQeVroD1A/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.47836538461538464" data-s="300,640" data-type="png" data-w="832" type="block" data-imgfileid="503529085" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8a626dfc-4127-472a-a353-25775fafafb8/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;1. 语言模态安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5.2 &lt;/strong&gt;的平均安全率为 &lt;strong&gt;78.39%&lt;/strong&gt;，展现出业界领先的安全水平，其安全机制已从依赖规则触发与启发式过滤，迈入以深层语义理解与价值对齐为核心的阶段。这一范式转变使模型在复杂、灰区场景中的安全判断更加稳定，也显著降低了在对抗输入下的失效风险，体现出当前最接近 &amp;ldquo;&lt;strong&gt;内生安全&lt;/strong&gt;&amp;rdquo; 的对齐形态。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini 3 Pro&lt;/strong&gt; 的平均安全率为 &lt;strong&gt;67.9%&lt;/strong&gt;，整体呈现出 &amp;ldquo;强但不均衡&amp;rdquo; 的安全特征：在基准评测与多语言安全上保持第二梯队领先，基准测试达到 88.06%，多语言安全率为 67.00%，合规性维度也取得 73.54% 的稳定成绩，显示其基础对齐与社会价值观校准较为扎实。然而，其对抗鲁棒性下降至 41.17%，与其基准表现形成明显落差，说明该模型在攻击驱动输入下仍存在可被利用的脆弱面，更适合 &amp;ldquo;常规分布&amp;rdquo; 下的安全场景，而在语义伪装与复杂上下文操纵中的泛化能力仍有提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Qwen3-VL &lt;/strong&gt;的平均安全率为 &lt;strong&gt;63.7%&lt;/strong&gt;，比肩 Gemini 3 Pro。其在&lt;strong&gt;合规性&lt;/strong&gt;方面表现尤为突出，以 77.11% 的成绩位居第二，体现了其在合规导向型安全策略上的系统优势。不过，其在对抗安全性（33.42%）与多语言安全（64.00%）上的明显回落，也反映出该模型更擅长 &amp;ldquo;规则明确型风险&amp;rdquo;，而在语义伪装与跨语境迁移方面仍有提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Grok 4.1 Fast &lt;/strong&gt;的平均安全率为 &lt;strong&gt;55.2%&lt;/strong&gt;，表现呈现出很大的不均衡性。尽管其在基线安全性（66.60%）和合规性评测（45.97%）中处于垫底位置，显示出系统性的合规短板 ，但其在&lt;strong&gt;对抗评测&lt;/strong&gt;中却展现了意外的韧性，以 46.39% 的安全率位列全场第二 。这种 &amp;ldquo;底座薄弱但对抗较强&amp;rdquo; 的独特性，反映了其防护策略可能更多依赖于对特定攻击模式的拦截，而非全维度的安全内化，在非英语语境和严监管场景中依然面临较大的合规挑战 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 多模态安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5.2 &lt;/strong&gt;的平均多模态安全率为 &lt;strong&gt;94.69%&lt;/strong&gt;，延续了全面领先的态势，在对抗评测下达到 97.24% 的近饱和表现，在基准场景中亦以 92.14% 稳居首位。这一结果表明，其安全机制不仅在文本层面实现了深度内化，在图文交互等复杂跨模态场景中同样具备高度稳定性，能够有效抵御视觉诱导、语义叠加等复合型风险，代表了当前多模态安全对齐的最高成熟度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Qwen3-VL &lt;/strong&gt;的平均安全率为&lt;strong&gt; 81.11%，超越 Gemini 3 Pro&lt;/strong&gt;。其以 83.32% 的基准成绩和 78.89% 的对抗成绩稳居第二，并在两类评测中均保持对 Gemini 3 Pro 的领先优势。这表明其在视觉 - 语言交互场景中的安全策略具备较好的结构完整性，能够在面对图文组合诱导时维持相对稳健的防御表现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini 3 Pro&lt;/strong&gt; 的平均安全率为 &lt;strong&gt;78.99%&lt;/strong&gt; 位列第三，整体呈现出 &amp;ldquo;可靠但保守&amp;rdquo; 的多模态安全特征。其在常规视 - 语言任务中的风险识别能力较为扎实，但在面对多轮视觉诱导、隐性语义嵌套等复杂攻击时，防御强度明显弱于前两名模型，说明其多模态安全机制仍更多建立在规则与触发层面，而非深层语义融合层面的统一对齐。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Grok 4.1 Fast &lt;/strong&gt;的平均安全率为 &lt;strong&gt;68.16%&lt;/strong&gt;。其表现具有一定 &amp;ldquo;反直觉&amp;rdquo; 性：其对抗成绩 68.34% 略高于基准成绩 67.97%，显示其安全水平对攻击扰动并不敏感。这一现象并不意味着其具备真正的鲁棒性，反而更可能反映出其更强的防护机制主要停留在浅层过滤与简单触发逻辑上，缺乏随攻击复杂度提升而动态调节的能力，整体仍难以支撑复杂真实场景下的多模态风险防控需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 文生图安全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Nano Banana Pro &lt;/strong&gt;的平均安全率为 &lt;strong&gt;59.86%&lt;/strong&gt;，在文生图安全评测中展现出当前最为成熟的整体防护水平，在基准评测（60.00%）、对抗评测（54.00%）与合规性评测（65.59%）三个维度均位居首位。其成绩随评测强度递进而稳定提升，表明该模型的安全机制并非仅针对静态提示词进行表层过滤，而是具备一定程度的风险语义重构与情境适配能力，能够在监管敏感场景下保持相对一致的防御表现。这一特征使其在艺术表达与内容合规之间形成了较为平衡的治理路径，是当前文生图模型中安全泛化能力最为突出的代表。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Seedream 4.5 &lt;/strong&gt;的平均安全率为 &lt;strong&gt;41.71%&lt;/strong&gt;，展现了坚实的合规基础，其基准安全（47.94%）与合规性（57.53%）成绩证明了其在受监管视觉场景下的精准防控优势，但是在对抗安全性（19.67%）方面成绩偏低，显示其基础防护能力仍存在结构性短板。该模型在显性监管红线与高风险类别上具备较为稳定的规则触发能力，然而这种以约束为主的防御模式在面对语义伪装、隐性诱导等对抗型提示时缺乏足够的语境理解支撑，导致在对抗场景中的安全鲁棒性仍显不足。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;大模型的 &amp;ldquo;安全人格&amp;rdquo; 画像&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8yFu85ydQMUTM8B86S5AJ06HuT5UGa6jzKmCNUictxFgK7yCXALFax41e7mBibLxDu3VMrRB30Bevw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6634615384615384" data-s="300,640" data-type="png" data-w="832" type="block" data-imgfileid="503529086" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b6dba02c-ec76-4037-833e-5f6f9012363d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;GPT-5.2（全能内化型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;其安全雷达图谱近乎全向饱和，表明安全机制已从外置规则演进为内生推理能力。在灰区与复杂语境中，GPT-5.2 往往能给出克制而精确的合规引导，避免过度拒绝与风险放行之间的摇摆。不过也正因其具备更强的语义理解与任务完成能力，在极少数高度隐蔽的对抗性场景中，其 &amp;ldquo;深度推理 &amp;mdash; 深度协作&amp;rdquo; 的优势亦可能被利用，对安全校准提出更高的持续演化要求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Qwen3-VL（准则合规型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在法律政策边界清晰、监管要求明确的场景中展现出极强的稳定性与可预期性，尤其在生物安全、政务合规等 &amp;ldquo;硬红线&amp;rdquo; 领域具备高度专业化的防御能力。然而，评测也显示，其安全策略明显偏向&lt;strong&gt;规则驱动&lt;/strong&gt;范式：当风险表达转向语义伪装或情境隐喻时，模型在跨语境推断与抽象风险识别方面的弹性仍显不足，使其在未知攻击形态下呈现出一定脆性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Gemini 3 Pro（伦理交互型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;采用 &amp;ldquo;先响应、后校准&amp;rdquo; 的人本化安全交互范式，在保障对话流畅度的同时保持较高的风险敏感性。其在社会价值观与文化语境对齐方面表现细腻，尤其擅长处理偏见与歧视类风险。但评测亦表明，其安全策略在部分场景中偏向&lt;strong&gt;事后纠偏&lt;/strong&gt;而非事前阻断，当面对对抗性重构或复杂情境操纵时，这种 &amp;ldquo;柔性防御&amp;rdquo; 在稳定性上仍有提升空间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Grok 4.1 Fast（自由效率型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;呈现出轻量化与极速响应的产品哲学，原生防御机制相对克制，更强调开放表达与低摩擦交互体验。其设计取向为用户提供了更大的创作自由度与更广阔的对话空间，体现出一种以&lt;strong&gt;效率与表达自由优先&lt;/strong&gt;的安全取舍路径，在开放性与防护性之间形成鲜明风格。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Nano Banana Pro（柔性重塑型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;擅长通过内生语义净化策略对高风险提示进行隐性重构，在维持生成质量与艺术表现力的同时，实现较为稳定的内容合规控制。这一 &amp;ldquo;柔性转译&amp;rdquo; 式治理模式在多数场景中有效平衡了安全与创作自由，但其对边界模糊风险的处理仍高度依赖隐式转换机制，一旦语义重塑失效，防护体系的显性支撑能力相对有限。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Seedream 4.5（坚实屏障型）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在文生图领域坚持以强约束为核心的安全设计理念，特别是在版权与暴力内容防御方面构建了稳定可靠的拦截闭环。然而，其安全体系明显呈现出 &amp;ldquo;&lt;strong&gt;阻断优先&lt;/strong&gt;&amp;rdquo; 特征：对边缘语义与灰区场景缺乏足够的语义判别弹性，导致在部分复杂创作需求下出现 &amp;ldquo;要么全挡、要么全漏&amp;rdquo; 的两极化风险，暴露出语义理解深度与生成自由度之间的结构性张力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对抗演进与治理挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 多轮自适应攻击的深层威胁&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究表明，攻击者通过持续观测模型响应并动态调整诱导策略，可形成具备 &amp;ldquo;自我进化&amp;rdquo; 能力的多步攻击链路。在此范式下，单一拦截层和静态规则体系难以形成有效防线，多轮自适应攻击在复杂场景中的绕过成功率显著提升，正在成为下一阶段大模型安全治理的核心挑战。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 跨语言安全的结构性不均衡&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;评测结果显示，多数模型在非英语语境（如泰语、阿拉伯语等）下的安全表现出现 &lt;strong&gt;20%&amp;ndash;40%&lt;/strong&gt; 的系统性下滑，暴露出当前安全对齐在语料分布与策略迁移上的显著不平衡。这一差距不仅削弱了模型的全球可用性，也放大了区域性风险外溢的可能性，构成全球部署背景下的长期隐患。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 决策透明度与可解释性的治理短板&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;尽管前沿模型在合规性指标上持续进步，但在拒绝决策的可解释性与责任可追溯性方面仍普遍存在结构性不足。当前安全机制更多体现为 &amp;ldquo;结果合规&amp;rdquo;，而非 &amp;ldquo;过程可审计&amp;rdquo;，这一缺口在高风险领域（如医疗、公共治理与国家安全）中尤为突出，已成为制约可信部署的重要制度性瓶颈。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本报告致力于为全球人工智能安全研究提供一份基于系统实证的关键参照坐标。随着模型能力呈指数级跃升，安全对齐已不再是事后修补式的技术叠加，而必须转向从底层架构、训练范式到多模态交互机制的全栈式深度嵌入。&lt;/p&gt;&lt;p&gt;本报告呼吁学术界、产业界与治理机构应当形成更加紧密的协同机制，共同构建兼具包容性、标准化与动态演进能力的安全评估体系，以制度化、工程化的方式推动生成式人工智能走向可控、可信与可持续的发展路径。&lt;/p&gt;&lt;p&gt;更为系统和深入的分析见论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚， 2025 ACM Fellow公布！陈宝权、贾佳亚、梅涛、朱军等多位华人入选</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 11:28:38 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;刚刚，美国计算机协会 ACM（Association for Computing Machinery）公布了最新一届会士名单。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad3gEycDKKqc5nvd4WHicBbYrCleoxNQU4EUicShF02Kaz14Dq5lh9crzQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.3910828025477706" data-s="300,640" data-type="png" data-w="785" type="block" data-imgfileid="503529582" data-aistatus="1" data-original-style="width: 426px;height: 593px;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/289df137-b0d1-4172-84e4-9f0c850b38c5/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;ACM 创立于 1947 年，是全世界计算机领域影响力最大的专业学术组织之一。&lt;/p&gt;&lt;p&gt;ACM Fellow 是由该组织授予资深会员的荣誉，目的为表彰会员中对于计算机相关领域贡献前 1% 的学者，其审查过程十分严格，每年遴选一次，研究员由同行提名，提名由委员会审查。&lt;/p&gt;&lt;p&gt;本年度新入选科学家中共有 71 人，他们的贡献涉及计算机图形学、网络安全、人机交互、数据管理、机器学习、人工智能、算法、可视化等领域。&lt;/p&gt;&lt;p&gt;ACM 主席 Yannis Ioannidis 表示：这份入选名单代表了「我们领域当前正在发生的事情的快照。例如，今年我们要表彰在计算机架构和软件工程等成熟学科工作的成员，以及在群体智能或场景识别等新兴学科的创新者。」&lt;/p&gt;&lt;p&gt;机器之心对这些华人入选者进行了简单介绍（如有遗漏或错误，欢迎在留言区指正）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pei Cao&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadS0W2hVoltHcjn53EQFkDIKIs1LGKLUAKfxqABRQkdeFwP8OicpStsXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9738219895287958" data-type="png" data-w="764" data-width="764" data-height="744" data-imgfileid="503529583" data-aistatus="1" data-original-style="width: 311px;height: 303px;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/9e373217-de62-422c-8489-a320bf74c022/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：YouTube&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：表彰其在网络缓存、搜索引擎效率和信息质量方面做出的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Pei Cao 是一位在业界极具影响力和知名度的技术专家与工程领导者。她曾先后在多家信息技术巨头任职，包括谷歌和脸书，目前担任 YouTube 公司的工程副总裁，在这一岗位上持续发挥着重要影响力。她于 2012 年加入 YouTube，担任工程总监兼首席软件工程师。在随后七年的时间里，她在这些岗位上表现卓越，并于 2019 年晋升为高级工程总监和杰出软件工程师，最终在 2022 年升任现职。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陈宝权（Baoquan Chen）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadOl1sWw4cVn1oNicic1slUSO8ASdwaWowen0hsa1X47j3jxLlbicOwuKEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.3333333333333333" data-type="png" data-w="240" data-width="240" data-height="320" data-imgfileid="503529584" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f301d786-c82a-4805-a53b-21e7fabfb566/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：北京大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：表彰其在大规模场景重建、离散几何处理和制造形状设计方面的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;陈宝权现任北京大学教授、智能学院副院长，研究领域为计算机图形学、三维视觉与可视化。在 ACM SIGGRAPH、IEEE VIS、ACM Transactions on Graphics (TOG)、IEEE Transactions on Visualization and Graphics （TVCG） 等国际会议和期刊发表论文 200 余篇。&lt;/p&gt;&lt;p&gt;陈宝权于 2017 年当选中国计算机学会会士，2020 年当选 IEEE Fellow，2021 年入选 IEEE Visualization Academy，当选中国图象图形学学会会士。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陈德铭 （Deming Chen）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadZRFcnJxXWHEjyicboicGyn2iaGmu11ZCa7pq0PnJYb86YkvkQxriamZib0g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.2366666666666666" data-type="png" data-w="300" data-width="300" data-height="371" data-imgfileid="503529585" data-aistatus="1" data-original-style="width: 239px;height: 296px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/0a4d6a27-2e9d-4f45-b377-b465277378df/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：伊利诺伊大学厄巴纳 - 香槟分校&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：对可重构计算的贡献，包括综合算法和可定制人工智能加速器设计方法。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;陈德铭于 1995 年获得宾夕法尼亚州匹兹堡大学计算机科学学士学位，并分别于 2001 年和 2005 年获得加州大学洛杉矶分校计算机科学硕士和博士学位。1995 年至 1999 年以及 2001 年至 2002 年担任软件工程师。&lt;/p&gt;&lt;p&gt;2005 年，陈德铭加入伊利诺伊大学厄巴纳 - 香槟分校电子与计算机工程系，并自 2015 年起担任该系的终身正教授。他同时也是协同科学实验室的研究教授，以及计算机科学系的兼职教授。目前，他的研究方向包括可重构计算、云计算、系统级和高级综合、机器学习和物联网以及硬件安全。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;郑光廷（Kwang-Ting Cheng）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadbicxOQV3yDZrWSKuGaDzuibv0osIIeP1obZXCa72iagFBem6sMLibWpAiaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7175925925925926" data-type="png" data-w="648" data-width="648" data-height="465" data-imgfileid="503529586" data-aistatus="1" data-original-style="width: 311px;height: 223px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/8ee7abd1-4c91-4770-9a4c-b55e0bbd98d8/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：香港科技大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在电子电路与计算系统的设计自动化以及软硬件协同设计方面做出的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;郑教授是国际知名的研究者，在推动跨学科研究合作的范畴上拥有丰富经验。他是电子测试及设计验证的权威，亦于多个学术领域上贡献良多，包括电子及光电子系统的设计自动化、计算机视觉，以及医学影像分析。郑教授于 2022 年 4 月 1 日出任香港科技大学副校长（研究及发展）。&lt;/p&gt;&lt;p&gt;郑教授于 1988 年在加州大学柏克莱分校取得电机工程及计算机科学博士学位。加入香港科大前，郑教授担任加州大学圣塔芭芭拉分校电机及计算机工程学系的教授。他自 1993 年开始在该校任教，并于加入该校前在 AT&amp;amp;T 贝尔实验室工作了五年。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;付昀（Yun Raymond Fu）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadNHsDmmoBWVfJo2RzhNGKVwliaDC3SDNo4WktoV5vRic5pTia8VXrGMlgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="1.037122969837587" data-type="png" data-w="431" data-width="431" data-height="447" data-imgfileid="503529587" data-aistatus="1" data-original-style="width: 273px;height: 283px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1e9835c3-90f2-44b5-a6b1-1943549171c6/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：东北大学 &amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在表征学习、计算机视觉、面部和手势识别方面的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;付昀是国际知名的高影响力人工智能研究者、杰出教授及连续创业者，获伊利诺伊大学厄巴纳香槟分校电子与计算机工程博士学位，现任美国东北大学工程学院与计算机学院双聘杰出教授，并担任电子与计算机工程系科研副主任，负责百余名教师的科研事务。&lt;/p&gt;&lt;p&gt;他在计算机视觉与机器学习领域作出多项奠基性贡献，提出的残差密集网络 RDN 与残差通道注意力网络 RCAN 发表在 CVPR2018 与 ECCV2018，被引用逾 1.3 万次，位列最具影响力论文之列。他已发表 500 余篇论文、拥有 50 余项专利，H-index 超过 107，总引用逾 5.8 万次，获得多项青年学者奖、最佳论文奖及来自顶级科技公司的产业奖项，并当选为多国科学院院士及 ACM、IEEE、AAAI 等多个学会 Fellow。在产业与创业方面，他四度成功创业，创办的 AI 公司 Giaran 于 2017 年被资生堂收购，推动增强现实技术在全球美妆电商中的规模化应用；同时他还是 TVision Insights 的联合创始人及首席科学家，该公司以计算机视觉技术重塑电视与流媒体广告衡量体系，获得多轮融资并在全球广告行业产生深远影响。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Zi Helen Huang&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad29SLLaEmZRvibWuEFCicIWl45TJyW3zQvYlJtWORZ5UX5oukuXcic0wjQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1" data-type="png" data-w="222" data-width="222" data-height="222" data-imgfileid="503529588" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/e7c7d35c-bbbe-4d15-ac69-54c62d0e6e07/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：澳大利亚昆士兰大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：对大规模多媒体内容理解、索引和检索做出贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;黄教授是澳大利亚昆士兰大学电子工程与计算机科学学院的数据科学学科负责人。她分别于 2001 年和 2007 年获得清华大学计算机科学学士学位和昆士兰大学计算机科学博士学位。她的研究领域主要包括多媒体索引与搜索、计算机视觉、推荐系统、社交数据分析。她在国际顶级学术会议和期刊上发表了 200 多篇论文，并担任《VLDB Journal》、《ACM Computing Surveys》等期刊的副主编，同时也是 VLDB 基金会董事会成员。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;贾佳亚（Jiaya Jia）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadmu6Mr2bRUbFUnEcJiaoNlibTQyuaMg822UJluufxXN0qGVp0Nm4gTAYQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.2328767123287672" data-type="png" data-w="292" data-width="292" data-height="360" data-imgfileid="503529589" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/53f9daae-0657-4a8e-8061-5e2fd148f442/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：香港科技大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：表彰其在计算机视觉领域的图像分割、场景解析和纹理分析方面做出的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;贾佳亚，思谋科技创始人、董事长，香港科技大学讲座教授（Chair Professor）、冯诺依曼研究院院长、IEEE Fellow，计算机视觉、人工智能与计算机影像学等领域顶尖专家。其研究方向聚焦于计算机视觉、语言与深度学习技术的前沿发展，包括图像与视频推理、视觉语言模型（VLM）、多模态 AI 以及生成式方法等。截至目前，其论文在 Google Scholar 上被引用超过 10 万次。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;贾小华（Xiaohua Jia）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiad7AcibfY2g51xQiaoiaibujjhpHleDl0IVjGP9xrTZEJOpyI0W6CTbyElkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.0987124463519313" data-type="png" data-w="233" data-width="233" data-height="256" data-imgfileid="503529590" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/69cefb76-05b0-46fa-9af2-b4ced8a81dab/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：香港城市大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：表彰其在数据安全和分布式计算系统领域做出的杰出贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;贾小华，香港城市大学讲座教授，ACM Fellow, IEEE Fellow。主要研究方向包括数据隐私与安全、区块链技术，以及云计算、分布式系统、网络与移动计算等方向。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;金海（Hai Jin）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadXDY21juEPZJeMzrLuED4Gg0GwUPBWfl4huia7VD52Nka14F9Mmq0Rzg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.7466666666666667" data-type="png" data-w="900" data-width="900" data-height="672" data-imgfileid="503529591" data-aistatus="1" data-original-style="width: 339px;height: 253px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/23a6da5c-3f65-4c45-847e-51c2b587f15e/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：华中科技大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在高效的数据中心处理、内存管理以及分布式系统架构方面做出的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;金海，电气与电子工程师协会会士，中国计算机学会会士，华中科技大学教授、博士生导师、硕士生导师。主要研究方向为计算机体系结构、并行与分布式处理、虚拟化技术与云计算、大数据、网络安全等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;马坚（Jian Ma）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="333" data-imgfileid="503529592" data-ratio="0.6673346693386774" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadA1k5fE3SgKbbVToe4kwc3Gx6a8TibUMXjr9A8QMvPB8ZicaDmtQibd4Pw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="499" data-width="499" data-original-style="width:319px;height:213px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/63fd49b4-1d3b-4cdd-9b79-791dae39d2b4/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：卡内基梅隆大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在计算生物学算法和机器学习方面的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;马坚现任卡内基梅隆大学计算机科学学院计算生物学教授，同时也是机器学习方向的兼职教授。他曾于 1996-2000 年在复旦大学就读本科，于 2000 年毕业于复旦大学计算机科学技术学院软件专业，并于 2003 年获得硕士学位 (导师为张亮教授)。2003 年赴美留学，2006 年从美国宾夕法尼亚州立大学获得计算机科学博士学位 (导师为计算生物学先驱 Webb Miller)。马坚曾获得过多个奖项，其中包括 2011 年美国国家科学基金会 CAREER 奖和 2020 年古根海姆奖 (Guggenheim Fellowship; 计算机科学领域)，并在 2022 年被选为美国医学与生物工程院 (American Institute for Medical and Biological Engineering) 会士。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;梅涛（Tao Mei）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadStQJEQyyZtDiaR48kYd9aj0dkbtdZJslgAibrmR2VicKAFXAkHjblZwBA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="1" data-type="png" data-w="500" data-width="500" data-height="500" data-imgfileid="503529593" data-aistatus="1" data-original-style="width: 289px;height: 289px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/84744512-2104-4401-a9de-e248aadf58f2/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：HiDream.ai（智象未来）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在多媒体分析、检索及应用方面的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;梅涛是人工智能与计算机视觉领域的全球知名学者，现任智象未来（HiDream.ai）创始人兼首席执行官。他拥有中国科学技术大学工学学士和博士学位，曾任京东集团副总裁、微软研究院资深研究员，在多媒体分析与视觉计算领域发表过 200 余篇学术论文。截至 2022 年，他已获得加拿大工程院外籍院士、IEEE Fellow、IAPR Fellow 等多项国际学术荣誉。其创立的智象未来聚焦生成式 AI 技术研发与应用创新。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;陈建利（Kian-Lee Tan）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadrd5bsk8G7eCSeeMWTxx582kCXicwpINvcq1j0ZqzCRicvoAuD00RdmQg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="1" data-type="png" data-w="300" data-width="300" data-height="300" data-imgfileid="503529594" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/af208dbe-b548-40f0-a3f3-78d676fa60b8/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：新加坡国立大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在高级数据库应用的查询优化与处理方面的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;陈建利（Kian-Lee Tan）是新加坡国立大学计算机学院计算机科学教授，1994 年获新加坡国立大学计算机科学博士学位，研究方向主要包括多处理器与分布式系统中的查询处理与优化、数据库性能、数据分析以及数据库安全。他在国际期刊与顶级会议发表论文 300 余篇，并合著多部数据库领域著作与专著，长期在数据库研究与学术组织中发挥重要影响力。陈建利曾获得 NUS 杰出研究者奖、优秀导师奖、新加坡总统科学奖及 IEEE 技术成就奖，担任过 VLDB Journal 主编、ACM TODS 与 WWW Journal 副编辑，以及多个国际顶级数据库会议的程序委员会主席，是 ACM 与 IEEE 会员。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;童行行（Hanghang Tong）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadiaiaOiclmrGoHkYBYJZVbpq5iaia2WicNCZGzupDyyvfYJ3zBeg3PZagL6pQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="1.00418410041841" data-type="png" data-w="239" data-width="239" data-height="240" data-imgfileid="503529595" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/11472674-b392-4402-ba0b-19480de96f27/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：伊利诺伊大学厄巴纳 - 香槟分校&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因对大规模图挖掘理论、算法和应用的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;童行行教授是伊利诺伊大学厄巴纳香槟分校计算机科学系教授兼 University Scholar，负责 IDEA Lab@UIUC。其研究聚焦于大规模数据挖掘、机器学习与人工智能，重点关注图数据与多媒体数据的方法与系统，并将相关技术广泛应用于社交网络分析、医疗健康、网络安全、信息物理系统、农业以及电子商务等领域，致力于从复杂真实数据中发现结构性规律并推动跨领域智能应用的发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;熊辉 (Hui Xiong)&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadicJE1K7bh9fmLyczgjefqNSBzgNFEQI14rgjibM8UVcHnSD61BGiaaZtA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.25" data-type="png" data-w="1080" data-width="2400" data-height="3000" data-imgfileid="503529596" data-aistatus="1" data-original-style="width: 230px;height: 287px;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/71011684-3844-42d3-9b79-4cbfdf689f2d/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：香港科技大学（广州）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在人工智能和移动计算领域研究方面做出的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;熊辉，现为香港科技大学（广州）协理副校长，人工智能学域讲座教授（Chair Professor）。长期从事数据挖掘与人工智能方面的科研工作，在 Nature Communications、TKDE、TOIS、KDD、VLDB、AAAI、IJCAI、NeurIPS 等国际顶级期刊和会议上发表论文 400 余篇。熊辉教授曾任美国罗格斯 - 新泽西州立大学杰出终身教授及百度研究院副院长，并主管 5 个实验室。他获得的部分荣誉包括 AAAS Fellow，AAAI Fellow, IEEE Fellow，ACM 杰出科学家，中国人工智能学会会士，中国教育部长江讲座教授，中国国家基金委海外杰青 B 类（海外及港澳学者合作研究基金），哈佛商业评论 2018 年 &amp;ldquo;拉姆。查兰管理实践奖&amp;rdquo;- 全场大奖，2017 IEEE ICDM Outstanding Service Award，ICDM-2011 最佳研究论文奖，和 AAAI-2021 最佳论文奖等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Li Xiong&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadufYSPXQtBb34yKQuUvAibiavWlibDPLZlicLOvfUHob41YfO9GLCGLoHDg/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="1.363888888888889" data-type="png" data-w="1080" data-width="1340" data-height="1828" data-imgfileid="503529597" data-aistatus="1" data-original-style="width: 248px;height: 338px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/7bfcce11-47d8-4729-8042-a8956dd29488/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：埃默里大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在编程语言静态类型系统和机械化数学方面的贡献而获奖。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Li Xiong 是埃默里大学计算机科学和生物医学信息学教授，Samuel Candler Dobbs 讲席教授。她曾在 2015 年至 2018 年担任温希普杰出研究教授。她拥有佐治亚理工学院博士学位、约翰・霍普金斯大学硕士学位以及中国科学技术大学学士学位。她的研究实验室 &amp;ldquo;可信信息管理与共享&amp;rdquo;（AIMS）致力于研究适用于医疗保健、公共卫生和空间智能的可信且增强隐私的人工智能解决方案。她因在隐私保护和数据安全共享与分析方面的贡献，被评选为 IEEE 会士（2022 年）和 AAAS 会士（2024 年）。她已发表 200 多篇论文，并获得七项最佳论文奖或提名奖。她的研究获得了政府和产业界 / 基金会（如 NSF、NIH、IARPA、AFOSR、PCORI、三菱、思科、AT&amp;amp;T、&lt;/p&gt;&lt;p&gt;&lt;strong&gt;杨俊峰（Junfeng Yang）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadJyxoS6rlaL6ChvlNuwRYYJRar8H4koWicpH7H48Rd4HicicWAjYgicfbKA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=17" data-ratio="0.6675" data-type="jpeg" data-w="800" data-width="800" data-height="534" data-imgfileid="503529598" data-aistatus="1" data-original-style="width: 306px;height: 204px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/d5b6d890-4b05-4a35-a5ae-105849bad1ce/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：哥伦比亚大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因其在可信软件和人工智能系统方面的领导力和贡献而获奖。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;杨俊峰是哥伦比亚大学计算机科学教授，也是哥伦比亚大学的衍生公司 NimbleDroid（位于纽约市）的联合创始人兼首席执行官，该公司致力于发明前沿工具，重新定义开发者打造出色应用的方式。此前，他曾在微软担任顾问和研究员，并在斯坦福大学获得计算机科学博士学位。十多年来，他一直致力于开发高性能、可靠且安全的软件。他发明的多种技术、算法和工具已被广泛应用于分析、测试、调试、监控和优化现实世界中的软件系统，包括 Android、Linux 以及微软和 VMware 的生产系统，惠及数亿用户。他的研究成果曾被《ACM 通讯》和《The Register》等媒体报道，并荣获谷歌教师研究奖、斯隆研究奖学金、美国空军科学研究办公室青年研究者奖以及美国国家科学基金会职业奖等奖项。他在众多顶级系统、安全、编程语言和软件工程会议上发表过论文并担任审稿人。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;易珂（Ke Yi）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadw7ib2mk3PwibnTics91YiaoKOia1soxPCFxxJPctxAwoAe9V1G2ib2D3CmwQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="1.46" data-type="png" data-w="300" data-width="300" data-height="438" data-imgfileid="503529599" data-aistatus="1" data-original-style="width: 243px;height: 355px;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/0114bc78-8e51-4876-a506-ac9d7b22cb28/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：香港科技大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在查询处理理论与实践方面的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;易珂（Ke Yi）是香港科技大学计算机科学与工程系教授，大数据技术理学硕士项目主任，研究方向涵盖数据库理论与系统、查询处理、数据安全与隐私、并行与分布式算法、采样与数据摘要、数据流、数据结构、外存算法与计算几何，其研究核心在于打通理论与实践的深度联系，致力于设计兼具严格理论保证与优秀实际性能的简洁算法，并强调能够指导工程实践的理论洞见。在理论研究基础上，其团队开发了多项系统原型，包括基于 Yannakakis+ 的查询重写优化器 Quorion、差分隐私 SQL 引擎 DPSQL、基于 GHD 与最坏情况最优连接算法的 SparkSQL+、安全 Yannakakis 算法驱动的双方安全查询系统 SecYan、Flink 上的连续查询与变更传播系统 CROWN 与 Cquirrel，以及基于 Wander Join 的 PostgreSQL 在线聚合系统 XDB。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;郑宇（Yu Zheng）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadmsOuEQ8TXFFQkcOmxiarPA8gTcP8Pk0uWCicibdeibAuibgDV8qiaMWIerCg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="1" data-type="png" data-w="845" data-width="845" data-height="845" data-imgfileid="503529600" data-aistatus="1" data-original-style="width: 299px;height: 299px;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/5ee74c31-0064-431b-9fe4-dd9d2efa762f/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：京东&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在时空数据挖掘和城市计算领域的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;郑宇（Yu Zheng）博士是京东集团副总裁，负责京东智能城市业务与研究，并担任京东科技首席数据科学家，长期致力于以大数据与人工智能技术解决复杂城市问题，研究方向涵盖大数据分析、时空数据挖掘、机器学习与人工智能。他曾任微软研究院高级研究经理，现为上海交通大学讲席教授、香港科技大学兼任教授，曾担任 ACM TIST 主编及多项国际期刊与学术组织重要职务，是 SIGKDD 中国分会主席。他在 KDD、IJCAI、AAAI、VLDB 等顶级会议和期刊发表大量高被引论文，总引用逾 6.2 万次，多次获得 SIGKDD、ACM SIGSPATIAL、IEEE MDM 等领域重大奖项，并广受国际会议与顶尖高校邀请作报告。其著作《Computing with Spatial Trajectories》与《Urban Computing》奠定了城市计算领域的学科基础；其技术成果拥有百余项专利，并在微软、京东及中国多个城市实现规模化落地应用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;朱军（Jun Zhu）&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8uYMdNaRAc4S0K5BxQVoiadLMpjxsnTiaW1Pgm3FLhG5Vvganiam0iaog6rTXmia5azLAaOrpUNIE5VlQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="1.271523178807947" data-type="png" data-w="302" data-width="302" data-height="384" data-imgfileid="503529601" data-aistatus="1" data-original-style="width: 249px;height: 317px;" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/361f1987-a8a2-4d4d-84a7-f569a2520688/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;机构：清华大学&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;入选理由：因在概率机器学习的理论和方法方面所做的贡献。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;朱军现任清华大学计算机系正教授、博士生导师，研究工作围绕机器学习基础理论、高效算法和应用展开，注重理论与实际问题结合。针对复杂数据隐含结构的学习与利用中的共性问题，研究了结构学习及基于结构的统计学习中若干关键问题，提出：（1）最大熵判别式学习的 PAC-Bayes 理论与方法；（2）正则化贝叶斯推理及正则化非参数贝叶斯推理理论；（3）贝叶斯模型的最大间隔学习理论与高效算法；（4）&amp;ldquo;珠算&amp;rdquo; 概率编程库等。针对互联网数据挖掘、社交网络分析、多模态数据融合、网络推荐等多个典型应用场景，将基础理论与实际问题结合，提出有效的计算模型和算法，申请 / 授权发明专利 17 项，含 3 项美国专利，研究成果已应用到微软的多个搜索引擎，包括人立方关系搜索引擎和学术搜索引擎等。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://www.acm.org/media-center/2026/january/fellows-2025&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>第二届CVPR 2026 CV4CHL Workshop征稿启动，用AI大模型守护儿童未来</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Thu, 22 Jan 2026 11:21:42 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-22</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-22</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474618" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/2c0fc60a-1ea0-4fb4-87dd-104f4b7add31/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;近年来，随着多模态大语言模型、具身人工智能等技术飞速发展，大多数应用已落地在人们生活的方方面面，但是针对儿童发育、健康和教育的相关人工智能和计算机视觉技术尚处于起步阶段。&lt;/p&gt;&lt;p&gt;CV4CHL (Workshop on Computer Vision for Children) ，传承自 ICLR 2025 首届 Workshop on AI for Children (AI4CHL)，由北美首家儿科人工智能初创公司 PediaMed AI (儿医智能) 联合伊利诺伊大学厄巴纳 - 香槟分校、香港科技大学（广州）、苏黎世联邦理工学院、深圳儿童医院等知名高校和研究所在 CVPR 2026 期间承办，目标是进一步汇集面向儿童及儿科 AI 和计算机视觉解决方案的多维度学科观点，填补该领域的关键空白。&lt;/p&gt;&lt;p&gt;本研讨会致力于搭建一个跨学科的桥梁，汇聚计算机视觉研究员、大模型技术专家、儿科医生、心理学家、教育家，共同探讨前沿计算机视觉和 AI 技术在儿童应用场景的创新应用与伦理挑战。&lt;/p&gt;&lt;p&gt;研讨会将包括多个主题演讲，期间儿医智能也将发布相关儿科 AI 产品，并联合伊利诺伊大学厄巴纳 - 香槟分校组织儿童人工智能未来方向的圆桌讨论，联合深圳儿童医院组织首届儿童步态分析挑战赛。挑战赛的日程安排将会在研讨会官方网站上更新。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;核心议题包括但不限于:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;受人类儿童时期学习能力，认知能力启发的基础模型、多模态大语言模型前沿研究&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;面向儿童的脑机接口技术&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;增强现实眼镜、智能眼镜与儿童的人机交互前沿研究&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;具身人工智能的儿童及儿科应用&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;儿童发育认知建模相关的计算机视觉和基础模型、例如凝视、手势分析&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;儿科智慧医疗，包括疾病早期筛查、医学影像与视频分析等&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 赋能教育，包括智能教育工具与特殊需求儿童辅助技术等&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 支持儿童、青少年心理健康&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;儿童人工智能技术的伦理与社会影响，涉及儿童隐私保护、社交机器人与人机交互等&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;时间与地点：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;投稿截止日期：2026 年 3 月 31 日&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;审稿结果通知日期：2026 年 4 月 8 日&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Workshop 时间：2026 年 6 月 3 日 - 6 月 7 日（具体日期待定）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;地点：美国科罗拉多州丹佛 (Denver, Colorado, USA)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;投稿规则：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本次投稿设 Proceeding 及 Non-proceeding (Abstract) 投稿赛道，将在 OpenReview 平台进行进行双盲审稿。Proceeding 赛道投稿正文限制为 8 页以内，参考文献和补充材料篇幅不限，论文将收录于 CVPR 2026 Workshop Proceeding，Non-proceeding 赛道非存档，作者可以在该赛道投稿已发表或者在审稿中的工作，投稿正文限制为 4 页以内，参考文献和补充材料篇幅不限，Non-proceeding 赛道的正文在研讨会后不会公开。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;投稿格式和模板遵循 CVPR 2026 官方投稿指南：https://cvpr.thecvf.com/Conferences/2026/CallForPapers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;CV4CHL 投稿网站：https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop/CV4CHL &amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;无论您是致力于前沿人工智能算法的研究者，还是关注儿童发育成长的行业专家，CV4CHL 都是您展示成果、激发灵感、参与讨论的最佳平台。诚邀投稿，共同用人工智能和计算机视觉技术点亮儿童的未来！&lt;/p&gt;&lt;p&gt;了解更多与投稿：https://pediamedai.com/cv4chl/&lt;/p&gt;&lt;p&gt;本研讨会由 PediaMed AI、UIUC HCESC、机器之心进行赞助，也欢迎更多企业加入，我们将在研讨会期间设置赞助商展位，详情请联系：xucao@pediamed.ai&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529439" data-ratio="2.1307779030439686" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKeL83xcMX5hfhpgAC7Ytha2ibPDSgjichKqGhXueNB55Kj9mrMibtHiaRpg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="887" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/80ce2653-b438-48e1-8862-a624ebe331f6/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>京东「再造」京东</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 18:14:22 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜微胖&lt;/section&gt;&lt;p data-pm-slice="0 0 []"&gt;&lt;strong&gt;这，很不京东&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要不是 App Logo 上那只举着魔法棒的小狗先「剧透」，你很难把它和京东联系在一起。&lt;/p&gt;&lt;p&gt;点开「京东AI 购」，反直觉几乎是瞬间发生。没有信息洪流扑面而来，也看不到叠床架屋的功能入口，页面干净到几乎只剩一个对话框。&lt;/p&gt;&lt;p&gt;等等，这不是个聊天 App？这真是用来「买东西」的地方？&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287" style="width: 59.4686%;"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="525" data-backw="266" data-imgfileid="503529354" data-ratio="1.9703703703703703" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKKY3nkSYfwbW0enDkCzficAMUD7iah13UlZsHxxWb85qib2tqXFENtrbEA/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=1" data-type="jpeg" data-w="1080" type="inline" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/50ccab7e-acd1-4a57-a248-f151c3f81cd2/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 56.64%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287" style="width: 40.4469%;"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKZo3wdrvLmCUiaVEyw8TwmYicq7nVeKOMickLlsHKRxpCqbcZunOibz5Qhw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="2.175" data-s="300,640" data-type="png" data-w="640" type="inline" data-backw="266" data-backh="579" data-imgfileid="503529386" data-aistatus="1" data-original-style="width:100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/db070d12-fe31-4699-97da-270e026857f3/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 主站 VS 新App页面设计，完全是两个世界。&lt;/sup&gt;&lt;/p&gt;&lt;p data-pm-slice="2 2 []"&gt;它不像一个电商 App，更不像那个你已经用了很多的京东，总是强调效率、审美多少有点「直男」的货架工具。&lt;/p&gt;&lt;p&gt;更出人意料的是，它还不是个「闷葫芦」。我还没开口，它先「说话」了。&lt;/p&gt;&lt;p&gt;页面上方弹出一句很有「活人感」的招呼。接着，「橱窗」一样的卡片提醒我，前两天买的丙烯颜料到了，还顺手附上一份使用指南。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="945" data-backw="578" data-imgfileid="503529388" data-ratio="1.6342592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK9sRaj7ibJcuBV3NIvjvFCqeAYB1hWrYDnwnib8aoXBnFDxpsfDpVozhA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" type="block" data-original-style="width:175px;height:286px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c8a25386-b1f9-4c79-8b89-01126f1ddbdc/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;那一刻的感觉，更像是一个已经和你混熟的助理，提前一步意识到：你现在，可能正需要这些。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/54c868f8-33e7-4cc2-aaa5-59cc087a9069/1768990095047.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;section&gt;&lt;span data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKSSPWgpWKl1VGQ7MBevBzPRStAria64DWgZwpcO3kdEdYcLND0mmuSVg%2F0%3Fwx_fmt%3Djpeg" data-mpvid="wxv_4351647101554900996" data-ratio="0.46272493573264784" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;auto=0&amp;vid=wxv_4351647101554900996" data-vh="495.75" data-vidtype="2" data-vw="661" data-w="1080" height="508" scrolling="no" width="661"&gt;&lt;div data-key="wxv_4351647101554900996"&gt;&lt;div data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5="" data-v-db5bdc2b=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;div data-v-6b6a00a5=""&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 点开卡片会自动生成一份基础指南，还有同类产品推荐。&lt;/sup&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;直到上手用过几次之后，我才意识到一个更大的变化正在发生。生活服务这件事，正在被压缩成一句话。&lt;/p&gt;&lt;p&gt;比如，「一句话，决策完成」。直接抛出需求：「小学生月底去鄱阳湖观鸟，作为观鸟新手，需要准备哪些装备？」&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7daedf2b-d26a-40fd-841e-dff4fe86d30d/1768990118956.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 过去需要查攻略、抄清单、逐一比对的过程，被压缩成了一次「直接交卷」。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;系统接住的不是关键词，而是一整个场景，装备被拆解、推理、重新组合成一套「省心方案」：双筒望远镜、防风外套、防蚊用品，甚至连折叠椅、观鸟笔记本和铅笔，都被一并考虑进去。&lt;/p&gt;&lt;p data-pm-slice="2 2 []"&gt;后续「PK」，更能助你完成决策前的「临门一脚」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="795" data-backw="477" data-imgfileid="503529397" data-ratio="1.6666666666666667" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKrHibqFOj6aDibHlEnJGNzwrKPXHiamC2bPop7giaxlUkGb9XibQk14eEC1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="477" type="block" data-original-style="width:159px;height:265px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8fc1258c-af6e-4544-a442-b86fea4ee456/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;还有「一句话，信息到位」。对话框被「焊」在商品页底部，不必再耐着性子把图文介绍从头翻到尾，直接发问该买多大的码、总结用户评价，AI&amp;nbsp;会自动去「抓答案」，把结果整理给你。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/e19d83ad-835c-4674-a1d5-b19ad06e73f0/1768990148777.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 针对你关心的问题，AI 会自动去「抓答案」，再把结果整理好给你。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;而「找优惠」、「试穿」这些用户期待值最高的能力，甚至被设计成常驻入口，紧挨对话框，一「点」即达。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/7488681d-e926-4cb9-9736-0477d5aa5eba/1768990170547.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;每天主站上那么多的优惠，哪些羊毛值得薅？一点即达。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这一刻，我终于意识到那种陌生感从何而来。这种极简设计&amp;mdash;&amp;mdash;一个对话框，甚至只是一个 tag、一个浮窗&amp;mdash;&amp;mdash;正在把原本庞大、厚重的电商世界折叠起来。原本需要被反复「逛」的货架体系，变成了一种「呼之则来、挥之则去」的能力，许多曾经耗时费力的事情，就这样被轻描淡写地完成了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;快思考&amp;nbsp;&amp;times;&amp;nbsp;慢思考：&lt;/strong&gt;&lt;strong&gt;生活服务，又被重新想了一遍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很长一段时间里，电商产品几乎都建立在一个默认前提上：用户是理性的。他们知道自己要买什么，打开 App，搜关键词、看参数、比价格，然后尽快完成下单。&lt;/p&gt;&lt;p&gt;但现实生活，很少这么标准和工整。&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;更多时候，需求本身是模糊、复杂、说不清楚的，你甚至不知道该从哪一步开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;第一次去婆罗洲热带雨林徒步的人，对该准备哪些装备毫无概念；新手爸妈面对即将到来的生活变化，也说不清楚到底要提前备齐什么；想吃点辣的，预算 20 块左右，别太远，一会儿还要开会，但也说不清吃啥。&lt;/p&gt;&lt;p&gt;当一个人还没想明白「要什么」时，传统电商那套以搜索和筛选为核心的机制，反而会变成一种负担&amp;mdash;&amp;mdash;它在挑战人性，要求一个还没想明白的人，先把逻辑捋顺。&lt;/p&gt;&lt;p&gt;在这种情况下，用户几乎不可能直接在传统平台里完成需求。他们往往会先转战内容平台（比如小红书）查攻略、做功课、记清单，把「该买什么」这件事想清楚；再返回电商或外卖平台，一件件搜索、对比、筛选。平台并不真正参与「思考」，而是把最费力的决策过程，完整地甩给了用户。&lt;/p&gt;&lt;p&gt;而&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;「&lt;/span&gt;京东&amp;nbsp;AI&amp;nbsp;购&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"line-height: 1.75em;margin-left: 8px;margin-right: 8px;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;」&lt;/span&gt;，试图接住的这些「说不清」的时刻。&lt;/p&gt;&lt;p&gt;它不再要求用户先把需求想明白再来下单，而是把原本压在用户身上的决策负荷，转移给&amp;nbsp;AI。这正是产品团队反复提到的&lt;strong&gt;慢思考能力&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;通过与 AI 「对话」，那段最「烧脑」的过程，不再发生在用户反复滑动、来回跳转的手指之间，也不再只存在于用户的脑中，而是被系统接管。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503529345" data-ratio="0.47129629629629627" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKicaotR5CiaO7zSrLD4YKtYC6xia0cYu3VznpNHzzx4oZWUKlibemicHpSEQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" type="block" data-original-style="width:392px;height:185px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f741231c-e7c5-4b9f-b90d-85f943028384/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;以「新手登山装备」为例。AI 做的第一件事，不是着急推荐买什么，而是弄清楚你到底想干嘛，确保别出错。&lt;/p&gt;&lt;p&gt;一句模糊的人话，会被拆解成一份「可计算的需求说明书」：新手、不懂行、不求专业进阶、预算有限、希望少踩坑。随后，多 Agent 各司其职、协同工作，从不同侧面反复验证：当前这套判断，是否真的贴合「新手登山」的核心意图。&lt;/p&gt;&lt;p&gt;当各个 Agent 给出结果后，系统会进行整合与排序，原则非常明确&amp;mdash;&amp;mdash;需求是否被满足，永远排在第一位。只有「新手可用」前提成立，系统才会进一步引入个人画像，把更符合习惯的商品往前放。&lt;/p&gt;&lt;p&gt;最后，才轮到商品本身「靠不靠谱」的判断。&lt;/p&gt;&lt;p&gt;AI 会结合京东强大的供应链数据（如实时规格、价格、销量），并从海量真实评价中提炼关键信号，把稳定性高、评价一致性强的商品作为重要加权项。&lt;/p&gt;&lt;p&gt;这些信息不仅影响排序，也会被直接写进推荐理由中。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1d753dce-94db-456b-8b43-8e48d71c074b/1768990200748.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 你得到的是一组数量有限、附带推荐说明的商品卡片。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;最终呈现在你面前的，不再是一个需要自己筛选、无限展开的货架，而是一组数量有限、附带推荐说明的商品卡片。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/5a6c6c11-a520-4272-b9de-7b94f6d21a5e/1768990220191.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp;外卖生活服务也是如此。推荐理由写得清楚，最终呈现的不再是一份「谁更热门」的商家榜单，而是最适合你当下情境的选择。评分和销量依然存在，但不再是第一优先级，而是用来优化结果。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;与此同时，还有另一种&lt;strong&gt;被极度压缩的慢思考形态&lt;/strong&gt;，出现在复购、常购、定期补货等高确定性场景中，比如卫生纸、猫粮猫砂。&lt;/p&gt;&lt;p&gt;在这些场景里，用户对「买什么」几乎没有任何犹豫。但在传统电商中，他们仍然不得不走完整套流程：从打开 App 到最终支付，七八步下来，没有创造什么新价值。&lt;/p&gt;&lt;p&gt;而通过「对话」，这条链路被直接压缩到近乎「自动驾驶 L4」。无论是「上次那杯咖啡，再来一杯」，还是「之前买的那本书，再来一本」，AI 都会自动完成整套需求映射。&lt;/p&gt;&lt;p&gt;调出历史订单、匹配你的口味或品类偏好、默认配送地址，把一张所有信息都已填好的「确认卡片」，直接递到你面前，几乎没有摩擦。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="450" data-backw="266" data-imgfileid="503529338" data-ratio="1.6879629629629629" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKcy8o445VWzjkTHzyvEYXIltmn0333TwXJBLN0YrrrjNqkEdpZJ62Fw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" type="inline" data-original-style="width:100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/85a30da5-4e3c-430c-89ad-8dfc79a52fae/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK5PFusDuPVgxicowruU9vhC4yjYqAUibHQgaezA6HtyR12a5MYAR3OTKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="1.423148148148148" data-s="300,640" data-type="png" data-w="1080" type="inline" data-backw="266" data-backh="379" data-imgfileid="503529339" data-aistatus="1" data-original-style="width:100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/fe9ba6ab-00f3-4815-b7bc-2d6eb7a63135/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;上次那杯咖啡，再来一杯；之前买的那本书，再来一本，AI 都会自动完成整套需求映射。&lt;/sup&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="576" data-backw="266" data-imgfileid="503529340" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKe8OgMMqash7icFwV993nA938jttcoYfb1swSn7eTWawaU2DtIrqBsEg/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=8" data-type="jpeg" data-w="1080" type="inline" data-original-style="width:100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/2f44965f-e50d-4411-8d2d-c63ab7da0ab3/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKc9sXekN8cvoxq5lichs4iciaiavgJv0qNHQIZibG6zsGiawP6t50oZgN3Sdw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.7046296296296297" data-s="300,640" data-type="png" data-w="1080" type="inline" data-backw="266" data-backh="454" data-imgfileid="503529342" data-aistatus="1" data-original-style="width:100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/2a9a0c13-2b97-44d6-a49d-9c4bfd037b3a/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 还能通过自然语言修改订单。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;但如果只强调慢思考，产品同样会走向另一种极端。&lt;/p&gt;&lt;p&gt;更多时候，用户其实处在&lt;strong&gt;快思考&lt;/strong&gt;&lt;strong&gt;状态&lt;/strong&gt;：目标清楚，只是想逛一逛，通过图片和简单对比，迅速做出判断。比如，想买支口红，但不知道「选哪一款」。这种情况下，关键不在于「把问题想清楚」，而是「如何更快搞定」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「爱购」承担的，正是这一侧的「快思考」需求。&lt;/strong&gt;因此，在产品形态上，它依然沿用了熟悉的双列信息流，但底层逻辑，已经换了一套。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="285" data-backw="578" data-imgfileid="503529343" data-ratio="0.4925925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKUJUZicPlxiaxJU4X4XeENRFibXcNRG0iaoTebSwI1EOa6MTRwasUz60Qicg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-type="png" data-w="1080" type="block" data-original-style="width:381px;height:188px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/e583dc5a-d35c-4335-8962-20e6446e6d45/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;传统电商平台里，当你搜索「口红」， 系统会召回尽可能多的相关商品，再按销量、价格、评分等维度排好队，交给你自己去翻。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="1181" data-backw="578" data-imgfileid="503529346" data-ratio="2.0435185185185185" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKs8kMwxyKC4ugUg4FEbibH0o5UoqJA6jRAeHpWyW3eEBqicDZpHaSzXSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-type="png" data-w="1080" type="block" data-original-style="width:177px;height:362px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/8676519a-e403-40dc-a8e4-73c01044ac35/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 京东主站搜索结果的呈现。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但「爱购」 不会把海量口红一次性铺开，它更像一位循循善诱的导购。一方面提供必要的「入门指引」，另一方面替你搭起一套清晰的「选购框架」。&lt;/p&gt;&lt;p&gt;例如，口红会被先拆解成几个方向：哑光雾面、滋润镜面、偏修护。当你点进「哑光雾面」，选择再进一步细化到质地、是否易脱色、适合肤质、品牌以及具体色系。&lt;a href="https://mp.weixin.qq.com/s/euEQ0S_HRKb2JFcqnJSvPQ"&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/f2d343fb-4f07-43b1-a240-ea3b0ef2b174/1768990288390.png" style="width: 700%;" class="fr-fic fr-dib"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span align="" alt="" border="" data-aiimageid="" data-aiimagesource="" data-aistatus="1" data-asynid="" data-backh="" data-backw="" data-before-oversubscription-url="" data-cacheurl="" data-cardimg="" data-copyright="" data-croporisrc="" data-cropselx1="" data-cropselx2="" data-cropsely1="" data-cropsely2="" data-cropx1="" data-cropx2="" data-cropy1="" data-cropy2="" data-fileid="" data-fromlib="" data-galleryid="" data-gallerysupplier="" data-height="" data-imgfileid="503529379" data-imgid="" data-imgqrcoded="" data-oversubscription-url="" data-positionback="" data-ratio="2.1574074074074074" data-remoteid="" data-retry="" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKdkgkLZ2Y8OScbmaicPHHv06WtUj87jcpIuBaLJTndh90WSDd4VUIJhA/640?wx_fmt=gif&amp;from=appmsg" data-type="gif" data-upload="" data-w="216" data-width="" height="" ismap="" sizes="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKdkgkLZ2Y8OScbmaicPHHv06WtUj87jcpIuBaLJTndh90WSDd4VUIJhA/640?wx_fmt=gif&amp;from=appmsg" title="" type="block" usemap="" width=""&gt;&lt;sup&gt;原本需要用户自己总结的筛选维度，被&lt;/sup&gt;&lt;/span&gt;&lt;em&gt;&lt;sup&gt;AI预先摆在了面前，供你边看边点、边问边筛。&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;每一次交互，都会让候选范围再收紧一圈，整个过程像一个不断收口的漏斗，最后「过滤」出最可能被你选中的一小撮。&lt;/p&gt;&lt;p&gt;正是在「一快」、「一慢」无感切换中，「京东 AI 购」最重要的创新渐渐显露&amp;mdash;&amp;mdash;&lt;strong&gt;同一套架构，兼容「快思考」与「慢思考」&lt;/strong&gt;。这并非概念噱头，而是源自对真实购物行为的长期观察，毕竟，没有谁会永远用同一种方式做决定。&lt;/p&gt;&lt;p&gt;通过将京东积累多年的供应链、履约和服务能力，重新组织进一套更贴近人类决策方式的交互逻辑中，「京东 AI 购」试图「兜住」这两种状态。&lt;/p&gt;&lt;p&gt;正是在这里，这个看起来「很不电商」的京东 App，开始真正与旧世界拉开距离。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如影随形的「对话框」：&lt;/strong&gt;&lt;strong&gt;一次低调却关键的交互转向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说，「对快与慢思考的兼容」构成了「京东 AI 购」内核，那么，真正让这种服务「常驻」的，是一个看起来并不起眼的设计：那个始终留在页面底部、几乎和你「形影不离」的对话框。&lt;/p&gt;&lt;p&gt;它的位置甚至有些执拗。无论你是在和 AI 聊天，还是已经点进商品详情页，它都没有消失。它并不提醒你使用，也不主动跳出来打断流程，只是安静地待在那里，等待被召唤。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="731" data-backw="338" data-imgfileid="503529350" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLqNn9ONcmA1YTbLc0GbusHAOR8XLpDE6CwUmkiaU04mQibMQ7RvhGepg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-type="png" data-w="1080" type="block" data-original-style="width:182px;height:394px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/c7734e51-3abd-4aa8-ace8-f368f855df56/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 已经点进商品详情页，对话框都没有消失，而是停在页面下方。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这个设计，源于一个被长期忽视的事实：购物中的疑问，并不会在搜索结束的那一刻消失。当用户真正进入商品详情页，决策成本并未降低，甚至可能进一步上升。&lt;/p&gt;&lt;p&gt;传统的商详页，越来越像一幅绵延长卷：营销图片层层堆叠，参数表绵延不绝，用户评论如同瀑布般倾泻而下。信息已足够完备，但当用户搜索关心的卖点时，比如「面料成分」、「羊绒含量」，却如大海捞针。&lt;/p&gt;&lt;p&gt;现在，这个始终留在页面底部的「对话框」，悄然接管了那些「看不完、看不懂、也不想看」的决策成本。&lt;/p&gt;&lt;p&gt;用户不再需要硬着头皮翻阅漫长的图文，随口说出你关心的问题，AI 便会从漫长「卷轴」中定位答案，整理好后，递到面前。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="1251" data-backw="578" data-imgfileid="503529329" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK1CbuBnup4StEgzkMj53B2sXic9JPPwEAXQrdhDj5ZYINxZjzosHQTnQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-type="png" data-w="1080" type="block" data-original-style="width:192px;height:415px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/28f1840f-ae11-413b-9378-0ec820d886bf/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;也正是在这一刻，你能切实感到技术没有被「炫」，而是真正嵌入生活服务的关键节点。&lt;/p&gt;&lt;p&gt;但这个看似轻巧的设计，并非一蹴而就，而是经历了一段不断推翻重来的过程。&lt;/p&gt;&lt;p&gt;最初，「京东 AI 购」的商详页，几乎直接移植了京东手机网页版。结果，用户一进入购买流程，仿佛被瞬间「踢回」十年前的传统电商界面，AI 好不容易营造出的沉浸感立刻被打断。这种强烈的割裂感，很快让团队自己都无法接受。&lt;/p&gt;&lt;p&gt;于是，他们选择彻底重构链路。但与此同时，京东主站最核心的底层能力又必须被完整保留。换句话说，当你点下「立即购买」的那一刻，后台需要瞬间接管。交易、支付、风控、物流，这套沉淀了数十年的系统必须无缝衔接、稳定运行，容不得半点闪失。&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-aistatus="1" data-backh="576" data-backw="266" data-imgfileid="503529351" data-ratio="2.1638888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKLqNn9ONcmA1YTbLc0GbusHAOR8XLpDE6CwUmkiaU04mQibMQ7RvhGepg/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-type="png" data-w="1080" type="inline" data-original-style="width:100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/11aa1020-70bb-46a2-b030-2eea58f3513f/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;td data-colwidth="287"&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK92MSkh4Zsm4awiakhclmvUP9KjehShndlrFnMdJNiaYsLHLjTf9koX7g/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=15" data-ratio="2.1638888888888888" data-s="300,640" data-type="jpeg" data-w="1080" type="inline" data-backw="266" data-backh="576" data-imgfileid="503529349" data-aistatus="1" data-original-style="width:100%;" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/eda954fb-4a83-453b-a559-2483dc46af37/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sup&gt;商品页面也做了减法（左图），还有PK功能，对话框保留在底部。它没有复刻主站那种信息密集的设计（右图）。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;真正决定把对话框「焊」在商品页底部的转折点，来自一个被反复观察到的心理事实：用户对 AI 的依赖，并不会在进入商品页时减弱，反而会因为参数复杂、信息密集而变得更强。传统商详页越像层层堆叠的「信息仓库」，用户就越容易陷入搜索与决策泥潭。&lt;/p&gt;&lt;p&gt;于是，「对话框」被赋予新的使命：替你读图、刷评论、抓重点，不再「问完即走」，而是随时待命：只要你还有犹豫，它就在那里。&lt;/p&gt;&lt;p&gt;而这仍然不是终点。产品负责人透露，团队接下来希望把这种理解能力进一步推向「生成式商详」。原本冰冷的参数表和评论区，将被重新组织为「千人千面」的动态答案：你关心优惠，它就把价格逻辑讲清楚；你在意参数，它就直接给出对比结论。&lt;/p&gt;&lt;p&gt;这一过程中，电商的交互逻辑也正在发生根本转向，从过去用户去适应页面，逐渐演进为页面主动适应用户。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;购物里的分寸：一场取与舍的练习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一家以效率、规模著称的电商巨头，却做了一个如此克制、安静的产品，还让它独立出来，怎么看，都是一场激进的尝试。&lt;/p&gt;&lt;p&gt;但放进真实的产品演进过程中，它反而更像一件被有心「按住」的作品：不是 AI 能做什么就一股脑地做什么，而是不断试探什么时候让 AI 大步流星、哪些地方必须保持敬畏。&lt;/p&gt;&lt;p&gt;这种分寸感，让它避开了炫技式的跃进，更像一个被设计为长期存在的产品：接受不完美，拒绝过度承诺，慢慢生长。&lt;/p&gt;&lt;p&gt;「大胆」与「克制」的切换，始终围绕着用户需求。产品团队告诉我们，所有向前一步的决定，都必须回答这个需求是否真实、迫切。&lt;/p&gt;&lt;p&gt;商详页面的设计如此，外卖与酒旅的生态接入也是如此。乍看之下，这些生活服务像是边界外扩，实则顺应了真实生活逻辑。现实生活中，人们并不会严格区分「这是购物 App 的事」、「那是生活服务 App 的事」。他们只关心，现在这个问题，能不能被更聪明地解决。&lt;/p&gt;&lt;p&gt;同样的判断，也体现在低客单价、强复购的场景中。「买不买」不是问题，真正消耗心力的，是那些机械重复却并不产生新价值的步骤。AI 的主动介入，本质上是对低效劳动的「清算」。&lt;/p&gt;&lt;p&gt;将 PK 能力单独「拎出来」，无非是将大多数用户购物时的必经之路显性化，并不是增加复杂度，而是替他消化低效劳动。&lt;/p&gt;&lt;p&gt;AI 大步流星的同时，即便身处对话式 AI 的浪潮，服务流程也并未全盘「 AI 化」。&lt;/p&gt;&lt;p&gt;搜索、咨询、决策阶段，可以是对话式的。一旦进入下单环节，交易体验必须和原生京东 App 保持一致，结算、地址与履约阶段，系统必须切回京东主站底层。&lt;/p&gt;&lt;p&gt;这种对「原生链路」的保留，本质上是对交易确定性的敬畏。产品团队解释说，当用户进入下单环节，他们需要的是熟悉感带来的安全感，而非 AI 创造的「惊喜」。&lt;/p&gt;&lt;p&gt;同样被有意剔除的，还有「内容化」的冲动。长篇种草、新闻播报、数字人展示&amp;mdash;&amp;mdash;这些本可以用来彰显技术能力的功能，最终都被放弃。过载的内容会稀释产品的纯度，也会模糊核心心智。用户来到这里，是为了在信息洪流中快速做出决策，而非陷入另一场需要消化的信息冗余。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「独立」的背后：一次主动「偏航」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果把时间尺度拉长，回看电商二十多年的演进路径，这场貌似主动的「偏航」，其实并不突兀。&lt;/p&gt;&lt;p&gt;京东几乎完整经历了&amp;nbsp;PC&amp;nbsp;时代、移动互联网时代，再到今天的每一个关键阶段。早期，电商解决的是供给问题，有没有货。接着是效率问题，能不能更快、更便宜地把货送到人面前。当供给极大丰富、履约成熟、价格高度透明之后，真正开始变得稀缺的，反而是&lt;strong&gt;决策本身&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;用户不再缺选项，缺的是判断；不再缺信息，缺的是「替我想一想」，「京东AI 购」更像是下一阶段的自然延伸：当平台已经足够擅长「把东西卖出去」，下一步就要回到人的决策上。&lt;/p&gt;&lt;p&gt;而在 2025 年，无论从技术进展还是用户心智变化来看，这件事都具备了现实可行性。&lt;/p&gt;&lt;p&gt;在技术层面，ReAct、多 Agent 等架构逐渐成熟，AI 开始具备被纳入决策、履约链条的条件，而不再局限于聊天。用户心智也在变化。「你帮我选」，不再只是信息过载下的被动妥协，而开始成为一种真实、甚至被主动期待的需求。&lt;/p&gt;&lt;p&gt;但即便如此，另一个问题仍然存在：为什么不直接把这套能力塞进主站 App？为什么要让用户多下一个软件？答案，还是要回到主站本身。&lt;/p&gt;&lt;p&gt;主站也有丰富的 AI 应用，但传统电商 App 天然背负着明确的 GMV 目标，也承载着高度复杂、密集的促销与转化逻辑。在这样的体系中，几乎不可能进行一场彻底的「减法」实验。而独立 App，提供了一块相对纯净的试验空间。&lt;/p&gt;&lt;p&gt;它更像一个先锋验证场，目标并不是短期的转化效率，而是验证一种新的用户心智模型：当电商从「货架」转向「代理人」，产品究竟应该长成什么样？这个问题，很难在主战场上被从容回答。&lt;/p&gt;&lt;p&gt;但是，独立并不意味着另起炉灶，更不是与主站「互搏」。前台交互是新的，但后台能力依然共用。供应链、交易系统、支付、履约、风控，全部来自京东已经成熟运转的基础设施。&lt;/p&gt;&lt;p&gt;如果一定要做一个比喻，主站更像一座稳定运行的「超级超市」，而 AI 购，更接近一间探索未来形态的「概念旗舰店」。它不承担规模化的压力，被允许试错、调整和打磨。&lt;/p&gt;&lt;p&gt;从这个意义上看，「独立」不是目的，而是为下一代电商形态，预留的一条试飞跑道。&lt;/p&gt;&lt;p&gt;在理解人类那些尚未成形的需求、拆解规模庞大而结构复杂的商品世界、以及捕捉不断变化的生活情境方面，这只举着魔法棒的小狗，才刚刚起步。它当然谈不上成熟，也远未完美，但它所指向的方向，却异常笃定，值得手机为它预留一方天地，让未来发生。&lt;/p&gt;&lt;p&gt;此刻，距离大年三十还有 20 多天。也许，你可以从一件再日常不过的小事开始：对它说出你的马年心愿。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>非Transformer架构的新突破，液态神经网络的推理小模型只用900M内存</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Wed, 21 Jan 2026 18:02:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-21-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-21-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;编辑｜冷猫&lt;/section&gt;&lt;p&gt;谷歌 2017 年提出的 Transformer 架构事实上已经基本垄断了大模型。&lt;/p&gt;&lt;p&gt;不采用 Transformer 架构的大模型已经是少之又少，而采用非 Transformer 架构，还能与主流第一梯队大模型扳手腕的，更是凤毛麟角。&lt;/p&gt;&lt;p&gt;不知道大家是否还有印象，当年有一个尝试&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650936710&amp;idx=1&amp;sn=dbbd17956166684cee4eb73e75e41111&amp;scene=21#wechat_redirect" target="_blank"&gt;给大模型装上「虫脑」&lt;/a&gt;的初创公司，他们的研究人员受到秀丽隐杆线虫的神经结构启发，研发出一种新型的灵活神经网络，也被称为液态神经网络。&lt;/p&gt;&lt;p&gt;这是一个连续时间模型，由多个简单的动态系统组成，这些系统通过非线性门相互调节。这种网络的特点是时间常数可变，输出通过求解微分方程得到。它在稳定性、表达能力和时间序列预测方面都优于传统模型。&lt;/p&gt;&lt;p&gt;除此以外，液态神经网络的另一个特点是规模小得多，在 2024 年该架构就实现了 1.3B 大小的模型部署，但彼时尚未能与主流大模型一拼高下。&lt;/p&gt;&lt;p&gt;提出液态神经网络架构，并且做出 Liquid Foundation Models（LFM）大模型的，是由 MIT 计算机科学和人工智能实验室 CSAIL 孵化，成立于 2023 年 3 月的初创公司 Liquid AI。&lt;/p&gt;&lt;p&gt;就在刚刚，Liquid AI 又一次在 LFM 模型上放大招。他们&lt;strong&gt;正式发布并开源了 LFM2.5-1.2B-Thinking，一款可完全在端侧运行的推理模型&lt;/strong&gt;。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="530" data-imgfileid="503529358" data-ratio="0.45555555555555555" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKSFMicjhbqKfic9e7qSGbKRnichml5FxAujRzQYPIeMmdJtbt1VpcCYVTA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" data-width="1164" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/8624f5ba-fea2-4758-8c9f-54af2bc1b0be/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;Liquid AI 声称，该模型专门为简洁推理而训练；在生成最终答案前，会先生成内部思考轨迹；在端侧级别的低延迟条件下，实现系统化的问题求解；在工具使用、数学推理和指令遵循方面表现尤为出色。&lt;/p&gt;&lt;p&gt;该模型在手机上&lt;strong&gt;仅需 900 MB 内存&lt;/strong&gt; 即可运行，同时在同等规模模型中实现了最快的推理速度和最佳的质量表现。两年前还必须依赖数据中心才能完成的能力，如今已经可以在你的口袋里离线运行。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKt16y1f4bm1YVbsf8drCg3gAAlyDSCfQG1DPW5mGibEPKPnd4zg6NCsw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.39198218262806234" data-type="png" data-w="898" data-width="898" data-height="352" data-imgfileid="503529359" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/a3055c94-f916-4d38-9016-5fe370f21d44/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Leap 开源链接：https://leap.liquid.ai/models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;HuggingFace 链接：https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;优于 Transformer 的性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与 Liquid AI 之前的模型 LFM2.5-1.2B-Instruct 相比，LFM2.5-1.2B-Thinking 在三项能力上实现了显著提升：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数学推理&lt;/strong&gt;：在 MATH-500 上从 63 提升至 88&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;指令遵循&lt;/strong&gt;：在 Multi-IF 上从 61 提升至 69&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;工具使用&lt;/strong&gt;：在 BFCLv3 上从 49 提升至 57&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在大多数推理基准测试中，LFM2.5-1.2B-Thinking 的表现已与甚至超过 Qwen3-1.7B，尽管其参数量少了 约 40%。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKYx3MymNrJwkuicibsASD4dDABSRaqoLeiacAibXTZJNzPYic3Xf4BbQjKbQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.7037037037037037" data-type="png" data-w="1080" data-width="1896" data-height="1334" data-imgfileid="503529360" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d82ef211-575f-41dc-a190-e2d3108fdce2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKvapL2VTsMOUFmQ0qCic5ibazboRMKtWxZlfbRky0Aiaib5Iicr7uHx142FQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5814814814814815" data-type="png" data-w="1080" data-width="1550" data-height="902" data-imgfileid="503529361" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/e4bb71c8-b328-4f0b-9d08-2931b73c9b10/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;同时，该模型在质量与测试时计算效率之间取得了良好平衡：与 Qwen3-1.7B（思考模式） 相比，它在使用更少输出 token 的情况下，依然提供了更高的整体性能。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKy9xY8cBw0SSuVbe6Lu7WMTP3qHUnDR89HNplacMxHULlVt32E4CcGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.42685185185185187" data-type="png" data-w="1080" data-width="2844" data-height="1215" data-imgfileid="503529362" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/bca0075c-60bd-492a-98f6-30d573ec0708/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在推理阶段，这一性能差距进一步拉大：LFM2.5-1.2B-Thinking 在推理速度和内存效率两方面，都&lt;strong&gt;优于纯 Transformer 模型&lt;/strong&gt;（如 Qwen3-1.7B）&lt;strong&gt;和混合架构模型&lt;/strong&gt;（如 Granite-4.0-H-1B）。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMK3JKPebJia17Dk4v1Zvlu2OzC5ibgd1Sd6T21ribykLIfwBZ3WhxlbNnSQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.7037037037037037" data-type="png" data-w="1080" data-width="2844" data-height="2001" data-imgfileid="503529363" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/01f0b7db-24b9-44fe-a420-f83f219ada0b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;Liquid AI 表示，LFM2.5-1.2B-Thinking 在 智能体式（agentic）任务和高推理强度任务（例如工具使用、数学、编程）中表现尤为突出。当模型需要规划一系列工具调用、验证中间结果并动态调整解题策略时，其生成的推理轨迹能够发挥实际价值。而在对话交互和创意写作等场景下，则更推荐使用 LFM2.5-1.2B-Instruct。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练细节&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;要构建能力强的小型推理模型，关键在于：在知识容量有限的前提下，通过&lt;strong&gt;多步推理&lt;/strong&gt;来弥补能力，同时又要保持答案简洁，以满足端侧低延迟部署的需求。&lt;/p&gt;&lt;p&gt;此前在 LFM-1B-Math 上的实验表明，在中期训练阶段引入推理轨迹，有助于模型内化「先推理，再作答」的模式。随后，基于合成推理轨迹进行的监督微调（SFT），进一步让模型能够稳定地产生思维链，而无需依赖特定格式的奖励设计。&lt;/p&gt;&lt;p&gt;然而，SFT 并不能解决推理模型中的一个常见问题：模型可能陷入重复文本模式，迟迟无法得出结论。这种行为通常被称为 &lt;strong&gt;「doom looping」（死循环式生成）&lt;/strong&gt;。为此，Liquid AI 采用了一种相对直接的缓解方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;在偏好对齐阶段&lt;/strong&gt;，基于 SFT 模型生成了 5 个温度采样候选和 1 个贪婪解码候选；当不存在循环时，选择由 LLM 评判得分最高的作为正样本、得分最低的作为负样本；一旦出现循环生成，则无论评判得分如何，直接将出现循环的候选作为负样本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;在 RLVR 阶段&lt;/strong&gt;，进一步在训练早期引入了基于 n-gram 的重复惩罚，以抑制循环生成行为。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过这些策略，模型在保持推理能力的同时，显著降低了陷入无效循环的风险。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKoH09l6mtb83qxD95HOycNFI7su0fNuPSmYFuWFfCV3ROdJpL2AAEww/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.10740740740740741" data-type="png" data-w="1080" data-width="1588" data-height="170" data-imgfileid="503529364" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/0f2311a0-f539-473c-afe5-557e2ab666b3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这一方法在一个具有代表性提示词的数据集上，将死循环生成的比例从 15.74%（中期训练阶段） 显著降低到了 0.36%（RLVR 阶段），效果非常直接且稳定。&lt;/p&gt;&lt;p&gt;Liquid AI 的 RL 训练流水线核心采用的是无 critic、类 GRPO 方法。整体实现是 reference-free 的，并结合了多项训练技巧，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;非对称比例裁剪（asymmetric ratio clipping）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对零方差提示组的动态过滤&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;超长样本掩码（overlong-sample masking）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不进行优势归一化（no advantage normalization）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;截断的重要性采样（truncated importance sampling）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKah3e3e0GKhUu1sozol7yqOxjEA4ROaD2VlFvkQwTT5SdFMf4am5n2g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="2880" data-height="1620" data-imgfileid="503529365" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/124a6906-ca93-41e0-ae80-f5fa6b509ff5/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;RL 方法的简化示意图：最终发布的 checkpoint 是一个合并模型，其「家族树」中包含 25 个不同的子 checkpoint。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Liquid AI 采用了一种高度并行的 &lt;strong&gt;Curriculum RL 训练框架&lt;/strong&gt;，先以指令跟随的 RLVR 作为基础起点，再分叉出面向推理、数学、工具使用等不同领域的专项 checkpoint。&lt;/p&gt;&lt;p&gt;这种并行结构不同于传统的「单模型、多任务同时训练」方式，往往会引发能力相互干扰。&lt;/p&gt;&lt;p&gt;Curriculum RL 提供了更精细的控制粒度：每个领域的模型都可以独立优化，拥有各自的奖励设计、超参数和评估标准。随后，我们在不同阶段进行迭代式模型合并，生成在多种能力之间更均衡的新 checkpoint。&lt;/p&gt;&lt;p&gt;实践表明，模型合并在保留整体性能的同时，能够有效吸收专项能力提升，是一条可行且可扩展的通用 RLVR 训练路径。&lt;/p&gt;&lt;p&gt;此外，&lt;strong&gt;Liquid AI 正在全力拓展 LFM 系列模型的生态系统和合作伙伴&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;LFM2.5-1.2B-Thinking 实现了开箱即用支持，兼容最流行的推理框架，包括 llama.cpp、MLX、vLLM 和 ONNX Runtime。所有框架均支持 CPU 和 GPU 加速，覆盖 Apple、AMD、Qualcomm 和 Nvidia 等硬件。&lt;/p&gt;&lt;p&gt;为了确保 LFM2.5 系列 能够在各种场景下高效运行，Liquid AI 正在快速扩展软硬件生态系统，并欢迎 Qualcomm Technologies, Inc.、Ollama、FastFlowLM 和 Cactus Compute 作为新的合作伙伴加入。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW86SLPI8ke4rQDiaibQ4jyDMKz8mKzyHt4afV881mEsVLxab8EG2lbnddiahY1ic3NWazu5HpjtpvpkIw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.6074074074074074" data-type="png" data-w="1080" data-width="1600" data-height="972" data-imgfileid="503529366" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/dd559534-53e2-4102-a370-6e9038647e98/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; LFM2.5-1.2B-Thinking 在不同硬件设备上的长上下文推理表现。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;LFM2.5-1.2B-Thinking 可能只是个起点，但它已经证明了一件事 &amp;mdash;&amp;mdash;Transformer 并非唯一解，小而强的端侧推理模型或许有更优解。&lt;/p&gt;&lt;p&gt;更重要的是，运行推理模型的门槛越来越低，让更多设备激发 AI 潜能，不论如何，都是一件美事。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://www.liquid.ai/blog/lfm2-5-1-2b-thinking-on-device-reasoning-under-1gb#training-recipe&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
