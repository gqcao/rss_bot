<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:wp="http://wordpress.org/export/1.0/">
  <channel>
    <title>机器之心</title>
    <link>https://www.jiqizhixin.com/</link>
    <description>机器之心</description>
    <language>zh-cn</language>
    <image>
      <url>https://cdn.jiqizhixin.com/assets/logo-324f67bf5f492bd3893d9ad58908e81cb12f7f7f507af266fbfb6e7691ad68e7.png</url>
      <title>机器之心</title>
      <link>https://www.jiqizhixin.com/rss</link>
    </image>
    <item>
      <title>Sebastian Raschka万字年终复盘：2025，属于「推理模型」的一年</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:58:51 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-9</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-9</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/fb81ab4c-43c5-47ad-a6bc-1be0d559462c/1767372891034.png" style="width: 700%;" class="fr-fic fr-dib"&gt;随着2025年的日历翻过最后一页，AI 领域再次证明了预测未来的难度。&lt;/p&gt;&lt;p&gt;在这一年，Scaling Law 并没有失效，但它的战场已经转移：从单纯的参数堆叠转向了推理侧的强化。DeepSeek R1 的横空出世，不仅打破了专有模型的神话，更让 RLVR 和 GRPO 算法成为了年度技术风向标。与此同时，我们在架构上看到了 MoE 与高效注意力机制的收敛，也在行业中目睹了「极限刷榜」带来的评估困境。&lt;/p&gt;&lt;p&gt;著名 AI 教育家与研究员 Sebastian Raschka 在他今年的年度总结中，以其一贯的「硬核工程视角」对 2025 年进行了全面复盘。从 DeepSeek 的成本经济学到推理模型的算法细节，从工具使用的演进到 AI 辅助编程的真实体验，Raschka 不仅梳理了技术脉络，还反思了人与 AI 的协作边界。&lt;/p&gt;&lt;p&gt;以下是 Sebastian Raschka 的博客原文：&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LGfm3xFmTvoajA6OCRy19ia47jib2vmJGLicqiaRRGr1IRgqaBkOwWpMeIQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4064814814814815" data-type="png" data-w="1080" data-width="1371" data-height="557" data-imgfileid="503526344" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e0dbd922-153f-4099-b22b-f3d7425d3c25/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p data-pm-slice="0 0 []"&gt;https://magazine.sebastianraschka.com/p/state-of-llms-2025&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;随着 2025 年接近尾声，我想回顾一下大语言模型（LLM）在本年度的一些最重要进展，反思现存的局限性和未解难题，并分享一些关于未来的想法。&lt;/p&gt;&lt;p&gt;正如我每年常说的那样，2025 年对于 LLM 和 AI 来说又是充满变数的一年，而且今年没有迹象表明这种进步正在饱和或放缓。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、推理之年：RLVR 与 GRPO&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想探讨的有趣话题很多，让我们按时间顺序从 2025 年 1 月开始说起。&lt;/p&gt;&lt;p&gt;Scaling 仍然有效，但它并没有真正改变 LLM 在实际应用中的表现或感觉（唯一的例外是 OpenAI 刚发布的 o1，它增加了推理轨迹）。因此，当 DeepSeek 在 2025 年 1 月发布 R1 论文，展示了类似推理的行为可以通过强化学习开发出来时，这意义非凡。（在 LLM 的语境下，推理意味着模型会解释其答案，而这种解释本身通常会带来答案准确性的提升。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lp4e3meiaLExm6gBeViavozaCaMdyRtxbvhKlAnvPY8aWia1lVwoe0gDZg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9787037037037037" data-type="png" data-w="1080" data-width="1496" data-height="1464" data-imgfileid="503526345" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/c7a7b942-af3e-440c-8ff2-db7d116b57ff/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 1：一个简短的回答和一个包含中间步骤的更长的回答，后者通常是推理模型生成的。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.1 DeepSeek 时刻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 因各种原因备受关注：&lt;/p&gt;&lt;p&gt;首先，DeepSeek R1 是作为开放权重模型发布的，其表现非常出色，足以媲美当时最好的专有模型（如 ChatGPT, Gemini 等）。&lt;/p&gt;&lt;p&gt;其次，DeepSeek R1 的论文促使许多人（尤其是投资者和记者）重新审视 2024 年 12 月发布的 DeepSeek V3 论文。这导致了一个修正后的结论：虽然训练最先进的模型仍然昂贵，但其成本可能比之前假设的低一个数量级，估计更接近 500 万美元，而不是 5000 万或 5 亿美元。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LhwBls2CmcZBdRcl9SRGiarXvicNvHicuEwnxyzJHwrXZniafNqsS4s6ibLA/640?wx_fmt=jpeg#imgIndex=3" data-ratio="0.18888888888888888" data-type="png" data-w="1080" data-width="1456" data-height="351" data-croporisrc="https://mmbiz.qlogo.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5I76ibsxkINcEUXNtPYWYcXkfVsWMAHu2xS3NHiaqianfPFpUDIHjBCuA/0?wx_fmt=png&amp;from=appmsg" data-cropx2="1456" data-cropy1="42.82352941176471" data-cropy2="317.3979238754326" data-imgfileid="503526346" data-aistatus="1" data-original-style="width: 578px;height: 109px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/35c9c5f4-a0ee-4ae7-971a-925272beec72/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 2：来自 DeepSeek V3 论文 的表格，估计训练 6710 亿参数 DeepSeek V3 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;DeepSeek R1 的补充材料估计，在 DeepSeek V3 基础上训练 R1 模型的成本仅需额外的 29.4 万美元，这再次远低于所有人的预期。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LypJzibIqWMIibn7jhS6gXUEqMC3mHKJCPlBoN9AK9zJCQBhfGaDdCCFQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.21203703703703702" data-type="png" data-w="1080" data-width="1358" data-height="288" data-imgfileid="503526348" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d993acdd-ee64-4cce-ad31-a8b16fac9840/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 3：来自 DeepSeek R1 论文补充材料的表格，估计在 DeepSeek V3 基础上训练 R1 模型的成本。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;当然，关于 500 万美元的估算有许多注意事项。例如，它仅涵盖了最终模型运行的算力信用成本，并未计入研究人员的薪水以及与超参数调整和实验相关的其他开发成本。&lt;/p&gt;&lt;p&gt;第三，也是最有趣的一点，该论文提出了带有可验证奖励的强化学习 (RLVR) 配合 GRPO 算法，作为一种新的（或至少是改进的）算法方法，用于开发所谓的推理模型并在后训练阶段改进 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LRTPlWqqflKSwPibDODO19NNYk5dmDOxSicQRzVnofHvZhc3C42lQbmcw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.875" data-type="png" data-w="1080" data-width="1456" data-height="1274" data-imgfileid="503526349" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/f4f8531a-ed73-4938-8c52-a7ea832864cf/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 4：强化学习应用的广泛概述及其时机。在这一概述中，我跳过了许多细节，但有兴趣的读者可以在我的《LLMs 推理的强化学习现状》一文中阅读更多内容。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在此之前，像监督指令微调 (SFT) 和基于人类反馈的强化学习 (RLHF) 这样的后训练方法（它们仍然是训练流程的重要组成部分）一直受限于昂贵的书面回复或偏好标签。（当然，人们也可以用其他 LLM 合成生成这些数据，但这有点像「先有鸡还是先有蛋」的问题。）&lt;/p&gt;&lt;p&gt;DeepSeek R1 和 RLVR 的重要性在于，它们允许我们在大量数据上对 LLM 进行后训练，这使它们成为通过在后训练期间扩展算力来改进和解锁能力的绝佳候选者（假设有可用的算力预算）。&lt;/p&gt;&lt;p&gt;RLVR 中的 V 代表「可验证」，意味着我们可以使用确定性方法来分配正确性标签，而这些标签足以让 LLM 学习复杂的问题解决能力。（典型的类别是数学和代码，但也有可能将此想法扩展到其他领域。）&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L8qmOyFvp2nZibke3IPXUx629WVtUMFHEbTtFzJNDlcYImjx79XVWA2Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5361111111111111" data-type="png" data-w="1080" data-width="1082" data-height="580" data-imgfileid="503526350" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/e6db5b0d-853f-4f20-96a2-30fc906a7fa1/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图5：可验证奖励的一个简单示例。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我不想在这里过于纠结技术细节，因为我想在这篇年度回顾文章中涵盖其他方面。关于推理 LLM 和 RLVR，完全可以写整篇文章或整本书。例如，如果您有兴趣了解更多，可以查看我之前的文章。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上所述，结论是：今年的 LLM 发展本质上是由使用 RLVR 和 GRPO 的推理模型主导的。 基本上，继 DeepSeek R1 之后，每一个主要的开放权重或专有 LLM 开发商都发布了其模型的推理（通常称为「思考/Thinking」）变体。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.2 LLM 关注重点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我要简洁地总结每一年 LLM 开发的关注重点（除了单纯扩展架构和预训练算力之外），我的列表会是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2022: RLHF + PPO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2023: LoRA SFT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2024: 中期训练 (Mid-Training)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2025: RLVR + GRPO&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;预训练仍然是一切的必要基础。除此之外，RLHF（通过 PPO 算法）当然是早在 2022 年带来最初 ChatGPT 模型的功臣。&lt;/p&gt;&lt;p&gt;在 2023 年，重点大量集中在 LoRA 和类 LoRA 的参数高效微调技术上，用于训练小型自定义 LLM。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lb3le591ibg3TBNr3SsxooOTJu42nl8Lc9nulFDXquv80XvRzVskk4rA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.36018518518518516" data-type="png" data-w="1080" data-width="1456" data-height="524" data-imgfileid="503526351" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9488821f-174a-4165-a48f-4b6b461d8c6e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 6：近年来专有和开源权重 LLM 开发的一些关注领域。请注意，这是累积性的，意味着例如 RLHF + PPO 仍然相关且被使用。然而，它已不再是讨论的热点话题。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;接着，在 2024 年，所有主要实验室开始通过关注合成数据、优化数据混合、使用特定领域数据以及增加专门的长上下文训练阶段，使其（预）训练流程更加复杂。我在当时的 2024 年文章中总结了这些不同的方法（当时我将这些技术归类为预训练，因为「中期训练」这个术语当时还没被创造出来）：&lt;/p&gt;&lt;p&gt;当时，我认为这些是预训练技术，因为它们使用相同的预训练算法和目标。今天，这些紧随常规通用数据预训练之后的、稍微更专业化的预训练阶段，通常被称为「中期训练」（作为常规预训练和包括 SFT、RLHF 以及现在的 RLVR 在内的后训练之间的桥梁）。&lt;/p&gt;&lt;p&gt;那么，你可能会问，接下来是什么？&lt;/p&gt;&lt;p&gt;我认为明年我们会看到对 RLVR 的（更多）关注。目前，RLVR 主要应用于数学和代码领域。 下一个合乎逻辑的步骤是，不仅使用最终答案的正确性作为奖励信号，还要在 RLVR 训练期间评判 LLM 的解释。这在过去多年里一直以「过程奖励模型」的研究标签存在。然而，它尚未取得超级成功。例如，引用 DeepSeek R1 论文：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;4.2. 不成功的尝试 [...] 总之，虽然 PRM 展示了良好的能力来对模型生成的前 N 个响应进行重新排序或辅助引导搜索 (Snell et al., 2024)，但在我们的实验中，与其在大规模强化学习过程中引入的额外计算开销相比，其优势是有限的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;然而，看看上个月发布的最新 DeepSeekMath-V2 论文（我在之前的文章《从 DeepSeek V3 到 V3.2：架构、稀疏注意力和 RL 更新》中讨论过），我认为未来我们会看到更多将「解释评分」作为训练信号的做法。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://sebastianraschka.com/blog/2025/technical-deepseek.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前对解释进行评分的方法涉及第二个 LLM。这引出了我看到的 RLVR 的另一个方向：扩展到数学和代码以外的其他领域。&lt;/p&gt;&lt;p&gt;所以，如果你今天问我如果不展望 2026 年和 2027 年会看到什么，我会说：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;2026: RLVR 的扩展和更多的推理时扩展&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2027: 持续学习&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了上述的 RLVR 扩展，我认为 2026 年将会有更多关注点放在推理时扩展上。推理时扩展意味着我们在训练后，让 LLM 生成答案时花费更多的时间和金钱，但其效果非常显著。&lt;/p&gt;&lt;p&gt;推理扩展并不是一个新的范式，LLM 平台已经在底层使用了某些技术。这是延迟、成本和响应准确性之间的权衡。然而，在某些应用中，准确性比延迟和成本更重要，极端的推理扩展完全是值得的。例如，正如最近的 DeepSeekV2-Math 论文所示，它将模型在具有挑战性的数学竞赛基准测试中的表现推向了金牌水平。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lgo4kxXoySblp3wm7ZrE6jXu78K1U8iaX6JllOCQctk68Lcw1qNrD0Mw/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526352" data-aistatus="1" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/079ab775-78ff-4af5-9402-9ec440e6d46b/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 7：两种推理时扩展方法的结合：自一致性与自精炼。额外的自精炼迭代可以提高准确性。该图来自 DeepSeekMath-V2 论文。自一致性与自精炼在《从零构建推理模型》一书的第 4 章和第 5 章中有详细说明。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;今年同事之间也有很多关于持续学习的讨论。简而言之，持续学习是指在不从头开始重新训练的情况下，在数据或知识上训练模型。 这并非新想法，我也好奇为什么今年它被提及这么多次，因为目前在持续学习方面并没有任何新的或实质性的突破。&lt;/p&gt;&lt;p&gt;持续学习的挑战在于灾难性遗忘（正如持续预训练的实验所示，学习新知识意味着 LLM 在某种程度上正在遗忘旧知识）。 不过，既然这看起来是一个如此热门的话题，我确实期望在未来几年在最小化灾难性遗忘和使持续学习方法开发成为重要进展方面取得更多进步。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、GRPO：年度研究宠儿&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在昂贵的 LLM 时代，学术研究近年来一直颇具挑战性。当然，尽管（或者正因为）预算较少，学术界仍然可以做出重要的发现，并成为主流和 LLM 进步及突破的关键支柱。近年来的流行例子包括 LoRA（2021 年的大型语言模型低秩适应）及其相关的参数高效微调方法。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LA631P3NNEmRQdJYWhaANufgibNMduQNOORWIHjiamrUu4GYZmVMpUBrA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.8175925925925925" data-type="png" data-w="1080" data-width="1456" data-height="1190" data-imgfileid="503526353" data-aistatus="1" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/ae1ea1db-0f96-4f41-a2b2-0df356415252/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 8：基于代码的 LoRA 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;另一个是 DPO（直接偏好优化：你的语言模型秘密地是一个奖励模型）及其相关的无奖励模型对齐方法，作为基于人类反馈的强化学习的替代方案。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L49PyWufJKTYcKleM4a242icoKynL9iangpUp1xpeLcthhibChbelZlycQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.8518518518518519" data-type="png" data-w="1080" data-width="1456" data-height="1240" data-imgfileid="503526354" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/c287f634-ddac-4a31-8834-33b92a91e666/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 9：基于代码的 DPO 教程介绍&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在我的圈子里，今年的研究亮点是 GRPO。虽然它是在 DeepSeek R1 论文中介绍的，而非源自学术界，但它仍然让研究人员度过了令人兴奋的一年：RLVR 和 GRPO 在概念上都很有趣，而且根据规模不同，进行实验的成本并不令人望而却步。&lt;/p&gt;&lt;p&gt;因此，今年我在 LLM 研究文献中看到了许多对 GRPO 的数学改进（来自公司和学术研究人员），这些后来被采纳进了最先进 LLM 的训练流程中。例如，其中包括以下改进：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Olmo 3：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;零梯度信号过滤 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;主动采样 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Token 级损失 (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无 KL 损失 (DAPO by Yu et al., 2025 和 Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Clip higher (DAPO by Yu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;截断重要性采样 (Yao et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无标准差归一化 (Dr. GRPO by Liu et al., 2025)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;DeepSeek V3.2：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;带有特定领域 KL 强度的 KL 调优（数学领域为零）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重新加权的 KL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Off-policy 序列掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留 top-p / top-k 的采样掩码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;保留原始 GRPO 优势归一化&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我可以确认，这些 GRPO 的技巧或修改在实践中具有巨大的影响。例如，采用了其中一些或多项修改后，糟糕的更新不再破坏我的训练运行，我也不再需要定期重新加载检查点。&lt;/p&gt;&lt;p&gt;即便是非常短的运行，我在采用这些技巧时也观察到了巨大的收益：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LG0z49N20icw8aZmCPlrg38v6b50RXiaia5icw5tZB2aISzTVlLYpY78o3w/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.28888888888888886" data-type="png" data-w="1080" data-width="1456" data-height="421" data-imgfileid="503526356" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/51928105-7550-4bb2-9271-f9f161b99223/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;em data-pm-slice="0 0 []"&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 10：我从零开始的 GRPO 训练代码部分结果，该代码可在 GitHub 上获取&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;无论如何，如果你想尝试一下，我在「从头构建推理模型」的代码库中有一个原生 GRPO 脚本。（我很快会添加更多包含相应修改的消融研究。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、LLM 架构：岔路口？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说到 LLM 架构，最先进的模型仍然使用老式的解码器风格 Transformer。然而，今年，开放权重 LLM 或多或少都收敛于使用混合专家 (MoE) 层，以及至少一种「效率调整」的注意力机制：分组查询注意力 、滑动窗口注意力或多头潜在注意力。&lt;/p&gt;&lt;p&gt;除了这些相当标准的 LLM 架构外，我们还看到了针对注意力机制的更激进的效率调整，旨在随序列长度线性扩展。这方面的例子包括 Qwen3-Next 和 Kimi Linear 中的 Gated DeltaNets，以及 NVIDIA Nemotron 3 中的 Mamba-2 层。&lt;/p&gt;&lt;p&gt;无论如何，我不想在这里深入太多细节，因为如果您想了解更多，我有一篇完整的 1.3 万字且最近更新的文章专门讨论这些架构：大型 LLM 架构比较&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LDjr3AVbCichiclibbibn5UjjYP6EAtjtPmkjo1IF8JyuLxgwS32BhhWolw/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="1.3712962962962962" data-type="png" data-w="1080" data-width="1167" data-height="1600" data-imgfileid="503526357" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/a31ab06a-5774-46c5-af13-be1d9b417128/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 11：大型 LLM 架构对比&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我的预测是，我们将继续基于 Transformer 架构构建至少几年，至少在最先进的建模性能方面是这样。 同时，我确实认为我们会看到越来越多像 Gated DeltaNet 和 Mamba 层这样的效率和工程调整，因为在 LLM 训练、部署和使用的规模下，从财务角度来看，这对那些仍在为服务 LLM 烧钱的公司来说是有意义的。&lt;/p&gt;&lt;p&gt;这并不意味着没有其他替代方案。正如我在《超越标准 LLM》中所写，文本扩散模型是一种有趣的方法。目前，它们属于实验性研究模型类别，但 Google 分享说他们将发布 Gemini Diffusion 模型。它在建模质量上不会与其最先进的产品相抗衡，但对于低延迟要求的任务（如代码补全），它将非常快且具吸引力。&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，两周前，开放权重的 LLaDA 2.0 模型发布了。其中最大的一个拥有 1000 亿参数，是迄今为止最大的文本扩散模型，与 Qwen3 30B 相当。（是的，它并没有推动整体的最先进水平，但在扩散模型领域仍是一个值得注意的版本。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、这也是推理扩展和工具使用的一年&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过扩展训练数据和架构来改进 LLM 是一个既定公式，且（仍然）持续奏效。然而，特别是在今年，这已不再是「唯一」足够的秘诀。 我们在 GPT 4.5（2025 年 2 月）上看到了这一点，据传它比 GPT 4（以及后来发布的 GPT 5）大得多，但单纯的Scaling 通常不是最明智的前进方式。GPT 4.5 的能力可能比 GPT 4 更好，但增加的训练预算被认为是「性价比低」。&lt;/p&gt;&lt;p&gt;相反，更好的训练流程（更加关注中期和后训练）和推理扩展推动了今年的大部分进步。 例如，如前所述，在谈论达到金牌级数学表现的 DeepSeekMath-V2 时，推理扩展是我们可以利用的杠杆之一，让 LLM 按需解决极其复杂的任务（GPT Heavy Thinking or Pro 是其他例子；由于高延迟和成本，将这些用于所有事情是没有意义的，但在某些例子中，如具有挑战性的数学或编码问题，高强度的推理扩展是有意义的。）&lt;/p&gt;&lt;p&gt;另一个重大改进来自以工具使用为核心的 LLM 训练。如您所知，幻觉是 LLM 最大的问题之一。可以说，幻觉率一直在改善，我认为这很大程度上归功于上述的工具使用。例如，当被问及谁赢得了 1998 年 FIFA 世界杯时，LLM 不再尝试死记硬背，而是可以通过工具使用传统的搜索引擎，并从该主题的可信网站（例如本例中的 FIFA 官方网站）选择和抓取此信息。数学问题也是如此，使用计算器 API 等等。&lt;/p&gt;&lt;p&gt;例如，OpenAI 的 gpt-oss 模型是今年发布的早期开放权重模型之一，其开发时就特别考虑了工具使用。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LElNRkjgywwZAA1LZxvDhyIvBQw9zicricPN0VYq3nDwEa9ukJe8r91Dg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.7416666666666667" data-type="png" data-w="1080" data-width="1456" data-height="1080" data-imgfileid="503526358" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/35d51828-d87b-490a-8483-b0d8b0178702/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 12：来自 gpt-oss 模型卡片论文的注释表格.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;遗憾的是，开源生态系统尚未完全赶上，许多（如果不是大多数）工具仍然默认在非工具使用模式下运行这些 LLM。一个原因是这是一个较新的、不断发展的范式，工具需要适应。另一个原因也是这是一个更难解决的问题，出于安全考虑（给予 LLM 无限制的工具使用访问权限可能会带来潜在的安全风险或对系统造成其他形式的破坏。我认为应该始终问的一个明智问题是：你会信任一个新实习生拥有这种级别的系统访问权限来做这件事吗？）&lt;/p&gt;&lt;p&gt;我确实认为，在未来几年，当在本地使用 LLM 时，启用和允许工具使用将变得越来越普遍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、年度词汇：Benchmaxxing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果我必须选一个词或趋势来描述今年的 LLM 发展，那将是「极限刷榜 (Benchmaxxing)」。 在这里，Benchmaxxing 意味着过度关注推高排行榜的分数，有时甚至到了基准测试表现本身成为目标，而不是作为通用能力的代理指标的地步。&lt;/p&gt;&lt;p&gt;一个突出的例子是 Llama 4，它在许多既定基准测试中得分极高。然而，一旦用户和开发者上手使用，他们就意识到这些分数并不能反映真实世界的能力和实用性。 正如那句流行语所说，如果测试集是公开的，它就不是真正的测试集。而如今的问题是，测试集数据不仅（有意或无意地）是训练语料库的一部分，而且在 LLM 开发过程中经常被直接优化。&lt;/p&gt;&lt;p&gt;过去，即使公共测试集的基准分数虚高，至少模型排名仍然保持不变。例如，参见下方 2019 年论文《ImageNet 分类器能泛化到 ImageNet 吗？》中的注释图。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LQiaIscKgRkvX6XoNzlyy7Buqfp4Im1F3G3Jsibm0y8df3xZD2SxCWsRQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6351851851851852" data-type="png" data-w="1080" data-width="1388" data-height="882" data-imgfileid="503526359" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/9fbf55b9-b295-43d6-acc8-069df620e25a/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 13：来自 2019 年论文《Do ImageNet Classifiers Generalize to ImageNet?》的标注图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在 LLM 开发中，这已经到了基准数字不再是值得信赖的 LLM 性能指标的地步。 然而，我确实认为基准测试仍然是 LLM 必须跨越的必要门槛。即，如果我看到一个 LLM 在基准 Y 上的得分低于 X，我就已经知道它不是一个好的 LLM。然而，如果它在基准 Y 上的得分高于 X，这并不意味着它比另一个在同一基准上得分高于 X 的 LLM 好多少。&lt;/p&gt;&lt;p&gt;另一个需要考虑的方面是，图像分类器只有一个工作，即分类图像。然而，LLM 用于许多不同的任务：翻译文本、总结文本、编写代码、头脑风暴、解决数学问题等等。评估图像分类器（有明确的指标如分类准确率）比评估 LLM 在确定性和自由形式任务上的表现要简单得多。&lt;/p&gt;&lt;p&gt;除了在实践中尝试 LLM 并不断生成新的基准测试外，遗憾的是，这个问题没有解决方案。 顺便说一句，如果你好奇了解 LLM 评估的主要类别，你可能会喜欢我的文章《从头理解 LLM 评估的 4 种主要方法》。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、AI 用于编码、写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然这个问题经常出现，我想分享一下我对 LLM 取代人类进行某些类型任务（甚至工作）的看法。 从高层次来看，我将 LLM 视为赋予某些职业的人们「超能力」的工具。我的意思是，当 LLM 被用好时，它们可以使个人效率大幅提高，并消除日常工作中的许多摩擦。这范围从相对平凡的任务（如确保章节标题的大小写一致）到在大型代码库中查找复杂的错误。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.1 编码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今天，我仍然自己编写大部分我关心的代码。「我关心的」是指在那些我理解代码且代码正确性至关重要的上下文中。例如，如果我设置一个 LLM 训练脚本，我会实现并仔细检查训练逻辑。这是为了 a) 确保它在做我认为它应该做的事情，以及 b) 保留我在该任务中的知识和专业技能。然而，我现在使用 LLM 来添加周围更平凡的代码，例如添加命令行 argparse 样板代码，以便我可以更方便地从命令行使用我自己的代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LMWf8Vp5AoXZKpSbGtVlHVVHJNFOg0qFNZDJJSx8PTz0zGAaox7KTHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="1.6666666666666667" data-type="png" data-w="960" data-width="960" data-height="1600" data-imgfileid="503526360" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/950d2605-f1a7-4ce2-bdcc-feb90ce3cf4b/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 14：使用提示「为 training-script.py 添加 argparse 以支持所有超参数选项」向训练脚本添加命令行参数的例子。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;但我也越来越多地依靠 LLM 来发现问题、建议改进或对想法进行健全性检查。同时，我想了解我正在构建什么，作为个人目标，我旨在加深我的知识和技能，并继续增长我的专业知识。&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，LLM 对于我核心专业知识之外的任务非常有价值。它们让我自动化了一些我本来没有时间或精力去处理的事情。一个例子是我最近写的一个工具，用于将我的 Substack 文章提取并备份为 Markdown。（我在 Markdown 中起草所有内容，但我经常直接在 Substack 编辑器中编辑和扩充文章，所以我的本地草稿并不总是最新的）。LLM 还帮助我清理了网站上的 CSS，这些 CSS 积累了多年的重复和不一致。今年有很多类似的案例我使用了 LLM。&amp;nbsp;&lt;/p&gt;&lt;p&gt;简而言之，我认为这里的诀窍是识别何时使用以及何时不使用 LLM。以及如何以一种有助于你增长专业知识同时也令人感到满足的方式使用 LLM。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.2 代码库和代码库&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 在编写代码方面变得更好了，但尽管我听到其他人这么说，我不认为代码是或将变得短暂或过时。LLM 赋予人们超能力来生成某些编码项目，这些项目如果由他们自己创建，将需要大量精力。 然而，纯粹由 LLM 生成的代码库并不能取代专家精心制作的代码库。这些专家代码库甚至可能是由人类编码员自己使用 LLM 创建的。但关键点在于，该领域的专家投入了大量时间和精力来创建、测试和完善它。其他人要复制它需要大量工作，所以如果它存在，为什么不采用它呢？&lt;/p&gt;&lt;p&gt;简而言之，我认为一个学习了良好设计模式和权衡取舍、并在职业生涯中研究、见过并构建了许多平台的专家全栈 Web 开发人员，将能够构建比一个随机提示 LLM 构建平台的人更好的平台。 很棒的是，一个随机的人现在可以构建一个平台，即使它不是最好的。然而，使用和提示 LLM 只能让那个人走这么远，平台的质量可能会停滞不前。因此，如果这个人真的关心改进平台，深入研究这里，学习其他人如何构建平台，并带着更多的知识回来更有效地使用 LLM 来指导和改进平台设计，将是一个好主意。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.3 技术写作和研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;与编码类似，我不认为 LLM 会使技术写作过时。写一本好的技术书籍需要数千小时和对主题的深刻熟悉。这个过程可能涉及 LLM 来提高清晰度、检查技术正确性、探索替代方案或运行小型实验，但核心工作仍然取决于人类的判断和专业知识。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lv2KFlI8vykxJPX6QTmGefhUaV8rvib3T4k5Q4vvAoWfjS320znibjf7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="1.499531396438613" data-type="png" data-w="1067" data-width="1067" data-height="1600" data-imgfileid="503526362" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/7b4a580c-7dbf-43cb-aacf-4fd2da543603/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp;图 15：一个非分阶段的例子，其中 LLM 只是帮助我找到并修复了前一篇文章中的错误。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;是的，LLM 可以让技术书籍变得更好。它们可以帮助作者发现错误、扩充参考文献，并通常减少花在平凡任务上的时间。这释放了更多时间用于真正需要创造力和经验的深度工作。&amp;nbsp;&lt;/p&gt;&lt;p&gt;从读者的角度来看，我也不认为 LLM 取代了技术写作。使用 LLM 了解一个主题对于快速提问和初学者级别的解释非常有效。然而，当你想要建立更深层次的理解时，这种方法很快就会变得混乱。&lt;/p&gt;&lt;p&gt;在那一点上，与其可能浪费数小时自己试图过滤 LLM 关于你试图学习但（尚）不是专家的主题的回复，通常遵循专家设计的结构化学习路径更有意义。（专家可能使用了也可能没有使用 LLM。）&lt;/p&gt;&lt;p&gt;当然，在参加课程或从书中学习时，使用 LLM 来澄清问题或探索旁支路径仍然非常有意义。让它设计测验或练习来实践知识也很棒。&lt;/p&gt;&lt;p&gt;总的来说，我认为 LLM 对作者和读者来说都是净收益。 但我也认为这里的诀窍是学会识别何时使用以及何时不使用 LLM。例如，主要的缺点是，当一个话题变得困难时，人们很容易立即使用 LLM，因为先自己努力解决问题通常会带来更强的学习效果。&lt;/p&gt;&lt;p&gt;我看待研究的方式也差不多。LLM 对于查找相关文献、发现数学符号中的问题和建议后续实验非常有用。但让一位人类研究员坐在驾驶座上仍然是有意义的。 也许这里的经验法则是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书完全由人类生成，它可能还有进一步改进的空间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果这篇（研究）文章或书可以通过仅仅提示 LLM 生成，那么它可能不够新颖和/或不够深刻。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;6.4 LLM 与职业倦怠&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 仍然相当新且在不断发展，我认为过度使用 LLM 也有一个较少讨论的缺点。例如，我认为如果模型做了所有的操作，而人类主要是在监督，工作可能会开始让人感到空虚。&lt;/p&gt;&lt;p&gt;当然，有些人真的喜欢专注于管理系统和编排工作流程，这是一个完全有效的偏好。但对于那些喜欢亲手做事的人来说，我认为这种工作模式可能会加速职业倦怠。（这对于那些期望因为有了 LLM 而能更快获得更多结果的公司来说尤其如此。）&lt;/p&gt;&lt;p&gt;与难题搏斗并最终看到它成功，有一种特别的满足感。当 LLM 一次性搞定解决方案时，我没有同样的感觉。我想这类似于烹饪（这只是我想到的，我不是一个好厨师）。如果你喜欢做披萨，使用预制的面团只加配料可能会消除很多乐趣，烹饪变成了达到目的的手段。这不一定是坏事，但我认为如果你在较长一段时间内（几个月或几年）每天做很多小时这样的工作，我能看到它会让人感到空虚并最终导致倦怠。 所以，一个自私的观点是写代码也比读代码更有趣。你可能会同意，创建 Pull Request 通常比审查它们更有趣（当然，这对每个人来说并不都是真的）。&lt;/p&gt;&lt;p&gt;也许一个很好的、理想化的（但并非完美的）类比，说明我们应该如何以可持续的方式使用 AI，就是国际象棋。&amp;nbsp;&lt;/p&gt;&lt;p&gt;国际象棋引擎在几十年前就超越了人类棋手，但人类进行的职业国际象棋仍然活跃且繁荣。我不是国际象棋专家，但我觉得这项游戏可能甚至变得更加丰富和有趣了。&lt;/p&gt;&lt;p&gt;根据我听到的（例如，基于 Kasparov 的《Deep Thinking》一书和以 Magnus Carlsen 为特色的播客），现代棋手一直在使用 AI 来探索不同的想法，挑战他们的直觉，并以前所未有的深度分析错误。&lt;/p&gt;&lt;p&gt;我认为这是一个有用的模型，可以用来思考智力工作其他形式中的 AI。如果用得好，AI 可以加速学习并扩展一个人可以合理承担的工作。我认为我们应该更多地把它视为合作伙伴而不是替代品。 但我也认为，如果 AI 被用来完全外包思考和编码，它就有可能破坏动力和长期技能发展。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LJmeDUugQnicvCtHxDPr3g1edcTd9R4AXG7qUsaziariaFjqD8mNrUC7Ew/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6129629629629629" data-type="png" data-w="1080" data-width="1456" data-height="892" data-imgfileid="503526363" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/033a26a8-67d5-4a5b-bf2d-7d9b1ba1e8a0/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 16：LLMs 降低了入门门槛，使程序员（无论是初学者还是专家）更加高效。然而，在我们即将结束 2025 年之际，我认为仍然值得投资成为专家，因为这样你将能从 LLMs 中获得更多的价值，并能够交付更出色的结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7、优势：私有数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;LLM 的通用编码、知识问答和写作能力在不断提高。这很大程度上是因为由于训练流程和范式（例如 RLVR）以及推理扩展和工具使用的改进，Scaling 仍然提供了正向的投资回报。&lt;/p&gt;&lt;p&gt;然而，这将在某个时刻开始趋于平稳（类似于我们在 GPT 4 到 GPT 4.5 开发中看到的），除非我们继续发明新的训练方法和/或架构（目前，还没有人知道这些可能是什么样子的）。&lt;/p&gt;&lt;p&gt;LLM 目前能够解决许多通用任务和低垂的果实。但要将它们确立在某些行业中，就需要更多的领域专业化。我认为 LLM 提供商会很乐意获得高质量的、特定领域的数据。目前看来，这将是一个挑战。&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，似乎大多数接触过的公司都拒绝了此类交易，恰恰是因为数据是专有的并且是其业务差异化的核心。（我从多个来源听到了这一点，还有一篇关于此主题的 The Information 文章。）&amp;nbsp;&lt;/p&gt;&lt;p&gt;在我看来，这完全说得通。我认为将有价值的专有数据（有一天可能会给公司带来优势）卖给 OpenAI 或 Anthropic 可能有点短视。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LPxp0fnU6IHnWXZEvkMUb3JNsLOvUebib7DibTchs39GH8ylYymtpyLPg/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.45092592592592595" data-type="png" data-w="1080" data-width="1456" data-height="657" data-imgfileid="503526364" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/31132ae5-d478-424b-9a69-6caa2846fcd2/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 17：可用于训练领域专用 LLMs 的数据领域和类型示例，但在这些情况下将数据出售给外部方可能会引起担忧。(我不是法律专家，这也不构成法律建议，但我可以想象，如果是一个纯本地的 LLM，不会离开公司的安全服务器，那么在患者健康数据上训练模型与开发其他使用该患者健康数据的内部软件并无不同。)&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;目前，LLM 开发在大规模上极其昂贵且具有挑战性，这就是为什么只有少数大公司开发最先进的 LLM。然而，我认为 LLM 开发正变得越来越商品化，因为 LLM 开发者频繁在雇主之间轮换，最终将被更大的金融机构、生物技术公司和其他有预算开发利用其私有数据的具有竞争力的内部 LLM 的公司聘用。&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些 LLM 甚至不必完全从头开始训练；许多最先进的 LLM 如 DeepSeek V3.2、Kimi K2 和 GLM 4.7 正在发布，可以进行调整和进一步的后训练。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8、从头构建 LLM 和推理模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你可能想知道我今年都在忙些什么。我的重心几乎完全放在了 LLM 相关的工作上。去年，我决定成为一名独立人士并创办了自己的公司，主要是为了有更多时间从事我自己的研究、书籍撰写、Substack 写作以及行业合作。&lt;/p&gt;&lt;p&gt;作为一名独立研究员，咨询项目是维持这种工作模式可持续的一部分。这不仅涵盖了日常开销（从食品杂货到健康保险），还包括一些不太显眼的成本，比如用于上述实验的云端算力费用。&lt;/p&gt;&lt;p&gt;随着时间的推移，我的目标是进一步减少咨询工作，将更多时间花在长篇研究和写作上，特别是我在这里分享的技术深度文章。&lt;/p&gt;&lt;p&gt;我很幸运，许多公司都联系我提供全职职位。如果独立这条路走不通，那将是一个可行的选择，但目前，我计划保持独立。&lt;/p&gt;&lt;p&gt;如果你觉得我的工作有用，并且在能力范围内，订阅我的 Substack 或购买我的一本书，确实有助于使这类工作变得可持续，我真心感谢大家的支持。&lt;/p&gt;&lt;p&gt;今年我的个人高光时刻之一是收到了关于我的书《从头构建大语言模型》 (Build A Large Language Model (From Scratch))的积极反馈。我收到了来自世界各地公司和大学读者的许多深思熟虑的留言。&lt;/p&gt;&lt;p&gt;这些反馈涵盖了广泛的用例：从大学教授将其作为主要教科书来教授 LLM 原理，到前学生用它准备面试并获得新职位，再到工程师依靠它作为在生产环境中实施自定义 LLM 的踏板。&lt;/p&gt;&lt;p&gt;得知这本书现在已经被翻译成至少九种语言，我也感到非常兴奋。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LXnVK0ap4icfhKtB43uZFxpWSicSRr3NUjdjAibrrRnu61WdnOFWoXU8LQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.7694444444444445" data-type="png" data-w="1080" data-width="1456" data-height="1120" data-imgfileid="503526365" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/b42684b8-231a-4273-b0d9-702e56a9d75c/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 18：构建一个大型语言模型（从头开始）翻译成不同语言。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;许多读者还问是否会有第二版，涵盖更新、更高级的主题。虽然我也考虑过这一点，但我对降低这本书的易读性持谨慎态度。例如，用更复杂的变体（如一些较新的 DeepSeek 模型中使用的多头潜在注意力）来替换标准的多头注意力，会大大提高准入门槛。&lt;/p&gt;&lt;p&gt;相反，目前我倾向于保持这本书的原样，因为它非常适合那些想入门 LLM 的人。对于对更高级材料感兴趣的读者，作为后续，我在这一年中向该书的 GitHub 代码库添加了大量的补充材料。我计划随着时间的推移继续扩展这些材料。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LHWmph5p8XvASuoIFxeQ3ZGjACkW5KnHMlGX1y4yq4gu2CwC0FiaxSZw/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="1.3546296296296296" data-type="png" data-w="1080" data-width="1178" data-height="1596" data-imgfileid="503526366" data-aistatus="1" data-original-style="null" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/c0f2302c-4fda-4dc6-876c-1b2b25f6a5b4/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 19：我今年为《从零构建大型语言模型》（From Scratch）仓库添加的一些附加内容摘录。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;此外，正如你可能知道的，我目前正在撰写续作《从头构建推理模型》。&lt;/p&gt;&lt;p&gt;第一本书《从头构建大语言模型》侧重于核心的大语言模型架构和预训练的基础知识。&lt;/p&gt;&lt;p&gt;[图片]&lt;/p&gt;&lt;p&gt;&lt;sup&gt;图 20：展示这两本从零开始的书籍如何相互关联的示意图。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;这本关于推理模型的书则紧接第一本书的内容。它从一个预训练好的基础模型开始，探索专门旨在提高推理能力的推理时扩展方法和强化学习技术。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LaNVxIytDmkdu3lwIcibBj66lUeicfHV7x21PyHayGMRhibBUowe1zbbqQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.8203703703703704" data-type="png" data-w="1080" data-width="1456" data-height="1194" data-imgfileid="503526369" data-aistatus="1" data-original-style="null" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/e3300f54-90ce-498d-b483-94878212d1c3/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 21：《从零构建推理模型》（早期访问版）的摘录.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;除了这个 Substack 博客，我正在努力撰写这本关于推理的书。在许多方面，我认为这是我迄今为止构思最周密、打磨最精细的一本书。&lt;/p&gt;&lt;p&gt;目前，我估计每一章大约花费 75-120 小时。如果你好奇的话，我估计具体的时间分配通常如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;3-5 小时： 头脑风暴和修改选题&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 构建内容结构&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;20 小时： 编写初始代码&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 运行额外实验并阅读最新文献以获取更多见解&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 制作图表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10 小时： 撰写初稿文本&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;10-20 小时： 重写和润色章节&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;5-10 小时： 制作练习题加上运行实验&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2-5 小时： 整合编辑和读者的建议&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前，我已经完成了第 6 章的一半，该章实现了用于训练推理模型的带有可验证奖励的强化学习代码。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LeiasrFI3kzZxIA9LPtzq8hzI7I8iaInogJ2qEX3icsPDaGFveKgQLjfBw/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.7101851851851851" data-type="png" data-w="1080" data-width="1456" data-height="1034" data-imgfileid="503526370" data-aistatus="1" data-original-style="null" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/297e6a06-c7f1-4a4a-b835-2b5e67110876/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 图 22：第 6 章和第 7 章中关于可验证奖励的强化学习实验的初步结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;《从头构建推理模型》是一项非常艰巨的工作，但我完全乐在其中！我希望你和其他读者会发现它像《从头构建大语言模型》一样有用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9、2025 年的惊喜与 2026 年的预测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我想用一些主要的收获来结束这篇文章，重点关注我认为对我来说有点令人惊讶的事情，以及我对 2026 年的预测。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9.1 2025 年值得注意和令人惊讶的事情&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;让我们从 2025 年的惊喜开始。如果你在 2024 年早些时候问我，这些可能是我没想到的发展：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;几个推理模型已经在主要数学竞赛中达到金牌级表现（OpenAI 的一个未命名模型、Gemini Deep Think 和开放权重的 DeepSeekMath-V2）。我对这种事情的发生并不感到惊讶，但我很惊讶这在 2025 年就已经发生了，而不是 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Llama 4（或一般的 Llama）在开放权重社区中几乎完全失宠，Qwen 在受欢迎程度上已经超过了 Llama（根据 Nathan Lambert 的 ATOM 项目报告的下载量和衍生品数量衡量）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Mistral AI 在 2025 年 12 月宣布的最新旗舰 Mistral 3 模型使用了 DeepSeek V3 架构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;除了 Qwen3 和 DeepSeek R1/V3.2 之外，许多额外的竞争者出现在最先进开放权重模型的竞赛中，包括 Kimi、GLM、MiniMax 和 Yi。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更便宜、高效的混合架构已经成为领先实验室的更大优先事项（Qwen3-Next、Kimi Linear、Nemotron 3），而不是由单独的实验室开发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;OpenAI 发布了一个开放权重模型（gpt-oss，我今年早些时候写了一篇关于它的独立文章）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MCP（加入 Linux 基金会）已经成为代理式 LLM 系统中工具和数据访问的标准（目前）；我原本预计生态系统在 2025 年会保持更加碎片化，直到至少 2026 年。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;9.2 2026 年预测&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们可能会看到一个工业规模、面向消费者的扩散模型，用于廉价、可靠、低延迟的推理，Gemini Diffusion 可能会率先推出。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开放权重社区将缓慢但稳定地采用具有本地工具使用和日益增强的代理能力的 LLM。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;RLVR 将更广泛地扩展到数学和编码以外的其他领域（例如化学、生物学等）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;经典的 RAG 将慢慢淡出作为文档查询的默认解决方案。与其在每个文档相关的查询上使用检索，开发人员将更多地依赖更好的长上下文处理，特别是随着将会有更好的「小型」开放权重模型出现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大量的 LLM 基准测试和性能进步将来自于改进的工具和推理时扩展，而不是来自于训练或核心模型本身。看起来 LLM 正在变得更好，但这主要是因为周围的应用正在改进。同时，开发人员将更多地专注于降低延迟，并使推理模型在不必要时减少推理 Token 的消耗。别误会，2026 年将进一步推动最先进水平，但今年的进步比例将更多地来自推理端，而不仅仅是训练端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后总结，我认为如果说 2025 年有一个元教训，那就是 LLM 的进步不再是关于单一的突破，而是通过多个独立的杠杆在多条战线上进行改进。这包括架构调整、数据质量改进、推理训练、推理扩展、工具调用等等。 同时，评估仍然很困难，基准测试是不完美的，关于何时以及如何使用这些系统的良好判断仍然至关重要。&lt;/p&gt;&lt;p&gt;我希望 2026 年我们继续看到有趣的改进，但也希望我们了解改进来自何处。这既需要更好和更一致的基准测试，当然也需要透明度。&lt;/p&gt;&lt;p&gt;谢谢阅读！&lt;/p&gt;&lt;p&gt;Cheers, Sebastian&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L5beSNXduviaPh5O08SOVvMAEOVUiaZqfrDN74M5rqYia6YE0L3ibDeiaSXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=23" data-ratio="0.6666666666666666" data-type="png" data-w="1080" data-width="1456" data-height="970" data-imgfileid="503526372" data-aistatus="1" data-original-style="null" data-index="25" src="https://image.jiqizhixin.com/uploads/editor/cfed2d35-1bfa-4b46-add0-e3c5b0e2cefc/640.png" alt="图片" data-report-img-idx="23" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;附赠：LLM 研究论文精选列表（2025 年 7 月至 12 月）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;今年 6 月，我曾分享了一篇附赠文章，其中包含了我为付费订阅者（是你们让这个 Substack 博客得以维持）精心挑选并收藏的研究论文列表。&lt;/p&gt;&lt;p&gt;以同样的方式，作为对所有好心支持者的感谢，我在下面准备了一份列表，列出了我在 2025 年 7 月至 12 月期间收藏并归类的所有有趣的研究文章。我略读了这些论文的摘要，但只详细阅读了其中很小的一部分。不过，我仍然喜欢不断收集这些有条理的列表，因为在进行特定项目时，我经常会回过头来查阅其中的某一组论文。&lt;/p&gt;&lt;p&gt;然而，鉴于目前这篇文章的篇幅已经非常巨大，我将这份列表分享在一篇单独的文章中，链接如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>KAN作者刘子鸣：AI还没等到它的「牛顿」</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:45:59 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-8</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-8</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/1c023bee-dd43-4080-8124-a33dfa63ca35/1767372187912.png" style="width: 700%;" class="fr-fic fr-dib"&gt;大家新年快乐！今天和大家分享 KAN 作者刘子鸣最新发布的一篇博客。&lt;/p&gt;&lt;p&gt;过去的一年，我们见证了 Scaling Laws 持续发力，模型能力不断刷新天花板。虽然 AI 社区从未停止对可解释性的探索，但在工程进展如此迅猛的当下，我们对模型内部机制的理解，似乎总是慢了半拍。&lt;/p&gt;&lt;p&gt;刘子鸣在博客中，借用科学史提出了一个发人深省的观点：如果参照物理学的发展史，&lt;strong&gt;今天的 AI 可能还远未在这个时代的「牛顿力学」时刻，而是仍处于「第谷（Tycho）时代」&lt;/strong&gt;，一个拥有大量观测和实验，却尚未来得及系统性总结规律的早期阶段。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526556" data-ratio="1.0787037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVydCiaASeS1zapMI5GD3fd59tlyBCbNQfbbrCiaaw9888j9thmPRNibJJPA/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/3ece9a6d-fcae-45cb-b21a-ced28a27fb4c/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;我们拥有海量的实验数据和强大的模型，却缺乏对底层现象的系统性梳理。他指出，为了追求短期性能指标，AI 领域跳过了「理解」这一关键步骤，这实际上是在背负高昂的「认知债务」。&lt;/p&gt;&lt;p&gt;更为矛盾的是，当前的学术发表机制往往偏爱「完美的故事」或「巨大的性能提升」，导致大量像「第谷的观测记录」那样碎片化但极具价值的「AI 现象学」工作被忽视。&lt;/p&gt;&lt;p&gt;为此，刘子鸣呼吁建立一种「平易近人的现象学」：&lt;strong&gt;不以即时应用为导向，回归到用 Toy Model（玩具模型）进行可控的、多视角的假设驱动探索&lt;/strong&gt;。他宣布将身体力行，通过博客分享「半成品」的实验笔记，并计划在清华大学开设相关课程，邀请社区共同偿还这笔认知债务，推动 AI 从「炼丹」走向真正的物理学。&lt;/p&gt;&lt;p&gt;明星数据科学家 Jeremy Howard 也在评论区表示赞同，长期以来「实验性观察」几乎无法在 AI/ML 期刊和会议上发表，这种现象无疑阻碍了该领域的发展。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyfwV2mmL3HK0JibYYJZPjnSVFomHx9k2gDIk8Tasyk1nwxYMDaGR8bng/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.3277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526557" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e2b0f798-3a38-431c-aa7a-15f6138ecbef/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;AI 物理学需要思维模式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大家都知道，物理学领域主要沿着「第谷 &amp;mdash; 开普勒 &amp;mdash; 牛顿」这一科研范式发展，而如果借用这一类比来理解 AI 的发展阶段，那么&lt;strong&gt;今天的 AI 研究很大程度上仍然停留在「第谷阶段」，即以「实验与观察」为主的阶段&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;但即便是在「观察」这一层面，业界目前所做的事情也极其原始：大多数人关注的仍然只是少数几个基于性能的指标调优。这背后，源于物理学与 AI 在目标上的根本差异。&lt;/p&gt;&lt;p&gt;物理学的目标是通过「理解世界来改变世界」，其中「理解」本身占据着核心地位。因此，这个领域对那些能够提供洞见即便（暂时）没有实际用途的工作，也具有极高的容忍度。&lt;/p&gt;&lt;p&gt;相比之下，AI 的目标则是「直接改变世界」，近些年 Scaling Laws 的盛行使得整个领域得以跳过「理解」这一阶段，直接进入对 AI 本身进行改造和强化。但这似乎构成了一种&lt;strong&gt;认知债务（cognitive debt）&amp;mdash;&amp;mdash; 这种债务迟早是要偿还的，如果不是现在，那也会是在未来&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，现在就谈论 AI 的「牛顿力学」阶段还为时过早，即使是在基础现象学层面，仍处于非常早期的阶段。AI 的现象学可以是相对宏观的 &amp;mdash;&amp;mdash; 连接不同的模型，例如涌现与 Scaling laws，也可以更微观 &amp;mdash;&amp;mdash; 聚焦于训练动态，例如 Grokking、双下降（double descent）或稳定性边缘（edge of stability）&amp;hellip;&amp;hellip;&lt;/p&gt;&lt;p&gt;我们首先需要发现更多现象，只有这样，我们才会有动力去建立模型，并发展理论来研究它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么 AI 现象学如此难以发展？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么 AI 现象学的发展如此困难？一个原因是&lt;strong&gt;论文发表文化在其中扮演了重要角色&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;总结来看，当前可发表的工作往往只有两类：在性能上有显著提升的工作（在这种情况下，现象学似乎「没有必要」），或者拥有一个足够吸引人的「故事」。&lt;/p&gt;&lt;p&gt;而所谓「好故事」，通常有两种形式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;普适性（Universality）&lt;/strong&gt;：该现象必须在大量不同设定中都能被验证，稳定性边缘（edge of stability）就是一个例子。但这类工作对投稿的要求极高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;惊奇性（Surprise）&lt;/strong&gt;：现象必须足够反直觉、足够出人意料。这种情况非常罕见，也高度不可预测，grokking 就是代表性案例。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这也解释了为什么 AI 领域中被反复引用的现象学例子如此之少。在「AI 物理学」仍处于如此早期阶段的情况下，却对现象学提出了过高的期望，反而抑制了它的发展。&lt;/p&gt;&lt;p&gt;朱泽园所写的《大语言模型的物理学》是一项非常出色的工作，但从我与朋友们的交流来看，大家普遍的感受是：这很有意思，但不知道如果自己想进入这个领域，该从哪里开始。&lt;/p&gt;&lt;p&gt;同样的情况也出现在我们自己的工作《叠加导致稳健的神经缩放》《 Superposition Leads to Robust Neural Scaling》中。很多人好奇这样的「故事」是如何被构思出来的。&lt;/p&gt;&lt;p&gt;我无法代表整个 AI 物理学领域的整个研究群体，但从个人经验来看，我花费了大量时间去「包装」一个故事 &amp;mdash;&amp;mdash; 这既「浪费」自己的时间，也在无形中拉大了与读者之间的距离。&lt;/p&gt;&lt;p&gt;更重要的是，能够被包装成故事的现象极其稀少。许多我个人觉得非常有趣的现象，因为无法整理成一篇论文，最终只能被随意丢弃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;迈向更易理解的现象学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因此，我倡导一种更易于接近、更具包容性的现象学研究方式。这种方法将比当前的 AI 现象学更宽容，也更接近物理学中现象学的精神。它应当：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;不以即时可用性为导向；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不被要求包装成一个完整的「故事」；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;不限制分析工具，只要它们在描述、预测上是有效的。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;同时，它将强调：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可控性&lt;/strong&gt;：使用玩具模型来简化和抽象现实场景，使得结果能够用最少的资源复现（理想情况下，一台笔记本加一个 CPU 就足够了）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;多视角刻画&lt;/strong&gt;：从尽可能多的角度和指标来描述研究对象 &amp;mdash;&amp;mdash; 就像「盲人摸象」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;好奇心或假设驱动的探索&lt;/strong&gt;：现象应当能够带来新的洞见，定性结果已经足够，定量结果当然更好。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;这种「可接近的现象学」也许不容易发表在主流 AI 会议上，但它对于社区建设具有极高价值。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;比如，研究者 A 发现了一个现象（关键在于把它公开出来），B 将其与自己此前观察到的现象联系起来，C 将二者统一，D 进行理论分析，E 再将这些洞见转化为算法改进。最终，这五个人可以一起写一篇论文。&lt;/p&gt;&lt;p&gt;但在传统模式下，A 可能只会在一个很小的圈子里合作。就我对 AI 物理学社区的理解，目前这个领域仍然高度碎片化，往往按应用领域分割。例如，做视觉的研究者通常只与其他视觉研究者合作，他们的直觉也主要由视觉任务塑造。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那我们能够做什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;就我个人的经验来看，我是先从写博客开始的，开始以博客文章的形式，分享我们自己的「AI 现象学」研究。读者应当抱有这样的预期：这是同事在分享阶段性结果 &amp;mdash;&amp;mdash; 工作可能并不完整，但原始数据和思考过程会被透明地呈现出来。&lt;/p&gt;&lt;p&gt;目标有三点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是迫使自己记录观察结果&lt;/strong&gt;：正如前面所说，无法写成论文的现象往往会被丢弃。这个尝试部分受到苏剑林博客的启发 &amp;mdash;&amp;mdash; 他的博客更偏向数学原理，而我的将更强调实验观察（现象学）、「物理直觉」，以及在必要时提供一些（半）定量分析，为未来的数学研究提供问题和直觉。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;二是吸引志同道合的研究者与学生&lt;/strong&gt;：如果你对这些问题感兴趣，欢迎联系我，一起探索。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;课程准备&lt;/strong&gt;：我计划在清华大学开设一门《Physics of AI》课程。这些博客文章（及配套代码）未来可能会成为课程材料。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么对于你来说，该如何开始：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一是找到你真正关心的问题&lt;/strong&gt;：例如，研究扩散模型损失函数的参数化方式，或复现已有现象（如 Grokking）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;定义一个简单的玩具模型&lt;/strong&gt;：例如，李天宏与何恺明的 JIT 论文使用一个二维螺旋数据集来研究损失参数化。而理解 grokking 的最好方式就是自己亲手训练一个模加任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;致力于彻底理解这个玩具模型&lt;/strong&gt;：这是最困难的一步。由于发表文化的影响，我们往往急于从玩具模型跳到更真实的模型。一旦玩具模型给出了「正向结果」，我们就会立刻离开。这是一种监督式使用玩具模型。而我认为，玩具模型在无监督使用时，才能真正展现其力量。既然是玩具，就应当以孩童般的好奇心去对待它，反复把玩，从所有可能的角度理解它（就像盲人摸象）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，我无法保证这些洞见会立刻转化为性能提升，但我相信：如果整个领域持续积累这样的理解，最终一定会发生一次类似渗流（percolation）的相变。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/ZimingLiu11/status/2006810684546494522&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://kindxiaoming.github.io/blog/2025/physics-of-ai/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>自回归也能做强视觉模型？NEPA开启「下一嵌入预测」时代，谢赛宁参与</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:41:44 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/80ddf4c3-cd2b-4aaa-9742-a7a969aaff98/1767371980146.png" style="width: 700%;" class="fr-fic fr-dib"&gt;众所周知，LeCun 不喜自回归，并且还提出了一种名为联合嵌入预测架构（JEPA）的新方向，并且该方向也一直在有&lt;a data-itemshowtype="0" data-linktype="2" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651008220&amp;idx=1&amp;sn=5619349cb36b173f01dd8503866bfea9&amp;scene=21#wechat_redirect" target="_blank"&gt;新成果&lt;/a&gt;涌现。&lt;/section&gt;&lt;p&gt;然而，自回归模型的成功也是有目共睹的，尤其是在语言领域。那么，生成式预训练在自然语言上的成功能否在视觉领域重现呢？&lt;/p&gt;&lt;p&gt;近日，密歇根大学、纽约大学、普林斯顿大学和弗吉尼亚大学的一个联合研究团队对此给出了肯定答案。&lt;/p&gt;&lt;p&gt;只不过，他们不是训练模型输出用于下游任务的特征，而是让它们生成嵌入（embeddings）以直接执行预测任务。可以说，这是从学习表征（learning representations）到学习模型（learning models）的一种范式转变。&lt;/p&gt;&lt;p&gt;具体而言，模型会通过因果掩码（causal masking）和停止梯度（stop gradient），以过去图块嵌入为条件，学习预测未来的图块嵌入。类似于下一 token 预测，该团队将这种方法称为&lt;strong&gt;下一嵌入预测自回归（Next-Embedding Predictive Autoregression）&lt;/strong&gt;，简称&amp;nbsp;&lt;strong&gt;NEPA&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21Tl60htjCibLb86l6ztHwZ5ibu1HPtRBWPOHE1oC0KCzzVxkbV70pJhiaeQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2363238512035011" data-s="300,640" data-type="png" data-w="914" type="block" data-imgfileid="503524697" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/28d28fa9-f4b4-4ece-b30b-b39829acf0af/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Next-Embedding Prediction Makes Strong Vision Learners&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.16922v1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目地址：https://sihanxu.me/nepa/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/SihanXU/nepa&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址：https://huggingface.co/collections/SixAILab/nepa&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该论文目前正是 alphaXiv 上热度第一的论文。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TRNiccU8mL773Yia5o5LyEPiciaTSoQURXJsiaGJZslKh4RYUiczEeJSJ1ZOQ/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.42592592592592593" data-s="300,640" data-type="jpeg" data-w="1080" type="block" data-imgfileid="503524703" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/af5e5d14-37e9-4b30-a8a5-3ca1a997ba8d/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;本文第一作者为 Sihan Xu，密歇根大学博士生，导师是密歇根大学电气工程与计算机科学系正教授 Stella X. Yu；这项研究的部分工作是其在纽约大学访问期间完成。纽约大学著名研究科学家谢赛宁也在作者名单中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;范式的转变&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视觉预训练是计算机视觉的核心议题之一。自监督学习也已成为现代视觉预训练方法的基石，使得无需人工标签即可训练可扩展的视觉学习器。&lt;/p&gt;&lt;p&gt;其核心目标是学习表征（learn representations）：优化模型，从而将原始像素映射到固定维度的表征，这些表征随后可被使用或针对下游任务进行微调。&lt;/p&gt;&lt;p&gt;这一哲学统一了基于实例判别（instance discrimination）、自蒸馏（self-distillation）和掩码重建（masked reconstruction）的方法。&lt;/p&gt;&lt;p&gt;其目标是学习能够被各种规模的下游模块（从轻量级的特定于任务的头到诸如视觉 - 语言模型等大型级联系统）所使用的视觉表征。&lt;/p&gt;&lt;p&gt;现代自然语言处理的成功则建立在一个根本不同的范式之上。&lt;/p&gt;&lt;p&gt;语言模型的预训练目标并不是作为特征提取器；而是作为生成式和预测式系统。其目标不是生成句子的静态嵌入，而是通过一个简单的因果目标（causal objective）对数据分布本身进行建模。&lt;/p&gt;&lt;p&gt;这种训练会迫使模型内化语言中的语义和条件依赖关系。推理不再是一个「编码&amp;rarr;解决任务」的两阶段过程，而是由模型本身执行的单一预测计算。&lt;/p&gt;&lt;p&gt;这一区别至关重要，涉及根本。它表明：&lt;strong&gt;生成式预测&lt;/strong&gt;（而非表征学习）可能提供了一条扩展预训练的直接途径。&lt;/p&gt;&lt;p&gt;最近的一系列研究已经转向了这一哲学。例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;早期的像素级生成式预训练（iGPT）展示了可迁移的特征，但在处理超长序列和弱语义对齐方面表现一般。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;JEPA 超越了像素层面，通过预测潜在目标（latent targets）来更紧密地与语义结构对齐。然而，JEPA 依然是通过从动量编码器（momentum encoder）回归到潜在目标来进行训练，而不是将生成式预测作为自监督目标。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于这些观察，Sihan Xu 等人想知道：&lt;strong&gt;极简的因果预训练是否也能产生强大的视觉学习器。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;具体来说，图像被分解为图块（patches），这些图块再被映射为图块级嵌入的序列。然后训练一个因果 Transformer，在给定所有先前嵌入的情况下预测下一个嵌入，这与语言模型中的「下一 Token 预测」范式非常近似。&lt;/p&gt;&lt;p&gt;基于这些观察，Sihan Xu 等人想知道：极简的因果预训练是否也能产生强大的视觉学习器？&lt;/p&gt;&lt;p&gt;具体来说，图像被分解为图块（patches），这些图块再被映射为图块级嵌入的序列。然后训练一个因果 Transformer，在给定所有先前嵌入的情况下预测下一个嵌入，这与语言模型中的「下一 Token 预测」范式非常近似。&lt;/p&gt;&lt;p&gt;该团队对目标嵌入使用停止梯度（stop-gradient）以创建一个稳定的预测任务。这种形式是刻意保持极简的。它不需要像素级解码器、不需要离散的视觉 Tokenizer（分词器），也不需要对比学习中常见的工程化数据增强、负样本对或动量编码器。整个学习信号源于模型在嵌入空间中预测未来的能力。&lt;/p&gt;&lt;p&gt;于是乎，一个新的模型家族诞生了：&lt;strong&gt;下一嵌入预测自回归（NEPA）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一嵌入预测自回归（NEPA）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;整体来看，NEPA 方法是极简主义的。如果说现在的视觉模型都在比拼谁的装备更复杂（动量编码器、解码器、离散 Tokenizer&amp;hellip;&amp;hellip;），那么 NEPA 就是那个穿着白 T 恤走进战场的选手。它的核心哲学非常简单：像 GPT 预测下一个词那样，去预测图像的下一个「特征块」。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TnFonJO3BcWgtt1mEpJI5DBeeqUUkTyo2BuOib64hOK3m7uPECYrXDJg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.8323494687131051" data-s="300,640" data-type="png" data-w="847" type="block" data-imgfileid="503524698" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/41714c99-1adc-47cd-98b3-3808c4d9b098/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其核心思路可以总结如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;切块与编码：首先，把一张图切成若干小块（Patch），每一块通过编码器变成一个向量（Embedding）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;预测未来：观看前面的块，猜下一块长什么样。这和语言模型（LLM）的「下一词预测」相似，只不过这里处理的是连续的数学向量，而不是离散的词。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;防止「作弊」：为了防止模型偷懒（比如输出一样的结果），作者借用了 SimSiam 的经典招数：&lt;strong&gt;停止梯度（Stop-Gradient）&lt;/strong&gt;。简单说，就是让作为「标准答案」的那个目标向量保持静止，不参与反向传播。这就像是射箭时，靶子必须固定，不能让你把靶子移到箭射中的地方。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;具体到架构设计上，他们采用了一个带有因果注意力掩码的标准视觉 Transformer（ViT）主干网络。&lt;/p&gt;&lt;p&gt;与像素级重建方法不同，该方法不需要单独的解码器。该 Transformer 直接根据过去的图像块嵌入来预测未来的图像块嵌入，使用单个主干网络同时进行上下文编码和预测，这与自回归语言模型类似。图像通过一个二维卷积（Conv2d）图像块嵌入层被分割成不重叠的图像块，并在输入到 Transformer 之前添加可学习的位置嵌入。&lt;/p&gt;&lt;p&gt;他们采用了带有层归一化（LayerNorm） 的预归一化设计，并对输出特征应用最终的层归一化。&lt;/p&gt;&lt;p&gt;为了提高稳定性和可扩展性，该团队该结合了受 DINOv3 和视觉大语言模型 VisionLLaMA 启发的现代训练和归一化方法，如图 2 所示。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TvtynlmVyjdNbnUQJ8cBTcj2znKrDxX3DxonMB9WG0443Tv13ibs5p9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="1.0035545023696681" data-s="300,640" data-type="png" data-w="844" type="block" data-imgfileid="503524699" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/72fe0ab4-3387-49b0-8b9f-11d165f64048/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这些模型设计有助于训练，但与核心框架无关，感兴趣的读者可参阅原论文以及相关论文。&lt;/p&gt;&lt;p&gt;训练好之后怎么用呢？换个「头」就行。下面是两个例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分类&lt;/strong&gt;：取出最后一个预测出来的嵌入向量，接个简单的分类头，就能识别这是猫还是狗。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;分割&lt;/strong&gt;：接一个 UPerNet 头。有趣的是，虽然训练时是「只看过去」的单向预测，但在做分割这种需要全局信息的任务时，可以解除封印，开启双向注意力（Bidirectional Attention），让模型看清全图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总之，NEPA 证明了，只要你有一个好的预测目标，就不需要那些花里胡哨的架构，一个标准的 Transformer 加上「防坍塌」技巧，就能成为顶级的视觉学习者。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在量化性能方面，NEPA 展现出了与 SOTA 方法相媲美甚至更优的实力。&lt;/p&gt;&lt;p&gt;仅在 ImageNet-1K 上进行预训练，NEPA 的 ViT-B 和 ViT-L 模型分别达到了 83.8% 和 85.3% 的 Top-1 准确率，这一成绩优于 MoCo v3、BEiT，并与 MAE 和 JEPA 处于同一水平。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TRVLkoJYcxnpXAFBjofpDlROJ65l161AHn76pdtdbHibcuReFAY2g9qw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.44351851851851853" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524701" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d52d992f-c7c5-4b3b-bfe6-12fbfc5ecb2f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;更重要的是，尽管预训练过程中从未涉及像素重建，NEPA 依然表现出了强大的迁移能力，在 ADE20K 语义分割任务上分别取得了 48.3% 和 54.0% 的 mIoU，证明了纯粹的嵌入预测足以学习到处理密集预测任务所需的丰富语义特征。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TqmjpE8gia2aXTDSOP3ozkNXXNEzeVyfeaT1AFZWjGDics64ibs0rT8Ribw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.4185185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524700" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d7f40ce3-acf1-4cbd-a058-94a2c8b4e43c/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;最后，通过对模型内部注意力和嵌入的可视化分析，研究揭示了 NEPA 的有效性来源。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vQ5z983QmeJMF0ibtxO21TUjhgpVP5uuXGIF9ib4S3NaJQibG5p9gjibibE68m8LetLCC7ArVc0lP2yQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.9287037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503524702" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/4a62b361-b7fd-4da0-b006-45d9c7eb1bd5/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;可视化结果显示，模型自动学会了长距离且以对象为中心的注意力模式，能够忽略背景干扰，将注意力集中在语义相关的区域。同时，预测出的嵌入向量在语义上与属于同一物体的其他图块高度相似，表明模型并非死记硬背局部纹理，而是真正理解了物体层面的结构。&lt;/p&gt;&lt;p&gt;这种通过简单的「下一嵌入预测」所习得的全局语义依赖，不仅验证了该方法的有效性，也为跨模态的统一预训练范式提供了一种无需复杂手工设计的通用视角。&lt;/p&gt;&lt;p&gt;消融实验和更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>「辍学创业」的风再次席卷硅谷，但真正的变量从来不是学位</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:37:17 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/94b1d6ec-0ad2-491f-94f9-bba80473d27e/1767371655483.png" style="width: 700%;" class="fr-fic fr-dib"&gt;在 80、90 后的成长记忆里，「辍学创业，成为亿万富翁」这类故事流传甚广。&lt;/p&gt;&lt;p&gt;理性分析后都知道，这里面有幸存者偏差，也有个体差异 &amp;mdash;&amp;mdash; 盖茨、扎克伯格都是哈佛级别，随时能回去拿学位；乔布斯也没有完全离开校园，而是以旁听生的身份自由选课。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyyJ0DGHyShpDgwP0zscmCDdlEkOeibPNtbOiamcIbpVeAa8bPibHFqhm9A/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2833333333333333" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526545" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/96c6c54c-7ad5-4924-ae5d-b4c362922ede/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;但没想到，最近，这股风又刮回来了。在硅谷，「辍学创业」正成为一个值得强调的正向标签。&lt;/p&gt;&lt;p&gt;这一趋势在 Y Combinator 的 Demo Day 上体现得尤为明显：越来越多的创始人在一分钟路演中主动强调自己的辍学身份。&lt;/p&gt;&lt;p&gt;Moxxie Ventures 创始人兼普通合伙人 Katie Jacobs Stanton 表示：「据我所知，YC 并未正式追踪辍学数据，但从近几批学员的情况来看，有太多创始人会特意强调自己从大学、研究生院甚至高中辍学的经历。辍学本身已成为一种资历，体现出创业者对事业的坚定信念和投入。我认为在风投圈，这被视为相当正面的特质。」&lt;/p&gt;&lt;p&gt;这些人的辍学动机不难理解：留在学校完成学业，可能意味着错过 AI 创业周期中最关键的窗口期。创办 Scale AI 的 Alexandr Wang、Lucy Guo 就是其中代表。&lt;/p&gt;&lt;p&gt;一位投资人表示，「大家普遍有一种紧迫感，或许还有错失恐惧症（FOMO）。现在的算盘很简单：要么完成学业，要么直接开始做产品。」&lt;/p&gt;&lt;p&gt;这种焦虑正催生极端案例。一位顶尖大学的教授近期透露，一名学生在最后一个学期放弃了学位。这位学生深信，拥有文凭反而会降低他获得融资的机会。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVydCwPkHBlP50wiaKI2icZxkduWicCyeqb7bamE8CjdIuzV5ceR6kibp6Brw/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.9490740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526546" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/d5a1318d-a0db-4380-9c0d-189cf2b78241/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;不过，也有投资人认为市场并没有如此极端。负责 General Catalyst 种子轮投资策略的 Yuri Sagalov 表示，风投其实没那么执着于「辍学」这个标签，尤其是对于即将毕业的学生：「对于大四才辍学的人，我从来没觉得他们和顺利毕业的人有什么本质区别。」&lt;/p&gt;&lt;p&gt;Sagalov 认为，即便是技术天才能够在没有正规教育的情况下创业，大学提供的社交网络和学校品牌仍然具有价值 &amp;mdash;&amp;mdash; 即使创始人最终没有拿到文凭。他说：「你依然能获得大部分社交价值&amp;hellip;&amp;hellip; 因为你可以标注自己曾就读于那所学校。大多数人在 LinkedIn 上看你的履历时，并不会太在意你是否真正毕业。」&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyPmsyjDBVL2WmIuS1yhFQW75qq6NvibqS1mfZE0lDRMO9D6ZFtZhFibrQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="1.0333333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526547" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/76a11474-9b4a-49a8-92db-7f54d3db19e3/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;尽管如今许多投资人认为创业者可以不要大学文凭，但并非所有风投都认同年轻创始人在当前市场具有优势。FPV Ventures 联合创始人 Wesley Chan 对投资辍学者并不那么热衷，因为他更看重一种大多数年轻创始人尚未具备的特质：智慧。Chan 认为，这种智慧通常存在于「更年长的创始人，或那些经历过挫折、身上带着伤疤的人」身上。&lt;/p&gt;&lt;p&gt;当然，需要指出的是，尽管许多引领 AI 浪潮的创始人都是年轻人，但大多数仍然选择完成学业。例如，Cursor 的 CEO Michael Truell 毕业于 MIT，而 Cognition 的联合创始人 Scott Wu 则毕业于哈佛大学。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVykyrFvXUtQZxytX4RdVrMeiaR2gOS1VkzgbbUyCVgx9j0psnZWQA5M5g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.5222222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526548" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/dba2aef9-242e-405e-b9ae-fa8f15f3bbc6/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyaG0YpZk6e5k73wrwQ86KxPyssgqwvot9lu5SqPElia9zxNG3T0U1QMg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.36018518518518516" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526549" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/4086ffd1-e465-438a-95b5-51a2bee59aaf/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;也有人指出，今天所说的「辍学」其实和早些年已经完全不一样了，那些「辍学」的人只是换了个地方，还是继续做原来的事情，而且是在资源更丰富的工业实验室。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyTSTXvcR5pvthe36ibVG9ib0jyK2hWymZWkx83sPS0k2IzJRSL8VzHxQQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.387037037037037" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526550" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/689ebafe-794b-4636-8e9b-4aac28483f45/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;所以归根结底，「辍学」永远只是表象。真正决定成败的，是创始人能否在正确的时间窗口、用正确的资源、做正确的事。无论是拿着文凭走出校门，还是中途转身投入创业，学位从来都不是核心变量 &amp;mdash;&amp;mdash; 能力、判断力、时机，以及能否接入真正有价值的人脉和资源网络，才是。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：https://techcrunch.com/2025/12/31/college-dropout-has-become-the-most-coveted-startup-founder-credential/&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>让模型自己找关键帧、视觉线索，小红书Video-Thinker破解视频推理困局</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:33:36 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503474619" data-ratio="0.5703703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-type="png" data-w="1080" type="block" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/fc89c8f2-f91d-4563-89ea-7a50a7de9d01/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着多模态大语言模型（MLLM）的飞速发展，&amp;ldquo;Thinking with Images&amp;rdquo; 范式已在图像理解和推理任务上取得了革命性突破 &amp;mdash;&amp;mdash; 模型不再是被动接收视觉信息，而是学会了主动定位与思考。&lt;/p&gt;&lt;p&gt;然而，当面对包含复杂时序依赖与动态叙事的视频推理任务时，这一能力尚未得到有效延伸。现有的视频推理方法往往受限于对外部工具的依赖或预设的提示词策略，难以让模型内生出对时间序列的自主导航与深度理解能力，导致模型在处理长视频或复杂逻辑时显得捉襟见肘。&lt;/p&gt;&lt;p&gt;为攻克这一难题，来自小红书的研究团队提出了 Video-Thinker：一种全新的 &amp;ldquo;Thinking with Videos&amp;rdquo; 范式，旨在通过强化学习激发 MLLM 在视频推理中的内生智能。&lt;/p&gt;&lt;p&gt;与传统方法不同，&lt;strong&gt;Video-Thinker 不依赖构建和调用外部工具，而是将 &amp;ldquo;时序定位（Grounding）&amp;rdquo; 与 &amp;ldquo;视觉描述（Captioning）&amp;rdquo; 这两种核心能力内化在模型的思维链（CoT）中，使其能在推理过程中自主寻找关键帧并提取视觉线索&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;团队精心构建了包含 10K 高质量样本的 Video-Thinker-10K 数据集，并采用 &amp;ldquo;监督微调 + 强化学习&amp;rdquo; 的两阶段训练策略。这一方法成功让模型在无外部辅助的情况下，实现了对视频内容的自主探索与自我修正。&lt;/p&gt;&lt;p&gt;实验结果显示，Video-Thinker-7B 凭借极高的数据效率，在 Video-Holmes 等多个高难度视频推理榜单上显著超越了现有基线，确立了 7B 量级 MLLM 的 SOTA（State-of-the-Art）性能，为视频大模型的动态推理开辟了新路径。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeNwpbTmrmBCnMgEmjJQIicQmMkibvO2253iaiaLpHloBfM8XREabmjbZGJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.2962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526141" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/4e333a4e-1dbb-4044-8312-4f2479fb5ff9/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文地址：https://www.arxiv.org/abs/2510.23473&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;模型地址：https://huggingface.co/ShijianW01/Video-Thinker-7B&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/DeepExperience/Video-Thinker&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;一、背景：视频推理的 &amp;ldquo;工具依赖困局&amp;rdquo; 与破局需求&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在多模态大语言模型（MLLM）进化的浪潮中，&amp;ldquo;Thinking with Images&amp;rdquo; 范式已经让模型在静态图像的理解与推理上取得了令人瞩目的突破。当模型学会了在像素间主动定位与思考，静态画面不再是信息的黑盒。&lt;/p&gt;&lt;p&gt;然而，当我们试图将这种范式延伸至视频领域时，情况却变得复杂得多。视频不仅仅是图像的简单堆叠，更包含了复杂的时序依赖、动态的叙事逻辑以及稍纵即逝的视觉细节。面对这种高维度的信息流，现有的视频推理方法正面临着难以突破的瓶颈。&lt;/p&gt;&lt;p&gt;当前主流的视频大模型在处理复杂推理任务时，往往陷入了一种对 &amp;ldquo;外部辅助&amp;rdquo; 的过度依赖。为了弥补模型对长视频处理能力的不足，研究者们通常采用挂载外部视觉工具（如检测器、追踪器）或设计繁复的预设提示词策略来辅助模型。这种做法虽然在一定程度上缓解了信息获取的难题，却在本质上造成了推理过程的 &amp;ldquo;割裂&amp;rdquo;：模型并非真正 &amp;ldquo;看见&amp;rdquo; 并 &amp;ldquo;理解&amp;rdquo; 了视频的时间脉络，而是被动地接收外部工具提取的碎片化特征，或是机械地遵循预设步骤进行填空。&lt;/p&gt;&lt;p&gt;这种缺乏内生主动性的架构，导致模型在面对长视频或需要深度逻辑推演的任务时显得捉襟见肘。由于缺乏对时间序列的自主导航能力，模型无法像人类一样根据当前的思考线索去主动 &amp;ldquo;快进&amp;rdquo;、&amp;ldquo;倒带&amp;rdquo; 或聚焦于某个关键帧。它无法自主决定何时通过 &amp;ldquo;Grounding（时序定位）&amp;rdquo; 来锁定证据，也无法灵活地利用 &amp;ldquo;Captioning（视觉描述）&amp;rdquo; 来提炼线索。这种感知与推理的脱节，使得模型难以在动态变化的视频内容中构建起连贯的思维链，最终限制了视频大模型向更高阶智能的跃升。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何让模型摆脱对外挂拐杖的依赖，内生出在时间流中自由探索与自我修正的能力，成为了视频推理领域亟待攻克的难题。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、方法：内生能力导向的 &amp;ldquo;数据 - 训练&amp;rdquo; 全链路设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Video-Thinker 的核心愿景在于实现 &amp;ldquo;能力内化&amp;rdquo;：打破传统视频大模型对外部视觉工具的依赖，将 &amp;ldquo;时序定位（Grounding）&amp;rdquo; 与 &amp;ldquo;视觉描述（Captioning）&amp;rdquo; 这两大核心能力直接植入模型的思维链（CoT）中。为达成这一目标，团队设计了一套精密的 &amp;ldquo;数据 - 训练&amp;rdquo; 协同机制：首先构建 Video-Thinker-10K 高质量结构化数据，随后通过 &amp;ldquo;监督微调（SFT）+ 组相对策略优化（GRPO）&amp;rdquo; 的两阶段训练范式，成功让模型学会了在动态视频流中自主导航、主动思考。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeznIic2mDNVxqTzFEicSk00iah47dUE5K6XjOpm5ClbJ2ReumqCve4Fxrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.8074074074074075" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526142" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/1a618c93-1f5f-4f6a-bd8b-049035bb50f8/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;数据炼金：Hindsight-Curation 驱动的思维链构建&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeho4a2hXCQ52OnREjTPuc8Wk8EKE3dVUYW8qib0o1O11a2maUnibhd9jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.24444444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526143" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/f373897f-9b7a-4b5d-a6b7-ce3a296f4ed2/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;要让模型真正掌握视频场景下的复杂推理能力，构建高质量的训练数据是必经之路。然而，现有的开源视频数据集普遍存在 &amp;ldquo;二元割裂&amp;rdquo; 的结构性缺陷：一类是以 ActivityNet、YouCook2 为代表的描述型数据，虽然拥有精确的时间段标注和画面描述，但缺乏需要深度思考的逻辑问答；另一类是以 STAR、LVBench 为代表的问答型数据，虽然问题极具挑战性，却往往缺失了支撑答案的关键帧定位与视觉细节。为了弥补这一鸿沟，团队整合了六大主流数据集，构建了 Video-Thinker-10K。该数据集并未止步于简单的拼接，而是引入了一套 &amp;ldquo;后见之明（Hindsight-Curation）&amp;rdquo; 的自动化流水线，通过 &amp;ldquo;补全 - 合成 - 验证&amp;rdquo; 的严密闭环，生产出兼具精准时序定位（Grounding）与详尽视觉描述（Captioning）的结构化推理数据，确保模型在学习过程中能够建立起从视觉证据到逻辑结论的完整映射。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1: 双向信息补全&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;面对不同源数据特性的差异，团队将 ActivityNet、TutorialVQA,、YouCook2、STAR、ScaleLong 和 LVBench 六大主流数据集划分为互补的两类，并实施了 &amp;ldquo;缺什么补什么&amp;rdquo; 的数据增强策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;针对 &amp;ldquo;有描述无推理&amp;rdquo; 的数据（如 ActivityNet、TutorialVQA、YouCook2）：这类数据具备精确的时间段标注和详尽的动作描述，但缺乏深度的逻辑问答。团队利用 DeepSeek-R1 强大的逻辑推理能力，以原有的细粒度片段描述为上下文，合成出需要跨越多个时间片段进行综合分析的复杂多跳问题，将单纯的感知任务升级为逻辑推理任务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;针对 &amp;ldquo;有问答无细节&amp;rdquo; 的数据（如 STAR、ScaleLong、LVBench）：这类数据虽然包含极具挑战性的推理问答，却往往缺失了支撑答案的具体视觉描述。团队借助 Gemini-2.5-Flash-Lite 的长窗口视觉理解能力，以标准答案为锚点进行反向推导，为关键时间窗口生成了与答案强相关的精细化视觉描述（Answer-Conditioned Captions），填补了推理过程中视觉证据的空白。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Step 2: 结构化思维链合成&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在完成了基础信息的双向补全后，系统调用 DeepSeek-V3 执行 &amp;ldquo;反向推理合成（Reverse-Curation Generation）&amp;rdquo;。模型接收标准答案、时序标注以及生成的视觉描述作为输入，被要求倒推并生成一条逻辑严密、逐步展开的推理轨迹。这条轨迹并非自由发散，而是必须严格遵循预定义的结构化格式，显式地将推理过程拆解为三个关键动作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&amp;lt;time&amp;gt;：执行时序定位任务，精确划定包含关键信息的视频时间窗口，明确模型 &amp;ldquo;关注哪里&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;lt;caption&amp;gt;：执行视觉证据提取任务，对该时间窗口内的核心视觉线索进行总结与描述，阐述模型 &amp;ldquo;看到了什么&amp;rdquo;；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;lt;think&amp;gt;：执行深度分析任务，基于提取的时空线索进行逻辑推演与综合判断，连接视觉证据与最终答案，解释 &amp;ldquo;意味着什么&amp;rdquo;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Step 3: 后见之明验证机制（Hindsight Curation）&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这是保障数据质量的关键防线。为了确保合成的推理轨迹真实有效而非 &amp;ldquo;自说自话&amp;rdquo;，团队引入了创新的 &amp;ldquo;后见之明&amp;rdquo; 验证流程，替代了昂贵的人工抽检。具体而言，系统使用 Qwen2.5-VL-7B-Instruct 充当 &amp;ldquo;独立验证官&amp;rdquo;，在屏蔽原始视频输入的情况下，仅将上一步生成的 &amp;lt;time&amp;gt; 时序标签和 &amp;lt;caption&amp;gt; 视觉描述作为上下文输入给模型。系统随后检测验证官能否仅凭这些提取出的线索推导出正确的标准答案。如果验证失败，意味着生成的视觉线索不足以支撑推理结论，系统将自动触发再生流程，进行最多三次的迭代修正。&lt;/p&gt;&lt;p&gt;这种 &amp;ldquo;以结果验证过程&amp;rdquo; 的闭环机制，有效剔除了无效或低质量的样本，确保了最终保留在 Video-Thinker-10K 中的每一条数据，其视觉证据与逻辑结论之间都具备严密且可复现的因果关系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;监督微调建立结构化思维范式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;监督微调（SFT）阶段旨在完成模型的 &amp;ldquo;冷启动&amp;rdquo; 初始化。由于预训练的多模态大模型本身并不具备输出特定标签（如 &amp;lt;time&amp;gt; 或 &amp;lt;caption&amp;gt;）的习惯，SFT 阶段的主要任务是通过强制教学，让模型习得 Video-Thinker 独有的结构化思考范式。&lt;/p&gt;&lt;p&gt;对于每一个样本 (V, Q, T, Y)，其中 V 是视频，Q 是问题， T 是包含 &amp;lt;time&amp;gt;，&amp;lt;caption&amp;gt; 和 &amp;lt;think&amp;gt; 的思维链， Y 是最终答案。SFT 的优化目标是最小化思维链与答案的负对数似然：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeARibnW5JBqicZEoRNSl9BPCg6f2wTwwBoKiaicwy3X08cXztia9h8rJpfgQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.1388888888888889" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526144" data-aistatus="1" data-original-style="width: 478px;height: 66px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/8e47ec95-fe26-4f1d-bf75-a64671afe036/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;通过这一阶段的训练，模型不再将视频视为一个模糊的整体进行黑盒猜测，而是建立起了一套严谨的 &amp;ldquo;定位 - 感知 - 推理&amp;rdquo; 标准动作序列：即先通过 &amp;lt;time&amp;gt; 标签主动定位关键片段，再利用 &amp;lt;caption&amp;gt; 标签提取视觉细节，最后通过 &amp;lt;think&amp;gt; 标签进行逻辑整合。这种显式的思维约束，不仅教会了模型如何使用内部工具，更有效抑制了其在缺乏证据时直接生成答案的幻觉倾向，为后续的强化学习奠定了坚实的策略基础。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习激发内生智能与 &amp;ldquo;顿悟&amp;rdquo; 时刻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;虽然 SFT 赋予了模型结构化的表达形式，但仅凭监督微调，模型往往只能 &amp;ldquo;模仿&amp;rdquo; 训练数据的表面模式，难以应对分布外的复杂场景。真正的智能源于在探索中自我优化，因此训练进入第二阶段：采用组相对策略优化（Group Relative Policy Optimization, GRPO）激发模型的内生潜能。&lt;/p&gt;&lt;p&gt;不同于传统 PPO 算法依赖庞大的价值网络来评估状态价值，GRPO 采用了一种更为高效的策略：它通过对同一输入并行采样多组不同的推理轨迹，利用组内输出的相对优势来指导梯度更新。这种 &amp;ldquo;摒弃 Critic 模型&amp;rdquo; 的设计不仅大幅降低了显存占用和计算成本，更关键的是，它允许模型在反复的试错与自我博弈中，自主探索出如何更高效地调用 &amp;lt;time&amp;gt; 和 &amp;lt;caption&amp;gt; 锚点来解决新问题，从而将机械的格式遵循升华为灵活的视频思维能力，真正实现对视频内容的自主导航。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;采样与双重奖励设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于每个输入 (V, Q)，模型采样生成 G 组不同的推理轨迹&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe6e6EW8oRib2KSXmTz3KFaU02ImAZLN2o9sDTF18B9F1uoaSGqQicgMRg/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.21081081081081082" data-s="300,640" data-type="png" data-w="370" type="block" data-imgfileid="503526145" data-aistatus="1" data-original-style="width: 123px;height: 26px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/1651b25c-d2aa-4b15-9dbd-a83c75b73d56/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 14.85%;"&gt;。为了兼顾推理的准确性与格式的规范性，团队设计了复合奖励函数：&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeZt54UAZibgxlenzPds0iaZNqgJelBLuLXOgYxlkCU4HgjmY0HTwGmxhQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.164" data-s="300,640" data-type="png" data-w="500" type="block" data-imgfileid="503526146" data-aistatus="1" data-original-style="width: 144px;height: 24px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/70ebcd5e-349e-4f81-ba3e-dc3c303c167b/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 20.07%;"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeicZib8KDZehCay61uCs7bKTMJyMG2VnaulmahUSQcudQibHoOeWYF8ia9g/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.4878048780487805" data-s="300,640" data-type="png" data-w="328" type="block" data-imgfileid="503526147" data-aistatus="1" data-original-style="width: 47px;height: 23px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/6515691f-f9ce-450e-b9fe-e15f89295f28/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 7.47%;"&gt;&amp;nbsp;：结果导向，奖励最终答案是否命中真值 Y。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6miberBMKw0f2BLUo4GrJr3s1D4IbW8LabOZNdUhenXicEos262JVgOQM00g/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.5111821086261981" data-s="300,640" data-type="png" data-w="313" type="block" data-imgfileid="503526148" data-aistatus="1" data-original-style="width: 45px;height: 23px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/3c4a17dc-0791-4025-a32a-1d0dcd04b694/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 8.03%;"&gt;&amp;nbsp;：过程约束，惩罚未遵循 &amp;lt;time&amp;gt; 和 &amp;lt;caption&amp;gt; 结构的行为，确保模型不偏离思考轨道。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;策略优化目标&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最终的优化目标通过最大化裁剪后的代理目标函数来更新参数&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6miberTCzibFUYpeIQib2KP0SLAYhGCdMh4b5xAYbCCv6CLPm52IYZTs8ccWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.08" data-s="300,640" data-type="png" data-w="50" type="block" data-imgfileid="503526149" data-aistatus="1" data-original-style="width: 20px;height: 22px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/1c83d20c-4346-4acd-a758-df2c1501730e/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 3.39%;"&gt;&amp;nbsp;，并引入 KL 散度约束防止策略突变：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeFOj66iaSo8icrF9cEJibyovibC0uRSNTzmvypiabrF0R03jva1iaVyoELTibg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.08148148148148149" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526150" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/1cdc5647-a994-4a73-93ac-1b7830ee7680/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;其中&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibes3Oobroq77qymvib8ic9D0MNMLv73Isp4mXlS2jlQqt0Xicplw3DxNuMQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.32113821138211385" data-s="300,640" data-type="png" data-w="492" type="block" data-imgfileid="503526151" data-aistatus="1" data-original-style="width: 77px;height: 25px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/e0296e3c-373e-456a-a978-401ff04a7123/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 14.21%;"&gt;代表新旧策略的概率比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;涌现的 &amp;ldquo;Aha Moment&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;经过 GRPO 的强化训练后，Video-Thinker 开始涌现出类似人类的高阶认知行为 &amp;mdash;&amp;mdash; 我们称之为 &amp;ldquo;顿悟时刻（Aha Moment）&amp;rdquo;。与传统模型线性的、单向的生成过程不同，Video-Thinker 在面对复杂推理时，不再是一条路走到黑。我们观察到，模型开始在思维链中自发展现出元认知（Metacognition）特征：它会对其初步生成的时序定位或视觉描述进行 &amp;ldquo;回头看&amp;rdquo;，主动发起自我质疑与修正。&lt;/p&gt;&lt;p&gt;这种动态的内部反馈机制，使得模型不再是被动的信息接收者，而是主动的探寻者。正是这种内生的反思能力，让 Video-Thinker 能够在仅有 7B 参数量且仅使用 10K 训练数据的情况下，打破了参数规模的限制，在 Video-Holmes 等高难度视频推理基准上，大幅超越了依赖海量数据训练的现有基线模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、评测：全面验证，7B 模型刷新视频推理 SOTA&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了全方位验证 Video-Thinker 的视频推理能力，研究团队构建了包含域内（In-Domain）与域外（Out-of-Domain）的双重评估体系。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;训练配置： 研究选用 Qwen2.5-VL-7B-Instruct 作为基础模型。训练过程严格遵循 &amp;ldquo;两阶段&amp;rdquo; 范式：首先在 Video-Thinker-10K 数据集上进行 1 个 epoch 的监督微调（SFT），让模型习得结构化的思考格式；随后引入 GRPO 算法进行强化学习训练，以激发模型自主视频推理的潜能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;评测数据集：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;域内评测：基于 ActivityNet、Star、ScaleLong、YouCook2、LVBench 等五个训练数据集构建了测试集（Held-out test sets），用于评估模型在熟悉领域内的表现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;域外评测：精选了 Video-Holmes、CG-Bench-Reasoning、VRBench、SciVideoBench、VideoTT、VideoMME 等六个具有挑战性的高难度复杂视频推理基准，重点考察模型在未知场景下的泛化能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基线模型： 对比阵容强大，涵盖了 InternVL、Qwen2.5-VL 等 5 个主流开源多模态基础模型，以及 Video-R1、VideoChat-R1、Temporal-R1 等 12 个开源视频推理模型，确保了比较的公平性与广泛性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;总体性能对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验结果表明，Video-Thinker-7B 在各项视频推理基准上均展现出显著优势，成功确立了 7B 参数量级模型的新 SOTA（State-of-the-Art）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;核心发现与数据解读：&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;域外泛化能力的质变&lt;/strong&gt;： Video-Thinker 在处理未见过的复杂任务时表现尤为惊艳。在侦探推理类的 Video-Holmes 榜单上，模型取得了 43.22% 的准确率，超越了次优基线模型 4.68 个百分点；在综合性基准 VRBench 上，准确率高达 80.69%，大幅领先最佳基线 11.44%。这充分证明了 Video-Thinker 并非仅仅 &amp;ldquo;记住&amp;rdquo; 了训练数据，而是真正习得了通过 &amp;ldquo;定位&amp;rdquo; 和 &amp;ldquo;描述&amp;rdquo; 来解决通用视频问题的能力。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;SFT 与 RL 的协同效应&lt;/strong&gt;： 消融实验揭示了一个关键结论：&lt;strong&gt;仅靠 SFT 无法实现强泛化&lt;/strong&gt;。Video-Thinker-SFT-7B 版本在多个基准上的表现甚至低于基础模型，这说明 SFT 的主要作用在于 &amp;ldquo;规范格式&amp;rdquo;。而随后的 &lt;strong&gt;GRPO 强化学习阶段才是性能飞跃的关键&lt;/strong&gt;，它使模型在 Video-Holmes 上的性能提升了 11.70%，在 VRBench 上提升了 18.29%。这种 &amp;ldquo;先通过 SFT 立规矩，再通过 GRPO 练内功&amp;rdquo; 的组合，被证明是提升大模型复杂推理能力的必由之路。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe7HRFtMCxAVCsXrrzog3Y0IW8D5vZ3E4F9zKmIWqf7lCyIy8Rsrdyqg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6935185185185185" data-s="300,640" data-type="png" data-w="1080" data-croporisrc="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe7HRFtMCxAVCsXrrzog3Y0IW8D5vZ3E4F9zKmIWqf7lCyIy8Rsrdyqg/0?wx_fmt=png&amp;from=appmsg" data-cropselx2="562" data-cropsely2="372" data-imgfileid="503526222" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/30d57f97-f037-4aa6-9373-d76fc563aea8/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;推理帧数鲁棒性分析：更高效的时序信息整合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;视频理解往往受限于输入帧数。为了探究 Video-Thinker 是否依赖高帧率输入，团队对比了模型在 16 帧、32 帧和 64 帧设置下的表现。实验数据表明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;正向的 Scaling Law&lt;/strong&gt;： 随着输入帧数从 16 增加到 64，绝大多数模型的性能均呈上升趋势，说明更丰富的时序信息确实有助于推理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;全方位的性能压制&lt;/strong&gt;： 值得注意的是，Video-Thinker-7B 在所有帧数档位上均持续优于对比基线（Qwen2.5-VL 和 Video-R1）。即使在仅输入 16 帧的受限条件下，Video-Thinker 依然能保持高水准的推理精度。这意味着该模型具备更高效的时序信息整合机制，无论是在计算资源受限的低帧率场景，还是信息丰富的高帧率场景，都能稳定发挥。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeKDEL6iakWh3NuzJMkBuA6eZdd5zD2uJaGLFnByuicgIlh1hYLx6nyIsA/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.3907407407407407" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526153" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/117b98f0-85da-403e-86da-b539d1510d16/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;深度归因分析：定位与描述能力的显著增强&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Video-Thinker 的核心假设是：强大的视频推理源于对视频内容的精准 &amp;ldquo;定位（Grounding）&amp;rdquo; 和细致 &amp;ldquo;描述（Captioning）&amp;rdquo;。为了验证这一假设，研究团队不仅评测最终答案的准确率，还专门针对这两项中间过程能力进行了定量评测。评测结果表明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;时序定位（Grounding）：在要求模型输出关键时间片段的任务中，Video-Thinker-7B 的平均交并比（mIoU）达到了 48.22%，相比基础模型（27.47%）提升了 75.5%。在 Recall@0.3 指标上，Video-Thinker 更是达到了 79.29%，几乎是基础模型的两倍。这表明模型在回答问题前，确实精准锁定了视频中的关键线索，而非盲目猜测。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;内容描述（Captioning）：在视频片段描述任务中，Video-Thinker 在 BLEU、METEOR 和 ROUGE-L 三大指标上全面领先。与基础模型相比，其整体描述质量提升了 31.2%；与 Video-R1 相比，提升幅度更是达到了 61.0%。生成更准确、更相关的中间描述，为模型进行后续的逻辑推理提供了坚实的信息基础。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeiawm0qc8hvJxsF00GQKaMY3q1TwcWJSGh5ibRLKBvglBNyABpVialj1XQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.2740740740740741" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526220" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/634098dc-cc09-4243-b617-b56bfdf48819/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;消融实验：内生能力 vs 外部工具&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然 &amp;ldquo;定位&amp;rdquo; 和 &amp;ldquo;描述&amp;rdquo; 如此重要，是否可以直接给基础模型外挂现成的专用工具（如专门的 Grounding 模型或 Captioning 模型）来达到同样的效果？研究团队进行了一组反直觉但极具价值的对比实验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 简单外挂工具的 &amp;ldquo;负优化&amp;rdquo; 陷阱&lt;/strong&gt;：实验结果首先打破了 &amp;ldquo;工具越强效果越好&amp;rdquo; 的迷思。当团队尝试 &amp;ldquo;基础模型 + 即插即用工具（Plug-and-play Tools）&amp;rdquo; 的组合时，模型性能不升反降。例如，使用 Temporal-R1-7B 配合 SkyCaptioner-V1-8B 时，准确率跌至 30.58%；即便调用参数量大十倍的 Qwen2.5-VL-72B-Instruct 作为专家工具，其 33.96% 的得分依然未能超过仅使用 7B 基础模型的效果。这表明简单的工具堆叠会造成信息割裂，导致推理链路效率降低。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 现有工具调用方法的局限&lt;/strong&gt;：为了进一步验证，团队对比了现有的代表性工具使用方法 &amp;mdash;&amp;mdash; VideoMind-7B。虽然 VideoMind-7B 通过更复杂的工具调用策略，将 Video-Holmes 的得分提升到了 38.98%，成功超越了基础模型和简单的外挂方案，但相比于 Video-Thinker 它依然存在明显差距（落后约 4.2%）。这说明即便是成熟的外部工具调用方式，在信息传递的连贯性和推理深度上仍存在天花板。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Video-Thinker 内生思维链的压倒性优势&lt;/strong&gt;：最终，通过训练获得内生能力的 Video-Thinker-7B 展现了统治级的表现。它在 Video-Holmes 上取得了 43.22% 的全场最高分（红色加粗），不仅远超外挂工具方案，也显著优于 VideoMind-7B；同时在 VRBench 上更是达到了 80.69% 的高分。实验有力地证明，在视频推理任务中，将 &amp;ldquo;感知 - 定位 - 描述 - 推理&amp;rdquo; 无缝融合的内生思维链（Endogenous CoT），比简单的工具堆叠甚至 VideoMind 这种外部调用方法都更为高效可靠。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeFias9Ahic98lWr7Pj0Flx7BiaNYpLiaGVwB9g9WGBZc3rksOlRh4aTTNIA/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5555555555555556" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526154" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/11ecb2b4-0d01-4eca-8bf5-34bde63fe7fb/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、结语：内生智能引领视频推理新方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Video-Thinker 的核心价值，在于打破了 &amp;ldquo;视频推理必须依赖外部工具&amp;rdquo; 的固有认知，通过 &amp;ldquo;高质量数据合成 + 精准强化训练&amp;rdquo; 的全链路设计，让 MLLM 真正实现内生 &amp;ldquo;时序定位&amp;rdquo; 与 &amp;ldquo;片段描述&amp;rdquo; 能力，实现了端到端的自主视频思考。其 7B 参数模型在多领域基准上刷新 SOTA 的表现，证明了视频推理能力并非依赖 &amp;ldquo;大参数 + 大数据&amp;rdquo; 的堆砌，而是在于对核心内生能力的精准培养。未来，随着技术迭代，Video-Thinker 有望进一步集成音频、字幕等多模态信息，拓展至小时级长视频推理场景，让 &amp;ldquo;用视频思考&amp;rdquo; 成为 MLLM 的基础能力。这种内生智能驱动的技术路径，不仅为视频推理领域提供了新范式，更将加速 AI 在安防监控、智能教育、工业运维等领域的落地应用，真正赋能千行百业的智能化升级。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>Meta重磅：让智能体摆脱人类知识的瓶颈，通往自主AI的SSR级研究</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:26:06 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-4</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-4</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/54185399-a0f2-4a8a-ac62-b3f0aeaf4876/1767370954770.png" style="width: 700%;" class="fr-fic fr-dib"&gt;众所周知，「超级智能」是 Meta 持续不变的宏大愿景。&lt;/p&gt;&lt;p&gt;为了尽早达到构建超级智能的目标，扎克伯格在这一年里可谓是大刀阔斧，搞得 Meta 研究部门鸡飞狗跳。&lt;/p&gt;&lt;p&gt;前 Meta FAIR 领军人物 Yann LeCun 锐评：「通往超级智能&amp;hellip; 在我看来完全是胡扯，这条路根本行不通。」&lt;/p&gt;&lt;p&gt;不过，Meta 决定构建「超级智能」，一个真正能够超越人类专家水平的自主 AI 智能体，是人工智能研究中最具雄心的前沿目标。&lt;/p&gt;&lt;p&gt;AI 智能体执行任务最具代表性的落地领域就是编程了。目前，基于 LLM 的编程智能体已经展现出令人瞩目的自动化能力，但它们在本质上仍然受到一个根本性限制：&lt;strong&gt;高度依赖人类的训练数据&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;学习自 GitHub 等真实编程数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;需要手工撰写的 Bug 报告、Issue 描述；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;用已有的测试用例来反馈。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这种依赖关系形成了一道关键瓶颈，使得这些系统只能不断打磨和复现既有人类知识，而难以真正走向自主发现新问题、探索新解法的道路。&lt;/p&gt;&lt;p&gt;为此，来自&lt;strong&gt; Meta FAIR 和 Meta TBD 实验室&lt;/strong&gt;的的一项全新研究工作，打破了这一关键瓶颈，提出了 &lt;strong&gt;SSR（自对弈 SWE-RL）&lt;/strong&gt;，旨在通过使软件代理能够自主生成学习经验，从而&lt;strong&gt;摆脱人类数据的限制&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;SSR 借鉴了 AlphaGo 等自对弈系统的成功经验，提出了一条通往「超智能软件智能体」的途径，这些智能体可以在无需现有问题描述、测试或人工监督的情况下，通过与真实代码库的交互来学习和改进。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ8obcqSDsUxwicg4yNArPAvjE63TUDiccibzy3G2KqNlv9I7D2uoYkVXGw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4203703703703704" data-type="png" data-w="1080" data-width="1138" data-height="478" data-imgfileid="503525401" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/5a01971b-9342-4e1b-aab2-4b37a74c1b1e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Toward Training Superintelligent Software Agents through Self-Play SWE-RL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接：https://arxiv.org/pdf/2512.18552&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在本文中，研究团队&lt;strong&gt;提出了 Self-play SWE-RL（SSR），作为迈向超级智能软件智能体训练范式的第一步&lt;/strong&gt;。该方法几乎不依赖人工数据，仅假设能够访问带有源代码与依赖环境的沙盒化代码仓库，而不需要任何人工标注的 issue 或测试用例。&lt;/p&gt;&lt;p&gt;基于这些真实世界代码库，通过一种自博弈（self-play）的强化学习框架训练单一 LLM 智能体，使其能够不断自主注入并修复复杂度逐步提升的软件缺陷。在该过程中，每个缺陷均通过测试补丁（test patch）进行形式化描述，而非使用自然语言的 issue 描述。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;SSR 的博弈方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SSR 的核心思想，是让大模型智能体通过一个持续循环的过程来自我进化。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ3gQgQL7pS1HiaPKhpu5943ZAl4WB70z2zuCxGVnzCRrL34lthFdWic2A/640?wx_fmt=jpeg&amp;from=appmsg#imgIndex=2" data-ratio="0.22037037037037038" data-type="jpeg" data-w="1080" data-width="1106" data-height="244" data-imgfileid="503525402" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/0864f449-b7f7-48ac-9c0a-a5edb67a9c62/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 自对弈 SWE-RL（SSR）框架概览。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;如图所示，同一个 LLM 策略被拆分成两个角色：Bug 注入智能体（bug-injection agent） 和 Bug 修复智能体（bug-solving agent）。这两个角色共享同一个容器化运行环境和同一套工具，但它们接收到的任务说明和目标约束不同。&lt;/p&gt;&lt;p&gt;具体来说：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bug 注入智能体&lt;/strong&gt;首先获得一个隔离的原始代码库环境，它的任务是通过生成一个包含必要文件的 &amp;ldquo;工件（artifact）&amp;rdquo; 来人为引入一个 Bug。随后系统会通过实际执行来验证该工件的一致性 &amp;mdash;&amp;mdash; 确保该 Bug 真实存在、可被复现。通过一致性验证的 Bug 工件会被视为有效样本，并提交给 Bug 修复智能体。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZVsFbm3fXrv5BicAwh0lsw7ka9KfK2h97de9TvBQJnicZmZQRRrgicmx9w/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.3277777777777778" data-type="png" data-w="1080" data-width="1106" data-height="363" data-imgfileid="503525403" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/b10d2d33-15b8-4a8c-9022-4488df054fee/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;SSR 采用的两种主要 bug 注入策略：面向移除的方法（左）移除大量代码块，而历史感知方法（右）有选择地恢复 git 日志中的历史更改以引入真实的 bug 模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bug 修复智能体&lt;/strong&gt;则针对该 Bug 生成最终补丁，补丁是否成功由该 Bug 所定义的测试结果来验证。若修复失败，该失败过程会被视为一种 &amp;ldquo;高阶 Bug（higher-order bug）&amp;rdquo;，促使智能体在新的上下文中再次尝试。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZ1gh1LHM8NwYMWicYI7W4s5ekaO9gwDml4YvDw3FwGBDG2KYKtSjQC8w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.13518518518518519" data-type="png" data-w="1080" data-width="2090" data-height="282" data-imgfileid="503525404" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/62ba6918-5d36-4af4-a324-1ce5cf9992d8/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; 智能体 bug 修复过程&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;最终，Bug 注入阶段的奖励信号 由一致性验证结果与修复结果共同构成，用于激励更高质量的 Bug 提案；Bug 修复阶段的奖励信号 则主要依赖测试结果。底层的同一个 LLM 策略模型会在这两种奖励信号的共同作用下进行联合更新。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;评估与测试&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队在 SWE-bench Verified 与 SWE-Bench Pro 两个基准测试上，对基础模型（Base Model）、传统强化学习方法（Baseline RL），以及 SSR 方法进行了系统对比。&lt;/p&gt;&lt;p&gt;Baseline RL 与 CWM 中的标准智能体强化学习类似，可以访问自然语言问题描述、通过测试与失败测试信息，以及评测脚本，强化学习过程本质上只是检查生成的解决方案是否通过这些给定测试。&lt;/p&gt;&lt;p&gt;相比之下，SSR 仅接触最原始的环境镜像，模型必须在完全没有任何问题描述和测试用例的情况下，通过自我对弈来自主发现问题、构造解决方案并进行验证。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZlnXpoSlia5tTO9AqGRnHO0uWhVAPlFBUP9PDXzC4tUHMibM3uyibghYew/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.375" data-type="png" data-w="1080" data-width="2168" data-height="812" data-imgfileid="503525405" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/da1614a9-ba21-476f-b674-158cf8565376/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;如图所示，实验结果呈现出两个关键现象：&lt;/p&gt;&lt;p&gt;首先，即便在完全没有任务相关训练数据的情况下，SSR 在整个训练过程中仍然表现出&lt;strong&gt;稳定而持续的自我提升能力&lt;/strong&gt;。这表明，大型语言模型可以仅凭与原始代码库的交互，就逐步增强自身的软件工程能力（例如问题定位与修复能力）。&lt;/p&gt;&lt;p&gt;其次，在整个训练轨迹中，SSR 在两个基准测试上&lt;strong&gt;始终优于传统 Baseline RL&lt;/strong&gt;。这意味着，由模型自主生成的学习任务，比人工构造的数据提供了更丰富、更有效的学习信号。&lt;/p&gt;&lt;p&gt;在 &lt;strong&gt;SWE-bench Verified 与 SWE-Bench Pro &lt;/strong&gt;基准测试上，SSR 展现出显著的自我提升能力（分别&lt;strong&gt;提升 +10.4 与 +7.8 个百分点&lt;/strong&gt;），并在整个训练过程中持续超越依赖人工数据的基线方法 &amp;mdash;&amp;mdash; 尽管模型的评测对象仍然是自然语言描述的问题，而这些描述在自博弈训练阶段完全未出现过。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZibWfyOcWrU4t1oy3wKhu0aWgDnMUQMwe5zXqN8ROqIxGDeM68eqhhSA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.2953703703703704" data-type="png" data-w="1080" data-width="1938" data-height="572" data-imgfileid="503525406" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/c2c1cb48-6eee-467b-8438-c7b18dfa5fd6/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; Self-play SWE-RL 的消融实验结果。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;消融实验结果表明，仅注入训练会降低整体性能，因为模型无法从任何 Bug 修复尝试中学习；仅修复训练同样表现较差，因为它缺乏由自我对弈持续生成的动态任务分布。&lt;/p&gt;&lt;p&gt;相比之下，自我对弈要求智能体不仅要修复 Bug，还要不断提出具有挑战性的 Bug，而这个过程本身就蕴含着丰富的学习内容：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;识别哪些测试可以通过；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以有意义的方式破坏系统功能；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;甚至刻意削弱测试以隐藏 Bug。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些行为不断扩展训练信号，并让模型持续暴露在新的失败模式之下。结果表明：一个持续进化、在线生成 Bug 并解决 Bug 的训练过程，是模型实现长期自我提升的关键。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;SSR 代表着在开发能够无需直接人工监督进行学习和改进的真正自主人工智能系统方面迈出了重要一步。&lt;/p&gt;&lt;p&gt;通过证明大型语言模型可以从真实世界的软件仓库中生成有意义的学习经验，这项工作为将人工智能训练扩展到人类策划数据集之外开辟了新的可能性。&lt;/p&gt;&lt;p&gt;该方法解决了当前人工智能开发中根本性的可扩展性限制。人工标注的训练数据昂贵、有限且可能存在偏差，为开发更强大的系统制造了瓶颈。SSR 的自生成课程有可能使训练在比目前通过传统数据收集方法更可行的问题上，数量级地更多样化和更具挑战性。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW98iacuWAiaBTm2Iq243SoVCZc3mtBCTdzB2fmhcx73Il2GIlvkP640ARSFP9PPdw80l6kAMJKddVmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.2824074074074074" data-type="png" data-w="1080" data-width="1154" data-height="326" data-imgfileid="503525407" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5cadd92b-f859-4f92-9a39-57a98620e499/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;随着 AI 系统能力日益增强，从真实世界环境中自主学习的能力对于开发能够在复杂问题解决场景中真正提供帮助甚至主导的智能体变得至关重要。SSR 的演示表明这种自主学习在软件领域是可行的，这为在其他技术领域实现类似能力指明了有前景的方向，尤其是在那些正式验证和迭代改进可行的领域。&lt;/p&gt;&lt;p&gt;尽管仍属早期成果，这些结果表明：未来的软件智能体或将能够在真实代码仓库中&lt;strong&gt;自主获取海量学习经验&lt;/strong&gt;，最终发展为在系统理解、复杂问题求解乃至从零构建全新软件方面超越人类能力的超级智能系统。&lt;/p&gt;&lt;p&gt;更多信息，请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>告别KV Cache枷锁，将长上下文压入权重，持续学习大模型有希望了？</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:19:00 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-3</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-3</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/a423d1bd-2785-49d7-bc2f-3b2bb71ced4b/1767370436779.png" style="width: 700%;" class="fr-fic fr-dib"&gt;人类已经走上了创造 AGI（通用人工智能）的道路，而其中一个关键方面是持续学习，即 AI 能通过与环境互动而不断学习新的知识和能力。&lt;/p&gt;&lt;p&gt;为此，研究社区已经在探索多种不同的道路，比如开发能够实时更新状态的循环神经网络（RNN），或者试图通过极大的缓存空间来容纳海量历史。然而，真正的 AGI 或许不应仅仅被动地「存储」信息，而应像人类一样在阅读中「进化」。&lt;/p&gt;&lt;p&gt;想象一下你生命中的第一次机器学习讲座：你或许记不清教授开口说的第一个单词，但那场讲座留给你的直觉和逻辑，此刻正潜移默化地帮助你理解这篇复杂的论文。这种能力的本质在于&lt;strong&gt;压缩&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;近日，Astera 研究所、英伟达、斯坦福大学、加州大学伯克利分校、加州大学圣地亚哥分校的一个联合团队提出的&lt;strong&gt;TTT-E2E（端到端测试时训练）&lt;/strong&gt;沿着这条 AGI 的必经之路迈出了重要一步。它彻底打破了传统模型在推理时静态不变的局限，让长上下文建模从一种「架构设计」进化为一种「学习问题」。&lt;/p&gt;&lt;section&gt;&lt;img data-aistatus="1" data-imgfileid="503526436" data-ratio="1.1814946619217082" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4L91pFPQo6nVmntfVwrDZKta2wT0jpib9zHePeJsYwufXW0vz0F1miaGEg/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=1" data-type="png" data-w="843" type="block" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/d86dbfee-54e9-443e-9a3e-d72d6ce4a240/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该方法可以在测试阶段通过给定上下文的下一个 token 预测持续学习，&lt;strong&gt;将读取的上下文信息压缩至权重参数中&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LbnCnuMwLIJstLKBXAUzTfzRzZ30fmjP52urgw2ZVX26Gz9ibkJLGTuw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=2" data-ratio="0.24722222222222223" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526435" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/8b5cd203-4aa8-4e8c-bed8-fe7193cb721e/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：End-to-End Test-Time Training for Long Context&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2512.23675&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码地址：https://github.com/test-time-training/e2e&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;困难是什么？召回与效率的永恒博弈&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;论文开篇明确了当前长上下文建模的两难境地。&lt;/p&gt;&lt;p&gt;Transformer 的全注意力机制虽然在长文本上表现优异，但其推理成本随长度线性增长，这在处理 128K 甚至更长的上下文时会产生巨大的延迟压力。为了解决效率问题，业界曾转向循环神经网络（RNN）或状态空间模型（SSM，如 Mamba）。这些模型虽然拥有恒定的每 token 计算成本，但在处理超长文本时，性能往往会大幅下降，无法像 Transformer 那样有效利用远距离的信息。&lt;/p&gt;&lt;p&gt;这种性能下降的根源在于&lt;strong&gt;「压缩率」的固定&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;传统的 RNN 将无限的序列压缩进固定大小的状态向量中，这不可避免地会导致信息丢失。&lt;/p&gt;&lt;p&gt;于是，该团队思考：是否能找到一种方案，既能像 RNN 一样拥有恒定的推理延迟，又能像 Transformer 一样通过增加「存储空间」来维持长距离性能？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端到端的测试时训练（TTT-E2E）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TTT-E2E&amp;nbsp;&lt;/strong&gt;的核心思想是将模型在测试阶段（推理阶段）的行为定义为一个在线优化过程。&lt;/p&gt;&lt;p&gt;具体而言，当模型读取长上下文时，它不仅仅是在做前向传播，还在同步进行梯度下降。&lt;/p&gt;&lt;p&gt;这种方法基于这样一个逻辑：如果我们将上下文看作一份学习资料，那么模型在预测下一个 token 之前，可以先在已经读过的 token 上进行自监督学习。&lt;/p&gt;&lt;p&gt;通过这种方式，上下文中的信息就被编码进了模型的权重 W 中，而不是存储在外部的 KV Cache 里。这就像是在阅读一本书时，你不断根据新读到的内容修正自己的认知模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LxLWGXZfhRTtEtzVljVlSPeupTL0vASd976OUHUflVZlCJkfibajLN6w/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=3" data-ratio="0.5686274509803921" data-s="300,640" data-type="png" data-w="867" type="block" data-imgfileid="503526437" data-aistatus="1" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/1d492afd-8f97-4fca-9fc3-ef687273168e/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4Lxyia5k9tWvPTHx6UnzibQw33DRUgLI5g2nIn583I1qicIlmUbZLhhNLSw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=4" data-ratio="0.8155452436194895" data-s="300,640" data-type="png" data-w="862" type="block" data-imgfileid="503526438" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/7bcd8f11-c4f6-47fb-9a95-289c968f38f9/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;为了使这一构想在工程上可行且高效，团队引入了两大核心技术支撑。&lt;/p&gt;&lt;p&gt;首先是&lt;strong&gt;元学习（Meta-Learning）&lt;/strong&gt;。传统的模型在预训练时并未考虑测试时的更新逻辑，这会导致训练与测试的脱节。TTT-E2E 通过外层循环（Outer Loop）优化模型的初始化参数，使得模型「学会如何学习」，即经过少量测试时梯度更新后，能达到最优的预测效果。&lt;/p&gt;&lt;p&gt;其次是&lt;strong&gt;架构的微调与滑动窗口的结合&lt;/strong&gt;。该团队意识到，如果完全摒弃注意力机制，模型会丧失局部精确记忆能力。因此，TTT-E2E 采用了一种混合架构：使用一个固定大小（如 8K）的滑动窗口注意力（SWA）来处理短期记忆，确保局部逻辑的严密；而对于超出窗口的长期记忆，则交给 TTT 更新后的 MLP 层来承担。这种设计模仿了生物记忆系统的层级结构：滑动窗口如同瞬时感官记忆，而动态更新的权重则如同长期经验。&lt;/p&gt;&lt;p&gt;为了平衡计算开销，团队在实现细节上也极具匠心。他们并非更新模型的所有层，而是&lt;strong&gt;仅针对最后四分之一的 Transformer 块进行 TTT&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;同时，他们为这些块设计了&lt;strong&gt;双 MLP 结构&lt;/strong&gt;，一个保持静态以锁定预训练知识，另一个则作为「快速权重」在测试时动态更新，从而解决了知识遗忘的问题。&lt;/p&gt;&lt;p&gt;详细的数学描述请参阅原论文。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验结果：性能与速度的双重飞跃&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;实验数据证明了 TTT-E2E 的强大潜力。研究团队在 3B 参数规模的模型上进行了系统性扩展实验。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LBlO3Wevm1keiaQjmYcs6ic0PibnAiaoKZXRnRQnmGDNfId7HewRrdJonOQ/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=5" data-ratio="0.5962962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526439" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/3dd6a39f-ed30-4ba8-922d-bf25373714c4/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;在性能扩展性方面，TTT-E2E 展现出了与全注意力 Transformer 几乎一致的性能曲线。&lt;/p&gt;&lt;p&gt;随着上下文长度从 8K 扩展到 128K，其他 RNN 基准模型（如 Mamba 和 Gated DeltaNet）的测试损失在达到 32K 之后开始显著回升，这意味着它们无法处理更长的序列。而 TTT-E2E 的损失函数则持续下降，始终保持着对 Transformer 的追赶态势，甚至在某些指标上更优。&lt;/p&gt;&lt;p&gt;在推理效率方面，TTT-E2E 展现了压倒性优势。&lt;/p&gt;&lt;p&gt;由于它不需要存储海量的 KV Cache，其推理延迟不随上下文长度增加而改变。在 128K 上下文的测试中，TTT-E2E 的处理速度比全注意力 Transformer 快了 2.7 倍。&lt;/p&gt;&lt;p&gt;这意味着开发者可以在不牺牲模型表现的前提下，极大地降低长文本应用的响应时间。&lt;/p&gt;&lt;p&gt;然而，研究也坦诚地指出了天下没有免费的午餐。尽管推理极快，但 TTT-E2E 的训练成本目前仍然较高。由于训练时需要计算「梯度的梯度」（二阶导数），其在短上下文下的训练速度比传统模型慢得多。&lt;/p&gt;&lt;p&gt;不过，该团队提出，可以通过从预训练好的 Transformer 节点开始微调，或者开发专门的 CUDA 内核来弥补这一短板。&lt;/p&gt;&lt;p&gt;此外，在大海捞针（NIAH）这类极端依赖精确召回的任务中，全注意力模型依然是无可争议的霸主。这进一步印证了作者的观点：TTT 的本质是压缩和理解，而非逐字的暴力存储。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LbN3HxMh55ia9RC4wFVOBGLLDElMhCib6cnRNqkTSIaeicb4CdMJ49iajDw/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=6" data-ratio="0.41203703703703703" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526440" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/98bad152-abff-4727-ad5d-34b2188851d7/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;通往无限长度的未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;TTT-E2E 的意义远不止于一个更快的算法。它标志着&lt;strong&gt;大模型正在从静态模型转变为动态个体&lt;/strong&gt;。在这一框架下，模型处理长文档的过程，本质上是一次微型的自我进化。&lt;/p&gt;&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJT3zmEXgjsICqiafRaZPVyyqS9585cwgmWiaoCh9ZVrX0rNyryWicekTbZU5vYMhr0q4fAfknaxh5g/640?wx_fmt=png&amp;amp;from=appmsg#imgIndex=7" data-ratio="0.3435185185185185" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526542" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/768ba919-b815-4acf-bf61-cbe68df628b8/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/p&gt;&lt;p&gt;这种「&lt;strong&gt;以计算换存储&lt;/strong&gt;」的思路，为我们描绘了一个充满想象力的未来：或许有一天，我们可以让模型在阅读一万本书的过程中不断调整自身，最终将人类的整个文明史浓缩进那跳动的参数矩阵之中，而无需担心硬件缓存的枯竭。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>LSTM之父率队造出PoPE：终结RoPE泛化难题，实现Transformer的极坐标进化</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:12:46 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03-2</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03-2</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/93fb2d86-8cb8-4c09-ba60-121a39d2c47b/1767370076338.png" style="width: 700%;" class="fr-fic fr-dib"&gt;Transformer 架构中的注意力机制是根据内容（what）和序列中的位置（where）将键（key）与查询（query）进行匹配。&lt;/p&gt;&lt;p&gt;而在近期 LSTM 之父 J&amp;uuml;rgen Schmidhuber 的 USI &amp;amp; SUPSI 瑞士 AI 实验室团队的一项新研究中，分析表明，当前流行的旋转位置嵌入（RoPE）方法中的 what 与 where 是纠缠在一起的。这种纠缠会损害模型性能，特别是当决策需要对这两个因素进行独立匹配时。&lt;/p&gt;&lt;p&gt;基于这一观察，他们提出了新的方案：&lt;strong&gt;极坐标位置嵌入（Polar Coordinate Position Embedding ）&lt;/strong&gt;，简称 &lt;strong&gt;PoPE&lt;/strong&gt;。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeaa852MoTybWn8jpcSh4jI7GiaWiaial8ANIKEJJhusQpjcicveJia6RSbJw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.36018411967779057" data-s="300,640" data-type="png" data-w="869" type="block" data-imgfileid="503526046" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/b1d3e9ab-ac5a-4d40-ac9f-e3085d8f77c2/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;该团队表示，PoPE 消除了内容与位置的混淆，使得其在需要仅通过位置或仅通过内容进行索引的诊断任务上表现远优于 RoPE。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeAJMXcXRNhBTqibONViaf8LH4Gq1z5FUh7vQUlHPPdMq6ukeam1dGTuTg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.29907407407407405" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526047" data-aistatus="1" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/21245005-246b-4dc6-a05d-fff374030913/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：Decoupling the &amp;quot;What&amp;quot; and &amp;quot;Where&amp;quot; With Polar Coordinate Positional Embeddings&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/abs/2509.10534&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该论文的一作为 Anand Gopalakrishnan，目前正在哈佛大学从事博士后研究，曾是 J&amp;uuml;rgen Schmidhuber 的博士生。参与者中还有 OpenAI 的研究科学家 R&amp;oacute;bert Csord&amp;aacute;s，以及科罗拉多大学计算机科学系教授 Michael C. Mozer（目前已加入谷歌 DeepMind）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RoPE 的问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在许多前沿模型中，为了将位置信息纳入进来，RoPE 是首选方法，包括 Llama 3、DeepSeek-v3、Gemma 3 和 Qwen3。它会为每个查询-键对生成注意力分数，该分数基于它们的匹配程度及其在输入序列中的相对位置。&lt;/p&gt;&lt;p&gt;为了更好地理解 RoPE，这里以特定层中的特定注意力头进行说明。该注意力头的作用是执行位置 t 的查询 q_t 与位置 s 的键 k_s 之间的匹配。键和查询是 d 维向量，被划分为 d/2 个二维分量。&lt;/p&gt;&lt;p&gt;这里用 q_tc 和 k_sc 分别表示查询和键的分量 c&amp;isin;{1,...,d/2}。RoPE 首先在 2D 平面中将每个分量 c 旋转一个与位置成正比的角度。如果 R (&amp;Phi;) 是执行角度 &amp;Phi; 旋转的 2&amp;times;2 矩阵，则旋转后的查询和键分别为 R (t&amp;theta;_c) q_tc 和 R (s&amp;theta;_c) k_sc，其中 &amp;theta;_c 是分量特定的基波波长（base wavelength）：&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibexmibiauLWjIG0PbPoAe1GfWBRHx39anibpibpxriaNedqutLxOeDxc51hSg/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.08874172185430464" data-s="300,640" data-type="png" data-w="755" type="block" data-imgfileid="503526045" data-aistatus="1" data-original-style="width: 249px;height: 22px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/c112cabb-db74-450f-ae36-90d9255292f7/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dii" style="width: 35.84%;"&gt;。下图展示了查询（或键）分量的构成及其在二维空间中的旋转方式。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibekfUhNiaq3X8qJNUXW0GgH6J8JOV7EsomOW5N2djTia7byguiaQIRCssOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7637540453074434" data-s="300,640" data-type="png" data-w="927" type="block" data-imgfileid="503526048" data-aistatus="1" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/d72bbc1b-878c-4ad7-9aab-ad1269fa8e14/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;对应的键和查询分量通过点积匹配并求和以获得注意力分数：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeeCDiaB0bhb87aqiadmfg5y5DticNqOT1mf791J3iaibpxEiaDhTwpBvsV9sw/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.10687022900763359" data-s="300,640" data-type="png" data-w="786" type="block" data-imgfileid="503526050" data-aistatus="1" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/d90da3f1-0a29-4cae-bd74-c1151b2cb897/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;将分量对齐的旋转仅取决于键和查询的相对位置，而不取决于它们的绝对位置。&lt;/p&gt;&lt;p&gt;如果将键和查询分量从笛卡尔坐标重新表示为极坐标：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe29L8VkWln5mey7DwBxUqsjDt49KiaZiaYMdbQP8mZA0slR9rl3ITX0pA/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.20552884615384615" data-s="300,640" data-type="png" data-w="832" type="block" data-imgfileid="503526049" data-aistatus="1" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/7063855f-07ab-4e52-8ffa-f3ac4d899ccb/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;由此，注意力分数可写为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibe4pIbApRlGibMX66nluKibebQb3Y5jibibnIhuay23w4sCzYHPZb0ml0obQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.21481481481481482" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526051" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/5c51532e-d530-446d-9bb5-83724d2c1c12/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;这清楚地表明，嵌入的每个双元素分量都被转换为单个幅值，并且通过 &amp;Phi;_{q_tc} 和 &amp;Phi;_{k_sc} 引入了对产生最大响应的相对位置（相位）的调整。因此，键和查询都混淆了关于特征存在与否的信息（what）和相对位置（where）。&lt;/p&gt;&lt;p&gt;该团队的假设是，通过解耦这两类不同的信息，特别是通过消除交互项 ，可以提高模型性能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决方案：PoPE&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 RoPE 中，该团队将键和查询的 d/2 个分量解释为复数。而在该团队提出的方法中，该团队利用了极坐标表示的另一种形式，称之为极坐标位置嵌入，即 PoPE。&lt;/p&gt;&lt;p&gt;在 PoPE 中，该团队将键和查询转换为相应的 d 元素复向量 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeibDGian0ahl6icUkGiacU0m0tcMxpemGTMxjB6O1IGlGy84T8pUEqicKyWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.0816326530612246" data-s="300,640" data-type="png" data-w="49" type="block" data-imgfileid="503526052" data-aistatus="1" data-original-style="width: 23px;height: 25px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/e2aa3d30-d2ea-4956-82c2-8504f4bb7035/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 2.93%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibegd3ic8CbCOEHS128licsuRS7DmmrBZoNica1qpYHDDQTna7OXCIsFGlDA/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="1.25" data-s="300,640" data-type="png" data-w="40" type="block" data-imgfileid="503526053" data-aistatus="1" data-original-style="width: 20px;height: 25px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/082f5d44-6197-40b7-8099-973c9d5f50e8/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 2.38%;"&gt;。每个元素 c 的幅值是对原始实值键或查询对应元素的重新缩放：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeOPahPypIrSKa76uOANvzgyMicyicCcKOktKYdQcD1AgPrPHujDWmDRXA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.05277777777777778" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526054" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/f8aceb03-9ddb-41fd-bd46-3912033354b9/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 &amp;sigma;(x)=ln (1+e^x) 表示 softplus 激活函数，确保幅值非负。相位仅取决于位置：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeMicgX3qdaPjlS7KC8NXyicJXjPEKujmKdIS0iaicdtDpvrtmFf8Wr5toeA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.058333333333333334" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526055" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/c0fcc614-37ee-47d4-991d-2a646e860286/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;PoPE 的注意力分数定义为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibesrEGhMcYFNNOQJAxG9Q8TKqian4kCM8GFUE0wEnicicjSS0YGe2dNLlVg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.10092592592592593" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526056" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/9ae717ea-2621-4c56-ad7f-3a65b43465d4/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;与 RoPE 相比，PoPE：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在单个元素而非元素对上进行索引，将频率数量从 d/2 增加到 d；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;消除了导致键和查询影响相位的交互项。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，还可以引入一个可学习但固定的偏置项 ：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6miberd8BBwY1dYYGTVJ6zpib7ZnKI3kd1jrFvOUFiaogjNCRIuCyJ9aEfnXQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.11574074074074074" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526057" data-aistatus="1" data-original-style="null" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/b8929536-62da-4fb1-bb96-38c055e12b6f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 &amp;delta;_c 是为每个频率调整最佳相对偏移的可学习偏置。&lt;/p&gt;&lt;p&gt;该团队使用 Triton 实现了 PoPE。&lt;/p&gt;&lt;p&gt;通过修改内核，在不显式实例化复杂矩阵的情况下计算点积的实部。该团队的定制 Flash Attention 相比标准版仅需额外一次乘法。该团队表示，虽然目前的通用变体内存开销较大，但可以通过在内核内部执行旋转来优化。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那么，表现如何呢？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该团队将 PoPE 与 RoPE 在两个超参数完全相同的 Transformer 模型上进行比较。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;间接索引（Indirect Indexing）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该任务要求在变长源字符串中识别目标字符，目标字符定义为距离指定源字符一定的相对偏移量。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeME0hhmR2uzPfWOGiaaahk0wMEvsicZQ3hKBnLKzDbRnqVxqyhroewEWQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.6253333333333333" data-s="300,640" data-type="png" data-w="750" type="block" data-imgfileid="503526058" data-aistatus="1" data-original-style="width: 341px;height: 213px;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/cbe1da62-81e8-41d0-b70b-cb943dd6a492/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;RoPE 在此任务中表现挣扎，平均准确率仅为 11.16%。PoPE 则几乎完美地解决了任务，平均准确率达到 94.82%。这表明 RoPE 难以分离内容和位置信息，而 PoPE 通过解耦实现了高效学习。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;音乐与基因组序列建模&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 JSB 和 MAESTRO 符号音乐数据集上，PoPE 均实现了比 RoPE 更低的负对数似然（NLL）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeUF6icLLBGGnOvKlZhhichFyys4JG4Cu4ia8b7ApicPFME2HT2fQtrjYhOQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.5661375661375662" data-s="300,640" data-type="png" data-w="945" type="block" data-imgfileid="503526059" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/f4c18190-f718-4b9f-8d5f-1c6d3ca292f7/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;在人类参考基因组数据集上，使用 PoPE 的模型 NLL（4.152）显著低于 RoPE 基线（4.217）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeoI9SrxNb62b2t9sQGhCs7vzfxMFeiaDIicQwTdibo5DaOVgRqDiaCU8MKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.439572192513369" data-s="300,640" data-type="png" data-w="935" type="block" data-imgfileid="503526060" data-aistatus="1" data-original-style="null" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/1a935b50-4be2-4cb8-9620-1fa0d20e21b3/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;语言建模&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 OpenWebText 数据集上，该团队测试了三种规模的模型（124M、253M、774M）。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeYoVUgLggoIMTDw2iaTwWH369UnmlZjbbyUADicqvlFGqJicbGVTgU5sQQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.4426840633737186" data-s="300,640" data-type="png" data-w="1073" type="block" data-imgfileid="503526061" data-aistatus="1" data-original-style="null" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/0941c39c-bc1a-4ae1-a0b0-d9c424843215/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;结果来看 ，在所有规模下，PoPE 的困惑度均始终低于 RoPE。&lt;/p&gt;&lt;p&gt;而在 LAMBADA、CBT、HellaSwag 等六项下游任务的零样本评估中，PoPE 在所有模型规模下的平均准确率均高于 RoPE。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibelt2iboMUDdEkSWF2ZB44TblkmDEhtcXkVLDHaFd2LjyME91DuicJd9Qw/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.287962962962963" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526062" data-aistatus="1" data-original-style="null" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/cce44a16-5d08-4580-bbaf-ec77dfd8767e/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;测试时长度外推&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该团队在 1024 个 token 上训练模型，并在长达 10240 个 token 的序列上评估。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeib3LV0ibZLoC1pm4wV8U2HPH0YMPBBhDmBSwXcGfjKw8n0PmQdSugybg/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="0.7" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526063" data-aistatus="1" data-original-style="null" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/e2f28f86-f598-405d-8e4a-728c64d48ff2/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;RoPE 的性能在长序列上显著下降。YaRN 在超过其微调长度后也会失效。&lt;/p&gt;&lt;p&gt;可以看到，PoPE 优势是在无需任何微调或插值的情况下，显示出强大的开箱即用外推能力，甚至优于专门的基线模型 YaRN。&lt;/p&gt;&lt;p&gt;PoPE 的稳定性也不错： RoPE 的外推性能随模型规模增加而恶化，而 PoPE 则保持大体稳定。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/agopal42/status/2003900824909746344&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>重新定义视频大模型时序定位！南大腾讯联合提出TimeLens，数据+算法全方位升级</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Sat, 03 Jan 2026 00:06:46 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-03</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-03</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg#imgIndex=0" data-ratio="0.5703703703703704" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503474619" data-aistatus="1" data-original-style="null" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/e9e7218a-2940-4b27-9356-9bf369f53e10/640.png" alt="图片" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;随着多模态大模型（MLLMs）的飞速发展，模型已经能够很好地理解视频中 &amp;ldquo;发生了什么（What）&amp;rdquo;，却无法精准地定位到事件在视频中 &amp;ldquo;何时发生（When）&amp;rdquo;。这种视频时序定位（Video Temporal Grounding, VTG）能力的严重缺陷，已成为制约 MLLM 迈向更精细化的视频理解的主要瓶颈。&lt;/p&gt;&lt;p&gt;长期以来，大量研究致力于设计复杂的模型结构，却忽视了两个关键问题：&lt;strong&gt;在数据层面，我们依赖的评测基准是否可靠？在算法层面，是否存在一套简洁通用的最佳实践？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对上述痛点，来自南京大学、腾讯 ARC Lab 和上海 AI Lab 的联合研究团队提出了 &lt;strong&gt;TimeLens&lt;/strong&gt;（时间透镜），系统性地揭示了现有数据的&amp;ldquo;评测陷阱&amp;rdquo;，构建出更可靠的评测基准和高质量训练数据，并探索出一套简洁有效的算法优化。得益于这些贡献，仅 &lt;strong&gt;8B 参数的 TimeLens 模型成为了开源模型中的新 SOTA&lt;/strong&gt;，更击败了 GPT-5 和 Gemini-2.5-Flash 等闭源巨头。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeaF1ka77WfhkTbGQTpWESwknglFOETcagqPEWJaJPoicc3pjicV21GSFg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.1527777777777778" data-type="png" data-w="1080" data-width="2938" data-height="448" data-imgfileid="503526103" data-aistatus="1" data-original-style="null" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/e55c517a-23f7-4c9d-ba05-8b323426f772/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="864" data-imgfileid="503526105" data-ratio="0.48333333333333334" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeox3Tw0YXruSXJJgDbTC44uBYg8Yf4MH5kBWKicPvnyXNe15f1neouGg/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-type="png" data-w="1080" data-width="1787" data-original-style="null" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/973b5ada-e72d-4d3d-8b74-3cdaa744435a/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文链接： https://arxiv.org/abs/2512.14698&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;项目主页： https://timelens-arc-lab.github.io/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代码链接： https://github.com/TencentARC/TimeLens&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;核心洞察：拨开数据质量的迷雾&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在深度学习中，&amp;ldquo;Data is fuel&amp;rdquo;（数据即燃料）是公认的真理。然而，团队发现，在 VTG 领域，燃料的质量却令人担忧。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 现有基准的 &amp;ldquo;隐形陷阱&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队通过一套标注流水线，对 Charades-STA、ActivityNet Captions 和 QVHighlights 等主流基准进行了严格的人工核验，发现这些基准数据集中充斥着大量的标注错误。许多样本中的文本描述模糊不清，或是文本描述的事件在视频中根本未出现。标注方面，也存在大量的时间边界标注错误，或是同一描述对应了视频中的多个片段却只标注了其中之一（漏标）。统计数据显示，这些错误在现有基准中的比例极高。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="406" data-imgfileid="503526106" data-ratio="0.2388888888888889" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibejkwWTPTQ6Bf4eU3ZRUjLy2Y5mUXSaPgGbkqMbhrEoOjNULiaeQsgUKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-type="png" data-w="1080" data-width="1700" data-original-style="null" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/d682fe04-d30b-48ef-987b-517ee7e931a9/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="1045" data-imgfileid="503526107" data-ratio="0.3527777777777778" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeWzCKg5tFBc7sq1whlzxTENwiazdZ1KdSn5poB6ryciaL5nzsaL2Gwf4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-type="png" data-w="1080" data-width="2964" data-original-style="null" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/a43170c9-ef78-46b6-bb90-bdf914b7ad89/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. TimeLens-Bench：对评估结果的&amp;ldquo;拨乱反正&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了解决现有数据集中存在的严重错误，团队构建了严格的标注准则，对上述三个基准数据集进行了全面的修复和重新标注，推出了 &lt;strong&gt;TimeLens-Bench&lt;/strong&gt;。这是一个经过严格交叉验证的高质量评测基准，能够更真实地反映模型的时序定位能力。&lt;/p&gt;&lt;p&gt;将 TimeLens-Bench 和原始 Benchmark 上的评测结果进行对比，揭露了过往评估结果的&lt;strong&gt;不可靠&lt;/strong&gt; &amp;mdash;&amp;mdash; 旧基准严重高估了开源模型的能力，而掩盖了前沿闭源模型（如 Gemini）的真实水平。TimeLens-Bench 对这一错误进行了拨乱反正，事实上，现有开源模型仍明显落后于闭源模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="973" data-imgfileid="503526109" data-ratio="0.7083333333333334" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibevbcLia2N9dCZhln1Qds3PM7YIrqEp3tJLH5UQnA5vCdntx6Ma0zezyA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" data-width="1374" data-original-style="null" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/479cf3fe-2444-47ec-a9ae-e2a1f566fb78/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 高质量训练数据：TimeLens-100K&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对同样低质量的训练数据，团队设计了一套自动化流水线，对训练数据进行了大规模的清洗和重标，发布了高质量的大型训练数据集 TimeLens-100K。实验证明，数据质量的提升能带来显著的性能增长。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="196" data-imgfileid="503526110" data-ratio="0.11388888888888889" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeWiauP93DPbiaIfhQXL13T0f0uvVjysLRdYHrBU9icGNgcPVmzvr5TY7iaw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-type="png" data-w="1080" data-width="1727" data-original-style="null" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/8f8dcbb9-765d-4e55-8eb1-a087b7c7181d/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;算法设计的&amp;ldquo;最佳实践&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在夯实数据基础后，TimeLens 进一步对 MLLM 在 VTG 任务上的算法设计进行了全方位的消融实验，从时间戳编码到训练范式，总结出一套简洁有效的 &amp;ldquo;最佳实践&amp;rdquo;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 简洁有效的时间戳编码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;时间戳编码（timestamp encoding）是 VTG 任务中的关键模型结构设计，决定了模型能否准确地感知到输入的每一视频帧的采样时间。&lt;/p&gt;&lt;p&gt;团队全面地对比了各种时间戳编码方式的优劣。实验结果表明，最优的时间戳编码方式是简单的&lt;strong&gt;交错文本编码&lt;/strong&gt;（Interleaved Textual Encoding） 策略，即在每一帧的视觉 Token 前插入文本形式的时间戳 token。这种方法无需修改 LLM 的底层架构，保证了实现上的简洁，同时还能取得最优的效果。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeKyI2hqwNGNRYoxbW5TAcic4gTM1ShSNZd8ibVe4f5DAnEYsxRX3UfBibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.26666666666666666" data-type="png" data-w="1080" data-width="3886" data-height="1035" data-imgfileid="503526111" data-aistatus="1" data-original-style="null" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/9c2ddb74-b23b-4526-b02b-b794eff208b8/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="396" data-imgfileid="503526112" data-ratio="0.2574074074074074" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6miberNNLLV9cJ6Qf4TI7hu1QBp1ZjxiaqxibVHzWnLP2bic5ic8Qbiau4TibibGlA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-type="png" data-w="1080" data-width="1536" data-original-style="null" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/ccbf81ec-c287-42ea-a32c-3eed08cae6b3/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;2. 训练范式：Thinking-free RLVR 的胜利&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着 DeepSeek-R1 等一系列工作的提出，带有可验证奖励机制的强化学习（RLVR）范式在提升模型推理能力方面的作用备受关注。而在 VTG 领域，关于训练范式的几个关键问题尚无定论：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;有监督微调（SFT）仍是 VTG 领域最为主流的训练范式，RLVR 范式在同样的训练开销下，是否明显优于 SFT？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;时序定位任务是一个以感知 (Perception) 而非推理 (Reasoning) 为主的任务。针对这样的任务进行 RLVR 训练时，显式的思考过程（thinking）是否是必须的？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SFT+RLVR 的多阶段训练，是否比单阶段训练的效果更好？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TimeLens 对比了多种训练范式的优劣。结论出人意料且极具启发性：单阶段的 Thinking-free RLVR 训练范式在计算效率和性能上均取得了最优。该范式直接让模型输出定位结果，并根据定位准确率（IoU）给予奖励。这种方式不需要生成冗长的中间思考过程，训练和推理效率高于 Thinking-based RLVR 范式和多阶段训练范式，且性能优于 SFT 范式。&lt;/p&gt;&lt;p&gt;这一结果表明，对于时序定位这种偏向感知（Perception-heavy）的任务，显式的思考过程不是必须的。 模型可以直接学习从任务输入到输出的映射，不需要进行复杂的逻辑推理。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-height="402" data-imgfileid="503526113" data-ratio="0.2611111111111111" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibepiaOFq8wlecEqicowyXRZr42pahuRYuIddv7sRibr1NpsE93nMFGPLUrg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-type="png" data-w="1080" data-width="1538" data-original-style="null" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/353c8d3e-0a18-4d1a-b779-827a11ecdba1/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3. 关键训练技巧：Early Stopping 与 Difficulty-based Sampling&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;针对&lt;strong&gt; Thinking-free RLVR &lt;/strong&gt;范式，团队进行了更加深入的实验探究，发现了两个关键的训练技巧。&lt;/p&gt;&lt;p&gt;首先，与 SFT 中 &amp;ldquo;训练越久越好&amp;rdquo; 的共识不同，在 RL 训练中，当奖励指标进入平台期后，就应该采用&lt;strong&gt;早停策略&lt;/strong&gt;（Early Stopping） 立即停止训练，在该阶段之后继续训练反而会使得模型的性能下降。&lt;/p&gt;&lt;p&gt;其次，&lt;strong&gt;基于难度的数据采样&lt;/strong&gt;（Difficulty-based Sampling） 至关重要。即使数据的标注质量有保证，也并非所有的数据都适合用于 RLVR 训练。需要预先使用待训练的模型进行推理，评估每个训练样本的难度，采样足够具有挑战性的样本进行 RLVR 训练，才能最大程度上提升模型的性能。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeDL8rq0biatiahy70w1iaXPibVzkIL6MNMLTRdFXcX6hiapaiaN0l9eHDSjAg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.3675925925925926" data-type="png" data-w="1080" data-width="2760" data-height="1014" data-imgfileid="503526114" data-aistatus="1" data-original-style="null" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/1835b9fe-1834-4ff4-af18-577df00a3ffe/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;实验验证：8B 模型逆袭闭源巨头&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队将上述数据和算法层面的所有改进聚合在了一起，每一项技术都带来了明显的性能提升，最终得到了 TimeLens 系列模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibehQibUAQOrgM0zHPuzfTibyRiaJ8eIZ3tTHA7vq6MPeM9DJNQ2aqShzuKg/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.674074074074074" data-type="png" data-w="1080" data-width="1134" data-height="764" data-imgfileid="503526115" data-aistatus="1" data-original-style="null" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/ea53279c-b3cf-4f4a-af09-9c4ec9afc496/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;评测结果表明，TimeLens-8B 展现出了惊人的性能，不仅大幅超越了 Qwen3-VL 等开源模型成为新的开源 SOTA，更以 8B 的参数量，在多项核心指标上全面击败了 GPT-5 和 Gemini-2.5-Flash 等前沿的闭源模型。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9EricQXXByphb4tN0ha6mibeu87R7erOKZ2jJ5UmVU3ZbVJVbyGq75STdswAJJc1gxNMxFr9mONkBQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.37222222222222223" data-type="png" data-w="1080" data-width="2938" data-height="1094" data-imgfileid="503526116" data-aistatus="1" data-original-style="null" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/1b7bd186-bae8-4c99-a8b4-aaad1ab1f37b/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;这一结果有力地证明了：在 VTG 任务中，通过系统性地提升数据质量并采用有效的算法设计，开源小尺寸模型完全具备挑战甚至超越闭源大模型的能力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;TimeLens 的贡献不止于一个 SOTA 开源模型。团队在数据和算法双维度的系统性探索，为后续研究提供了极具参考价值的方法论与设计蓝图。&lt;/p&gt;&lt;p&gt;目前，TimeLens 的代码、模型、训练数据和评测基准都已开源，希望能为未来的视频时序定位研究提供一个更好的起点。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>刚刚，梁文锋署名，DeepSeek元旦新论文要开启架构新篇章</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 02 Jan 2026 01:09:42 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-02-7</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-02-7</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;span data-pm-slice='1 1 ["para",{"tagName":"p","attributes":{"style":"text-align: justify; margin-left: 8px; margin-right: 8px; line-height: 1.75em;"},"namespaceURI":"http://www.w3.org/1999/xhtml"}]'&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/0a2a2f50-06ff-4f41-b0ff-35c5077d020b/1767287211074.png" style="width: 700%;" class="fr-fic fr-dib"&gt;新年第一天，&lt;/span&gt;DeepSeek 发布了一篇新论文，提出了一种名为 &lt;strong&gt;mHC &lt;/strong&gt;（流形约束超连接）的新架构。&lt;/p&gt;&lt;p&gt;该研究旨在解决传统超连接在大规模模型训练中的不稳定性问题，同时保持其显著的性能增益 。&lt;/p&gt;&lt;p&gt;简单来说，DeepSeek 提出的 mHC 通过将传统 Transformer 的单一残差流扩展为多流并行架构，并利用 Sinkhorn-Knopp 算法将连接矩阵约束在双拟随机矩阵流形上，成功解决了超连接（HC）在大规模训练中因破坏恒等映射属性而导致的数值不稳定和信号爆炸问题。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu4ibOU6Pz3DBge7SsWpXibRTJUlDfwKstNXItYjzdcz5d8mjEHRCsSpUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.4009259259259259" data-type="png" data-w="1080" data-width="1857" data-height="744" data-backw="578" data-backh="232" data-imgfileid="503526531" data-aistatus="1" data-original-style="width: 100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/681fb9b4-e28c-4518-a6ab-f48e27aadcee/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;论文标题：mHC: Manifold-Constrained Hyper-Connections&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;论文地址：https://arxiv.org/pdf/2512.24880&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这篇论文的第一作者有三位：Zhenda Xie（解振达）、Yixuan Wei（韦毅轩）、Huanqi Cao。值得注意的是，&lt;strong&gt;DeepSeek 创始人 &amp;amp; CEO 梁文锋也在作者名单中&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;传统的残差连接（即 Transformer 中的 x + F (x) 结构）凭借「恒等映射」保证了信号无损传输和训练稳定性。但它的瓶颈在于信息通道的宽度受限于隐藏层维度 C。&lt;/p&gt;&lt;p&gt;近期，以字节跳动Seed团队提出的 Hyper-Connections (HC) 为代表的研究，通过扩展残差流宽度和多样化连接模式，拓展了过去十年中广泛应用的残差连接范式。&lt;/p&gt;&lt;p&gt;虽然这些方法带来了显著的性能提升，但但也带来了两个严重问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数值不稳定性&lt;/strong&gt;： 原始的 HC 中，连接矩阵是自由学习的，没有约束。这导致信号在经过多层传播后，数值会「爆炸」或「消失」，破坏了恒等映射的特性，模型越深越难训练。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;系统开销大&lt;/strong&gt;： 通道变宽意味着显存读写 (I/O) 和通信成本成倍增加，也就是所谓的「显存墙」问题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从根本上破坏了残差连接固有的恒等映射属性，导致了严重的训练不稳定性和受限的可扩展性，并额外增加了显著的内存访问开销。&lt;/p&gt;&lt;p&gt;为了解决这些挑战，DeepSeek 的研究团队提出了 &lt;strong&gt;Manifold-Constrained Hyper-Connections (mHC，流形约束超连接)&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这是一个通用框架，它将 HC 的残差连接空间投影到一个特定的流形上，以恢复恒等映射属性，同时结合严格的基础设施优化以确保效率。&lt;/p&gt;&lt;p&gt;它的核心目的是：&lt;strong&gt;在保留「加宽残差流」带来的性能提升的同时，解决其导致的训练不稳定和显存消耗过大的问题&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;团队利用 &lt;strong&gt;Sinkhorn-Knopp 算法&lt;/strong&gt;将残差连接矩阵投影到 Birkhoff 多胞形（双随机矩阵）上。这使得信号传播变为特征的「凸组合」，从数学上严格保证了信号范数的稳定性（能量守恒）。为了抵消加宽通道带来的开销，团队实施了&lt;strong&gt;内核融合、选择性重计算以及扩展的 DualPipe 通信计算重叠策略&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;实证表明，mHC 不仅解决了稳定性问题，且在大规模训练中（如 27B 模型）表现出卓越的可扩展性。&lt;strong&gt;在 n=4 的扩展倍率下，仅增加了 6.7% 的训练时间开销，却换来了显著的性能提升&lt;/strong&gt;。mHC 为基础模型的拓扑架构演进指明了方向。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuWc4rRxWWuzV7IUSlo17DsmhkM2SXmyib8GhSjZwFOMuUODAlUZKLF2w/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.5333333333333333" data-type="png" data-w="1080" data-width="1230" data-height="656" data-backw="578" data-backh="308" data-imgfileid="503526532" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/f8d34b49-ef0d-4acf-8fc3-d5f184dd9420/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 1：残差连接范式示意图。 本图对比了以下三种结构设计： (a) 标准残差连接（Residual Connection）； (b) Hyper-Connections (HC)； (c) 我们提出的 Manifold-Constrained Hyper-Connections (mHC)。与无约束的 HC 不同，mHC 专注于优化残差连接空间，通过将矩阵投影到受约束的流形上，以确保稳定性。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;具体方法介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;流形约束超连接 (mHC)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;借鉴恒等映射（Identity Mapping）原则，mHC 的核心前提是将残差映射 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIugGo3g9vnssrHcqvTZAa0oALLlicOeq2OTTKa4B6c3FfHZ8JG3yJCciaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="78" type="block" data-imgfileid="503526513" data-aistatus="1" data-original-style="width:26px;height:20px;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/5d0e0bd6-a5db-457b-862c-873520cf847f/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dii" style="width: 4.4%;"&gt;&amp;nbsp;约束在一个特定的流形上。&lt;/p&gt;&lt;p&gt;虽然原始的恒等映射是通过强制执行 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuw3bqSd6T1fPT6KuNudXzSIIGicYbS5qN6KPFTQpL6LL44Xv87TW7ic1Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.35294117647058826" data-s="300,640" data-type="png" data-w="136" type="block" data-imgfileid="503526514" data-aistatus="1" data-original-style="width:44px;height:20px;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/3d287c0e-7288-4eae-8eea-9bc58f24b2da/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dii" style="width: 7.15%;"&gt;&amp;nbsp;来确保稳定性，但它能从根本上阻止残差流内部的信息交换，而这种交换对于最大化多流架构的潜力至关重要。&lt;/p&gt;&lt;p&gt;因此，该 DeepSeek 团队提出&lt;strong&gt;将残差映射投影到一个流形上&lt;/strong&gt;，既能保持跨层信号传播的稳定性，又能促进残差流之间的相互作用，以保持模型的表达能力（expressivity）。&lt;/p&gt;&lt;p&gt;为此，他们的做法是将 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIugGo3g9vnssrHcqvTZAa0oALLlicOeq2OTTKa4B6c3FfHZ8JG3yJCciaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="78" type="block" data-imgfileid="503526513" data-aistatus="1" data-original-style="width:26px;height:20px;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/e379e966-3f77-45c2-82aa-ce80637dda67/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dii" style="width: 4.86%;"&gt;&amp;nbsp;限制为&lt;strong&gt;双拟随机矩阵&lt;/strong&gt;（Doubly Stochastic Matrix），即具有非负项且行和与列和均为 1 的矩阵。&lt;/p&gt;&lt;p&gt;形式上，令 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuLB4EiaMkymEvvjpXDSCxdhJcHw4nb4SRs6iaMrofib4lTjpdpT7F0e9Tw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.5058823529411764" data-s="300,640" data-type="png" data-w="85" type="block" data-imgfileid="503526515" data-aistatus="1" data-original-style="width:33px;height:20px;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/d0854374-79a4-45b2-bef6-d72ebe704698/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dii" style="width: 5.5%;"&gt; 表示双拟随机矩阵的流形（也称为 Birkhoff 多胞形），再将 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIugGo3g9vnssrHcqvTZAa0oALLlicOeq2OTTKa4B6c3FfHZ8JG3yJCciaA/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="78" type="block" data-imgfileid="503526513" data-aistatus="1" data-original-style="width:26px;height:20px;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/37cec6ac-b28a-4bbc-8e8d-a2157fed32ed/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dii" style="width: 4.4%;"&gt; 约束在 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuib5icCv1jUl2IdROrlmyG5kQG7V7LbLV6ydCQJFzynEtvMkHDBPGAmEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="0.2663316582914573" data-s="300,640" data-type="png" data-w="199" type="block" data-imgfileid="503526517" data-aistatus="1" data-original-style="width:64px;height:20px;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/bda87b21-963c-4191-b8df-a371fdb2bf8d/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dii" style="width: 10.45%;"&gt;&amp;nbsp;中，定义为：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuK61YoYvSGHRibexohJsAjhGp3dxwdpglHJsw9yn7DU3rPdlbHj4F1Zg/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.06296296296296296" data-s="300,640" data-type="png" data-w="1080" type="block" data-imgfileid="503526518" data-aistatus="1" data-original-style="width:488px;height:31px;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/3b334315-7815-4d40-affe-73810776779c/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 1_n 表示全 1 的 n 维向量。&lt;/p&gt;&lt;p&gt;为什么选择双拟随机性？因为其具有多项有利于大规模训练的理论属性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;范数保持&lt;/strong&gt;：其谱范数有界且不超过 1（即 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuKWSLATvszgrAaUHMwGiapQEvzic4UzY8WQRxQT55shibuhQSaBjlDeCgA/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.25" data-s="300,640" data-type="png" data-w="192" type="block" data-imgfileid="503526516" data-aistatus="1" data-original-style="width:64px;height:20px;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/13d8b516-5e4b-48b9-9d8f-e33655a902c4/640.png" alt="图片" data-report-img-idx="15" data-fail="0" class="fr-fic fr-dii" style="width: 10.36%;"&gt;&amp;nbsp;），这意味着学习到的映射是非扩张的，可有效缓解梯度爆炸问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;复合封闭性&lt;/strong&gt;：双拟随机矩阵集对矩阵乘法具有封闭性，确保了跨多层的复合残差映射仍保持双拟随机，从而可在整个模型深度上维持稳定性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;几何解释&lt;/strong&gt;：该集合构成了 Birkhoff 多胞形，是排列矩阵集的凸包。这意味着残差映射充当了排列的凸组合，其重复应用会单调地增加跨流的信息混合，起到鲁棒的特征融合作用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，该团队还对输入映射 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuj3M0wYDbRRVV308EG6QT3pxicF0WyPK1lTjGt3Wstxy6myJCILvpRXA/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.7164179104477612" data-s="300,640" data-type="png" data-w="67" type="block" data-imgfileid="503526519" data-aistatus="1" data-original-style="width:27px;height:20px;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/ec50d175-f532-4f48-a627-a3a6c1cd3f9d/640.png" alt="图片" data-report-img-idx="16" data-fail="0" class="fr-fic fr-dii" style="width: 4.95%;"&gt; 和输出映射 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuyjIvia1xUpYibv39gAfldygWiawc4Mgh6WSdW7hM2F8uGGa3lt1ebeYwg/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.6" data-s="300,640" data-type="png" data-w="75" type="block" data-imgfileid="503526520" data-aistatus="1" data-original-style="width:35px;height:21px;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/a2f18adb-002b-461c-808e-59cf8430f686/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dii" style="width: 6.05%;"&gt;&amp;nbsp;施加了非负约束，以防止因正负系数复合导致的信号抵消。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参数化与流形投影&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本节将详述 mHC 中各映射的计算过程。&lt;/p&gt;&lt;p&gt;给定第 l 层的输入隐藏矩阵 x_l，先将其展平为向量 &amp;nbsp;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIukF9M9WPW5uGibN4tsiaYpKMPoe4cRRBUxMZF8UEanjrLN7Rj4gPQdPkg/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.14285714285714285" data-s="300,640" data-type="png" data-w="252" type="block" data-imgfileid="503526521" data-aistatus="1" data-original-style="width:154px;height:22px;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/854fcc4a-b40a-4a4d-83d1-1dbdd48a405c/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dii" style="width: 17.78%;"&gt;&amp;nbsp;以保留完整的上下文信息。然后，按照 HC 的原始公式获取动态映射和静态映射：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu7Ranvm6vcNZuKB3RNRZibaonaeH3iaFYZAb4q5H5o0dzuk5ltcVTiaeibA/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.22936893203883496" data-s="300,640" data-type="png" data-w="824" type="block" data-imgfileid="503526522" data-aistatus="1" data-original-style="null" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/7e9baf9a-e757-439c-a6ed-bb6294999897/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;最终的约束映射通过以下方式获得：&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuXF246icVr0aA4Pa6vicrvYNNxwA9jquJN12eWO4VOgqJvDdXR76jMPgg/640?wx_fmt=png&amp;from=appmsg#imgIndex=15" data-ratio="0.1710843373493976" data-s="300,640" data-type="png" data-w="830" type="block" data-imgfileid="503526523" data-aistatus="1" data-original-style="null" data-index="17" src="https://image.jiqizhixin.com/uploads/editor/8028392c-1845-479e-85b2-6e14d12c5cbe/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;其中 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIudcx4h5nDpb121KduPQ3PRFuo5G81xeanCfBdYzCzXn79NH4j4rUmSw/640?wx_fmt=png&amp;from=appmsg#imgIndex=16" data-ratio="0.5405405405405406" data-s="300,640" data-type="png" data-w="74" type="block" data-imgfileid="503526533" data-aistatus="1" data-original-style="width:41px;height:22px;" data-index="18" src="https://image.jiqizhixin.com/uploads/editor/5986ae35-dfa1-40a4-848a-f0df17f7abdf/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dii" style="width: 5.32%;"&gt;&amp;nbsp;是 Sigmoid 函数。Sinkhorn-Knopp 算子首先通过指数操作确保所有元素为正，然后进行迭代规范化，交替缩放行和列使其和为 1。&lt;/p&gt;&lt;p&gt;DeepSeek 在实验中采用 t_max=20 次迭代。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;高效基础设施设计&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeepSeek 还为 mHC 量身定制了基础设施设计，使其在 n=4 时在大模型中的训练开销仅增加 6.7%：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算子融合 (Kernel Fusion)&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;重新调整 RMSNorm 的顺序以提高效率，并采用混合精度策略。&lt;/p&gt;&lt;p&gt;开发了统一的算子，将多次扫描和矩阵乘法融合，减少内存带宽瓶颈和算子启动开销。&lt;/p&gt;&lt;p&gt;在单个算子中实现 Sinkhorn-Knopp 迭代及其自定义反向传播。&lt;/p&gt;&lt;p&gt;将 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIulme6ZlkBhd9ax9fn6cPzhh8IXJiawMXGiamO7nBnmItTCFLO9okpOibUg/640?wx_fmt=png&amp;from=appmsg#imgIndex=17" data-ratio="0.6" data-type="png" data-w="75" data-width="75" data-height="45" data-imgfileid="503526534" data-aistatus="1" data-original-style="width:33px;height:20px;" data-index="19" src="https://image.jiqizhixin.com/uploads/editor/40c52fbe-7188-4658-bdf5-6ef61932eb90/640.png" alt="图片" data-report-img-idx="17" data-fail="0" class="fr-fic fr-dii" style="width: 5.5%;"&gt; 和 &lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu9yGvSDeqia4icCzhic67UZmxxK35b25IKmmypHAf7rKaxibVVpzZpPay4w/640?wx_fmt=png&amp;from=appmsg#imgIndex=18" data-ratio="0.7164179104477612" data-type="png" data-w="67" data-width="67" data-height="48" data-imgfileid="503526535" data-aistatus="1" data-original-style="width:28px;height:20px;" data-index="20" src="https://image.jiqizhixin.com/uploads/editor/93b76360-6e01-431a-8b51-1e1e0328926c/640.png" alt="图片" data-report-img-idx="18" data-fail="0" class="fr-fic fr-dii" style="width: 4.49%;"&gt;&amp;nbsp;的应用与残差合并融合，显著减少了内存读写量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重计算 (Recomputing)&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;为了减轻 n 流设计带来的内存压力，DeepSeek 在前向传播后丢弃 mHC 算子的中间激活，并在反向传播时即时重新计算。&lt;/p&gt;&lt;p&gt;通过推导得出最优重计算块大小 L_r^*，以最小化总内存占用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DualPipe 中的通信重叠&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;扩展了 DualPipe 调度算法，以改善流水线并行阶段边界处的通信与计算重叠在专用高优先级计算流上执行 MLP 层的内核，并避免在注意力层使用持久算子，以防止阻塞通信流并提高设备利用率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;研究团队通过语言模型预训练来验证所提方法的有效性，并对基线模型、超连接（HC）以及提出的流形约束超连接（mHC）进行了对比分析。&lt;/p&gt;&lt;p&gt;他们采用了受 DeepSeek-V3 启发的 MoE 架构，训练了四种不同的模型变体，以覆盖不同的评估体系。&lt;/p&gt;&lt;p&gt;具体而言，HC 和 mHC 的扩展率 n 均设置为 4，主要关注点是一个 27B 参数规模的模型。其训练数据集的大小与其参数量成正比，该模型用于展示系统层面的主要结果。在此基础上，他们通过引入使用成比例数据训练的较小的 &amp;nbsp;3B 和 9B 模型来分析计算扩展性，从而观察不同计算规模下的性能趋势。此外，为了专门研究 Token 规模的影响，他们另外训练了一个独立的 3B 模型，该模型在一个固定的 1T Token 的语料库上进行训练。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuLlqLwFqxfSLovsicuarmZteM7p8njq0JAtJOhm6g8MysNGticDYD7V1w/640?wx_fmt=png&amp;from=appmsg#imgIndex=19" data-ratio="1.402" data-s="300,640" data-type="png" data-w="1000" type="block" data-backw="578" data-backh="810" data-imgfileid="503526526" data-aistatus="1" data-original-style="width: 100%;" data-index="21" src="https://image.jiqizhixin.com/uploads/editor/bcf2c93c-8dad-4aaf-ab46-aece171d8f7d/640.png" alt="图片" data-report-img-idx="19" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;主要结果&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuoWYsiaDtI3Coib2VN5HxR2sHUDOlkAV47JTYWAzkic7xZXialibta3KgEibw/640?wx_fmt=png&amp;from=appmsg#imgIndex=20" data-ratio="0.30628803245436104" data-s="300,640" data-type="png" data-w="986" type="block" data-backw="578" data-backh="177" data-imgfileid="503526524" data-aistatus="1" data-original-style="width: 100%;" data-index="22" src="https://image.jiqizhixin.com/uploads/editor/10a5f90c-c963-416d-beed-5648a508e81c/640.png" alt="图片" data-report-img-idx="20" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 5：流形约束超连接 (mHC) 的训练稳定性。 该图展示了：(a) mHC 和 HC 相对于基线模型的训练损失绝对差值；(b) 三种方法在训练过程中的梯度范数。所有实验均基于 27B 参数规模的模型。实验结果表明，mHC 在损失函数和梯度范数两方面均表现出更优的稳定性。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;研究团队首先考察 27B 模型的训练稳定性和收敛性。如图 5 (a) 所示，mHC 有效缓解了在 HC 中观察到的训练不稳定问题，与基线模型相比，最终损失降低了 0.021。图 5 (b) 中的梯度范数分析进一步证实了这种稳定性的提升：mHC 表现出明显优于 HC 的行为，保持了与基线模型相当的稳定轮廓。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu5WnO9MoZCYyNMOpOOYUh2HxhocYrc0jdMtnNaibQvpFmZIibDEjmvcHw/640?wx_fmt=png&amp;from=appmsg#imgIndex=21" data-ratio="0.20773930753564154" data-s="300,640" data-type="png" data-w="982" type="block" data-backw="578" data-backh="120" data-imgfileid="503526525" data-aistatus="1" data-original-style="width: 100%;" data-index="23" src="https://image.jiqizhixin.com/uploads/editor/2003584e-34b9-4f4b-87cc-b7650953e7d9/640.png" alt="图片" data-report-img-idx="21" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;表 4：27B 模型在系统级基准测试上的结果。 本表对比了基线模型、HC 以及 mHC 在 8 个不同的下游基准测试中的零样本和少样本性能表现。结果显示，mHC 始终优于基线模型，并在大多数基准测试中超越了 HC，证明了其在大规模预训练中的有效性。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;表 4 展示了在多种下游基准测试中的性能表现。mHC 带来了全面的提升，一致性地优于基线模型，并在大多数任务上超过了 HC。值得注意的是，与 HC 相比，mHC 进一步增强了模型的推理能力，在 BBH &amp;nbsp;和 DROP 任务上分别实现了 2.1% 和 2.3% 的性能增益。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规模扩展实验&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuBNFBJ1DJOUqZN74REIv9vkeqGibHPIvG64YfLLR2zCT5gqgkwWXIzCA/640?wx_fmt=png&amp;from=appmsg#imgIndex=22" data-ratio="0.27070707070707073" data-s="300,640" data-type="png" data-w="990" type="block" data-backw="578" data-backh="156" data-imgfileid="503526527" data-aistatus="1" data-original-style="width: 100%;" data-index="24" src="https://image.jiqizhixin.com/uploads/editor/169a42bc-fc86-4f41-b003-5ff35fcea3a1/640.png" alt="图片" data-report-img-idx="22" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;图 6：mHC 与基线模型的扩展特性对比。 (a) 计算扩展曲线：实线描绘了在不同计算预算下的性能差距。每个点代表模型大小与数据集大小的最优计算配置，涵盖了从 3B、9B 到 27B 参数规模的规模扩展过程。 (b) Token 扩展曲线：展示了 3B 模型在训练过程中的轨迹。每个点代表模型在不同训练 Token 数量下的性能表现。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;为了评估该方法的扩展性，研究者报告了在不同规模下 mHC 相对于基线模型的损失改善情况。在图 6 (a) 中，他们绘制了涵盖 3B、9B 和 27B 参数规模的计算规模扩展曲线。其轨迹表明，即使在更高的计算预算下，性能优势依然稳健地得以保持，仅表现出轻微的衰减。&lt;/p&gt;&lt;p&gt;此外，他们在图 6 (b) 中考察了训练过程中的动态变化，展示了 3B 模型的 Token 扩展曲线。总的来看，这些发现验证了 mHC 在大规模场景下的有效性。这一结论在他们内部的大规模训练实验中得到了进一步的证实。&lt;/p&gt;&lt;p&gt;更多详情请参阅原论文。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>OpenDataArena全面升级版正式上线，四大核心模块重构数据价值评估新格局</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 02 Jan 2026 01:03:49 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-02-6</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-02-6</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBvLRsVGY4rRKCGuKKSkOqnGrvGwXxqqDxHlia88ZCbqyicswl2HC89BcZA/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1#imgIndex=0" alt="图片" data-ratio="0.5703703703703704" data-w="1080" data-backw="562" data-backh="321" data-aistatus="1" data-original-style="width: 100%;" data-index="2" src="https://image.jiqizhixin.com/uploads/editor/aa4f0fb5-3a49-451d-916d-458a24b75256/640.png" data-report-img-idx="0" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/p&gt;&lt;p&gt;为破解长期以来学界与业界难以对数据进行价值量化的困局，上海人工智能实验室（上海 AI 实验室）OpenDataLab 团队在今年 8 月正式开源了首个全面、公正的后训练数据价值评测平台 &amp;mdash;&amp;mdash;&lt;strong&gt;OpenDataArena (ODA)&amp;nbsp;&lt;/strong&gt;。该项目致力于将数据选择从「盲目试错」的炼丹术，转变为一门可复现、可分析、可累积的严谨科学。&lt;/p&gt;&lt;p&gt;在初版系统发布后的数月间，项目通过团队内部及小范围社区用户的深度使用，完成了高强度的技术验证与功能打磨。伴随着评测规模、工具链和分析能力的持续扩展，近期，我们终于迎来了&amp;nbsp;&lt;strong&gt;ODA 的全面升级 &amp;mdash;&amp;mdash; 一个结论更系统、功能更完整、视角更多元的正式版本&lt;/strong&gt;，该项目正式面向全体开发者开放。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LM6uxpktbPYekOKeBKON1I7SMKwknL0HibqTfcldgk2ticFCXR44nqZtw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="0.3851851851851852" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="223" data-imgfileid="503526368" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/7a96b038-a3ea-456a-8284-42b2e43c785f/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;项目主页： https://opendataarena.github.io/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开源工具： https://github.com/OpenDataArena/OpenDataArena-Tool&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据集： https://huggingface.co/OpenDataArena/datasets&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;报告链接：https://arxiv.org/pdf/2512.14051&amp;nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ODA 的核心理念非常明确：数据价值必须通过真实的训练来检验，而非主观的臆测。为此，我们&lt;strong&gt;立足于全新发布的正式版本，对平台进行了体系化的深度重构&lt;/strong&gt;，由四个相互支撑的核心模块组成了这套完整的数据评测基础设施。这标志着 ODA 已经从最初的功能验证阶段，发展成为可以对数据价值进行系统化评测的重要平台。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LB1ibad4vuOO7B5OVrFWyeHpvEAsiaWWkr2w8SqRzJLhl0J14mQJvfTKQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.7150537634408602" data-s="300,640" data-type="png" data-w="744" type="block" data-backw="578" data-backh="413" data-imgfileid="503526371" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/11b48278-3b1f-4e28-8ad0-2fd5ffd2e117/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;一、数据价值排行榜 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先，ODA 项目打造了&lt;strong&gt;数据价值排行榜&lt;/strong&gt;。通过构建一套统一的训练与评测流程，让数据在固定的模型规模（如 Llama3、Qwen2/3 7-8B）和训练配置下，对来自不同领域的文本及多模态数据进行横向评测。&lt;/p&gt;&lt;p&gt;评测覆盖&lt;strong&gt;通用、数学、代码、科学与长链推理&lt;/strong&gt;等能力维度，这使得数据价值能直接通过下游任务（如数学、代码、推理等）的实际表现来量化，而非主观判断。目前，ODA 平台已经从初版仅仅只有文本数据的评测，扩展到了&lt;strong&gt;多模态数据集的质量评测&lt;/strong&gt;，并以最先进的 Qwen3-VL 作为真实训练的基准模型。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LBUsuTDNeAPoUYORKbhqsuBfrlCxmcpicXSEx5mwiap88S5BSXEv0pZ7g/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.5944444444444444" data-s="300,640" data-type="png" data-w="1080" type="block" data-backw="578" data-backh="344" data-imgfileid="503526373" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/7837f64a-3732-4e23-8044-68c3613b31ed/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;二、数据血缘探索器 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;其次，针对数据界常见的「近亲繁殖」问题，ODA 全新发布&lt;strong&gt;「数据血缘探索器」&lt;/strong&gt;。它像绘制族谱一样，清晰地刻画出数据集之间的继承、混合与蒸馏关系。通过结构化建模与可视化展示，研究者可以直观地看到不同数据集之间的高度重叠与依赖关系，看到社区中被反复复用的核心数据源，以及更清晰的发现潜在的训练&amp;ndash;测试污染与「近亲繁殖」问题。这一能力让「为什么某些数据集长期霸榜」不再是经验结论，而是可以被结构性解释的现象。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LiccUeTeb9GZXPBbjTINf2lAOicSuOYJLKujWMNLuHIppRxgFpgWGmA6g/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.7522123893805309" data-s="300,640" data-type="png" data-w="904" type="block" data-backw="578" data-backh="435" data-imgfileid="503526378" data-aistatus="1" data-original-style="width:100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/2ef09f54-2727-47f3-9ada-d635d08c0d71/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;三、多维数据评分器 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;除了看模型结果，ODA 还从数据本体出发，对数据质量进行&lt;strong&gt;细粒度刻画&lt;/strong&gt;。ODA 提供了一个细粒度的评分框架，基于模型评估、LLM-as-a-Judge 与启发式指标等多种方法，从指令复杂度、响应质量、多样性等维度对数据进行深度剖析，生成每份数据的专属「体检报告」，并已对&lt;strong&gt;千万级样本的评分结果进行开源&lt;/strong&gt;。 这使得研究者不仅能判断「哪份数据更有效」，还能进一步分析它为什么有效。值得一提的是，在初版的基础上，ODA 多维数据评分器目前已经扩展支持 &lt;strong&gt;80+ 种多维度的评分器&lt;/strong&gt;，支持用户一键方便的对所需要的数据维度进行打分。&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LN3sX7jdIkoNfsrP9FYHDh4QoyV0zpOVZ6p1KUVF6XUBvd8f8OUbETQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-ratio="0.7522123893805309" data-s="300,640" data-type="png" data-w="904" type="block" data-backw="578" data-backh="435" data-imgfileid="503526379" data-aistatus="1" data-original-style="width: 100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/24bce8eb-9b51-43f1-868a-e84251dc44b5/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;四、全开源评测工具箱 &lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9fn3Ku1BLjJMJA5E8HHQ4LamBK7N12TJ9tJADvou546B5z7NcU1Yy3MPNfScmgC2nVr7ASdutsqg/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="0.22123893805309736" data-s="300,640" data-type="png" data-w="904" type="block" data-backw="578" data-backh="128" data-imgfileid="503526380" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/9d31c63c-184c-4e1d-9c1a-4f6fae6999ba/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 700%;"&gt;&lt;/section&gt;&lt;p&gt;此外，为了促进社区共建，&lt;strong&gt;ODA 完全开源&lt;/strong&gt;&lt;strong&gt;了&lt;/strong&gt;其训练、评分和可视化工具，覆盖从模型微调到结果复现的完整流程，以及上述精细化的数据评价打分器。ODA 工具支持用户&lt;strong&gt;一键复现结果&lt;/strong&gt;，或对自己私有数据进行标准化评测，实现真正意义上的横向对比。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、硬核发现：那些被忽视的数据真相&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在对 120 多个主流数据集进行超过 600 次训练和 4000 万条数据的深度分析后，OpenDataLab 团队得出了一系列具有指导意义的「硬核」结论，足以重塑业界对高质量数据的认知 ：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 解答质量比问题复杂度更关键&lt;/strong&gt;： 实验发现，单纯增加问题的复杂度并不能有效预测数据价值。相反，解答的长度（推理过程的充分性）与最终质量呈强正相关，这在数学和科学类任务中尤为突出。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 代码数据的「异类」属性&lt;/strong&gt;： 搞代码模型不能照搬数学的逻辑。代码讲究简洁精准，长篇大论反而会损害效果。这意味着通用的评分标准在代码领域经常失效，必须建立针对性的评估体系。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 开源数据「近亲繁殖」严重&lt;/strong&gt;： ODA 的数据血缘分析显示，社区反复依赖的核心数据源比较有限（例如 GSM8K 被多次复用），由此造成了严重的数据同质化。借助数据血缘分析，更极端的发现是，数据污染越来越严重：大量训练样本直接与测试集发生重叠。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.「少即是多」的局限性&lt;/strong&gt;： 尽管 LIMA 等研究曾宣称少量精选数据即可成功，但 ODA 的实验证明这极度依赖模型底座的先天能力。如果底座一般，过少的数据量会导致性能崩塌。真正稳健的路径是追求「高质量且具规模（High-Density Volume）」 的数据配方。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. 为什么有些数据集能霸榜？&lt;/strong&gt; 以 AM-Thinking-distilled 为代表的超大规模聚集型数据集，能够同时在数学与代码任务上取得明显的优势，关键原因在于其跨领域融合能力。它通过递归方式整合了&lt;strong&gt; 435 个数据节点&lt;/strong&gt;，显著提升了数据分布的多样性与互补性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6. 数据可以弥补底座差距&lt;/strong&gt;： 这是一个令人振奋的发现。即使 Llama 3.1 和 Qwen 2.5 之间存在显著的底座分差，只要用上如 OpenThoughts3-1.2M 这样的高质量微调数据，这个差距几乎可以被抹平。可以说，好的数据配方真的能让模型「逆天改命」。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;未来展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;OpenDataArena 的远景，绝不不满足于仅仅建立一个排行榜，更致力于将数据研发从「玄学」推向可复现、可分析的「科学」。未来，ODA 将持续进化，探索智能体数据，金融、医疗等垂直领域的深层价值。&lt;/p&gt;&lt;p&gt;在这个数据决定 AI 上限的时代，唯有手握科学的标尺，才能精准丈量每一份数据的真实「重量」。&lt;/p&gt;]]&gt;</content:encoded>
    </item>
    <item>
      <title>特斯拉FSD首次横穿美国，Model3实现1万英里零干预，马斯克预言兑现了</title>
      <description>&lt;![CDATA[]]&gt;</description>
      <author>机器之心</author>
      <pubDate>Fri, 02 Jan 2026 00:59:47 +0800</pubDate>
      <link>https://www.jiqizhixin.com/articles/2026-01-02-5</link>
      <guid>https://www.jiqizhixin.com/articles/2026-01-02-5</guid>
      <source>机器之心</source>
      <content:encoded>&lt;![CDATA[&lt;p&gt;&lt;img src="https://image.jiqizhixin.com/uploads/editor/682d6fe4-8a4f-4aff-9920-7a4f0436d522/1767286609265.png" style="width: 700%;" class="fr-fic fr-dib"&gt;在 2025 年最后一天，一个名为 David Moss 的小哥完成了一项壮举：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;成功实现世界上首次美国西海岸到东海岸的全自动驾驶之旅，同时也成为世界上第一个连续驾驶特斯拉 FSD 行驶 10000 英里的人。&lt;/strong&gt;&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuKQ8wKshRI3rhsBkpp8NRLaUiaFUWNFA0nbCvmBsNVZSHVsZIDe7W5Jw/640?wx_fmt=png&amp;from=appmsg#imgIndex=1" data-ratio="1.272045028142589" data-type="png" data-w="1066" data-width="1066" data-height="1356" data-backw="578" data-backh="735" data-imgfileid="503526482" data-aistatus="1" data-original-style="width:100%;" data-index="3" src="https://image.jiqizhixin.com/uploads/editor/45e45b75-e858-431a-8ddd-3cb9a86685ff/640.png" alt="图片" data-report-img-idx="1" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他开着一辆搭载 FSD V14.2 的 2025 款 Model 3，从洛杉矶的 Tesla Diner 出发，历时 2 天 20 小时，走了 2732.4 英里（约 4400 公里），最终抵达南卡罗来纳州的 Myrtle Beach。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu9pRjbkzBqXyBtict3cLNBmNYUxY3wCKoaexQBnG4RiajUGWmRYdUuAKA/640?wx_fmt=png&amp;from=appmsg#imgIndex=2" data-ratio="0.75" data-type="png" data-w="680" data-width="680" data-height="510" data-backw="578" data-backh="434" data-imgfileid="503526483" data-aistatus="1" data-original-style="width: 100%;" data-index="4" src="https://image.jiqizhixin.com/uploads/editor/e0b1116a-d59f-406e-9ba7-4f484381dc06/640.png" alt="图片" data-report-img-idx="2" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 一起完成壮举的搭档&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;整个过程零干预，甚至包括所有停车和在 Tesla 超级充电站充电的环节都没有人为接管。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu78r6Ic6vqgrT8ryjzOqsRqKtOqtFib31fXlKz7LiantcJc2RdEadWuEA/640?wx_fmt=png&amp;from=appmsg#imgIndex=3" data-ratio="0.562962962962963" data-type="png" data-w="1080" data-width="1200" data-height="675" data-backw="578" data-backh="325" data-imgfileid="503526485" data-aistatus="1" data-original-style="width: 100%;" data-index="5" src="https://image.jiqizhixin.com/uploads/editor/9dbf3409-c9aa-4457-ba58-98c6476eb92c/640.png" alt="图片" data-report-img-idx="3" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;他特别强调这是完全靠 FSD 完成的，并且数据可以通过 Whole Mars 的 FSD 数据库公开验证。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuE5aenf2Zkia2KEPvHrXWhFVVr6qLhAt1pWFDHGUHKsZwf1r9dRls5yw/640?wx_fmt=png&amp;from=appmsg#imgIndex=4" data-ratio="0.6537037037037037" data-type="png" data-w="1080" data-width="1725" data-height="1128" data-backw="578" data-backh="378" data-imgfileid="503526486" data-aistatus="1" data-original-style="width: 100%;" data-index="6" src="https://image.jiqizhixin.com/uploads/editor/5dd57762-0dcf-4743-995e-9570291e9e69/640.png" alt="图片" data-report-img-idx="4" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;sup&gt;你可在这里追踪他的 FSD 里程 https://fsddb.com/profile/DavidMoss，数据显示，他使用 FSD 在 Model 3 上行驶了 1 万多英里，从未亲自驾驶过车辆。&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Moss 在一张地图上详细标注了横跨美国的路线图：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-aistatus="1" data-backh="254" data-backw="578" data-height="899" data-imgfileid="503526488" data-ratio="0.4388888888888889" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuaVXZ8VOSasrCRhk1RpqWwRUvYhFVosEqG8mtia1FmD8se2T7L0gXyWA/640?wx_fmt=png&amp;from=appmsg#imgIndex=5" data-type="png" data-w="1080" data-width="2048" data-original-style="width:100%;" data-index="7" src="https://image.jiqizhixin.com/uploads/editor/7b99369e-979b-4d7b-9bad-5f00ceea90ba/640.png" alt="图片" data-report-img-idx="5" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;并列出了大约 30 个超级充电站的几乎完整的停留信息：&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu6uDN5ngLW1ybMfjBluNzNoYY5XaE428n5UnjKWalyb1c283Op8RZOw/640?wx_fmt=png&amp;from=appmsg#imgIndex=6" data-ratio="2.030456852791878" data-type="png" data-w="591" data-width="591" data-height="1200" data-backw="578" data-backh="1174" data-imgfileid="503526489" data-aistatus="1" data-original-style="width: 100%;" data-index="8" src="https://image.jiqizhixin.com/uploads/editor/1abaf619-2578-4be4-b025-7c0a7c82578f/640.png" alt="图片" data-report-img-idx="6" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;有网友在评论区询问：过程中是否出现过险情，Moss 表示完全没有。即使对于人类驾驶员来说，这也是不容易实现的。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuNF6YhSv7wBNqBmVuksLRotdIwQdXUWPaO63CIqcA9Myx5Ga1mMNRHQ/640?wx_fmt=png&amp;from=appmsg#imgIndex=7" data-ratio="0.3133208255159475" data-type="png" data-w="1066" data-width="1066" data-height="334" data-backw="578" data-backh="181" data-imgfileid="503526490" data-aistatus="1" data-original-style="width: 100%;" data-index="9" src="https://image.jiqizhixin.com/uploads/editor/7000fae3-5886-4209-a43d-56e0ca70138b/640.png" alt="图片" data-report-img-idx="7" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;马斯克看后直接转发并回复「Cool。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIunkrzLIGiaktUCYiczjA5lLsX2JSTwCNTcWJwQiaweBL7vQSGh4sFibzxmg/640?wx_fmt=png&amp;from=appmsg#imgIndex=8" data-ratio="1.223463687150838" data-type="png" data-w="1074" data-width="1074" data-height="1314" data-backw="578" data-backh="707" data-imgfileid="503526491" data-aistatus="1" data-original-style="width:100%;" data-index="10" src="https://image.jiqizhixin.com/uploads/editor/4ac9fd7d-9399-4434-b0d3-daa05c4c4712/640.png" alt="图片" data-report-img-idx="8" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;特斯拉 AI 主管 Ashok Elluswamy 称赞道：「这是世界上首次全自动海岸到海岸驾驶，感谢 David Moss！」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu83KGFH2tfSIpOUv9wiadZIxUBonbeZaJEWEZYRDR6qjrF0icxtKokjAw/640?wx_fmt=png&amp;from=appmsg#imgIndex=9" data-ratio="0.20610687022900764" data-type="png" data-w="1048" data-width="1048" data-height="216" data-backw="578" data-backh="119" data-imgfileid="503526492" data-aistatus="1" data-original-style="width: 100%;" data-index="11" src="https://image.jiqizhixin.com/uploads/editor/0709dd22-a7f5-42ea-9481-1604fc595282/640.png" alt="图片" data-report-img-idx="9" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;马斯克预言终兑现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Andrej Karpathy （特斯拉自动驾驶团队前领导、OpenAI 创始成员）也在第一时间发来贺电。他说，横跨美国的 coast-to-coast 自动驾驶，一直是 Autopilot 团队从立项之初就设定的目标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;事实上，马斯克最初预计，这一里程碑可以在 2017 年底实现。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;「为了完成它，团队投入了大量时间。无数个深夜，大家围坐在一起进行马拉松式的片段复盘，一条条查看自动接管的录像：先分流、再归类、再拆解问题，逐项规划项目，把每一个缺口补上，目标只有一个 &amp;mdash;&amp;mdash; 把干预次数降到零。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuKctwdRCRtVvstcWeTsEr3zs4fnw3LFf9EmZloc4HiaXrFxBsVVQJKYg/640?wx_fmt=png&amp;from=appmsg#imgIndex=10" data-ratio="0.592436974789916" data-type="png" data-w="714" data-width="714" data-height="423" data-backw="578" data-backh="342" data-imgfileid="503526493" data-aistatus="1" data-original-style="width: 100%;" data-index="12" src="https://image.jiqizhixin.com/uploads/editor/1f97343a-6e65-4f99-ae03-5d8c5072748f/640.png" alt="图片" data-report-img-idx="10" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;FSD v14.2（Full Self-Driving v14.2）是特斯拉在 2025 年底推出的一次关键自动驾驶软件更新，属于其 FSD 路线的最新进化版本，也允许用户跟踪他们在自动驾驶模式下行驶了多少英里。&lt;/p&gt;&lt;p&gt;相较此前的 v14.1.x，这一版本在驾驶表现、感知能力和决策逻辑上都有明显强化。&lt;/p&gt;&lt;p&gt;从特斯拉官方和社区的普遍反馈来看，FSD v14.2 明显朝着「更像人开车」演进。它在感知和决策上更稳定，对复杂路口、无保护左转、车道博弈的处理更果断，整体驾驶节奏更连贯。&lt;/p&gt;&lt;p&gt;虽然从定义上看，它依然是需要驾驶员监督的 L2 级系统，但在真实道路中的完成度已经显著提升。&lt;/p&gt;&lt;p&gt;小鹏汽车 CEO 何小鹏曾这样评价特斯拉 FSD v14.2：「我最近在美国花了四个小时试驾了特斯拉的 FSD V14.2。一句话总结：如果 FSD 在 2024 年仅仅是『不错的 L2 级驾驶辅助』，那么这个最新版本让我相信 L4 级自动驾驶指日可待。」&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIu2zn4jOSoI5w2yD2wwXtSgJjtJaPRyolybstuyhUbR0mZ4UGH1POBXw/640?wx_fmt=png&amp;from=appmsg#imgIndex=11" data-ratio="0.33195020746887965" data-type="png" data-w="723" data-width="723" data-height="240" data-backw="578" data-backh="192" data-imgfileid="503526494" data-aistatus="1" data-original-style="width: 100%;" data-index="13" src="https://image.jiqizhixin.com/uploads/editor/8d22b21b-a8aa-4140-bb58-e59bf92b19e5/640.png" alt="图片" data-report-img-idx="11" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;特斯拉 vs Waymo：两条路线的较量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;消息刷屏后，有 X 友 Yuchen Jin 向 Andrej Karpathy 抛出了一个尖锐的问题：你现在还认为 Waymo 的软件更好吗，还是特斯拉已经领先了？&lt;/p&gt;&lt;p&gt;要知道，Karpathy 过去的判断是 &amp;mdash;&amp;mdash;Waymo 有硬件问题，特斯拉有软件问题。&lt;/p&gt;&lt;p&gt;他回复说，如今两者都堪称「完美驾驶」，虽存在差异，但要么需要时间才能显现，要么只能在大规模车辆数据中被统计出来。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuJwN93J78IPAwbj14F0ZqU1HdoFnIALibx1LvWD43s4wK7lutumTBNuA/640?wx_fmt=png&amp;from=appmsg#imgIndex=12" data-ratio="0.975925925925926" data-type="png" data-w="1080" data-width="1310" data-height="1278" data-backw="578" data-backh="564" data-imgfileid="503526495" data-aistatus="1" data-original-style="width: 100%;" data-index="14" src="https://image.jiqizhixin.com/uploads/editor/91197589-2210-44bd-aa76-2e23d81619ad/640.png" alt="图片" data-report-img-idx="12" data-fail="0" class="fr-fic fr-dib" style="width: 50%;"&gt;&lt;/section&gt;&lt;p&gt;不久前发生在旧金山的一次停电，或许提供了一个现实注脚。停电导致 Waymo 的服务大面积中断，而特斯拉 FSD 基本未受影响。&lt;/p&gt;&lt;p&gt;网友分析指出，原因在于两条技术路线的根本差异。&lt;/p&gt;&lt;p&gt;Waymo 采用高度模块化的系统，依赖高清地图、激光雷达、多传感器融合、5G 网络以及多套神经网络协同工作。在一切条件正常时，它表现非常出色。但只要其中一个关键模块失效，系统就会迅速退化。&lt;/p&gt;&lt;p&gt;当交通信号灯断电后，现实世界已经发生变化，而 HD 地图无法即时反映，车辆无法确认状态，只能回退到最保守的策略 &amp;mdash;&amp;mdash; 直接停车（brick 模式），车辆还失去了与远程人工接管员的连接，进一步放大了系统的脆弱性。&lt;/p&gt;&lt;p&gt;而特斯拉 FSD 走的是端到端：一个巨大的神经网络，直接把摄像头的像素输入，转换为转向和制动控制。这正是 Andrej 所提出的 Software 2.0 思想 &amp;mdash;&amp;mdash; 不再为每一种场景手写 C++ 逻辑，而是用数十亿英里的人类驾驶数据去训练模型，代码本身就是模型权重。因此，它的驾驶方式更像人类。&lt;/p&gt;&lt;p&gt;一些观察者认为，如今真正面临软件瓶颈的，反而是 Waymo。模块化架构在规模化与依赖关系上，可能是一种长期的陷阱。长期来看，赢家会是特斯拉 FSD。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuZsbfqnDeuUq5HL6M1ReypCUSI39ZqaDdgY8N7QJRXZfD5PUQhLZhEw/640?wx_fmt=png&amp;from=appmsg#imgIndex=13" data-ratio="0.875" data-type="png" data-w="720" data-width="720" data-height="630" data-backw="578" data-backh="506" data-imgfileid="503526496" data-aistatus="1" data-original-style="width: 100%;" data-index="15" src="https://image.jiqizhixin.com/uploads/editor/77eea60a-2550-4499-bd6b-c012c50893f5/640.png" alt="图片" data-report-img-idx="13" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;迈向真正的自动驾驶&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;122 年前，汽车先驱 Horatio Jackson 和 Sewall Crocker （以及他们在途中收养的斗牛犬）曾从旧金山驾车前往纽约，用整整 63 天 横穿美国，只为证明汽车并非昙花一现的新奇玩意。&lt;/p&gt;&lt;p&gt;他们因此成为历史上第一批驾车横跨美国的人类 &amp;mdash;&amp;mdash; 以及那只狗。&lt;/p&gt;&lt;section data-pm-slice="0 0 []"&gt;&lt;img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4ataLIR7Ge5M8ia2JGDOIuTrNbgBJzOTnvvpyQEnbmd9pqtB10jJjibO7Xkc3lBjDr9EuumTexh7Q/640?wx_fmt=png&amp;from=appmsg#imgIndex=14" data-ratio="0.9925690021231423" data-type="png" data-w="942" data-width="942" data-height="935" data-backw="578" data-backh="574" data-imgfileid="503526498" data-aistatus="1" data-original-style="width:100%;" data-index="16" src="https://image.jiqizhixin.com/uploads/editor/ddd85ba9-9741-4498-955e-359e7873406a/640.png" alt="图片" data-report-img-idx="14" data-fail="0" class="fr-fic fr-dib" style="width: 70%;"&gt;&lt;/section&gt;&lt;p&gt;今天的这场壮举，或许只是自动驾驶迈出的一小步，但对「自动驾驶即机器人」而言，却可能是一记关键跳跃。&lt;/p&gt;&lt;p&gt;马斯克正在持续加码无人驾驶。6 月，特斯拉已在德克萨斯州奥斯汀推出一项有限规模的机器人出租车服务，使用的是搭载 FSD 的改装版 Model Y。更值得注意的是，马斯克近期透露，这批车辆已进入前排不再配备安全监控员的测试阶段。&lt;/p&gt;&lt;p&gt;从「有人盯着的自动驾驶」，到「系统自己负责」，这一变化幅度貌似不大，却触及了自动驾驶从辅助工具走向真正自主体的临界点。&lt;/p&gt;&lt;p&gt;&lt;sup&gt;参考链接：&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/DavidMoss/status/2006255297212358686&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/karpathy/status/2006436622909452501?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/Yuchenj_UW/status/2003173409665212629?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/SawyerMerritt/status/2006042728983908626?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/SawyerMerritt/status/2006042725385195766?s=20&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;https://x.com/elonmusk/status/2006290674761736346?s=20&lt;/sup&gt;&lt;/p&gt;]]&gt;</content:encoded>
    </item>
  </channel>
</rss>
